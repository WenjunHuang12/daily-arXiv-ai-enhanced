<div id=toc></div>

# Table of Contents

- [cs.GT](#cs.GT) [Total: 2]
- [cs.IT](#cs.IT) [Total: 11]
- [cs.DB](#cs.DB) [Total: 7]
- [cs.DS](#cs.DS) [Total: 11]
- [cs.IR](#cs.IR) [Total: 8]


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [1] [Optimized Distortion in Linear Social Choice](https://arxiv.org/abs/2510.20020)
*Luise Ge,Gregory Kehne,Yevgeniy Vorobeychik*

Main category: cs.GT

TL;DR: 该论文首次研究线性效用函数下的投票机制扭曲问题，提出了基于候选嵌入维度的扭曲边界，并开发了多项式时间的实例最优算法来最小化扭曲。


<details>
  <summary>Details</summary>
Motivation: 传统投票理论使用偏好排序可能导致相对于功利主义社会福利的次优结果。当候选人有向量表示且效用为参数化函数时，需要研究线性效用函数下的扭曲问题。

Method: 研究确定性和随机投票规则的线性社会选择扭曲，提出仅依赖候选嵌入维度的边界，并开发多项式时间的实例最优算法。

Result: 获得了仅依赖嵌入维度且独立于候选人和选民数量的扭曲边界，在推荐系统和意见调查等实际领域中对标准规则进行了基准测试。

Conclusion: 线性效用函数下的投票扭曲可以通过实例最优算法有效最小化，该方法在现实应用中优于标准投票规则。

Abstract: Social choice theory offers a wealth of approaches for selecting a candidate
on behalf of voters based on their reported preference rankings over options.
When voters have underlying utilities for these options, however, using
preference rankings may lead to suboptimal outcomes vis-\`a-vis utilitarian
social welfare. Distortion is a measure of this suboptimality, and provides a
worst-case approach for developing and analyzing voting rules when utilities
have minimal structure. However in many settings, such as common paradigms for
value alignment, alternatives admit a vector representation, and it is natural
to suppose that utilities are parametric functions thereof. We undertake the
first study of distortion for linear utility functions. Specifically, we
investigate the distortion of linear social choice for deterministic and
randomized voting rules. We obtain bounds that depend only on the dimension of
the candidate embedding, and are independent of the numbers of candidates or
voters. Additionally, we introduce poly-time instance-optimal algorithms for
minimizing distortion given a collection of candidates and votes. We
empirically evaluate these in two real-world domains: recommendation systems
using collaborative filtering embeddings, and opinion surveys utilizing
language model embeddings, benchmarking several standard rules against our
instance-optimal algorithms.

</details>


### [2] [Strategic Costs of Perceived Bias in Fair Selection](https://arxiv.org/abs/2510.20606)
*L. Elisa Celis,Lingxiao Huang,Milind Sohoni,Nisheeth K. Vishnoi*

Main category: cs.GT

TL;DR: 本文开发了一个博弈论模型，揭示在择优系统中，不同社会经济群体对选择后价值的感知差异如何导致努力程度的理性差异，从而在看似公平的选择过程中传播不平等。


<details>
  <summary>Details</summary>
Motivation: 旨在解释择优系统中持续存在的种族、性别和阶级差异现象，连接理性选择理论和结构性不平等解释，展示技术社会环境如何影响个人在择优系统中的激励。

Method: 开发了一个博弈论模型，候选人在不同社会经济群体中根据感知的选择后价值战略性地选择努力程度，努力转化为可观察的才能，选择仅基于才能。

Result: 描述了在大代理限制下的独特纳什均衡，推导出明确公式显示估值差异和机构选择性如何共同决定努力、代表性、社会福利和效用。

Conclusion: 提出了一个成本敏感优化框架，量化如何修改选择性或感知价值以减少差异而不损害机构目标，揭示了感知驱动的偏见机制。

Abstract: Meritocratic systems, from admissions to hiring, aim to impartially reward
skill and effort. Yet persistent disparities across race, gender, and class
challenge this ideal. Some attribute these gaps to structural inequality;
others to individual choice. We develop a game-theoretic model in which
candidates from different socioeconomic groups differ in their perceived
post-selection value--shaped by social context and, increasingly, by AI-powered
tools offering personalized career or salary guidance. Each candidate
strategically chooses effort, balancing its cost against expected reward;
effort translates into observable merit, and selection is based solely on
merit. We characterize the unique Nash equilibrium in the large-agent limit and
derive explicit formulas showing how valuation disparities and institutional
selectivity jointly determine effort, representation, social welfare, and
utility. We further propose a cost-sensitive optimization framework that
quantifies how modifying selectivity or perceived value can reduce disparities
without compromising institutional goals. Our analysis reveals a
perception-driven bias: when perceptions of post-selection value differ across
groups, these differences translate into rational differences in effort,
propagating disparities backward through otherwise "fair" selection processes.
While the model is static, it captures one stage of a broader feedback cycle
linking perceptions, incentives, and outcome--bridging rational-choice and
structural explanations of inequality by showing how techno-social environments
shape individual incentives in meritocratic systems.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [3] [Information Gradient for Nonlinear Gaussian Channel with Applications to Task-Oriented Communication](https://arxiv.org/abs/2510.20179)
*Tadashi Wadayama*

Main category: cs.IT

TL;DR: 提出了一个基于梯度的框架，用于通过互信息最大化来优化参数化非线性高斯信道。利用分数-费雪桥方法，推导出计算可行的信息梯度公式，该梯度可以表示为输出分布的分数函数和前端函数雅可比矩阵的组合，并通过去噪分数匹配和自动微分框架实现高效优化。


<details>
  <summary>Details</summary>
Motivation: 传统的互信息优化方法在非线性信道中计算复杂，难以实现端到端优化。本文旨在开发一个计算可行的梯度框架，能够直接优化非线性前端参数，而无需显式计算输出分布。

Method: 采用分数-费雪桥方法推导信息梯度公式，该梯度由两个关键部分组成：通过去噪分数匹配学习的边际输出分布的分数函数，以及通过自动微分框架中的向量-雅可比乘积高效处理的前端函数雅可比矩阵。

Result: 实验验证证实了信息梯度公式相对于解析解的正确性，并证明了该方法在优化线性和非线性信道以实现其目标方面的有效性。

Conclusion: 该框架为参数化非线性高斯信道的互信息最大化提供了一个实用且高效的梯度优化方法，支持端到端优化而无需显式计算输出分布。

Abstract: We propose a gradient-based framework for optimizing parametric nonlinear
Gaussian channels via mutual information maximization. Leveraging the
score-to-Fisher bridge (SFB) methodology, we derive a computationally tractable
formula for the information gradient that is the gradient of mutual information
with respect to the parameters of the nonlinear front-end. Our formula
expresses this gradient in terms of two key components: the score function of
the marginal output distribution, which can be learned via denoising score
matching (DSM), and the Jacobian of the front-end function, which is handled
efficiently using the vector-Jacobian product (VJP) within automatic
differentiation frameworks. This enables practical parameter optimization
through gradient ascent. Furthermore, we extend this framework to task-oriented
scenarios, deriving gradients for both task-specific mutual information, where
a task variable depends on the channel input, and the information bottleneck
(IB) objective. A key advantage of our approach is that it facilitates
end-to-end optimization of the nonlinear front-end without requiring explicit
computation on the output distribution. Extensive experimental validation
confirms the correctness of our information gradient formula against analytical
solutions and demonstrates its effectiveness in optimizing both linear and
nonlinear channels toward their objectives.

</details>


### [4] [New Second-Order Achievability Bounds for Coding with Side Information via Type Deviation Convergence](https://arxiv.org/abs/2510.20241)
*Xiang Li,Cheuk Ting Li*

Main category: cs.IT

TL;DR: 提出了一个名为类型偏差收敛的二阶可达性框架，适用于网络信息论设置，特别适用于有损源编码和带成本的信道编码。改进了Wyner-Ziv问题、Heegard-Berger问题和Gelfand-Pinsker问题的二阶可达性界。


<details>
  <summary>Details</summary>
Motivation: 为网络信息论中的各种设置提供一个通用的二阶可达性分析框架，特别关注有损源编码和带成本的信道编码问题，以改进现有的性能界限。

Method: 提出了类型偏差收敛框架，这是一种二阶可达性分析方法。将该框架应用于Wyner-Ziv问题、Heegard-Berger问题和Gelfand-Pinsker问题，推导出改进的二阶可达性界。

Result: 为Wyner-Ziv问题提供了一个优于所有已知界限的二阶可达性界；为Heegard-Berger问题和带成本的Gelfand-Pinsker问题提供了改进的二阶可达性界。

Conclusion: 类型偏差收敛框架是网络信息论中二阶可达性分析的有效工具，能够显著改进多个重要问题的性能界限，特别在有损源编码和带成本的信道编码方面表现出色。

Abstract: We propose a framework for second-order achievability, called type deviation
convergence, that is generally applicable to settings in network information
theory, and is especially suitable for lossy source coding and channel coding
with cost. We give a second-order achievability bound for lossy source coding
with side information at the decoder (Wyner-Ziv problem) that improves upon all
known bounds (e.g., Watanabe-Kuzuoka-Tan, Yassaee-Aref-Gohari and
Li-Anantharam). We also give second-order achievability bounds for lossy
compression where side information may be absent (Heegard-Berger problem) and
channels with noncausal state information at the encoder and cost constraint
(Gelfand-Pinsker problem with cost) that improve upon previous bounds.

</details>


### [5] [A Location-Aware Hybrid Deep Learning Framework for Dynamic Near-Far Field Channel Estimation in Low-Altitude UAV Communications](https://arxiv.org/abs/2510.20277)
*Wenli Yuan,Kan Yu,Xiaowu Liu,Kaixuan Li,Qixun Zhang,Zhiyong Feng*

Main category: cs.IT

TL;DR: 提出了一种基于位置感知混合深度学习架构的统一信道估计框架，用于解决低空无人机通信中的混合近远场传播条件挑战。


<details>
  <summary>Details</summary>
Motivation: 传统信道估计方法基于远场假设，无法捕捉近场场景的复杂信道变化，且忽略了实时收发器位置等有价值的几何先验信息。

Method: 结合CNN进行空间特征提取、BiLSTM网络建模时间演化、多头自注意力机制增强对判别性信道分量的关注，并嵌入实时收发器位置作为几何先验。

Result: 在归一化均方误差(NMSE)上平均至少减少30.25%，显著优于现有基准方法。

Conclusion: 所提出的位置感知混合深度学习框架能有效处理混合近远场传播条件，显著提升低空无人机通信的信道估计性能。

Abstract: In low altitude UAV communications, accurate channel estimation remains
challenging due to the dynamic nature of air to ground links, exacerbated by
high node mobility and the use of large scale antenna arrays, which introduce
hybrid near and far field propagation conditions. While conventional estimation
methods rely on far field assumptions, they fail to capture the intricate
channel variations in near-field scenarios and overlook valuable geometric
priors such as real-time transceiver positions. To overcome these limitations,
this paper introduces a unified channel estimation framework based on a
location aware hybrid deep learning architecture. The proposed model
synergistically combines convolutional neural networks (CNNs) for spatial
feature extraction, bidirectional long short term memory (BiLSTM) networks for
modeling temporal evolution, and a multihead self attention mechanism to
enhance focus on discriminative channel components. Furthermore, real-time
transmitter and receiver locations are embedded as geometric priors, improving
sensitivity to distance under near field spherical wavefronts and boosting
model generalization. Extensive simulations validate the effectiveness of the
proposed approach, showing that it outperforms existing benchmarks by a
significant margin, achieving at least a 30.25% reduction in normalized mean
square error (NMSE) on average.

</details>


### [6] [Moving or Predicting? RoleAware-MAPP: A Role-Aware Transformer Framework for Movable Antenna Position Prediction to Secure Wireless Communications](https://arxiv.org/abs/2510.20293)
*Wenxu Wang,Xiaowu Liu,Wei Gong,Yujia Zhao,Kaixuan Li,Qixun Zhang,Zhiyong Feng,Kan Yu*

Main category: cs.IT

TL;DR: 提出RoleAware-MAPP框架，利用Transformer和领域知识解决可移动天线定位问题，显著提升物理层安全性能


<details>
  <summary>Details</summary>
Motivation: 解决可移动天线技术在实际部署中的两大挑战：实时优化计算复杂度和机械运动与信道快速变化的时间不匹配问题

Method: 将MA定位问题重新定义为预测任务，采用基于Transformer的框架，包含角色感知嵌入、物理信息语义特征和复合损失函数三个关键组件

Result: 在3GPP兼容场景下，平均保密率达到0.3569 bps/Hz，严格正保密容量达到81.52%，比最强基线分别提升48.4%和5.39个百分点

Conclusion: RoleAware-MAPP框架通过整合领域知识，有效解决了可移动天线定位的关键挑战，在物理层安全方面表现出优越性能

Abstract: Movable antenna (MA) technology provides a promising avenue for actively
shaping wireless channels through dynamic antenna positioning, thereby enabling
electromagnetic radiation reconstruction to enhance physical layer security
(PLS). However, its practical deployment is hindered by two major challenges:
the high computational complexity of real time optimization and a critical
temporal mismatch between slow mechanical movement and rapid channel
variations. Although data driven methods have been introduced to alleviate
online optimization burdens, they are still constrained by suboptimal training
labels derived from conventional solvers or high sample complexity in
reinforcement learning. More importantly, existing learning based approaches
often overlook communication-specific domain knowledge, particularly the
asymmetric roles and adversarial interactions between legitimate users and
eavesdroppers, which are fundamental to PLS. To address these issues, this
paper reformulates the MA positioning problem as a predictive task and
introduces RoleAware-MAPP, a novel Transformer based framework that
incorporates domain knowledge through three key components: role-aware
embeddings that model user specific intentions, physics-informed semantic
features that encapsulate channel propagation characteristics, and a composite
loss function that strategically prioritizes secrecy performance over mere
geometric accuracy. Extensive simulations under 3GPP-compliant scenarios show
that RoleAware-MAPP achieves an average secrecy rate of 0.3569 bps/Hz and a
strictly positive secrecy capacity of 81.52%, outperforming the strongest
baseline by 48.4% and 5.39 percentage points, respectively, while maintaining
robust performance across diverse user velocities and noise conditions.

</details>


### [7] [Ergodic Mutual Information and Outage Probability for SIM-Assisted Holographic MIMO Communications](https://arxiv.org/abs/2510.20307)
*Anastasios Papazafeiropoulos,Pandelis Kourtessis,Dimitra I. Kaklamani,Iakovos S. Venieris*

Main category: cs.IT

TL;DR: 本文研究了堆叠智能超表面辅助MIMO系统的遍历互信息和中断概率，使用大随机矩阵理论推导了互信息分布，并基于统计CSI提出了中断概率的闭式表达式和优化算法。


<details>
  <summary>Details</summary>
Motivation: 堆叠智能超表面相比单层超表面具有更好的性能，但目前文献中缺乏对SIM辅助MIMO系统的遍历互信息和中断概率的研究。

Method: 使用大随机矩阵理论工具分析互信息分布，推导基于统计CSI的中断概率闭式表达式，并应用梯度下降法优化中断概率。

Result: 仿真结果验证了理论分析，显示相比传统MIMO系统和单层超表面有性能提升，且所提优化算法比交替优化基准更快、开销更小。

Conclusion: 堆叠智能超表面能显著提升MIMO系统性能，所提分析方法有效且优化算法高效。

Abstract: Stacked intelligent metasurface (SIM) is a promising enabler for
next-generation high-capacity networks that exhibit better performance compared
to its single-layer counterpart by means of just wave propagation. However, the
study of ergodic mutual information (EMI) and outage probability for
SIM-assisted multiple-input-multiple-output (MIMO) systems is not available in
the literature. To this end, we obtain the distribution of the MI by using
large random matrix theory (RMT) tools. Next, we derive a tight closed-form
expression for the outage probability based on statistical channel state
information (CSI). Moreover, we apply the gradient descent method for the
minimization of the outage probability. Simulation results verify the
analytical results and provide fundamental insights such as the performance
enhancements compared to conventional MIMO systems and the single-layer
counterpart. Notably the proposed optimization algorithm is faster than the
alternating optimization (AO) benchmark by saving significant overhead.

</details>


### [8] [Robust Analog Lagrange Coded Computing: Theory and Algorithms via Discrete Fourier Transforms](https://arxiv.org/abs/2510.20379)
*Rimpi Borah,J. Harshan*

Main category: cs.IT

TL;DR: 提出了安全的模拟拉格朗日编码计算框架，通过DFT码纠错算法增强对拜占庭工作节点的鲁棒性，并利用信任配置文件优化任务分配策略。


<details>
  <summary>Details</summary>
Motivation: 现有ALCC框架虽然能保护数据隐私和应对延迟节点，但无法抵御拜占庭工作节点返回错误结果的威胁，需要增强其安全性。

Method: 使用DFT码的纠错算法构建新的重建策略，并基于DFT解码器性能理论提出考虑工作节点信任配置文件的任务分配方法。

Result: 提出的框架在有限数量拜占庭工作节点下显著提高了计算精度，且当主服务器掌握信任配置文件时能进一步优化性能。

Conclusion: 该安全ALCC框架有效提升了对抗拜占庭攻击的能力，但需注意浮点实现精度噪声可能被利用的合谋攻击风险。

Abstract: Analog Lagrange Coded Computing (ALCC) is a recently proposed computational
paradigm wherein certain computations over analog datasets are efficiently
performed using distributed worker nodes through floating point representation.
While the vanilla version of ALCC is known to preserve the privacy of the
datasets from the workers and also achieve resilience against stragglers, it is
not robust against Byzantine workers that return erroneous results.
Highlighting this vulnerability, we propose a secure ALCC framework that is
resilient against a wide range of integrity threats from the Byzantine workers.
As a foundational step, we use error-correction algorithms for Discrete Fourier
Transform (DFT) codes to build novel reconstruction strategies for ALCC thereby
improving its computational accuracy in the presence of a bounded number of
Byzantine workers. Furthermore, capitalizing on some theoretical results on the
performance of the DFT decoders, we propose novel strategies for distributing
the ALCC computational tasks to the workers, and show that such methods
significantly improve the accuracy when the workers' trust profiles are
available at the master server. Finally, we study the robustness of the
proposed framework against colluding attacks, and show that interesting attack
strategies can be executed by exploiting the inherent precision noise owing to
floating point implementation.

</details>


### [9] [Adversary-Aware Private Inference over Wireless Channels](https://arxiv.org/abs/2510.20518)
*Mohamed Seif,Malcolm Egan,Andrea J. Goldsmith,H. Vincent Poor*

Main category: cs.IT

TL;DR: 提出了一种用于隐私保护AI感知的新框架，设备在将提取的特征传输到模型服务器之前应用特征变换


<details>
  <summary>Details</summary>
Motivation: 解决边缘网络中传感器和模型服务器分离时特征传输的隐私风险，防止对手重构敏感个人数据

Method: 设备在传输前对提取的特征进行变换处理

Result: 未在摘要中明确说明

Conclusion: 该框架为保护AI感知中的个体特征隐私提供了解决方案

Abstract: AI-based sensing at wireless edge devices has the potential to significantly
enhance Artificial Intelligence (AI) applications, particularly for vision and
perception tasks such as in autonomous driving and environmental monitoring. AI
systems rely both on efficient model learning and inference. In the inference
phase, features extracted from sensing data are utilized for prediction tasks
(e.g., classification or regression). In edge networks, sensors and model
servers are often not co-located, which requires communication of features. As
sensitive personal data can be reconstructed by an adversary, transformation of
the features are required to reduce the risk of privacy violations. While
differential privacy mechanisms provide a means of protecting finite datasets,
protection of individual features has not been addressed. In this paper, we
propose a novel framework for privacy-preserving AI-based sensing, where
devices apply transformations of extracted features before transmission to a
model server.

</details>


### [10] [Simultaneous Wireless Information and Power Transfer for Fluid Antenna Systems](https://arxiv.org/abs/2510.20569)
*Feilong Zhang,Jianxin Dai,Zhaohui Yang,Kai-Kit Wong,Lingyuxiu Li,Jianglin Ye*

Main category: cs.IT

TL;DR: 提出了一种结合MISO流体天线与传统固定位置天线的新通信系统，通过天线位置优化提升能量收集效率。


<details>
  <summary>Details</summary>
Motivation: 流体天线技术通过改变天线位置来提高通信速率，本文旨在利用这一特性提升SWIPT系统中的能量收集效率。

Method: 在SWIPT框架下，通过优化发射和接收流体天线位置以及发射协方差矩阵，在满足IR最小SINR约束条件下最大化ER的功率接收。

Result: 仿真结果表明，与传统固定位置天线相比，流体天线系统能显著提升ER的能量收集效率。

Conclusion: 流体天线系统在SWIPT应用中具有显著优势，能有效提高能量收集性能。

Abstract: Fluid antenna is a promising wireless communication technology that enhances
communication rate by changing the antenna positions. This article proposes a
new communication system that combines multiple-input single-output (MISO)
fluid antennas with traditional fixed-position antennas, utilizing antenna
position optimization to improve energy harvesting efficiency. In this model,
we consider simultaneous wireless information and power transfer (SWIPT) which
transmits identical signals from the base station to both information receiver
(IR) and energy receiver (ER). We strive to enhance the power delivered to the
ER by fine-tuning the positions of transmit and receive fluid antennas, along
with optimizing the transmit covariance matrix, subject to a given minimum
signal-to-interference-plus-noise ratio (SINR) constraint at the IR. Simulation
results indicate that fluid antenna systems significantly enhance the energy
harvesting efficiency of the ER compared to traditional fixed-position
antennas.

</details>


### [11] [Stacked Intelligent Metasurfaces for 6G Wireless Networks: Principles, Applications, and Research Directions](https://arxiv.org/abs/2510.20572)
*Enyu Shi,Jiayi Zhang,Zhilong Liu,Ziheng Liu,Arumugam Nallanathan,Merouane Debbah,Shi Jin,Bo Ai*

Main category: cs.IT

TL;DR: 本文综述了基于堆叠智能超表面(SIM)的分布式无线网络，探讨其在6G网络中的应用场景、系统架构和关键技术，展示了显著的性能提升，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要提供无处不在的连接、弹性覆盖和智能服务，分布式无线架构如无蜂窝大规模MIMO因其可扩展性和公平性受到关注。SIM作为可重构智能表面的演进，提供了增强的电磁域处理能力。

Method: 将SIM集成到分布式无线网络中，实现先进的波域操作，包括分层框架、用户关联和联合预编码等信号处理技术。

Result: 案例研究表明SIM辅助的分布式无线网络在干扰管理、能量和频谱效率以及物理层安全性方面取得了显著性能提升。

Conclusion: SIM辅助的分布式无线网络为实现可扩展和智能的6G网络铺平了道路，未来需要在硬件设计、能耗建模、算法开发和人工智能集成等方面进一步研究。

Abstract: The sixth-generation (6G) wireless networks are expected to deliver
ubiquitous connectivity, resilient coverage, and intelligence-driven services
in highly dynamic environments. To achieve these goals, distributed wireless
architectures such as cell-free massive multiple-input multiple-output (MIMO)
have attracted significant attention due to their scalability and fairness.
Recently, stacked intelligent metasurfaces (SIMs) have emerged as a promising
evolution of reconfigurable intelligent surfaces, offering multi-layer
electromagnetic domain processing with enhanced controllability and spatial
degrees of freedom. By integrating SIMs into distributed wireless networks,
advanced wave-domain operations can be realized, enabling efficient
interference management, improved energy and spectral efficiency, and robust
physical-layer security. This article provides a comprehensive overview of
SIM-aided distributed wireless networks, including their application scenarios,
classification, and system architectures. Key signal processing challenges,
such as hierarchical frameworks, user association, and joint precoding, are
discussed, followed by case studies demonstrating significant performance
gains. Finally, future research directions in hardware design, energy
consumption modeling, algorithm development, and artificial intelligence
integration are highlighted, aiming to pave the way for scalable and
intelligent 6G distributed wireless networks.

</details>


### [12] [Super-Linear Growth of the Capacity-Achieving Input Support for the Amplitude-Constrained AWGN Channel](https://arxiv.org/abs/2510.20723)
*Haiyang Wang*

Main category: cs.IT

TL;DR: 本文研究了幅度受限AWGN信道容量达到输入分布的支撑集大小增长问题，证明了最优输入分布的支撑点数K(A)随幅度约束A增加呈超线性增长。


<details>
  <summary>Details</summary>
Motivation: 虽然Smith(1971)已证明最优输入是离散的且只有有限个支撑点，但关于支撑点数K(A)随幅度约束A增加的紧致界仍然开放。本文旨在填补这一理论空白。

Method: 结合输出分布在总变差意义下收敛到均匀分布的特性，以及高斯混合逼近的定量极限，推导新的解析下界。

Result: 证明了K(A)随A增加呈超线性增长，提供了比现有文献更精确的增长速率下界。

Conclusion: 本文为幅度受限AWGN信道的最优输入分布支撑集大小提供了新的理论下界，解决了该领域长期存在的开放问题。

Abstract: We study the growth of the support size of the capacity-achieving input
distribution for the amplitude-constrained additive white Gaussian noise (AWGN)
channel. While it is known since Smith (1971) that the optimal input is
discrete with finitely many mass points, tight bounds on the number of support
points $K(A)$ as the amplitude constraint $A$ increases remain open. Building
on recent work by Dytso \emph{et al.} (2019) and Mattingly \emph{et al.}
(2018), we derive a new analytical lower bound showing that $K(A)$ grows
super-linearly in $A$. Our approach combines total-variation convergence of the
output distribution to the uniform law with quantitative limits on Gaussian
mixture approximation.

</details>


### [13] [MIMO-Zak-OTFS with Superimposed Spread Pilots](https://arxiv.org/abs/2510.20734)
*Abhishek Bairwa,Ananthanarayanan Chockalingam*

Main category: cs.IT

TL;DR: 该论文提出了一种用于MIMO-Zak-OTFS系统的叠加扩频导频设计和有效信道估计方法，通过在交叉模糊域分离导频序列，并结合turbo迭代来减轻导频-数据干扰。


<details>
  <summary>Details</summary>
Motivation: 在MIMO-Zak-OTFS系统中，数据与扩频导频信号叠加在同一帧中，不同发射天线的导频需要在接收端有效分离以实现良好的信道估计性能。

Method: 提出了一种在交叉模糊域分离导频序列的扩频导频设计，通过简单的读取操作估计有效信道抽头，并采用信道估计与检测之间的turbo迭代来减轻导频-数据干扰。

Result: 仿真结果显示，在2×2和3×3 MIMO-Zak-OTFS系统中，采用高斯sinc脉冲成形滤波器和车辆-A信道模型，所提出的导频设计和估计方案经过三次turbo迭代后能获得非常好的估计/检测性能。

Conclusion: 所提出的叠加扩频导频设计和turbo迭代信道估计方案在MIMO-Zak-OTFS系统中能够有效实现信道估计，具有良好的性能表现。

Abstract: In this paper, we consider the problem of spread pilot design and effective
channel estimation in multiple-input multiple-output Zak-OTFS (MIMO-Zak-OTFS)
with superimposed spread pilots, where data and spread pilot signals are
superimposed in the same frame. To achieve good estimation performance in a
MIMO setting, the spread pilots at different transmit antennas need to be
effectively separated at the receiver. Towards this, we propose a spread pilot
design that separates the pilot sequences in the cross-ambiguity domain and
enables the estimation of the effective channel taps by a simple read-off
operation. To further alleviate the effect of pilot-data interference on
performance, we carry out turbo iterations between channel estimation and
detection. Simulation results for $2\times 2$ and $3\times 3$ MIMO-Zak-OTFS
with Gaussian-sinc pulse shaping filter for vehicular-A channel model show that
the proposed pilot design and estimation scheme with three turbo iterations can
achieve very good estimation/detection performance.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [14] [Query Optimization in the Wild: Realities and Trends](https://arxiv.org/abs/2510.20082)
*Yuanyuan Tian*

Main category: cs.DB

TL;DR: 传统查询优化器设计面临云时代挑战，论文提出三个关键趋势：优化与执行的反馈循环、从单查询到工作负载的优化范围扩展、从单体到可组合架构的转变。


<details>
  <summary>Details</summary>
Motivation: 云计算、海量数据和统一数据平台的兴起暴露了传统单体查询优化器架构的局限性，需要重新思考工业级数据库系统的优化器设计。

Method: 从工业视角回顾查询优化的过去和现状，识别当前挑战，分析三个正在兴起的行业趋势。

Result: 识别出三个关键趋势：优化与执行的紧密反馈循环、优化范围扩展到工作负载、向可组合架构转变，这些趋势为查询优化实践指明了发展方向。

Conclusion: 这些趋势共同描绘了查询优化向更动态、全面和适应性强的未来发展的清晰路径。

Abstract: For nearly half a century, the core design of query optimizers in industrial
database systems has remained remarkably stable, relying on foundational
principles from System R and the Volcano/Cascades framework. However, the rise
of cloud computing, massive data volumes, and unified data platforms has
exposed the limitations of this traditional, monolithic architecture. Taking an
industrial perspective, this paper reviews the past and present of query
optimization in production systems and identifies the challenges they face
today. Then this paper highlights three key trends gaining momentum in the
industry that promise to address these challenges. First, a tighter feedback
loop between query optimization and query execution is being used to improve
the robustness of query performance. Second, the scope of optimization is
expanding from a single query to entire workloads through the convergence of
query optimization and workload optimization. Third, and perhaps most
transformatively, the industry is moving from monolithic designs to composable
architectures that foster agility and cross-engine collaboration. Together,
these trends chart a clear path toward a more dynamic, holistic, and adaptable
future for query optimization in practice.

</details>


### [15] [UREM: A High-performance Unified and Resilient Enhancement Method for Multi- and High-Dimensional Indexes](https://arxiv.org/abs/2510.20110)
*Ming Sheng,Shuliang Wang,Yong Zhang,Yi Luo,Xianbo Liu,Zeming Li*

Main category: cs.DB

TL;DR: UREM是一种统一且弹性的增强方法，适用于多维度和高维度索引，能够自适应不同场景，提升查询性能。


<details>
  <summary>Details</summary>
Motivation: 现有索引增强方法存在局限性：结构导向方法在静态负载下表现良好但缺乏通用性，布局导向方法通用性好但在静态负载下性能不佳。需要开发统一且弹性的增强方法。

Method: UREM通过布局优化提升静态负载下的查询性能，通过部分布局重组使索引在查询变化时保持性能稳定，可统一应用于不同平台的各种索引。

Result: 在20个广泛使用的索引上评估，UREM在静态负载下将多维度和高维度索引的查询性能分别提升最高5.73倍和9.18倍，在动态负载下平均提升5.72倍和9.47倍。

Conclusion: UREM是首个高性能的统一弹性增强方法，能够显著提升不同索引在各种场景下的查询性能，部分传统索引增强后性能甚至超过最新先进索引。

Abstract: Numerous multi- or high-dimensional indexes with distinct advantages have
been proposed on various platforms to meet application requirements. To achieve
higher-performance queries, most indexes employ enhancement methods, including
structure-oriented and layout-oriented enhancement methods. Existing
structure-oriented methods tailored to specific indexes work well under static
workloads but lack generality and degrade under dynamic workloads. The
layout-oriented methods exhibit good generality and perform well under dynamic
workloads, but exhibit suboptimal performance under static workloads.
Therefore, it is an open challenge to develop a unified and resilient
enhancement method that can improve query performance for different indexes
adaptively under different scenarios. In this paper, we propose UREM, which is
the first high-performance Unified and Resilient Enhancement Method designed
for both multi- and high-dimensional indexes, capable of adapting to different
scenarios. Specifically, UREM (1) can be uniformly applied with different
indexes on various platforms; (2) enhances the query performance of indexes by
layout optimization under static workloads; (3) enables indexes to stabilize
performance when queries shift through partial layout reorganization. We
evaluate UREM on 20 widely used indexes. Experimental results demonstrate that
UREM improves the query performance of multi- and high-dimensional indexes by
up to 5.73x and 9.18x under static workloads, and by an average of 5.72x and
9.47x under dynamic workloads. Moreover, some traditional indexes enhanced by
UREM even achieve performance comparable to or even surpassing that of recent
advanced indexes.

</details>


### [16] [RAG-Stack: Co-Optimizing RAG Quality and Performance From the Vector Database Perspective](https://arxiv.org/abs/2510.20296)
*Wenqi Jiang*

Main category: cs.DB

TL;DR: RAG-Stack是一个三支柱蓝图，用于在检索增强生成(RAG)系统中共同优化质量和性能，包括中间表示层、成本模型和计划探索算法。


<details>
  <summary>Details</summary>
Motivation: 在端到端RAG管道中，如何联合优化系统性能和生成质量是一个实际但具有挑战性的问题，因为涉及算法和系统层面的众多参数。

Method: 提出RAG-Stack三支柱框架：RAG-IR中间表示层解耦质量和性能；RAG-CM成本模型估计系统性能；RAG-PE计划探索算法搜索高质量高性能配置。

Result: RAG-Stack提供了一个系统化的质量-性能协同优化范式，能够有效解决RAG系统中复杂的优化问题。

Conclusion: 这个三支柱蓝图有望成为未来RAG质量-性能协同优化的标准范式。

Abstract: Retrieval-augmented generation (RAG) has emerged as one of the most prominent
applications of vector databases. By integrating documents retrieved from a
database into the prompt of a large language model (LLM), RAG enables more
reliable and informative content generation. While there has been extensive
research on vector databases, many open research problems remain once they are
considered in the wider context of end-to-end RAG pipelines. One practical yet
challenging problem is how to jointly optimize both system performance and
generation quality in RAG, which is significantly more complex than it appears
due to the numerous knobs on both the algorithmic side (spanning models and
databases) and the systems side (from software to hardware). In this paper, we
present RAG-Stack, a three-pillar blueprint for quality-performance
co-optimization in RAG systems. RAG-Stack comprises: (1) RAG-IR, an
intermediate representation that serves as an abstraction layer to decouple
quality and performance aspects; (2) RAG-CM, a cost model for estimating system
performance given an RAG-IR; and (3) RAG-PE, a plan exploration algorithm that
searches for high-quality, high-performance RAG configurations. We believe this
three-pillar blueprint will become the de facto paradigm for RAG
quality-performance co-optimization in the years to come.

</details>


### [17] [Hybrid Mixed Integer Linear Programming for Large-Scale Join Order Optimisation](https://arxiv.org/abs/2510.20308)
*Manuel Schönberger,Immanuel Trummer,Wolfgang Mauerer*

Main category: cs.DB

TL;DR: 提出基于混合整数线性规划（MILP）的新方法来解决大规模查询的连接顺序优化问题，能够处理多达100个关系的复杂查询，并实现最稳健的计划质量。


<details>
  <summary>Details</summary>
Motivation: 传统查询优化器在小型查询中依赖穷举搜索方法，但在大规模查询中效率低下。现有启发式方法随着查询规模增大，解决方案质量下降或存在高度次优的最坏情况行为。

Method: 开发了能够优化任意bushy树结构的MILP模型，并将其嵌入混合框架中，在MILP求解器最有优势的地方应用，对较不复杂的优化步骤使用更高效的方法。

Result: 该方法能够优雅地扩展到包含多达100个关系的极大查询规模，并在多种连接排序方法中始终实现最稳健的计划质量。

Conclusion: 基于MILP的混合框架方法成功解决了大规模查询的连接顺序优化问题，克服了现有方法的局限性，提供了高效且稳健的解决方案。

Abstract: Finding optimal join orders is among the most crucial steps to be performed
by query optimisers. Though extensively studied in data management research,
the problem remains far from solved: While query optimisers rely on exhaustive
search methods to determine ideal solutions for small problems, such methods
reach their limits once queries grow in size. Yet, large queries become
increasingly common in real-world scenarios, and require suitable methods to
generate efficient execution plans. While a variety of heuristics have been
proposed for large-scale query optimisation, they suffer from degrading
solution quality as queries grow in size, or feature highly sub-optimal
worst-case behavior, as we will show.
  We propose a novel method based on the paradigm of mixed integer linear
programming (MILP): By deriving a novel MILP model capable of optimising
arbitrary bushy tree structures, we address the limitations of existing MILP
methods for join ordering, and can rely on highly optimised MILP solvers to
derive efficient tree structures that elude competing methods. To ensure
optimisation efficiency, we embed our MILP method into a hybrid framework,
which applies MILP solvers precisely where they provide the greatest advantage
over competitors, while relying on more efficient methods for less complex
optimisation steps. Thereby, our approach gracefully scales to extremely large
query sizes joining up to 100 relations, and consistently achieves the most
robust plan quality among a large variety of competing join ordering methods.

</details>


### [18] [An Empirical Study on Database Usage in Microservices](https://arxiv.org/abs/2510.20582)
*Maxime André,Marco Raglianti,Souhaila Serbout,Anthony Cleve,Michele Lanza*

Main category: cs.DB

TL;DR: 对微服务架构中数据库使用情况的实证研究，分析了约1000个GitHub项目，涵盖15年间的180种数据库技术，发现52%的微服务组合使用多种数据库类别。


<details>
  <summary>Details</summary>
Motivation: 微服务架构改变了数据库管理模式，从单一数据库转向多个小型、异构、分布式数据库。虽然数据管理是主要挑战，但相关研究文献稀缺。

Method: 收集并发布开放数据集，分析约1000个GitHub项目，涵盖180种数据库技术（14个类别），进行综合实践分析。

Result: 微服务主要使用关系型、键值、文档和搜索数据库；52%的微服务组合多种数据库类别；复杂度与数据库数量相关；旧系统偏好关系型数据库，新系统更多采用键值和文档技术；小众数据库通常与主流数据库结合使用。

Conclusion: 提供了18个发现和9个建议，为研究人员和从业者理解微服务中数据库使用提供了实证证据。

Abstract: Microservices architectures are an integral part of modern software
development. Their adoption brings significant changes to database management.
Instead of relying on a single database, a microservices architecture is
typically composed of multiple, smaller, heterogeneous, and distributed DBs. In
these data-intensive systems, the variety and combination of database
categories and technologies play a crucial role in storing and managing data.
While data management in microservices is a major challenge, research
literature is scarce.
  We present an empirical study on how databases are used in microservices. On
the dataset we collected (and released as open data for future research),
considering 15 years of microservices, we examine ca. 1,000 GitHub projects
that use databases selected among 180 technologies from 14 categories. We
perform a comprehensive analysis of current practices, providing researchers
and practitioners with empirical evidence to better understand database usage
in microservices. We report 18 findings and 9 recommendations. We show that
microservices predominantly use Relational, Key-Value, Document, and Search
databases. Notably, 52% of microservices combine multiple database categories.
Complexity correlates with database count, with older systems favoring
Relational databases and newer ones increasingly adopting Key-Value and
Document technologies. Niche databases (e.g., EventStoreDB, PostGIS), while not
widespread, are often combined with a mainstream one.

</details>


### [19] [Balanced Popularity in Multi-Product Billboard Advertisement](https://arxiv.org/abs/2510.20600)
*Dildar Ali,Suman Banerjee,Yamuna Prasad*

Main category: cs.DB

TL;DR: 本文研究了多产品影响力最大化问题，旨在为多个产品选择广告位，在预算和影响力平衡约束下最大化总影响力。


<details>
  <summary>Details</summary>
Motivation: 传统的广告位选择主要针对单一产品，而现实中广告商通常需要同时推广多个产品，且希望各产品的影响力相对均衡。

Method: 采用线性规划松弛与随机舍入方法，并提出基于贪心算法和平衡校正的启发式算法。

Result: 在真实轨迹和广告牌数据集上的实验表明，所提方法相比基线方法能获得更高的影响力。

Conclusion: 该问题具有NP难性质，提出的解决方案能有效处理多产品广告位选择问题，并在实际应用中表现良好。

Abstract: The billboard advertisement has emerged as an effective out-of-home
advertisement technique where the objective is to choose a limited number of
slots to play some advertisement content (e.g., animation, video, etc.) with
the hope that the content will be visible to a large number of travelers, and
this will be helpful to earn more revenue. In this paper, we study a variant of
the influential slot selection problem where the advertiser wants to promote
multiple products. Formally, we call this problem the \textsc{Multi-Product
Influence Maximization Problem for the Balanced Popularity} Problem. The input
to our problem is a trajectory and a billboard database, as well as a budget
for each product. The goal here is to choose a subset of slots for each product
such that the aggregated influence of all the products gets maximized subject
to the following two constraints: total selection cost for each product is less
than or equal to the allocated budget for that product, and the difference
between the influence for any two products is less than or equal to a given
threshold. We show that the problem is NP-hard to solve optimally. We formulate
this problem as a linear programming problem and use linear programming
relaxation with randomized rounding. Further, we propose a greedy-based
heuristic with balance correction to solve this problem. We conduct a number of
experiments with real-world trajectory and billboard datasets, and the results
are reported. From the reported results, we observe that the proposed solution
approaches lead to more influence compared to many baseline methods.

</details>


### [20] [Downsizing Diffusion Models for Cardinality Estimation](https://arxiv.org/abs/2510.20681)
*Xinhe Mu,Zhaoqi Zhou,Zaijiu Shang,Chuan Zhou,Gang Fu,Guiying Yan,Guoliang Li,Zhiming Ma*

Main category: cs.DB

TL;DR: ADC+是基于扩散模型的联合分布基数估计器，通过轻量级评分估计器计算点密度，使用GMM预测选择性并结合重要性采样进行校正，相比现有方法在准确性和效率上都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 受基于评分的扩散模型在高维文本、视频和图像分布估计中的优异表现启发，开发首个基于扩散模型的联合分布基数估计器。

Method: ADC使用轻量级评分估计器近似评分函数来计算点密度；ADC+结合GMM预测选择性，使用重要性采样蒙特卡洛校正，并通过决策树识别高选择性查询来跳过校正阶段。

Result: 在真实数据集上，ADC+以约66%的存储空间优于Naru、MSCN等方法，在95%和99%分位误差上比MSCN准确3倍；在合成数据集上比Naru准确10倍。

Conclusion: ADC+在准确性和效率上都显著优于现有方法，特别是在处理复杂多边相关属性时表现出更强的鲁棒性。

Abstract: Inspired by the performance of score-based diffusion models in estimating
complex text, video, and image distributions with thousands of dimensions, we
introduce Accelerated Diffusion Cardest (ADC), the first joint distribution
cardinality estimator based on a downsized diffusion model.
  To calculate the pointwise density value of data distributions, ADC's density
estimator uses a formula that evaluates log-likelihood by integrating the score
function, a gradient mapping which ADC has learned to efficiently approximate
using its lightweight score estimator. To answer ranged queries, ADC's
selectivity estimator first predicts their selectivity using a Gaussian Mixture
Model (GMM), then uses importance sampling Monte Carlo to correct its
predictions with more accurate pointwise density values calculated by the
density estimator. ADC+ further trains a decision tree to identify the
high-volume, high-selectivity queries that the GMM alone can predict very
accurately, in which case it skips the correction phase to prevent Monte Carlo
from adding more variance. Doing so lowers median Q-error and cuts per-query
latency by 25 percent, making ADC+ usually twice as fast as Naru, arguably the
state-of-the-art joint distribution cardinality estimator.
  Numerical experiments using well-established benchmarks show that on all
real-world datasets tested, ADC+ is capable of rivaling Naru and outperforming
MSCN, DeepDB, LW-Tree, and LW-NN using around 66 percent their storage space,
being at least 3 times as accurate as MSCN on 95th and 99th percentile error.
Furthermore, on a synthetic dataset where attributes exhibit complex,
multilateral correlations, ADC and ADC+ are considerably robust while almost
every other learned model suffered significant accuracy declines. In this case,
ADC+ performs better than any other tested model, being 10 times as accurate as
Naru on 95th and 99th percentile error.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [21] [On Hardness and Approximation of Broadcasting in Sparse Graphs](https://arxiv.org/abs/2510.20026)
*Jeffrey Bringolf,Hovhannes A. Harutyunyan,Shahin Kamali,Seyed-Mohammad Seyed-Javadi*

Main category: cs.DS

TL;DR: 本文研究了稀疏图中的电话广播问题，证明了在k-环图和k-路径图上该问题是NP难的，同时提出了多项式时间近似方案，并发现带宽有界图上的问题可在多项式时间内解决。


<details>
  <summary>Details</summary>
Motivation: 电话广播问题在一般图上已被证明是NP难的，但在稀疏图族中的计算复杂性仍存在未解决的问题。本文旨在研究k-环图、k-路径图等简单稀疏图族中的复杂性边界。

Method: 采用NP难性证明和算法设计相结合的方法：首先证明k-环图和k-路径图上的NP难性，然后为这些图族设计多项式时间近似方案，最后研究带宽有界图的多项式时间可解性。

Result: 1) 证明了k-环图和k-路径图上的电话广播问题是NP难的；2) 为这些图族设计了PTAS，改进了现有的近似因子；3) 证明了带宽有界图上的问题可在多项式时间内解决。

Conclusion: 本文确定了电话广播问题在稀疏图族中的复杂性边界：在k-环图和k-路径图上NP难但可近似，在带宽有界图上多项式时间可解，为理解该问题在稀疏图上的计算复杂性提供了重要进展。

Abstract: We study the Telephone Broadcasting problem in sparse graphs. Given a
designated source in an undirected graph, the task is to disseminate a message
to all vertices in the minimum number of rounds, where in each round every
informed vertex may inform at most one uninformed neighbor. For general graphs
with $n$ vertices, the problem is NP-hard. Recent work shows that the problem
remains NP-hard even on restricted graph classes such as cactus graphs of
pathwidth $2$ [Aminian et al., ICALP 2025] and graphs at distance-1 to a path
forest [Egami et al., MFCS 2025].
  In this work, we investigate the problem in several sparse graph families. We
first prove NP-hardness for $k$-cycle graphs, namely graphs formed by $k$
cycles sharing a single vertex, as well as $k$-path graphs, namely graphs
formed by $k$ paths with shared endpoints. Despite multiple efforts to
understand the problem in these simple graph families, the computational
complexity of the problem had remained unsettled, and our hardness results
answer open questions by Bhabak and Harutyunyan [CALDAM 2015] and Harutyunyan
and Hovhannisyan [COCAO 2023] concerning the problem's complexity in $k$-cycle
and $k$-path graphs, respectively.
  On the positive side, we present Polynomial-Time Approximation Schemes
(PTASs) for $k$-cycle and $k$-path graphs, improving over the best existing
approximation factors of $2$ for $k$-cycle graphs and an approximation factor
of $4$ for $k$-path graphs. Moreover, we identify a structural frontier for
tractability by showing that the problem is solvable in polynomial time on
graphs of bounded bandwidth. This result generalizes existing tractability
results for special sparse families such as necklace graphs.

</details>


### [22] [Parallel Joinable B-Trees in the Fork-Join I/O Model](https://arxiv.org/abs/2510.20053)
*Michael Goodrich,Yan Gu,Ryuto Kitagawa,Yihan Sun*

Main category: cs.DS

TL;DR: 本文提出了一种基于B树的并行集合操作算法，在Fork-Join I/O模型下实现了高效的I/O性能，解决了现有连接框架在I/O效率方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的并行连接框架树虽然支持高效的集合操作，但其I/O访问模式效率低下，且缺乏对I/O成本的严格理论保证。本文旨在解决这一关键问题。

Method: 引入Fork-Join I/O模型来衡量并行计算中的I/O成本，提出基于B树的新并行算法，支持并集、交集和差集操作。

Result: 算法实现了O(m log_B(n/m))的I/O工作量和O(log_B m · log_2 log_B n + log_B n)的I/O跨度，其中n和m≤n是两棵树的大小，B是块大小。

Conclusion: 该工作首次为并行连接框架树提供了严格的I/O成本理论保证，证明了在Fork-Join I/O模型下可以实现高效的并行集合操作。

Abstract: Balanced search trees are widely used in computer science to efficiently
maintain dynamic ordered data. To support efficient set operations (e.g.,
union, intersection, difference) using trees, the join-based framework is
widely studied. This framework has received particular attention in the
parallel setting, and has been shown to be effective in enabling simple and
theoretically efficient set operations on trees. Despite the widespread
adoption of parallel join-based trees, a major drawback of previous work on
such data structures is the inefficiency of their input/output (I/O) access
patterns. Some recent work (e.g., C-trees and PaC-trees) focused on more
I/O-friendly implementations of these algorithms. Surprisingly, however, there
have been no results on bounding the I/O-costs for these algorithms. It remains
open whether these algorithms can provide tight, provable guarantees in
I/O-costs on trees.
  This paper studies efficient parallel algorithms for set operations based on
search tree algorithms using a join-based framework, with a special focus on
achieving I/O efficiency in these algorithms. To better capture the
I/O-efficiency in these algorithms in parallel, we introduce a new
computational model, Fork-Join I/O Model, to measure the I/O costs in fork-join
parallelism. This model measures the total block transfers (I/O work) and their
critical path (I/O span). Under this model, we propose our new solution based
on B-trees. Our parallel algorithm computes the union, intersection, and
difference of two B-trees with $O(m \log_B(n/m))$ I/O work and $O(\log_B m
\cdot \log_2 \log_B n + \log_B n)$ I/O span, where $n$ and $m \leq n$ are the
sizes of the two trees, and $B$ is the block size.

</details>


### [23] [Optimal Rounding for Two-Stage Bipartite Matching](https://arxiv.org/abs/2510.20153)
*Tristan Pollner,Amin Saberi,Anders Wikum*

Main category: cs.DS

TL;DR: 本文研究两阶段二分图匹配问题，提出了多项式时间近似算法，在顶点加权图中达到7/8近似比，在边加权图中达到约0.828近似比，改进了现有最佳结果。


<details>
  <summary>Details</summary>
Motivation: 研究两阶段二分图匹配问题，其中图的边分两批出现，需要设计在线算法来最大化总匹配权重。

Method: 通过将两阶段揭示的分数匹配进行舍入，使离线节点（或边）以与其分数权重成比例的概率被匹配，最多损失常数因子。利用依赖舍入产生的负关联性来推导随机图中最大权重匹配期望大小的新下界。

Result: 在顶点加权图中达到7/8近似比，在边加权图中达到2√2-2≈0.828近似比，且这些比率与自然分数松弛的完整性间隙上界匹配。对于仅有分布样本访问的情况，多项式数量样本足以在近似比中获得ε的加性损失。

Conclusion: 提出的算法改进了两阶段二分图匹配问题的最佳已知近似比，并扩展到仅有分布样本访问的设置。

Abstract: We study two-stage bipartite matching, in which the edges of a bipartite
graph on vertices $(B_1 \cup B_2, I)$ are revealed in two batches. In stage
one, a matching must be selected from among revealed edges $E \subseteq B_1
\times I$. In stage two, edges $E^\theta \subseteq B_2 \times I$ are sampled
from a known distribution, and a second matching must be selected between $B_2$
and unmatched vertices in $I$. The objective is to maximize the total weight of
the combined matching. We design polynomial-time approximations to the optimum
online algorithm, achieving guarantees of $7/8$ for vertex-weighted graphs and
$2\sqrt{2}-2 \approx 0.828$ for edge-weighted graphs under arbitrary
distributions. Both approximation ratios match known upper bounds on the
integrality gap of the natural fractional relaxation, improving upon the
best-known approximation of 0.767 by Feng, Niazadeh, and Saberi for unweighted
graphs whose second batch consists of independently arriving nodes.
  Our results are obtained via an algorithm that rounds a fractional matching
revealed in two stages, aiming to match offline nodes (respectively, edges)
with probability proportional to their fractional weights, up to a
constant-factor loss. We leverage negative association (NA) among offline node
availabilities -- a property induced by dependent rounding -- to derive new
lower bounds on the expected size of the maximum weight matching in random
graphs where one side is realized via NA binary random variables. Moreover, we
extend these results to settings where we have only sample access to the
distribution. In particular, $\text{poly}(n,\epsilon^{-1})$ samples suffice to
obtain an additive loss of $\epsilon$ in the approximation ratio for the
vertex-weighted problem; a similar bound holds for the edge-weighted problem
with an additional (unavoidable) dependence on the scale of edge weights.

</details>


### [24] [Smoothed Analysis of Online Metric Matching with a Single Sample: Beyond Metric Distortion](https://arxiv.org/abs/2510.20288)
*Yingxi Li,Ellen Vitercik,Mingwei Yang*

Main category: cs.DS

TL;DR: 本文研究了欧几里得度量空间中的在线度量匹配问题，在服务器对抗且请求来自不同分布的情况下，提出了一个不依赖分布知识、仅需每个分布一个样本的O(1)竞争比算法。


<details>
  <summary>Details</summary>
Motivation: 在线度量匹配问题中，现有算法在非i.i.d.设置下通常只能达到Ω(log n)竞争比。本文旨在突破这一障碍，在更一般的分布设置下获得更好的竞争比保证。

Method: 采用简单的确定性嵌入方法，直接分析算法在目标度量上的成本，而非分别分析嵌入失真和算法性能。结合通过主化参数推导的欧几里得度量离线最优下界。

Result: 对于d≠2的欧几里得度量空间，提出了一个O(1)竞争比的算法，这是首个在非平凡度量空间非i.i.d.设置下达到o(log n)竞争比的算法。

Conclusion: 通过绕过概率度量嵌入的Ω(log n)障碍，本文证明了在欧几里得度量空间中，即使服务器对抗且请求来自不同分布，也能实现常数竞争比的在线匹配。

Abstract: In the online metric matching problem, $n$ servers and $n$ requests lie in a
metric space. Servers are available upfront, and requests arrive sequentially.
An arriving request must be matched immediately and irrevocably to an available
server, incurring a cost equal to their distance. The goal is to minimize the
total matching cost.
  We study this problem in the Euclidean metric $[0, 1]^d$, when servers are
adversarial and requests are independently drawn from distinct distributions
that satisfy a mild smoothness condition. Our main result is an
$O(1)$-competitive algorithm for $d \neq 2$ that requires no distributional
knowledge, relying only on a single sample from each request distribution. To
our knowledge, this is the first algorithm to achieve an $o(\log n)$
competitive ratio for non-trivial metrics beyond the i.i.d. setting. Our
approach bypasses the $\Omega(\log n)$ barrier introduced by probabilistic
metric embeddings: instead of analyzing the embedding distortion and the
algorithm separately, we directly bound the cost of the algorithm on the target
metric of a simple deterministic embedding. We then combine this analysis with
lower bounds on the offline optimum for Euclidean metrics, derived via
majorization arguments, to obtain our guarantees.

</details>


### [25] [Separations between Oblivious and Adaptive Adversaries for Natural Dynamic Graph Problems](https://arxiv.org/abs/2510.20341)
*Aaron Bernstein,Sayan Bhattacharya,Nick Fischer,Peter Kiss,Thatchaphol Saranurak*

Main category: cs.DS

TL;DR: 本文首次在动态图问题中建立了针对遗忘对手和自适应对手的动态算法之间的更新时间分离，基于细粒度复杂性假设。


<details>
  <summary>Details</summary>
Motivation: 研究动态算法在不同对手模型下的性能差异，填补了现有分离结果要么依赖强密码学假设，要么针对非显式输入问题的空白。

Method: 基于组合BMM、3SUM和APSP假设，分析增量最大独立集和减量最大团问题的算法复杂度，并与现有算法进行对比。

Result: 证明了在自适应对手下，增量最大独立集需要n^(1-o(1))摊销更新时间，减量最大团需要Δ/n^(o(1))摊销更新时间，而遗忘对手下仅需polylog(n)时间。

Conclusion: 在自然动态图问题中首次实现了指数级分离，同时提供了增量与减量算法在三角形检测问题上的首个分离结果。

Abstract: We establish the first update-time separation between dynamic algorithms
against oblivious adversaries and those against adaptive adversaries in natural
dynamic graph problems, based on popular fine-grained complexity hypotheses.
Specifically, under the combinatorial BMM hypothesis, we show that every
combinatorial algorithm against an adaptive adversary for the incremental
maximal independent set problem requires $n^{1-o(1)}$ amortized update time.
Furthermore, assuming either the 3SUM or APSP hypotheses, every algorithm for
the decremental maximal clique problem needs $\Delta/n^{o(1)}$ amortized update
time when the initial maximum degree is $\Delta \le \sqrt{n}$. These lower
bounds are matched by existing algorithms against adaptive adversaries. In
contrast, both problems admit algorithms against oblivious adversaries that
achieve $\operatorname{polylog}(n)$ amortized update time [Behnezhad,
Derakhshan, Hajiaghayi, Stein, Sudan; FOCS '19] [Chechik, Zhang; FOCS '19].
Therefore, our separations are exponential. Previously known separations for
dynamic algorithms were either engineered for contrived problems and relied on
strong cryptographic assumptions [Beimel, Kaplan, Mansour, Nissim, Saranurak,
Stemmer; STOC '22], or worked for problems whose inputs are not explicitly
given but are accessed through oracle calls [Bateni, Esfandiari, Fichtenberger,
Henzinger, Jayaram, Mirrokni, Wiese; SODA '23].
  As a byproduct, we also provide a separation between incremental and
decremental algorithms for the triangle detection problem: we show a
decremental algorithm with $\tilde{O}(n^{\omega})$ total update time, while
every incremental algorithm requires $n^{3-o(1)}$ total update time, assuming
the OMv hypothesis. To our knowledge this is the first separation of this kind.

</details>


### [26] [$\ell_2/\ell_2$ Sparse Recovery via Weighted Hypergraph Peeling](https://arxiv.org/abs/2510.20361)
*Nick Fischer,Vasileios Nakos*

Main category: cs.DS

TL;DR: 提出了一种新的k稀疏近似算法，在O((k/ε) log n)时间内实现(1+ε)因子近似，改进了之前最快的算法，运行时间减少了log n倍。


<details>
  <summary>Details</summary>
Motivation: 改进现有k稀疏近似算法的运行时间，寻求更高效且实用的解决方案。

Method: 使用非自适应线性草图，结合新的加权超图剥离技术，将已知的超图剥离过程扩展到边和节点具有权重的场景。

Result: 算法在O((k/ε) log n)时间内恢复最佳k稀疏近似，使用O((k/ε) log n)行和O(log n)列稀疏度的草图，运行时间比之前最快算法减少了log n倍。

Conclusion: 该方法简单实用，在广泛参数范围内达到最优，加权超图剥离技术为相关问题的分析提供了新工具。

Abstract: We demonstrate that the best $k$-sparse approximation of a length-$n$ vector
can be recovered within a $(1+\epsilon)$-factor approximation in
$O((k/\epsilon) \log n)$ time using a non-adaptive linear sketch with
$O((k/\epsilon) \log n)$ rows and $O(\log n)$ column sparsity. This improves
the running time of the fastest-known sketch [Nakos, Song; STOC '19] by a
factor of $\log n$, and is optimal for a wide range of parameters.
  Our algorithm is simple and likely to be practical, with the analysis built
on a new technique we call weighted hypergraph peeling. Our method naturally
extends known hypergraph peeling processes (as in the analysis of Invertible
Bloom Filters) to a setting where edges and nodes have (possibly correlated)
weights.

</details>


### [27] [From Incremental Transitive Cover to Strongly Polynomial Maximum Flow](https://arxiv.org/abs/2510.20368)
*Daniel Dadush,James B. Orlin,Aaron Sidford,László A. Végh*

Main category: cs.DS

TL;DR: 本文提出了更快的强多项式时间算法来解决结构化网络中的最大流问题，包括在n^(ω+o(1))时间内计算最大二分b-匹配，以及在m^(1+o(1))W时间内解决具有树分解宽度W的图上的问题。


<details>
  <summary>Details</summary>
Motivation: 旨在改进Orlin在2013年提出的最先进O(mn)时间最大流算法，通过加强和高效实现其方法来解决结构化网络中的最大流问题。

Method: 开发了一个通用框架，将任意容量的最大流问题转化为：(1)解决一系列多项式有界容量的最大流问题；(2)动态维护在弧添加下的传递闭包的大小有界超集（称为增量传递覆盖问题）。

Result: 实现了更快的强多项式时间算法，具体包括n^(ω+o(1))时间最大二分b-匹配算法和m^(1+o(1))W时间树分解图上的最大流算法。

Conclusion: 通过结合Chen等人和Brand等人的弱多项式几乎线性时间最大流算法，并开发增量传递覆盖数据结构，成功改进了结构化网络中最大流问题的计算效率。

Abstract: We provide faster strongly polynomial time algorithms solving maximum flow in
structured $n$-node $m$-arc networks. Our results imply an $n^{\omega +
o(1)}$-time strongly polynomial time algorithms for computing a maximum
bipartite $b$-matching where $\omega$ is the matrix multiplication constant.
Additionally, they imply an $m^{1 + o(1)} W$-time algorithm for solving the
problem on graphs with a given tree decomposition of width $W$.
  We obtain these results by strengthening and efficiently implementing an
approach in Orlin's (STOC 2013) state-of-the-art $O(mn)$ time maximum flow
algorithm. We develop a general framework that reduces solving maximum flow
with arbitrary capacities to (1) solving a sequence of maximum flow problems
with polynomial bounded capacities and (2) dynamically maintaining a
size-bounded supersets of the transitive closure under arc additions; we call
this problem \emph{incremental transitive cover}. Our applications follow by
leveraging recent weakly polynomial, almost linear time algorithms for maximum
flow due to Chen, Kyng, Liu, Peng, Gutenberg, Sachdeva (FOCS 2022) and Brand,
Chen, Kyng, Liu, Peng, Gutenberg, Sachdeva, Sidford (FOCS 2023), and by
developing incremental transitive cover data structures.

</details>


### [28] [Compact representations of pattern-avoiding permutations](https://arxiv.org/abs/2510.20382)
*László Kozma,Michal Opler*

Main category: cs.DS

TL;DR: 本文设计了一种数据结构，能够以O(n lg s_π)比特存储任何避免固定模式π的大小为n的排列τ，支持O(1)时间的τ(i)和τ⁻¹(i)查询，突破了通用排列的下界限制。


<details>
  <summary>Details</summary>
Motivation: 模式避免排列在组合数学和理论计算机科学中具有重要意义。现有数据结构对通用排列的查询时间存在下界限制，但对于模式避免排列，可以利用其特殊结构设计更高效的数据结构。

Method: 设计了一种基于模式避免排列特殊结构的数据结构，利用Stanley-Wilf极限s_π实现最优空间占用。对于有界树宽排列类，进一步减少空间开销到低阶加性项。

Result: 实现了O(1)时间的排列值查询和逆查询，支持更复杂的几何查询如矩形范围计数（O(lg lg n)时间），突破了通用情况下的下界限制。所有数据结构都能在线性时间内构建。

Conclusion: 证明了模式避免排列可以利用其组合结构设计突破通用下界的高效数据结构，为这类重要数学对象提供了实用的计算工具。

Abstract: Pattern-avoiding permutations are a central object of study in both
combinatorics and theoretical computer science. In this paper we design a data
structure that can store any size-$n$ permutation $\tau$ that avoids an
arbitrary (and unknown) fixed pattern $\pi$ in the asymptotically optimal $O(n
\lg{s_\pi})$ bits, where $s_\pi$ is the Stanley-Wilf limit of $\pi$. Our data
structure supports $\tau(i)$ and $\tau^{-1}(i)$ queries in $O(1)$ time,
sidestepping the lower bound of Golynski (SODA 2009) that holds for general
permutations. Comparable results were previously known only in more restricted
cases, e.g., when $\tau$ is separable, which means avoiding the patterns 2413
and 3142.
  We also extend our data structure to support more complex geometric queries
on pattern-avoiding permutations (or planar point sets) such as rectangle range
counting in $O(\lg\lg{n})$ time. This result circumvents the lower bound of
$\Omega{(\lg{n}/\lg\lg{n})}$ by P\u{a}tra\c{s}cu (STOC 2007) that holds in the
general case. For bounded treewidth permutation classes (which include the
above-mentioned separable class), we further reduce the space overhead to a
lower order additive term, making our data structure succinct. This extends and
improves results of Chakraborty et al. (ISAAC 2024) that were obtained for
separable permutations via different techniques. All our data structures can be
constructed in linear time.

</details>


### [29] [Parallel $(1+ε)$-Approximate Multi-Commodity Mincost Flow in Almost Optimal Depth and Work](https://arxiv.org/abs/2510.20456)
*Bernhard Haeupler,Yonggang Jiang,Yaowei Long,Thatchaphol Saranurak,Shengzhe Wang*

Main category: cs.DS

TL;DR: 提出了一种并行算法，用于在无向图上计算(1+ε)-近似最小成本流，其中容量和成本同时分配给边和顶点。该算法在ε>1/polylog(m)时实现Õ(m)工作量和Õ(1)深度，使得工作和深度都几乎最优。


<details>
  <summary>Details</summary>
Motivation: 现有的Õ(m)工作量算法需要Ω(m)深度，即使对于只有边容量的最小成本流或只有顶点容量的最大流等特殊情况也是如此。本文旨在开发一种在保持几乎最优工作量的同时实现常数深度的并行算法。

Method: 关键技术贡献是首次构建了具有(1+ε)长度松弛、Õ(1)拥塞松弛和Õ(1)步数限制的长度约束流快捷方式。这推广了有影响力的(Õ(1),ε)-跳集概念，允许对拥塞进行额外控制。还开发了用于计算长度约束顶点扩展器分解的近线性时间算法。

Result: 算法在ε>1/polylog(m)时实现Õ(m)工作量和Õ(1)深度，工作和深度都几乎最优。进一步扩展到解决(1+ε)-近似k-商品最小成本流问题，具有几乎最优的Õ(mk)工作量和Õ(1)深度，与商品数量k无关。

Conclusion: 该工作提供了第一个在保持几乎最优工作量的同时实现常数深度的并行最小成本流算法，推广了先前关于最短路径和最大流等特殊情况的几乎最优并行算法。

Abstract: We present a parallel algorithm for computing $(1+\epsilon)$-approximate
mincost flow on an undirected graph with $m$ edges, where capacities and costs
are assigned to both edges and vertices. Our algorithm achieves $\hat{O}(m)$
work and $\hat{O}(1)$ depth when $\epsilon > 1/\mathrm{polylog}(m)$, making
both the work and depth almost optimal, up to a subpolynomial factor.
  Previous algorithms with $\hat{O}(m)$ work required $\Omega(m)$ depth, even
for special cases of mincost flow with only edge capacities or max flow with
vertex capacities. Our result generalizes prior almost-optimal parallel
$(1+\epsilon)$-approximation algorithms for these special cases, including
shortest paths [Li, STOC'20] [Andoni, Stein, Zhong, STOC'20] [Rozhen, Haeupler,
Marinsson, Grunau, Zuzic, STOC'23] and max flow with only edge capacities
[Agarwal, Khanna, Li, Patil, Wang, White, Zhong, SODA'24].
  Our key technical contribution is the first construction of
length-constrained flow shortcuts with $(1+\epsilon)$ length slack,
$\hat{O}(1)$ congestion slack, and $\hat{O}(1)$ step bound. This provides a
strict generalization of the influential concept of
$(\hat{O}(1),\epsilon)$-hopsets [Cohen, JACM'00], allowing for additional
control over congestion. Previous length-constrained flow shortcuts [Haeupler,
Hershkowitz, Li, Roeyskoe, Saranurak, STOC'24] incur a large constant in the
length slack, which would lead to a large approximation factor. To enable our
flow algorithms to work under vertex capacities, we also develop a
close-to-linear time algorithm for computing length-constrained vertex expander
decomposition.
  Building on Cohen's idea of path-count flows [Cohen, SICOMP'95], we further
extend our algorithm to solve $(1+\epsilon)$-approximate $k$-commodity mincost
flow problems with almost-optimal $\hat{O}(mk)$ work and $\hat{O}(1)$ depth,
independent of the number of commodities $k$.

</details>


### [30] [Provably Small Portfolios for Multiobjective Optimization with Application to Subsidized Facility Location](https://arxiv.org/abs/2510.20555)
*Swati Gupta,Jai Moondra,Mohit Singh*

Main category: cs.DS

TL;DR: 该论文提出了投资组合的概念，为多目标优化问题构建一个小型解集，使得对于给定目标函数类中的任意函数，投资组合中至少存在一个α近似解。论文提供了构建投资组合的可证明算法，并应用于公平补贴设施选址问题。


<details>
  <summary>Details</summary>
Motivation: 多目标现实问题（如设施选址和公交路线规划）在平衡多个利益相关者优先级时变得复杂。传统方法通过显式平衡公平性和效率目标来建模，但这种方法得到的解结构可能差异很大。

Method: 引入投资组合概念，构建小型解集P，使得对于目标函数类C中的任意函数h(·)，P中至少存在一个α近似解。提供了构建投资组合的可证明算法，适用于锥组合和单调插值类（如Lp范数和top-ℓ范数）。

Result: 开发了新颖的双准则近似算法，应用于公平补贴设施选址问题，显著减少了美国各州的医疗荒漠现象。

Conclusion: 投资组合方法帮助决策者理解多个目标平衡的影响，为多目标优化问题提供了有效的解决方案框架。

Abstract: Many multiobjective real-world problems, such as facility location and bus
routing, become more complex when optimizing the priorities of multiple
stakeholders. These are often modeled using infinite classes of objectives,
e.g., $L_p$ norms over group distances induced by feasible solutions in a fixed
domain. Traditionally, the literature has considered explicitly balancing
`equity' (or min-max) and `efficiency' (or min-sum) objectives to capture this
trade-off. However, the structure of solutions obtained by such modeling
choices can be very different. Taking a solution-centric approach, we introduce
the concept of provably small set of solutions $P$, called a {\it portfolio},
such that for every objective function $h(\cdot)$ in the given class
$\mathbf{C}$, there exists some solution in $P$ which is an
$\alpha$-approximation for $h(\cdot)$. Constructing such portfolios can help
decision-makers understand the impact of balancing across multiple objectives.
  Given a finite set of base objectives $h_1, \ldots, h_N$, we give provable
algorithms for constructing portfolios for (1) the class of conic combinations
$\mathbf{C} = \{\sum_{j \in [N]}\lambda_j h_j: \lambda \ge 0\}$ and for (2) any
class $\mathbf{C}$ of functions that interpolates monotonically between the
min-sum efficiency objective (i.e., $h_1 + \ldots + h_N$) and the min-max
equity objective (i.e., $\max_{j \in [N]} h_j$). Examples of the latter are
$L_p$ norms and top-$\ell$ norms. As an application, we study the Fair
Subsidized Facility Location (FSFL) problem, motivated by the crisis of medical
deserts caused due to pharmacy closures. FSFL allows subsidizing facilities in
underserved areas using revenue from profitable locations. We develop a novel
bicriteria approximation algorithm and show a significant reduction of medical
deserts across states in the U.S.

</details>


### [31] [A Deterministic Polylogarithmic Competitive Algorithm for Matching with Delays](https://arxiv.org/abs/2510.20588)
*Marc Dufay,Roger Wattenhofer*

Main category: cs.DS

TL;DR: 本文提出了一个O(log⁵ m)竞争比的在线最小成本完美匹配延迟问题算法，相比之前O(m^0.59)的竞争比有指数级改进，且仅与下界相差多对数因子。


<details>
  <summary>Details</summary>
Motivation: 当度量空间无限或未知时，现有最优算法Azar和Jacob-Fanani的竞争比为O(m^0.59)，与下界Ω(log m/log log m)存在指数级差距，需要改进算法性能。

Method: 提出了一个确定性算法，不需要预先知道度量空间或m的值，通过优化匹配策略来同时最小化匹配成本和请求等待时间。

Result: 算法达到了O(log⁵ m)的竞争比，相比之前结果有指数级改进，且仅比已知下界多一个多对数因子。

Conclusion: 该算法在未知度量空间下显著提升了在线最小成本完美匹配延迟问题的性能，几乎达到了理论最优。

Abstract: In the online Min-cost Perfect Matching with Delays (MPMD) problem, $m$
requests in a metric space are submitted at different times by an adversary.
The goal is to match all requests while (i) minimizing the sum of the distances
between matched pairs as well as (ii) how long each request remained unmatched
after it appeared.
  While there exist almost optimal algorithms when the metric space is finite
and known a priori, this is not the case when the metric space is infinite or
unknown. In this latter case, the best known algorithm, due to Azar and
Jacob-Fanani, has competitiveness $\mathcal{O}(m^{0.59})$ which is
exponentially worse than the best known lower bound of $\Omega(\log m / \log
\log m)$ by Ashlagi et al.
  We present a $\mathcal{O}(\log^5 m)$-competitive algorithm for the MPMD
problem. This algorithm is deterministic and does not need to know the metric
space or $m$ in advance. This is an exponential improvement over previous
results and only a polylogarithmic factor away from the lower bound.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [32] [Automating Iconclass: LLMs and RAG for Large-Scale Classification of Religious Woodcuts](https://arxiv.org/abs/2510.19986)
*Drew B. Thomas*

Main category: cs.IR

TL;DR: 提出了一种结合大语言模型和向量数据库的早期现代宗教图像分类方法，使用完整页面上下文生成详细描述，通过混合向量搜索匹配Iconclass代码，在分类精度上显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统图像和基于关键词的搜索方法在早期现代宗教图像分类中效果有限，需要更准确的大规模分析方法来推进艺术史和数字人文学科研究。

Method: 利用大语言模型生成包含视觉和文本元素的完整页面描述，通过检索增强生成(RAG)和混合向量搜索匹配相关Iconclass分类代码。

Result: 在五个和四个分类级别上分别达到87%和92%的精确度，显著优于传统图像和关键词搜索方法。

Conclusion: 该方法展示了LLMs和RAG在艺术史和数字人文学科研究中的巨大潜力，为大规模早期现代视觉档案分析提供了强大工具。

Abstract: This paper presents a novel methodology for classifying early modern
religious images by using Large Language Models (LLMs) and vector databases in
combination with Retrieval-Augmented Generation (RAG). The approach leverages
the full-page context of book illustrations from the Holy Roman Empire,
allowing the LLM to generate detailed descriptions that incorporate both visual
and textual elements. These descriptions are then matched to relevant Iconclass
codes through a hybrid vector search. This method achieves 87% and 92%
precision at five and four levels of classification, significantly
outperforming traditional image and keyword-based searches. By employing
full-page descriptions and RAG, the system enhances classification accuracy,
offering a powerful tool for large-scale analysis of early modern visual
archives. This interdisciplinary approach demonstrates the growing potential of
LLMs and RAG in advancing research within art history and digital humanities.

</details>


### [33] [Rank-GRPO: Training LLM-based Conversational Recommender Systems with Reinforcement Learning](https://arxiv.org/abs/2510.20150)
*Yaochen Zhu,Harald Steck,Dawen Liang,Yinhan He,Jundong Li,Nathan Kallus*

Main category: cs.IR

TL;DR: 提出了ConvRec-R1框架，通过两阶段训练解决LLM在推荐系统中的挑战：第一阶段使用Remap-Reflect-Adjust管道构建行为克隆数据集，第二阶段提出Rank-GRPO方法优化推荐排名质量。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在推荐任务中的三个主要问题：生成目录外项目、违反输出格式要求、排名质量在列表末尾急剧下降。

Method: 两阶段框架：第一阶段使用Remap-Reflect-Adjust管道从黑盒LLM构建高质量演示数据；第二阶段提出Rank-GRPO方法，将排名作为优化单位，重新定义奖励函数并引入基于几何平均的排名级重要性比率。

Result: 在Reddit-v2数据集上的实验表明，ConvRec-R1比GRPO基线收敛更快，在Recall和NDCG指标上表现更好。

Conclusion: ConvRec-R1框架有效解决了LLM在推荐系统中的对齐问题，Rank-GRPO方法在排名任务中表现出优越性能。

Abstract: Large language models (LLMs) are reshaping the recommender system paradigm by
enabling users to express preferences and receive recommendations through
conversations. Yet, aligning LLMs to the recommendation task remains
challenging: pretrained LLMs often generate out-of-catalog items, violate
required output formats, and their ranking quality degrades sharply toward the
end of the generated list. To this end, we propose ConvRec-R1, a two-stage
framework for end-to-end training of LLM-based conversational recommender
systems. In Stage 1, we construct a behavioral-cloning dataset with a
Remap-Reflect-Adjust pipeline, which produces high-quality, catalog-grounded
demonstrations from powerful blackbox LLMs to warm-start the RL training. In
Stage 2, we propose Rank-GRPO, a principled extension of group relative policy
optimization (GRPO) tailored to tasks with rank-style outputs. Rank-GRPO treats
each rank in the recommendation list as the unit instead of token (too
fine-grained) or sequence (too coarse), redefining rewards to remove non-causal
credit assignment and introducing a rank-level importance ratio based on the
geometric mean of rank-wise token probabilities to stabilize policy updates.
Experiments on the public Reddit-v2 dataset show that ConvRec-R1 converges
faster and achieves higher Recall and NDCG than GRPO-style baselines. Code and
datasets are released at https://github.com/yaochenzhu/Rank-GRPO.

</details>


### [34] [Multimedia-Aware Question Answering: A Review of Retrieval and Cross-Modal Reasoning Architectures](https://arxiv.org/abs/2510.20193)
*Rahul Raja,Arpita Vats*

Main category: cs.IR

TL;DR: 本文综述了整合多媒体检索管道的问答系统最新进展，重点关注视觉、语言和音频模态与用户查询的对齐架构，分析了检索方法、融合技术和答案生成策略，并讨论了关键挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统问答系统依赖结构化文本数据，但多媒体内容的快速增长为检索增强型问答带来了新的挑战和机遇，需要整合图像、音频、视频和结构化元数据等多种模态。

Method: 基于检索方法、融合技术和答案生成策略对方法进行分类，分析基准数据集、评估协议和性能权衡，重点关注多模态对齐架构。

Result: 系统回顾了多媒体检索增强问答系统的最新进展，识别了不同方法的性能特点和适用场景。

Conclusion: 跨模态对齐、延迟-准确性权衡和语义基础是当前面临的关键挑战，需要进一步研究以构建更鲁棒和上下文感知的多媒体问答系统。

Abstract: Question Answering (QA) systems have traditionally relied on structured text
data, but the rapid growth of multimedia content (images, audio, video, and
structured metadata) has introduced new challenges and opportunities for
retrieval-augmented QA. In this survey, we review recent advancements in QA
systems that integrate multimedia retrieval pipelines, focusing on
architectures that align vision, language, and audio modalities with user
queries. We categorize approaches based on retrieval methods, fusion
techniques, and answer generation strategies, and analyze benchmark datasets,
evaluation protocols, and performance tradeoffs. Furthermore, we highlight key
challenges such as cross-modal alignment, latency-accuracy tradeoffs, and
semantic grounding, and outline open problems and future research directions
for building more robust and context-aware QA systems leveraging multimedia
data.

</details>


### [35] [Balancing Fine-tuning and RAG: A Hybrid Strategy for Dynamic LLM Recommendation Updates](https://arxiv.org/abs/2510.20260)
*Changping Meng,Hongyi Ling,Jianling Wang,Yifan Liu,Shuzhou Zhang,Dapeng Hong,Mingyan Gao,Onkar Dalal,Ed Chi,Lichan Hong,Haokai Lu,Ningren Han*

Main category: cs.IR

TL;DR: 该论文研究了LLM推荐系统的更新策略，比较了持续微调与RAG方法的优劣，提出了一种结合周期性微调和低成本RAG的混合更新策略，在十亿级用户平台上通过A/B测试验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 用户兴趣和内容的动态变化对LLM推荐系统构成挑战，初始微调无法捕捉实时变化，需要有效的更新机制来保持推荐质量。

Method: 使用LLM驱动的用户兴趣探索系统作为案例研究，比较持续微调和RAG方法，提出混合更新策略结合周期性微调的长效知识适应和RAG的敏捷性。

Result: 在十亿级用户平台上进行的实时A/B实验表明，混合方法在用户满意度方面取得了统计学显著提升。

Conclusion: 混合更新策略为维护高质量LLM推荐系统提供了一个实用且成本效益高的框架。

Abstract: Large Language Models (LLMs) empower recommendation systems through their
advanced reasoning and planning capabilities. However, the dynamic nature of
user interests and content poses a significant challenge: While initial
fine-tuning aligns LLMs with domain knowledge and user preferences, it fails to
capture such real-time changes, necessitating robust update mechanisms. This
paper investigates strategies for updating LLM-powered recommenders, focusing
on the trade-offs between ongoing fine-tuning and Retrieval-Augmented
Generation (RAG). Using an LLM-powered user interest exploration system as a
case study, we perform a comparative analysis of these methods across
dimensions like cost, agility, and knowledge incorporation. We propose a hybrid
update strategy that leverages the long-term knowledge adaptation of periodic
fine-tuning with the agility of low-cost RAG. We demonstrate through live A/B
experiments on a billion-user platform that this hybrid approach yields
statistically significant improvements in user satisfaction, offering a
practical and cost-effective framework for maintaining high-quality LLM-powered
recommender systems.

</details>


### [36] [From Generation to Attribution: Music AI Agent Architectures for the Post-Streaming Era](https://arxiv.org/abs/2510.20276)
*Wonil Kim,Hyeongseok Wi,Seungsoon Park,Taejun Kim,Sangeun Keum,Keunhyoung Kim,Taewan Kim,Jongmin Jung,Taehyoung Kim,Gaetan Guerrero,Mael Le Goff,Julie Po,Dongjoo Moon,Juhan Nam,Jongpil Lee*

Main category: cs.IR

TL;DR: 提出基于内容块的音乐AI代理架构，通过块级检索和代理编排将归属直接嵌入创作流程，旨在解决AI音乐生成中的归属、权利管理和经济模型问题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在重塑音乐创作，但其快速发展暴露了归属、权利管理和经济模型的结构性缺陷。现有流媒体系统无法处理AI驱动生产的规模和复杂性。

Method: 提出内容块音乐AI代理架构，将音乐组织为细粒度组件（块）存储在块数据库中，通过归属层实现透明来源追踪和实时结算，支持迭代式、基于会话的交互。

Result: 该框架将AI从生成工具转变为公平AI媒体平台的基础设施，实现细粒度归属、公平补偿和参与式互动。

Conclusion: 该架构指向后流媒体范式，音乐不再作为静态目录，而是作为协作和适应性生态系统运作。

Abstract: Generative AI is reshaping music creation, but its rapid growth exposes
structural gaps in attribution, rights management, and economic models. Unlike
past media shifts, from live performance to recordings, downloads, and
streaming, AI transforms the entire lifecycle of music, collapsing boundaries
between creation, distribution, and monetization. However, existing streaming
systems, with opaque and concentrated royalty flows, are ill-equipped to handle
the scale and complexity of AI-driven production. We propose a content-based
Music AI Agent architecture that embeds attribution directly into the creative
workflow through block-level retrieval and agentic orchestration. Designed for
iterative, session-based interaction, the system organizes music into granular
components (Blocks) stored in BlockDB; each use triggers an Attribution Layer
event for transparent provenance and real-time settlement. This framework
reframes AI from a generative tool into infrastructure for a Fair AI Media
Platform. By enabling fine-grained attribution, equitable compensation, and
participatory engagement, it points toward a post-streaming paradigm where
music functions not as a static catalog but as a collaborative and adaptive
ecosystem.

</details>


### [37] [Rotate Both Ways: Time-and-Order RoPE for Generative Recommendation](https://arxiv.org/abs/2510.20455)
*Xiaokai Wei,Jiajun Wu,Daiyao Yi,Reza Shirkavand,Michelle Gong*

Main category: cs.IR

TL;DR: 提出了TO-RoPE方法，通过旋转位置嵌入联合建模用户行为序列中的时间和顺序信息，在生成式推荐系统中优于现有时间编码方法。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐系统需要同时考虑交互事件在序列中的位置（索引）和实际发生时间，现有方法通过学习嵌入或相对注意力偏差注入时间信息，但RoPE方法如果设计得当可能是更强的替代方案。

Method: 提出Time-and-Order RoPE (TO-RoPE)，将索引和时间作为角度源来直接塑造查询-键几何结构，包括三种实现：早期融合、按维度分割和按头分割。

Result: 在公开数据集和工业数据集上的广泛实验表明，TO-RoPE变体在编码时间和索引方面始终比现有方法提高准确性。

Conclusion: 旋转嵌入为生成式推荐提供了一个简单、有原则且易于部署的基础。

Abstract: Generative recommenders, typically transformer-based autoregressive models,
predict the next item or action from a user's interaction history. Their
effectiveness depends on how the model represents where an interaction event
occurs in the sequence (discrete index) and when it occurred in wall-clock
time. Prevailing approaches inject time via learned embeddings or relative
attention biases. In this paper, we argue that RoPE-based approaches, if
designed properly, can be a stronger alternative for jointly modeling temporal
and sequential information in user behavior sequences. While vanilla RoPE in
LLMs considers only token order, generative recommendation requires
incorporating both event time and token index. To address this, we propose
Time-and-Order RoPE (TO-RoPE), a family of rotary position embedding designs
that treat index and time as angle sources shaping the query-key geometry
directly. We present three instantiations: early fusion, split-by-dim, and
split-by-head. Extensive experiments on both publicly available datasets and a
proprietary industrial dataset show that TO-RoPE variants consistently improve
accuracy over existing methods for encoding time and index. These results
position rotary embeddings as a simple, principled, and deployment-friendly
foundation for generative recommendation.

</details>


### [38] [Analyticup E-commerce Product Search Competition Technical Report from Team Tredence_AICOE](https://arxiv.org/abs/2510.20674)
*Rakshith R,Shubham Sharma,Mohammed Sameer Khan,Ankush Chopra*

Main category: cs.IR

TL;DR: Tredence_AICOE团队开发的多语言电商搜索系统，在查询-类别相关性和查询-商品相关性任务中，通过数据增强和多策略微调Gemma-3 12B和Qwen-2.5 14B模型，最终在排行榜上获得第四名。


<details>
  <summary>Details</summary>
Motivation: 解决多语言电商搜索中的查询-类别相关性和查询-商品相关性评估问题，确保对所有目标语言的完整覆盖。

Method: 通过翻译现有数据集进行数据增强，覆盖开发集中缺失的语言；使用多种策略微调Gemma-3 12B和Qwen-2.5 14B模型；Gemma-3 12B(4位)模型在原始和翻译数据上表现最佳。

Result: Gemma-3 12B(4位)模型在QC任务中使用原始和翻译数据获得最佳性能，在QI任务中使用原始、翻译和少数类数据创建获得最佳性能；最终在排行榜上排名第四，私有测试集平均F1得分为0.8857。

Conclusion: 数据增强和多策略模型微调方法有效提升了多语言电商搜索系统的性能，在两项相关性任务中均取得了良好结果。

Abstract: This study presents the multilingual e-commerce search system developed by
the Tredence_AICOE team. The competition features two multilingual relevance
tasks: Query-Category (QC) Relevance, which evaluates how well a user's search
query aligns with a product category, and Query-Item (QI) Relevance, which
measures the match between a multilingual search query and an individual
product listing. To ensure full language coverage, we performed data
augmentation by translating existing datasets into languages missing from the
development set, enabling training across all target languages. We fine-tuned
Gemma-3 12B and Qwen-2.5 14B model for both tasks using multiple strategies.
The Gemma-3 12B (4-bit) model achieved the best QC performance using original
and translated data, and the best QI performance using original, translated,
and minority class data creation. These approaches secured 4th place on the
final leaderboard, with an average F1-score of 0.8857 on the private test set.

</details>


### [39] [Generative Reasoning Recommendation via LLMs](https://arxiv.org/abs/2510.20815)
*Minjie Hong,Zetong Zhou,Zirun Guo,Ziang Zhang,Ruofan Hu,Weinan Gan,Jieming Zhu,Zhou Zhao*

Main category: cs.IR

TL;DR: GREAM框架通过协同语义对齐、推理课程激活和稀疏正则化组策略优化，将预训练LLM适配为生成式推理推荐模型，支持直接序列推荐和顺序推理推荐两种模式，在三个数据集上取得优于基线的性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在原生作为生成式推理推荐模型时面临的文本语义与协同过滤信号之间的建模差距，以及用户反馈的稀疏性和随机性问题。

Method: 提出GREAM框架，包含三个组件：协同语义对齐（融合异构文本证据构建语义一致的离散项目索引）、推理课程激活（构建带显式思维链监督的合成数据集和递进式课程）、稀疏正则化组策略优化（通过残差敏感可验证奖励和奖励校准组优势估计稳定后训练）。

Result: 在三个数据集上的实验表明，GREAM相比强基线模型取得了持续的性能提升。

Conclusion: GREAM为可验证强化学习驱动的LLM推荐器提供了一条实用路径，支持高吞吐低延迟的直接序列推荐和具有因果透明度的顺序推理推荐。

Abstract: Despite their remarkable reasoning capabilities across diverse domains, large
language models (LLMs) face fundamental challenges in natively functioning as
generative reasoning recommendation models (GRRMs), where the intrinsic
modeling gap between textual semantics and collaborative filtering signals,
combined with the sparsity and stochasticity of user feedback, presents
significant obstacles. This work explores how to build GRRMs by adapting
pre-trained LLMs, which achieves a unified understanding-reasoning-prediction
manner for recommendation tasks. We propose GREAM, an end-to-end framework that
integrates three components: (i) Collaborative-Semantic Alignment, which fuses
heterogeneous textual evidence to construct semantically consistent, discrete
item indices and auxiliary alignment tasks that ground linguistic
representations in interaction semantics; (ii) Reasoning Curriculum Activation,
which builds a synthetic dataset with explicit Chain-of-Thought supervision and
a curriculum that progresses through behavioral evidence extraction, latent
preference modeling, intent inference, recommendation formulation, and denoised
sequence rewriting; and (iii) Sparse-Regularized Group Policy Optimization
(SRPO), which stabilizes post-training via Residual-Sensitive Verifiable Reward
and Bonus-Calibrated Group Advantage Estimation, enabling end-to-end
optimization under verifiable signals despite sparse successes. GREAM natively
supports two complementary inference modes: Direct Sequence Recommendation for
high-throughput, low-latency deployment, and Sequential Reasoning
Recommendation that first emits an interpretable reasoning chain for causal
transparency. Experiments on three datasets demonstrate consistent gains over
strong baselines, providing a practical path toward verifiable-RL-driven LLM
recommenders.

</details>
