<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 5]
- [cs.DB](#cs.DB) [Total: 8]
- [cs.IR](#cs.IR) [Total: 8]
- [cs.MM](#cs.MM) [Total: 3]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Compression with Privacy-Preserving Random Access](https://arxiv.org/abs/2511.14524)
*Venkat Chandar,Aslan Tchamkerten,Shashank Vatedka*

Main category: cs.IT

TL;DR: 该论文证明i.i.d.二进制源序列可以在任意高于熵率的条件下无损压缩，使得解码任意单个比特X_i时不会泄露其他比特{X_j: j≠i}的任何信息。


<details>
  <summary>Details</summary>
Motivation: 研究在无损压缩中实现信息隔离，确保解码单个比特时不会泄露其他比特的信息，这对于隐私保护和安全通信具有重要意义。

Method: 通过设计特定的压缩方案，使得压缩后的码字在解码单个比特时只能获得该比特的信息，而无法获得其他比特的任何信息。

Result: 成功实现了在任意高于熵率的压缩条件下，保证单个比特解码时的信息隔离，即解码X_i不会泄露其他X_j的信息。

Conclusion: 证明了i.i.d.二进制源序列可以在无损压缩的同时实现严格的信息隔离，为隐私保护压缩提供了理论基础。

Abstract: It is shown that an i.i.d. binary source sequence $X_1, \ldots, X_n$ can be losslessly compressed at any rate above entropy such that the individual decoding of any $X_i$ reveals \emph{no} information about the other bits $\{X_j : j \neq i\}$.

</details>


### [2] [DNA Storage in the Short Molecule Regime](https://arxiv.org/abs/2511.14284)
*Ran Tamir,Nir Weinberger,Albert Guillén i Fàbregas*

Main category: cs.IT

TL;DR: 本文完成了DNA存储系统中短DNA分子可靠信息存储容量猜想的证明，提出了两种编码方案，其中随机编码方案实现了与已有下界匹配的容量上界。


<details>
  <summary>Details</summary>
Motivation: 研究DNA存储系统中短DNA分子能够可靠存储的信息量，验证Shomorony和Heckel(2022)提出的容量猜想。

Method: 提出两种编码方案：1）随机编码方案，通过量化概率单纯形中随机生成的概率质量函数获得码字；2）低复杂度编码方案，在除极短分子外的范围内达到最优缩放。

Result: 通过分析最优最大似然解码器，获得了与最近建立的下界在整个短分子范围内匹配的容量上界。

Conclusion: 完成了DNA存储系统短分子容量猜想的证明，提出了达到最优缩放的低复杂度编码方案。

Abstract: We study the amount of reliable information that can be stored in a DNA-based storage system composed of short DNA molecules. In this regime, Shomorony and Heckel (2022) put forward a conjecture on the scaling of the number of information bits that can be reliably stored. In this paper, we complete the proof of this conjecture. We analyze a random-coding scheme in which each codeword is obtained by quantizing a randomly generated probability mass function drawn from the probability simplex. By analyzing the optimal maximum-likelihood decoder, we derive an achievability bound that matches a recently established converse bound across the entire short-molecule regime. We also propose a second coding scheme, which operates with significantly lower computational complexity but achieves the optimal scaling, except for a specific range of very short molecules.

</details>


### [3] [The Capacity of Collusion-Resilient Decentralized Secure Aggregation with Groupwise Keys](https://arxiv.org/abs/2511.14444)
*Zhou Li,Xiang Zhang,Yizhou Zhao,Haiqiang Chen,Jihao Fan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 本文研究了在实用组密钥和抗共谋条件下的去中心化安全聚合问题，确定了最优的通信速率和密钥速率区域，并给出了可行性条件和最小资源需求。


<details>
  <summary>Details</summary>
Motivation: 受近期高效组密钥生成协议的启发，研究在对称组密钥设置下的去中心化安全聚合问题，为去中心化学习系统提供通信和密钥高效的安全聚合设计思路。

Method: 采用信息论方法分析去中心化安全聚合问题，考虑用户通过无差错广播信道连接，每个用户持有私密输入并配备组密钥来掩盖输入，同时满足恢复和安全约束。

Result: 当G=1或G≥K-T时，带组密钥的DSA不可行；当2≤G<K-T时，为安全计算一个期望和符号，每个用户必须广播至少一个符号，每个组密钥必须包含至少(K-T-2)/binom(K-T-1,G)个独立符号。

Conclusion: 研究结果建立了带组密钥的DSA的基本极限，为去中心化学习系统中的通信和密钥高效安全聚合提供了设计指导。

Abstract: This paper investigates the information-theoretic decentralized secure aggregation (DSA) problem under practical groupwise secret keys and collusion resilience. In DSA, $K$ users are interconnected through error-free broadcast channels. Each user holds a private input and aims to compute the sum of all other users' inputs, while satisfying the security constraint that no user, even when colluding with up to $T$ other users, can infer any information about the inputs beyond the recovered sum. To ensure security, users are equipped with secret keys to mask their inputs. Motivated by recent advances in efficient group-based key generation protocols, we consider the symmetric groupwise key setting, where every subset of $G$ users shares a group key that is independent of all other group keys. The problem is challenging because the recovery and security constraints must hold simultaneously for all users, and the structural constraints on the secret keys limit the flexibility of key correlations. We characterize the optimal rate region consisting of all achievable pairs of per-user broadcast communication rate and groupwise key rate. In particular, we show that DSA with groupwise keys is infeasible when $G=1$ or $G\ge K-T$. Otherwise, when $2\le G<K-T$, to securely compute one symbol of the desired sum, each user must broadcast at least one symbol, and each group key must contain at least $(K-T-2)/\binom{K-T-1}{G}$ independent symbols. Our results establish the fundamental limits of DSA with groupwise keys and provide design insights for communication- and key-efficient secure aggregation in decentralized learning systems.

</details>


### [4] [Monimial Matrix Analogue of Yoshida's theorem](https://arxiv.org/abs/2511.14480)
*Ananda Chakraborty*

Main category: cs.IT

TL;DR: 本文研究了有限域上线性码的权重枚举器变体，推广了平均完全联合权重枚举器的概念，建立了MacWilliams型恒等式和Yoshida定理的单项式类似物。


<details>
  <summary>Details</summary>
Motivation: 研究有限域上线性码的权重枚举器变体，特别是平均完全联合权重枚举器的推广，以深化对编码理论中权重分布的理解。

Method: 推广平均完全联合权重枚举器的概念，建立MacWilliams型恒等式，并发展Yoshida定理的单项式矩阵类似物。

Result: 给出了平均完全联合权重枚举器的广义表示，并建立了平均g重完全联合权重枚举器的单项式矩阵类似Yoshida定理。

Conclusion: 成功推广了平均完全联合权重枚举器的概念，建立了相关恒等式和定理，为编码理论中的权重分布分析提供了新工具。

Abstract: In this paper, we study variants of weight enumerators of linear codes over $\mathbb{F}_q$. We generalize the concept of average complete joint weight enumerators of two linear codes over $\mathbb{F}_q$. We also give its MacWilliams type identities. Then we establish a monomial analogue of Yoshida's theorem for this average complete joint weight enumerators. Finally, we present the generalized representation for average of $g$-fold complete joint weight enumerators for $\mathbb{F}_q$-linear codes and establish a monomial matrix analogue of Yoshida's theorem for average $g$-fold complete joint weight enumerators.

</details>


### [5] [Neural Networks-Enabled Channel Reconstruction for Fluid Antenna Systems: A Data-Driven Approach](https://arxiv.org/abs/2511.14520)
*Haoyu Liang,Zhentian Zhang,Jian Dang,Hao Jiang,Zaichen Zhang*

Main category: cs.IT

TL;DR: 提出了一种基于神经网络的数据驱动信道重建方法，用于流体天线系统，在提高重建精度的同时显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 流体天线系统通过利用紧凑阵列空间内的电磁端口相关性提供空间分集，但需要准确的信道状态信息。现有信道重建方法在模型无关场景下缺乏高精度和高效计算的通用解决方案。

Method: 采用神经网络驱动的数据驱动信道重建框架，结合模型无关的方法实现高效计算。

Result: 数值结果表明该方法具有快速收敛和鲁棒的重建能力，在重建精度和计算复杂度方面均优于现有最先进技术。

Conclusion: 所提出的神经网络驱动信道重建方法为流体天线系统提供了一种高精度、低复杂度的实用解决方案，显著提升了系统性能。

Abstract: Fluid antenna systems (FASs) offer substantial spatial diversity by exploiting the electromagnetic port correlation within compact array spaces, thereby generating favorable small-scale fading conditions with beneficial channel gain envelope fluctuations. This unique capability opens new opportunities for a wide range of communication applications and emerging technologies. However, accurate channel state information (CSI) must be acquired before a fluid antenna can be effectively utilized. Although several efforts have been made toward channel reconstruction in FASs, a generally applicable solution to both model-based or model-free scenario with both high precision and efficient computational flow remains lacking. In this work, we propose a data-driven channel reconstruction approach enabled by neural networks. The proposed framework not only achieves significantly enhanced reconstruction accuracy but also requires substantially lower computational complexity compared with existing model-free methods. Numerical results further demonstrate the rapid convergence and robust reconstruction capability of the proposed scheme, outperforming current state-of-the-art techniques.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [6] [SQL-to-Text Generation with Weighted-AST Few-Shot Prompting](https://arxiv.org/abs/2511.13907)
*Sriom Chakrabarti,Chuangtao Ma,Arijit Khan,Sebastian Link*

Main category: cs.DB

TL;DR: 提出Weighted-AST检索提示方法，通过结构感知提示确保SQL查询生成的文本描述既流畅又忠实于原始查询逻辑，在多个基准数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有SQL-to-Text生成方法在保持SQL查询精确语义方面的不足，特别是当存在多种正确表述时，确保生成的描述忠实于原始查询逻辑。

Method: 提出Weighted-AST检索提示架构，整合结构查询表示和LLM提示，使用基于抽象语法树（AST）的相似性度量检索语义相关示例作为少样本提示。

Result: 在Spider、SParC和CoSQL三个基准数据集上，执行准确率（EX）提升高达+17.24%，在精确匹配（EM）方面表现优异，人类评估显示语义保真度更一致，同时保持竞争力的运行时性能。

Conclusion: Weighted-AST提示是一种可扩展且有效的方法，能够从结构化数据库查询中推导出自然语言解释。

Abstract: SQL-to-Text generation aims at translating structured SQL queries into natural language descriptions, thereby facilitating comprehension of complex database operations for non-technical users. Although large language models (LLMs) have recently demonstrated promising results, current methods often fail to maintain the exact semantics of SQL queries, particularly when there are multiple possible correct phrasings. To address this problem, our work proposes Weighted-AST retrieval with prompting, an architecture that integrates structural query representations and LLM prompting. This method retrieves semantically relevant examples as few-shot prompts using a similarity metric based on an Abstract Syntax Tree (AST) with learned feature weights. Our structure-aware prompting technique ensures that generated descriptions are both fluent and faithful to the original query logic. Numerous experiments on three benchmark datasets - Spider, SParC, and CoSQL show that our method outperforms the current baselines by up to +17.24% in execution Accuracy (EX), performs superior in Exact Match (EM) and provides more consistent semantic fidelity when evaluated by humans, all while preserving competitive runtime performance. These results demonstrate that Weighted-AST prompting is a scalable and effective method for deriving natural language explanations from structured database queries.

</details>


### [7] [Fast Verification of Strong Database Isolation (Extended Version)](https://arxiv.org/abs/2511.14067)
*Zhiheng Cai,Si Liu,Hengfeng Wei,Yuxing Chen,Anqun Pan*

Main category: cs.DB

TL;DR: VeriStrong是一个用于验证强数据库隔离保证的快速验证器，使用超多边图形式化方法来捕获事务依赖关系，并通过优化的SMT求解实现高效验证。


<details>
  <summary>Details</summary>
Motivation: 验证数据库是否遵守其声称的隔离保证（如可序列化和快照隔离）至关重要，但在黑盒设置中具有挑战性，因为只能观察到系统行为且存在不确定的事务依赖关系。

Method: 提出超多边图形式化方法来紧凑地捕获数据库执行中的确定和不确定事务依赖关系，开发了可验证可序列化和快照隔离的完备编码，并针对数据库工作负载特性优化SMT求解。

Result: 在多样化基准测试中，VeriStrong不仅显著优于现有最先进的验证器，还能扩展到超出它们能力范围的大型通用工作负载，同时保持高精度的隔离异常检测。

Conclusion: VeriStrong通过创新的形式化方法和针对性的优化，为强数据库隔离保证提供了高效、可扩展且准确的验证解决方案。

Abstract: Strong isolation guarantees, such as serializability and snapshot isolation, are essential for maintaining data consistency and integrity in modern databases. Verifying whether a database upholds its claimed guarantees is increasingly critical, as these guarantees form a contract between the vendor and its users. However, this task is challenging, particularly in black-box settings, where only observable system behavior is available and often involves uncertain dependencies between transactions.
  In this paper, we present VeriStrong, a fast verifier for strong database isolation. At its core is a novel formalism called hyper-polygraphs, which compactly captures both certain and uncertain transactional dependencies in database executions. Leveraging this formalism, we develop sound and complete encodings for verifying both serializability and snapshot isolation. To achieve high efficiency, VeriStrong tailors SMT solving to the characteristics of database workloads, in contrast to prior general-purpose approaches. Our extensive evaluation across diverse benchmarks shows that VeriStrong not only significantly outperforms state-of-the-art verifiers on the workloads they support, but also scales to large, general workloads beyond their reach, while maintaining high accuracy in detecting isolation anomalies.

</details>


### [8] [Chipmink: Efficient Delta Identification for Massive Object Graph](https://arxiv.org/abs/2511.14162)
*Supawit Chockchowwat,Sumay Thakurdesai,Zhaoheng Li,Matthew Krafczyk,Yongjoo Park*

Main category: cs.DB

TL;DR: Chipmink是一个基于图的对象存储系统，通过动态分区对象到pod中实现高效的部分持久化，相比传统完整快照方法显著减少存储空间和提升持久化速度。


<details>
  <summary>Details</summary>
Motivation: 现有数据科学工具的对象持久化机制（如Pickle、Dill）依赖完整快照，会冗余存储未更改对象，导致时间和存储效率低下。数据科学系统缺乏像DBMS那样的集中式缓冲区管理器来跟踪脏对象。

Method: 提出图基对象存储Chipmink，作为集中式缓冲区管理器。通过动态将对象分区到适当的子组（称为pod）中，基于对象大小和引用结构最小化预期持久化成本。这些pod有效隔离脏对象，实现高效部分持久化。

Result: Chipmink支持依赖共享内存、GPU和远程对象的库，在真实笔记本和脚本中相比最佳基线实现存储空间减少36.5倍，持久化速度提升12.4倍。

Conclusion: Chipmink通过图基对象存储和动态pod分区，有效解决了数据科学系统中对象持久化的效率问题，支持多种计算环境并显著提升性能。

Abstract: Ranging from batch scripts to computational notebooks, modern data science tools rely on massive and evolving object graphs that represent structured data, models, plots, and more. Persisting these objects is critical, not only to enhance system robustness against unexpected failures but also to support continuous, non-linear data exploration via versioning. Existing object persistence mechanisms (e.g., Pickle, Dill) rely on complete snapshotting, often redundantly storing unchanged objects during execution and exploration, resulting in significant inefficiency in both time and storage. Unlike DBMSs, data science systems lack centralized buffer managers that track dirty objects. Worse, object states span various locations such as memory heaps, shared memory, GPUs, and remote machines, making dirty object identification fundamentally more challenging. In this work, we propose a graph-based object store, named Chipmink, that acts like the centralized buffer manager. Unlike static pages in DBMSs, persistence units in Chipmink are dynamically induced by partitioning objects into appropriate subgroups (called pods), minimizing expected persistence costs based on object sizes and reference structure. These pods effectively isolate dirty objects, enabling efficient partial persistence. Our experiments show that Chipmink is general, supporting libraries that rely on shared memory, GPUs, and remote objects. Moreover, Chipmink achieves up to 36.5x smaller storage sizes and 12.4x faster persistence than the best baselines in real-world notebooks and scripts.

</details>


### [9] [Gradient-Based Join Ordering](https://arxiv.org/abs/2511.14482)
*Tim Schwabe,Maribel Acosta*

Main category: cs.DB

TL;DR: 本文提出了一种基于梯度的连接顺序优化方法，通过将离散的连接顺序问题转化为连续可微的松弛空间，使用Gumbel-Softmax参数化和可微约束来实现梯度搜索。


<details>
  <summary>Details</summary>
Motivation: 传统连接顺序优化方法存在计算复杂度高和可扩展性有限的问题，需要一种更高效的解决方案。

Method: 将查询计划连续松弛为软邻接矩阵，使用Gumbel-Softmax参数化和可微约束，结合图神经网络成本模型进行梯度搜索。

Result: 在两个图数据集上，该方法能找到与传统离散局部搜索方法相当甚至更优成本的计划，且运行时间随查询大小线性增长。

Conclusion: 这是迈向基于梯度的连接顺序优化的第一步，有望在未来实现更有效和高效的查询优化器。

Abstract: Join ordering is the NP-hard problem of selecting the most efficient sequence in which to evaluate joins (conjunctive, binary operators) in a database query. As the performance of query execution critically depends on this choice, join ordering lies at the core of query optimization. Traditional approaches cast this problem as a discrete combinatorial search over binary trees guided by a cost model, but they often suffer from high computational complexity and limited scalability. We show that, when the cost model is differentiable, the query plans can be continuously relaxed into a soft adjacency matrix representing a superposition of plans. This continuous relaxation, together with a Gumbel-Softmax parameterization of the adjacency matrix and differentiable constraints enforcing plan validity, enables gradient-based search for plans within this relaxed space. Using a learned Graph Neural Network as the cost model, we demonstrate that this gradient-based approach can find comparable and even lower-cost plans compared to traditional discrete local search methods on two different graph datasets. Furthermore, we empirically show that the runtime of this approach scales linearly with query size, in contrast to quadratic or exponential runtimes of classical approaches. We believe this first step towards gradient-based join ordering can lead to more effective and efficient query optimizers in the future.

</details>


### [10] [Overview and Prospects of Using Integer Surrogate Keys for Data Warehouse Performance Optimization](https://arxiv.org/abs/2511.14502)
*Sviatoslav Stumpf,Vladislav Povyshev*

Main category: cs.DB

TL;DR: 使用整数型日期时间标签替代标准DATE和TIMESTAMP类型，可显著优化数据仓库和时间序列性能，减少存储30-60%，提升查询速度25-40%。


<details>
  <summary>Details</summary>
Motivation: 传统日期时间类型在数据仓库和时间序列应用中存在存储效率低和查询性能不足的问题，需要更高效的表示方法。

Method: 提出32位和64位整数格式替代标准日期时间类型，并开发相应的索引、聚合、压缩和批处理算法。

Result: 在金融、电信、物联网和科学研究等实际应用中验证，存储需求减少30-60%，查询执行速度提升25-40%，吞吐量最高提升8倍。

Conclusion: 整数型日期时间标签是优化数据仓库和时间序列性能的有效方法，具有实际应用价值和广泛适用性。

Abstract: The aim of this paper is to examine and demonstrate how integer-based datetime labels (integer surrogate keys for time) can optimize data-warehouse and time-series performance, proposing practical formats and algorithms and validating their efficiency on real-world workloads. It is shown that replacing standard DATE and TIMESTAMP types with 32- and 64-bit integer formats reduces storage requirements by 30-60 percent and speeds up query execution by 25-40 percent. The paper presents indexing, aggregation, compression, and batching algorithms demonstrating up to an eightfold increase in throughput. Practical examples from finance, telecommunications, IoT, and scientific research confirm the efficiency and versatility of the proposed approach.

</details>


### [11] [Scalable Enforcement of Fine Grained Access Control Policies in Relational Database Management Systems](https://arxiv.org/abs/2511.14629)
*Anadi Shakya,Primal Pappachan,David Maier,Roberto Yus,Sharad Mehrotra,Johann-Christoph Freytag*

Main category: cs.DB

TL;DR: Sieve是一个用于关系数据库管理系统的中间件，通过查询重写和缓存机制优化细粒度访问控制策略执行，能在包含200-1200条策略的工作负载下将策略评估性能提升2-10倍。


<details>
  <summary>Details</summary>
Motivation: 智能技术的普及和GDPR、CPRA等隐私法规的发展增加了对细粒度访问控制策略管理的需求，但现有方法无法扩展到数千条策略，导致查询性能下降和系统效率降低。

Method: Sieve结合查询重写和缓存机制：使用保护表达式重写查询来分组和过滤策略，并能有效利用数据库索引；集成具有有效替换策略和刷新机制的缓存机制以适应动态工作负载。

Result: 在两个数据库管理系统上的实验表明，Sieve能够扩展到大型数据集和策略库，保持低查询延迟和系统负载，在200-1200条策略的工作负载下将策略评估性能提升2-10倍。缓存扩展在动态工作负载下进一步将查询性能提升6-22%。

Conclusion: Sieve适用于智能环境中的实时访问控制，支持高效、可扩展的用户偏好和隐私策略管理。

Abstract: The proliferation of smart technologies and evolving privacy regulations such as the GDPR and CPRA has increased the need to manage fine-grained access control (FGAC) policies in database management systems (DBMSs). Existing approaches to enforcing FGAC policies do not scale to thousands of policies, leading to degraded query performance and reduced system effectiveness. We present Sieve, a middleware for relational DBMSs that combines query rewriting and caching to optimize FGAC policy enforcement. Sieve rewrites a query with guarded expressions that group and filter policies and can efficiently use indexes in the DBMS. It also integrates a caching mechanism with an effective replacement strategy and a refresh mechanism to adapt to dynamic workloads. Experiments on two DBMSs with real and synthetic datasets show that Sieve scales to large datasets and policy corpora, maintaining low query latency and system load and improving policy evaluation performance by between 2x and 10x on workloads with 200 to 1,200 policies. The caching extension further improves query performance by between 6 and 22 percent under dynamic workloads, especially with larger cache sizes. These results highlight Sieve's applicability for real-time access control in smart environments and its support for efficient, scalable management of user preferences and privacy policies.

</details>


### [12] [Natural Language Interfaces for Databases: What Do Users Think?](https://arxiv.org/abs/2511.14718)
*Panos Ipeirotis,Haotian Zheng*

Main category: cs.DB

TL;DR: NLIDBs通过自然语言查询数据库，但存在可用性问题。研究比较SQL-LLM和Snowflake，发现SQL-LLM显著提升查询效率、准确性和用户体验。


<details>
  <summary>Details</summary>
Motivation: 探索自然语言数据库接口的用户体验维度，包括用户挫败感、查询优化策略和错误恢复等未被充分研究的可用性挑战。

Method: 采用混合方法用户研究，比较SQL-LLM（先进NL2SQL系统）和Snowflake（传统SQL分析平台），20名参与者完成12个查询任务。

Result: SQL-LLM显著减少查询时间（418秒 vs 629秒，p=0.036），提高准确率（75% vs 50%，p=0.002），减少查询重构，更快错误恢复，降低用户挫败感。

Conclusion: 设计良好的用户友好NLIDB在商业分析中具有实际意义，强调可用性与技术准确性在现实部署中的关键作用。

Abstract: Natural Language Interfaces for Databases (NLIDBs) aim to make database querying accessible by allowing users to ask questions in everyday language rather than using formal SQL queries. Despite significant advancements in translation accuracy, critical usability challenges, such as user frustration, query refinement strategies, and error recovery, remain underexplored. To investigate these usability dimensions, we conducted a mixed-method user study comparing SQL-LLM, a state-of-the-art NL2SQL system, with Snowflake, a traditional SQL analytics platform. Our controlled evaluation involved 20 participants completing realistic database querying tasks across 12 queries each. Results show that SQL-LLM significantly reduced query completion times by 10 to 30 percent (mean: 418 s vs. 629 s, p = 0.036) and improved overall accuracy from 50 to 75 percent (p = 0.002). Additionally, participants using SQL-LLM exhibited fewer query reformulations, recovered from errors 30 to 40 seconds faster, and reported lower frustration levels compared to Snowflake users. Behavioral analysis revealed that SQL-LLM encouraged structured, schema-first querying strategies, enhancing user confidence and efficiency, particularly for complex queries. These findings underscore the practical significance of well-designed, user-friendly NLIDBs in business analytics settings, emphasizing the critical role of usability alongside technical accuracy in real-world deployments.

</details>


### [13] [Cloud-Native Vector Search: A Comprehensive Performance Analysis](https://arxiv.org/abs/2511.14748)
*Zhaoheng Li,Wei Ding,Silu Huang,Zikang Wang,Yuanjin Lin,Ke Wu,Yongjoo Park,Jianjun Chen*

Main category: cs.DB

TL;DR: 本文系统研究云原生向量搜索，发现尽管云服务商默认使用聚类索引，但图索引在高并发、高召回率、高维数据和大数据类型场景中表现更优，且云搜索需要不同的索引参数化策略。


<details>
  <summary>Details</summary>
Motivation: 随着数据和任务复杂度的增长，向量索引被部署到远程存储（云原生向量搜索），但云服务商默认使用聚类索引，需要研究哪种索引类型更适合云环境。

Method: 分析聚类索引和图索引在远程存储上的瓶颈，比较不同工作负载下的性能表现，研究云搜索与本地搜索的索引参数差异，并整合云缓存机制。

Result: 图索引在高并发、高召回率、高维数据和大数据类型场景中优于聚类索引；云搜索需要不同的索引参数化；某些索引优化会与缓存机制冲突。

Conclusion: 云原生向量搜索需要根据具体工作负载选择索引类型，图索引在特定场景下更具优势，且需要调整索引参数以适应云环境，同时要考虑缓存兼容性。

Abstract: Vector search has been widely employed in recommender system and retrieval-augmented-generation pipelines, commonly performed with vector indexes to efficiently find similar items in large datasets. Recent growths in both data and task complexity have motivated placing vector indexes onto remote storage -- cloud-native vector search, which cloud providers have recently introduced services for. Yet, despite varying workload characteristics and various available vector index forms, providers default to using cluster-based indexes, which on paper do adapt well to differences between disk and cloud-based environment: their fetch granularities and lack of notable intra-query dependencies aligns with the large optimal fetch sizes and minimizes costly round-trips (i.e., as opposed to graph-based indexes) to remote storage, respectively.
  This paper systematically studies cloud-native vector search: What and how should indexes be built and used for on-cloud vector search? We analyze bottlenecks of two common index classes, cluster and graph indexes, on remote storage, and show that despite current standardized adoption of cluster indexes on the cloud, graph indexes are favored in workloads requiring high concurrency and recall, or operating on high-dimensional data or large datatypes. We further find that on-cloud search demands significantly different indexing and search parameterizations versus on-disk search for optimal performance. Finally, we incorporate existing cloud-based caching setups into vector search and find that certain index optimizations work against caching, and study how this can be mitigated to maximize gains under various available cache sizes.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [14] [TaoSearchEmb: A Multi-Objective Reinforcement Learning Framework for Dense Retrieval in Taobao Search](https://arxiv.org/abs/2511.13885)
*Xingxian Liu,Dongshuai Li,Tao Wen,Jiahui Wan,Gui Ling,Fuyu Lv,Dan Ou,Haihong Tang*

Main category: cs.IR

TL;DR: 提出了Retrieval-GRPO，一种基于多目标强化学习的稠密检索框架，通过动态检索Top-K候选产品和引入相关性LLM作为奖励模型，消除了离线硬负样本构建，解决了多任务学习中的跷跷板效应。


<details>
  <summary>Details</summary>
Motivation: 现有稠密检索方法依赖复杂的离线硬负样本构建流程，限制了模型迭代效率；同时多任务学习框架在同时优化语义相关性和非相关性目标时面临跷跷板效应。

Method: 使用强化学习动态优化嵌入表示，结合LLM生成的相关性分数、产品质量分数和多路排他性指标作为奖励信号，实现多目标用户偏好对齐和实时纠错。

Result: 离线在线实验验证了Retrieval-GRPO的有效性，已在中国最大电商平台部署，显著提升了复杂长尾查询的语义泛化能力。

Conclusion: Retrieval-GRPO不仅消除了对硬负样本的依赖，还通过协同多目标优化缓解了跷跷板效应，显著增强了语义表示能力的进化潜力。

Abstract: Dense retrieval, as the core component of e-commerce search engines, maps user queries and items into a unified semantic space through pre-trained embedding models to enable large-scale real-time semantic retrieval. Despite the rapid advancement of LLMs gradually replacing traditional BERT architectures for embedding, their training paradigms still adhere to BERT-like supervised fine-tuning and hard negative mining strategies. This approach relies on complex offline hard negative sample construction pipelines, which constrain model iteration efficiency and hinder the evolutionary potential of semantic representation capabilities. Besides, existing multi-task learning frameworks face the seesaw effect when simultaneously optimizing semantic relevance and non-relevance objectives. In this paper, we propose Retrieval-GRPO, a multi-objective reinforcement learning-based dense retrieval framework designed to address these challenges. The method eliminates offline hard negative sample construction by dynamically retrieving Top-K candidate products for each query during training, while introducing a relevance LLM as a reward model to generate real-time feedback. Specifically, the retrieval model dynamically optimizes embedding representations through reinforcement learning, with reward signals combining LLM-generated relevance scores, product quality scores, and multi-way exclusivity metrics to achieve multi-objective user preference alignment and real-time error correction. This mechanism not only removes dependency on hard negatives but also mitigates the seesaw effect through collaborative multi-objective optimization, significantly enhancing the model's semantic generalization capability for complex long-tail queries. Extensive offline and online experiments validate the effectiveness of Retrieval-GRPO, which has been deployed on China's largest e-commerce platform.

</details>


### [15] [NeuroPath: Neurobiology-Inspired Path Tracking and Reflection for Semantically Coherent Retrieval](https://arxiv.org/abs/2511.14096)
*Junchen Li,Rongzheng Wang,Yihong Huang,Qizhi Chen,Jiasheng Zhang,Shuang Liang*

Main category: cs.IR

TL;DR: NeuroPath是一个基于神经生物学启发的语义路径追踪RAG框架，通过动态路径追踪和后检索补全来解决多跳问答中的语义连贯性和噪声问题，在多个数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的RAG方法在多跳问答中难以捕捉文档间的复杂依赖关系，而现有的图基RAG方法在节点匹配和子图构建过程中会损失语义连贯性并引入无关噪声。

Method: NeuroPath包含两个步骤：动态路径追踪（在知识图上进行目标导向的语义路径追踪和剪枝）和后检索补全（使用中间推理和原始查询进行第二阶段检索，完善查询目标并补全推理路径中的缺失信息）。

Result: 在三个多跳QA数据集上，NeuroPath相比先进的图基RAG方法在recall@2和recall@5上分别平均提升16.3%和13.5%；相比迭代式RAG方法，准确率更高且token消耗减少22.8%。

Conclusion: NeuroPath在多跳问答任务中表现出色，具有良好的鲁棒性和可扩展性，能够有效提升语义连贯性并减少噪声干扰。

Abstract: Retrieval-augmented generation (RAG) greatly enhances large language models (LLMs) performance in knowledge-intensive tasks. However, naive RAG methods struggle with multi-hop question answering due to their limited capacity to capture complex dependencies across documents. Recent studies employ graph-based RAG to capture document connections. However, these approaches often result in a loss of semantic coherence and introduce irrelevant noise during node matching and subgraph construction. To address these limitations, we propose NeuroPath, an LLM-driven semantic path tracking RAG framework inspired by the path navigational planning of place cells in neurobiology. It consists of two steps: Dynamic Path Tracking and Post-retrieval Completion. Dynamic Path Tracking performs goal-directed semantic path tracking and pruning over the constructed knowledge graph (KG), improving noise reduction and semantic coherence. Post-retrieval Completion further reinforces these benefits by conducting second-stage retrieval using intermediate reasoning and the original query to refine the query goal and complete missing information in the reasoning path. NeuroPath surpasses current state-of-the-art baselines on three multi-hop QA datasets, achieving average improvements of 16.3% on recall@2 and 13.5% on recall@5 over advanced graph-based RAG methods. Moreover, compared to existing iter-based RAG methods, NeuroPath achieves higher accuracy and reduces token consumption by 22.8%. Finally, we demonstrate the robustness of NeuroPath across four smaller LLMs (Llama3.1, GLM4, Mistral0.3, and Gemma3), and further validate its scalability across tasks of varying complexity. Code is available at https://github.com/KennyCaty/NeuroPath.

</details>


### [16] [WebRec: Enhancing LLM-based Recommendations with Attention-guided RAG from Web](https://arxiv.org/abs/2511.14182)
*Zihuai Zhao,Yujuan Ding,Wenqi Fan,Qing Li*

Main category: cs.IR

TL;DR: 提出了WebRec框架，利用LLMs的推理能力将推荐任务转化为适合网络检索的用户偏好查询，并通过MP-Head处理网络检索中的噪声信息，提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于RAG的推荐系统未能充分利用网络这一丰富的最新信息来源，面临查询生成和噪声处理两大挑战。

Method: WebRec框架：1) 使用LLMs将推荐任务解释为用户偏好查询；2) 设计MP-Head通过消息传递增强LLM对分散相关信息的注意力。

Result: 大量实验证明所提出的基于网络的RAG方法在推荐场景中的有效性。

Conclusion: WebRec框架成功解决了网络检索在推荐系统中的关键挑战，为LLM-based推荐系统提供了新的有效范式。

Abstract: Recommender systems play a vital role in alleviating information overload and enriching users' online experience. In the era of large language models (LLMs), LLM-based recommender systems have emerged as a prevalent paradigm for advancing personalized recommendations. Recently, retrieval-augmented generation (RAG) has drawn growing interest to facilitate the recommendation capability of LLMs, incorporating useful information retrieved from external knowledge bases. However, as a rich source of up-to-date information, the web remains under-explored by existing RAG-based recommendations. In particular, unique challenges are posed from two perspectives: one is to generate effective queries for web retrieval, considering the inherent knowledge gap between web search and recommendations; another challenge lies in harnessing online websites that contain substantial noisy content. To tackle these limitations, we propose WebRec, a novel web-based RAG framework, which takes advantage of the reasoning capability of LLMs to interpret recommendation tasks into queries of user preferences that cater to web retrieval. Moreover, given noisy web-retrieved information, where relevant pieces of evidence are scattered far apart, an insightful MP-Head is designed to enhance LLM attentions between distant tokens of relevant information via message passing. Extensive experiments have been conducted to demonstrate the effectiveness of our proposed web-based RAG methods in recommendation scenarios.

</details>


### [17] [LLM-Aligned Geographic Item Tokenization for Local-Life Recommendation](https://arxiv.org/abs/2511.14221)
*Hao Jiang,Guoquan Wang,Donglin Zhou,Sheng Yu,Yang Zeng,Wencong Zeng,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: LGSID是一个用于本地生活推荐的LLM对齐地理项目标记化框架，通过强化学习对齐LLM和分层地理标记化，有效捕获细粒度空间特征和真实世界距离感知。


<details>
  <summary>Details</summary>
Motivation: 在本地生活服务等特定领域任务中，简单将位置信息注入提示无法捕获细粒度空间特征和项目间的真实距离感知。

Method: 提出LGSID框架，包含两个关键组件：基于RL的地理LLM对齐和分层地理项目标记化。RL对齐模块训练列表奖励模型捕获空间关系，使用G-DPO算法将空间知识和协作信号注入LLM；分层标记化策略从离散空间和内容属性派生主令牌，使用对齐LLM的地理表示向量精炼残差令牌。

Result: 在快手真实工业数据集上的大量实验表明，LGSID持续优于最先进的判别式和生成式推荐模型。消融研究、可视化和案例研究进一步验证了其有效性。

Conclusion: LGSID框架成功解决了本地生活推荐中空间特征捕获不足的问题，通过地理对齐和分层标记化显著提升了推荐性能。

Abstract: Recent advances in Large Language Models (LLMs) have enhanced text-based recommendation by enriching traditional ID-based methods with semantic generalization capabilities. Text-based methods typically encode item textual information via prompt design and generate discrete semantic IDs through item tokenization. However, in domain-specific tasks such as local-life services, simply injecting location information into prompts fails to capture fine-grained spatial characteristics and real-world distance awareness among items. To address this, we propose LGSID, an LLM-Aligned Geographic Item Tokenization Framework for Local-life Recommendation. This framework consists of two key components: (1) RL-based Geographic LLM Alignment, and (2) Hierarchical Geographic Item Tokenization. In the RL-based alignment module, we initially train a list-wise reward model to capture real-world spatial relationships among items. We then introduce a novel G-DPO algorithm that uses pre-trained reward model to inject generalized spatial knowledge and collaborative signals into LLMs while preserving their semantic understanding. Furthermore, we propose a hierarchical geographic item tokenization strategy, where primary tokens are derived from discrete spatial and content attributes, and residual tokens are refined using the aligned LLM's geographic representation vectors. Extensive experiments on real-world Kuaishou industry datasets show that LGSID consistently outperforms state-of-the-art discriminative and generative recommendation models. Ablation studies, visualizations, and case studies further validate its effectiveness.

</details>


### [18] [Infer As You Train: A Symmetric Paradigm of Masked Generative for Click-Through Rate Prediction](https://arxiv.org/abs/2511.14403)
*Moyu Zhang,Yujun Jin,Yun Chen,Jinxin Hu,Yu Zhang,Xiaoyi Zeng*

Main category: cs.IR

TL;DR: 提出对称掩码生成范式SGCTR，在CTR预测中实现训练和推理阶段的对称性，通过生成能力在推理时重新定义输入特征以提升预测准确性


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在训练阶段使用生成范式，但在推理时仍回归判别范式，未能充分利用生成能力提升预测精度，存在训练与推理阶段的不对称问题

Method: SGCTR框架在训练阶段学习特征依赖关系获得生成能力，在推理阶段应用生成能力迭代重新定义输入样本特征，减轻噪声特征影响

Result: 大量实验验证SGCTR的优越性，证明在训练和推理阶段对称应用生成范式能显著释放其在CTR预测中的潜力

Conclusion: 通过建立训练与推理阶段的对称性，生成范式在CTR预测中能发挥更强大的作用，SGCTR为此提供了有效解决方案

Abstract: Generative models are increasingly being explored in click-through rate (CTR) prediction field to overcome the limitations of the conventional discriminative paradigm, which rely on a simple binary classification objective. However, existing generative models typically confine the generative paradigm to the training phase, primarily for representation learning. During online inference, they revert to a standard discriminative paradigm, failing to leverage their powerful generative capabilities to further improve prediction accuracy. This fundamental asymmetry between the training and inference phases prevents the generative paradigm from realizing its full potential. To address this limitation, we propose the Symmetric Masked Generative Paradigm for CTR prediction (SGCTR), a novel framework that establishes symmetry between the training and inference phases. Specifically, after acquiring generative capabilities by learning feature dependencies during training, SGCTR applies the generative capabilities during online inference to iteratively redefine the features of input samples, which mitigates the impact of noisy features and enhances prediction accuracy. Extensive experiments validate the superiority of SGCTR, demonstrating that applying the generative paradigm symmetrically across both training and inference significantly unlocks its power in CTR prediction.

</details>


### [19] [Jasper-Token-Compression-600M Technical Report](https://arxiv.org/abs/2511.14405)
*Dun Zhang,Ziyang Zeng,Yudong Zhou,Shuyang Lu*

Main category: cs.IR

TL;DR: Jasper-Token-Compression-600M是一个双语（英中）模型，通过知识蒸馏和token压缩技术，在保持8B模型性能的同时实现了0.6B模型的高效推理。


<details>
  <summary>Details</summary>
Motivation: 将蒸馏方法扩展到双语领域，结合对比学习提升模型性能，并通过token压缩技术提高推理效率。

Method: 使用基于一维卷积的token压缩模块，动态调整压缩率训练，结合知识蒸馏和对比学习。

Result: 模型在保持8B模型性能的同时，实现了比传统0.6B模型更高的效率。

Conclusion: 该方法成功实现了模型性能与效率的平衡，为双语模型的高效部署提供了可行方案。

Abstract: This technical report presents the training methodology and evaluation results of the open-source Jasper-Token-Compression-600M model, released in November 2025. Building on previous distillation-based recipes from the English Stella and Jasper models, we successfully extend this approach to a bilingual (English and Chinese) domain, further enhancing model performance through the incorporation of contrastive learning. A key innovation of our model is the introduction of a one-dimensional convolution-based token compression module. We dynamically adjust the compression rate during training, enabling the model to learn more robust and efficient compressed text representations. By combining knowledge distillation with token compression techniques, we achieve significant improvements in both embedding quality and inference efficiency. Our model performs with higher efficiency than a traditional 0.6B model while achieving performance comparable to that of an 8B model. For more information on the model release, visit: https://huggingface.co/infgrad/Jasper-Token-Compression-600M.

</details>


### [20] [Effective Diversification of Multi-Carousel Book Recommendation](https://arxiv.org/abs/2511.14461)
*Daniël Wilten,Gideon Maillette de Buy Wenniger,Arjen Hommersom,Paul Lucassen,Emiel Poortman*

Main category: cs.IR

TL;DR: 本文提出在协同过滤算法基础上增加项目多样性的方法，用于改善公共图书馆网络目录中的图书推荐系统，并在准确性和多样性之间找到平衡。


<details>
  <summary>Details</summary>
Motivation: 虽然轮播界面为电影流媒体平台提供了结构化和易于导航的内容展示方式，但仅靠轮播本身无法增加推荐多样性，而多样性对于保持用户参与度至关重要。

Method: 在协同过滤算法基础上提出了几种增加项目多样性的方法，并引入了评估这些策略的指标。

Result: 所提出的系统在准确性和超越准确性方面找到了合适的平衡。

Conclusion: 在图书推荐系统中，通过增加项目多样性的方法可以有效改善推荐质量，特别是在公共图书馆网络目录的应用场景中。

Abstract: Using multiple carousels, lists that wrap around and can be scrolled, is the basis for offering content in most contemporary movie streaming platforms. Carousels allow for highlighting different aspects of users' taste, that fall in categories such as genres and authors. However, while carousels offer structure and greater ease of navigation, they alone do not increase diversity in recommendations, while this is essential to keep users engaged. In this work we propose several approaches to effectively increase item diversity within the domain of book recommendations, on top of a collaborative filtering algorithm. These approaches are intended to improve book recommendations in the web catalogs of public libraries. Furthermore, we introduce metrics to evaluate the resulting strategies, and show that the proposed system finds a suitable balance between accuracy and beyond-accuracy aspects.

</details>


### [21] [NeuCLIRBench: A Modern Evaluation Collection for Monolingual, Cross-Language, and Multilingual Information Retrieval](https://arxiv.org/abs/2511.14758)
*Dawn Lawrie,James Mayfield,Eugene Yang,Andrew Yates,Sean MacAvaney,Ronak Pradeep,Scott Miller,Paul McNamee,Luca Soldani*

Main category: cs.IR

TL;DR: NeuCLIRBench是一个用于跨语言和多语言检索评估的测试集合，包含中文、波斯语、俄语的原始文档及其英文机器翻译版本，支持单语、跨语言和多语言检索场景。


<details>
  <summary>Details</summary>
Motivation: 为了准确衡量检索系统的进展，需要能够可靠区分系统性能的测试集合和相关性判断。

Method: 结合TREC NeuCLIR 2022-2024的主题，包含25万多个相关性判断，涵盖约150个单语和跨语言查询以及100个多语言查询，并提供神经检索系统的融合基线。

Result: 该集合提供了强大的统计区分能力来区分不同检索方法，并公开可用。

Conclusion: NeuCLIRBench为跨语言和多语言检索研究提供了全面的评估基准，特别是为重新排序算法开发者提供了更好的第一阶段检索基线。

Abstract: To measure advances in retrieval, test collections with relevance judgments that can faithfully distinguish systems are required. This paper presents NeuCLIRBench, an evaluation collection for cross-language and multilingual retrieval. The collection consists of documents written natively in Chinese, Persian, and Russian, as well as those same documents machine translated into English. The collection supports several retrieval scenarios including: monolingual retrieval in English, Chinese, Persian, or Russian; cross-language retrieval with English as the query language and one of the other three languages as the document language; and multilingual retrieval, again with English as the query language and relevant documents in all three languages. NeuCLIRBench combines the TREC NeuCLIR track topics of 2022, 2023, and 2024. The 250,128 judgments across approximately 150 queries for the monolingual and cross-language tasks and 100 queries for multilingual retrieval provide strong statistical discriminatory power to distinguish retrieval approaches. A fusion baseline of strong neural retrieval systems is included with the collection so that developers of reranking algorithms are no longer reliant on BM25 as their first-stage retriever. NeuCLIRBench is publicly available.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [22] [Can LLMs Create Legally Relevant Summaries and Analyses of Videos?](https://arxiv.org/abs/2511.13772)
*Lyra Hoeben-Kuil,Gijs van Dijck,Jaromir Savelka,Johanna Gunawan,Konrad Kollnig,Marta Kolacz,Mindy Duffourc,Shashank Chakravarthy,Hannes Westermann*

Main category: cs.MM

TL;DR: 研究探索大型语言模型从视频中理解法律事件并生成法律信函的能力，在120个YouTube法律问题视频测试中，71.7%的摘要被评为高质量或中等质量。


<details>
  <summary>Details</summary>
Motivation: 法律专业人士需要理解事件的法律相关事实并用文本表达，这对普通人来说具有挑战性。现有AI方法依赖用户用文字描述事件，但这对许多人来说仍很困难。

Method: 使用大型语言模型基于120个YouTube视频中的法律事件进行总结和法律信函起草，评估模型从视频内容理解法律问题的能力。

Result: 71.7%的视频摘要被评为高质量或中等质量，表明LLMs在理解视频法律事件方面具有潜力。

Conclusion: 这项研究为在司法可及性等领域应用AI技术打开了大门，展示了LLMs从视频中提取法律相关信息的可行性。

Abstract: Understanding the legally relevant factual basis of an event and conveying it through text is a key skill of legal professionals. This skill is important for preparing forms (e.g., insurance claims) or other legal documents (e.g., court claims), but often presents a challenge for laypeople. Current AI approaches aim to bridge this gap, but mostly rely on the user to articulate what has happened in text, which may be challenging for many. Here, we investigate the capability of large language models (LLMs) to understand and summarize events occurring in videos. We ask an LLM to summarize and draft legal letters, based on 120 YouTube videos showing legal issues in various domains. Overall, 71.7\% of the summaries were rated as of high or medium quality, which is a promising result, opening the door to a number of applications in e.g. access to justice.

</details>


### [23] [Real-Time Mobile Video Analytics for Pre-arrival Emergency Medical Services](https://arxiv.org/abs/2511.14119)
*Liuyi Jin,Amran Haroon,Radu Stoleru,Pasan Gunawardena,Michael Middleton,Jeeeun Kim*

Main category: cs.MM

TL;DR: TeleEMS是一个移动实时视频分析系统，通过融合音频和视频数据，在急救人员到达前提供多模态推理，改善紧急医疗服务。


<details>
  <summary>Details</summary>
Motivation: 当前EMS基础设施受限于一对一视频流和有限的分析能力，调度员和急救人员需要在高压环境下手动处理大量嘈杂冗余信息。

Method: 系统包含客户端和服务器端，服务器端集成EMS-Stream通信骨干网，支持多方视频流，并包含三个实时分析模块：音频症状分析、视频生命体征分析和联合文本-生命体征分析。

Result: EMSLlama在症状提取方面优于GPT-4o（精确匹配0.89 vs 0.57），文本-生命体征融合提高了推理鲁棒性，能够提供可靠的到达前干预建议。

Conclusion: TeleEMS展示了移动实时视频分析在转变EMS运营方面的潜力，弥合了旁观者、调度员和急救人员之间的差距，为下一代智能EMS基础设施铺平了道路。

Abstract: Timely and accurate pre-arrival video streaming and analytics are critical for emergency medical services (EMS) to deliver life-saving interventions. Yet, current-generation EMS infrastructure remains constrained by one-to-one video streaming and limited analytics capabilities, leaving dispatchers and EMTs to manually interpret overwhelming, often noisy or redundant information in high-stress environments. We present TeleEMS, a mobile live video analytics system that enables pre-arrival multimodal inference by fusing audio and video into a unified decision-making pipeline before EMTs arrive on scene.
  TeleEMS comprises two key components: TeleEMS Client and TeleEMS Server. The TeleEMS Client runs across phones, smart glasses, and desktops to support bystanders, EMTs en route, and 911 dispatchers. The TeleEMS Server, deployed at the edge, integrates EMS-Stream, a communication backbone that enables smooth multi-party video streaming. On top of EMSStream, the server hosts three real-time analytics modules: (1) audio-to-symptom analytics via EMSLlama, a domain-specialized LLM for robust symptom extraction and normalization; (2) video-to-vital analytics using state-of-the-art rPPG methods for heart rate estimation; and (3) joint text-vital analytics via PreNet, a multimodal multitask model predicting EMS protocols, medication types, medication quantities, and procedures.
  Evaluation shows that EMSLlama outperforms GPT-4o (exact-match 0.89 vs. 0.57) and that text-vital fusion improves inference robustness, enabling reliable pre-arrival intervention recommendations. TeleEMS demonstrates the potential of mobile live video analytics to transform EMS operations, bridging the gap between bystanders, dispatchers, and EMTs, and paving the way for next-generation intelligent EMS infrastructure.

</details>


### [24] [MindCross: Fast New Subject Adaptation with Limited Data for Cross-subject Video Reconstruction from Brain Signals](https://arxiv.org/abs/2511.14196)
*Xuan-Hao Liu,Yan-Kai Liu,Tianyi Zhou,Bao-Liang Lu,Wei-Long Zheng*

Main category: cs.MM

TL;DR: MindCross是一个新颖的跨被试脑解码框架，通过特定编码器和共享编码器分别提取被试特定和不变信息，并使用Top-K协作模块实现快速、数据高效的新被试适应。


<details>
  <summary>Details</summary>
Motivation: 现有脑解码框架主要依赖被试依赖范式，需要大量脑数据，但脑-视频数据收集成本高导致数据稀缺。跨被试方法往往过度关注被试不变信息而忽略被试特定信息，导致适应策略缓慢。

Method: 设计N个特定编码器和一个共享编码器分别提取被试特定和不变信息，采用Top-K协作模块利用先前被试编码器的知识增强新被试解码。

Result: 在fMRI/EEG到视频基准测试上的广泛实验证明了MindCross在跨被试解码和新被试适应方面的有效性和效率，仅使用一个模型。

Conclusion: MindCross实现了快速且数据高效的新被试适应，解决了脑解码中的数据稀缺问题，为跨被试脑解码提供了有效解决方案。

Abstract: Reconstructing video from brain signals is an important brain decoding task. Existing brain decoding frameworks are primarily built on a subject-dependent paradigm, which requires large amounts of brain data for each subject. However, the expensive cost of collecting brain-video data causes severe data scarcity. Although some cross-subject methods being introduced, they often overfocus with subject-invariant information while neglecting subject-specific information, resulting in slow fine-tune-based adaptation strategy. To achieve fast and data-efficient new subject adaptation, we propose MindCross, a novel cross-subject framework. MindCross's N specific encoders and one shared encoder are designed to extract subject-specific and subject-invariant information, respectively. Additionally, a Top-K collaboration module is adopted to enhance new subject decoding with the knowledge learned from previous subjects' encoders. Extensive experiments on fMRI/EEG-to-video benchmarks demonstrate MindCross's efficacy and efficiency of cross-subject decoding and new subject adaptation using only one model.

</details>
