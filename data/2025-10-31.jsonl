{"id": "2510.25917", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.25917", "abs": "https://arxiv.org/abs/2510.25917", "authors": ["Mehdi Karbalayghareh", "David J. Love", "Christopher G. Brinton"], "title": "Coherence-Aware Distributed Learning under Heterogeneous Downlink Impairments", "comment": "10 pages, 5 figures", "summary": "The performance of federated learning (FL) over wireless networks critically\ndepends on accurate and timely channel state information (CSI) across\ndistributed devices. This requirement is tightly linked to how rapidly the\nchannel gains vary, i.e., the coherence intervals. In practice, edge devices\noften exhibit unequal coherence times due to differences in mobility and\nscattering environments, leading to unequal demands for pilot signaling and\nchannel estimation resources. Conventional FL schemes that overlook this\ncoherence disparity can suffer from severe communication inefficiencies and\ntraining overhead. This paper proposes a coherence-aware,\ncommunication-efficient framework for joint channel training and model updating\nin practical wireless FL systems operating under heterogeneous fading dynamics.\nFocusing on downlink impairments, we introduce a resource-reuse strategy based\non product superposition, enabling the parameter server to efficiently schedule\nboth static and dynamic devices by embedding global model updates for static\ndevices within pilot transmissions intended for mobile devices. We\ntheoretically analyze the convergence behavior of the proposed scheme and\nquantify its gains in expected communication efficiency and training accuracy.\nExperiments demonstrate the effectiveness of the proposed framework under\nmobility-induced dynamics and offer useful insights for the practical\ndeployment of FL over wireless channels."}
{"id": "2510.26147", "categories": ["cs.IT", "eess.SP", "math.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.26147", "abs": "https://arxiv.org/abs/2510.26147", "authors": ["Xilai Fan", "Ya-Feng Liu"], "title": "Duality-Based Fixed Point Iteration Algorithm for Beamforming Design in ISAC Systems", "comment": "6 pages, 1 figure, submitted to IEEE WCNC 2026", "summary": "In this paper, we investigate the beamforming design problem in an integrated\nsensing and communication (ISAC) system, where a multi-antenna base station\nsimultaneously serves multiple communication users while performing radar\nsensing. We formulate the problem as the minimization of the total transmit\npower, subject to signal-to-interference-plus-noise ratio (SINR) constraints\nfor communication users and mean-squared-error (MSE) constraints for radar\nsensing. The core challenge arises from the complex coupling between\ncommunication SINR requirements and sensing performance metrics. To efficiently\naddress this challenge, we first establish the equivalence between the original\nISAC beamforming problem and its semidefinite relaxation (SDR), derive its\nLagrangian dual formulation, and further reformulate it as a generalized\ndownlink beamforming (GDB) problem with potentially indefinite weighting\nmatrices. Compared to the classical DB problem, the presence of indefinite\nweighting matrices in the GDB problem introduces substantial analytical and\ncomputational challenges. Our key technical contributions include (i) a\nnecessary and sufficient condition for the boundedness of the GDB problem, and\n(ii) a tailored efficient fixed point iteration (FPI) algorithm with a provable\nconvergence guarantee for solving the GDB problem. Building upon these results,\nwe develop a duality-based fixed point iteration (Dual-FPI) algorithm, which\nintegrates an outer subgradient ascent loop with an inner FPI loop. Simulation\nresults demonstrate that the proposed Dual-FPI algorithm achieves globally\noptimal solutions while significantly reducing computational complexity\ncompared with existing baseline approaches."}
{"id": "2510.26279", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.26279", "abs": "https://arxiv.org/abs/2510.26279", "authors": ["Fuying Li", "Yajun Wang", "Zhuxian Lian", "Wen Chen"], "title": "Efficient Spectral Efficiency Maximization Design for IRS-aided MIMO Systems", "comment": null, "summary": "Driven by the growing demand for higher spectral efficiency in wireless\ncommunications, intelligent reflecting surfaces (IRS) have attracted\nconsiderable attention for their ability to dynamically reconfigure the\npropagation environment. This work addresses the spectral efficiency\nmaximization problem in IRS-assisted multiple-input multiple-output (MIMO)\nsystems, which involves the joint optimization of the transmit precoding matrix\nand the IRS phase shift configuration. This problem is inherently challenging\ndue to its non-convex nature. To tackle it effectively, we introduce a\ncomputationally efficient algorithm, termed ADMM-APG, which integrates the\nalternating direction method of multipliers (ADMM) with the accelerated\nprojected gradient (APG) method. The proposed framework decomposes the original\nproblem into tractable subproblems, each admitting a closed-form solution while\nmaintaining low computational complexity. Simulation results demonstrate that\nthe ADMM-APG algorithm consistently surpasses existing benchmark methods in\nterms of spectral efficiency and computational complexity, achieving\nsignificant performance gains across a range of system configurations."}
{"id": "2510.26442", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.26442", "abs": "https://arxiv.org/abs/2510.26442", "authors": ["Xuesong Wang", "Xinyan Xie", "Mo Li", "Zhaoqian Liu"], "title": "Diffusion-Aided Bandwidth-Efficient Semantic Communication with Adaptive Requests", "comment": "Submitted to IEEE ICC 2026", "summary": "Semantic communication focuses on conveying the intrinsic meaning of data\nrather than its raw symbolic representation. For visual content, this paradigm\nshifts from traditional pixel-level transmission toward leveraging the semantic\nstructure of images to communicate visual meaning. Existing approaches\ngenerally follow one of two paths: transmitting only text descriptions, which\noften fail to capture precise spatial layouts and fine-grained appearance\ndetails; or transmitting text alongside dense latent visual features, which\ntends to introduce substantial semantic redundancy. A key challenge, therefore,\nis to reduce semantic redundancy while preserving semantic understanding and\nvisual fidelity, thereby improving overall transmission efficiency. This paper\nintroduces a diffusion-based semantic communication framework with adaptive\nretransmission. The system transmits concise text descriptions together with a\nlimited set of key latent visual features, and employs a diffusion-based\ninpainting model to reconstruct the image. A receiver-side semantic consistency\nmechanism is designed to evaluate the alignment between the reconstructed image\nand the original text description. When a semantic discrepancy is detected, the\nreceiver triggers a retransmission to request a small set of additional latent\nblocks and refine the image reconstruction. This approach significantly reduces\nbandwidth usage while preserving high semantic accuracy, achieving an efficient\nbalance between reconstruction quality and transmission overhead."}
{"id": "2510.26033", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.26033", "abs": "https://arxiv.org/abs/2510.26033", "authors": ["David Smith", "Jie Dong", "Yizhou Yang"], "title": "Engineering Social Optimality via Utility Shaping in Non-Cooperative Games under Incomplete Information and Imperfect Monitoring", "comment": null, "summary": "In this paper, we study decentralized decision-making where agents optimize\nprivate objectives under incomplete information and imperfect public\nmonitoring, in a non-cooperative setting. By shaping utilities-embedding shadow\nprices or Karush-Kuhn-Tucker(KKT)-aligned penalties-we make the stage game an\nexact-potential game whose unique equilibrium equals the (possibly constrained)\nsocial optimum. We characterize the Bayesian equilibrium as a stochastic\nvariational inequality; strong monotonicity follows from a single-inflection\ncompressed/stretched-exponential response combined with convex pricing. We give\ntracking bounds for damped-gradient and best-response-with-hysteresis updates\nunder a noisy public index, and corresponding steady-state error. The framework\naccommodates discrete and continuous action sets and composes with slower\ndiscrete assignment. Deployable rules include: embed prices/penalties; publish\na single public index; tune steps, damping, and dual rates for contraction.\nComputational experiments cover (i) a multi-tier supply chain and (ii) a\nnon-cooperative agentic-AI compute market of bidding bots. Relative to\nprice-only baselines, utility shaping attains near-centralized welfare,\neliminates steady-state constraint/capacity violations when feasible, and\naccelerates convergence; with quantization, discrete equilibria track\ncontinuous ones within the mesh. The blueprint is portable to demand response,\ncloud/edge scheduling, and transportation pricing and biosecurity/agriculture.\nOverall, utility shaping plus a public index implements the constrained social\noptimum with stable equilibria under noise and drift-an\noperations-research-friendly alternative to heavy messaging or full mechanism\ndesign."}
{"id": "2510.26495", "categories": ["cs.DB", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26495", "abs": "https://arxiv.org/abs/2510.26495", "authors": ["Linzhuang Sun", "Tianyu Guo", "Hao Liang", "Yuying Li", "Qifeng Cai", "Jingxuan Wei", "Bihui Yu", "Wentao Zhang", "Bin Cui"], "title": "Rethinking Text-to-SQL: Dynamic Multi-turn SQL Interaction for Real-world Database Exploration", "comment": null, "summary": "Recent advances in Text-to-SQL have achieved strong results in static,\nsingle-turn tasks, where models generate SQL queries from natural language\nquestions. However, these systems fall short in real-world interactive\nscenarios, where user intents evolve and queries must be refined over multiple\nturns. In applications such as finance and business analytics, users\niteratively adjust query constraints or dimensions based on intermediate\nresults. To evaluate such dynamic capabilities, we introduce DySQL-Bench, a\nbenchmark assessing model performance under evolving user interactions. Unlike\nprevious manually curated datasets, DySQL-Bench is built through an automated\ntwo-stage pipeline of task synthesis and verification. Structured tree\nrepresentations derived from raw database tables guide LLM-based task\ngeneration, followed by interaction-oriented filtering and expert validation.\nHuman evaluation confirms 100% correctness of the synthesized data. We further\npropose a multi-turn evaluation framework simulating realistic interactions\namong an LLM-simulated user, the model under test, and an executable database.\nThe model must adapt its reasoning and SQL generation as user intents change.\nDySQL-Bench covers 13 domains across BIRD and Spider 2 databases, totaling\n1,072 tasks. Even GPT-4o attains only 58.34% overall accuracy and 23.81% on the\nPass@5 metric, underscoring the benchmark's difficulty. All code and data are\nreleased at https://github.com/Aurora-slz/Real-World-SQL-Bench ."}
{"id": "2510.26289", "categories": ["cs.MM"], "pdf": "https://arxiv.org/pdf/2510.26289", "abs": "https://arxiv.org/abs/2510.26289", "authors": ["Zijing Xu", "Yunfeng Kou", "Kunming Wu", "Hong Liu"], "title": "Contribution-Guided Asymmetric Learning for Robust Multimodal Fusion under Imbalance and Noise", "comment": null, "summary": "Multimodal learning faces two major challenges: modality imbalance and data\nnoise, which significantly affect the robustness and generalization ability of\nmodels. Existing methods achieve modality balance by suppressing dominant\nmodalities, but they neglect the inherent differences in the information value\nbetween modalities, potentially leading to convergence to suboptimal solutions.\nThis paper proposes an innovative modality compression paradigm,\nContribution-Guided Asymmetric Learning (CAL), which aims to enhance the\ncontribution of high-contribution modalities while compressing weak modalities\nto increase their contribution, allowing both to improve the performance of\nmultimodal information fusion. CAL is based on a modality contribution metric\nW^m combining the information quantity I(m) and confidence D(m), and it designs\nan asymmetric gradient acceleration mechanism and a contribution-aware\nAsymmetric Information Bottleneck (AIB) compression mechanism. The former\naccelerates the gradient update of modalities, while the latter dynamically\ncompresses the noise of low-contribution modalities.\n  On five benchmark datasets, including emotion recognition, scene recognition,\nand event localization tasks, CAL has shown outstanding performance in\nimbalanced fusion tasks and noise robustness tests. On CREMA-D, KS, and AVE,\nCAL achieves 79.30%, 74.82%, and 74.21% accuracy, significantly outperforming\nthe existing state-of-the-art model ARL. In high-noise robustness tests, CAL\nalso achieved leading performance under various attack strategies on the\nMVSA-Single and NYUD2 datasets. These results validate the significant\nadvantages of CAL in modality imbalance and noise interference. CAL, as a\nflexible and efficient framework, is easy to transfer to other tasks and has\nbroad adaptability and potential application prospects."}
{"id": "2510.25861", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2510.25861", "abs": "https://arxiv.org/abs/2510.25861", "authors": ["Christian Coester", "Tze-Yang Poon"], "title": "Online 3-Taxi on General Metrics", "comment": null, "summary": "The online $k$-taxi problem, introduced in 1990 by Fiat, Rabani and Ravid, is\na generalization of the $k$-server problem where $k$ taxis must serve a\nsequence of requests in a metric space. Each request is a pair of two points,\nrepresenting the pick-up and drop-off location of a passenger. In the\ninteresting ''hard'' version of the problem, the cost is the total distance\nthat the taxis travel without a passenger. The problem is known to be\nsubstantially harder than the $k$-server problem, and prior to this work even\nfor $k=3$ taxis it has been unknown whether a finite competitive ratio is\nachievable on general metric spaces. We present an $O(1)$-competitive algorithm\nfor the $3$-taxi problem."}
{"id": "2510.26095", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26095", "abs": "https://arxiv.org/abs/2510.26095", "authors": ["Jingyuan He", "Jiongnan Liu", "Vishan Vishesh Oberoi", "Bolin Wu", "Mahima Jagadeesh Patel", "Kangrui Mao", "Chuning Shi", "I-Ta Lee", "Arnold Overwijk", "Chenyan Xiong"], "title": "ORBIT -- Open Recommendation Benchmark for Reproducible Research with Hidden Tests", "comment": "Accepted to NeurIPS 2025 Datasets & Benchmarks track", "summary": "Recommender systems are among the most impactful AI applications, interacting\nwith billions of users every day, guiding them to relevant products, services,\nor information tailored to their preferences. However, the research and\ndevelopment of recommender systems are hindered by existing datasets that fail\nto capture realistic user behaviors and inconsistent evaluation settings that\nlead to ambiguous conclusions. This paper introduces the Open Recommendation\nBenchmark for Reproducible Research with HIdden Tests (ORBIT), a unified\nbenchmark for consistent and realistic evaluation of recommendation models.\nORBIT offers a standardized evaluation framework of public datasets with\nreproducible splits and transparent settings for its public leaderboard.\nAdditionally, ORBIT introduces a new webpage recommendation task, ClueWeb-Reco,\nfeaturing web browsing sequences from 87 million public, high-quality webpages.\nClueWeb-Reco is a synthetic dataset derived from real, user-consented, and\nprivacy-guaranteed browsing data. It aligns with modern recommendation\nscenarios and is reserved as the hidden test part of our leaderboard to\nchallenge recommendation models' generalization ability. ORBIT measures 12\nrepresentative recommendation models on its public benchmark and introduces a\nprompted LLM baseline on the ClueWeb-Reco hidden test. Our benchmark results\nreflect general improvements of recommender systems on the public datasets,\nwith variable individual performances. The results on the hidden test reveal\nthe limitations of existing approaches in large-scale webpage recommendation\nand highlight the potential for improvements with LLM integrations. ORBIT\nbenchmark, leaderboard, and codebase are available at\nhttps://www.open-reco-bench.ai."}
{"id": "2510.26452", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.26452", "abs": "https://arxiv.org/abs/2510.26452", "authors": ["Yi-Ting Hong", "Stefano Rini", "Luca Barletta"], "title": "PolarZero: A Reinforcement Learning Approach for Low-Complexity Polarization Kernel Design", "comment": null, "summary": "Polar codes with large kernels can achieve improved error exponents but are\nchallenging to design with low decoding complexity. This work investigates\nkernel construction under recursive maximum likelihood decoding (RMLD) using a\nreinforcement learning framework based on the Gumbel AlphaZero algorithm. The\nproposed method efficiently explores the design space and identifies large-size\nkernels that satisfy a given error exponent while minimizing decoding\ncomplexity. For a size-16 kernel, it achieves 17% lower decoding complexity\nthan handcrafted designs while reaching an error exponent of 0.5183 compared to\n0.5 for Arikan's kernel, demonstrating the effectiveness of the learning-based\napproach for practical polar code construction."}
{"id": "2510.26055", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.26055", "abs": "https://arxiv.org/abs/2510.26055", "authors": ["Alon Bebchuk"], "title": "NP-Hardness of Approximating Nash Social Welfare with Supermodular Valuations", "comment": null, "summary": "We study the problem of allocating a set of indivisible items to agents with\nsupermodular utilities to maximize the Nash social welfare. We show that the\nproblem is NP-hard for any approximation factor."}
{"id": "2510.26264", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2510.26264", "abs": "https://arxiv.org/abs/2510.26264", "authors": ["Tomasz Kociumaka", "Jakub Radoszewski"], "title": "Space-Efficient k-Mismatch Text Indexes", "comment": "SODA 2026", "summary": "A central task in string processing is text indexing, where the goal is to\npreprocess a text (a string of length $n$) into an efficient index (a data\nstructure) supporting queries about the text. Cole, Gottlieb, and Lewenstein\n(STOC 2004) proposed $k$-errata trees, a family of text indexes supporting\napproximate pattern matching queries of several types. In particular,\n$k$-errata trees yield an elegant solution to $k$-mismatch queries, where we\nare to report all substrings of the text with Hamming distance at most $k$ to\nthe query pattern. The resulting $k$-mismatch index uses $O(n\\log^k n)$ space\nand answers a query for a length-$m$ pattern in $O(\\log^k n \\log \\log n + m +\nocc)$ time, where $occ$ is the number of approximate occurrences.\n  In retrospect, $k$-errata trees appear very well optimized: even though a\nlarge body of work has adapted $k$-errata trees to various settings throughout\nthe past two decades, the original time-space trade-off for $k$-mismatch\nindexing has not been improved in the general case. We present the first such\nimprovement, a $k$-mismatch index with $O(n\\log^{k-1} n)$ space and the same\nquery time as $k$-errata trees.\n  Previously, due to a result of Chan, Lam, Sung, Tam, and Wong (Algorithmica\n2010), such an $O(n\\log^{k-1} n)$-size index has been known only for texts over\nalphabets of constant size. In this setting, however, we obtain an even smaller\n$k$-mismatch index of size only $O(n \\log^{k-2+\\varepsilon+\\frac{2}{k+2-(k\n\\bmod 2)}} n)\\subseteq O(n\\log^{k-1.5+\\varepsilon} n)$ for $2\\le k\\le O(1)$ and\nany constant $\\varepsilon>0$. Along the way, we also develop improved indexes\nfor short patterns, offering better trade-offs in this practically relevant\nspecial case."}
{"id": "2510.26104", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.26104", "abs": "https://arxiv.org/abs/2510.26104", "authors": ["Zhaoqi Zhang", "Haolei Pei", "Jun Guo", "Tianyu Wang", "Yufei Feng", "Hui Sun", "Shaowei Liu", "Aixin Sun"], "title": "OneTrans: Unified Feature Interaction and Sequence Modeling with One Transformer in Industrial Recommender", "comment": null, "summary": "In recommendation systems, scaling up feature-interaction modules (e.g.,\nWukong, RankMixer) or user-behavior sequence modules (e.g., LONGER) has\nachieved notable success. However, these efforts typically proceed on separate\ntracks, which not only hinders bidirectional information exchange but also\nprevents unified optimization and scaling. In this paper, we propose OneTrans,\na unified Transformer backbone that simultaneously performs user-behavior\nsequence modeling and feature interaction. OneTrans employs a unified tokenizer\nto convert both sequential and non-sequential attributes into a single token\nsequence. The stacked OneTrans blocks share parameters across similar\nsequential tokens while assigning token-specific parameters to non-sequential\ntokens. Through causal attention and cross-request KV caching, OneTrans enables\nprecomputation and caching of intermediate representations, significantly\nreducing computational costs during both training and inference. Experimental\nresults on industrial-scale datasets demonstrate that OneTrans scales\nefficiently with increasing parameters, consistently outperforms strong\nbaselines, and yields a 5.68% lift in per-user GMV in online A/B tests."}
{"id": "2510.26552", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.26552", "abs": "https://arxiv.org/abs/2510.26552", "authors": ["Shaocheng Liu", "Qi Chen", "Minquan Cheng"], "title": "Entropy Functions on Two-Dimensional Faces of Polymatroidal Region of Degree Four: Part II: Information Theoretic Constraints Breed New Combinatorial Structures", "comment": "submitted to IEEE Transactions on Information Theory", "summary": "Characterization of entropy functions is of fundamental importance in\ninformation theory. By imposing constraints on their Shannon outer bound, i.e.,\nthe polymatroidal region, one obtains the faces of the region and entropy\nfunctions on them with special structures. In this series of two papers, we\ncharacterize entropy functions on the $2$-dimensional faces of the\npolymatroidal region $\\Gamma_4$. In Part I, we formulated the problem,\nenumerated all $59$ types of $2$-dimensional faces of $\\Gamma_4$ by a\nalgorithm, and fully characterized entropy functions on $49$ types of them. In\nthis paper, i.e., Part II, we will characterize entropy functions on the\nremaining $10$ types of faces, among which $8$ types are fully characterized\nand $2$ types are partially characterized. To characterize these types of\nfaces, we introduce some new combinatorial design structures which are\ninteresting themself."}
{"id": "2510.26178", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.26178", "abs": "https://arxiv.org/abs/2510.26178", "authors": ["Yanran Tang", "Ruihong Qiu", "Xue Li", "Zi Huang"], "title": "ReaKase-8B: Legal Case Retrieval via Knowledge and Reasoning Representations with LLMs", "comment": null, "summary": "Legal case retrieval (LCR) is a cornerstone of real-world legal decision\nmaking, as it enables practitioners to identify precedents for a given query\ncase. Existing approaches mainly rely on traditional lexical models and\npretrained language models to encode the texts of legal cases. Yet there are\nrich information in the relations among different legal entities as well as the\ncrucial reasoning process that uncovers how legal facts and legal issues can\nlead to judicial decisions. Such relational reasoning process reflects the\ndistinctive characteristics of each case that can distinguish one from another,\nmirroring the real-world judicial process. Naturally, incorporating such\ninformation into the precise case embedding could further enhance the accuracy\nof case retrieval. In this paper, a novel ReaKase-8B framework is proposed to\nleverage extracted legal facts, legal issues, legal relation triplets and legal\nreasoning for effective legal case retrieval. ReaKase-8B designs an in-context\nlegal case representation learning paradigm with a fine-tuned large language\nmodel. Extensive experiments on two benchmark datasets from COLIEE 2022 and\nCOLIEE 2023 demonstrate that our knowledge and reasoning augmented embeddings\nsubstantially improve retrieval performance over baseline models, highlighting\nthe potential of integrating legal reasoning into legal case retrieval systems.\nThe code has been released on https://github.com/yanran-tang/ReaKase-8B."}
{"id": "2510.26231", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.26231", "abs": "https://arxiv.org/abs/2510.26231", "authors": ["Haochen Chen", "Qi Huang", "Anan Wu", "Wenhao Zhang", "Jianliang Ye", "Jianming Wu", "Kai Tan", "Xin Lu", "Xin Xu"], "title": "DiSE: A diffusion probabilistic model for automatic structure elucidation of organic compounds", "comment": null, "summary": "Automatic structure elucidation is essential for self-driving laboratories as\nit enables the system to achieve truly autonomous. This capability closes the\nexperimental feedback loop, ensuring that machine learning models receive\nreliable structure information for real-time decision-making and optimization.\nHerein, we present DiSE, an end-to-end diffusion-based generative model that\nintegrates multiple spectroscopic modalities, including MS, 13C and 1H chemical\nshifts, HSQC, and COSY, to achieve automated yet accurate structure elucidation\nof organic compounds. By learning inherent correlations among spectra through\ndata-driven approaches, DiSE achieves superior accuracy, strong generalization\nacross chemically diverse datasets, and robustness to experimental data despite\nbeing trained on calculated spectra. DiSE thus represents a significant advance\ntoward fully automated structure elucidation, with broad potential in natural\nproduct research, drug discovery, and self-driving laboratories."}
{"id": "2510.26407", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.26407", "abs": "https://arxiv.org/abs/2510.26407", "authors": ["Ivan Razvorotnev", "Marina Munkhoeva", "Evgeny Frolov"], "title": "Barlow Twins for Sequential Recommendation", "comment": null, "summary": "Sequential recommendation models must navigate sparse interaction data\npopularity bias and conflicting objectives like accuracy versus diversity While\nrecent contrastive selfsupervised learning SSL methods offer improved accuracy\nthey come with tradeoffs large batch requirements reliance on handcrafted\naugmentations and negative sampling that can reinforce popularity bias In this\npaper we introduce BT-SR a novel noncontrastive SSL framework that integrates\nthe Barlow Twins redundancyreduction principle into a Transformerbased nextitem\nrecommender BTSR learns embeddings that align users with similar shortterm\nbehaviors while preserving longterm distinctionswithout requiring negative\nsampling or artificial perturbations This structuresensitive alignment allows\nBT-SR to more effectively recognize emerging user intent and mitigate the\ninfluence of noisy historical context Our experiments on five public benchmarks\ndemonstrate that BTSR consistently improves nextitem prediction accuracy and\nsignificantly enhances longtail item coverage and recommendation calibration\nCrucially we show that a single hyperparameter can control the\naccuracydiversity tradeoff enabling practitioners to adapt recommendations to\nspecific application needs"}
{"id": "2510.26461", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26461", "abs": "https://arxiv.org/abs/2510.26461", "authors": ["Danial Ebrat", "Sepideh Ahmadian", "Luis Rueda"], "title": "Vectorized Context-Aware Embeddings for GAT-Based Collaborative Filtering", "comment": null, "summary": "Recommender systems often struggle with data sparsity and cold-start\nscenarios, limiting their ability to provide accurate suggestions for new or\ninfrequent users. This paper presents a Graph Attention Network (GAT) based\nCollaborative Filtering (CF) framework enhanced with Large Language Model (LLM)\ndriven context aware embeddings. Specifically, we generate concise textual user\nprofiles and unify item metadata (titles, genres, overviews) into rich textual\nembeddings, injecting these as initial node features in a bipartite user item\ngraph. To further optimize ranking performance, we introduce a hybrid loss\nfunction that combines Bayesian Personalized Ranking (BPR) with a cosine\nsimilarity term and robust negative sampling, ensuring explicit negative\nfeedback is distinguished from unobserved data. Experiments on the MovieLens\n100k and 1M datasets show consistent improvements over state-of-the-art\nbaselines in Precision, NDCG, and MAP while demonstrating robustness for users\nwith limited interaction history. Ablation studies confirm the critical role of\nLLM-augmented embeddings and the cosine similarity term in capturing nuanced\nsemantic relationships. Our approach effectively mitigates sparsity and\ncold-start limitations by integrating LLM-derived contextual understanding into\ngraph-based architectures. Future directions include balancing recommendation\naccuracy with coverage and diversity, and introducing fairness-aware\nconstraints and interpretability features to enhance system performance\nfurther."}
{"id": "2510.26546", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.26546", "abs": "https://arxiv.org/abs/2510.26546", "authors": ["Min Hou", "Xin Liu", "Le Wu", "Chenyi He", "Hao Liu", "Zhi Li", "Xin Li", "Si Wei"], "title": "WeaveRec: An LLM-Based Cross-Domain Sequential Recommendation Framework with Model Merging", "comment": null, "summary": "Cross-Domain Sequential Recommendation (CDSR) seeks to improve user\npreference modeling by transferring knowledge from multiple domains. Despite\nthe progress made in CDSR, most existing methods rely on overlapping users or\nitems to establish cross-domain correlations-a requirement that rarely holds in\nreal-world settings. The advent of large language models (LLM) and\nmodel-merging techniques appears to overcome this limitation by unifying\nmulti-domain data without explicit overlaps. Yet, our empirical study shows\nthat naively training an LLM on combined domains-or simply merging several\ndomain-specific LLMs-often degrades performance relative to a model trained\nsolely on the target domain. To address these challenges, we first\nexperimentally investigate the cause of suboptimal performance in LLM-based\ncross-domain recommendation and model merging. Building on these insights, we\nintroduce WeaveRec, which cross-trains multiple LoRA modules with source and\ntarget domain data in a weaving fashion, and fuses them via model merging.\nWeaveRec can be extended to multi-source domain scenarios and notably does not\nintroduce additional inference-time cost in terms of latency or memory.\nFurthermore, we provide a theoretical guarantee that WeaveRec can reduce the\nupper bound of the expected error in the target domain. Extensive experiments\non single-source, multi-source, and cross-platform cross-domain recommendation\nscenarios validate that WeaveRec effectively mitigates performance degradation\nand consistently outperforms baseline approaches in real-world recommendation\ntasks."}
{"id": "2510.26750", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.26750", "abs": "https://arxiv.org/abs/2510.26750", "authors": ["Martim Afonso", "Nuno Saavedra", "Bruno Lourenço", "Alexandra Mendes", "João Ferreira"], "title": "ProfOlaf: Semi-Automated Tool for Systematic Literature Reviews", "comment": "4 pages, 1 Figure, 2 tables", "summary": "Systematic reviews and mapping studies are critical for synthesizing\nresearch, identifying gaps, and guiding future work, but they are often\nlabor-intensive and time-consuming. Existing tools provide partial support for\nspecific steps, leaving much of the process manual and error-prone. We present\nProfOlaf, a semi-automated tool designed to streamline systematic reviews while\nmaintaining methodological rigor. ProfOlaf supports iterative snowballing for\narticle collection with human-in-the-loop filtering and uses large language\nmodels to assist in analyzing articles, extracting key topics, and answering\nqueries about the content of papers. By combining automation with guided manual\neffort, ProfOlaf enhances the efficiency, quality, and reproducibility of\nsystematic reviews across research fields. A video describing and demonstrating\nProfOlaf is available at: https://youtu.be/4noUXfcmxsE"}
