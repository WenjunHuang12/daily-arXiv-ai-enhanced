<div id=toc></div>

# Table of Contents

- [cs.MM](#cs.MM) [Total: 3]
- [cs.IR](#cs.IR) [Total: 15]
- [cs.IT](#cs.IT) [Total: 15]
- [cs.DS](#cs.DS) [Total: 7]
- [cs.GT](#cs.GT) [Total: 6]
- [cs.DB](#cs.DB) [Total: 2]


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [1] [AutoMV: An Automatic Multi-Agent System for Music Video Generation](https://arxiv.org/abs/2512.12196)
*Xiaoxuan Tang,Xinping Lei,Chaoran Zhu,Shiyun Chen,Ruibin Yuan,Yizhi Li,Changjae Oh,Ge Zhang,Wenhao Huang,Emmanouil Benetos,Yang Liu,Jiaheng Liu,Yinghao Ma*

Main category: cs.MM

TL;DR: AutoMV是一个多智能体系统，能够从完整歌曲直接生成音乐视频，解决了现有方法在视频长度、音乐结构对齐和时间一致性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有音乐到视频生成方法只能产生短小、不连贯的视频片段，无法与音乐结构、节拍或歌词对齐，缺乏时间一致性，无法生成完整的音乐视频。

Method: 首先使用音乐处理工具提取音乐属性（结构、人声轨道、时间对齐歌词），然后通过编剧和导演智能体设计脚本、角色档案和摄像机指令，调用图像和视频生成器生成关键帧和场景，最后通过验证智能体评估输出，实现多智能体协作。

Result: AutoMV在所有四个评估类别（音乐内容、技术、后期制作、艺术）上显著优于现有基线方法，缩小了与专业音乐视频的差距。同时提出了包含12个细粒度标准的评估基准。

Conclusion: AutoMV展示了多智能体系统在生成连贯长格式音乐视频方面的有效性，虽然大型多模态模型作为自动评估工具仍有改进空间，但该方法为音乐视频生成提供了有前景的解决方案。

Abstract: Music-to-Video (M2V) generation for full-length songs faces significant challenges. Existing methods produce short, disjointed clips, failing to align visuals with musical structure, beats, or lyrics, and lack temporal consistency. We propose AutoMV, a multi-agent system that generates full music videos (MVs) directly from a song. AutoMV first applies music processing tools to extract musical attributes, such as structure, vocal tracks, and time-aligned lyrics, and constructs these features as contextual inputs for following agents. The screenwriter Agent and director Agent then use this information to design short script, define character profiles in a shared external bank, and specify camera instructions. Subsequently, these agents call the image generator for keyframes and different video generators for "story" or "singer" scenes. A Verifier Agent evaluates their output, enabling multi-agent collaboration to produce a coherent longform MV. To evaluate M2V generation, we further propose a benchmark with four high-level categories (Music Content, Technical, Post-production, Art) and twelve ine-grained criteria. This benchmark was applied to compare commercial products, AutoMV, and human-directed MVs with expert human raters: AutoMV outperforms current baselines significantly across all four categories, narrowing the gap to professional MVs. Finally, we investigate using large multimodal models as automatic MV judges; while promising, they still lag behind human expert, highlighting room for future work.

</details>


### [2] [JointAVBench: A Benchmark for Joint Audio-Visual Reasoning Evaluation](https://arxiv.org/abs/2512.12772)
*Jianghan Chao,Jianzhang Gao,Wenhui Tan,Yuchong Sun,Ruihua Song,Liyun Ru*

Main category: cs.MM

TL;DR: JointAVBench是一个用于评估多模态大语言模型音频-视频联合理解能力的新基准，包含严格的相关性要求、五个认知维度、四种音频类型和三种场景跨度，通过自动化流水线生成数据，测试显示现有模型仍有很大提升空间。


<details>
  <summary>Details</summary>
Motivation: 现有评估数据集在以下方面存在不足：1）缺乏严格的多模态依赖性（问题不能仅通过视觉或音频单独回答）；2）音频信息类型不够多样；3）场景跨度变化有限。这些限制阻碍了对能够处理视觉和音频信息的Omni-LLMs进行全面严格的评估。

Method: 提出JointAVBench基准，具有严格的音频-视频相关性，涵盖五个认知维度、四种音频信息类型（语音、声音事件、音乐、声音特征）和三种场景跨度（单场景、跨场景、全场景）。采用自动化流水线，利用最先进的视觉-LLMs、音频-LLMs和通用LLMs合成严格需要音频-视觉联合理解的问题和答案。

Result: 评估了领先的纯视觉、纯音频和Omni-LLMs模型。结果显示，即使表现最好的Omni-LLM平均准确率也只有62.6%，虽然优于单模态基线模型，但在跨场景推理等方面仍有很大提升空间。

Conclusion: JointAVBench填补了现有评估基准的空白，为评估多模态大语言模型的音频-视频联合理解能力提供了全面严格的测试平台。结果表明当前模型在音频-视觉联合理解方面仍有显著不足，特别是在跨场景推理方面需要进一步改进。

Abstract: Understanding videos inherently requires reasoning over both visual and auditory information. To properly evaluate Omni-Large Language Models (Omni-LLMs), which are capable of processing multi-modal information including vision and audio, an effective benchmark must comprehensively cover three key aspects: (1) multi-modal dependency (i.e., questions that cannot be answered using vision or audio alone), (2) diverse audio information types (e.g., speech, sound events), and (3) varying scene spans. However, existing datasets fall short in one or more of these dimensions, limiting strict and comprehensive evaluation. To address this gap, we introduce JointAVBench, a novel benchmark with strict audio-video correlation, spanning five cognitive dimensions, four audio information types (speech, sound events, music, vocal traits), and three scene spans (single-, cross-, and full-scene). Given the high cost of manual annotation, we propose an automated pipeline that leverages state-of-the-art vision-LLMs, audio-LLMs, and general-purpose LLMs to synthesize questions and answers that strictly require joint audio-visual understanding. We evaluate leading vision-only, audio-only, and Omni-LLMs on our dataset. Results show that even the best-performing Omni-LLM achieves an average accuracy of only 62.6\%, outperforming uni-modal baselines but revealing substantial room for improvement, especially in cross-scene reasoning.

</details>


### [3] [Integrated Semantic and Temporal Alignment for Interactive Video Retrieval](https://arxiv.org/abs/2512.13169)
*Thanh-Danh Luu,Le-Vu Nguyen Dinh,Duc-Thien Tran,Duy-Bao Bui,Nam-Tien Le,Tinh-Anh Nguyen Nhu*

Main category: cs.MM

TL;DR: 论文提出QUEST和DANTE两个组件，构建了一个综合视频检索框架，解决复杂视频检索任务中的OOK查询和时序对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频检索系统存在局限性：缺乏可扩展的整体架构，依赖"冻结"的嵌入模型，无法处理知识外(OOK)查询和真实世界复杂检索任务，如TRAKE时序检索挑战。

Method: 提出综合视频检索框架：1) 使用TransNetV2进行场景分割，BEiT-3生成视觉嵌入存储在Milvus，Gemini OCR提取元数据存储在Elasticsearch；2) QUEST组件：双分支框架，利用LLM进行查询重写和外部图像搜索处理OOK查询；3) DANTE组件：动态规划算法解决时序不连贯的TRAKE任务。

Result: 构建了一个鲁棒智能的系统，显著提升了处理复杂真实世界视频搜索查询的能力，在TRAKE等复杂检索任务上取得了先进性能。

Conclusion: 提出的QUEST和DANTE组件构成了一个综合视频检索框架，能够有效解决知识外查询和时序对齐问题，显著推进了复杂视频检索任务的技术水平。

Abstract: The growing volume of video data and the introduction of complex retrieval challenges, such as the Temporal Retrieval and Alignment of Key Events (TRAKE) task at the Ho Chi Minh City AI Challenge 2025, expose critical limitations in existing systems. Many methodologies lack scalable, holistic architectures and rely on "frozen" embedding models that fail on out-of-knowledge (OOK) or real-world queries. This paper introduces the comprehensive video retrieval framework developed by team AIO\_Owlgorithms to address these gaps. Our system features an architecture integrating TransNetV2 for scene segmentation, BEiT-3 for visual embeddings in Milvus, and Gemini OCR for metadata in Elasticsearch. We propose two components: (1) \textbf{QUEST} (Query Understanding and External Search for Out-of-Knowledge Tasks), a two-branch framework that leverages a Large Language Model (LLM) for query rewriting and an external image search pathway to resolve OOK queries; and (2) \textbf{DANTE} (Dynamic Alignment of Narrative Temporal Events), a dynamic programming algorithm that efficiently solves the temporally-incoherent TRAKE task. These contributions form a robust and intelligent system that significantly advances the state-of-the-art in handling complex, real-world video search queries.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [4] [Breaking the Curse of Dimensionality: On the Stability of Modern Vector Retrieval](https://arxiv.org/abs/2512.12458)
*Vihan Lakshman,Blaise Munyampirwa,Julian Shun,Benjamin Coleman*

Main category: cs.IR

TL;DR: 论文通过稳定性理论重新审视向量检索中的维度灾难问题，证明了在三种实际检索场景中如何保持稳定性，为模型和系统设计提供指导。


<details>
  <summary>Details</summary>
Motivation: 现代向量数据库虽然能高效检索高维神经嵌入，但经典理论预测这类任务会遭受维度灾难，导致点间距离难以区分，从而破坏最近邻搜索效率。作者旨在重新审视这一悖论，通过稳定性理论解释为什么实际应用中向量检索仍然有效。

Method: 基于稳定性理论，扩展到三种实际检索场景：1）多向量搜索，分析Chamfer距离和平均池化聚合的稳定性；2）过滤向量搜索，研究不匹配过滤器的惩罚机制对稳定性的影响；3）稀疏向量搜索，形式化并证明新的充分稳定性条件。通过合成和真实数据集进行实验验证。

Result: 实验结果表明：1）Chamfer距离能保持单向量稳定性，而平均池化可能破坏稳定性；2）足够大的不匹配过滤器惩罚可以诱导稳定性，即使底层搜索不稳定；3）稀疏向量搜索的稳定性条件得到验证。实验结果与理论预测一致。

Conclusion: 通过稳定性理论框架，论文解释了为什么实际向量检索系统能避免维度灾难，并为模型和系统设计提供了具体指导，帮助在实际应用中保持检索稳定性。

Abstract: Modern vector databases enable efficient retrieval over high-dimensional neural embeddings, powering applications from web search to retrieval-augmented generation. However, classical theory predicts such tasks should suffer from the curse of dimensionality, where distances between points become nearly indistinguishable, thereby crippling efficient nearest-neighbor search. We revisit this paradox through the lens of stability, the property that small perturbations to a query do not radically alter its nearest neighbors. Building on foundational results, we extend stability theory to three key retrieval settings widely used in practice: (i) multi-vector search, where we prove that the popular Chamfer distance metric preserves single-vector stability, while average pooling aggregation may destroy it; (ii) filtered vector search, where we show that sufficiently large penalties for mismatched filters can induce stability even when the underlying search is unstable; and (iii) sparse vector search, where we formalize and prove novel sufficient stability conditions. Across synthetic and real datasets, our experimental results match our theoretical predictions, offering concrete guidance for model and system design to avoid the curse of dimensionality.

</details>


### [5] [Reveal Hidden Pitfalls and Navigate Next Generation of Vector Similarity Search from Task-Centric Views](https://arxiv.org/abs/2512.12980)
*Tingyang Chen,Cong Fu,Jiahua Wu,Haotian Wu,Hua Fan,Xiangyu Ke,Yunjun Gao,Yabo Ni,Anxiang Zeng*

Main category: cs.IR

TL;DR: Iceberg是一个端到端的向量相似性搜索基准测试套件，关注实际应用场景而非仅召回-延迟权衡，揭示传统评估与下游任务性能的显著差异


<details>
  <summary>Details</summary>
Motivation: 当前VSS基准测试主要关注基于距离度量的召回-延迟权衡，忽略了检索质量对下游任务的实际影响，这种脱节可能误导学术研究和工业实践

Method: 提出Iceberg基准套件，从任务中心视角识别信息损失漏斗的三个主要来源：嵌入损失、度量误用和数据分布敏感性；在8个多样化数据集上评估13种最先进的VSS方法

Result: 基于应用级指标的重新排名与传统基于召回-延迟的排名存在显著偏差；定义了任务中心元特征并推导出可解释的决策树，指导实践者根据具体工作负载选择和调优VSS方法

Conclusion: 需要从孤立的召回-延迟评估转向端到端的应用性能评估，Iceberg为VSS方法的实际应用价值提供了更全面的评估框架

Abstract: Vector Similarity Search (VSS) in high-dimensional spaces is rapidly emerging as core functionality in next-generation database systems for numerous data-intensive services -- from embedding lookups in large language models (LLMs), to semantic information retrieval and recommendation engines. Current benchmarks, however, evaluate VSS primarily on the recall-latency trade-off against a ground truth defined solely by distance metrics, neglecting how retrieval quality ultimately impacts downstream tasks. This disconnect can mislead both academic research and industrial practice.
  We present Iceberg, a holistic benchmark suite for end-to-end evaluation of VSS methods in realistic application contexts. From a task-centric view, Iceberg uncovers the Information Loss Funnel, which identifies three principal sources of end-to-end performance degradation: (1) Embedding Loss during feature extraction; (2) Metric Misuse, where distances poorly reflect task relevance; (3) Data Distribution Sensitivity, highlighting index robustness across skews and modalities. For a more comprehensive assessment, Iceberg spans eight diverse datasets across key domains such as image classification, face recognition, text retrieval, and recommendation systems. Each dataset, ranging from 1M to 100M vectors, includes rich, task-specific labels and evaluation metrics, enabling assessment of retrieval algorithms within the full application pipeline rather than in isolation. Iceberg benchmarks 13 state-of-the-art VSS methods and re-ranks them based on application-level metrics, revealing substantial deviations from traditional rankings derived purely from recall-latency evaluations. Building on these insights, we define a set of task-centric meta-features and derive an interpretable decision tree to guide practitioners in selecting and tuning VSS methods for their specific workloads.

</details>


### [6] [FloodSQL-Bench: A Retrieval-Augmented Benchmark for Geospatially-Grounded Text-to-SQL](https://arxiv.org/abs/2512.12084)
*Hanzhou Liu,Kai Yin,Zhitong Chen,Chenyue Liu,Ali Mostafavi*

Main category: cs.IR

TL;DR: FLOODSQL-BENCH是一个针对洪水管理领域的空间地理基准测试，整合了多表、异构数据集和空间连接，用于评估Text-to-SQL模型在复杂领域特定任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL基准主要关注单表查询或通用领域的有限连接，无法反映领域特定、多表和空间推理的复杂性，特别是在洪水管理等高风险应用领域。

Method: 通过整合异构数据集（社会、基础设施和灾害数据层），基于键、空间和混合连接构建地理空间基准测试，并系统评估大型语言模型在相同检索增强生成设置下的表现。

Result: 建立了统一的开放基准测试，基于真实世界灾害管理数据，为高风险应用领域的Text-to-SQL研究提供了实用的测试平台。

Conclusion: FLOODSQL-BENCH填补了现有基准在领域特定复杂查询评估方面的空白，为推进高风险应用领域的Text-to-SQL研究提供了重要工具。

Abstract: Existing Text-to-SQL benchmarks primarily focus on single-table queries or limited joins in general-purpose domains, and thus fail to reflect the complexity of domain-specific, multi-table and geospatial reasoning, To address this limitation, we introduce FLOODSQL-BENCH, a geospatially grounded benchmark for the flood management domain that integrates heterogeneous datasets through key-based, spatial, and hybrid joins. The benchmark captures realistic flood-related information needs by combining social, infrastructural, and hazard data layers. We systematically evaluate recent large language models with the same retrieval-augmented generation settings and measure their performance across difficulty tiers. By providing a unified, open benchmark grounded in real-world disaster management data, FLOODSQL-BENCH establishes a practical testbed for advancing Text-to-SQL research in high-stakes application domains.

</details>


### [7] [FuXi-$γ$: Efficient Sequential Recommendation with Exponential-Power Temporal Encoder and Diagonal-Sparse Positional Mechanism](https://arxiv.org/abs/2512.12740)
*Dezhi Yi,Wei Guo,Wenyang Cui,Wenxuan He,Huifeng Guo,Yong Liu,Zhenhua Dong,Ye Lu*

Main category: cs.IR

TL;DR: FuXi-γ是一个高效的序列推荐框架，采用解码器Transformer结构，通过指数幂时间编码器和对角稀疏位置机制，在提升推荐质量的同时大幅加速训练和推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的序列推荐方法存在高计算开销问题，主要源于时间编码的不连续内存访问和对长序列的密集注意力机制。需要设计一个既高效又有效的推荐框架。

Method: 采用解码器Transformer结构，引入两个关键创新：1）指数幂时间编码器，使用可调指数衰减函数编码相对时间间隔，模拟艾宾浩斯遗忘曲线；2）对角稀疏位置机制，利用Toeplitz矩阵的对称性，通过对角滑动策略修剪低贡献注意力块。

Result: 在四个真实世界数据集上的实验表明，FuXi-γ在推荐质量上达到最先进水平，同时训练加速最高达4.74倍，推理加速最高达6.18倍。

Conclusion: FuXi-γ通过原理性架构设计，在保持推荐效果的同时显著提升效率，为长序列推荐提供了一个实用且可扩展的解决方案。

Abstract: Sequential recommendation aims to model users' evolving preferences based on their historical interactions. Recent advances leverage Transformer-based architectures to capture global dependencies, but existing methods often suffer from high computational overhead, primarily due to discontinuous memory access in temporal encoding and dense attention over long sequences. To address these limitations, we propose FuXi-$γ$, a novel sequential recommendation framework that improves both effectiveness and efficiency through principled architectural design. FuXi-$γ$ adopts a decoder-only Transformer structure and introduces two key innovations: (1) An exponential-power temporal encoder that encodes relative temporal intervals using a tunable exponential decay function inspired by the Ebbinghaus forgetting curve. This encoder enables flexible modeling of both short-term and long-term preferences while maintaining high efficiency through continuous memory access and pure matrix operations. (2) A diagonal-sparse positional mechanism that prunes low-contribution attention blocks using a diagonal-sliding strategy guided by the persymmetry of Toeplitz matrix. Extensive experiments on four real-world datasets demonstrate that FuXi-$γ$ achieves state-of-the-art performance in recommendation quality, while accelerating training by up to 4.74$\times$ and inference by up to 6.18$\times$, making it a practical and scalable solution for long-sequence recommendation. Our code is available at https://github.com/Yeedzhi/FuXi-gamma.

</details>


### [8] [Intelligent Scientific Literature Explorer using Machine Learning (ISLE)](https://arxiv.org/abs/2512.12760)
*Sina Jani,Arman Heidari,Amirmohammad Anvari,Zahra Rahimi*

Main category: cs.IR

TL;DR: 该论文提出一个集成系统，用于科学文献探索，结合大规模数据获取、混合检索、语义主题建模和异构图谱构建，提升文献发现和解释能力。


<details>
  <summary>Details</summary>
Motivation: 科学出版速度加快使研究人员难以发现、情境化和解释相关文献。传统关键词搜索系统语义理解有限，现有AI工具通常只关注检索、聚类或可视化等孤立任务。

Method: 系统整合arXiv全文数据和OpenAlex结构化元数据，采用BM25词汇搜索与嵌入语义搜索的混合检索架构，使用BERTopic或NMF进行主题建模，构建包含论文、作者、机构、国家和主题的知识图谱。

Result: 评估显示在多个查询中，系统在检索相关性、主题一致性和可解释性方面均有改进。

Conclusion: 该框架为AI辅助科学发现提供了可扩展的基础，能够揭示查询相关的出版物及其概念和关系景观。

Abstract: The rapid acceleration of scientific publishing has created substantial challenges for researchers attempting to discover, contextualize, and interpret relevant literature. Traditional keyword-based search systems provide limited semantic understanding, while existing AI-driven tools typically focus on isolated tasks such as retrieval, clustering, or bibliometric visualization. This paper presents an integrated system for scientific literature exploration that combines large-scale data acquisition, hybrid retrieval, semantic topic modeling, and heterogeneous knowledge graph construction. The system builds a comprehensive corpus by merging full-text data from arXiv with structured metadata from OpenAlex. A hybrid retrieval architecture fuses BM25 lexical search with embedding-based semantic search using Reciprocal Rank Fusion. Topic modeling is performed on retrieved results using BERTopic or non-negative matrix factorization depending on computational resources. A knowledge graph unifies papers, authors, institutions, countries, and extracted topics into an interpretable structure. The system provides a multi-layered exploration environment that reveals not only relevant publications but also the conceptual and relational landscape surrounding a query. Evaluation across multiple queries demonstrates improvements in retrieval relevance, topic coherence, and interpretability. The proposed framework contributes an extensible foundation for AI-assisted scientific discovery.

</details>


### [9] [SPAR: Session-based Pipeline for Adaptive Retrieval on Legacy File Systems](https://arxiv.org/abs/2512.12938)
*Duy A. Nguyen,Hai H. Do,Minh Doan,Minh N. Do*

Main category: cs.IR

TL;DR: SPAR是一个针对遗留企业系统的轻量级RAG框架，采用两阶段检索：先创建语义元数据索引，再按需动态生成会话特定的向量数据库，相比传统RAG减少了计算开销并提高了检索效果。


<details>
  <summary>Details</summary>
Motivation: 企业历史数据大多存储在缺乏结构化组织和语义索引的遗留文件系统中，导致检索和分析效率低下且容易出错。传统RAG需要构建和维护完整的向量数据库，成本高昂。

Method: SPAR框架将LLM集成到RAG架构中，采用两阶段轻量级流程：1) 创建语义元数据索引；2) 按需动态生成会话特定的向量数据库。相比传统RAG减少了计算开销，提高了透明度和可控性。

Result: 理论复杂度分析显示SPAR相比标准LLM-based RAG具有计算优势。在包含大量生物医学文献的合成企业级文件系统上验证，SPAR在检索效果和下游模型准确性方面均有提升。

Conclusion: SPAR为遗留企业环境提供了一种高效、轻量级的RAG解决方案，减少了计算开销并提高了检索质量。论文讨论了设计权衡，并指出了在不同企业环境中部署SPAR面临的开放挑战。

Abstract: The ability to extract value from historical data is essential for enterprise decision-making. However, much of this information remains inaccessible within large legacy file systems that lack structured organization and semantic indexing, making retrieval and analysis inefficient and error-prone. We introduce SPAR (Session-based Pipeline for Adaptive Retrieval), a conceptual framework that integrates Large Language Models (LLMs) into a Retrieval-Augmented Generation (RAG) architecture specifically designed for legacy enterprise environments. Unlike conventional RAG pipelines, which require costly construction and maintenance of full-scale vector databases that mirror the entire file system, SPAR employs a lightweight two-stage process: a semantic Metadata Index is first created, after which session-specific vector databases are dynamically generated on demand. This design reduces computational overhead while improving transparency, controllability, and relevance in retrieval. We provide a theoretical complexity analysis comparing SPAR with standard LLM-based RAG pipelines, demonstrating its computational advantages. To validate the framework, we apply SPAR to a synthesized enterprise-scale file system containing a large corpus of biomedical literature, showing improvements in both retrieval effectiveness and downstream model accuracy. Finally, we discuss design trade-offs and outline open challenges for deploying SPAR across diverse enterprise settings.

</details>


### [10] [BLADE: A Behavior-Level Data Augmentation Framework with Dual Fusion Modeling for Multi-Behavior Sequential Recommendation](https://arxiv.org/abs/2512.12964)
*Yupeng Li,Mingyue Cheng,Yucong Luo,Yitong Zhou,Qingyang Mao,Shijin Wang*

Main category: cs.IR

TL;DR: BLADE框架通过双重项目-行为融合架构处理行为异质性，并通过三种行为级数据增强方法缓解数据稀疏问题，提升多行为序列推荐性能


<details>
  <summary>Details</summary>
Motivation: 多行为序列推荐面临两个基本挑战：用户行为的异质性和数据稀疏性，导致推荐性能不理想

Method: 提出BLADE框架：1）双重项目-行为融合架构，在输入层和中间层融入行为信息；2）三种行为级数据增强方法，直接在行为序列上操作；3）通过对比学习增强表示学习和泛化能力

Result: 在三个真实世界数据集上的实验证明了该方法的有效性

Conclusion: BLADE框架通过处理行为异质性和数据稀疏性，显著提升了多行为序列推荐的性能

Abstract: Multi-behavior sequential recommendation aims to capture users' dynamic interests by modeling diverse types of user interactions over time. Although several studies have explored this setting, the recommendation performance remains suboptimal, mainly due to two fundamental challenges: the heterogeneity of user behaviors and data sparsity. To address these challenges, we propose BLADE, a framework that enhances multi-behavior modeling while mitigating data sparsity. Specifically, to handle behavior heterogeneity, we introduce a dual item-behavior fusion architecture that incorporates behavior information at both the input and intermediate levels, enabling preference modeling from multiple perspectives. To mitigate data sparsity, we design three behavior-level data augmentation methods that operate directly on behavior sequences rather than core item sequences. These methods generate diverse augmented views while preserving the semantic consistency of item sequences. These augmented views further enhance representation learning and generalization via contrastive learning. Experiments on three real-world datasets demonstrate the effectiveness of our approach.

</details>


### [11] [Do Reviews Matter for Recommendations in the Era of Large Language Models?](https://arxiv.org/abs/2512.12978)
*Chee Heng Tan,Huiying Zheng,Jing Wang,Zhuoyi Lin,Shaodi Feng,Huijing Zhan,Xiaoli Li,J. Senthilnath*

Main category: cs.IR

TL;DR: LLM推荐系统在数据稀疏和冷启动场景下优于传统深度学习方法，用户评论的移除或随机扭曲不一定降低推荐准确性，需要重新思考如何更有效利用文本评论中的用户偏好。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型(LLM)的出现，推荐系统正在经历重大变革。传统上用户评论是提升推荐质量的重要上下文信息源，但LLM展现出前所未有的文本理解和生成能力，这引发了一个问题：在LLM时代，显式的用户评论是否仍然必要？

Method: 通过比较深度学习方法和LLM方法，系统研究文本评论在推荐中的演变作用。在八个公共数据集上进行广泛实验，评估LLM在零样本、少样本和微调场景下的性能。引入RAREval基准评估框架，全面评估文本评论对推荐性能的贡献，包括移除部分或全部文本评论、随机扭曲、数据稀疏和冷启动用户设置等场景。

Result: LLM能够作为有效的评论感知推荐引擎，通常优于传统深度学习方法，特别是在数据稀疏和冷启动条件下。此外，移除部分或全部文本评论以及随机扭曲不一定导致推荐准确性的下降。

Conclusion: 这些发现促使我们重新思考如何更有效地利用文本评论中的用户偏好。LLM在推荐系统中展现出强大的潜力，特别是在处理数据稀疏和冷启动问题时，传统依赖显式用户评论的方法可能需要重新评估。

Abstract: With the advent of large language models (LLMs), the landscape of recommender systems is undergoing a significant transformation. Traditionally, user reviews have served as a critical source of rich, contextual information for enhancing recommendation quality. However, as LLMs demonstrate an unprecedented ability to understand and generate human-like text, this raises the question of whether explicit user reviews remain essential in the era of LLMs. In this paper, we provide a systematic investigation of the evolving role of text reviews in recommendation by comparing deep learning methods and LLM approaches. Particularly, we conduct extensive experiments on eight public datasets with LLMs and evaluate their performance in zero-shot, few-shot, and fine-tuning scenarios. We further introduce a benchmarking evaluation framework for review-aware recommender systems, RAREval, to comprehensively assess the contribution of textual reviews to the recommendation performance of review-aware recommender systems. Our framework examines various scenarios, including the removal of some or all textual reviews, random distortion, as well as recommendation performance in data sparsity and cold-start user settings. Our findings demonstrate that LLMs are capable of functioning as effective review-aware recommendation engines, generally outperforming traditional deep learning approaches, particularly in scenarios characterized by data sparsity and cold-start conditions. In addition, the removal of some or all textual reviews and random distortion does not necessarily lead to declines in recommendation accuracy. These findings motivate a rethinking of how user preference from text reviews can be more effectively leveraged. All code and supplementary materials are available at: https://github.com/zhytk/RAREval-data-processing.

</details>


### [12] [Are Large Language Models Really Effective for Training-Free Cold-Start Recommendation?](https://arxiv.org/abs/2512.13001)
*Genki Kusano,Kenya Abe,Kunihiro Takeoka*

Main category: cs.IR

TL;DR: 本文首次在相同条件下系统比较了LLM和TEM在训练免费推荐中的表现，发现TEM方法在冷启动和热启动场景下均优于LLM重排序器，挑战了LLM直接排序是唯一可行方案的普遍认知。


<details>
  <summary>Details</summary>
Motivation: 现实推荐系统常面临无训练数据的冷启动问题（如新服务上线或全新用户），传统方法无法应用。虽然LLM被探索为有前景的解决方案，且TEM能力不断增强，但尚无研究在相同条件下直接比较这两种方法。

Method: 首次进行受控实验，在相同设置下系统评估LLM和TEM两种方法在训练免费推荐中的表现，特别关注更具挑战性的训练免费冷启动推荐（TFCSR）场景。

Result: 实验结果显示TEM方法优于LLM重排序器，这一趋势不仅在冷启动设置中成立，在具有丰富交互的热启动设置中也同样成立。

Conclusion: LLM直接排序并非唯一可行方案，TEM方法为训练免费推荐提供了更强大、更可扩展的基础，挑战了该领域的普遍认知。

Abstract: Recommender systems usually rely on large-scale interaction data to learn from users' past behaviors and make accurate predictions. However, real-world applications often face situations where no training data is available, such as when launching new services or handling entirely new users. In such cases, conventional approaches cannot be applied. This study focuses on training-free recommendation, where no task-specific training is performed, and particularly on \textit{training-free cold-start recommendation} (TFCSR), the more challenging case where the target user has no interactions. Large language models (LLMs) have recently been explored as a promising solution, and numerous studies have been proposed. As the ability of text embedding models (TEMs) increases, they are increasingly recognized as applicable to training-free recommendation, but no prior work has directly compared LLMs and TEMs under identical conditions. We present the first controlled experiments that systematically evaluate these two approaches in the same setting. The results show that TEMs outperform LLM rerankers, and this trend holds not only in cold-start settings but also in warm-start settings with rich interactions. These findings indicate that direct LLM ranking is not the only viable option, contrary to the commonly shared belief, and TEM-based approaches provide a stronger and more scalable basis for training-free recommendation.

</details>


### [13] [Progressive Refinement of E-commerce Search Ranking Based on Short-Term Activities of the Buyer](https://arxiv.org/abs/2512.13037)
*Taoran Sheng,Sathappan Muthiah,Atiq Islam,Jinming Feng*

Main category: cs.IR

TL;DR: 论文提出了一种基于上下文逐步优化的电商搜索排序方法，通过从简单启发式特征到高级序列模型的渐进式改进，显著提升了搜索结果与买家当前需求和意图的匹配度。


<details>
  <summary>Details</summary>
Motivation: 电商搜索面临的主要挑战是如何在买家购物旅程中（从浏览到购买决策，或意图转变时）动态调整搜索结果，使其与买家当前需求和偏好保持一致。

Method: 采用系统化方法，从基础方法开始，逐步融入更多上下文信息和最先进技术。通过将这种演进式上下文框架应用于搜索结果页面上的商品，逐步使搜索结果更贴近买家兴趣和当前搜索意图。

Result: 从简单启发式自回归特征到高级序列模型的渐进式改进显著提升了排序器性能。上下文技术的集成增强了生产排序器的性能，在离线和在线A/B测试中都改善了搜索结果（以平均倒数排名MRR衡量）。

Conclusion: 论文详细阐述了迭代方法及其对电商平台搜索结果上下文化的重要贡献，证明了渐进式上下文优化框架在提升搜索相关性方面的有效性。

Abstract: In e-commerce shopping, aligning search results with a buyer's immediate needs and preferences presents a significant challenge, particularly in adapting search results throughout the buyer's shopping journey as they move from the initial stages of browsing to making a purchase decision or shift from one intent to another. This study presents a systematic approach to adapting e-commerce search results based on the current context. We start with basic methods and incrementally incorporate more contextual information and state-of-the-art techniques to improve the search outcomes. By applying this evolving contextual framework to items displayed on the search engine results page (SERP), we progressively align search outcomes more closely with the buyer's interests and current search intentions. Our findings demonstrate that this incremental enhancement, from simple heuristic autoregressive features to advanced sequence models, significantly improves ranker performance. The integration of contextual techniques enhances the performance of our production ranker, leading to improved search results in both offline and online A/B testing in terms of Mean Reciprocal Rank (MRR). Overall, the paper details iterative methodologies and their substantial contributions to search result contextualization on e-commerce platforms.

</details>


### [14] [A Simple and Effective Framework for Symmetric Consistent Indexing in Large-Scale Dense Retrieval](https://arxiv.org/abs/2512.13074)
*Huimu Wang,Yiming Qiu,Xingzhi Yao,Zhiguo Chen,Guoyu Tang,Songlin Wang,Sulong Xu,Mingming Li*

Main category: cs.IR

TL;DR: 论文提出SCI框架解决稠密检索中双塔架构的表示空间错位和检索索引不一致问题，通过对称表示对齐和一致性索引模块提升匹配精度和检索稳定性。


<details>
  <summary>Details</summary>
Motivation: 稠密检索已成为大规模信息检索系统的行业标准，但其广泛采用的双塔编码架构存在表示空间错位和检索索引不一致的固有挑战，这会降低匹配精度、检索稳定性以及对长尾查询的性能。这些问题在语义ID生成中进一步放大，限制了下游生成模型的性能上限。

Method: 提出SCI框架，包含两个协同模块：1) 对称表示对齐模块，采用创新的输入交换机制统一双塔表示空间而不增加参数；2) 一致性索引与双塔协同模块，通过双视图索引策略重新设计检索路径，保持从训练到推理的一致性。

Result: 该框架是系统化、轻量级且工程友好的，需要最小开销同时完全支持十亿级部署。在公共数据集和真实世界电商数据集上的结果验证了其有效性，并提供了理论保证。

Conclusion: SCI框架通过解决双塔架构的核心挑战，提升了稠密检索系统的匹配精度和检索稳定性，特别是在语义ID生成场景中，为下游生成模型提供了更好的性能基础。

Abstract: Dense retrieval has become the industry standard in large-scale information retrieval systems due to its high efficiency and competitive accuracy. Its core relies on a coarse-to-fine hierarchical architecture that enables rapid candidate selection and precise semantic matching, achieving millisecond-level response over billion-scale corpora. This capability makes it essential not only in traditional search and recommendation scenarios but also in the emerging paradigm of generative recommendation driven by large language models, where semantic IDs-themselves a form of coarse-to-fine representation-play a foundational role. However, the widely adopted dual-tower encoding architecture introduces inherent challenges, primarily representational space misalignment and retrieval index inconsistency, which degrade matching accuracy, retrieval stability, and performance on long-tail queries. These issues are further magnified in semantic ID generation, ultimately limiting the performance ceiling of downstream generative models.
  To address these challenges, this paper proposes a simple and effective framework named SCI comprising two synergistic modules: a symmetric representation alignment module that employs an innovative input-swapping mechanism to unify the dual-tower representation space without adding parameters, and an consistent indexing with dual-tower synergy module that redesigns retrieval paths using a dual-view indexing strategy to maintain consistency from training to inference. The framework is systematic, lightweight, and engineering-friendly, requiring minimal overhead while fully supporting billion-scale deployment. We provide theoretical guarantees for our approach, with its effectiveness validated by results across public datasets and real-world e-commerce datasets.

</details>


### [15] [Towards Practical Large-scale Dynamical Heterogeneous Graph Embedding: Cold-start Resilient Recommendation](https://arxiv.org/abs/2512.13120)
*Mabiao Long,Jiaxi Liu,Yufeng Li,Hao Xiong,Junchi Yan,Kefan Wang,Yi Cao,Jiandong Ding*

Main category: cs.IR

TL;DR: 提出一个两阶段框架，结合可扩展的静态图变换器HetSGFormer和轻量级增量更新算法ILLE，解决动态异构图嵌入在生产环境中的可扩展性、数据新鲜度和冷启动问题。


<details>
  <summary>Details</summary>
Motivation: 在生产环境中部署动态异构图嵌入面临三个关键挑战：可扩展性（处理十亿级图）、数据新鲜度（实时更新嵌入）和冷启动问题（稀疏数据的有效嵌入）。

Method: 采用两阶段方法：1) HetSGFormer - 用于静态学习的可扩展图变换器，具有线性可扩展性，捕获全局结构；2) ILLE - 轻量级、基于CPU的增量局部线性嵌入算法，用于实时更新，避免昂贵的完全重新训练。

Result: 在十亿级图上，A/B测试显示：HetSGFormer相比之前方法提升了6.11%的广告商价值；ILLE模块进一步提升了3.22%，并将嵌入刷新及时性提高了83.2%。

Conclusion: 该工作提供了一个经过验证的框架，用于在生产环境中部署动态图学习，通过结合深度图表示和低延迟增量更新，有效解决了可扩展性、数据新鲜度和冷启动问题。

Abstract: Deploying dynamic heterogeneous graph embeddings in production faces key challenges of scalability, data freshness, and cold-start. This paper introduces a practical, two-stage solution that balances deep graph representation with low-latency incremental updates. Our framework combines HetSGFormer, a scalable graph transformer for static learning, with Incremental Locally Linear Embedding (ILLE), a lightweight, CPU-based algorithm for real-time updates. HetSGFormer captures global structure with linear scalability, while ILLE provides rapid, targeted updates to incorporate new data, thus avoiding costly full retraining. This dual approach is cold-start resilient, leveraging the graph to create meaningful embeddings from sparse data. On billion-scale graphs, A/B tests show HetSGFormer achieved up to a 6.11% lift in Advertiser Value over previous methods, while the ILLE module added another 3.22% lift and improved embedding refresh timeliness by 83.2%. Our work provides a validated framework for deploying dynamic graph learning in production environments.

</details>


### [16] [Know Your Users! Estimating User Domain Knowledge in Conversational Recommenders](https://arxiv.org/abs/2512.13173)
*Ivica Kostric,Ujwal Gadiraju,Krisztian Balog*

Main category: cs.IR

TL;DR: 论文提出通过游戏化数据收集协议创建包含不同领域知识水平用户对话行为的数据集，以支持开发能自适应用户知识水平的对话推荐系统。


<details>
  <summary>Details</summary>
Motivation: 当前对话推荐系统通常将所有用户视为专家，导致对领域不熟悉的用户交互体验差。需要能根据用户知识水平自适应调整对话策略的系统，但缺乏包含不同知识水平用户对话行为的数据集。

Method: 设计了基于游戏的数据收集协议，激发用户表达不同层次的知识，并发布了由此产生的数据集。提出了从对话中估计用户领域知识的新任务。

Result: 创建了首个包含不同领域知识水平用户对话行为的数据集，为开发用户知识感知的对话推荐系统提供了基础资源。

Conclusion: 通过游戏化数据收集方法成功解决了缺乏用户知识水平数据的问题，为未来开发自适应用户知识水平的对话推荐系统奠定了基础。

Abstract: The ideal conversational recommender system (CRS) acts like a savvy salesperson, adapting its language and suggestions to each user's level of expertise. However, most current systems treat all users as experts, leading to frustrating and inefficient interactions when users are unfamiliar with a domain. Systems that can adapt their conversational strategies to a user's knowledge level stand to offer a much more natural and effective experience. To make a step toward such adaptive systems, we introduce a new task: estimating user domain knowledge from conversations, enabling a CRS to better understand user needs and personalize interactions. A key obstacle to developing such adaptive systems is the lack of suitable data; to our knowledge, no existing dataset captures the conversational behaviors of users with varying levels of domain knowledge. Furthermore, in most dialogue collection protocols, users are free to express their own preferences, which tends to concentrate on popular items and well-known features, offering little insight into how novices explore or learn about unfamiliar features. To address this, we design a game-based data collection protocol that elicits varied expressions of knowledge, release the resulting dataset, and provide an initial analysis to highlight its potential for future work on user-knowledge-aware CRS.

</details>


### [17] [BlossomRec: Block-level Fused Sparse Attention Mechanism for Sequential Recommendations](https://arxiv.org/abs/2512.13368)
*Mengyang Ma,Xiaopeng Li,Wanyu Wang,Zhaocheng Du,Jingtong Gao,Pengyue Jia,Yuyang Ye,Yiqi Wang,Yunpeng Weng,Weihong Luo,Xiao Han,Xiangyu Zhao*

Main category: cs.IR

TL;DR: BlossomRec是一种用于序列推荐系统的稀疏注意力机制，通过分离建模长短期用户兴趣，在保持性能的同时显著降低计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在序列推荐系统中随着用户交互历史增长，计算时间和内存需求急剧增加。现有高效注意力方法和SSM模型在长序列建模上效果不佳，在短序列上性能不稳定。

Method: 设计稀疏注意力机制BlossomRec，将用户兴趣分为长短期两类，分别用两种不同的稀疏注意力模式计算，通过可学习门控输出结合结果，显著减少参与注意力计算的交互数量。

Result: 在四个公开数据集上的实验表明，BlossomRec与最先进的Transformer模型结合时，在显著降低内存使用的同时，达到相当甚至更好的性能。

Conclusion: BlossomRec通过稀疏注意力机制有效建模不同长度的用户序列，在效率和效果上都有显著优势，为序列推荐系统提供了高效的解决方案。

Abstract: Transformer structures have been widely used in sequential recommender systems (SRS). However, as user interaction histories increase, computational time and memory requirements also grow. This is mainly caused by the standard attention mechanism. Although there exist many methods employing efficient attention and SSM-based models, these approaches struggle to effectively model long sequences and may exhibit unstable performance on short sequences. To address these challenges, we design a sparse attention mechanism, BlossomRec, which models both long-term and short-term user interests through attention computation to achieve stable performance across sequences of varying lengths. Specifically, we categorize user interests in recommendation systems into long-term and short-term interests, and compute them using two distinct sparse attention patterns, with the results combined through a learnable gated output. Theoretically, it significantly reduces the number of interactions participating in attention computation. Extensive experiments on four public datasets demonstrate that BlossomRec, when integrated with state-of-the-art Transformer-based models, achieves comparable or even superior performance while significantly reducing memory usage, providing strong evidence of BlossomRec's efficiency and effectiveness.The code is available at https://github.com/ronineume/BlossomRec.

</details>


### [18] [Automated Information Flow Selection for Multi-scenario Multi-task Recommendation](https://arxiv.org/abs/2512.13396)
*Chaohua Yang,Dugang Liu,Shiwei Li,Yuwen Fu,Xing Tang,Weihong Luo,Xiangyu Zhao,Xiuqiang He,Zhong Ming*

Main category: cs.IR

TL;DR: 提出AutoIFS框架，通过LoRA解耦信息单元和自动筛选信息流，解决多场景多任务推荐系统的架构复杂和信息噪声问题。


<details>
  <summary>Details</summary>
Motivation: 现有MSMTR模型存在两个主要问题：1) 依赖复杂架构（如MoE），增加信息融合复杂度、模型规模和训练成本；2) 提取所有信息流而不筛选，引入噪声。

Method: 提出AutoIFS框架：1) 使用低秩适应(LoRA)解耦四个信息单元，实现灵活高效的信息融合；2) 引入信息流选择网络，基于模型性能反馈自动过滤无效的场景-任务信息流；3) 采用简单有效的剪枝函数消除无用信息流。

Result: 在两个公共基准数据集和在线A/B测试中验证了AutoIFS的有效性，表明该方法能提升模型性能。

Conclusion: AutoIFS通过轻量级架构和自动信息流选择，解决了MSMTR系统的复杂性和噪声问题，实现了更高效的多场景多任务推荐。

Abstract: Multi-scenario multi-task recommendation (MSMTR) systems must address recommendation demands across diverse scenarios while simultaneously optimizing multiple objectives, such as click-through rate and conversion rate. Existing MSMTR models typically consist of four information units: scenario-shared, scenario-specific, task-shared, and task-specific networks. These units interact to generate four types of relationship information flows, directed from scenario-shared or scenario-specific networks to task-shared or task-specific networks. However, these models face two main limitations: 1) They often rely on complex architectures, such as mixture-of-experts (MoE) networks, which increase the complexity of information fusion, model size, and training cost. 2) They extract all available information flows without filtering out irrelevant or even harmful content, introducing potential noise. Regarding these challenges, we propose a lightweight Automated Information Flow Selection (AutoIFS) framework for MSMTR. To tackle the first issue, AutoIFS incorporates low-rank adaptation (LoRA) to decouple the four information units, enabling more flexible and efficient information fusion with minimal parameter overhead. To address the second issue, AutoIFS introduces an information flow selection network that automatically filters out invalid scenario-task information flows based on model performance feedback. It employs a simple yet effective pruning function to eliminate useless information flows, thereby enhancing the impact of key relationships and improving model performance. Finally, we evaluate AutoIFS and confirm its effectiveness through extensive experiments on two public benchmark datasets and an online A/B test.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [19] [Differentially Private Community Detection in $h$-uniform Hypergraphs](https://arxiv.org/abs/2512.12031)
*Javad Zahedi Moghaddam,Aria Nosratinia*

Main category: cs.IT

TL;DR: 研究h-均匀超图中连接隐私保护下的精确恢复阈值，分析三种差分隐私机制在h-均匀随机块模型中的性能


<details>
  <summary>Details</summary>
Motivation: 在超图数据分析中，如何在保护连接隐私（超边差分隐私）的同时实现社区检测的精确恢复，研究隐私预算对恢复性能的影响

Method: 基于h-均匀随机块模型，研究三种差分隐私机制：稳定性机制、采样机制和扰动机制，计算每种机制的精确恢复阈值

Result: 采样机制和随机响应机制能保证纯ε-超边差分隐私，而稳定性机制无法达到此隐私级别。隐私预算的最小值随簇内与簇间超边密度比的对数增长

Conclusion: 隐私预算对精确恢复区域有收缩效应，不同机制的隐私预算依赖关系不同：稳定性机制和贝叶斯采样机制依赖于超图参数，而随机响应机制仅依赖于超图大小

Abstract: This paper studies the exact recovery threshold subject to preserving the privacy of connections in $h$-uniform hypergraphs. Privacy is characterized by the $(ε, δ)$-hyperedge differential privacy (DP), an extension of the notion of $(ε, δ)$-edge DP in the literature. The hypergraph observations are modeled through a $h$-uniform stochastic block model ($h$-HSBM) in the dense regime. We investigate three differentially private mechanisms: stability-based, sampling-based, and perturbation-based mechanisms. We calculate the exact recovery threshold for each mechanism and study the contraction of the exact recovery region due to the privacy budget, $(ε, δ)$. Sampling-based mechanisms and randomized response mechanisms guarantee pure $ε$-hyperedge DP where $δ=0$, while the stability-based mechanisms cannot achieve this level of privacy. The dependence of the limits of the privacy budget on the parameters of the $h$-uniform hypergraph is studied. More precisely, it is proven rigorously that the minimum privacy budget scales logarithmically with the ratio between the density of in-cluster hyperedges and the cross-cluster hyperedges for stability-based and Bayesian sampling-based mechanisms, while this budget depends only on the size of the hypergraph for the randomized response mechanism.

</details>


### [20] [A Framework for Scalable Digital Twin Deployment in Smart Campus Building Facility Management](https://arxiv.org/abs/2512.12149)
*Thyda Siv*

Main category: cs.IT

TL;DR: 该研究提出了一个用于智能校园建筑的可扩展数字孪生部署框架，通过集成3D激光扫描、BIM建模和物联网数据可视化来支持设施运维，并在佐治亚理工学院的Price Gilbert大楼进行了案例验证。


<details>
  <summary>Details</summary>
Motivation: 现有数字孪生研究往往局限于孤立领域（如点云几何或能源分析），缺乏将建筑几何、设备元数据和运营数据集成到统一设施管理平台的可扩展、可互操作工作流程。校园环境中的设施管理需要更全面的解决方案。

Method: 研究方法包括：(1) 使用地面激光扫描进行实景捕捉和结构化点云处理；(2) 开发包含建筑、机电、管道、输送和传感器系统的丰富BIM模型；(3) 创建数字孪生环境，在数字孪生管理平台中链接设备元数据、维护策略和模拟物联网数据。

Result: 在佐治亚理工学院Price Gilbert大楼的案例研究中，成功建模了509个设备项目并嵌入OmniClass分类到数字孪生中。开发了10个交互式仪表板可视化系统性能。结果显示该框架实现了集中化资产文档管理、改进的系统可视性以及增强的预防性和反应性维护工作流程。

Conclusion: 尽管大多数物联网数据因现有传感器基础设施有限而采用模拟方式，但原型验证了可扩展数字孪生用于设施管理的可行性，并为实时监控、分析集成和未来自主建筑运营建立了参考模型。

Abstract: Digital twin (DT) offers significant opportunities for enhancing facility management (FM) in campus environments. However, existing research often focuses narrowly on isolated domains, such as point-cloud geometry or energy analytics, without providing a scalable and interoperable workflow that integrates building geometry, equipment metadata, and operational data into a unified FM platform. This study proposes a comprehensive framework for scalable digital-twin deployment in smart campus buildings by integrating 3D laser scanning, BIM modeling, and IoT-enabled data visualization to support facility operations and maintenance. The methodology includes: (1) reality capture using terrestrial laser scanning and structured point-cloud processing; (2) development of an enriched BIM model incorporating architectural, mechanical, electrical, plumbing, conveying, and sensor systems; and (3) creation of a digital-twin environment that links equipment metadata, maintenance policies, and simulated IoT data within a digital-twin management platform. A case study of the Price Gilbert Building at Georgia Tech demonstrates the implementation of this workflow. A total of 509 equipment items were modeled and embedded with OmniClass classifications into the digital twin. Ten interactive dashboards were developed to visualize system performance. Results show that the proposed framework enables centralized asset documentation, improved system visibility, and enhanced preventive and reactive maintenance workflows. Although most IoT data were simulated due to limited existing sensor infrastructure, the prototype validates the feasibility of a scalable digital twin for facility management and establishes a reference model for real-time monitoring, analytics integration, and future autonomous building operations.

</details>


### [21] [Large and Small Model Collaboration for Air Interface](https://arxiv.org/abs/2512.12170)
*Yiming Cui,Jiajia Guo,Xiao Li,Chao-Kai Wen,Shi Jin*

Main category: cs.IT

TL;DR: 提出LASCO框架，利用大模型作为通用信道知识库，小模型作为轻量插件捕获环境特定知识，实现高效的环境自适应CSI反馈


<details>
  <summary>Details</summary>
Motivation: 现有工作主要依赖大模型的跨环境通用知识，忽视了环境特定适应的潜在收益。直接微调大模型存在训练成本高、多用户场景推理效率低、灾难性遗忘风险以及模型参数访问受限等问题

Method: 建立协作框架：大模型作为通用信道知识库，小模型作为轻量插件捕获环境特定知识。具体针对CSI反馈任务开发LASCO框架：大模型产生初始CSI重建，通过参考SAM和代理SAM学习环境引起的重建偏移，并将偏移传回大模型。进一步提出E-LASCO，增加可学习的协作系数来控制不同环境中大模型和小模型的贡献

Result: 数值结果表明，LASCO和E-LASCO使大模型能够以显著降低的训练成本、更少的数据收集需求和更快的适应速度实现环境特定性能增益

Conclusion: 提出的协作框架有效解决了大模型环境适应中的实际限制，通过大小模型协作实现了高效的环境特定适应，为无线通信中的AI模型应用提供了新思路

Abstract: Large artificial intelligence models (LAMs) have shown strong capability in wireless communications, yet existing works mainly rely on their generalized knowledge across environments while overlooking the potential gains of environment-specific adaptation. Directly fine-tuning LAMs for adaptation is often impractical due to prohibitive training costs, low inference efficiency in multi-user scenarios, and the risk of catastrophic forgetting, in addition to the limited accessibility of model parameters. To address these limitations, we establish a collaborative framework for air interface. In this framework, unlike prior approaches that either depend solely on LAMs or require direct fine-tuning, LAMs are exploited as a universal channel knowledge base while small artificial intelligence models (SAMs) are employed as lightweight plugins to capture environment-specific knowledge, facilitating efficient environment-specific adaptation of LAMs. Subsequently, we instantiate this framework for CSI feedback tasks, and develop a large and small collaboration framework for CSI feedback, referred to as LASCO. LASCO operates by letting the base LAM produce an initial CSI reconstruction, learning the environment-induced reconstruction shift through a reference SAM and a proxy SAM, and transferring this shift back to the LAM. To further enhance adaptability, we introduce elastic-LASCO (E-LASCO), which augments LASCO with learnable collaboration coefficients that control the contribution of LAMs and SAMs across different environments. Numerical results demonstrate that LASCO and E-LASCO enables LAMs to achieve environment-specific performance gains with significantly reduced training costs, lower data collection requirements, and faster adaptation speed.

</details>


### [22] [Hulls of Free Linear Codes over a Non-Unital Ring](https://arxiv.org/abs/2512.12335)
*Anup Kushwaha,Om Prakash*

Main category: cs.IT

TL;DR: 研究非单位环E上自由线性码的壳码，包括壳的生成矩阵、构建构造方法、置换等价性，并分类长度≤8的最优自由E-线性码


<details>
  <summary>Details</summary>
Motivation: 研究非单位环E上自由线性码的壳码结构，探索如何从较小长度和壳秩的码构建更大码，并解决置换等价性和壳变化问题

Method: 1) 分析E-线性码各种壳的剩余码和挠码，获得自由E-线性码壳的生成矩阵显式形式；2) 提出四种构建构造方法从较小码构造更大码；3) 研究自由E-线性码的置换等价性；4) 讨论壳变化问题

Result: 1) 获得了自由E-线性码壳的生成矩阵显式形式；2) 提出了四种有效的构建构造方法；3) 解决了置换等价性问题；4) 分类了长度≤8的最优自由E-线性码

Conclusion: 该论文系统研究了非单位环E上自由线性码的壳码理论，建立了完整的理论框架，包括壳的生成矩阵、构造方法、等价性分析，并给出了最优码的分类结果

Abstract: This paper investigates the hull codes of free linear codes over a non-unital ring $ E= \langle κ,τ\mid 2 κ=2 τ=0,~ κ^2=κ,~ τ^2=τ,~ κτ=κ,~ τκ=τ\rangle$. Initially, we examine the residue and torsion codes of various hulls of $E$-linear codes and obtain an explicit form of the generator matrix of the hull of a free $E$-linear code. Then, we propose four build-up construction methods to construct codes with a larger length and hull-rank from codes with a smaller length and hull-rank. Some illustrative examples are also given to support our build-up construction methods. Subsequently, we study the permutation equivalence of two free $E$-linear codes and discuss the hull-variation problem. As an application, we classify optimal free $E$-linear codes for lengths up to $8$.

</details>


### [23] [ElasticVR: Elastic Task Computing in Multi-User Multi-Connectivity Wireless Virtual Reality (VR) Systems](https://arxiv.org/abs/2512.12366)
*Babak Badnava,Jacob Chakareski,Morteza Hashemi*

Main category: cs.IT

TL;DR: ElasticVR框架通过可扩展的360度视频分块和边缘-客户端多连接架构，结合多智能体深度强化学习，优化VR应用的QoE和能耗


<details>
  <summary>Details</summary>
Motivation: 高保真360度视频流需要大量计算和带宽，而可扩展的360度视频分块技术能够根据用户和系统资源弹性调整计算任务。需要平衡通信、计算、能耗和QoE之间的权衡

Method: 将可扩展360度视频分块集成到边缘-客户端无线多连接架构中，提出ElasticVR框架。采用两种多智能体深度强化学习方案：CPPG（集中训练集中执行）和IPPG（集中训练分散执行），优化多用户多连接环境下的任务卸载

Result: ElasticVR框架相比无弹性VR计算，PSNR提升43.21%，响应时间降低42.35%，能耗减少56.83%

Conclusion: ElasticVR框架通过弹性VR计算任务和多智能体强化学习，有效平衡了通信、计算、能耗和QoE的权衡，显著提升了VR应用的性能表现

Abstract: Diverse emerging VR applications integrate streaming of high fidelity 360 video content that requires ample amounts of computation and data rate. Scalable 360 video tiling enables having elastic VR computational tasks that can be scaled adaptively in computation and data rate based on the available user and system resources. We integrate scalable 360 video tiling in an edge-client wireless multi-connectivity architecture for joint elastic task computation offloading across multiple VR users called ElasticVR. To balance the trade-offs in communication, computation, energy consumption, and QoE that arise herein, we formulate a constrained QoE and energy optimization problem that integrates the multi-user/multi-connectivity action space with the elasticity of VR computational tasks. The ElasticVR framework introduces two multi-agent deep reinforcement learning solutions, namely CPPG and IPPG. CPPG adopts a centralized training and centralized execution approach to capture the coupling between users' communication and computational demands. This leads to globally coordinated decisions at the cost of increased computational overheads and limited scalability. To address the latter challenges, we also explore an alternative strategy denoted IPPG that adopts a centralized training with decentralized execution paradigm. IPPG leverages shared information and parameter sharing to learn robust policies; however, during execution, each user takes action independently based on its local state information only. The decentralized execution alleviates the communication and computation overhead of centralized decision-making and improves scalability. We show that the ElasticVR framework improves the PSNR by 43.21%, while reducing the response time and energy consumption by 42.35% and 56.83%, respectively, compared with a case where no elasticity is incorporated into VR computations.

</details>


### [24] [Linear Codes with Certain Dimension of Hermitian Hulls](https://arxiv.org/abs/2512.12519)
*Jiabin Wang,Jinquan Luo*

Main category: cs.IT

TL;DR: 研究有限域上酉空间中Hermitian ℓ-互补码的计数公式和渐近性质，发现Hermitian自正交码与无限制码在渐近重量分布上相似，并证明当字母表大小趋于无穷时，MDS码在Hermitian自正交码类中是渐近稠密的。


<details>
  <summary>Details</summary>
Motivation: 研究Hermitian ℓ-互补码的枚举和渐近性质，探索Hermitian自正交码与无限制码在渐近行为上的关系，特别关注最小距离约束下Hermitian自正交码的渐近特性。

Method: 在有限域F_{q^2}上的酉空间中研究Hermitian ℓ-互补码，推导计数公式的闭式表达式，分析渐近重量分布，研究具有最小距离约束的Hermitian自正交码的渐近行为。

Result: 得到了Hermitian ℓ-互补码计数公式的闭式表达式；发现Hermitian自正交码与无限制码在渐近重量分布上相似；证明了当字母表大小趋于无穷时，MDS码在Hermitian自正交码类中是渐近稠密的。

Conclusion: Hermitian自正交码在渐近性质上与无限制码有相似性，特别地，在字母表大小趋于无穷的条件下，MDS码在Hermitian自正交码中是普遍存在的，这为编码理论提供了重要的渐近性质洞察。

Abstract: In this paper, we study the enumerative and asymptotic properties related to Hermitian $\ell$-complementary codes on the unitary space over $\F_{q^2}$. We provide some closed form expressions for the counting formulas of Hermitian $\ell$-complementary codes. There is a similarity in the asymptotic weight distribution between Hermitian self-orthogonal codes and unrestricted codes. Furthermore, we study the asymptotic behavior of Hermitian self-orthogonal codes whose minimum distance is at least $d$. In particular, we conclude that MDS codes within the class of Hermitian self-orthogonal codes are asymptotically dense when the alphabet size approaches to infinity.

</details>


### [25] [Vertical Heterogeneous Networks Beyond 5G: CoMP Coverage Enhancement and Optimization](https://arxiv.org/abs/2512.12563)
*Tian Shi,Wenkun Wen,Peiran Wu,Minghua Xia*

Main category: cs.IT

TL;DR: 本文提出了一种在垂直异构网络中利用无人机作为空中基站，通过协调多点传输框架提升稀疏空中用户下行覆盖性能的方法，包括随机部署和优化部署两种策略。


<details>
  <summary>Details</summary>
Motivation: 低空无线网络对低空经济发展至关重要，但在动态三维空间中为稀疏分布的空中用户提供可靠连接面临重大挑战。现有系统难以应对非均匀用户分布和移动性强的空中环境。

Method: 提出协调多点传输框架，使无人机空中基站和地面基站能够联合传输。考虑两种无人机部署策略：1）随机部署，使用随机几何分析推导闭式覆盖表达式；2）优化部署，采用覆盖感知的加权K-means聚类算法最大化未覆盖区域的协作覆盖。

Result: 理论分析和蒙特卡洛仿真表明，所提出的CoMP使能的垂直异构网络显著提高了下行覆盖概率，特别是在稀疏空中用户场景中。优化部署策略相比随机部署能更好地提升覆盖性能。

Conclusion: 智能无人机协调和几何感知部署能够为低空无线网络提供稳健、自适应的连接，展示了协调多点传输在垂直异构网络中的巨大潜力，为未来低空经济应用提供了重要技术支撑。

Abstract: Low-altitude wireless networks are increasingly vital for the low-altitude economy, enabling wireless coverage in high-mobility and hard-to-reach environments. However, providing reliable connectivity to sparsely distributed aerial users in dynamic three-dimensional (3D) spaces remains a significant challenge. This paper investigates downlink coverage enhancement in vertical heterogeneous networks (VHetNets) beyond 5G, where uncrewed aerial vehicles (UAVs) operate as emerging aerial base stations (ABSs) alongside legacy terrestrial base stations (TBSs). To improve coverage performance, we propose a coordinated multi-point (CoMP) transmission framework that enables joint transmission from ABSs and TBSs. This approach mitigates the limitations of non-uniform user distributions and enhances reliability for sparse aerial users. Two UAV deployment strategies are considered: \textit{i)} random UAV placement, analyzed using stochastic geometry to derive closed-form coverage expressions, and \textit{ii)} optimized UAV placement using a coverage-aware weighted $K$-means clustering algorithm to maximize cooperative coverage in underserved areas. Theoretical analyses and Monte Carlo simulations demonstrate that the proposed CoMP-enabled VHetNet significantly improves downlink coverage probability, particularly in scenarios with sparse aerial users. These findings highlight the potential of intelligent UAV coordination and geometry-aware deployment to enable robust, adaptive connectivity in low-altitude wireless networks.

</details>


### [26] [Linear Binary Codes Correcting One or More Errors](https://arxiv.org/abs/2512.12591)
*Timofei Izhitskii*

Main category: cs.IT

TL;DR: 论文研究线性二进制码的纠错能力，针对单纠错情况证明了汉明界的可达性并给出了最小码字长度的精确表达式，对一般情况通过陪集结构分析得到了线性码参数的简单下界。


<details>
  <summary>Details</summary>
Motivation: 研究线性二进制码的纠错能力，特别是单纠错码的最优构造和一般线性码的参数界限，旨在为纠错码设计提供理论指导。

Method: 对于单纠错情况，采用构造性方法证明汉明界的可达性；对于一般情况，通过分析线性码的陪集结构来推导参数下界。

Result: 证明了单纠错线性二进制码可以达到汉明界，并给出了最小码字长度的精确表达式；对于一般线性码，得到了基于陪集结构的简单参数下界。

Conclusion: 论文为线性二进制码的纠错能力提供了理论分析框架，单纠错码的最优构造和一般码的参数下界结果对纠错码设计具有指导意义。

Abstract: This paper examines linear binary codes capable of correcting one or more errors. For the single-error-correcting case, it is shown that the Hamming bound is achieved by a constructive method, and an exact expression for the minimal codeword length is derived. For the general case, a simple lower bound for the parameters of linear codes is derived from an analysis of the coset structure.

</details>


### [27] [C-PASS: Center-Fed Pinching Antenna System](https://arxiv.org/abs/2512.12619)
*Xu Gan,Yuanwei Liu*

Main category: cs.IT

TL;DR: 提出了一种新型中心馈电夹持天线系统（C-PASS），相比传统端馈PASS，信号从中心输入端口馈入并向波导两侧传播，可在单个波导中实现空间复用增益。


<details>
  <summary>Details</summary>
Motivation: 传统端馈夹持天线系统（PASS）在空间复用能力方面存在限制，需要提升单波导系统的自由度（DoF）和复用增益，以实现更高的信道容量。

Method: 提出C-PASS架构，信号从中心输入端口馈入并向波导两侧传播。推导了自由度和功率缩放定律的闭式表达式，通过理论分析和数值仿真验证性能。

Result: C-PASS相比传统PASS可实现两倍的自由度，并获得额外的复用增益O(PT ln⁴N/N²)，其中PT为发射功率，N为夹持天线数量。数值结果表明C-PASS能显著提升信道容量。

Conclusion: C-PASS架构通过中心馈电设计有效提升了单波导系统的空间复用能力，在自由度和复用增益方面相比传统PASS有显著优势，为高容量通信系统提供了新方案。

Abstract: A novel architecture of the center-fed pinching antenna system (C-PASS) is proposed. In contrast to the conventional end-fed PASS, signals are fed from the center input ports and propagate towards both sides of the waveguide. By doing so, spatial-multiplexing gain can be achieved in a single waveguide. Based on the proposed C-PASS, closed-form expressions for the degree of freedom (DoF) and power scaling laws are derived. These theoretical results reveal that C-PASS can achieve \emph{twice} the DoF and an additional multiplexing gain of $\mathcal{O}(P_T \ln^4 N/N^2)$ compared to the conventional PASS, where $P_T$ and $N$ represent the transmit power and pinching antenna number, respectively. Numerical results are provided to demonstrate that substantial capacity improvements can be achieved through the enhanced DoF and multiplexing gain of the C-PASS.

</details>


### [28] [From Information Freshness to Semantics of Information and Goal-oriented Communications](https://arxiv.org/abs/2512.12758)
*Jiping Luo,Erfan Delfani,Mehrdad Salimnejad,Nikolaos Pappas*

Main category: cs.IT

TL;DR: 该论文系统梳理了从传统失真度量到信息新鲜度（AoI）再到面向任务的语义感知通信的演进，提出了统一的语义感知度量框架，并分析了基于MDP和Lyapunov优化的调度策略设计方法。


<details>
  <summary>Details</summary>
Motivation: 未来无线网络需要支持实时数据驱动的信息物理系统，传统基于准确性、吞吐量和延迟的通信范式已不足以满足需求，因为信息的价值取决于其与特定任务的语义相关性。

Method: 论文系统化地组织了现有的语义感知度量，包括内容和版本感知度量、上下文相关失真公式、历史依赖的错误持续性度量，并基于马尔可夫决策过程（MDP）和Lyapunov优化方法分析最优调度策略。

Result: 提出了一个统一的语义感知通信框架，能够显著提高效率、可靠性和任务性能，为6G及以后的语义通信架构设计提供指导原则。

Conclusion: 面向目标的语义感知通信系统通过选择性生成和传输任务相关信息，克服了纯准确性或新鲜度中心设计的局限性，为信息论、控制论和网络视角提供了桥梁。

Abstract: Future wireless networks must support real-time, data-driven cyber-physical systems in which communication is tightly coupled with sensing, inference, control, and decision-making. Traditional communication paradigms centered on accuracy, throughput, and latency are increasingly inadequate for these systems, where the value of information depends on its semantic relevance to a specific task. This paper provides a unified exposition of the progression from classical distortion-based frameworks, through information freshness metrics such as the Age of Information (AoI) and its variants, to the emerging paradigm of goal-oriented semantics-aware communication. We organize and systematize existing semantics-aware metrics, including content- and version-aware measures, context-dependent distortion formulations, and history-dependent error persistence metrics that capture lasting impact and urgency. Within this framework, we highlight how these metrics address the limitations of purely accuracy- or freshness-centric designs, and how they collectively enable the selective generation and transmission of only task-relevant information. We further review analytical tools based on Markov decision process (MDP) and Lyapunov optimization methods that have been employed to characterize optimal or near-optimal timing and scheduling policies under semantic performance criteria and communication constraints. By synthesizing these developments into a coherent framework, the paper clarifies the design principles underlying goal-oriented, semantics-aware communication systems. It illustrates how they can significantly improve efficiency, reliability, and task performance. The presented perspective aims to serve as a bridge between information-theoretic, control-theoretic, and networking viewpoints, and to guide the design of semantic communication architectures for 6G and beyond.

</details>


### [29] [Information-Theoretic Limits of Integrated Sensing and Communication with Finite Learning Capacity](https://arxiv.org/abs/2512.13292)
*Farshad Rostami Ghadi,F. Javier Lopez-Martinez,Kai-Kit Wong,Christos Masouros*

Main category: cs.IT

TL;DR: 提出AI辅助ISAC的统一信息论框架，引入AI容量预算概念量化学习模型有限能力对联合通信感知性能的限制，推导可达速率-感知区域上下界，分析高斯/衰落信道及MIMO系统，优化资源分配，建立学习-信息权衡定律，提出实用训练方法。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC系统通常假设理想信号处理能力，但实际AI辅助系统中学习模块的有限表示能力会限制联合性能。需要量化这种限制，为下一代ISAC系统的模型大小、波形和硬件协同设计提供理论指导。

Method: 建立统一信息论框架，引入AI容量预算概念量化学习模型限制。推导可达速率-感知区域的上下界，分析高斯信道中有限学习容量等效为加性噪声。扩展到瑞利/莱斯衰落和MIMO系统，使用新矩阵不等式和AI容量与有效噪声协方差的构造映射。优化学习约束下的资源分配，建立学习-信息权衡定律，提出变分训练方法。

Result: 对于高斯信道，有限学习容量表现为等效加性噪声，得到通信速率和感知失真的简单解析表达式。推导出可达速率-感知区域的上下界，获得高斯情况下的闭式资源分配条件。建立了连接学习模块表示能力与可达性能前沿的通用学习-信息权衡定律。提出的变分训练方法能够强制执行容量约束并指导实证评估。

Conclusion: 该框架为AI辅助ISAC系统提供了理论基础，量化了学习模型有限能力对联合性能的限制。推导的缩放定律为下一代ISAC系统的模型大小、波形和硬件协同设计提供了定量指导，有助于在实际约束下优化系统性能。

Abstract: This paper develops a unified information-theoretic framework for artificial-intelligence (AI)-aided integrated sensing and communication (ISAC), where a learning component with limited representational capacity is embedded within the transceiver loop. The study introduces the concept of an AI capacity budget to quantify how the finite ability of a learning model constrains joint communication and sensing performance. Under this framework, the paper derives both converse (upper) and achievability (lower) bounds that define the achievable rate-sensing region. For Gaussian channels, the effect of limited learning capacity is shown to behave as an equivalent additive noise, allowing simple analytical expressions for the resulting communication rate and sensing distortion. The theory is then extended to Rayleigh and Rician fading as well as to multiple-input multiple-output (MIMO) systems through new matrix inequalities and a constructive mapping between AI capacity and effective noise covariance. Resource allocation between sensing and communication is optimized under this learning constraint, yielding closed-form conditions in the Gaussian case. A general learning-information trade-off law is also established, linking the representational power of the learning module to the achievable performance frontier. Finally, a practical variational training procedure is proposed to enforce the capacity constraint and to guide empirical evaluation. The derived scaling laws provide quantitative insight for co-designing model size, waveform, and hardware in next-generation ISAC systems.

</details>


### [30] [Machine learning discovers new champion codes](https://arxiv.org/abs/2512.13370)
*Yang-Hui He,Alexander Kasprzyk,Q Le,Dmitrii Riabchenko*

Main category: cs.IT

TL;DR: 使用Transformer预测线性码的最小汉明距离，结合遗传算法搜索，开发出发现最优线性码的新方法，有效缩小搜索空间。


<details>
  <summary>Details</summary>
Motivation: 线性纠错码是现代数字通信和存储系统的数学基础，但识别最优线性码（达到或超过已知最佳最小汉明距离的码）仍然具有挑战性。需要开发更有效的方法来发现这些最优码。

Method: 训练Transformer模型预测一类线性码的最小汉明距离，然后将其与遗传算法配对，在搜索空间中进行优化搜索。这种方法结合了深度学习和进化算法。

Result: 该方法有效减少了发现最优线性码所需的搜索空间，能够应用于广义环面码、Reed-Muller码、Bose-Chaudhuri-Hocquenghem码、代数几何码以及潜在的量子码等多种码型的研究和构造。

Conclusion: Transformer与遗传算法结合的方法为发现最优线性码提供了新颖有效的途径，在纠错码研究和构造中具有广泛应用前景。

Abstract: Linear error-correcting codes form the mathematical backbone of modern digital communication and storage systems, but identifying champion linear codes (linear codes achieving or exceeding the best known minimum Hamming distance) remains challenging. By training a transformer to predict the minimum Hamming distance of a class of linear codes and pairing it with a genetic algorithm over the search space, we develop a novel method for discovering champion codes. This model effectively reduces the search space of linear codes needed to achieve champion codes. Our results present the use of this method in the study and construction of error-correcting codes, applicable to codes such as generalised toric, Reed-Muller, Bose-Chaudhuri-Hocquenghem, algebrogeometric, and potentially quantum codes.

</details>


### [31] [Two Families of Linear Codes Containing Non-GRS MDS Codes](https://arxiv.org/abs/2512.13429)
*Kanat Abdukhalikov,Gyanendra K. Verma*

Main category: cs.IT

TL;DR: 通过修改广义Reed-Solomon码的生成矩阵构造了两类新的线性码，研究了它们的MDS性质、非GRS特性以及自正交和自对偶性质。


<details>
  <summary>Details</summary>
Motivation: 在广义Reed-Solomon码的基础上构造新的线性码，探索具有MDS性质但非GRS的码类，并研究它们的代数特性。

Method: 通过修改GRS码的生成矩阵构造两类新的线性码，推导其校验矩阵，建立MDS性质的充要条件，分析自正交和自对偶性质。

Result: 成功构造了两类新的线性码族，给出了明确的校验矩阵，建立了MDS性质的判别条件，发现了非GRS的MDS子族，并刻画了自正交和自对偶性质。

Conclusion: 该工作扩展了线性码的构造方法，提供了新的MDS码类，特别是非GRS的MDS码，为编码理论提供了新的工具和实例。

Abstract: We construct two new families of linear codes by modifying the generator matrices of generalized Reed-Solomon (GRS) codes. For these codes, we explicitly derive parity-check matrices and establish necessary and sufficient conditions ensuring the MDS property. Additionally, we explore subfamilies within these constructions that are non-GRS MDS codes. We also characterize their self-orthogonal and self-dual properties and present some explicit constructions and examples.

</details>


### [32] [From Zipf's Law to Neural Scaling through Heaps' Law and Hilberg's Hypothesis](https://arxiv.org/abs/2512.13491)
*Łukasz Dębowski*

Main category: cs.IT

TL;DR: 论文证明了在特定假设下，神经缩放定律可以从Zipf定律推导出来，通过Heap定律和Hilberg假设作为中间步骤。


<details>
  <summary>Details</summary>
Motivation: 研究神经缩放定律（描述基础模型交叉熵率随训练数据、参数和计算量的变化）与Zipf定律（描述词元分布的幂律尾部）之间的演绎关系，建立两者之间的理论联系。

Method: 通过系统推导建立四个统计定律之间的逻辑链条：从Zipf定律推导Heap定律（词汇增长规律），从Heap定律推导Hilberg假设（熵缩放规律），再从Hilberg假设推导神经缩放定律。使用Santa Fe过程作为满足所有四个定律的玩具示例进行说明。

Result: 证明了在特定广泛假设下，神经缩放定律是Zipf定律的必然结果，建立了这两个机器学习与定量语言学中重要定律之间的理论联系。

Conclusion: 神经缩放定律与Zipf定律之间存在深刻的演绎关系，揭示了语言统计规律与机器学习模型性能缩放之间的内在联系，为理解基础模型的缩放行为提供了理论基础。

Abstract: We inspect the deductive connection between the neural scaling law and Zipf's law -- two statements discussed in machine learning and quantitative linguistics. The neural scaling law describes how the cross entropy rate of a foundation model -- such as a large language model -- changes with respect to the amount of training tokens, parameters, and compute. By contrast, Zipf's law posits that the distribution of tokens exhibits a power law tail. Whereas similar claims have been made in more specific settings, we show that the neural scaling law is a consequence of Zipf's law under certain broad assumptions that we reveal systematically. The derivation steps are as follows: We derive Heaps' law on the vocabulary growth from Zipf's law, Hilberg's hypothesis on the entropy scaling from Heaps' law, and the neural scaling from Hilberg's hypothesis. We illustrate these inference steps by a toy example of the Santa Fe process that satisfies all the four statistical laws.

</details>


### [33] [Hyper-Minrank: A Unified Hypergraph Characterization of Multi-Sender Index Coding](https://arxiv.org/abs/2512.13615)
*Ali Khalesi,Petros Elia*

Main category: cs.IT

TL;DR: 本文提出了一种超图公式，将经典的Bar-Yossef等人范式推广到多发送者索引编码(MSIC)设置，建立了紧致的可达性-逆等价关系，并提供了超图版本的Haemers型界限。


<details>
  <summary>Details</summary>
Motivation: 现有索引编码研究主要关注单发送者场景，而实际通信系统如多发送者缓存辅助通信、编码计算、分布式存储和边缘/卫星系统等都需要多发送者索引编码理论。需要建立能够捕捉多发送者信号抵消和边信息的统一框架。

Method: 引入4-正则边信息超图G、新的邻接表示A_G = [A_1 ... A_N]，以及子超图有效性的简单拟合准则。该公式包含专门设计的超边来捕捉边信息和跨发送者信号抵消。

Result: 建立了N发送者、K接收者问题的紧致可达性-逆等价关系：每个有效拟合诱导一个有效的线性多发送者索引码，每个线性码诱导一个有效拟合，最优标量线性广播长度等于超最小秩l**lin(G) = hyperminrank(G)。提供了计算hyperminrank(G)的精确算法，在某些情况下复杂度优于近似LT-CMAR解。

Conclusion: 该框架统一了嵌入式索引编码等已知设置，可直接应用于多发送者缓存辅助通信、编码计算、分布式存储和边缘/卫星系统，其中hyperminrank可作为统一设计目标。

Abstract: This work introduces a hypergraph formulation that generalizes the classical paradigm of Bar-Yossef et al. to the multi-sender index coding (MSIC) setting. Central to the model is a 4-regular side-information hypergraph G, a new adjacency representation A_G = [A_1 ... A_N], and a simple fitting criterion for sub-hypergraph validity, in the presence of specially designed hyperedges that capture both side information and cross-sender signal cancellation. This formulation establishes a tight achievability-converse equivalence for the general N-sender, K-receiver problem: every valid fitting induces a valid linear multi-sender index code, every linear code induces a valid fitting, and the optimal scalar linear broadcast length equals the hyper-minrank l**lin(G) = hyperminrank(G) = min*{A fits G} sum_{n=1}^N rank(A_n). Beyond this exact characterization, the approach yields hypergraph analogues of Haemers-type bounds on the broadcast length, including a clique-cover upper bound and a lower bound via the clique number of a carefully defined complement hypergraph. Algorithmically, we provide an exact procedure to compute hyperminrank(G), and show that in certain regimes its complexity is asymptotically better than approximate LT-CMAR solutions. The framework captures well-known settings such as embedded index coding, and applies directly to multi-sender cache-aided communications, coded computation, distributed storage, and edge/satellite systems, where hyperminrank can serve as a unified design target.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [34] [Optimal non-adaptive algorithm for edge estimation](https://arxiv.org/abs/2512.11994)
*Arijit Bishnu,Debarshi Chanda,Buddha Dev Das,Arijit Ghosh,Gopinath Mishra*

Main category: cs.DS

TL;DR: 提出一种简单的非自适应随机算法，仅使用度查询和随机边查询来估计简单无向图中边的数量，查询复杂度为$\widetilde{O}(\sqrt{n})$，并证明了匹配的下界。


<details>
  <summary>Details</summary>
Motivation: 在仅能进行度查询和随机边查询的限制下，如何高效估计图中边的总数是一个重要问题。传统方法可能需要更多查询或更复杂的算法，本文旨在设计简单高效的算法并确定最优查询复杂度。

Method: 提出非自适应随机算法：独立采样一组顶点并查询其度数，同时独立采样一组边，利用这些查询结果估计图中总边数。算法简单且查询复杂度为$\widetilde{O}(\sqrt{n})$。

Result: 算法仅需$\widetilde{O}(\sqrt{n})$次查询即可估计边数，并证明了匹配的下界，确立了该问题在度查询和随机边查询下的最优非自适应查询复杂度。

Conclusion: 本文解决了在度查询和随机边查询模型下估计图中边数的问题，提出了简单高效的算法并证明了其最优性，为该问题的查询复杂度提供了完整答案。

Abstract: We present a simple nonadaptive randomized algorithm that estimates the number of edges in a simple, unweighted, undirected graph, possibly containing isolated vertices, using only degree and random edge queries. For an $n$-vertex graph, our method requires only $\widetilde{O}(\sqrt{n})$ queries, achieving sublinear query complexity. The algorithm independently samples a set of vertices and queries their degrees, and also independently samples a set of edges, using the answers to these queries to estimate the total number of edges in the graph. We further prove a matching lower bound, establishing the optimality of our algorithm and resolving the non-adaptive query complexity of this problem with respect to degree and random-edge queries.

</details>


### [35] [Load Balancing with Duration Predictions](https://arxiv.org/abs/2512.12202)
*Yossi Azar,Niv Buchbinder,Tomer Epshtein*

Main category: cs.DS

TL;DR: 研究带预测的动态负载均衡问题，填补了完全已知和完全未知作业时长之间的空白，设计了对预测准确性敏感的算法并证明了相应下界


<details>
  <summary>Details</summary>
Motivation: 传统动态负载均衡研究要么假设作业时长完全已知（clairvoyant），要么完全未知，但现实情况通常介于两者之间——算法可以获得作业时长的估计或预测。现有算法要么需要完全准确信息，要么在完全未知时性能很差，需要研究如何利用不完美的预测信息来提升性能。

Method: 研究带预测的动态负载均衡模型，算法可以获得作业时长的预测信息。设计新的算法，其性能平滑地依赖于预测的准确性，而不是简单地将预测直接应用于传统clairvoyant算法。同时证明使用这种不准确预测的算法的竞争性下界。

Result: 发现直接将预测应用于传统clairvoyant算法会导致性能显著下降。设计了更好的算法，其性能随预测准确性平滑变化。证明了使用不准确预测的算法的竞争性下界，填补了完全已知和完全未知设置之间的空白。

Conclusion: 通过引入预测模型，在完全已知和完全未知的负载均衡设置之间建立了桥梁。设计的算法能够有效利用不完美的预测信息，性能随预测准确性平滑变化，为现实场景中的动态负载均衡提供了更实用的解决方案。

Abstract: We study the classic fully dynamic load balancing problem on unrelated machines where jobs arrive and depart over time and the goal is minimizing the maximum load, or more generally the l_p-norm of the load vector. Previous work either studied the clairvoyant setting in which exact durations are known to the algorithm, or the unknown duration setting in which no information on the duration is given to the algorithm. For the clairvoyant setting algorithms with polylogarithmic competitive ratios were designed, while for the unknown duration setting strong lower bounds exist and only polynomial competitive factors are possible.
  We bridge this gap by studying a more realistic model in which some estimate/prediction of the duration is available to the algorithm. We observe that directly incorporating predictions into classical load balancing algorithms designed for the clairvoyant setting can lead to a notable decline in performance. We design better algorithms whose performance depends smoothly on the accuracy of the available prediction. We also prove lower bounds on the competitiveness of algorithms that use such inaccurate predictions.

</details>


### [36] [Learning with Structure: Computing Consistent Subsets on Structurally-Regular Graphs](https://arxiv.org/abs/2512.12860)
*Aritra Banik,Mano Prakash Parthasarathi,Venkatesh Raman,Diya Roy,Abhishek Sahu*

Main category: cs.DS

TL;DR: 论文研究了图上的最小一致子集问题，针对顶点覆盖数和邻域多样性两个参数提出了固定参数可处理算法。


<details>
  <summary>Details</summary>
Motivation: 最小一致子集问题在监督聚类和实例选择中自然出现，但现代应用中大量训练数据带来了计算挑战。虽然已有研究将该问题扩展到图度量空间，但在简单图类上仍是NP难问题，需要寻找在顶点数和颜色数上都高效的算法。

Method: 针对两个图结构参数：顶点覆盖数(vc)和邻域多样性(nd)，设计了参数化算法。算法运行时间分别为vc^O(vc)·Poly(n,c)和nd^O(nd)·Poly(n,c)，在参数化复杂度框架下是固定参数可处理的。

Result: 证明了最小一致子集问题在顶点覆盖数和邻域多样性参数下是固定参数可处理的，算法对颜色数量具有多项式依赖关系，即使颜色数量任意多也能保持高效。

Conclusion: 通过利用图的结构参数，成功解决了最小一致子集问题的计算复杂性挑战，为监督聚类和实例选择提供了实用的高效算法。

Abstract: The Minimum Consistent Subset (MCS) problem arises naturally in the context of supervised clustering and instance selection. In supervised clustering, one aims to infer a meaningful partitioning of data using a small labeled subset. However, the sheer volume of training data in modern applications poses a significant computational challenge. The MCS problem formalizes this goal: given a labeled dataset $\mathcal{X}$ in a metric space, the task is to compute a smallest subset $S \subseteq \mathcal{X}$ such that every point in $\mathcal{X}$ shares its label with at least one of its nearest neighbors in $S$.
  Recently, the MCS problem has been extended to graph metrics, where distances are defined by shortest paths. Prior work has shown that MCS remains NP-hard even on simple graph classes like trees, though an algorithm with runtime $\mathcal{O}(2^{6c} \cdot n^6)$ is known for trees, where $c$ is the number of colors and $n$ the number of vertices. This raises the challenge of identifying graph classes that admit algorithms efficient in both $n$ and $c$.
  In this work, we study the Minimum Consistent Subset problem on graphs, focusing on two well-established measures: the vertex cover number ($vc$) and the neighborhood diversity ($nd$). We develop an algorithm with running time $vc^{\mathcal{O}(vc)}\cdot\text{Poly}(n,c)$, and another algorithm with runtime $nd^{\mathcal{O}(nd)}\cdot\text{Poly}(n,c)$. In the language of parameterized complexity, this implies that MCS is fixed-parameter tractable (FPT) parameterized by the vertex cover number and the neighborhood diversity. Notably, our algorithms remain efficient for arbitrarily many colors, as their complexity is polynomially dependent on the number of colors.

</details>


### [37] [Sub-$n^k$ Deterministic algorithm for minimum $k$-way cut in simple graphs](https://arxiv.org/abs/2512.12900)
*Mohit Daga*

Main category: cs.DS

TL;DR: 提出了一种确定性精确算法解决简单图上的最小k割问题，结合主序列划分和Kawarabayashi-Thorup收缩技术，在特定条件下获得确定性亚n^k时间算法。


<details>
  <summary>Details</summary>
Motivation: 最小k割问题是图论中的经典问题，现有算法多为随机化算法或时间复杂度较高。本文旨在开发确定性精确算法，改进现有结果的时间复杂度。

Method: 结合主序列划分和Kawarabayashi-Thorup收缩技术，通过结构分解定理将最优k割表示为边界和内部割的组合，构建规范边界族进行分支搜索。

Result: 获得了时间复杂度为Õ(poly(m)+(n/λ_j+n^{ω/3})^R)的确定性算法，当λ_j ≥ n^ε时，得到确定性亚n^k时间算法n^{(1-ε)(k-1)+o(k)}。

Conclusion: 提出的PSP×KT框架结合小λ精确子程序，为最小k割问题提供了确定性算法，时间复杂度与随机化算法相当，改进了确定性算法的性能。

Abstract: We present a \emph{deterministic exact algorithm} for the \emph{minimum $k$-cut problem} on simple graphs.
  Our approach combines the \emph{principal sequence of partitions (PSP)}, derived canonically from ideal loads, with a single level of \emph{Kawarabayashi--Thorup (KT)} contractions at the critical PSP threshold~$λ_j$.
  Let $j$ be the smallest index with $κ(P_j)\ge k$ and $R := k - κ(P_{j-1})$.
  We prove a structural decomposition theorem showing that an optimal $k$-cut can be expressed as the level-$(j\!-\!1)$ boundary $A_{\le j-1}$ together with exactly $(R-r)$ \emph{non-trivial} internal cuts of value at most~$λ_j$ and $r$ \emph{singleton isolations} (``islands'') inside the parts of~$P_{j-1}$.
  At this level, KT contractions yield kernels of total size $\widetilde{O}(n / λ_j)$, and from them we build a \emph{canonical border family}~$\mathcal{B}$ of the same order that deterministically covers all optimal refinement choices.
  Branching only over~$\mathcal{B}$ (and also including an explicit ``island'' branch) gives total running time
  $$
  T(n,m,k) = \widetilde{O}\left(\mathrm{poly}(m)+\Bigl(\tfrac{n}{λ_j}+n^{ω/3}\Bigr)^{R}\right),
  $$
  where $ω< 2.373$ is the matrix multiplication exponent.
  In particular, if $λ_j \ge n^{\varepsilon}$ for some constant $\varepsilon > 0$, we obtain a \emph{deterministic sub-$n^k$-time algorithm}, running in $n^{(1-\varepsilon)(k-1)+o(k)}$ time.
  Finally, combining our PSP$\times$KT framework with a small-$λ$ exact subroutine via a simple meta-reduction yields a deterministic $n^{c k+O(1)}$ algorithm for $c = \max\{ t/(t+1), ω/3 \} < 1$, aligning with the exponent in the randomized bound of He--Li (STOC~2022) under the assumed subroutine.

</details>


### [38] [Deterministic and Exact Fully-dynamic Minimum Cut of Superpolylogarithmic Size in Subpolynomial Time](https://arxiv.org/abs/2512.13105)
*Antoine El-Hayek,Monika Henzinger,Jason Li*

Main category: cs.DS

TL;DR: 提出首个确定性局部最小割算法，实现完全动态最小割的确定性更新时间为n^{o(1)}，当最小割规模不超过2^{Θ(log^{3/4-c}n)}时，改进了之前的工作。


<details>
  <summary>Details</summary>
Motivation: 现有完全动态最小割算法在最小割规模较大时存在限制，需要开发更高效的确定性算法来处理更大规模的最小割问题。

Method: 提出确定性局部最小割算法，替代之前工作中的随机化LocalKCut过程，结合图稀疏化技术。

Result: 当最小割规模不超过2^{Θ(log^{3/4-c}n)}时，获得确定性更新时间为n^{o(1)}的完全动态最小割算法；在加权图上获得首个(1+ε)-近似完全动态最小割算法。

Conclusion: 通过确定性局部最小割算法显著提高了完全动态最小割算法的性能，突破了先前算法在最小割规模上的限制。

Abstract: We present an exact fully-dynamic minimum cut algorithm that runs in $n^{o(1)}$ deterministic update time when the minimum cut size is at most $2^{Θ(\log^{3/4-c}n)}$ for any $c>0$, improving on the previous algorithm of Jin, Sun, and Thorup (SODA 2024) whose minimum cut size limit is $(\log n)^{o(1)}$. Combined with graph sparsification, we obtain the first $(1+ε)$-approximate fully-dynamic minimum cut algorithm on weighted graphs, for any $ε\ge2^{-Θ(\log^{3/4-c}n)}$, in $n^{o(1)}$ randomized update time.
  Our main technical contribution is a deterministic local minimum cut algorithm, which replaces the randomized LocalKCut procedure from El-Hayek, Henzinger, and Li (SODA 2025).

</details>


### [39] [Kernelization dichotomies for hitting minors under structural parameterizations](https://arxiv.org/abs/2512.13210)
*Marin Bougeret,Eric Brandwein,Ignasi Sau*

Main category: cs.DS

TL;DR: 该论文研究了F-MINOR-DELETION问题的核复杂性，将基于解大小的多项式核提升到基于到有界消除距离图的顶点删除距离的参数化核，得到了包含平面图的F族的精确多项式核和平面顶点删除的近似核。


<details>
  <summary>Details</summary>
Motivation: 研究F-MINOR-DELETION问题的核复杂性，扩展先前仅针对特定情况（如顶点覆盖和反馈顶点集）的结果，为更广泛的图族建立统一的核复杂性理论框架。

Method: 基于Jansen和Pieterse的技术，结合Jansen、de Kroon和Wlodarczyk的结果的改编，将基于解大小的核提升到基于到有界消除距离图的顶点删除距离的参数化核。

Result: 得到了包含平面图的每个F族的精确多项式核和平面顶点删除的近似多项式核，建立了无限组二分定理，为仙人掌顶点删除、外平面顶点删除和树宽-t顶点删除等问题提供了核复杂性分类。

Conclusion: 该研究为F-MINOR-DELETION问题建立了统一的核复杂性理论，将先前仅针对特定情况的结果扩展到更广泛的图族，为参数化复杂性理论提供了重要的理论进展。

Abstract: For a finite collection of connected graphs $\mathcal{F}$, the $\mathcal{F}$-MINOR-DELETION problem consists in, given a graph $G$ and an integer $\ell$, deciding whether $G$ contains a vertex set of size at most $\ell$ whose removal results in an $\mathcal{F}$-minor-free graph. We lift the existence of (approximate) polynomial kernels for $\mathcal{F}$-MINOR-DELETION by the solution size to (approximate) polynomial kernels parameterized by the vertex-deletion distance to graphs of bounded elimination distance to $\mathcal{F}$-minor-free graphs. This results in exact polynomial kernels for every family $\mathcal{F}$ that contains a planar graph, and an approximate polynomial kernel for PLANAR VERTEX DELETION. Moreover, combining our result with a previous lower bound, we obtain the following infinite set of dichotomies, assuming $NP \not\subseteq coNP/poly$: for any finite set $\mathcal{F}$ of biconnected graphs on at least three vertices containing a planar graph, and any minor-closed class of graphs $\mathcal{C}$, $\mathcal{F}$-MINOR-DELETION admits a polynomial kernel parameterized by the vertex-deletion distance to $\mathcal{C}$ if and only if $\mathcal{C}$ has bounded elimination distance to $\mathcal{F}$-minor-free graphs. For instance, this yields dichotomies for CACTUS VERTEX DELETION, OUTERPLANAR VERTEX DELETION, and TREEWIDTH-$t$ VERTEX DELETION for every integer $t \geq 0$. Prior to our work, such dichotomies were only known for the particular cases of VERTEX COVER and FEEDBACK VERTEX SET. Our approach builds on the techniques developed by Jansen and Pieterse [Theor. Comput. Sci. 2020] and also uses adaptations of some of the results by Jansen, de Kroon, and Wlodarczyk [STOC 2021].

</details>


### [40] [Space Efficient Algorithms for Parameterised Problems](https://arxiv.org/abs/2512.13342)
*Sheikh Shakil Akhtar,Pranabendu Misra,Geevarghese Philip*

Main category: cs.DS

TL;DR: 研究空间高效的FPT算法，针对图问题在有限内存下运行，使用f(k)*poly(n)时间和g(k)*polylog(n)工作空间


<details>
  <summary>Details</summary>
Motivation: 针对大数据场景中需要处理超大规模问题实例的情况，使用poly(n)内存成本过高；同时理论上有趣，因为标准方法（如删除大量顶点/边）不可用

Method: 开发新的算法方法，在时间f(k)*poly(n)和工作空间g(k)*polylog(n)内解决k-Path、MaxLeaf SubTree和Multicut in Trees问题

Result: 为k-Path、MaxLeaf SubTree和Multicut in Trees问题提供了空间高效的FPT算法

Conclusion: 在有限内存环境下成功开发了空间高效的FPT算法，解决了大数据场景中的实际需求，并为图问题的空间受限计算提供了新的理论方法

Abstract: We study "space efficient" FPT algorithms for graph problems with limited memory. Let n be the size of the input graph and k be the parameter. We present algorithms that run in time f(k)*poly(n) and use g(k)*polylog(n) working space, where f and g are functions of k alone, for k-Path, MaxLeaf SubTree and Multicut in Trees. These algorithms are motivated by big-data settings where very large problem instances must be solved, and using poly(n) memory is prohibitively expensive. They are also theoretically interesting, since most of the standard methods tools, such as deleting a large set of vertices or edges, are unavailable, and we must a develop different way to tackle them.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [41] [Differentially Private Online Distributed Aggregative Games With Time-Varying and Non-Identical Communication and Feedback Delays](https://arxiv.org/abs/2512.12344)
*Olusola Odeyomi,Tokunbo Ogunfunmi,Adjovi Laba*

Main category: cs.GT

TL;DR: 提出一种在线分布式双平均算法，解决具有时变成本函数的聚合博弈中的隐私泄露、时变非一致通信延迟和反馈延迟问题


<details>
  <summary>Details</summary>
Motivation: 在分布式非合作聚合博弈中，存在两个主要挑战：1) 好奇的代理可能窃取邻居的敏感信息；2) 网络拥塞导致的通信延迟和反馈延迟会阻碍纳什均衡收敛。现有研究假设延迟固定且一致，但实际中延迟是时变且非一致的，这一问题从未被考虑过

Method: 提出在线分布式双平均算法，同时处理隐私泄露、时变非一致通信延迟和反馈延迟问题。算法通过分布式方式保护隐私，并适应时变非一致的延迟环境

Result: 算法实现了可证明的低遗憾界限，仿真结果显示每个客户端本地行动的时间平均值随时间收敛

Conclusion: 首次解决了聚合博弈中隐私泄露与时变非一致通信/反馈延迟的联合挑战，提出的算法有效且收敛

Abstract: This paper investigates online distributed aggregative games with time-varying cost functions, where agents are interconnected through an unbalanced communication graph. Due to the distributed and noncooperative nature of the game, some curious agents may wish to steal sensitive information from neighboring agents during parameter exchanges. Additionally, communication delays arising from network congestion, particularly in wireless settings, as well as feedback delays, can hinder the convergence of agents to a Nash equilibrium. Although a recent work addressed both communication and feedback delays in aggregative games, it is based on the unrealistic assumption that the delays are fixed over time and identical across agents. Hence, the case of time-varying and non-identical delays across agents has never been considered in aggregative games. In this work, we address the combined challenges of privacy leakage with time-varying and non-identical communication and feedback delays for the first time. We propose an online distributed dual averaging algorithm that simultaneously tackles these challenges while achieving a provably low regret bound. Our simulation result shows that the running average of each client's local action converges over time.

</details>


### [42] [Simultaneous AlphaZero: Extending Tree Search to Markov Games](https://arxiv.org/abs/2512.12486)
*Tyler Becker,Zachary Sunberg*

Main category: cs.GT

TL;DR: Simultaneous AlphaZero扩展AlphaZero框架，用于处理具有同时动作的多步两人零和确定性马尔可夫博弈，通过矩阵博弈解决联合动作选择，并采用遗憾最优求解器处理赌博机反馈的不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有的AlphaZero框架主要处理顺序动作的博弈，而许多现实世界场景涉及同时动作的交互。需要扩展框架来处理具有同时动作的多步两人零和确定性马尔可夫博弈，特别是在存在赌博机反馈不确定性的情况下。

Method: 1. 将联合动作选择建模为矩阵博弈，其收益包含即时奖励和未来价值估计；2. 在蒙特卡洛树搜索中，采用遗憾最优求解器处理赌博机反馈下的矩阵博弈；3. 在连续状态离散动作的追逃博弈和卫星监护维护场景中验证方法。

Result: Simultaneous AlphaZero在连续状态离散动作的追逃博弈和卫星监护维护场景中展现出稳健策略，即使面对最大程度利用对手也能保持良好性能。

Conclusion: Simultaneous AlphaZero成功扩展了AlphaZero框架到同时动作博弈领域，通过矩阵博弈建模和遗憾最优求解器处理赌博机反馈，为复杂多智能体交互场景提供了有效的解决方案。

Abstract: Simultaneous AlphaZero extends the AlphaZero framework to multistep, two-player zero-sum deterministic Markov games with simultaneous actions. At each decision point, joint action selection is resolved via matrix games whose payoffs incorporate both immediate rewards and future value estimates. To handle uncertainty arising from bandit feedback during Monte Carlo Tree Search (MCTS), Simultaneous AlphaZero incorporates a regret-optimal solver for matrix games with bandit feedback. Simultaneous AlphaZero demonstrates robust strategies in a continuous-state discrete-action pursuit-evasion game and satellite custody maintenance scenarios, even when evaluated against maximally exploitative opponents.

</details>


### [43] [Generative AI as Digital Representatives in Collective Decision-Making: A Game-Theoretical Approach](https://arxiv.org/abs/2512.12582)
*Kexin Chen,Jianwei Huang,Yuan Luo*

Main category: cs.GT

TL;DR: 研究团队决策中成员如何战略性地向生成式AI透露个人信息，以平衡团队偏好与沟通成本，发现偏好冲突会驱动竞争性信息透露。


<details>
  <summary>Details</summary>
Motivation: 生成式AI作为数字代表参与团队决策时，需要准确代表成员偏好，但获取完整个人信息不现实。需要解决成员如何战略性地透露信息给AI的问题。

Method: 建立博弈论框架，建模成员在集体决策中向生成式AI战略透露信息的行为，分析均衡策略和AI不完美学习偏好结果。

Result: 获得闭式均衡解，发现偏好冲突驱动竞争性信息透露；数字代表产生的总体偏好损失不小于直接参与，但个体成员可能获得更符合自己偏好的决策。

Conclusion: 成员会战略平衡团队偏好与沟通成本；偏好冲突导致更多信息透露；数字代表在特定条件下（高参与成本或AI先进）可能让个体获得更好结果。

Abstract: Generative Artificial Intelligence (GenAI) enables digital representatives to make decisions on behalf of team members in collaborative tasks, but faces challenges in accurately representing preferences. While supplying GenAI with detailed personal information improves representation fidelity, feasibility constraints make complete information access impractical. We bridge this gap by developing a game-theoretic framework that models strategic information revelation to GenAI in collective decision-making. The technical challenges lie in characterizing members' equilibrium behaviors under interdependent strategies and quantifying the imperfect preference learning outcomes by digital representatives. Our contribution includes closed-form equilibrium characterizations that reveal how members strategically balance team decision preference against communication costs. Our analysis yields an interesting finding: Conflicting preferences between team members drive competitive information revelation, with members revealing more information than those with aligned preferences. While digital representatives produce aggregate preference losses no smaller than direct participation, individual members may paradoxically achieve decisions more closely aligned with their preferences when using digital representatives, particularly when manual participation costs are high or when GenAI systems are sufficiently advanced.

</details>


### [44] [A Direct Second-Order Method for Solving Two-Player Zero-Sum Games](https://arxiv.org/abs/2512.12910)
*David Yang,Yuan Gao,Tianyi Lin,Christian Kroer*

Main category: cs.GT

TL;DR: 提出首个用于计算双人零和博弈纳什均衡的直接二阶方法，结合半光滑牛顿法与预测遗憾匹配+，实现局部超线性收敛和全局效率保证


<details>
  <summary>Details</summary>
Motivation: 现有方法在计算双人零和博弈纳什均衡时存在效率限制，需要开发既能保证全局收敛又能实现局部快速收敛的算法

Method: 构建Douglas-Rachford风格的分裂公式，采用半光滑牛顿法求解；开发混合算法，结合预测遗憾匹配+的全局收敛性和半光滑牛顿法的局部超线性收敛

Result: 算法实现局部超线性收敛；混合算法在高精度解上比预测遗憾匹配+快一个数量级；矩阵游戏数值实验验证了性能优势

Conclusion: 提出的混合二阶方法在双人零和博弈纳什均衡计算中实现了局部快速收敛和全局效率的平衡，显著提升了求解速度

Abstract: We introduce, to our knowledge, the first direct second-order method for computing Nash equilibria in two-player zero-sum games. To do so, we construct a Douglas-Rachford-style splitting formulation, which we then solve with a semi-smooth Newton (SSN) method. We show that our algorithm enjoys local superlinear convergence. In order to augment the fast local behavior of our SSN method with global efficiency guarantees, we develop a hybrid method that combines our SSN method with the state-of-the-art first-order method for game solving, Predictive Regret Matching$^+$ (PRM$^+$). Our hybrid algorithm leverages the global progress provided by PRM$^+$, while achieving a local superlinear convergence rate once it switches to SSN near a Nash equilibrium. Numerical experiments on matrix games demonstrate order-of-magnitude speedups over PRM$^+$ for high-precision solutions.

</details>


### [45] [Fair Coordination in Strategic Scheduling](https://arxiv.org/abs/2512.13244)
*Wei-Chen Lee,Martin Bullinger,Alessandro Abate,Michael Wooldridge*

Main category: cs.GT

TL;DR: 研究战略代理调度问题，关注公平性而非传统完工时间最小化，分析可信性、平等性和嫉妒自由等公平属性及其组合的计算复杂性


<details>
  <summary>Details</summary>
Motivation: 传统调度研究主要关注完工时间最小化，但本文考虑战略代理（代表不同权重的作业）的公平性。代理需要选择相同的机器处理作业，希望结果在战略考虑下保持公平

Method: 提出可信性（确保分配是纳什均衡）和平等性（要求等权重作业分配到等负载机器）两个自然属性。结合基于嫉妒自由的公平性层次结构，以及基于"对高权重代理嫉妒更合理"思想的松弛版本。开发统一算法框架，通过微调关键子程序实现不同属性

Result: 建立了这些属性单独或组合时的可满足性和决策版本的完整复杂性图景。研究了在完工时间优化下的结构约束。正结果通过统一算法方法实现

Conclusion: 该研究为战略代理调度中的公平性提供了系统分析框架，揭示了不同公平属性之间的计算复杂性关系，并为实现这些属性提供了统一的算法方法

Abstract: We consider a scheduling problem of strategic agents representing jobs of different weights. Each agent has to decide on one of a finite set of identical machines to get their job processed. In contrast to the common and exclusive focus on makespan minimization, we want the outcome to be fair under strategic considerations of the agents. Two natural properties are credibility, which ensures that the assignment is a Nash equilibrium and equality, requiring that agents with equal-weight jobs are assigned to machines of equal load. We combine these two with a hierarchy of fairness properties based on envy-freeness together with several relaxations based on the idea that envy seems more justified towards agents with a higher weight. We present a complete complexity landscape for satisfiability and decision versions of these properties, alone or in combination, and study them as structural constraints under makespan optimization. For our positive results, we develop a unified algorithmic approach, where we achieve different properties by fine-tuning key subroutines.

</details>


### [46] [Distributed Places and Safe Net Reduction](https://arxiv.org/abs/2512.13538)
*Victor Khomenko,Maciej Koutny,Alex Yakovlev*

Main category: cs.GT

TL;DR: 该论文提出了一种基于分布式位置的新概念，用于减少安全Petri网的规模而不改变其行为，并将该技术应用于具有迭代行为的进程表达式，实现了从指数级到多项式级的优化。


<details>
  <summary>Details</summary>
Motivation: 并发系统的形式化规范通常会产生大型Petri网，这给验证和实现带来挑战。虽然之前的研究已经解决了无循环行为的情况，但对于包含迭代的进程表达式，仍然需要有效的简化方法。

Method: 提出分布式位置的概念，将单个网位置的行为分布实现。如果分布式位置覆盖了安全Petri网，就可以静态且局部地删除某些位置而不改变行为。将该技术应用于从进程表达式组合推导出的安全Petri网代数（boxes）。

Result: 对于包含迭代的进程表达式，使用分布式位置技术能够将原本指数级数量的位置减少到多项式级（二次），与之前无循环行为情况下的优化效果类似。

Conclusion: 分布式位置技术为安全Petri网的简化提供了有效方法，特别适用于具有迭代行为的组合系统，显著提高了验证和实现的可行性。

Abstract: Being able to find small Petri nets with the same behaviour as formal specifications of concurrent systems benefits both effective verification and practical implementation of such systems. This paper considers specifications given in the form of compositionally defined safe nets.
  The paper discusses a novel concept of distributed place which implements the behaviour of an individual net place. It is shown that if distributed places cover a safe Petri net, then it is possible to delete some places without changing the behaviour. Crucially, the reduction is both static and local, making it computationally feasible in practice.
  The resulting reduction technique is then applied to an algebra of safe Petri nets (boxes) derived compositionally from process (box) expressions. Though the original derivation can yield exponentially large boxes, prior research demonstrated that if a box expression does not involve cyclic behaviours, the exponential number of places can be reduced down to polynomial (quadratic). In this paper, using distributed places, it is show that similar optimisation can also be achieved in the case of process expressions with iteration.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [47] [CoLSE: A Lightweight and Robust Hybrid Learned Model for Single-Table Cardinality Estimation using Joint CDF](https://arxiv.org/abs/2512.12624)
*Lankadinee Rathuwadu,Guanli Liu,Christopher Leckie,Renata Borovica-Gajic*

Main category: cs.DB

TL;DR: CoLSE：基于Copula理论和轻量神经网络的混合学习基数估计方法，在准确率、训练时间、推理延迟和模型大小之间取得良好平衡


<details>
  <summary>Details</summary>
Motivation: 现有基数估计方法难以在准确性、效率和内存占用三个关键因素之间取得平衡，需要一种能同时兼顾这些因素的新方法

Method: 提出CoLSE混合学习方法：1）使用基于Copula理论的新算法直接建模查询区间的联合概率；2）集成轻量神经网络来修正残差估计误差

Result: 实验结果显示CoLSE在准确性、训练时间、推理延迟和模型大小之间取得了有利的权衡，优于现有最先进方法

Conclusion: CoLSE通过结合Copula理论和神经网络校正，为单表基数估计提供了一种在多个关键指标上表现均衡的有效解决方案

Abstract: Cardinality estimation (CE), the task of predicting the result size of queries is a critical component of query optimization. Accurate estimates are essential for generating efficient query execution plans. Recently, machine learning techniques have been applied to CE, broadly categorized into query-driven and data-driven approaches. Data-driven methods learn the joint distribution of data, while query-driven methods construct regression models that map query features to cardinalities. Ideally, a CE technique should strike a balance among three key factors: accuracy, efficiency, and memory footprint. However, existing state-of-the-art models often fail to achieve this balance.
  To address this, we propose CoLSE, a hybrid learned approach for single-table cardinality estimation. CoLSE directly models the joint probability over queried intervals using a novel algorithm based on copula theory and integrates a lightweight neural network to correct residual estimation errors. Experimental results show that CoLSE achieves a favorable trade-off among accuracy, training time, inference latency, and model size, outperforming existing state-of-the-art methods.

</details>


### [48] [Database Research needs an Abstract Relational Query Language](https://arxiv.org/abs/2512.12957)
*Wolfgang Gatterbauer,Diandre Miguel Sabale*

Main category: cs.DB

TL;DR: 论文提出抽象关系查询语言(ARQL)作为关系查询的语义优先参考元语言，将查询意图与用户界面语法分离，并引入ARC作为具体实现，支持文本、机器推理和可视化三种模态。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的普及，SQL查询越来越多由机器生成，而人类主要阅读、验证和调试查询。这种转变使关系查询语言成为意图沟通的接口，需要重新思考关系语言设计，特别是需要一种能分离查询意图与语法的抽象语言。

Method: 提出抽象关系查询语言(ARQL)框架，将查询分为三部分：关系核心（决定意图的组合结构）、模态（针对不同受众的核心表示）、约定（解释核心的环境级语义参数）。引入抽象关系演算(ARC)作为ARQL的具体实例，是元组关系演算(TRC)的严格泛化，提供文本、抽象语言树(ALT)和分层图(higraph)三种模态。

Result: ARC作为关系查询的"罗塞塔石碑"，提供了缺失的词汇表，使不同关系查询语言的比较成为可能。它支持机器推理和人类理解，将语言选择问题转化为模态选择问题，使查询意图与语法表示分离。

Conclusion: ARQL框架和ARC实现为关系查询语言设计提供了新的理论基础，特别是在LLM时代，查询生成与验证分离的背景下。这种语义优先的方法使关系模式显式化，支持跨语言比较，并为人类与机器之间的意图沟通提供了更好的接口。

Abstract: For decades, SQL has been the default language for composing queries, but it is increasingly used as an artifact to be read and verified rather than authored. With Large Language Models (LLMs), queries are increasingly machine-generated, while humans read, validate, and debug them. This shift turns relational query languages into interfaces for back-and-forth communication about intent, which will lead to a rethinking of relational language design, and more broadly, relational interface design.
  We argue that this rethinking needs support from an Abstract Relational Query Language (ARQL): a semantics-first reference metalanguage that separates query intent from user-facing syntax and makes underlying relational patterns explicit and comparable across user-facing languages. An ARQL separates a query into (i) a relational core (the compositional structure that determines intent), (ii) modalities (alternative representations of that core tailored to different audiences), and (iii) conventions (orthogonal environment-level semantic parameters under which the core is interpreted, e.g., set vs. bag semantics, or treatment of null values). Usability for humans or machines then depends less on choosing a particular language and more on choosing an appropriate modality. Comparing languages becomes a question of which relational patterns they support and what conventions they choose.
  We introduce Abstract Relational Calculus (ARC), a strict generalization of Tuple Relational Calculus (TRC), as a concrete instance of ARQL. ARC comes in three modalities: (i) a comprehension-style textual notation, (ii) an Abstract Language Tree (ALT) for machine reasoning about meaning, and (iii) a diagrammatic hierarchical graph (higraph) representation for humans. ARC provides the missing vocabulary and acts as a Rosetta Stone for relational querying.

</details>
