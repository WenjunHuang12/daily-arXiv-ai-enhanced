{"id": "2512.15043", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2512.15043", "abs": "https://arxiv.org/abs/2512.15043", "authors": ["Chun Fang", "Luowen Liu", "Kun Huang", "Tao Ruan", "Sheng Yan", "Zhen Wang", "Huan Li", "Qiang Liu", "Xingxing Wang"], "title": "A Joint Auction Framework with Externalities and Adaptation", "comment": null, "summary": "Recently, joint advertising has gained significant attention as an effective approach to enhancing the efficiency and revenue of advertising slot allocation. Unlike traditional advertising, which allocates advertising slots exclusively to a single advertiser, joint advertising displays advertisements from brands and stores that have established a joint selling relationship within the same advertising slot. However, existing approaches often struggle to accommodate both joint and traditional advertising frameworks, thereby limiting the revenue potential and generalizability of joint advertising. Furthermore, these methods are constrained by two critical limitations: they generally neglect the influence of global externalities, and they fail to address the bidding variability stemming from multi-party advertiser participation. Collectively, these limitations present substantial challenges to the design of joint auction mechanisms. To address these challenges, we propose a Joint Auction Framework incorporating Externalities and Adaptation, and leverage the automated mechanism design (AMD) method through our proposed JEANet to compute joint auction mechanisms that satisfy the conditions of individual rationality (IR) and approximate dominant strategy incentive compatibility (DSIC). As the first AMD method to integrate global externalities into joint auctions, JEANet dynamically adapts to the bidding characteristics of multi-party advertiser and enables unified auctions that integrate both joint and traditional advertising. Extensive experimental results demonstrate that JEANet outperforms state-of-the-art baselines in multi-slot joint auctions."}
{"id": "2512.15210", "categories": ["cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15210", "abs": "https://arxiv.org/abs/2512.15210", "authors": ["Ameet Gadekar", "Aristides Gionis", "Thibault Marette"], "title": "Label-consistent clustering for evolving data", "comment": "26 pages", "summary": "Data analysis often involves an iterative process, where solutions must be continuously refined in response to new data. Typically, as new data becomes available, an existing solution must be updated to incorporate the latest information. In addition to seeking a high-quality solution for the task at hand, it is also crucial to ensure consistency by minimizing drastic changes from previous solutions. Applying this approach across many iterations, ensures that the solution evolves gradually and smoothly.\n  In this paper, we study the above problem in the context of clustering, specifically focusing on the $k$-center problem. More precisely, we study the following problem: Given a set of points $X$, parameters $k$ and $b$, and a prior clustering solution $H$ for $X$, our goal is to compute a new solution $C$ for $X$, consisting of $k$ centers, which minimizes the clustering cost while introducing at most $b$ changes from $H$. We refer to this problem as label-consistent $k$-center, and we propose two constant-factor approximation algorithms for it. We complement our theoretical findings with an experimental evaluation demonstrating the effectiveness of our methods on real-world datasets."}
{"id": "2512.15473", "categories": ["cs.DS", "cs.DM"], "pdf": "https://arxiv.org/pdf/2512.15473", "abs": "https://arxiv.org/abs/2512.15473", "authors": ["Jannis Blauth", "Ramin Mousavi"], "title": "A Constant-Factor Approximation for Directed Latency", "comment": null, "summary": "In the Directed Latency problem, we are given an asymmetric metric on a set of vertices (or clients), and a given depot $s$. We seek a path $P$ starting at $s$ and visiting all the clients so as to minimize the sum of client waiting times (also known as latency) before being visited on the path.\n  In contrast to the symmetric version of this problem (also known as the Deliveryperson problem and the Repairperson problem in the literature), there are significant gaps in our understanding of Directed Latency. The best approximation factor has remained at $O(\\log n)$, where $n$ is the number of clients, for more than a decade [Friggstad, Salavatipour, and Svitkina, '13]. Only recently, [Friggstad and Swamy, '22] presented a constant-factor approximation but in quasi-polynomial time. Both results follow similar ideas: they consider buckets with geometrically-increasing distances, build paths in each bucket, and then stitch together all these paths to get a feasible solution. [Friggstad and Swamy, '22] showed if we guess a vertex from each bucket and augment a standard LP relaxation with these guesses, then one can reduce the stitching cost. Unfortunately, there are logarithmically many buckets so the running time of their algorithm is quasi-polynomial.\n  In this paper, we present the first constant-factor approximation for Directed Latency in polynomial time by introducing a completely new way of bucketing which helps us strengthen a standard LP relaxation with less aggressive guessing. Although the resulting LP is no longer a relaxation of Directed Latency, it still admits a good solution. We present a rounding algorithm for fractional solutions of our LP, crucially exploiting the way we restricted the feasibility region of the LP formulation."}
{"id": "2512.14733", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14733", "abs": "https://arxiv.org/abs/2512.14733", "authors": ["Qiang Chen", "Venkatesh Ganapati Hegde"], "title": "Where to Explore: A Reach and Cost-Aware Approach for Unbiased Data Collection in Recommender Systems", "comment": "IEEE Conference on Cognitive Machine Intelligence Nov. 11-14, 2025, Pittsburgh, PA, USA", "summary": "Exploration is essential to improve long-term recommendation quality, but it often degrades short-term business performance, especially in remote-first TV environments where users engage passively, expect instant relevance, and offer few chances for correction. This paper introduces an approach for delivering content-level exploration safely and efficiently by optimizing its placement based on reach and opportunity cost. Deployed on a large-scale streaming platform with over 100 million monthly active users, our approach identifies scroll-depth regions with lower engagement and strategically introduces a dedicated container, the \"Something Completely Different\" row containing randomized content. Rather than enforcing exploration uniformly across the user interface (UI), we condition its appearance on empirically low-cost, high-reach positions to ensure minimal tradeoff against platform-level watch time goals. Extensive A/B testing shows that this strategy preserves business metrics while collecting unbiased interaction data. Our method complements existing intra-row diversification and bandit-based exploration techniques by introducing a deployable, behaviorally informed mechanism for surfacing exploratory content at scale. Moreover, we demonstrate that the collected unbiased data, integrated into downstream candidate generation, significantly improves user engagement, validating its value for recommender systems."}
{"id": "2512.14776", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.14776", "abs": "https://arxiv.org/abs/2512.14776", "authors": ["Xiangxiang Li", "Haiyan Wang", "Yao Ge", "Xiaohong Shen", "Miaowen Wen", "Shun Zhang", "Yong Liang Guan"], "title": "Low-Complexity Channel Estimation for Internet of Vehicles AFDM Communications With Sparse Bayesian Learning", "comment": null, "summary": "Affine frequency division multiplexing (AFDM) has been considered as a promising waveform to enable high-reliable connectivity in the internet of vehicles. However, accurate channel estimation is critical and challenging to achieve the expected performance of the AFDM systems in doubly-dispersive channels. In this paper, we propose a sparse Bayesian learning (SBL) framework for AFDM systems and develop a dynamic grid update strategy with two off-grid channel estimation methods, i.e., grid-refinement SBL (GR-SBL) and grid-evolution SBL (GE-SBL) estimators. Specifically, the GR-SBL employs a localized grid refinement method and dynamically updates grid for a high-precision estimation. The GE-SBL estimator approximates the off-grid components via first-order linear approximation and enables gradual grid evolution for estimation accuracy enhancement. Furthermore, we develop a distributed computing scheme to decompose the large-dimensional channel estimation model into multiple manageable small-dimensional sub-models for complexity reduction of GR-SBL and GE-SBL, denoted as distributed GR-SBL (D-GR-SBL) and distributed GE-SBL (D-GE-SBL) estimators, which also support parallel processing to reduce the computational latency. Finally, simulation results demonstrate that the proposed channel estimators outperform existing competitive schemes. The GR-SBL estimator achieves high-precision estimation with fine step sizes at the cost of high complexity, while the GE-SBL estimator provides a better trade-off between performance and complexity. The proposed D-GR-SBL and D-GE-SBL estimators effectively reduce complexity and maintain comparable performance to GR-SBL and GE-SBL estimators, respectively."}
{"id": "2512.15331", "categories": ["cs.MM", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.15331", "abs": "https://arxiv.org/abs/2512.15331", "authors": ["Fei Zhao", "Mengxi Guo", "Shijie Zhao", "Junlin Li", "Li Zhang", "Xiaodong Xie"], "title": "A Preprocessing Framework for Video Machine Vision under Compression", "comment": "Accepted as a POSTER and for publication in the DCC 2024 proceedings", "summary": "There has been a growing trend in compressing and transmitting videos from terminals for machine vision tasks. Nevertheless, most video coding optimization method focus on minimizing distortion according to human perceptual metrics, overlooking the heightened demands posed by machine vision systems. In this paper, we propose a video preprocessing framework tailored for machine vision tasks to address this challenge. The proposed method incorporates a neural preprocessor which retaining crucial information for subsequent tasks, resulting in the boosting of rate-accuracy performance. We further introduce a differentiable virtual codec to provide constraints on rate and distortion during the training stage. We directly apply widely used standard codecs for testing. Therefore, our solution can be easily applied to real-world scenarios. We conducted extensive experiments evaluating our compression method on two typical downstream tasks with various backbone networks. The experimental results indicate that our approach can save over 15% of bitrate compared to using only the standard codec anchor version."}
{"id": "2512.14723", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.14723", "abs": "https://arxiv.org/abs/2512.14723", "authors": ["Jens E. d'Hondt", "Teun Kortekaas", "Odysseas Papapetrou", "Themis Palpanas"], "title": "MS-Index: Fast Top-k Subsequence Search for Multivariate Time Series under Euclidean Distance", "comment": "12 pages, to be published in PVLDB Volume 19 Issue 2", "summary": "Modern applications frequently collect and analyze temporal data in the form of multivariate time series (MTS) -- time series that contain multiple channels. A common task in this context is subsequence search, which involves identifying all MTS that contain subsequences highly similar to a query time series. In practical scenarios, not all channels of an MTS are relevant to every query. For instance, airplane sensors may gather data on a plethora of components and subsystems, but only a few of these are relevant to a specific query, such as identifying the cause of a malfunctioning landing gear, or a specific flight maneuver. Consequently, the relevant query channels are often specified at query time. In this work, we introduce the Multivariate Subsequence Index (MS-Index), a novel algorithm for nearest neighbor MTS subsequence search under Euclidean distance that supports ad-hoc selection of query channels. The algorithm is exact and demonstrates query performance that scales sublinearly to the number of query channels. We examine the properties of \\name with a thorough experimental evaluation over 34 datasets, and show that it outperforms the state-of-the-art one to two orders of magnitude for both raw and normalized subsequences."}
{"id": "2512.15372", "categories": ["cs.IR", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.15372", "abs": "https://arxiv.org/abs/2512.15372", "authors": ["Mikel Williams-Lekuona", "Georgina Cosma"], "title": "Image Complexity-Aware Adaptive Retrieval for Efficient Vision-Language Models", "comment": "Accepted paper for ECIR 2026", "summary": "Vision transformers in vision-language models apply uniform computational effort across all images, expending 175.33 GFLOPs (ViT-L/14) whether analysing a straightforward product photograph or a complex street scene. We propose ICAR (Image Complexity-Aware Retrieval), which enables vision transformers to use less compute for simple images whilst processing complex images through their full network depth. The key challenge is maintaining cross-modal alignment: embeddings from different processing depths must remain compatible for text matching. ICAR solves this through dual-path training that produces compatible embeddings from both reduced-compute and full-compute processing. This maintains compatibility between image representations and text embeddings in the same semantic space, whether an image exits early or processes fully. Unlike existing two-stage approaches that require expensive reranking, ICAR enables direct image-text matching without additional overhead. To determine how much compute to use, we develop ConvNeXt-IC, which treats image complexity assessment as a classification task. By applying modern classifier backbones rather than specialised architectures, ConvNeXt-IC achieves state-of-the-art performance with 0.959 correlation with human judgement (Pearson) and 4.4x speedup. Evaluated on standard benchmarks augmented with real-world web data, ICAR achieves 20% practical speedup while maintaining category-level performance and 95% of instance-level performance, enabling sustainable scaling of vision-language systems."}
{"id": "2512.15049", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.15049", "abs": "https://arxiv.org/abs/2512.15049", "authors": ["Kai Huang", "Xinyu Xie", "Chunpeng Chen", "Wenjie Guan", "Xiaoran Wang", "Jinbei Zhang"], "title": "On the Stochastic Analysis of Random Linear Streaming Codes in Multi-Hop Relay Networks", "comment": null, "summary": "In this paper, we aim to explore the stochastic performance limit of large-field-size Random Linear Streaming Codes (RLSCs) in multi-hop relay networks. In our model, a source transmits a sequence of streaming messages to a destination through multiple relays subject to a delay constraint. Most previous research focused on deterministic adversarial channel which introduces only restricted types of erasure patterns, and aimed to design the optimal capacity-achieving codes. In this paper, we focus on stochastic channel where each hop is subject to i.i.d. packet erasures, and carry out stochastic analysis on the error probability of multi-hop RLSCs. Our contributions are three-folds. Firstly, the error event of large-field-size RLSCs is characterized in two-hop relay network with a novel framework, which features quantification of information flowing through each node in the network. Due to the erasures in different hops, some source symbols can be \"detained\" at the source or relay while others have arrived at the destination. By iteratively computing the number of detained symbols at each node, this framework extends the concept \"information debt\" from point-to-point network [Pinwen Su et al. 2022] into two-hop relay networks. Secondly, based on the error event, the expression of average error probability in two-hop network is derived by carefully analyzing the expectation terms. To handle the expectation over all possible erasure patterns along two hops of the network, the transition matrices of the detained symbols are novelly constructed in a \"band fashion\" with nested structure. Thirdly, the derived results in two-hop network are further generalized into relay networks with arbitrary number of hops. Furthermore, simulations are conducted to verify the accuracy of our stochastic analysis, and compare with some existing streaming codes for the adversarial channels."}
{"id": "2512.15630", "categories": ["cs.MM", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.15630", "abs": "https://arxiv.org/abs/2512.15630", "authors": ["Sarah Kaißer", "Markus Kleffmann", "Kristina Schaaff"], "title": "One Size Doesn't Fit All: Age-Aware Gamification Mechanics for Multimedia Learning Environments", "comment": null, "summary": "Gamification is widely used in digital learning. However, most systems neglect age-related differences. This paper investigates how gamification can be designed in an age-aware way to address learners' diverse motivational and cognitive needs. Based on a targeted literature review, we present a mapping of age groups, mechanics, and effects. Furthermore, we derive five design principles for age-specific gamification and identify three technical patterns for implementation in multimedia learning environments. The results indicate that gamification is not universally effective, but rather requires a differentiated design to support engagement and inclusivity across the lifespan."}
{"id": "2512.15157", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.15157", "abs": "https://arxiv.org/abs/2512.15157", "authors": ["Cristina Aguiar", "Jacques Chabin", "Alexandre Chanson", "Mirian Halfeld-Ferrari", "Nicolas Hiot", "Nicolas Labroche", "Patrick Marcel", "Verónika Peralta", "Felipe Vasconcelos"], "title": "Extracting node comparison insights for the interactive exploration of property graphs", "comment": null, "summary": "While scoring nodes in graphs to understand their importance (e.g., in terms of centrality) has been investigated for decades, comparing nodes in property graphs based on their properties has not, to our knowledge, yet been addressed. In this paper, we propose an approach to automatically extract comparison of nodes in property graphs, to support the interactive exploratory analysis of said graphs. We first present a way of devising comparison indicators using the context of nodes to be compared. Then, we formally define the problem of using these indicators to group the nodes so that the comparisons extracted are both significant and not straightforward. We propose various heuristics for solving this problem. Our tests on real property graph databases show that simple heuristics can be used to obtain insights within minutes while slower heuristics are needed to obtain insights of higher quality."}
{"id": "2512.15384", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.15384", "abs": "https://arxiv.org/abs/2512.15384", "authors": ["Gregor Donabauer", "Samy Ateia", "Udo Kruschwitz", "Maximilian Burger", "Matthias May", "Christian Gilfrich", "Maximilian Haas", "Julio Ruben Rodas Garzaro", "Christoph Eckl"], "title": "MedNuggetizer: Confidence-Based Information Nugget Extraction from Medical Documents", "comment": "Preprint accepted at ECIR 2026", "summary": "We present MedNuggetizer, https://mednugget-ai.de/; access is available upon request.}, a tool for query-driven extraction and clustering of information nuggets from medical documents to support clinicians in exploring underlying medical evidence. Backed by a large language model (LLM), \\textit{MedNuggetizer} performs repeated extractions of information nuggets that are then grouped to generate reliable evidence within and across multiple documents. We demonstrate its utility on the clinical use case of \\textit{antibiotic prophylaxis before prostate biopsy} by using major urological guidelines and recent PubMed studies as sources of information. Evaluation by domain experts shows that \\textit{MedNuggetizer} provides clinicians and researchers with an efficient way to explore long documents and easily extract reliable, query-focused medical evidence."}
{"id": "2512.15092", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.15092", "abs": "https://arxiv.org/abs/2512.15092", "authors": ["Chao Zhou", "Changsheng You", "Cong Zhou", "Liujia Yao", "Weijie Yuan", "Beixiong Zheng", "Nan Wu"], "title": "Rotatable IRS-Assisted 6DMA Communications: A Two-timescale Design", "comment": "13 pages, 8 figures, submitted to IEEE for possible publication", "summary": "Intelligent reflecting surface (IRS) and movable antenna (MA) are promising technologies to enhance wireless communication by reconfiguring channels at the environment and transceiver sides. However, their performance is constrained by practical limitations. To address this, we propose a multi-functional antenna/surface system that leverages their complementary advantages. A rotatable IRS (R-IRS) is deployed to enhance downlink communications from a six-dimensional MA (6DMA)-equipped base station (BS) to multiple single-antenna users. To reduce the complexity of real-time channel estimation and beamforming, we formulate an optimization problem to maximize the average sum-rate using a two-timescale (TTS) transmission protocol. Specifically, the BS antenna configuration (including position and rotation) and IRS rotation and reflection are optimized based on statistical channel state information (S-CSI), while BS transmit beamforming is designed using instantaneous CSI (I-CSI) in the short timescale. We first consider a single-user case and show that the 6DMA at the BS should form a sparse array for multi-beam transmission towards both the IRS and the user, allowing efficient coordination of direct and reflected channels, while the IRS rotation achieves effective multi-path alignment. For the general multi-user case, the optimization problem is non-convex and challenging to solve. To tackle this, we propose an efficient algorithm combining weighted minimum mean-square error (WMMSE) and stochastic successive convex approximation (SSCA) techniques. A low-complexity algorithm is also proposed to reduce computational complexity. Numerical results validate the proposed system, showing significant performance gains by jointly exploiting the spatial degrees of freedom of the 6DMA-BS and R-IRS under the TTS protocol."}
{"id": "2512.15372", "categories": ["cs.IR", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.15372", "abs": "https://arxiv.org/abs/2512.15372", "authors": ["Mikel Williams-Lekuona", "Georgina Cosma"], "title": "Image Complexity-Aware Adaptive Retrieval for Efficient Vision-Language Models", "comment": "Accepted paper for ECIR 2026", "summary": "Vision transformers in vision-language models apply uniform computational effort across all images, expending 175.33 GFLOPs (ViT-L/14) whether analysing a straightforward product photograph or a complex street scene. We propose ICAR (Image Complexity-Aware Retrieval), which enables vision transformers to use less compute for simple images whilst processing complex images through their full network depth. The key challenge is maintaining cross-modal alignment: embeddings from different processing depths must remain compatible for text matching. ICAR solves this through dual-path training that produces compatible embeddings from both reduced-compute and full-compute processing. This maintains compatibility between image representations and text embeddings in the same semantic space, whether an image exits early or processes fully. Unlike existing two-stage approaches that require expensive reranking, ICAR enables direct image-text matching without additional overhead. To determine how much compute to use, we develop ConvNeXt-IC, which treats image complexity assessment as a classification task. By applying modern classifier backbones rather than specialised architectures, ConvNeXt-IC achieves state-of-the-art performance with 0.959 correlation with human judgement (Pearson) and 4.4x speedup. Evaluated on standard benchmarks augmented with real-world web data, ICAR achieves 20% practical speedup while maintaining category-level performance and 95% of instance-level performance, enabling sustainable scaling of vision-language systems."}
{"id": "2512.15308", "categories": ["cs.DB", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15308", "abs": "https://arxiv.org/abs/2512.15308", "authors": ["Basil Ell"], "title": "Graph Pattern-based Association Rules Evaluated Under No-repeated-anything Semantics in the Graph Transactional Setting", "comment": null, "summary": "We introduce graph pattern-based association rules (GPARs) for directed labeled multigraphs such as RDF graphs. GPARs support both generative tasks, where a graph is extended, and evaluative tasks, where the plausibility of a graph is assessed. The framework goes beyond related formalisms such as graph functional dependencies, graph entity dependencies, relational association rules, graph association rules, multi-relation and path association rules, and Horn rules. Given a collection of graphs, we evaluate graph patterns under no-repeated-anything semantics, which allows the topology of a graph to be taken into account more effectively. We define a probability space and derive confidence, lift, leverage, and conviction in a probabilistic setting. We further analyze how these metrics relate to their classical itemset-based counterparts and identify conditions under which their characteristic properties are preserved."}
{"id": "2512.15526", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15526", "abs": "https://arxiv.org/abs/2512.15526", "authors": ["Abdullah Al Munem", "Sumona Yeasmin", "Mohammad Rezwanul Huq"], "title": "BERT and CNN integrated Neural Collaborative Filtering for Recommender Systems", "comment": null, "summary": "Every day, a significant number of users visit the internet for different needs. The owners of a website generate profits from the user interaction with the contents or items of the website. A robust recommendation system can increase user interaction with a website by recommending items according to the user's unique preferences. BERT and CNN-integrated neural collaborative filtering (NCF) have been proposed for the recommendation system in this experiment. The proposed model takes inputs from the user and item profile and finds the user's interest. This model can handle numeric, categorical, and image data to extract the latent features from the inputs. The model is trained and validated on a small sample of the MovieLens dataset for 25 epochs. The same dataset has been used to train and validate a simple NCF and a BERT-based NCF model and compared with the proposed model. The proposed model outperformed those two baseline models. The obtained result for the proposed model is 0.72 recall and 0.486 Hit Ratio @ 10 for 799 users on the MovieLens dataset. This experiment concludes that considering both categorical and image data can improve the performance of a recommendation system."}
{"id": "2512.15191", "categories": ["cs.IT", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.15191", "abs": "https://arxiv.org/abs/2512.15191", "authors": ["Mengchu Xu", "Jian Wang", "Yonina C. Eldar"], "title": "Sparse Principal Component Analysis with Energy Profile Dependent Sample Complexity", "comment": "33 pages, 7 figures", "summary": "We study sparse principal component analysis in the high-dimensional, sample-limited regime, aiming to recover a leading component supported on a few coordinates. Despite extensive progress, most methods and analyses are tailored to the flat-spike case, offering little guidance when spike energy is unevenly distributed across the support. Motivated by this, we propose Spectral Energy Pursuit (SEP), an effective iterative scheme that repeatedly screens and reselects coordinates, with a sample complexity that adapts to the energy profile. We develop our framework around a structure function \\(s(p)\\) that quantifies how spike energy accumulates over its top \\(p\\) entries. We establish that SEP succeeds with a sample size of order \\(\\max_{1\\le p\\le k} p\\,s^2(p)\\,\\log n\\), which matches the classical \\(k^2\\log n\\) sample complexity for flat spikes and improves toward the \\(k\\log n\\) regime as the profile becomes more concentrated. As a lightweight post-processing, a single truncated power iteration is proven to enable the final estimator to attain a uniform statistical error bound. Empirical simulations across flat, power-law, and exponential signals validate that SEP adapts to profile structure without tuning and outperforms existing algorithms."}
{"id": "2512.15363", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.15363", "abs": "https://arxiv.org/abs/2512.15363", "authors": ["Zixin Wei", "Yucan Guo", "Jinyang Li", "Xiaolin Han", "Xiaolong Jin", "Chenhao Ma"], "title": "Revisiting Task-Oriented Dataset Search in the Era of Large Language Models: Challenges, Benchmark, and Solution", "comment": "Accepted to Proc. VLDB Endow. (PVLDB), Vol. 19. 14 pages, 8 figures", "summary": "The search for suitable datasets is the critical \"first step\" in data-driven research, but it remains a great challenge. Researchers often need to search for datasets based on high-level task descriptions. However, existing search systems struggle with this task due to ambiguous user intent, task-to-dataset mapping and benchmark gaps, and entity ambiguity. To address these challenges, we introduce KATS, a novel end-to-end system for task-oriented dataset search from unstructured scientific literature. KATS consists of two key components, i.e., offline knowledge base construction and online query processing. The sophisticated offline pipeline automatically constructs a high-quality, dynamically updatable task-dataset knowledge graph by employing a collaborative multi-agent framework for information extraction, thereby filling the task-to-dataset mapping gap. To further address the challenge of entity ambiguity, a unique semantic-based mechanism is used for task entity linking and dataset entity resolution. For online retrieval, KATS utilizes a specialized hybrid query engine that combines vector search with graph-based ranking to generate highly relevant results. Additionally, we introduce CS-TDS, a tailored benchmark suite for evaluating task-oriented dataset search systems, addressing the critical gap in standardized evaluation. Experiments on our benchmark suite show that KATS significantly outperforms state-of-the-art retrieval-augmented generation frameworks in both effectiveness and efficiency, providing a robust blueprint for the next generation of dataset discovery systems."}
{"id": "2512.15365", "categories": ["cs.DB", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.15365", "abs": "https://arxiv.org/abs/2512.15365", "authors": ["Gajendra Doniparthi", "Shashank Balu Pandhare", "Stefan Deßloch", "Timo Mühlhaus"], "title": "ArcBERT: An LLM-based Search Engine for Exploring Integrated Multi-Omics Metadata", "comment": null, "summary": "Traditional search applications within Research Data Management (RDM) ecosystems are crucial in helping users discover and explore the structured metadata from the research datasets. Typically, text search engines require users to submit keyword-based queries rather than using natural language. However, using Large Language Models (LLMs) trained on domain-specific content for specialized natural language processing (NLP) tasks is becoming increasingly common. We present ArcBERT, an LLM-based system designed for integrated metadata exploration. ArcBERT understands natural language queries and relies on semantic matching, unlike traditional search applications. Notably, ArcBERT also understands the structure and hierarchies within the metadata, enabling it to handle diverse user querying patterns effectively."}
{"id": "2512.15241", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.15241", "abs": "https://arxiv.org/abs/2512.15241", "authors": ["Yinghui Ye", "Ying Li", "Xiaoli Chu", "Gan Zheng", "Sumei Sun"], "title": "Symbol Detection in Ambient Backscatter Communications Under Residual Time Synchronization Errors", "comment": null, "summary": "Ambient backscatter communications (AmBC), where a backscatter transmitter (BT) modulates and reflects ambient signals to a backscatter receiver (BR), have been deemed a low-power communication technology for the Internet of Things. Previous work on symbol detection in AmBC assumed perfect time synchronization (TS), which is unrealistic in practice. The residual TS errors (RTSE) cause \\emph{partial sample mismatch}, degrading symbol detection performance. To address this, we propose a new AmBC symbol detection framework that incorporates the BT's current and adjacent symbols, as well as channel coefficients. Using energy detector (ED) as a case study, we derive both exact and approximate bit error rate (BER) expressions. Our results show that the ED's BER performance degrades significantly under RTSE, with the symbol detection threshold optimized under the assumption of perfect TS. We then derive a closed-form expression for a near-optimal symbol detection threshold that minimizes BER under RTSE. To estimate the required parameters for the detection threshold, we propose a novel method exploiting the attributes of the BR's received signal samples. The analytical results are verified by simulation results."}
{"id": "2512.15365", "categories": ["cs.DB", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.15365", "abs": "https://arxiv.org/abs/2512.15365", "authors": ["Gajendra Doniparthi", "Shashank Balu Pandhare", "Stefan Deßloch", "Timo Mühlhaus"], "title": "ArcBERT: An LLM-based Search Engine for Exploring Integrated Multi-Omics Metadata", "comment": null, "summary": "Traditional search applications within Research Data Management (RDM) ecosystems are crucial in helping users discover and explore the structured metadata from the research datasets. Typically, text search engines require users to submit keyword-based queries rather than using natural language. However, using Large Language Models (LLMs) trained on domain-specific content for specialized natural language processing (NLP) tasks is becoming increasingly common. We present ArcBERT, an LLM-based system designed for integrated metadata exploration. ArcBERT understands natural language queries and relies on semantic matching, unlike traditional search applications. Notably, ArcBERT also understands the structure and hierarchies within the metadata, enabling it to handle diverse user querying patterns effectively."}
{"id": "2512.15342", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.15342", "abs": "https://arxiv.org/abs/2512.15342", "authors": ["Zhentian Zhang", "Jian Dang", "David Morales-Jimenez", "Hao Jiang", "Zaichen Zhang", "Christos Masouros", "Chan-Byoung Chae"], "title": "Joint Activity Detection and Channel Estimation For Fluid Antenna System Exploiting Geographical and Angular Information", "comment": null, "summary": "The fluid antenna system (FAS) refers to a family of reconfigurable antenna technologies that provide substantial spatial gains within a compact, predefined small space, thereby offering extensive degrees of freedom in the physical layer for future communication networks. The acquisition of channel state information (CSI) is critical, as it determines the placement of ports/antennas, which directly impacts FAS-based optimization. Although various channel estimation methods have been developed, significant flaws persist. For instance, the performance of greedy-based algorithms is heavily influenced by signal assumptions, and current model-free methods are infeasible due to prohibitively high computational complexity issue. Consequently, there is a pressing need for a well-balanced solution that exhibits flexibility, feasibility, and low complexity to support massive connectivity in FAS. In this work, we propose methods based on approximate message passing (AMP) integrated with adaptive expectation maximization (EM). The EM-AMP framework uniquely enables efficient large matrix computations with adaptive learning capabilities, independent of prior knowledge of the model or parameters within potential distributions, making it a robust candidate for FAS networks. We introduce two variants of the EM-AMP framework that leverage geographical and angular features in a FAS network. These proposed algorithms demonstrate improved estimation precision, fast convergence, and low computational complexity in large activity regions. Additionally, we analytically elucidate the reasons behind the inherent performance floor of greedy-based methods and highlight the critical role of angular information in algorithm design. Extensive numerical results validate the promising efficacy of the proposed algorithm designs and the derived analytical findings."}
{"id": "2512.15399", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15399", "abs": "https://arxiv.org/abs/2512.15399", "authors": ["Phillip Stephan", "Florian Euchner", "Stephan ten Brink"], "title": "Three-Dimensional Radio Localization: A Channel Charting-Based Approach", "comment": null, "summary": "Channel charting creates a low-dimensional representation of the radio environment in a self-supervised manner using manifold learning. Preserving relative spatial distances in the latent space, channel charting is well suited to support user localization. While prior work on channel charting has mainly focused on two-dimensional scenarios, real-world environments are inherently three-dimensional. In this work, we investigate two distinct three-dimensional indoor localization scenarios using simulated, but realistic ray tracing-based datasets: a factory hall with a three-dimensional spatial distribution of datapoints, and a multistory building where each floor exhibits a two-dimensional datapoint distribution. For the first scenario, we apply the concept of augmented channel charting, which combines classical localization and channel charting, to a three-dimensional setting. For the second scenario, we introduce multistory channel charting, a two-stage approach consisting of floor classification via clustering followed by the training of a dedicated expert neural network for channel charting on each individual floor, thereby enhancing the channel charting performance. In addition, we propose a novel feature engineering method designed to extract sparse features from the beamspace channel state information that are suitable for localization."}
{"id": "2512.15419", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.15419", "abs": "https://arxiv.org/abs/2512.15419", "authors": ["Shilei Li", "Dawei Shi", "Hao Yu", "Ling Shi"], "title": "Variational Robust Kalman Filters: A Unified Framework", "comment": "23 pages", "summary": "Robustness and adaptivity are two competing objectives in Kalman filters (KF). Robustness involves temporarily inflating prior estimates of noise covariances, while adaptivity updates prior beliefs using real-time information. In practical applications, both process and measurement noise can be influenced by outliers, be time-varying, or both. Existing works may not effectively address the above complex noise scenarios, as there is an intrinsic incompatibility between robust filters and adaptive filters. In this work, we propose a unified variational robust Kalman filter, built on a Student's t-distribution induced loss function and variational inference, and solved through fixed-point iteration in a computationally efficient manner. We demonstrate that robustness can be understood as a prerequisite for adaptivity, making it possible to merge the above two competing goals into a single framework through switching rules. Additionally, our proposed filter can recover conventional KF, robust KF, and adaptive KF by adjusting parameters, and can suppress both the imperfect process and measurement noise, enabling it to perform superiorly in complex noise environments. Simulations verify the effectiveness of the proposed method."}
{"id": "2512.15425", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.15425", "abs": "https://arxiv.org/abs/2512.15425", "authors": ["Peng Yuan", "Zulin Wang", "Tao Luo", "Yuanhan Ni"], "title": "An Anti-Interference AFDM System: Interference Impacts Analyses and Parameter Optimization", "comment": null, "summary": "This paper proposes an anti-interference affine frequency division multiplexing (AFDM) system to ensure reliability and resource efficiency under malicious high-power interference originating from adversarial devices in high-mobility scenarios. Closed-form expressions of interferences in the discrete affine Fourier transform (DAFT) domain are derived by utilizing the stationary phase principle and the Affine Fourier transform convolution theorem, which indicates that interference impacts can be classified into stationary and non-stationary categories. On this basis, we reveal the analytical relationship between packet throughput and the paramerters of spread spectrum and error correction coding in our proposed anti-interference system, which enables the design of a parameter optimization algorithm that maximizes packet throughput. For reception, by jointly utilizing the autocorrelation function of spreading sequence and the cyclic-shift property of AFDM input-output relation, we design a linear-complexity correlation-based DAFT domain detector (CDD) capable of achieving full diversity gain, which performs correlation-based equalization to avoid matrix inversion. Numerical results validate the accuracy of the derived closed-form expressions and verify that the proposed anti-interference AFDM system could achieve high packet throughput under interference in high-mobility scenarios."}
{"id": "2512.15562", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15562", "abs": "https://arxiv.org/abs/2512.15562", "authors": ["Xingyu Zhou", "Le Liang", "Hao Ye", "Jing Zhang", "Chao-Kai Wen", "Shi Jin"], "title": "Reducing Pilots in Channel Estimation With Predictive Foundation Models", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Accurate channel state information (CSI) acquisition is essential for modern wireless systems, which becomes increasingly difficult under large antenna arrays, strict pilot overhead constraints, and diverse deployment environments. Existing artificial intelligence-based solutions often lack robustness and fail to generalize across scenarios. To address this limitation, this paper introduces a predictive-foundation-model-based channel estimation framework that enables accurate, low-overhead, and generalizable CSI acquisition. The proposed framework employs a predictive foundation model trained on large-scale cross-domain CSI data to extract universal channel representations and provide predictive priors with strong cross-scenario transferability. A pilot processing network based on a vision transformer architecture is further designed to capture spatial, temporal, and frequency correlations from pilot observations. An efficient fusion mechanism integrates predictive priors with real-time measurements, enabling reliable CSI reconstruction even under sparse or noisy conditions. Extensive evaluations across diverse configurations demonstrate that the proposed estimator significantly outperforms both classical and data-driven baselines in accuracy, robustness, and generalization capability."}
