{"id": "2602.05496", "categories": ["cs.MM", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.05496", "abs": "https://arxiv.org/abs/2602.05496", "authors": ["Hanwen Zhang", "Yao Liu", "Peiyuan Jiang", "Lang Junjie", "Xie Jun", "Yihui He", "Yajiao Deng", "Siyu Du", "Qiao Liu"], "title": "XEmoGPT: An Explainable Multimodal Emotion Recognition Framework with Cue-Level Perception and Reasoning", "comment": null, "summary": "Explainable Multimodal Emotion Recognition plays a crucial role in applications such as human-computer interaction and social media analytics. However, current approaches struggle with cue-level perception and reasoning due to two main challenges: 1) general-purpose modality encoders are pretrained to capture global structures and general semantics rather than fine-grained emotional cues, resulting in limited sensitivity to emotional signals; and 2) available datasets usually involve a trade-off between annotation quality and scale, which leads to insufficient supervision for emotional cues and ultimately limits cue-level reasoning. Moreover, existing evaluation metrics are inadequate for assessing cue-level reasoning performance. To address these challenges, we propose eXplainable Emotion GPT (XEmoGPT), a novel EMER framework capable of both perceiving and reasoning over emotional cues. It incorporates two specialized modules: the Video Emotional Cue Bridge (VECB) and the Audio Emotional Cue Bridge (AECB), which enhance the video and audio encoders through carefully designed tasks for fine-grained emotional cue perception. To further support cue-level reasoning, we construct a large-scale dataset, EmoCue, designed to teach XEmoGPT how to reason over multimodal emotional cues. In addition, we introduce EmoCue-360, an automated metric that extracts and matches emotional cues using semantic similarity, and release EmoCue-Eval, a benchmark of 400 expert-annotated samples covering diverse emotional scenarios. Experimental results show that XEmoGPT achieves strong performance in both emotional cue perception and reasoning.", "AI": {"tldr": "\u63d0\u51faXEmoGPT\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u95e8\u6a21\u5757\u589e\u5f3a\u60c5\u611f\u7ebf\u7d22\u611f\u77e5\uff0c\u6784\u5efa\u5927\u89c4\u6a21\u6570\u636e\u96c6\u652f\u6301\u7ebf\u7d22\u7ea7\u63a8\u7406\uff0c\u5e76\u5f15\u5165\u65b0\u8bc4\u4f30\u6307\u6807", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a1)\u901a\u7528\u6a21\u6001\u7f16\u7801\u5668\u7f3a\u4e4f\u5bf9\u7ec6\u7c92\u5ea6\u60c5\u611f\u7ebf\u7d22\u7684\u654f\u611f\u6027\uff1b2)\u73b0\u6709\u6570\u636e\u96c6\u5728\u6807\u6ce8\u8d28\u91cf\u548c\u89c4\u6a21\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u5bfc\u81f4\u60c5\u611f\u7ebf\u7d22\u76d1\u7763\u4e0d\u8db3\u3002\u6b64\u5916\uff0c\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u7ebf\u7d22\u7ea7\u63a8\u7406\u6027\u80fd\u3002", "method": "\u63d0\u51faXEmoGPT\u6846\u67b6\uff0c\u5305\u542b\u89c6\u9891\u60c5\u611f\u7ebf\u7d22\u6865(VECB)\u548c\u97f3\u9891\u60c5\u611f\u7ebf\u7d22\u6865(AECB)\u4e24\u4e2a\u4e13\u95e8\u6a21\u5757\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u4efb\u52a1\u589e\u5f3a\u89c6\u9891\u548c\u97f3\u9891\u7f16\u7801\u5668\u7684\u7ec6\u7c92\u5ea6\u60c5\u611f\u7ebf\u7d22\u611f\u77e5\u80fd\u529b\u3002\u6784\u5efa\u5927\u89c4\u6a21\u6570\u636e\u96c6EmoCue\u652f\u6301\u7ebf\u7d22\u7ea7\u63a8\u7406\uff0c\u5e76\u5f15\u5165EmoCue-360\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u548cEmoCue-Eval\u57fa\u51c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cXEmoGPT\u5728\u60c5\u611f\u7ebf\u7d22\u611f\u77e5\u548c\u63a8\u7406\u65b9\u9762\u90fd\u53d6\u5f97\u4e86\u5f3a\u52b2\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "XEmoGPT\u901a\u8fc7\u4e13\u95e8\u7684\u60c5\u611f\u7ebf\u7d22\u611f\u77e5\u6a21\u5757\u3001\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u65b0\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u4e2d\u7684\u7ebf\u7d22\u7ea7\u611f\u77e5\u548c\u63a8\u7406\u6311\u6218\u3002"}}
{"id": "2602.05072", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.05072", "abs": "https://arxiv.org/abs/2602.05072", "authors": ["Yuan-Pon Chen", "Olgica Milenkovic", "Jo\u00e3o Ribeiro", "Jin Sima"], "title": "Correcting Contextual Deletions in DNA Nanopore Readouts", "comment": "31 pages, 0 figures, 3 tables", "summary": "The problem of designing codes for deletion-correction and synchronization has received renewed interest due to applications in DNA-based data storage systems that use nanopore sequencers as readout platforms. In almost all instances, deletions are assumed to be imposed independently of each other and of the sequence context. These assumptions are not valid in practice, since nanopore errors tend to occur within specific contexts. We study contextual nanopore deletion-errors through the example setting of deterministic single deletions following (complete) runlengths of length at least $k$. The model critically depends on the runlength threshold $k$, and we examine two regimes for $k$: a) $k=C\\log n$ for a constant $C\\in(0,1)$; in this case, we study error-correcting codes that can protect from a constant number $t$ of contextual deletions, and show that the minimum redundancy (ignoring lower-order terms) is between $(1-C)t\\log n$ and $2(1-C)t\\log n$, meaning that it is a ($1-C$)-fraction of that of arbitrary $t$-deletion-correcting codes. To complement our non-constructive redundancy upper bound, we design efficiently and encodable and decodable codes for any constant $t$. In particular, for $t=1$ and $C>1/2$ we construct efficient codes with redundancy that essentially matches our non-constructive upper bound; b) $k$ equal a constant; in this case we consider the extremal problem where the number of deletions is not bounded and a deletion is imposed after every run of length at least $k$, which we call the extremal contextual deletion channel. This combinatorial setting arises naturally by considering a probabilistic channel that introduces contextual deletions after each run of length at least $k$ with probability $p$ and taking the limit $p\\to 1$. We obtain sharp bounds on the maximum achievable rate under the extremal contextual deletion channel for arbitrary constant $k$.", "AI": {"tldr": "\u7814\u7a76DNA\u5b58\u50a8\u4e2d\u7eb3\u7c73\u5b54\u6d4b\u5e8f\u7684\u4e0a\u4e0b\u6587\u76f8\u5173\u5220\u9664\u9519\u8bef\uff0c\u5206\u6790\u4e24\u79cd\u8fd0\u884c\u957f\u5ea6\u9608\u503ck\u7684\u7f16\u7801\u65b9\u6848\uff1ak=Clogn\u65f6\u6784\u9020\u9ad8\u6548\u7ea0\u5220\u7801\uff0ck\u4e3a\u5e38\u6570\u65f6\u7814\u7a76\u6781\u7aef\u4e0a\u4e0b\u6587\u5220\u9664\u4fe1\u9053\u7684\u5bb9\u91cf\u6781\u9650\u3002", "motivation": "DNA\u6570\u636e\u5b58\u50a8\u7cfb\u7edf\u4e2d\u7eb3\u7c73\u5b54\u6d4b\u5e8f\u5668\u4f1a\u4ea7\u751f\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u5220\u9664\u9519\u8bef\uff0c\u800c\u975e\u4f20\u7edf\u5047\u8bbe\u7684\u72ec\u7acb\u968f\u673a\u9519\u8bef\u3002\u73b0\u6709\u6a21\u578b\u5047\u8bbe\u5220\u9664\u72ec\u7acb\u4e14\u4e0e\u5e8f\u5217\u4e0a\u4e0b\u6587\u65e0\u5173\uff0c\u8fd9\u4e0e\u5b9e\u9645\u4e0d\u7b26\uff0c\u9700\u8981\u7814\u7a76\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u7eb3\u7c73\u5b54\u5220\u9664\u9519\u8bef\u6a21\u578b\u3002", "method": "\u7814\u7a76\u786e\u5b9a\u6027\u5355\u5220\u9664\u8ddf\u968f\u957f\u5ea6\u81f3\u5c11\u4e3ak\u7684\u5b8c\u6574\u8fd0\u884c\u957f\u5ea6\u540e\u7684\u9519\u8bef\u6a21\u578b\u3002\u5206\u6790\u4e24\u79cdk\u503c\u60c5\u51b5\uff1a1) k=Clogn\u65f6\uff0c\u7814\u7a76\u80fd\u7ea0\u6b63t\u4e2a\u4e0a\u4e0b\u6587\u5220\u9664\u7684\u7ea0\u5220\u7801\uff0c\u7ed9\u51fa\u5197\u4f59\u5ea6\u4e0a\u4e0b\u754c\u5e76\u6784\u9020\u9ad8\u6548\u7f16\u89e3\u7801\u65b9\u6848\uff1b2) k\u4e3a\u5e38\u6570\u65f6\uff0c\u7814\u7a76\u6781\u7aef\u4e0a\u4e0b\u6587\u5220\u9664\u4fe1\u9053\uff08\u6bcf\u4e2a\u957f\u5ea6\u2265k\u7684\u8fd0\u884c\u540e\u90fd\u53d1\u751f\u5220\u9664\uff09\uff0c\u63a8\u5bfc\u6700\u5927\u53ef\u8fbe\u901f\u7387\u3002", "result": "\u5bf9\u4e8ek=Clogn\uff1a\u5197\u4f59\u5ea6\u4e0a\u4e0b\u754c\u4e3a(1-C)tlogn\u52302(1-C)tlogn\u4e4b\u95f4\uff0c\u662f\u4efb\u610ft-\u5220\u9664\u7ea0\u6b63\u7801\u7684(1-C)\u5206\u6570\u3002\u6784\u9020\u4e86t=1\u4e14C>1/2\u65f6\u7684\u9ad8\u6548\u7f16\u7801\uff0c\u5197\u4f59\u5ea6\u63a5\u8fd1\u7406\u8bba\u4e0a\u754c\u3002\u5bf9\u4e8ek\u4e3a\u5e38\u6570\uff1a\u83b7\u5f97\u4e86\u6781\u7aef\u4e0a\u4e0b\u6587\u5220\u9664\u4fe1\u9053\u4e0b\u4efb\u610f\u5e38\u6570k\u7684\u6700\u5927\u53ef\u8fbe\u901f\u7387\u7684\u7cbe\u786e\u754c\u9650\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u5220\u9664\u9519\u8bef\u6a21\u578b\u66f4\u7b26\u5408\u7eb3\u7c73\u5b54\u6d4b\u5e8f\u5b9e\u9645\uff0c\u76f8\u6bd4\u4f20\u7edf\u72ec\u7acb\u5220\u9664\u6a21\u578b\u80fd\u663e\u8457\u964d\u4f4e\u5197\u4f59\u5ea6\u8981\u6c42\u3002\u7814\u7a76\u4e3aDNA\u5b58\u50a8\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u7f16\u7801\u65b9\u6848\u8bbe\u8ba1\u7406\u8bba\u57fa\u7840\uff0c\u533a\u5206\u4e86\u4e24\u79cd\u4e0d\u540ck\u503c\u60c5\u51b5\u4e0b\u7684\u7f16\u7801\u6027\u80fd\u6781\u9650\u3002"}}
{"id": "2602.04936", "categories": ["cs.DS", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.04936", "abs": "https://arxiv.org/abs/2602.04936", "authors": ["Stanislav Byriukov"], "title": "Deterministic Retrieval at Scale: Optimal-Space LCP Indexing and 308x Energy Reduction on Modern GPUs", "comment": null, "summary": "We study deterministic top-k retrieval under Longest Common Prefix (LCP) similarity for N sequences of length L. We prove a tight Omega(N) space lower bound (cell-probe model) and present a trie-based index using O(N*L) space with O(L+k) query time. We contrast this with pairwise materialization (Theta(N^2)), which hits a practical OOM wall at scale, while our indexed approach remains O(N) in memory. We then introduce Thermal-Aware Logic (TAL), which turns prefix structure into range-bounded scans. In hardware measurements, TAL reduces energy per query by 308x (0.0145 J vs 4.46 J) and cuts p95 latency by 329x (0.114 ms vs 37.5 ms) on a 20M-item range-scan benchmark, while sustaining near-peak utilization (~99%) under long runs. The result is a deterministic retrieval primitive with receipts in regimes where approximate methods are unacceptable.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6700\u957f\u516c\u5171\u524d\u7f00\u76f8\u4f3c\u5ea6\u7684\u786e\u5b9a\u6027top-k\u68c0\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7Trie\u7d22\u5f15\u548c\u70ed\u611f\u77e5\u903b\u8f91\u6280\u672f\uff0c\u5728\u4fdd\u8bc1\u786e\u5b9a\u6027\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u80fd\u8017\u548c\u5ef6\u8fdf\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u4e24\u4e24\u8ba1\u7b97\u7684\u76f8\u4f3c\u5ea6\u68c0\u7d22\u65b9\u6cd5\u5728\u89c4\u6a21\u6269\u5c55\u65f6\u9762\u4e34\u5185\u5b58\u7206\u70b8\u95ee\u9898\uff08O(N\u00b2)\uff09\uff0c\u800c\u8fd1\u4f3c\u65b9\u6cd5\u5728\u67d0\u4e9b\u9700\u8981\u786e\u5b9a\u6027\u7ed3\u679c\u7684\u573a\u666f\u4e2d\u4e0d\u53ef\u63a5\u53d7\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u9ad8\u6548\u53c8\u786e\u5b9a\u6027\u7684\u68c0\u7d22\u65b9\u6848\u3002", "method": "1. \u6784\u5efaTrie\u7d22\u5f15\uff0c\u4f7f\u7528O(N*L)\u7a7a\u95f4\u590d\u6742\u5ea6\uff1b2. \u63d0\u51fa\u70ed\u611f\u77e5\u903b\u8f91(TAL)\uff0c\u5c06\u524d\u7f00\u7ed3\u6784\u8f6c\u6362\u4e3a\u8303\u56f4\u53d7\u9650\u626b\u63cf\uff1b3. \u5b9e\u73b0O(L+k)\u67e5\u8be2\u65f6\u95f4\u3002", "result": "1. \u7406\u8bba\u8bc1\u660e\uff1a\u5728cell-probe\u6a21\u578b\u4e2d\u8fbe\u5230\u03a9(N)\u7a7a\u95f4\u4e0b\u754c\uff1b2. \u6027\u80fd\u63d0\u5347\uff1a\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff0c\u80fd\u8017\u964d\u4f4e308\u500d\uff080.0145J vs 4.46J\uff09\uff0cp95\u5ef6\u8fdf\u964d\u4f4e329\u500d\uff080.114ms vs 37.5ms\uff09\uff1b3. \u8d44\u6e90\u5229\u7528\uff1a\u5728\u957f\u65f6\u8fd0\u884c\u4e2d\u4fdd\u6301\u63a5\u8fd1\u5cf0\u503c\u5229\u7528\u7387\uff08~99%\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u786e\u5b9a\u6027\u68c0\u7d22\u539f\u8bed\uff0c\u5728\u9700\u8981\u7cbe\u786e\u7ed3\u679c\u7684\u573a\u666f\u4e2d\u4f18\u4e8e\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u901a\u8fc7\u7d22\u5f15\u548c\u786c\u4ef6\u4f18\u5316\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21\u9ad8\u6548\u68c0\u7d22\u3002"}}
{"id": "2602.04912", "categories": ["cs.IR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04912", "abs": "https://arxiv.org/abs/2602.04912", "authors": ["James Gao", "Josh Zhou", "Qi Sun", "Ryan Huang", "Steven Yoo"], "title": "Atomic Information Flow: A Network Flow Model for Tool Attributions in RAG Systems", "comment": null, "summary": "Many tool-based Retrieval Augmented Generation (RAG) systems lack precise mechanisms for tracing final responses back to specific tool components -- a critical gap as systems scale to complex multi-agent architectures. We present \\textbf{Atomic Information Flow (AIF)}, a graph-based network flow model that decomposes tool outputs and LLM calls into atoms: indivisible, self-contained units of information. By modeling LLM orchestration as a directed flow of atoms from tool and LLM nodes to a response super-sink, AIF enables granular attribution metrics for AI explainability.\n  Motivated by the max-flow min-cut theorem in network flow theory, we train a lightweight Gemma3 (4B parameter) language model as a context compressor to approximate the minimum cut of tool atoms using flow signals computed offline by AIF. We note that the base Gemma3-4B model struggles to identify critical information with \\textbf{54.7\\%} accuracy on HotpotQA, barely outperforming lexical baselines (BM25). However, post-training on AIF signals boosts accuracy to \\textbf{82.71\\%} (+28.01 points) while achieving \\textbf{87.52\\%} (+1.85\\%) context token compression -- bridging the gap with the Gemma3-27B variant, a model nearly $7\\times$ larger.", "AI": {"tldr": "\u63d0\u51faAtomic Information Flow (AIF)\u6846\u67b6\uff0c\u5c06\u5de5\u5177RAG\u7cfb\u7edf\u7684\u4fe1\u606f\u6d41\u5efa\u6a21\u4e3a\u539f\u5b50\u5355\u5143\u7684\u7f51\u7edc\u6d41\uff0c\u5e76\u8bad\u7ec3\u8f7b\u91cf\u7ea7Gemma3\u6a21\u578b\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u538b\u7f29\u5668\uff0c\u663e\u8457\u63d0\u5347\u5173\u952e\u4fe1\u606f\u8bc6\u522b\u51c6\u786e\u7387\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5de5\u5177\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7cfb\u7edf\u7f3a\u4e4f\u5c06\u6700\u7ec8\u54cd\u5e94\u8ffd\u6eaf\u5230\u7279\u5b9a\u5de5\u5177\u7ec4\u4ef6\u7684\u7cbe\u786e\u673a\u5236\uff0c\u8fd9\u5728\u7cfb\u7edf\u6269\u5c55\u5230\u590d\u6742\u591a\u667a\u80fd\u4f53\u67b6\u6784\u65f6\u6210\u4e3a\u5173\u952e\u7f3a\u9677\u3002", "method": "\u63d0\u51fa\u539f\u5b50\u4fe1\u606f\u6d41(AIF)\u6a21\u578b\uff0c\u5c06\u5de5\u5177\u8f93\u51fa\u548cLLM\u8c03\u7528\u5206\u89e3\u4e3a\u4e0d\u53ef\u5206\u5272\u7684\u81ea\u5305\u542b\u4fe1\u606f\u539f\u5b50\u5355\u5143\uff0c\u5efa\u6a21\u4e3a\u4ece\u5de5\u5177/LLM\u8282\u70b9\u5230\u54cd\u5e94\u8d85\u7ea7\u6c47\u7684\u6709\u5411\u6d41\u3002\u57fa\u4e8e\u7f51\u7edc\u6d41\u7406\u8bba\u7684\u6700\u5927\u6d41\u6700\u5c0f\u5272\u5b9a\u7406\uff0c\u8bad\u7ec3\u8f7b\u91cf\u7ea7Gemma3(4B\u53c2\u6570)\u6a21\u578b\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u538b\u7f29\u5668\uff0c\u4f7f\u7528AIF\u8ba1\u7b97\u7684\u79bb\u7ebf\u6d41\u4fe1\u53f7\u6765\u8fd1\u4f3c\u5de5\u5177\u539f\u5b50\u7684\u6700\u5c0f\u5272\u3002", "result": "\u57fa\u7840Gemma3-4B\u6a21\u578b\u5728HotpotQA\u4e0a\u8bc6\u522b\u5173\u952e\u4fe1\u606f\u51c6\u786e\u7387\u4ec5\u4e3a54.7%\uff0c\u7565\u4f18\u4e8e\u8bcd\u6cd5\u57fa\u7ebf(BM25)\u3002\u7ecf\u8fc7AIF\u4fe1\u53f7\u8bad\u7ec3\u540e\uff0c\u51c6\u786e\u7387\u63d0\u5347\u81f382.71%(+28.01\u70b9)\uff0c\u540c\u65f6\u5b9e\u73b087.52%(+1.85%)\u7684\u4e0a\u4e0b\u6587token\u538b\u7f29\uff0c\u6027\u80fd\u63a5\u8fd17\u500d\u5927\u7684Gemma3-27B\u53d8\u4f53\u3002", "conclusion": "AIF\u6846\u67b6\u4e3a\u5de5\u5177RAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7ec6\u7c92\u5ea6\u7684\u53ef\u8ffd\u6eaf\u6027\uff0c\u901a\u8fc7\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u6a21\u578b\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u538b\u7f29\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5173\u952e\u4fe1\u606f\u8bc6\u522b\u80fd\u529b\uff0c\u4e3aAI\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5f52\u56e0\u5ea6\u91cf\u65b9\u6cd5\u3002"}}
{"id": "2602.05324", "categories": ["cs.GT", "cs.MA", "cs.RO", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.05324", "abs": "https://arxiv.org/abs/2602.05324", "authors": ["Mahdis Rabbani", "Navid Mojahed", "Shima Nazari"], "title": "A Data Driven Structural Decomposition of Dynamic Games via Best Response Maps", "comment": "11 pages, 6 figures, 5 tables, Submitted to RSS 2026", "summary": "Dynamic games are powerful tools to model multi-agent decision-making, yet computing Nash (generalized Nash) equilibria remains a central challenge in such settings. Complexity arises from tightly coupled optimality conditions, nested optimization structures, and poor numerical conditioning. Existing game-theoretic solvers address these challenges by directly solving the joint game, typically requiring explicit modeling of all agents' objective functions and constraints, while learning-based approaches often decouple interaction through prediction or policy approximation, sacrificing equilibrium consistency. This paper introduces a conceptually novel formulation for dynamic games by restructuring the equilibrium computation. Rather than solving a fully coupled game or decoupling agents through prediction or policy approximation, a data-driven structural reduction of the game is proposed that removes nested optimization layers and derivative coupling by embedding an offline-compiled best-response map as a feasibility constraint. Under standard regularity conditions, when the best-response operator is exact, any converged solution of the reduced problem corresponds to a local open-loop Nash (GNE) equilibrium of the original game; with a learned surrogate, the solution is approximately equilibrium-consistent up to the best-response approximation error. The proposed formulation is supported by mathematical proofs, accompanying a large-scale Monte Carlo study in a two-player open-loop dynamic game motivated by the autonomous racing problem. Comparisons are made against state-of-the-art joint game solvers, and results are reported on solution quality, computational cost, and constraint satisfaction.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u52a8\u6001\u535a\u5f08\u6c42\u89e3\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u7ed3\u6784\u7b80\u5316\uff0c\u7528\u79bb\u7ebf\u7f16\u8bd1\u7684\u6700\u4f73\u54cd\u5e94\u6620\u5c04\u66ff\u4ee3\u5d4c\u5957\u4f18\u5316\uff0c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u4fdd\u6301\u5747\u8861\u4e00\u81f4\u6027\u3002", "motivation": "\u52a8\u6001\u535a\u5f08\u662f\u5efa\u6a21\u591a\u667a\u80fd\u4f53\u51b3\u7b56\u7684\u6709\u529b\u5de5\u5177\uff0c\u4f46\u8ba1\u7b97\u7eb3\u4ec0\u5747\u8861\uff08\u5e7f\u4e49\u7eb3\u4ec0\u5747\u8861\uff09\u4ecd\u7136\u9762\u4e34\u6311\u6218\uff1a\u7d27\u8026\u5408\u7684\u6700\u4f18\u6027\u6761\u4ef6\u3001\u5d4c\u5957\u4f18\u5316\u7ed3\u6784\u3001\u6570\u503c\u6761\u4ef6\u5dee\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u76f4\u63a5\u6c42\u89e3\u8054\u5408\u535a\u5f08\uff08\u9700\u8981\u663e\u5f0f\u5efa\u6a21\u6240\u6709\u667a\u80fd\u4f53\u7684\u76ee\u6807\u51fd\u6570\u548c\u7ea6\u675f\uff09\uff0c\u8981\u4e48\u901a\u8fc7\u9884\u6d4b\u6216\u7b56\u7565\u8fd1\u4f3c\u89e3\u8026\u4ea4\u4e92\uff08\u727a\u7272\u5747\u8861\u4e00\u81f4\u6027\uff09\u3002", "method": "\u63d0\u51fa\u6982\u5ff5\u65b0\u9896\u7684\u52a8\u6001\u535a\u5f08\u516c\u5f0f\u5316\u65b9\u6cd5\uff1a\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u7ed3\u6784\u7b80\u5316\u91cd\u6784\u5747\u8861\u8ba1\u7b97\u3002\u4e0d\u662f\u6c42\u89e3\u5b8c\u5168\u8026\u5408\u7684\u535a\u5f08\uff0c\u4e5f\u4e0d\u662f\u901a\u8fc7\u9884\u6d4b\u6216\u7b56\u7565\u8fd1\u4f3c\u89e3\u8026\u667a\u80fd\u4f53\uff0c\u800c\u662f\u63d0\u51fa\u5c06\u79bb\u7ebf\u7f16\u8bd1\u7684\u6700\u4f73\u54cd\u5e94\u6620\u5c04\u4f5c\u4e3a\u53ef\u884c\u6027\u7ea6\u675f\u5d4c\u5165\uff0c\u4ece\u800c\u79fb\u9664\u5d4c\u5957\u4f18\u5316\u5c42\u548c\u5bfc\u6570\u8026\u5408\u3002", "result": "\u5728\u6807\u51c6\u6b63\u5219\u6761\u4ef6\u4e0b\uff0c\u5f53\u6700\u4f73\u54cd\u5e94\u7b97\u5b50\u7cbe\u786e\u65f6\uff0c\u7b80\u5316\u95ee\u9898\u7684\u4efb\u4f55\u6536\u655b\u89e3\u5bf9\u5e94\u4e8e\u539f\u59cb\u535a\u5f08\u7684\u5c40\u90e8\u5f00\u73af\u7eb3\u4ec0\uff08\u5e7f\u4e49\u7eb3\u4ec0\uff09\u5747\u8861\uff1b\u4f7f\u7528\u5b66\u4e60\u4ee3\u7406\u65f6\uff0c\u89e3\u5728\u6700\u4f73\u54cd\u5e94\u8fd1\u4f3c\u8bef\u5dee\u8303\u56f4\u5185\u8fd1\u4f3c\u5747\u8861\u4e00\u81f4\u3002\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\u652f\u6301\uff0c\u5e76\u5728\u81ea\u52a8\u9a7e\u9a76\u8d5b\u8f66\u95ee\u9898\u7684\u53cc\u73a9\u5bb6\u5f00\u73af\u52a8\u6001\u535a\u5f08\u4e2d\u8fdb\u884c\u5927\u89c4\u6a21\u8499\u7279\u5361\u6d1b\u7814\u7a76\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u89e3\u8d28\u91cf\u3001\u8ba1\u7b97\u6210\u672c\u548c\u7ea6\u675f\u6ee1\u8db3\u65b9\u9762\u4e0e\u6700\u5148\u8fdb\u7684\u8054\u5408\u535a\u5f08\u6c42\u89e3\u5668\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002\u901a\u8fc7\u7ed3\u6784\u7b80\u5316\u52a8\u6001\u535a\u5f08\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e2\u4fdd\u6301\u5747\u8861\u4e00\u81f4\u6027\u53c8\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.04926", "categories": ["cs.DB", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04926", "abs": "https://arxiv.org/abs/2602.04926", "authors": ["Ning Wang", "Kuanyan Zhu", "Daniel Yuehwoon Yee", "Yitang Gao", "Shiying Huang", "Zirun Xu", "Sainyam Galhotra"], "title": "Pruning Minimal Reasoning Graphs for Efficient Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-augmented generation (RAG) is now standard for knowledge-intensive LLM tasks, but most systems still treat every query as fresh, repeatedly re-retrieving long passages and re-reasoning from scratch, inflating tokens, latency, and cost. We present AutoPrunedRetriever, a graph-style RAG system that persists the minimal reasoning subgraph built for earlier questions and incrementally extends it for later ones. AutoPrunedRetriever stores entities and relations in a compact, ID-indexed codebook and represents questions, facts, and answers as edge sequences, enabling retrieval and prompting over symbolic structure instead of raw text. To keep the graph compact, we apply a two-layer consolidation policy (fast ANN/KNN alias detection plus selective $k$-means once a memory threshold is reached) and prune low-value structure, while prompts retain only overlap representatives and genuinely new evidence. We instantiate two front ends: AutoPrunedRetriever-REBEL, which uses REBEL as a triplet parser, and AutoPrunedRetriever-llm, which swaps in an LLM extractor. On GraphRAG-Benchmark (Medical and Novel), both variants achieve state-of-the-art complex reasoning accuracy, improving over HippoRAG2 by roughly 9--11 points, and remain competitive on contextual summarize and generation. On our harder STEM and TV benchmarks, AutoPrunedRetriever again ranks first, while using up to two orders of magnitude fewer tokens than graph-heavy baselines, making it a practical substrate for long-running sessions, evolving corpora, and multi-agent pipelines.", "AI": {"tldr": "\u63d0\u51faAutoPrunedRetriever\uff0c\u4e00\u79cd\u56fe\u5f0fRAG\u7cfb\u7edf\uff0c\u901a\u8fc7\u6301\u4e45\u5316\u6700\u5c0f\u63a8\u7406\u5b50\u56fe\u5e76\u589e\u91cf\u6269\u5c55\uff0c\u51cf\u5c11\u91cd\u590d\u68c0\u7d22\u548c\u63a8\u7406\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u4f20\u7edfRAG\u7cfb\u7edf\u5bf9\u6bcf\u4e2a\u67e5\u8be2\u90fd\u91cd\u65b0\u68c0\u7d22\u957f\u6bb5\u843d\u5e76\u4ece\u5934\u63a8\u7406\uff0c\u5bfc\u81f4token\u4f7f\u7528\u3001\u5ef6\u8fdf\u548c\u6210\u672c\u8fc7\u9ad8\u3002\u9700\u8981\u4e00\u79cd\u80fd\u6301\u4e45\u5316\u5e76\u590d\u7528\u5148\u524d\u63a8\u7406\u7ed3\u679c\u7684\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u56fe\u7ed3\u6784\u5b58\u50a8\u5b9e\u4f53\u548c\u5173\u7cfb\uff0c\u5c06\u95ee\u9898\u3001\u4e8b\u5b9e\u548c\u7b54\u6848\u8868\u793a\u4e3a\u8fb9\u5e8f\u5217\u3002\u91c7\u7528\u4e24\u5c42\u6574\u5408\u7b56\u7565\uff08\u5feb\u901fANN/KNN\u522b\u540d\u68c0\u6d4b+\u9009\u62e9\u6027k-means\uff09\u4fdd\u6301\u56fe\u7d27\u51d1\uff0c\u5e76\u526a\u679d\u4f4e\u4ef7\u503c\u7ed3\u6784\u3002\u63d0\u4f9b\u4e24\u79cd\u524d\u7aef\u5b9e\u73b0\uff1a\u57fa\u4e8eREBEL\u4e09\u5143\u7ec4\u89e3\u6790\u5668\u548c\u57fa\u4e8eLLM\u63d0\u53d6\u5668\u3002", "result": "\u5728GraphRAG-Benchmark\u4e0a\u6bd4HippoRAG2\u63d0\u53479-11\u4e2a\u70b9\uff0c\u5728STEM\u548cTV\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6392\u540d\u7b2c\u4e00\uff0c\u540c\u65f6token\u4f7f\u7528\u91cf\u6bd4\u57fa\u7ebf\u51cf\u5c11\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "AutoPrunedRetriever\u901a\u8fc7\u56fe\u5f0f\u6301\u4e45\u5316\u548c\u589e\u91cf\u6269\u5c55\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u77e5\u8bc6\u590d\u7528\uff0c\u4e3a\u957f\u4f1a\u8bdd\u3001\u6f14\u5316\u8bed\u6599\u5e93\u548c\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u3002"}}
{"id": "2602.05097", "categories": ["cs.IT", "math.AG"], "pdf": "https://arxiv.org/pdf/2602.05097", "abs": "https://arxiv.org/abs/2602.05097", "authors": ["Matteo Bonini", "Arianna Dionigi", "Francesco Ghiandoni"], "title": "On QC and GQC algebraic geometry codes", "comment": null, "summary": "We present new constructions of quasi-cyclic (QC) and generalized quasi-cyclic (GQC) codes from algebraic curves. Unlike previous approaches based on elliptic curves, our method applies to curves that are Kummer extensions of the rational function field, including hyperelliptic, norm-trace, and Hermitian curves. This allows QC codes with flexible co-index. Explicit parameter formulas are derived using known automorphism-group classifications.", "AI": {"tldr": "\u63d0\u51fa\u4ece\u4ee3\u6570\u66f2\u7ebf\u6784\u9020\u51c6\u5faa\u73af\u7801\u548c\u5e7f\u4e49\u51c6\u5faa\u73af\u7801\u7684\u65b0\u65b9\u6cd5\uff0c\u9002\u7528\u4e8eKummer\u6269\u5f20\u66f2\u7ebf\uff0c\u5305\u62ec\u8d85\u692d\u5706\u66f2\u7ebf\u3001\u8303\u8ff9\u66f2\u7ebf\u548cHermitian\u66f2\u7ebf", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u692d\u5706\u66f2\u7ebf\u7684\u51c6\u5faa\u73af\u7801\u6784\u9020\u65b9\u6cd5\u53d7\u9650\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u3001\u53c2\u6570\u66f4\u4e30\u5bcc\u7684\u6784\u9020\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u534f\u6307\u6570\u7684\u51c6\u5faa\u73af\u7801", "method": "\u5229\u7528\u4ee3\u6570\u66f2\u7ebf\u6784\u9020\u51c6\u5faa\u73af\u7801\u548c\u5e7f\u4e49\u51c6\u5faa\u73af\u7801\uff0c\u7279\u522b\u662fKummer\u6269\u5f20\u7684\u6709\u7406\u51fd\u6570\u57df\u66f2\u7ebf\uff0c\u5305\u62ec\u8d85\u692d\u5706\u66f2\u7ebf\u3001\u8303\u8ff9\u66f2\u7ebf\u548cHermitian\u66f2\u7ebf", "result": "\u83b7\u5f97\u4e86\u5177\u6709\u7075\u6d3b\u534f\u6307\u6570\u7684\u51c6\u5faa\u73af\u7801\uff0c\u5e76\u5229\u7528\u5df2\u77e5\u7684\u81ea\u540c\u6784\u7fa4\u5206\u7c7b\u63a8\u5bfc\u51fa\u660e\u786e\u7684\u53c2\u6570\u516c\u5f0f", "conclusion": "\u8be5\u65b9\u6cd5\u6269\u5c55\u4e86\u51c6\u5faa\u73af\u7801\u7684\u6784\u9020\u8303\u56f4\uff0c\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u53c2\u6570\u9009\u62e9\uff0c\u4e3a\u7f16\u7801\u7406\u8bba\u63d0\u4f9b\u4e86\u65b0\u7684\u6784\u9020\u5de5\u5177"}}
{"id": "2602.04985", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2602.04985", "abs": "https://arxiv.org/abs/2602.04985", "authors": ["Simon Bartlmae", "Andreas Hene", "Joshua K\u00f6nen", "Heiko R\u00f6glin"], "title": "Parameterized Algorithms for the Drone Delivery Problem", "comment": "Full (extended) version of the ISAAC 2025 paper. 35 pages, 9 figures", "summary": "Timely delivery and optimal routing remain fundamental challenges in the modern logistics industry. Building on prior work that considers single-package delivery across networks using multiple types of collaborative agents with restricted movement areas (e.g., drones or trucks), we examine the complexity of the problem under structural and operational constraints. Our focus is on minimizing total delivery time by coordinating agents that differ in speed and movement range across a graph. This problem formulation aligns with the recently proposed Drone Delivery Problem with respect to delivery time (DDT), introduced by Erlebach et al. [ISAAC 2022].\n  We first resolve an open question posed by Erlebach et al. [ISAAC 2022] by showing that even when the delivery network is a path graph, DDT admits no polynomial-time approximation within any polynomially encodable factor $a(n)$, unless P=NP. Additionally, we identify the intersection graph of the agents, where nodes represent agents and edges indicate an overlap of the movement areas of two agents, as an important structural concept. For path graphs, we show that DDT becomes tractable when parameterized by the treewidth $w$ of the intersection graph, and we present an exact FPT algorithm with running time $f(w)\\cdot\\text{poly}(n,k)$, for some computable function $f$. For general graphs, we give an FPT algorithm with running time $f(\u0394,w)\\cdot\\text{poly}(n,k)$, where $\u0394$ is the maximum degree of the intersection graph. In the special case where the intersection graph is a tree, we provide a simple polynomial-time algorithm.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u65e0\u4eba\u673a\u914d\u9001\u95ee\u9898(DDT)\u7684\u590d\u6742\u6027\uff0c\u8bc1\u660e\u4e86\u5373\u4f7f\u5728\u8def\u5f84\u56fe\u4e0a\u8be5\u95ee\u9898\u4e5f\u65e0\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u4ea4\u96c6\u56fe\u6811\u5bbd\u5ea6\u7684FPT\u7b97\u6cd5\u3002", "motivation": "\u73b0\u4ee3\u7269\u6d41\u884c\u4e1a\u9762\u4e34\u53ca\u65f6\u914d\u9001\u548c\u6700\u4f18\u8def\u5f84\u89c4\u5212\u7684\u57fa\u672c\u6311\u6218\u3002\u57fa\u4e8e\u5148\u524d\u5173\u4e8e\u4f7f\u7528\u591a\u79cd\u534f\u4f5c\u4ee3\u7406\uff08\u5982\u65e0\u4eba\u673a\u6216\u5361\u8f66\uff09\u5728\u7f51\u7edc\u4e0a\u8fdb\u884c\u5355\u5305\u88f9\u914d\u9001\u7684\u7814\u7a76\uff0c\u672c\u6587\u5728\u7ed3\u6784\u548c\u64cd\u4f5c\u7ea6\u675f\u4e0b\u8003\u5bdf\u4e86\u8be5\u95ee\u9898\u7684\u590d\u6742\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u901a\u8fc7\u534f\u8c03\u4e0d\u540c\u901f\u5ea6\u548c\u79fb\u52a8\u8303\u56f4\u7684\u4ee3\u7406\u6765\u6700\u5c0f\u5316\u603b\u914d\u9001\u65f6\u95f4\u3002", "method": "1. \u8bc1\u660e\u5373\u4f7f\u5728\u8def\u5f84\u56fe\u4e0a\uff0cDDT\u95ee\u9898\u4e5f\u65e0\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u89e3\uff08\u9664\u975eP=NP\uff09\uff1b2. \u5f15\u5165\u4ee3\u7406\u7684\u4ea4\u96c6\u56fe\u6982\u5ff5\uff0c\u5176\u4e2d\u8282\u70b9\u8868\u793a\u4ee3\u7406\uff0c\u8fb9\u8868\u793a\u4e24\u4e2a\u4ee3\u7406\u79fb\u52a8\u533a\u57df\u91cd\u53e0\uff1b3. \u5bf9\u4e8e\u8def\u5f84\u56fe\uff0c\u63d0\u51fa\u57fa\u4e8e\u4ea4\u96c6\u56fe\u6811\u5bbd\u5ea6\u7684\u7cbe\u786eFPT\u7b97\u6cd5\uff1b4. \u5bf9\u4e8e\u4e00\u822c\u56fe\uff0c\u63d0\u51fa\u57fa\u4e8e\u4ea4\u96c6\u56fe\u6700\u5927\u5ea6\u548c\u6811\u5bbd\u5ea6\u7684FPT\u7b97\u6cd5\uff1b5. \u5bf9\u4e8e\u4ea4\u96c6\u56fe\u4e3a\u6811\u7684\u60c5\u51b5\uff0c\u63d0\u4f9b\u7b80\u5355\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002", "result": "1. \u89e3\u51b3\u4e86Erlebach\u7b49\u4eba\u63d0\u51fa\u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u8bc1\u660eDDT\u5373\u4f7f\u5728\u8def\u5f84\u56fe\u4e0a\u4e5f\u65e0\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u89e3\uff1b2. \u5bf9\u4e8e\u8def\u5f84\u56fe\uff0c\u5f53\u53c2\u6570\u5316\u4e3a\u4ea4\u96c6\u56fe\u7684\u6811\u5bbd\u5ea6w\u65f6\uff0cDDT\u53d8\u5f97\u53ef\u5904\u7406\uff1b3. \u5bf9\u4e8e\u4e00\u822c\u56fe\uff0c\u7ed9\u51fa\u4e86\u57fa\u4e8e\u6700\u5927\u5ea6\u0394\u548c\u6811\u5bbd\u5ea6w\u7684FPT\u7b97\u6cd5\uff1b4. \u5f53\u4ea4\u96c6\u56fe\u4e3a\u6811\u65f6\uff0c\u63d0\u4f9b\u4e86\u7b80\u5355\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002", "conclusion": "\u672c\u6587\u6df1\u5165\u5206\u6790\u4e86\u65e0\u4eba\u673a\u914d\u9001\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u8bc1\u660e\u4e86\u5373\u4f7f\u5728\u7b80\u5355\u8def\u5f84\u56fe\u4e0a\u8be5\u95ee\u9898\u4e5f\u6781\u5176\u56f0\u96be\uff0c\u4f46\u901a\u8fc7\u5f15\u5165\u4ea4\u96c6\u56fe\u7ed3\u6784\u6982\u5ff5\u548c\u53c2\u6570\u5316\u590d\u6742\u6027\u65b9\u6cd5\uff0c\u4e3a\u7279\u5b9a\u60c5\u51b5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7b97\u6cd5\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u7269\u6d41\u914d\u9001\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2602.05062", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.05062", "abs": "https://arxiv.org/abs/2602.05062", "authors": ["Julian Killingback", "Mahta Rafiee", "Madine Manas", "Hamed Zamani"], "title": "Scaling Laws for Embedding Dimension in Information Retrieval", "comment": "9 Pages, 7 figures", "summary": "Dense retrieval, which encodes queries and documents into a single dense vector, has become the dominant neural retrieval approach due to its simplicity and compatibility with fast approximate nearest neighbor algorithms. As the tasks dense retrieval performs grow in complexity, the fundamental limitations of the underlying data structure and similarity metric -- namely vectors and inner-products -- become more apparent. Prior recent work has shown theoretical limitations inherent to single vectors and inner-products that are generally tied to the embedding dimension. Given the importance of embedding dimension for retrieval capacity, understanding how dense retrieval performance changes as embedding dimension is scaled is fundamental to building next generation retrieval models that balance effectiveness and efficiency. In this work, we conduct a comprehensive analysis of the relationship between embedding dimension and retrieval performance. Our experiments include two model families and a range of model sizes from each to construct a detailed picture of embedding scaling behavior. We find that the scaling behavior fits a power law, allowing us to derive scaling laws for performance given only embedding dimension, as well as a joint law accounting for embedding dimension and model size. Our analysis shows that for evaluation tasks aligned with the training task, performance continues to improve as embedding size increases, though with diminishing returns. For evaluation data that is less aligned with the training task, we find that performance is less predictable, with performance degrading with larger embedding dimensions for certain tasks. We hope our work provides additional insight into the limitations of embeddings and their behavior as well as offers a practical guide for selecting model and embedding dimension to achieve optimal performance with reduced storage and compute costs.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u53d1\u73b0\uff0c\u7a20\u5bc6\u68c0\u7d22\u6a21\u578b\u7684\u5d4c\u5165\u7ef4\u5ea6\u4e0e\u68c0\u7d22\u6027\u80fd\u4e4b\u95f4\u5b58\u5728\u5e42\u5f8b\u7f29\u653e\u5173\u7cfb\uff0c\u6027\u80fd\u968f\u7ef4\u5ea6\u589e\u52a0\u800c\u63d0\u5347\u4f46\u6536\u76ca\u9012\u51cf\uff0c\u4e14\u4efb\u52a1\u5bf9\u9f50\u7a0b\u5ea6\u5f71\u54cd\u6027\u80fd\u53ef\u9884\u6d4b\u6027\u3002", "motivation": "\u968f\u7740\u7a20\u5bc6\u68c0\u7d22\u4efb\u52a1\u590d\u6742\u6027\u589e\u52a0\uff0c\u57fa\u4e8e\u5355\u5411\u91cf\u548c\u5185\u79ef\u7684\u5e95\u5c42\u6570\u636e\u7ed3\u6784\u4e0e\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u7684\u5c40\u9650\u6027\u65e5\u76ca\u660e\u663e\u3002\u5148\u524d\u7814\u7a76\u63ed\u793a\u4e86\u4e0e\u5d4c\u5165\u7ef4\u5ea6\u76f8\u5173\u7684\u7406\u8bba\u9650\u5236\uff0c\u7406\u89e3\u5d4c\u5165\u7ef4\u5ea6\u7f29\u653e\u5982\u4f55\u5f71\u54cd\u68c0\u7d22\u6027\u80fd\u5bf9\u4e8e\u6784\u5efa\u5e73\u8861\u6548\u679c\u4e0e\u6548\u7387\u7684\u4e0b\u4e00\u4ee3\u68c0\u7d22\u6a21\u578b\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u4e24\u4e2a\u6a21\u578b\u5bb6\u65cf\u548c\u4e00\u7cfb\u5217\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u8fdb\u884c\u7efc\u5408\u5b9e\u9a8c\uff0c\u6784\u5efa\u8be6\u7ec6\u7684\u5d4c\u5165\u7f29\u653e\u884c\u4e3a\u56fe\u666f\u3002\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u5d4c\u5165\u7ef4\u5ea6\u4e0e\u68c0\u7d22\u6027\u80fd\u7684\u5173\u7cfb\uff0c\u63a8\u5bfc\u7f29\u653e\u89c4\u5f8b\u3002", "result": "\u53d1\u73b0\u7f29\u653e\u884c\u4e3a\u7b26\u5408\u5e42\u5f8b\u5173\u7cfb\uff0c\u80fd\u591f\u4ec5\u57fa\u4e8e\u5d4c\u5165\u7ef4\u5ea6\u63a8\u5bfc\u6027\u80fd\u7f29\u653e\u89c4\u5f8b\uff0c\u4ee5\u53ca\u8003\u8651\u5d4c\u5165\u7ef4\u5ea6\u548c\u6a21\u578b\u89c4\u6a21\u7684\u8054\u5408\u89c4\u5f8b\u3002\u5bf9\u4e8e\u4e0e\u8bad\u7ec3\u4efb\u52a1\u5bf9\u9f50\u7684\u8bc4\u4f30\u4efb\u52a1\uff0c\u6027\u80fd\u968f\u5d4c\u5165\u7ef4\u5ea6\u589e\u52a0\u800c\u6301\u7eed\u6539\u5584\u4f46\u6536\u76ca\u9012\u51cf\uff1b\u5bf9\u4e8e\u4e0e\u8bad\u7ec3\u4efb\u52a1\u5bf9\u9f50\u5ea6\u8f83\u4f4e\u7684\u8bc4\u4f30\u6570\u636e\uff0c\u6027\u80fd\u53ef\u9884\u6d4b\u6027\u8f83\u5dee\uff0c\u67d0\u4e9b\u4efb\u52a1\u4e2d\u8f83\u5927\u5d4c\u5165\u7ef4\u5ea6\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7406\u89e3\u5d4c\u5165\u7684\u5c40\u9650\u6027\u53ca\u5176\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u5e76\u4e3a\u9009\u62e9\u6a21\u578b\u548c\u5d4c\u5165\u7ef4\u5ea6\u4ee5\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\u540c\u65f6\u964d\u4f4e\u5b58\u50a8\u548c\u8ba1\u7b97\u6210\u672c\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\u3002"}}
{"id": "2602.05681", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.05681", "abs": "https://arxiv.org/abs/2602.05681", "authors": ["Anna Lunghi", "Mattia Piccinato", "Matteo Castiglioni", "Alberto Marchesi"], "title": "A Stronger Benchmark for Online Bilateral Trade: From Fixed Prices to Distributions", "comment": null, "summary": "We study online bilateral trade, where a learner facilitates repeated exchanges between a buyer and a seller to maximize the Gain From Trade (GFT), i.e., the social welfare. In doing so, the learner must guarantee not to subsidize the market. This constraint is usually imposed per round through Weak Budget Balance (WBB). Despite that, Bernasconi et al. [2024] show that a Global Budget Balance (GBB) constraint on the profit -- enforced over the entire time horizon -- can improve the GFT by a multiplicative factor of two. While this might appear to be a marginal relaxation, this implies that all existing WBB-focused algorithms suffer linear regret when measured against the GBB optimum. In this work, we provide the first algorithm to achieve sublinear regret against the GBB benchmark in stochastic environments under one-bit feedback. In particular, we show that when the joint distribution of valuations has a bounded density, our algorithm achieves $\\widetilde{\\mathcal{O}}(T^{3/4})$ regret. Our result shows that there is no separation between the one-dimensional problem of learning the optimal WBB price and the two-dimensional problem of learning the optimal GBB distribution over pairs of prices.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5728\u7ebf\u53cc\u8fb9\u4ea4\u6613\uff0c\u5b66\u4e60\u8005\u5728\u91cd\u590d\u4ea4\u6613\u4e2d\u6700\u5927\u5316\u4ea4\u6613\u6536\u76ca(GFT)\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e0d\u8865\u8d34\u5e02\u573a\u3002\u73b0\u6709\u7b97\u6cd5\u57fa\u4e8e\u6bcf\u8f6e\u5f31\u9884\u7b97\u5e73\u8861(WBB)\uff0c\u4f46\u5168\u5c40\u9884\u7b97\u5e73\u8861(GBB)\u7ea6\u675f\u53ef\u5c06GFT\u63d0\u5347\u4e24\u500d\u3002\u4f5c\u8005\u9996\u6b21\u63d0\u51fa\u5728\u968f\u673a\u73af\u5883\u4e0b\u5b9e\u73b0\u9488\u5bf9GBB\u57fa\u51c6\u7684\u6b21\u7ebf\u6027\u9057\u61be\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u5728\u7ebf\u53cc\u8fb9\u4ea4\u6613\u7b97\u6cd5\u4e3b\u8981\u5173\u6ce8\u6bcf\u8f6e\u5f31\u9884\u7b97\u5e73\u8861(WBB)\u7ea6\u675f\uff0c\u4f46Bernasconi\u7b49\u4eba[2024]\u53d1\u73b0\u5168\u5c40\u9884\u7b97\u5e73\u8861(GBB)\u7ea6\u675f\u80fd\u663e\u8457\u63d0\u5347\u4ea4\u6613\u6536\u76ca\u3002\u7136\u800c\uff0c\u6240\u6709\u73b0\u6709WBB\u7b97\u6cd5\u5728GBB\u57fa\u51c6\u4e0b\u90fd\u6709\u7ebf\u6027\u9057\u61be\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u80fd\u5728GBB\u7ea6\u675f\u4e0b\u5b9e\u73b0\u6b21\u7ebf\u6027\u9057\u61be\u7684\u65b0\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u9996\u4e2a\u5728\u968f\u673a\u73af\u5883\u4e0b\u9488\u5bf9GBB\u57fa\u51c6\u7684\u6b21\u7ebf\u6027\u9057\u61be\u7b97\u6cd5\u3002\u5728\u4f30\u503c\u8054\u5408\u5206\u5e03\u5177\u6709\u6709\u754c\u5bc6\u5ea6\u7684\u6761\u4ef6\u4e0b\uff0c\u7b97\u6cd5\u4f7f\u7528\u5355\u6bd4\u7279\u53cd\u9988\uff0c\u5b9e\u73b0$\\widetilde{\\mathcal{O}}(T^{3/4})$\u7684\u9057\u61be\u754c\u3002\u7b97\u6cd5\u8868\u660e\u5b66\u4e60\u6700\u4f18WBB\u4ef7\u683c\u7684\u4e00\u7ef4\u95ee\u9898\u4e0e\u5b66\u4e60\u6700\u4f18GBB\u4ef7\u683c\u5bf9\u5206\u5e03\u7684\u4e8c\u7ef4\u95ee\u9898\u4e4b\u95f4\u6ca1\u6709\u5206\u79bb\u3002", "result": "\u5f53\u4f30\u503c\u8054\u5408\u5206\u5e03\u5177\u6709\u6709\u754c\u5bc6\u5ea6\u65f6\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u5355\u6bd4\u7279\u53cd\u9988\u4e0b\u5b9e\u73b0$\\widetilde{\\mathcal{O}}(T^{3/4})$\u7684\u9057\u61be\u754c\u3002\u8fd9\u662f\u9996\u4e2a\u5728\u968f\u673a\u73af\u5883\u4e0b\u9488\u5bf9GBB\u57fa\u51c6\u5b9e\u73b0\u6b21\u7ebf\u6027\u9057\u61be\u7684\u7b97\u6cd5\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "conclusion": "\u5168\u5c40\u9884\u7b97\u5e73\u8861(GBB)\u7ea6\u675f\u76f8\u6bd4\u5f31\u9884\u7b97\u5e73\u8861(WBB)\u80fd\u663e\u8457\u63d0\u5347\u5728\u7ebf\u53cc\u8fb9\u4ea4\u6613\u7684\u6027\u80fd\u3002\u63d0\u51fa\u7684\u7b97\u6cd5\u9996\u6b21\u5728\u968f\u673a\u73af\u5883\u4e0b\u5b9e\u73b0\u9488\u5bf9GBB\u57fa\u51c6\u7684\u6b21\u7ebf\u6027\u9057\u61be\uff0c\u8bc1\u660e\u5b66\u4e60\u6700\u4f18WBB\u4ef7\u683c\u4e0e\u5b66\u4e60\u6700\u4f18GBB\u4ef7\u683c\u5bf9\u5206\u5e03\u4e4b\u95f4\u6ca1\u6709\u6839\u672c\u6027\u96be\u5ea6\u5dee\u5f02\u3002"}}
{"id": "2602.05452", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.05452", "abs": "https://arxiv.org/abs/2602.05452", "authors": ["Alexandros Zeakis", "George Papadakis", "Dimitrios Skoutas", "Manolis Koubarakis"], "title": "DistillER: Knowledge Distillation in Entity Resolution with Large Language Models", "comment": null, "summary": "Recent advances in Entity Resolution (ER) have leveraged Large Language Models (LLMs), achieving strong performance but at the cost of substantial computational resources or high financial overhead. Existing LLM-based ER approaches operate either in unsupervised settings and rely on very large and costly models, or in supervised settings and require ground-truth annotations, leaving a critical gap between time efficiency and effectiveness. To make LLM-powered ER more practical, we investigate Knowledge Distillation (KD) as a means to transfer knowledge from large, effective models (Teachers) to smaller, more efficient models (Students) without requiring gold labels. We introduce DistillER, the first framework that systematically bridges this gap across three dimensions: (i) Data Selection, where we study strategies for identifying informative subsets of data; (ii) Knowledge Elicitation, where we compare single- and multi-teacher settings across LLMs and smaller language models (SLMs); and (iii) Distillation Algorithms, where we evaluate supervised fine-tuning and reinforcement learning approaches. Our experiments reveal that supervised fine-tuning of Students on noisy labels generated by LLM Teachers consistently outperforms alternative KD strategies, while also enabling high-quality explanation generation. Finally, we benchmark DistillER against established supervised and unsupervised ER methods based on LLMs and SLMs, demonstrating significant improvements in both effectiveness and efficiency.", "AI": {"tldr": "DistillER\u662f\u4e00\u4e2a\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u8f6c\u79fb\u5230\u5c0f\u6a21\u578b\u7684\u5b9e\u4f53\u89e3\u6790\u6846\u67b6\uff0c\u65e0\u9700\u9ec4\u91d1\u6807\u7b7e\uff0c\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u5b9e\u4f53\u89e3\u6790\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u7684\u5927\u6a21\u578b\uff0c\u8981\u4e48\u9700\u8981\u76d1\u7763\u5b66\u4e60\u7684\u6807\u6ce8\u6570\u636e\uff0c\u5b58\u5728\u6548\u7387\u4e0e\u6548\u679c\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002\u9700\u8981\u4e00\u79cd\u66f4\u5b9e\u7528\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faDistillER\u6846\u67b6\uff0c\u4ece\u4e09\u4e2a\u7ef4\u5ea6\u7cfb\u7edf\u89e3\u51b3\u77e5\u8bc6\u84b8\u998f\u95ee\u9898\uff1a\u6570\u636e\u9009\u62e9\uff08\u8bc6\u522b\u4fe1\u606f\u4e30\u5bcc\u7684\u5b50\u96c6\uff09\u3001\u77e5\u8bc6\u63d0\u53d6\uff08\u6bd4\u8f83\u5355/\u591a\u6559\u5e08\u8bbe\u7f6e\uff09\u3001\u84b8\u998f\u7b97\u6cd5\uff08\u8bc4\u4f30\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728LLM\u6559\u5e08\u751f\u6210\u7684\u566a\u58f0\u6807\u7b7e\u4e0a\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u7684\u5b66\u751f\u6a21\u578b\uff0c\u6301\u7eed\u4f18\u4e8e\u5176\u4ed6\u77e5\u8bc6\u84b8\u998f\u7b56\u7565\uff0c\u540c\u65f6\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u89e3\u91ca\u3002DistillER\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u90fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u77e5\u8bc6\u84b8\u998f\u662f\u4f7fLLM\u9a71\u52a8\u7684\u5b9e\u4f53\u89e3\u6790\u66f4\u5b9e\u7528\u7684\u6709\u6548\u9014\u5f84\uff0cDistillER\u6846\u67b6\u6210\u529f\u586b\u8865\u4e86\u6548\u7387\u4e0e\u6548\u679c\u4e4b\u95f4\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.05405", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.05405", "abs": "https://arxiv.org/abs/2602.05405", "authors": ["Yi Chen", "Li Ming", "Chong Han"], "title": "Enabling Large-Scale Channel Sounding for 6G: A Framework for Sparse Sampling and Multipath Component Extraction", "comment": "13 pages", "summary": "Realizing the 6G vision of artificial intelligence (AI) and integrated sensing and communication (ISAC) critically requires large-scale real-world channel datasets for channel modeling and data-driven AI models. However, traditional frequency-domain channel sounding methods suffer from low efficiency due to a prohibitive number of frequency points to avoid delay ambiguity. This paper proposes a novel channel sounding framework involving sparse nonuniform sampling along with a likelihood-rectified space-alternating generalized expectation-maximization (LR-SAGE) algorithm for multipath component extraction. This framework enables the acquisition of channel datasets that are tens or even hundreds of times larger within the same channel measurement duration, thereby providing the massive data required to harness the full potential of AI scaling laws. Specifically, we propose a Parabolic Frequency Sampling (PFS) strategy that non-uniformly distributes frequency points, effectively eliminating delay ambiguity while reducing sampling overhead by orders of magnitude. To efficiently extract multipath components (MPCs) from the channel data measured by PFS, we develop a LR-SAGE algorithm, rectifying the likelihood distortion caused by nonuniform sampling and molecular absorption effect. Simulation results and experimental validation at 280--300~GHz confirm that the proposed PFS and LR-SAGE algorithm not only achieve 50$\\times$ faster measurement, a 98\\% reduction in data volume and a 99.96\\% reduction in post-processing computational complexity, but also successfully captures MPCs and channel characteristics consistent with traditional exhaustive measurements, demonstrating its potential as a fundamental enabler for constructing the massive ISAC datasets required by AI-native 6G systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u4fe1\u9053\u6d4b\u91cf\u6846\u67b6\uff0c\u901a\u8fc7\u7a00\u758f\u975e\u5747\u5300\u91c7\u6837\u548cLR-SAGE\u7b97\u6cd5\uff0c\u57286G\u7cfb\u7edf\u4e2d\u5b9e\u73b050\u500d\u6d4b\u91cf\u52a0\u901f\u548c99.96%\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4e", "motivation": "\u5b9e\u73b06G\u7684AI\u548cISAC\u613f\u666f\u9700\u8981\u5927\u89c4\u6a21\u771f\u5b9e\u4fe1\u9053\u6570\u636e\u96c6\uff0c\u4f46\u4f20\u7edf\u9891\u57df\u4fe1\u9053\u6d4b\u91cf\u65b9\u6cd5\u56e0\u907f\u514d\u5ef6\u8fdf\u6a21\u7cca\u9700\u8981\u5927\u91cf\u9891\u70b9\u800c\u6548\u7387\u4f4e\u4e0b", "method": "\u63d0\u51fa\u629b\u7269\u7ebf\u9891\u7387\u91c7\u6837(PFS)\u7b56\u7565\u8fdb\u884c\u975e\u5747\u5300\u9891\u70b9\u5206\u5e03\uff0c\u7ed3\u5408\u4f3c\u7136\u6821\u6b63\u7a7a\u95f4\u4ea4\u66ff\u5e7f\u4e49\u671f\u671b\u6700\u5927\u5316(LR-SAGE)\u7b97\u6cd5\u63d0\u53d6\u591a\u5f84\u5206\u91cf", "result": "\u5728280-300GHz\u9a8c\u8bc1\u4e2d\uff0c\u5b9e\u73b050\u500d\u6d4b\u91cf\u52a0\u901f\u300198%\u6570\u636e\u91cf\u51cf\u5c11\u548c99.96%\u540e\u5904\u7406\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u4f20\u7edf\u6d4b\u91cf\u4e00\u81f4\u7684\u591a\u5f84\u5206\u91cf\u6355\u83b7", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6784\u5efaAI\u539f\u751f6G\u7cfb\u7edf\u6240\u9700\u7684\u5927\u89c4\u6a21ISAC\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u57fa\u7840\u4f7f\u80fd\u6280\u672f\uff0c\u80fd\u591f\u5145\u5206\u5229\u7528AI\u6269\u5c55\u5b9a\u5f8b\u7684\u6f5c\u529b"}}
{"id": "2602.05193", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2602.05193", "abs": "https://arxiv.org/abs/2602.05193", "authors": ["Xingfu Li", "Yongping Wang"], "title": "Polynomial-Time Solutions for Longest Common Subsequence Related Problems Between a Sequence and a Pangenome Graph", "comment": "13 pages", "summary": "A pangenome captures the genetic diversity across multiple individuals simultaneously, providing a more comprehensive reference for genome analysis than a single linear genome, which may introduce allele bias. A widely adopted pangenome representation is a node-labeled directed graph, wherein the paths correspond to plausible genomic sequences within a species. Consequently, evaluating sequence-to-pangenome graph similarity constitutes a fundamental task in pangenome construction and analysis. This study explores the Longest Common Subsequence (LCS) problem and three of its variants involving a sequence and a pangenome graph. We present four polynomial-time reductions that transform these LCS-related problems into the longest path problem in a directed acyclic graph (DAG). These reductions demonstrate that all four problems can be solved in polynomial time, establishing their membership in the complexity class P.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u5e8f\u5217\u5230\u6cdb\u57fa\u56e0\u7ec4\u56fe\u7684LCS\u95ee\u9898\u53ca\u5176\u53d8\u4f53\u8f6c\u5316\u4e3aDAG\u4e2d\u7684\u6700\u957f\u8def\u5f84\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u95ee\u9898\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u53ef\u89e3\u6027\u3002", "motivation": "\u6cdb\u57fa\u56e0\u7ec4\u6bd4\u5355\u4e00\u7ebf\u6027\u57fa\u56e0\u7ec4\u80fd\u66f4\u597d\u5730\u6355\u6349\u9057\u4f20\u591a\u6837\u6027\uff0c\u4f46\u9700\u8981\u6709\u6548\u7684\u5e8f\u5217\u5230\u6cdb\u57fa\u56e0\u7ec4\u56fe\u76f8\u4f3c\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002LCS\u95ee\u9898\u53ca\u5176\u53d8\u4f53\u662f\u8bc4\u4f30\u8fd9\u79cd\u76f8\u4f3c\u6027\u7684\u57fa\u672c\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u4e86\u56db\u79cd\u591a\u9879\u5f0f\u65f6\u95f4\u5f52\u7ea6\uff0c\u5c06\u5e8f\u5217\u5230\u6cdb\u57fa\u56e0\u7ec4\u56fe\u7684LCS\u95ee\u9898\u53ca\u5176\u4e09\u4e2a\u53d8\u4f53\u8f6c\u5316\u4e3a\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u4e2d\u7684\u6700\u957f\u8def\u5f84\u95ee\u9898\u3002", "result": "\u6240\u6709\u56db\u4e2a\u95ee\u9898\u90fd\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u89e3\u51b3\uff0c\u8bc1\u660e\u4e86\u5b83\u4eec\u5c5e\u4e8e\u590d\u6742\u5ea6\u7c7bP\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5e8f\u5217\u5230\u6cdb\u57fa\u56e0\u7ec4\u56fe\u7684\u76f8\u4f3c\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u9ad8\u6548\u7b97\u6cd5\uff0c\u5bf9\u6cdb\u57fa\u56e0\u7ec4\u6784\u5efa\u548c\u5206\u6790\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.05152", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.05152", "abs": "https://arxiv.org/abs/2602.05152", "authors": ["Yuntong Hu", "Sha Li", "Naren Ramakrishnan", "Liang Zhao"], "title": "RAG without Forgetting: Continual Query-Infused Key Memory", "comment": "24 pages, 12 figures", "summary": "Retrieval-augmented generation (RAG) systems commonly improve robustness via query-time adaptations such as query expansion and iterative retrieval. While effective, these approaches are inherently stateless: adaptations are recomputed for each query and discarded thereafter, precluding cumulative learning and repeatedly incurring inference-time cost. Index-side approaches like key expansion introduce persistence but rely on offline preprocessing or heuristic updates that are weakly aligned with downstream task utility, leading to semantic drift and noise accumulation. We propose Evolving Retrieval Memory (ERM), a training-free framework that transforms transient query-time gains into persistent retrieval improvements. ERM updates the retrieval index through correctness-gated feedback, selectively attributes atomic expansion signals to the document keys they benefit, and progressively evolves keys via stable, norm-bounded updates. We show that query and key expansion are theoretically equivalent under standard similarity functions and prove convergence of ERM's selective updates, amortizing optimal query expansion into a stable index with zero inference-time overhead. Experiments on BEIR and BRIGHT across 13 domains demonstrate consistent gains in retrieval and generation, particularly on reasoning-intensive tasks, at native retrieval speed.", "AI": {"tldr": "ERM\u6846\u67b6\u5c06\u67e5\u8be2\u65f6\u7684\u4e34\u65f6\u6269\u5c55\u8f6c\u5316\u4e3a\u6301\u4e45\u7684\u68c0\u7d22\u6539\u8fdb\uff0c\u901a\u8fc7\u6b63\u786e\u6027\u95e8\u63a7\u53cd\u9988\u9009\u62e9\u6027\u66f4\u65b0\u6587\u6863\u952e\uff0c\u5b9e\u73b0\u96f6\u63a8\u7406\u5f00\u9500\u7684\u6301\u7eed\u5b66\u4e60\u3002", "motivation": "\u73b0\u6709RAG\u7cfb\u7edf\u5728\u67e5\u8be2\u65f6\u8fdb\u884c\u6269\u5c55\uff08\u5982\u67e5\u8be2\u6269\u5c55\u3001\u8fed\u4ee3\u68c0\u7d22\uff09\u662f\u4e34\u65f6\u6027\u7684\uff0c\u6bcf\u6b21\u67e5\u8be2\u90fd\u9700\u8981\u91cd\u65b0\u8ba1\u7b97\uff0c\u65e0\u6cd5\u7d2f\u79ef\u5b66\u4e60\u4e14\u4ea7\u751f\u91cd\u590d\u63a8\u7406\u6210\u672c\u3002\u7d22\u5f15\u7aef\u65b9\u6cd5\uff08\u5982\u952e\u6269\u5c55\uff09\u867d\u7136\u6301\u4e45\u4f46\u4f9d\u8d56\u79bb\u7ebf\u9884\u5904\u7406\u6216\u542f\u53d1\u5f0f\u66f4\u65b0\uff0c\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6548\u7528\u5bf9\u9f50\u5f31\uff0c\u5bfc\u81f4\u8bed\u4e49\u6f02\u79fb\u548c\u566a\u58f0\u7d2f\u79ef\u3002", "method": "\u63d0\u51faERM\uff08\u6f14\u5316\u68c0\u7d22\u8bb0\u5fc6\uff09\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u6b63\u786e\u6027\u95e8\u63a7\u53cd\u9988\u66f4\u65b0\u68c0\u7d22\u7d22\u5f15\uff1b2\uff09\u5c06\u539f\u5b50\u6269\u5c55\u4fe1\u53f7\u9009\u62e9\u6027\u5f52\u56e0\u5230\u53d7\u76ca\u7684\u6587\u6863\u952e\uff1b3\uff09\u901a\u8fc7\u7a33\u5b9a\u3001\u8303\u6570\u6709\u754c\u7684\u66f4\u65b0\u9010\u6b65\u6f14\u5316\u952e\u3002\u7406\u8bba\u8bc1\u660e\u67e5\u8be2\u6269\u5c55\u548c\u952e\u6269\u5c55\u5728\u6807\u51c6\u76f8\u4f3c\u5ea6\u51fd\u6570\u4e0b\u7b49\u4ef7\uff0c\u5e76\u8bc1\u660eERM\u9009\u62e9\u6027\u66f4\u65b0\u7684\u6536\u655b\u6027\u3002", "result": "\u5728BEIR\u548cBRIGHT\u768413\u4e2a\u9886\u57df\u5b9e\u9a8c\u4e2d\uff0c\u68c0\u7d22\u548c\u751f\u6210\u6027\u80fd\u5747\u83b7\u5f97\u4e00\u81f4\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u751f\u68c0\u7d22\u901f\u5ea6\u3002", "conclusion": "ERM\u6210\u529f\u5c06\u67e5\u8be2\u65f6\u7684\u4e34\u65f6\u589e\u76ca\u8f6c\u5316\u4e3a\u6301\u4e45\u7684\u68c0\u7d22\u6539\u8fdb\uff0c\u5b9e\u73b0\u4e86\u96f6\u63a8\u7406\u5f00\u9500\u7684\u6301\u7eed\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u73b0\u6709RAG\u7cfb\u7edf\u65e0\u6cd5\u7d2f\u79ef\u5b66\u4e60\u548c\u91cd\u590d\u8ba1\u7b97\u7684\u95ee\u9898\u3002"}}
{"id": "2602.05835", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.05835", "abs": "https://arxiv.org/abs/2602.05835", "authors": ["Kiarash Banihashem", "Natalie Collina", "Aleksandrs Slivkins"], "title": "Bandit Social Learning with Exploration Episodes", "comment": null, "summary": "We study a stylized social learning dynamics where self-interested agents collectively follow a simple multi-armed bandit protocol. Each agent controls an ``episode\": a short sequence of consecutive decisions. Motivating applications include users repeatedly interacting with an AI, or repeatedly shopping at a marketplace. While agents are incentivized to explore within their respective episodes, we show that the aggregate exploration fails: e.g., its Bayesian regret grows linearly over time. In fact, such failure is a (very) typical case, not just a worst-case scenario. This conclusion persists even if an agent's per-episode utility is some fixed function of the per-round outcomes: e.g., $\\min$ or $\\max$, not just the sum. Thus, externally driven exploration is needed even when some amount of exploration happens organically.", "AI": {"tldr": "\u7814\u7a76\u793e\u4f1a\u5b66\u4e60\u52a8\u6001\u4e2d\u81ea\u5229\u4ee3\u7406\u4eba\u7684\u96c6\u4f53\u63a2\u7d22\u5931\u8d25\u95ee\u9898\uff0c\u5373\u4f7f\u4e2a\u4f53\u5728\u5404\u81ea\u51b3\u7b56\u5e8f\u5217\u4e2d\u6709\u63a2\u7d22\u52a8\u673a\uff0c\u4f46\u6574\u4f53\u63a2\u7d22\u4ecd\u7136\u4e0d\u8db3\u3002", "motivation": "\u7814\u7a76\u5728\u91cd\u590d\u4ea4\u4e92\u573a\u666f\uff08\u5982\u7528\u6237\u4e0eAI\u4e92\u52a8\u3001\u5e02\u573a\u8d2d\u7269\uff09\u4e2d\uff0c\u81ea\u5229\u4ee3\u7406\u4eba\u9075\u5faa\u591a\u81c2\u8001\u864e\u673a\u534f\u8bae\u65f6\u7684\u96c6\u4f53\u63a2\u7d22\u884c\u4e3a\u3002\u867d\u7136\u4e2a\u4f53\u6709\u63a2\u7d22\u52a8\u673a\uff0c\u4f46\u9700\u8981\u4e86\u89e3\u6574\u4f53\u63a2\u7d22\u662f\u5426\u6709\u6548\u3002", "method": "\u91c7\u7528\u98ce\u683c\u5316\u7684\u793e\u4f1a\u5b66\u4e60\u52a8\u6001\u6a21\u578b\uff0c\u6bcf\u4e2a\u4ee3\u7406\u4eba\u63a7\u5236\u4e00\u4e2a\"\u7247\u6bb5\"\uff08\u8fde\u7eed\u51b3\u7b56\u5e8f\u5217\uff09\uff0c\u5206\u6790\u81ea\u5229\u4ee3\u7406\u4eba\u5728\u591a\u81c2\u8001\u864e\u673a\u534f\u8bae\u4e0b\u7684\u96c6\u4f53\u884c\u4e3a\u3002", "result": "\u53d1\u73b0\u96c6\u4f53\u63a2\u7d22\u5931\u8d25\uff1a\u8d1d\u53f6\u65af\u9057\u61be\u968f\u65f6\u95f4\u7ebf\u6027\u589e\u957f\u3002\u8fd9\u79cd\u5931\u8d25\u662f\u5178\u578b\u60c5\u51b5\u800c\u975e\u6700\u574f\u60c5\u51b5\uff0c\u5373\u4f7f\u4ee3\u7406\u4eba\u6548\u7528\u51fd\u6570\u662f\u6bcf\u8f6e\u7ed3\u679c\u7684\u56fa\u5b9a\u51fd\u6570\uff08\u5982\u6700\u5c0f\u503c\u3001\u6700\u5927\u503c\u6216\u603b\u548c\uff09\u4e5f\u6210\u7acb\u3002", "conclusion": "\u5373\u4f7f\u5b58\u5728\u4e00\u5b9a\u7a0b\u5ea6\u7684\u6709\u673a\u63a2\u7d22\uff0c\u4ecd\u9700\u8981\u5916\u90e8\u9a71\u52a8\u7684\u63a2\u7d22\u673a\u5236\u6765\u786e\u4fdd\u6709\u6548\u7684\u96c6\u4f53\u5b66\u4e60\u3002"}}
{"id": "2602.05503", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.05503", "abs": "https://arxiv.org/abs/2602.05503", "authors": ["Christopher Spinrath", "Angela Bonifati", "Rachid Echahed"], "title": "Repairing Property Graphs under PG-Constraints", "comment": "This paper, without the appendix, has been accepted for publication in Volume 19 of PVLDB", "summary": "Recent standardization efforts for graph databases lead to standard query languages like GQL and SQL/PGQ, and constraint languages like Property Graph Constraints (PG-Constraints). In this paper, we embark on the study of repairing property graphs under PG-Constraints. We identify a significant subset of PG-Constraints, encoding denial constraints and including recursion as a key feature, while still permitting automata-based structural analyses of errors. We present a comprehensive repair pipeline for these constraints to repair Property Graphs, involving changes in the graph topology and leading to node, edge and, optionally, label deletions. We investigate three algorithmic strategies for the repair procedure, based on Integer Linear Programming (ILP), a naive, and an LP-guided greedy algorithm. Our experiments on various real-world datasets reveal that repairing with label deletions can achieve a 59% reduction in deletions compared to node/edge deletions. Moreover, the LP-guided greedy algorithm offers a runtime advantage of up to 97% compared to the ILP strategy, while matching the same quality.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728PG-Constraints\u7ea6\u675f\u4e0b\u4fee\u590d\u5c5e\u6027\u56fe\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6574\u6570\u7ebf\u6027\u89c4\u5212\u3001\u6734\u7d20\u7b97\u6cd5\u548cLP\u5f15\u5bfc\u8d2a\u5fc3\u7b97\u6cd5\u7684\u4e09\u79cd\u4fee\u590d\u7b56\u7565\uff0c\u5b9e\u9a8c\u663e\u793a\u6807\u7b7e\u5220\u9664\u6bd4\u8282\u70b9/\u8fb9\u5220\u9664\u51cf\u5c1159%\u7684\u5220\u9664\u91cf\uff0cLP\u5f15\u5bfc\u8d2a\u5fc3\u7b97\u6cd5\u6bd4ILP\u7b56\u7565\u8fd0\u884c\u65f6\u95f4\u51cf\u5c1197%\u4e14\u8d28\u91cf\u76f8\u5f53\u3002", "motivation": "\u968f\u7740\u56fe\u6570\u636e\u5e93\u6807\u51c6\u5316\u53d1\u5c55\uff0c\u51fa\u73b0\u4e86GQL\u3001SQL/PGQ\u7b49\u6807\u51c6\u67e5\u8be2\u8bed\u8a00\u548cPG-Constraints\u7ea6\u675f\u8bed\u8a00\u3002\u5f53\u524d\u9700\u8981\u7814\u7a76\u5728PG-Constraints\u7ea6\u675f\u4e0b\u5982\u4f55\u6709\u6548\u4fee\u590d\u5c5e\u6027\u56fe\uff0c\u4ee5\u89e3\u51b3\u56fe\u6570\u636e\u4e2d\u7684\u7ea6\u675f\u8fdd\u53cd\u95ee\u9898\u3002", "method": "\u8bc6\u522bPG-Constraints\u7684\u91cd\u8981\u5b50\u96c6\uff0c\u652f\u6301\u5426\u5b9a\u7ea6\u675f\u548c\u9012\u5f52\u7279\u6027\uff0c\u5141\u8bb8\u57fa\u4e8e\u81ea\u52a8\u673a\u7684\u7ed3\u6784\u9519\u8bef\u5206\u6790\u3002\u63d0\u51fa\u5b8c\u6574\u7684\u5c5e\u6027\u56fe\u4fee\u590d\u6d41\u7a0b\uff0c\u6d89\u53ca\u56fe\u62d3\u6251\u7ed3\u6784\u53d8\u66f4\uff0c\u652f\u6301\u8282\u70b9\u3001\u8fb9\u548c\u53ef\u9009\u6807\u7b7e\u5220\u9664\u3002\u7814\u7a76\u4e86\u4e09\u79cd\u7b97\u6cd5\u7b56\u7565\uff1a\u6574\u6570\u7ebf\u6027\u89c4\u5212(ILP)\u3001\u6734\u7d20\u7b97\u6cd5\u548cLP\u5f15\u5bfc\u8d2a\u5fc3\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u6807\u7b7e\u5220\u9664\u76f8\u6bd4\u8282\u70b9/\u8fb9\u5220\u9664\u53ef\u4ee5\u51cf\u5c1159%\u7684\u5220\u9664\u64cd\u4f5c\u3002LP\u5f15\u5bfc\u8d2a\u5fc3\u7b97\u6cd5\u76f8\u6bd4ILP\u7b56\u7565\u5728\u8fd0\u884c\u65f6\u95f4\u4e0a\u51cf\u5c11\u9ad8\u8fbe97%\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u7684\u4fee\u590d\u8d28\u91cf\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aPG-Constraints\u7ea6\u675f\u4e0b\u7684\u5c5e\u6027\u56fe\u4fee\u590d\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0cLP\u5f15\u5bfc\u8d2a\u5fc3\u7b97\u6cd5\u5728\u6548\u7387\u548c\u8d28\u91cf\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u6807\u7b7e\u5220\u9664\u7b56\u7565\u663e\u8457\u51cf\u5c11\u4e86\u4fee\u590d\u6210\u672c\u3002"}}
{"id": "2602.05462", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.05462", "abs": "https://arxiv.org/abs/2602.05462", "authors": ["Kuo Shang", "Chen Yuan", "Ruiqi Zhu"], "title": "Explicit List-Decodable Linearized Reed-Solomon Subspace Codes via Subspace Designs", "comment": "28 pages", "summary": "The sum-rank metric is the mixture of the Hamming and rank metrics. The sum-rank metric found its application in network coding, locally repairable codes, space-time coding, and quantum-resistant cryptography. Linearized Reed-Solomon (LRS) codes are the sum-rank analogue of Reed-Solomon codes and strictly generalize both Reed-Solomon and Gabidulin codes.\n  In this work, we construct an explicit family of $\\mathbb{F}_h$-linear sum-rank metric codes over arbitrary fields $\\mathbb{F}_h$. Our construction enables efficient list decoding up to a fraction $\u03c1$ of errors in the sum-rank metric with rate $1-\u03c1-\\varepsilon$, for any desired $\u03c1\\in (0,1)$ and $\\varepsilon>0$. Our codes are subcodes of LRS codes, obtained by restricting message polynomials to an $\\mathbb{F}_h$-subspace derived from subspace designs, and the decoding list size is bounded by $h^{\\mathrm{poly}(1/\\varepsilon)}$.\n  Beyond the standard LRS setting, we further extend our linear-algebraic decoding framework to folded Linearized Reed-Solomon (FLRS) codes. We show that folded evaluations satisfy appropriate interpolation conditions and that the corresponding solution space forms a low-dimensional, structured affine subspace. This structure enables effective control of the list size and yields the first explicit positive-rate FLRS subcodes that are efficiently list decodable beyond the unique-decoding radius. To the best of our knowledge, this also constitutes the first explicit construction of positive-rate sum-rank metric codes that admit efficient list decoding beyond the unique decoding radius, thereby providing a new general framework for constructing efficiently decodable codes under the sum-rank metric.", "AI": {"tldr": "\u672c\u6587\u6784\u9020\u4e86\u5728\u4efb\u610f\u57df\u4e0a\u7684\ud835\udd3d_h-\u7ebf\u6027sum-rank\u5ea6\u91cf\u7801\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u5217\u8868\u8bd1\u7801\uff0c\u8bd1\u7801\u534a\u5f84\u8fbe\u5230\u03c1\uff0c\u7801\u73871-\u03c1-\u03b5\uff0c\u5217\u8868\u5927\u5c0f\u53d7h^poly(1/\u03b5)\u9650\u5236\u3002\u540c\u65f6\u6269\u5c55\u5230\u6298\u53e0\u7ebf\u6027\u5316Reed-Solomon\u7801\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u8d85\u8d8a\u552f\u4e00\u8bd1\u7801\u534a\u5f84\u7684\u9ad8\u6548\u5217\u8868\u8bd1\u7801\u3002", "motivation": "sum-rank\u5ea6\u91cf\u5728\u591a\u79cd\u7f16\u7801\u5e94\u7528\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u8d85\u8d8a\u552f\u4e00\u8bd1\u7801\u534a\u5f84\u7684\u9ad8\u6548\u5217\u8868\u8bd1\u7801\u6784\u9020\u3002\u73b0\u6709\u7ebf\u6027\u5316Reed-Solomon\u7801\u867d\u7136\u63a8\u5e7f\u4e86Reed-Solomon\u548cGabidulin\u7801\uff0c\u4f46\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u7a81\u7834\u552f\u4e00\u8bd1\u7801\u9650\u5236\u3002", "method": "\u6784\u9020\ud835\udd3d_h-\u7ebf\u6027sum-rank\u5ea6\u91cf\u7801\u4f5c\u4e3aLRS\u7801\u7684\u5b50\u7801\uff0c\u901a\u8fc7\u5b50\u7a7a\u95f4\u8bbe\u8ba1\u9650\u5236\u6d88\u606f\u591a\u9879\u5f0f\u5230\u7279\u5b9a\ud835\udd3d_h-\u5b50\u7a7a\u95f4\u3002\u5efa\u7acb\u7ebf\u6027\u4ee3\u6570\u8bd1\u7801\u6846\u67b6\uff0c\u8bc1\u660e\u6298\u53e0\u6c42\u503c\u6ee1\u8db3\u63d2\u503c\u6761\u4ef6\uff0c\u89e3\u7a7a\u95f4\u5f62\u6210\u4f4e\u7ef4\u7ed3\u6784\u4eff\u5c04\u5b50\u7a7a\u95f4\u3002", "result": "\u5b9e\u73b0\u4e86\u7801\u73871-\u03c1-\u03b5\u3001\u8bd1\u7801\u534a\u5f84\u03c1\u7684\u9ad8\u6548\u5217\u8868\u8bd1\u7801\uff0c\u5217\u8868\u5927\u5c0fh^poly(1/\u03b5)\u3002\u9996\u6b21\u6784\u9020\u51fa\u8d85\u8d8a\u552f\u4e00\u8bd1\u7801\u534a\u5f84\u7684\u6b63\u7801\u7387FLRS\u5b50\u7801\uff0c\u4e3asum-rank\u5ea6\u91cf\u7801\u63d0\u4f9b\u4e86\u65b0\u7684\u9ad8\u6548\u8bd1\u7801\u6846\u67b6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u8d85\u8d8a\u552f\u4e00\u8bd1\u7801\u534a\u5f84\u7684\u6b63\u7801\u7387sum-rank\u5ea6\u91cf\u7801\u7684\u663e\u5f0f\u6784\u9020\uff0c\u5efa\u7acb\u4e86\u9ad8\u6548\u7684\u7ebf\u6027\u4ee3\u6570\u5217\u8868\u8bd1\u7801\u6846\u67b6\uff0c\u4e3asum-rank\u5ea6\u91cf\u7801\u7684\u8bbe\u8ba1\u548c\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.05476", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2602.05476", "abs": "https://arxiv.org/abs/2602.05476", "authors": ["Ameet Gadekar"], "title": "Tight FPT Approximations for Fair $k$-center with Outliers", "comment": "22 pages, 2 figures", "summary": "The $k$-center problem is a fundamental clustering objective that has been extensively studied in approximation algorithms. Recent work has sought to incorporate modern constraints such as fairness and robustness, motivated by biased and noisy data. In this paper, we study fair $k$-center with outliers, where centers must respect group-based representation constraints while up to $z$ points may be discarded.\n  While a bi-criteria FPT approximation was previously known, no true approximation algorithm was available for this problem. We present the first deterministic $3$-approximation algorithm running in fixed-parameter tractable time parameterized by $k$. Our approach departs from projection-based methods and instead directly constructs a fair solution using a novel iterative ball-finding framework, based on a structural trichotomy that enables fixed-parameter approximation for the problem.\n  We further extend our algorithm to fair $k$-supplier with outliers and to the more general fair-range setting with both lower and upper bounds. Finally, we show that improving the approximation factor below $3$ is $\\mathrm{W[2]}$-hard, establishing the optimality of our results.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u786e\u5b9a\u6027\u76843-\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5e26\u79bb\u7fa4\u70b9\u7684\u516c\u5e73k-center\u95ee\u9898\uff0c\u7b97\u6cd5\u5728\u53c2\u6570k\u4e0b\u5177\u6709\u56fa\u5b9a\u53c2\u6570\u53ef\u5904\u7406\u65f6\u95f4\uff0c\u5e76\u8bc1\u660e3-\u8fd1\u4f3c\u662f\u6700\u4f18\u7684\u3002", "motivation": "k-center\u95ee\u9898\u662f\u4e00\u4e2a\u57fa\u7840\u805a\u7c7b\u76ee\u6807\uff0c\u6700\u8fd1\u7814\u7a76\u5f00\u59cb\u7eb3\u5165\u516c\u5e73\u6027\u548c\u9c81\u68d2\u6027\u7b49\u73b0\u4ee3\u7ea6\u675f\u3002\u672c\u6587\u7814\u7a76\u5e26\u79bb\u7fa4\u70b9\u7684\u516c\u5e73k-center\u95ee\u9898\uff0c\u4e2d\u5fc3\u70b9\u9700\u8981\u6ee1\u8db3\u57fa\u4e8e\u7fa4\u4f53\u7684\u4ee3\u8868\u6027\u7ea6\u675f\uff0c\u540c\u65f6\u5141\u8bb8\u4e22\u5f03\u6700\u591az\u4e2a\u70b9\u3002\u4e4b\u524d\u53ea\u6709\u53cc\u6807\u51c6FPT\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u7f3a\u4e4f\u771f\u6b63\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002", "method": "\u91c7\u7528\u65b0\u9896\u7684\u8fed\u4ee3\u7403\u5bfb\u627e\u6846\u67b6\uff0c\u57fa\u4e8e\u7ed3\u6784\u4e09\u5206\u6cd5\u76f4\u63a5\u6784\u5efa\u516c\u5e73\u89e3\uff0c\u800c\u4e0d\u662f\u57fa\u4e8e\u6295\u5f71\u7684\u65b9\u6cd5\u3002\u7b97\u6cd5\u5728\u53c2\u6570k\u4e0b\u5177\u6709\u56fa\u5b9a\u53c2\u6570\u53ef\u5904\u7406\u65f6\u95f4\uff0c\u5e76\u6269\u5c55\u5230\u516c\u5e73k-supplier\u95ee\u9898\u548c\u66f4\u4e00\u822c\u7684\u516c\u5e73\u8303\u56f4\u8bbe\u7f6e\u3002", "result": "\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u786e\u5b9a\u6027\u76843-\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u8fd0\u884c\u65f6\u95f4\u4e3a\u56fa\u5b9a\u53c2\u6570\u53ef\u5904\u7406\u65f6\u95f4\uff08\u53c2\u6570\u4e3ak\uff09\u3002\u7b97\u6cd5\u6269\u5c55\u5230\u516c\u5e73k-supplier\u548c\u516c\u5e73\u8303\u56f4\u8bbe\u7f6e\u3002\u8bc1\u660e\u5c06\u8fd1\u4f3c\u56e0\u5b50\u6539\u8fdb\u52303\u4ee5\u4e0b\u662fW[2]-\u96be\u7684\uff0c\u786e\u7acb\u4e86\u7ed3\u679c\u7684\u6700\u4f18\u6027\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u4e3a\u5e26\u79bb\u7fa4\u70b9\u7684\u516c\u5e73k-center\u95ee\u9898\u63d0\u4f9b\u4e86\u771f\u6b63\u7684\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u8fbe\u5230\u4e86\u6700\u4f18\u76843-\u8fd1\u4f3c\u56e0\u5b50\uff0c\u5e76\u5728\u56fa\u5b9a\u53c2\u6570\u53ef\u5904\u7406\u65f6\u95f4\u5185\u8fd0\u884c\u3002\u7ed3\u679c\u6269\u5c55\u5230\u76f8\u5173\u53d8\u4f53\uff0c\u5e76\u5efa\u7acb\u4e86\u7406\u8bba\u6700\u4f18\u6027\u754c\u9650\u3002"}}
{"id": "2602.05216", "categories": ["cs.IR", "cs.AI", "math.HO"], "pdf": "https://arxiv.org/pdf/2602.05216", "abs": "https://arxiv.org/abs/2602.05216", "authors": ["Luke Alexander", "Eric Leonen", "Sophie Szeto", "Artemii Remizov", "Ignacio Tejeda", "Giovanni Inchiostro", "Vasily Ilin"], "title": "Semantic Search over 9 Million Mathematical Theorems", "comment": "Feedback is welcome", "summary": "Searching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek a specific theorem, lemma, or proposition that answers a query. While semantic search has seen rapid progress, its behavior on large, highly technical corpora such as research-level mathematical theorems remains poorly understood. In this work, we introduce and study semantic theorem retrieval at scale over a unified corpus of $9.2$ million theorem statements extracted from arXiv and seven other sources, representing the largest publicly available corpus of human-authored, research-level theorems. We represent each theorem with a short natural-language description as a retrieval representation and systematically analyze how representation context, language model choice, embedding model, and prompting strategy affect retrieval quality. On a curated evaluation set of theorem-search queries written by professional mathematicians, our approach substantially improves both theorem-level and paper-level retrieval compared to existing baselines, demonstrating that semantic theorem search is feasible and effective at web scale. The theorem search tool is available at \\href{https://huggingface.co/spaces/uw-math-ai/theorem-search}{this link}, and the dataset is available at \\href{https://huggingface.co/datasets/uw-math-ai/TheoremSearch}{this link}.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u8bed\u4e49\u5b9a\u7406\u68c0\u7d22\u7cfb\u7edf\uff0c\u5728920\u4e07\u4e2a\u5b9a\u7406\u8bed\u53e5\u7684\u7edf\u4e00\u8bed\u6599\u5e93\u4e0a\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u57fa\u7ebf\u66f4\u597d\u7684\u5b9a\u7406\u7ea7\u548c\u8bba\u6587\u7ea7\u68c0\u7d22\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u6570\u5b66\u68c0\u7d22\u5de5\u5177\u901a\u5e38\u8fd4\u56de\u6574\u7bc7\u8bba\u6587\uff0c\u800c\u6570\u5b66\u5bb6\u548c\u5b9a\u7406\u8bc1\u660e\u4ee3\u7406\u901a\u5e38\u9700\u8981\u67e5\u627e\u7279\u5b9a\u7684\u5b9a\u7406\u3001\u5f15\u7406\u6216\u547d\u9898\u3002\u867d\u7136\u8bed\u4e49\u641c\u7d22\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u5728\u5927\u578b\u3001\u9ad8\u5ea6\u6280\u672f\u6027\u7684\u7814\u7a76\u7ea7\u6570\u5b66\u5b9a\u7406\u8bed\u6599\u5e93\u4e0a\u7684\u8868\u73b0\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u4ecearXiv\u548c\u5176\u4ed6\u4e03\u4e2a\u6765\u6e90\u63d0\u53d6\u4e86920\u4e07\u4e2a\u5b9a\u7406\u8bed\u53e5\uff0c\u6784\u5efa\u4e86\u6700\u5927\u7684\u516c\u5f00\u7814\u7a76\u7ea7\u5b9a\u7406\u8bed\u6599\u5e93\u3002\u4f7f\u7528\u7b80\u77ed\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u4f5c\u4e3a\u68c0\u7d22\u8868\u793a\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u8868\u793a\u4e0a\u4e0b\u6587\u3001\u8bed\u8a00\u6a21\u578b\u9009\u62e9\u3001\u5d4c\u5165\u6a21\u578b\u548c\u63d0\u793a\u7b56\u7565\u5bf9\u68c0\u7d22\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u5728\u4e13\u4e1a\u6570\u5b66\u5bb6\u7f16\u5199\u7684\u5b9a\u7406\u641c\u7d22\u67e5\u8be2\u8bc4\u4f30\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9a\u7406\u7ea7\u548c\u8bba\u6587\u7ea7\u68c0\u7d22\u65b9\u9762\u90fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u8bc1\u660e\u8bed\u4e49\u5b9a\u7406\u641c\u7d22\u5728Web\u89c4\u6a21\u4e0a\u662f\u53ef\u884c\u4e14\u6709\u6548\u7684\u3002", "conclusion": "\u8bed\u4e49\u5b9a\u7406\u641c\u7d22\u5728\u5927\u89c4\u6a21\u6570\u5b66\u8bed\u6599\u5e93\u4e0a\u662f\u53ef\u884c\u7684\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u6539\u8fdb\u4e86\u6570\u5b66\u5185\u5bb9\u7684\u68c0\u7d22\u6548\u679c\uff0c\u76f8\u5173\u5de5\u5177\u548c\u6570\u636e\u96c6\u5df2\u516c\u5f00\u53ef\u7528\u3002"}}
{"id": "2602.05888", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05888", "abs": "https://arxiv.org/abs/2602.05888", "authors": ["Merlin de la Haye", "Pascal Lenzner", "Farehe Soheil", "Marcus Wunderlich"], "title": "Metric Hedonic Games on the Line", "comment": "accepted at AAMAS 2026, full version", "summary": "Hedonic games are fundamental models for investigating the formation of coalitions among a set of strategic agents, where every agent has a certain utility for every possible coalition of agents it can be part of. To avoid the intractability of defining exponentially many utilities for all possible coalitions, many variants with succinct representations of the agents' utility functions have been devised and analyzed, e.g., modified fractional hedonic games by Monaco et al. [JAAMAS 2020]. We extend this by studying a novel succinct variant that is related to modified fractional hedonic games. In our model, each agent has a fixed type-value and an agent's cost for some given coalition is based on the differences between its value and those of the other members of its coalition. This allows to model natural situations like athletes forming training groups with similar performance levels or voters that partition themselves along a political spectrum.\n  In particular, we investigate natural variants where an agent's cost is defined by distance thresholds, or by the maximum or average value difference to the other agents in its coalition. For these settings, we study the existence of stable coalition structures, their properties, and their quality in terms of the price of anarchy and the price of stability. Further, we investigate the impact of limiting the maximum number of coalitions. Despite the simple setting with metric distances on a line, we uncover a rich landscape of models, partially with counter-intuitive behavior. Also, our focus on both swap stability and jump stability allows us to study the influence of fixing the number and the size of the coalitions. Overall, we find that stable coalition structures always exist but that their properties and quality can vary widely.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7c7b\u578b\u503c\u7684\u7b80\u6d01\u4eab\u4e50\u535a\u5f08\u6a21\u578b\uff0c\u7814\u7a76\u7ebf\u578b\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u57fa\u4e8e\u8ddd\u79bb\u9608\u503c\u3001\u6700\u5927/\u5e73\u5747\u5dee\u5f02\u7684\u8054\u76df\u7a33\u5b9a\u6027\u3001\u4ef7\u683c\u7b49\u6027\u8d28", "motivation": "\u4f20\u7edf\u4eab\u4e50\u535a\u5f08\u9700\u8981\u5b9a\u4e49\u6307\u6570\u7ea7\u6548\u7528\u51fd\u6570\uff0c\u8ba1\u7b97\u590d\u6742\u3002\u672c\u6587\u63d0\u51fa\u7b80\u6d01\u8868\u793a\u7684\u65b0\u53d8\u4f53\uff0c\u57fa\u4e8e\u4ee3\u7406\u7c7b\u578b\u503c\u5dee\u5f02\u5efa\u6a21\u81ea\u7136\u573a\u666f\uff08\u5982\u8fd0\u52a8\u5458\u6309\u6c34\u5e73\u5206\u7ec4\u3001\u9009\u6c11\u6309\u653f\u6cbb\u5149\u8c31\u5206\u533a\uff09", "method": "\u5b9a\u4e49\u57fa\u4e8e\u7c7b\u578b\u503c\u7684\u4eab\u4e50\u535a\u5f08\u6a21\u578b\uff0c\u4ee3\u7406\u6210\u672c\u57fa\u4e8e\u4e0e\u8054\u76df\u5185\u5176\u4ed6\u6210\u5458\u7684\u7c7b\u578b\u503c\u5dee\u5f02\u3002\u7814\u7a76\u4e09\u79cd\u6210\u672c\u51fd\u6570\uff1a\u8ddd\u79bb\u9608\u503c\u3001\u6700\u5927\u5dee\u5f02\u3001\u5e73\u5747\u5dee\u5f02\u3002\u5206\u6790\u4ea4\u6362\u7a33\u5b9a\u6027\u548c\u8df3\u8dc3\u7a33\u5b9a\u6027\uff0c\u8003\u8651\u8054\u76df\u6570\u91cf\u9650\u5236", "result": "\u7a33\u5b9a\u8054\u76df\u7ed3\u6784\u59cb\u7ec8\u5b58\u5728\uff0c\u4f46\u5176\u6027\u8d28\u548c\u6548\u7387\u5dee\u5f02\u5f88\u5927\u3002\u5728\u7ebf\u578b\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u53d1\u73b0\u4e86\u4e30\u5bcc\u7684\u6a21\u578b\u666f\u89c2\uff0c\u90e8\u5206\u7ed3\u679c\u5177\u6709\u53cd\u76f4\u89c9\u884c\u4e3a\u3002\u4ef7\u683c\u548c\u7a33\u5b9a\u6027\u53d7\u8054\u76df\u6570\u91cf\u548c\u5927\u5c0f\u9650\u5236\u7684\u5f71\u54cd", "conclusion": "\u5c3d\u7ba1\u8bbe\u5b9a\u7b80\u5355\uff08\u7ebf\u578b\u5ea6\u91cf\u7a7a\u95f4\uff09\uff0c\u4f46\u63ed\u793a\u4e86\u4e30\u5bcc\u7684\u6a21\u578b\u884c\u4e3a\u3002\u7a33\u5b9a\u8054\u76df\u603b\u662f\u5b58\u5728\uff0c\u4f46\u8d28\u91cf\u548c\u7279\u6027\u53d8\u5316\u663e\u8457\u3002\u540c\u65f6\u7814\u7a76\u4ea4\u6362\u548c\u8df3\u8dc3\u7a33\u5b9a\u6027\u6709\u52a9\u4e8e\u7406\u89e3\u8054\u76df\u6570\u91cf\u548c\u5927\u5c0f\u56fa\u5b9a\u7684\u5f71\u54cd"}}
{"id": "2602.05540", "categories": ["cs.DB", "cs.OS"], "pdf": "https://arxiv.org/pdf/2602.05540", "abs": "https://arxiv.org/abs/2602.05540", "authors": ["Felix Schuhknecht", "Nick Rassau"], "title": "Taking the Leap: Efficient and Reliable Fine-Grained NUMA Migration in User-space", "comment": null, "summary": "Modern multi-socket architectures offer a single virtual address space, but physically divide main-memory across multiple regions, where each region is attached to a CPU and its cores. While this simplifies the usage, developers must be aware of non-uniform memory access (NUMA), where an access by a thread running on a core-local NUMA region is significantly cheaper than an access from a core-remote region. Obviously, if query answering is parallelized across the cores of multiple regions, then the portion of the database on which the query is operating should be distributed across the same regions to ensure local accesses. As the present data placement might not fit this, migrating pages from one NUMA region to another can be performed to improve the situation. To do so, different options exist: One option is to rely on automatic NUMA balancing integrated in Linux, which is steered by the observed access patterns and frequency. Another option is to actively trigger migration via the system call move_pages(). Unfortunately, both variants have significant downsides in terms of their feature set and performance. As an alternative, we propose a new user-space migration method called page_leap() that can perform page migration asynchronously at a high performance by exploiting features of the virtual memory subsystem. The method is (a) actively triggered by the user, (b) ensures that all pages are eventually migrated, (c) handles concurrent writes correctly, (d) supports pooled memory, (e) adaptively adjusts its migration granularity based on the workload, and (f) supports both small pages and huge pages.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fapage_leap()\uff0c\u4e00\u79cd\u65b0\u7684\u7528\u6237\u7a7a\u95f4\u5185\u5b58\u9875\u9762\u8fc1\u79fb\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316NUMA\u67b6\u6784\u4e0b\u7684\u6570\u636e\u5e93\u67e5\u8be2\u6027\u80fd\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6848\u5177\u6709\u66f4\u9ad8\u6027\u80fd\u548c\u66f4\u5b8c\u6574\u529f\u80fd\u96c6\u3002", "motivation": "\u73b0\u4ee3\u591a\u63d2\u69fd\u67b6\u6784\u867d\u7136\u63d0\u4f9b\u5355\u4e00\u865a\u62df\u5730\u5740\u7a7a\u95f4\uff0c\u4f46\u7269\u7406\u5185\u5b58\u5206\u5e03\u5728\u591a\u4e2aNUMA\u533a\u57df\u3002\u5f53\u67e5\u8be2\u5728\u591a\u533a\u57df\u6838\u5fc3\u4e0a\u5e76\u884c\u6267\u884c\u65f6\uff0c\u9700\u8981\u5c06\u76f8\u5173\u6570\u636e\u5206\u5e03\u5230\u76f8\u540c\u533a\u57df\u4ee5\u786e\u4fdd\u672c\u5730\u8bbf\u95ee\u3002\u73b0\u6709\u8fc1\u79fb\u65b9\u6848\uff08Linux\u81ea\u52a8NUMA\u5e73\u8861\u548cmove_pages()\u7cfb\u7edf\u8c03\u7528\uff09\u5728\u529f\u80fd\u96c6\u548c\u6027\u80fd\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\u3002", "method": "\u63d0\u51fapage_leap()\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684\u7528\u6237\u7a7a\u95f4\u5f02\u6b65\u9875\u9762\u8fc1\u79fb\u6280\u672f\uff0c\u901a\u8fc7\u5229\u7528\u865a\u62df\u5185\u5b58\u5b50\u7cfb\u7edf\u7684\u7279\u6027\u5b9e\u73b0\u9ad8\u6027\u80fd\u8fc1\u79fb\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u4ee5\u4e0b\u7279\u70b9\uff1a\u7528\u6237\u4e3b\u52a8\u89e6\u53d1\u3001\u786e\u4fdd\u6240\u6709\u9875\u9762\u6700\u7ec8\u8fc1\u79fb\u3001\u6b63\u786e\u5904\u7406\u5e76\u53d1\u5199\u5165\u3001\u652f\u6301\u6c60\u5316\u5185\u5b58\u3001\u57fa\u4e8e\u5de5\u4f5c\u8d1f\u8f7d\u81ea\u9002\u5e94\u8c03\u6574\u8fc1\u79fb\u7c92\u5ea6\u3001\u540c\u65f6\u652f\u6301\u5c0f\u9875\u9762\u548c\u5927\u9875\u9762\u3002", "result": "page_leap()\u65b9\u6cd5\u5728\u529f\u80fd\u5b8c\u6574\u6027\u548c\u6027\u80fd\u65b9\u9762\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3NUMA\u67b6\u6784\u4e0b\u7684\u6570\u636e\u5c40\u90e8\u6027\u95ee\u9898\uff0c\u63d0\u5347\u6570\u636e\u5e93\u67e5\u8be2\u7684\u5e76\u884c\u6267\u884c\u6548\u7387\u3002", "conclusion": "page_leap()\u4e3aNUMA\u67b6\u6784\u4e0b\u7684\u5185\u5b58\u9875\u9762\u8fc1\u79fb\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u529f\u80fd\u5b8c\u6574\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u9ad8\u6027\u80fd\u6570\u636e\u5c40\u90e8\u6027\u4f18\u5316\u7684\u6570\u636e\u5e93\u7cfb\u7edf\u548c\u5176\u4ed6\u5185\u5b58\u5bc6\u96c6\u578b\u5e94\u7528\u3002"}}
{"id": "2602.05666", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.05666", "abs": "https://arxiv.org/abs/2602.05666", "authors": ["Chao Zhou", "Changsheng You", "Cong Zhou", "Li Chen", "Yi Gong", "Chengwen Xing"], "title": "Low-complexity Design for Beam Coverage in Near-field and Far-field: A Fourier Transform Approach", "comment": "13 pages, 7 figures, submitted to IEEE for possible publication", "summary": "In this paper, we study efficient beam coverage design for multi-antenna systems in both far-field and near-field cases. To reduce the computational complexity of existing sampling-based optimization methods, we propose a new low-complexity yet efficient beam coverage design. To this end, we first formulate a general beam coverage optimization problem to maximize the worst-case beamforming gain over a target region. For the far-field case, we show that the beam coverage design can be viewed as a spatial-frequency filtering problem, where angular coverage can be achieved by weight-shaping in the antenna domain via an inverse FT, yielding an infinite-length weighting sequence. Under the constraint of a finite number of antennas, a surrogate scheme is proposed by directly truncating this sequence, which inevitably introduces a roll-off effect at the angular boundaries, yielding degraded worst-case beamforming gain. To address this issue, we characterize the finite-antenna-induced roll-off effect, based on which a roll-off-aware design with a protective zoom is developed to ensure a flat beamforming-gain profile within the target angular region. Next, we extend the proposed method to the near-field case. Specifically, by applying a first-order Taylor approximation to the near-field channel steering vector (CSV), the two-dimensional (2D) beam coverage design (in both angle and inverse-range) can be transformed into a 2D inverse FT, leading to a low-complexity beamforming design. Furthermore, an inherent near-field range defocusing effect is observed, indicating that sufficiently wide angular coverage results in range-insensitive beam steering. Finally, numerical results demonstrate that the proposed FT-based approach achieves a comparable worst-case beamforming performance with that of conventional sampling-based optimization methods while significantly reducing the computational complexity.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5085\u91cc\u53f6\u53d8\u6362\u7684\u4f4e\u590d\u6742\u5ea6\u6ce2\u675f\u8986\u76d6\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u8fdc\u573a\u548c\u8fd1\u573a\u591a\u5929\u7ebf\u7cfb\u7edf\uff0c\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u91c7\u6837\u7684\u6ce2\u675f\u8986\u76d6\u4f18\u5316\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u9700\u8981\u8bbe\u8ba1\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u4e14\u9ad8\u6548\u7684\u6ce2\u675f\u8986\u76d6\u8bbe\u8ba1\u65b9\u6cd5\u3002", "method": "\u5c06\u6ce2\u675f\u8986\u76d6\u8bbe\u8ba1\u8f6c\u5316\u4e3a\u7a7a\u95f4\u9891\u7387\u6ee4\u6ce2\u95ee\u9898\uff0c\u901a\u8fc7\u9006\u5085\u91cc\u53f6\u53d8\u6362\u5b9e\u73b0\u89d2\u5ea6\u8986\u76d6\u3002\u9488\u5bf9\u6709\u9650\u5929\u7ebf\u6570\u5f15\u5165\u7684\u6eda\u964d\u6548\u5e94\uff0c\u63d0\u51fa\u5177\u6709\u4fdd\u62a4\u653e\u5927\u7684\u6eda\u964d\u611f\u77e5\u8bbe\u8ba1\u3002\u5bf9\u4e8e\u8fd1\u573a\u60c5\u51b5\uff0c\u901a\u8fc7\u5bf9\u8fd1\u573a\u4fe1\u9053\u5bfc\u5411\u77e2\u91cf\u8fdb\u884c\u4e00\u9636\u6cf0\u52d2\u8fd1\u4f3c\uff0c\u5c06\u4e8c\u7ef4\u6ce2\u675f\u8986\u76d6\u8bbe\u8ba1\u8f6c\u5316\u4e3a\u4e8c\u7ef4\u9006\u5085\u91cc\u53f6\u53d8\u6362\u3002", "result": "\u6240\u63d0\u51fa\u7684FT-based\u65b9\u6cd5\u5728\u5b9e\u73b0\u4e0e\u5e38\u89c4\u91c7\u6837\u4f18\u5316\u65b9\u6cd5\u76f8\u5f53\u7684\u6ce2\u675f\u6210\u5f62\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002\u540c\u65f6\u89c2\u5bdf\u5230\u8fd1\u573a\u8303\u56f4\u6563\u7126\u6548\u5e94\uff0c\u8868\u660e\u8db3\u591f\u5bbd\u7684\u89d2\u5ea6\u8986\u76d6\u4f1a\u5bfc\u81f4\u8303\u56f4\u4e0d\u654f\u611f\u7684\u6ce2\u675f\u5bfc\u5411\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u5085\u91cc\u53f6\u53d8\u6362\u7684\u65b9\u6cd5\u4e3a\u591a\u5929\u7ebf\u7cfb\u7edf\u7684\u6ce2\u675f\u8986\u76d6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4f4e\u590d\u6742\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u8fdc\u573a\u548c\u8fd1\u573a\u573a\u666f\uff0c\u5728\u6027\u80fd\u548c\u590d\u6742\u5ea6\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2602.05773", "categories": ["cs.DS", "cs.DM", "math.CO", "math.GT"], "pdf": "https://arxiv.org/pdf/2602.05773", "abs": "https://arxiv.org/abs/2602.05773", "authors": ["Y\u0131lmaz Arslano\u011flu"], "title": "A Structural Equivalence of Symmetric TSP to a Constrained Group Steiner Tree Problem", "comment": "4 pages, 3 figures, brief communication note to be submitted to ORL", "summary": "We present a brief structural equivalence between the symmetric TSP and a constrained Group Steiner Tree Problem (cGSTP) defined on a simplicial incidence graph. Given the complete weighted graph on the city set V, we form the bipartite incidence graph between triangles and edges. Selecting an admissible, disk-like set of triangles induces a unique boundary cycle. With global connectivity and local regularity constraints, maximizing net weight in the cGSTP is exactly equivalent to minimizing the TSP tour length.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u5bf9\u79f0\u65c5\u884c\u5546\u95ee\u9898\uff08TSP\uff09\u4e0e\u5728\u5355\u7eaf\u5f62\u5173\u8054\u56fe\u4e0a\u5b9a\u4e49\u7684\u7ea6\u675f\u7ec4\u65af\u5766\u7eb3\u6811\u95ee\u9898\uff08cGSTP\uff09\u4e4b\u95f4\u7684\u7ed3\u6784\u7b49\u4ef7\u6027\u3002", "motivation": "\u63a2\u7d22TSP\u4e0e\u5176\u4ed6\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e4b\u95f4\u7684\u7ed3\u6784\u8054\u7cfb\uff0c\u53ef\u80fd\u4e3aTSP\u63d0\u4f9b\u65b0\u7684\u6c42\u89e3\u89c6\u89d2\u548c\u7b97\u6cd5\u601d\u8def\u3002", "method": "\u5c06\u5b8c\u5168\u52a0\u6743\u57ce\u5e02\u56fe\u8f6c\u6362\u4e3a\u4e09\u89d2\u5f62\u548c\u8fb9\u7684\u4e8c\u5206\u5173\u8054\u56fe\uff0c\u901a\u8fc7\u9009\u62e9\u53ef\u63a5\u53d7\u7684\u5706\u76d8\u72b6\u4e09\u89d2\u5f62\u96c6\u5408\u6765\u8bf1\u5bfc\u552f\u4e00\u7684\u8fb9\u754c\u5faa\u73af\uff0c\u5728\u5168\u5c40\u8fde\u901a\u6027\u548c\u5c40\u90e8\u6b63\u5219\u6027\u7ea6\u675f\u4e0b\u5efa\u7acb\u7b49\u4ef7\u5173\u7cfb\u3002", "result": "\u8bc1\u660e\u4e86\u5728cGSTP\u4e2d\u6700\u5927\u5316\u51c0\u6743\u91cd\u4e0e\u6700\u5c0f\u5316TSP\u65c5\u884c\u8def\u5f84\u957f\u5ea6\u5b8c\u5168\u7b49\u4ef7\u3002", "conclusion": "\u5efa\u7acb\u4e86\u5bf9\u79f0TSP\u4e0e\u7ea6\u675f\u7ec4\u65af\u5766\u7eb3\u6811\u95ee\u9898\u4e4b\u95f4\u7684\u7cbe\u786e\u7ed3\u6784\u7b49\u4ef7\uff0c\u4e3aTSP\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u5b66\u6846\u67b6\u3002"}}
{"id": "2602.05334", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.05334", "abs": "https://arxiv.org/abs/2602.05334", "authors": ["Dawn Lawrie", "James Mayfield", "Eugene Yang", "Andrew Yates", "Sean MacAvaney", "Ronak Pradeep", "Scott Miller", "Paul McNamee", "Luca Soldaini"], "title": "NeuCLIRTech: Chinese Monolingual and Cross-Language Information Retrieval Evaluation in a Challenging Domain", "comment": "14 pages, 6 figures", "summary": "Measuring advances in retrieval requires test collections with relevance judgments that can faithfully distinguish systems. This paper presents NeuCLIRTech, an evaluation collection for cross-language retrieval over technical information. The collection consists of technical documents written natively in Chinese and those same documents machine translated into English. It includes 110 queries with relevance judgments. The collection supports two retrieval scenarios: monolingual retrieval in Chinese, and cross-language retrieval with English as the query language. NeuCLIRTech combines the TREC NeuCLIR track topics of 2023 and 2024. The 110 queries with 35,962 document judgments provide strong statistical discriminatory power when trying to distinguish retrieval approaches. A fusion baseline of strong neural retrieval systems is included so that developers of reranking algorithms are not reliant on BM25 as their first stage retriever. The dataset and artifacts are released on Huggingface Datasets", "AI": {"tldr": "NeuCLIRTech\u662f\u4e00\u4e2a\u7528\u4e8e\u6280\u672f\u4fe1\u606f\u8de8\u8bed\u8a00\u68c0\u7d22\u7684\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e2d\u6587\u6280\u672f\u6587\u6863\u53ca\u5176\u82f1\u6587\u673a\u5668\u7ffb\u8bd1\u7248\u672c\uff0c\u63d0\u4f9b110\u4e2a\u67e5\u8be2\u548c35,962\u4e2a\u6587\u6863\u76f8\u5173\u6027\u6807\u6ce8\uff0c\u652f\u6301\u4e2d\u6587\u5355\u8bed\u68c0\u7d22\u548c\u82f1\u6587\u67e5\u8be2\u7684\u8de8\u8bed\u8a00\u68c0\u7d22\u573a\u666f\u3002", "motivation": "\u4e3a\u4e86\u51c6\u786e\u8861\u91cf\u68c0\u7d22\u7cfb\u7edf\u7684\u8fdb\u5c55\uff0c\u9700\u8981\u80fd\u591f\u53ef\u9760\u533a\u5206\u7cfb\u7edf\u6027\u80fd\u7684\u6d4b\u8bd5\u96c6\u3002\u5f53\u524d\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u6280\u672f\u4fe1\u606f\u8de8\u8bed\u8a00\u68c0\u7d22\u7684\u8bc4\u4f30\u8d44\u6e90\uff0c\u7279\u522b\u662f\u5728\u4e2d\u6587-\u82f1\u6587\u6280\u672f\u6587\u6863\u573a\u666f\u4e0b\u3002", "method": "\u6574\u5408TREC NeuCLIR 2023\u548c2024\u8d5b\u9053\u4e3b\u9898\uff0c\u6784\u5efa\u5305\u542b\u539f\u751f\u4e2d\u6587\u6280\u672f\u6587\u6863\u53ca\u5176\u82f1\u6587\u673a\u5668\u7ffb\u8bd1\u7248\u672c\u7684\u6570\u636e\u96c6\u3002\u5305\u542b110\u4e2a\u67e5\u8be2\u548c35,962\u4e2a\u6587\u6863\u76f8\u5173\u6027\u6807\u6ce8\uff0c\u63d0\u4f9b\u5f3a\u7edf\u8ba1\u533a\u5206\u80fd\u529b\u3002\u8fd8\u5305\u542b\u57fa\u4e8e\u795e\u7ecf\u68c0\u7d22\u7cfb\u7edf\u7684\u878d\u5408\u57fa\u7ebf\uff0c\u907f\u514d\u91cd\u6392\u5e8f\u7b97\u6cd5\u4f9d\u8d56BM25\u4f5c\u4e3a\u7b2c\u4e00\u7ea7\u68c0\u7d22\u5668\u3002", "result": "\u521b\u5efa\u4e86NeuCLIRTech\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u652f\u6301\u4e24\u79cd\u68c0\u7d22\u573a\u666f\uff1a\u4e2d\u6587\u5355\u8bed\u68c0\u7d22\u548c\u82f1\u6587\u67e5\u8be2\u7684\u8de8\u8bed\u8a00\u68c0\u7d22\u3002\u6570\u636e\u96c6\u548c\u5de5\u5177\u5df2\u53d1\u5e03\u5728Huggingface Datasets\u5e73\u53f0\u4e0a\u3002", "conclusion": "NeuCLIRTech\u4e3a\u6280\u672f\u4fe1\u606f\u8de8\u8bed\u8a00\u68c0\u7d22\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u7684\u8bc4\u4f30\u8d44\u6e90\uff0c\u5177\u6709\u5f3a\u7edf\u8ba1\u533a\u5206\u80fd\u529b\uff0c\u80fd\u591f\u53ef\u9760\u5730\u8bc4\u4f30\u548c\u6bd4\u8f83\u4e0d\u540c\u68c0\u7d22\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u4e3a\u91cd\u6392\u5e8f\u7b97\u6cd5\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u57fa\u7ebf\u652f\u6301\u3002"}}
{"id": "2602.05651", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.05651", "abs": "https://arxiv.org/abs/2602.05651", "authors": ["Nick Rassau", "Felix Schuhknecht"], "title": "One Size Does NOT Fit All: On the Importance of Physical Representations for Datalog Evaluation", "comment": null, "summary": "Datalog is an increasingly popular recursive query language that is declarative by design, meaning its programs must be translated by an engine into the actual physical execution plan. When generating this plan, a central decision is how to physically represent all involved relations, an aspect in which existing Datalog engines are surprisingly restrictive and often resort to one-size-fits-all solutions. The reason for this is that the typical execution plan of a Datalog program not only performs a single type of operation against the physical representations, but a mixture of operations, such as insertions, lookups, and containment-checks. Further, the relevance of each operation type highly depends on the workload characteristics, which range from familiar properties such as the size, multiplicity, and arity of the individual relations to very specific Datalog properties, such as the \"interweaving\" of rules when relations occur multiple times, and in particular the recursiveness of the query which might generate new tuples on the fly during evaluation. This indicates that a variety of physical representations, each with its own strengths and weaknesses, is required to meet the specific needs of different workload situations. To evaluate this, we conduct an in-depth experimental study of the interplay between potentially suitable physical representations and seven dimensions of workload characteristics that vary across actual Datalog programs, revealing which properties actually matter. Based on these insights, we design an automatic selection mechanism that utilizes a set of decision trees to identify suitable physical representations for a given workload.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76Datalog\u67e5\u8be2\u5f15\u64ce\u4e2d\u7269\u7406\u8868\u793a\u7684\u9009\u62e9\u95ee\u9898\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\u4e0e\u7269\u7406\u8868\u793a\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u51b3\u7b56\u6811\u7684\u81ea\u52a8\u9009\u62e9\u673a\u5236\u3002", "motivation": "\u73b0\u6709Datalog\u5f15\u64ce\u5728\u7269\u7406\u8868\u793a\u9009\u62e9\u4e0a\u8fc7\u4e8e\u9650\u5236\uff0c\u901a\u5e38\u91c7\u7528\u4e00\u5200\u5207\u7684\u89e3\u51b3\u65b9\u6848\u3002Datalog\u7a0b\u5e8f\u7684\u6267\u884c\u8ba1\u5212\u6d89\u53ca\u591a\u79cd\u64cd\u4f5c\u7c7b\u578b\uff08\u63d2\u5165\u3001\u67e5\u627e\u3001\u5305\u542b\u68c0\u67e5\uff09\uff0c\u4e14\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\u5bf9\u64cd\u4f5c\u9700\u6c42\u5dee\u5f02\u5f88\u5927\uff0c\u9700\u8981\u591a\u6837\u5316\u7684\u7269\u7406\u8868\u793a\u6765\u6ee1\u8db3\u4e0d\u540c\u573a\u666f\u9700\u6c42\u3002", "method": "1. \u6df1\u5165\u5b9e\u9a8c\u7814\u7a76\uff1a\u5206\u6790\u6f5c\u5728\u5408\u9002\u7684\u7269\u7406\u8868\u793a\u4e0eDatalog\u7a0b\u5e8f\u7684\u4e03\u4e2a\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\u7ef4\u5ea6\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff1b2. \u8bbe\u8ba1\u81ea\u52a8\u9009\u62e9\u673a\u5236\uff1a\u5229\u7528\u4e00\u7ec4\u51b3\u7b56\u6811\u4e3a\u7ed9\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u8bc6\u522b\u5408\u9002\u7684\u7269\u7406\u8868\u793a\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u63ed\u793a\u4e86\u54ea\u4e9b\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\u771f\u6b63\u5f71\u54cd\u7269\u7406\u8868\u793a\u7684\u6027\u80fd\uff0c\u5e76\u5f00\u53d1\u4e86\u80fd\u591f\u6839\u636e\u5de5\u4f5c\u8d1f\u8f7d\u7279\u5f81\u81ea\u52a8\u9009\u62e9\u6700\u4f18\u7269\u7406\u8868\u793a\u7684\u51b3\u7b56\u6811\u7cfb\u7edf\u3002", "conclusion": "Datalog\u67e5\u8be2\u5f15\u64ce\u9700\u8981\u6839\u636e\u5177\u4f53\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\u7075\u6d3b\u9009\u62e9\u7269\u7406\u8868\u793a\uff0c\u57fa\u4e8e\u51b3\u7b56\u6811\u7684\u81ea\u52a8\u9009\u62e9\u673a\u5236\u80fd\u591f\u6709\u6548\u63d0\u5347\u67e5\u8be2\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5f15\u64ce\u7269\u7406\u8868\u793a\u9009\u62e9\u8fc7\u4e8e\u9650\u5236\u7684\u95ee\u9898\u3002"}}
{"id": "2602.05744", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.05744", "abs": "https://arxiv.org/abs/2602.05744", "authors": ["Guglielmo Beretta", "Tommaso Cesari", "Roberto Colomboni"], "title": "Generalized Pinsker Inequality for Bregman Divergences of Negative Tsallis Entropies", "comment": null, "summary": "The Pinsker inequality lower bounds the Kullback--Leibler divergence $D_{\\textrm{KL}}$ in terms of total variation and provides a canonical way to convert $D_{\\textrm{KL}}$ control into $\\lVert \\cdot \\rVert_1$-control. Motivated by applications to probabilistic prediction with Tsallis losses and online learning, we establish a generalized Pinsker inequality for the Bregman divergences $D_\u03b1$ generated by the negative $\u03b1$-Tsallis entropies -- also known as $\u03b2$-divergences. Specifically, for any $p$, $q$ in the relative interior of the probability simplex $\u0394^K$, we prove the sharp bound \\[\n  D_\u03b1(p\\Vert q) \\ge \\frac{C_{\u03b1,K}}{2}\\cdot \\|p-q\\|_1^2, \\] and we determine the optimal constant $C_{\u03b1,K}$ explicitly for every choice of $(\u03b1,K)$.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9Tsallis\u635f\u5931\u7684\u6982\u7387\u9884\u6d4b\u548c\u5728\u7ebf\u5b66\u4e60\u5e94\u7528\uff0c\u5efa\u7acb\u4e86\u8d1f\u03b1-Tsallis\u71b5\u751f\u6210\u7684Bregman\u6563\u5ea6\uff08\u5373\u03b2-\u6563\u5ea6\uff09\u7684\u5e7f\u4e49Pinsker\u4e0d\u7b49\u5f0f\uff0c\u7ed9\u51fa\u4e86\u4efb\u610f\u6982\u7387\u5355\u7eaf\u5f62\u5185\u4e24\u70b9\u95f4\u6563\u5ea6\u7684\u5c16\u9510\u4e0b\u754c\u3002", "motivation": "\u4f20\u7edfPinsker\u4e0d\u7b49\u5f0f\u5c06Kullback-Leibler\u6563\u5ea6\u4e0b\u754c\u8868\u793a\u4e3a\u603b\u53d8\u5dee\uff0c\u4e3a\u5c06KL\u6563\u5ea6\u63a7\u5236\u8f6c\u6362\u4e3aL1\u8303\u6570\u63a7\u5236\u63d0\u4f9b\u4e86\u6807\u51c6\u65b9\u6cd5\u3002\u672c\u6587\u52a8\u673a\u6e90\u4e8eTsallis\u635f\u5931\u7684\u6982\u7387\u9884\u6d4b\u548c\u5728\u7ebf\u5b66\u4e60\u5e94\u7528\uff0c\u9700\u8981\u5efa\u7acb\u66f4\u4e00\u822c\u7684Bregman\u6563\u5ea6\uff08\u7279\u522b\u662f\u8d1f\u03b1-Tsallis\u71b5\u751f\u6210\u7684\u03b2-\u6563\u5ea6\uff09\u7684\u7c7b\u4f3c\u4e0d\u7b49\u5f0f\u3002", "method": "\u9488\u5bf9\u8d1f\u03b1-Tsallis\u71b5\u751f\u6210\u7684Bregman\u6563\u5ea6D\u03b1\uff08\u5373\u03b2-\u6563\u5ea6\uff09\uff0c\u7814\u7a76\u5176\u5728\u6982\u7387\u5355\u7eaf\u5f62\u0394^K\u76f8\u5bf9\u5185\u90e8\u4efb\u610f\u4e24\u70b9p,q\u4e4b\u95f4\u7684\u4e0b\u754c\u5173\u7cfb\u3002\u901a\u8fc7\u6570\u5b66\u5206\u6790\u786e\u5b9a\u6700\u4f18\u5e38\u6570C_{\u03b1,K}\uff0c\u8bc1\u660e\u5bf9\u4e8e\u6240\u6709(\u03b1,K)\u9009\u62e9\uff0c\u4e0d\u7b49\u5f0fD\u03b1(p\u2225q) \u2265 C_{\u03b1,K}/2\u00b7\u2016p-q\u2016\u2081\u00b2\u6210\u7acb\u3002", "result": "\u8bc1\u660e\u4e86\u5e7f\u4e49Pinsker\u4e0d\u7b49\u5f0f\uff1a\u5bf9\u4e8e\u6982\u7387\u5355\u7eaf\u5f62\u0394^K\u76f8\u5bf9\u5185\u90e8\u4efb\u610fp,q\uff0c\u6709D\u03b1(p\u2225q) \u2265 C_{\u03b1,K}/2\u00b7\u2016p-q\u2016\u2081\u00b2\uff0c\u5176\u4e2dC_{\u03b1,K}\u662f\u6700\u4f18\u5e38\u6570\u3002\u4e3a\u6bcf\u4e2a(\u03b1,K)\u7ec4\u5408\u660e\u786e\u786e\u5b9a\u4e86\u6700\u4f18\u5e38\u6570\uff0c\u5efa\u7acb\u4e86\u03b2-\u6563\u5ea6\u7684\u5c16\u9510\u4e0b\u754c\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5efa\u7acb\u4e86\u8d1f\u03b1-Tsallis\u71b5\u751f\u6210\u7684Bregman\u6563\u5ea6\u7684\u5e7f\u4e49Pinsker\u4e0d\u7b49\u5f0f\uff0c\u4e3aTsallis\u635f\u5931\u7684\u6982\u7387\u9884\u6d4b\u548c\u5728\u7ebf\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u5de5\u5177\uff0c\u5c06\u4f20\u7edfPinsker\u4e0d\u7b49\u5f0f\u63a8\u5e7f\u5230\u66f4\u4e00\u822c\u7684\u6563\u5ea6\u5ea6\u91cf\u6846\u67b6\u3002"}}
{"id": "2602.05904", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2602.05904", "abs": "https://arxiv.org/abs/2602.05904", "authors": ["Nikhil Bansal", "Neng Huang", "Euiwoong Lee"], "title": "Improved SDP-Based Algorithm for Coloring 3-Colorable Graphs", "comment": "32 pages", "summary": "We present a polynomial-time algorithm that colors any 3-colorable $n$-vertex graph using $O(n^{0.19539})$ colors, improving upon the previous best bound of $\\widetilde{O}(n^{0.19747})$ by Kawarabayashi, Thorup, and Yoneda [STOC 2024]. Our result constitutes the first progress in nearly two decades on SDP-based approaches to this problem.\n  The earlier SDP-based algorithms of Arora, Chlamt\u00e1\u010d, and Charikar [STOC 2006] and Chlamt\u00e1\u010d [FOCS 2007] rely on extracting a large independent set from a suitably \"random-looking\" second-level neighborhood, under the assumption that the KMS algorithm [Karger, Motwani, and Sudan, JACM 1998] fails to find one globally. We extend their analysis to third-level neighborhoods. We then come up with a new vector $5/2$-coloring, which allows us to extract a large independent set from some third-level neighborhood. The new vector coloring construction may be of independent interest.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u4e3a\u4efb\u610f3\u53ef\u7740\u8272n\u9876\u70b9\u56fe\u4f7f\u7528O(n^0.19539)\u79cd\u989c\u8272\u7740\u8272\uff0c\u6539\u8fdb\u4e86\u4e4b\u524d\u7684\u6700\u4f73\u8fb9\u754c\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u6539\u8fdb3\u53ef\u7740\u8272\u56fe\u7684\u8fd1\u4f3c\u7740\u8272\u7b97\u6cd5\uff0c\u8fd9\u662f\u8fd1\u4e8c\u5341\u5e74\u6765SDP\uff08\u534a\u6b63\u5b9a\u89c4\u5212\uff09\u65b9\u6cd5\u5728\u8be5\u95ee\u9898\u4e0a\u7684\u9996\u6b21\u8fdb\u5c55\u3002", "method": "\u6269\u5c55\u4e86\u5148\u524dSDP\u7b97\u6cd5\u7684\u5206\u6790\u5230\u7b2c\u4e09\u7ea7\u90bb\u57df\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u5411\u91cf5/2\u7740\u8272\u65b9\u6cd5\uff0c\u53ef\u4ee5\u4ece\u7b2c\u4e09\u7ea7\u90bb\u57df\u4e2d\u63d0\u53d6\u5927\u7684\u72ec\u7acb\u96c6\u3002", "result": "\u7b97\u6cd5\u5c063\u53ef\u7740\u8272\u56fe\u7684\u7740\u8272\u989c\u8272\u6570\u4ece\u4e4b\u524d\u7684O(n^0.19747)\u6539\u8fdb\u5230O(n^0.19539)\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6e10\u8fdb\u6539\u8fdb\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4ee3\u8868\u4e86\u8fd1\u4e8c\u5341\u5e74\u67653\u53ef\u7740\u8272\u56feSDP\u65b9\u6cd5\u7684\u9996\u6b21\u8fdb\u5c55\uff0c\u65b0\u7684\u5411\u91cf\u7740\u8272\u6784\u9020\u53ef\u80fd\u5177\u6709\u72ec\u7acb\u7684\u7814\u7a76\u4ef7\u503c\u3002"}}
{"id": "2602.05366", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05366", "abs": "https://arxiv.org/abs/2602.05366", "authors": ["Yichen Tang", "Weihang Su", "Yiqun Liu", "Qingyao Ai"], "title": "Multi-Field Tool Retrieval", "comment": "12 pages, 4 figures", "summary": "Integrating external tools enables Large Language Models (LLMs) to interact with real-world environments and solve complex tasks. Given the growing scale of available tools, effective tool retrieval is essential to mitigate constraints of LLMs' context windows and ensure computational efficiency. Existing approaches typically treat tool retrieval as a traditional ad-hoc retrieval task, matching user queries against the entire raw tool documentation. In this paper, we identify three fundamental challenges that limit the effectiveness of this paradigm: (i) the incompleteness and structural inconsistency of tool documentation; (ii) the significant semantic and granular mismatch between user queries and technical tool documents; and, most importantly, (iii) the multi-aspect nature of tool utility, that involves distinct dimensions, such as functionality, input constraints, and output formats, varying in format and importance. To address these challenges, we introduce Multi-Field Tool Retrieval, a framework designed to align user intent with tool representations through fine-grained, multi-field modeling. Experimental results show that our framework achieves SOTA performance on five datasets and a mixed benchmark, exhibiting superior generalizability and robustness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5b57\u6bb5\u5de5\u5177\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u591a\u5b57\u6bb5\u5efa\u6a21\u89e3\u51b3LLM\u5de5\u5177\u68c0\u7d22\u4e2d\u7684\u6587\u6863\u4e0d\u5b8c\u6574\u3001\u8bed\u4e49\u4e0d\u5339\u914d\u548c\u591a\u7ef4\u5ea6\u5de5\u5177\u6548\u7528\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u68c0\u7d22\u65b9\u6cd5\u5c06\u5de5\u5177\u68c0\u7d22\u89c6\u4e3a\u4f20\u7edfad-hoc\u68c0\u7d22\u4efb\u52a1\uff0c\u5b58\u5728\u4e09\u4e2a\u6839\u672c\u6311\u6218\uff1a1) \u5de5\u5177\u6587\u6863\u4e0d\u5b8c\u6574\u548c\u7ed3\u6784\u4e0d\u4e00\u81f4\uff1b2) \u7528\u6237\u67e5\u8be2\u4e0e\u6280\u672f\u5de5\u5177\u6587\u6863\u4e4b\u95f4\u7684\u663e\u8457\u8bed\u4e49\u548c\u7c92\u5ea6\u4e0d\u5339\u914d\uff1b3) \u5de5\u5177\u6548\u7528\u7684\u591a\u7ef4\u5ea6\u7279\u6027\uff08\u529f\u80fd\u3001\u8f93\u5165\u7ea6\u675f\u3001\u8f93\u51fa\u683c\u5f0f\u7b49\uff09\u3002", "method": "\u63d0\u51fa\u591a\u5b57\u6bb5\u5de5\u5177\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u591a\u5b57\u6bb5\u5efa\u6a21\u5bf9\u9f50\u7528\u6237\u610f\u56fe\u4e0e\u5de5\u5177\u8868\u793a\uff0c\u89e3\u51b3\u6587\u6863\u4e0d\u5b8c\u6574\u3001\u8bed\u4e49\u4e0d\u5339\u914d\u548c\u591a\u7ef4\u5ea6\u5de5\u5177\u6548\u7528\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u6df7\u5408\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86SOTA\u6027\u80fd\uff0c\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u591a\u5b57\u6bb5\u5de5\u5177\u68c0\u7d22\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u68c0\u7d22\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5efa\u6a21\u663e\u8457\u63d0\u5347\u4e86\u5de5\u5177\u68c0\u7d22\u7684\u6027\u80fd\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2602.05674", "categories": ["cs.DB", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.05674", "abs": "https://arxiv.org/abs/2602.05674", "authors": ["Miguel Fuentes", "Brett Mullins", "Yingtai Xiao", "Daniel Kifer", "Cameron Musco", "Daniel Sheldon"], "title": "Fast Private Adaptive Query Answering for Large Data Domains", "comment": null, "summary": "Privately releasing marginals of a tabular dataset is a foundational problem in differential privacy. However, state-of-the-art mechanisms suffer from a computational bottleneck when marginal estimates are reconstructed from noisy measurements. Recently, residual queries were introduced and shown to lead to highly efficient reconstruction in the batch query answering setting. We introduce new techniques to integrate residual queries into state-of-the-art adaptive mechanisms such as AIM. Our contributions include a novel conceptual framework for residual queries using multi-dimensional arrays, lazy updating strategies, and adaptive optimization of the per-round privacy budget allocation. Together these contributions reduce error, improve speed, and simplify residual query operations. We integrate these innovations into a new mechanism (AIM+GReM), which improves AIM by using fast residual-based reconstruction instead of a graphical model approach. Our mechanism is orders of magnitude faster than the original framework and demonstrates competitive error and greatly improved scalability.", "AI": {"tldr": "\u63d0\u51faAIM+GReM\u673a\u5236\uff0c\u901a\u8fc7\u6b8b\u5dee\u67e5\u8be2\u548c\u9ad8\u6548\u91cd\u6784\u6539\u8fdb\u5dee\u5206\u9690\u79c1\u8fb9\u9645\u91ca\u653e\uff0c\u5927\u5e45\u63d0\u5347\u8ba1\u7b97\u6548\u7387", "motivation": "\u73b0\u6709\u5dee\u5206\u9690\u79c1\u8fb9\u9645\u91ca\u653e\u673a\u5236\u5728\u4ece\u566a\u58f0\u6d4b\u91cf\u91cd\u6784\u8fb9\u9645\u4f30\u8ba1\u65f6\u5b58\u5728\u8ba1\u7b97\u74f6\u9888\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51fa\u57fa\u4e8e\u591a\u7ef4\u6570\u7ec4\u7684\u6b8b\u5dee\u67e5\u8be2\u6982\u5ff5\u6846\u67b6\u3001\u60f0\u6027\u66f4\u65b0\u7b56\u7565\u548c\u81ea\u9002\u5e94\u9690\u79c1\u9884\u7b97\u5206\u914d\uff0c\u5c06\u6b8b\u5dee\u67e5\u8be2\u96c6\u6210\u5230AIM\u7b49\u81ea\u9002\u5e94\u673a\u5236\u4e2d", "result": "AIM+GReM\u673a\u5236\u6bd4\u539f\u59cb\u6846\u67b6\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u5177\u6709\u7ade\u4e89\u6027\u7684\u8bef\u5dee\u548c\u663e\u8457\u6539\u5584\u7684\u53ef\u6269\u5c55\u6027", "conclusion": "\u6b8b\u5dee\u67e5\u8be2\u4e0e\u81ea\u9002\u5e94\u673a\u5236\u7684\u96c6\u6210\u80fd\u6709\u6548\u89e3\u51b3\u5dee\u5206\u9690\u79c1\u8fb9\u9645\u91ca\u653e\u7684\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u51c6\u786e\u7684\u9690\u79c1\u4fdd\u62a4\u6570\u636e\u53d1\u5e03"}}
{"id": "2602.05751", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.05751", "abs": "https://arxiv.org/abs/2602.05751", "authors": ["Ravi Sharan Bhagavathula", "Pavan Koteshwar Srinath", "Alvaro Valcarce Rial", "Baltasar-Beferull Lozano"], "title": "MU-MIMO Uplink Timely Throughput Maximization for Extended Reality Applications", "comment": "14 pages, single column, 4 figures. This work has been submitted to the IEEE for possible publication", "summary": "In this work, we study the cross-layer timely throughput maximization for extended reality (XR) applications through uplink multi-user MIMO (MU-MIMO) scheduling. Timely scheduling opportunities are characterized by the peak age of information (PAoI)-metric and are incorporated into a network-side optimization problem as constraints modeling user satisfaction. The problem being NP-hard, we resort to a signaling-free, weighted proportional fair-based iterative heuristic algorithm, where the weights are derived with respect to the PAoI metric. Extensive numerical simulation results demonstrate that the proposed algorithm consistently outperforms existing baselines in terms of XR capacity without sacrificing the overall system throughput.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u52a0\u6743\u6bd4\u4f8b\u516c\u5e73\u7684\u8fed\u4ee3\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u901a\u8fc7\u4e0a\u884cMU-MIMO\u8c03\u5ea6\u6700\u5927\u5316XR\u5e94\u7528\u7684\u8de8\u5c42\u53ca\u65f6\u541e\u5410\u91cf\uff0c\u5728\u4fdd\u6301\u7cfb\u7edf\u603b\u541e\u5410\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347XR\u5bb9\u91cf\u3002", "motivation": "\u7814\u7a76\u6269\u5c55\u73b0\u5b9e(XR)\u5e94\u7528\u7684\u4e0a\u884c\u591a\u7528\u6237MIMO\u8c03\u5ea6\u4e2d\u7684\u8de8\u5c42\u53ca\u65f6\u541e\u5410\u91cf\u6700\u5927\u5316\u95ee\u9898\uff0c\u9700\u8981\u6ee1\u8db3\u7528\u6237\u5bf9\u4fe1\u606f\u65b0\u9c9c\u5ea6\uff08PAoI\uff09\u7684\u8981\u6c42\u3002", "method": "\u91c7\u7528\u65e0\u4fe1\u4ee4\u7684\u52a0\u6743\u6bd4\u4f8b\u516c\u5e73\u8fed\u4ee3\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u6743\u91cd\u6839\u636ePAoI\u6307\u6807\u63a8\u5bfc\uff0c\u5c06\u53ca\u65f6\u8c03\u5ea6\u673a\u4f1a\u4f5c\u4e3a\u7528\u6237\u6ee1\u610f\u5ea6\u7ea6\u675f\u7eb3\u5165\u7f51\u7edc\u4fa7\u4f18\u5316\u95ee\u9898\u3002", "result": "\u5e7f\u6cdb\u7684\u6570\u503c\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u4fdd\u6301\u6574\u4f53\u7cfb\u7edf\u541e\u5410\u91cf\u7684\u540c\u65f6\uff0c\u5728XR\u5bb9\u91cf\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86NP-hard\u7684\u8de8\u5c42\u53ca\u65f6\u541e\u5410\u91cf\u4f18\u5316\u95ee\u9898\uff0c\u4e3aXR\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u670d\u52a1\u8d28\u91cf\u4fdd\u969c\u3002"}}
{"id": "2602.05925", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2602.05925", "abs": "https://arxiv.org/abs/2602.05925", "authors": ["G\u00e1bor Melis"], "title": "Adaptive Hashing: Faster Hash Functions with Fewer Collisions", "comment": null, "summary": "Hash tables are ubiquitous, and the choice of hash function, which maps a key to a bucket, is key to their performance. We argue that the predominant approach of fixing the hash function for the lifetime of the hash table is suboptimal and propose adapting it to the current set of keys. In the prevailing view, good hash functions spread the keys ``randomly'' and are fast to evaluate. General-purpose ones (e.g. Murmur) are designed to do both while remaining agnostic to the distribution of the keys, which limits their bucketing ability and wastes computation. When these shortcomings are recognized, one may specify a hash function more tailored to some assumed key distribution, but doing so almost always introduces an unbounded risk in case this assumption does not bear out in practice. At the other, fully key-aware end of the spectrum, Perfect Hashing algorithms can discover hash functions to bucket a given set of keys optimally, but they are costly to run and require the keys to be known and fixed ahead of time. Our main conceptual contribution is that adapting the hash table's hash function to the keys online is necessary for the best performance, as adaptivity allows for better bucketing of keys \\emph{and} faster hash functions. We instantiate the idea of online adaptation with minimal overhead and no change to the hash table API. The experiments show that the adaptive approach marries the common-case performance of weak hash functions with the robustness of general-purpose ones.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u54c8\u5e0c\u51fd\u6570\u65b9\u6cd5\uff0c\u6839\u636e\u5f53\u524d\u952e\u96c6\u52a8\u6001\u8c03\u6574\u54c8\u5e0c\u51fd\u6570\uff0c\u4ee5\u63d0\u5347\u54c8\u5e0c\u8868\u6027\u80fd", "motivation": "\u4f20\u7edf\u54c8\u5e0c\u8868\u5728\u6574\u4e2a\u751f\u547d\u5468\u671f\u4e2d\u4f7f\u7528\u56fa\u5b9a\u54c8\u5e0c\u51fd\u6570\u5b58\u5728\u5c40\u9650\u6027\uff1a\u901a\u7528\u54c8\u5e0c\u51fd\u6570\uff08\u5982Murmur\uff09\u5bf9\u952e\u5206\u5e03\u4e0d\u654f\u611f\uff0c\u5bfc\u81f4\u5206\u6876\u80fd\u529b\u6709\u9650\u4e14\u6d6a\u8d39\u8ba1\u7b97\uff1b\u9488\u5bf9\u7279\u5b9a\u5206\u5e03\u5b9a\u5236\u7684\u54c8\u5e0c\u51fd\u6570\u5728\u5047\u8bbe\u4e0d\u6210\u7acb\u65f6\u98ce\u9669\u9ad8\uff1b\u5b8c\u7f8e\u54c8\u5e0c\u7b97\u6cd5\u6210\u672c\u9ad8\u4e14\u9700\u8981\u9884\u5148\u77e5\u9053\u56fa\u5b9a\u952e\u96c6\u3002\u9700\u8981\u4e00\u79cd\u5728\u7ebf\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u6765\u5e73\u8861\u6027\u80fd\u4e0e\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u5728\u7ebf\u81ea\u9002\u5e94\u54c8\u5e0c\u51fd\u6570\u65b9\u6cd5\uff0c\u5728\u8fd0\u884c\u65f6\u6839\u636e\u5f53\u524d\u952e\u96c6\u52a8\u6001\u8c03\u6574\u54c8\u5e0c\u51fd\u6570\uff0c\u4ee5\u6700\u5c0f\u5f00\u9500\u5b9e\u73b0\uff0c\u4e14\u4e0d\u6539\u53d8\u54c8\u5e0c\u8868API\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u5f31\u54c8\u5e0c\u51fd\u6570\u7684\u5e38\u89c1\u60c5\u51b5\u6027\u80fd\u548c\u901a\u7528\u54c8\u5e0c\u51fd\u6570\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u81ea\u9002\u5e94\u65b9\u6cd5\u80fd\u591f\u7ed3\u5408\u5f31\u54c8\u5e0c\u51fd\u6570\u7684\u5e38\u89c1\u60c5\u51b5\u6027\u80fd\u548c\u901a\u7528\u54c8\u5e0c\u51fd\u6570\u7684\u9c81\u68d2\u6027\uff0c\u5b9e\u73b0\u66f4\u597d\u7684\u952e\u5206\u6876\u548c\u66f4\u5feb\u7684\u54c8\u5e0c\u51fd\u6570\u8ba1\u7b97\u3002", "conclusion": "\u54c8\u5e0c\u8868\u54c8\u5e0c\u51fd\u6570\u7684\u5728\u7ebf\u81ea\u9002\u5e94\u662f\u63d0\u5347\u6027\u80fd\u7684\u5fc5\u8981\u6761\u4ef6\uff0c\u81ea\u9002\u5e94\u65b9\u6cd5\u80fd\u591f\u5728\u8fd0\u884c\u65f6\u6839\u636e\u952e\u96c6\u4f18\u5316\u54c8\u5e0c\u51fd\u6570\uff0c\u5b9e\u73b0\u66f4\u597d\u7684\u5206\u6876\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2602.05408", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.05408", "abs": "https://arxiv.org/abs/2602.05408", "authors": ["Zihao Guo", "Ligang Zhou", "Zeyang Tang", "Feicheng Li", "Ying Nie", "Zhiming Peng", "Qingyun Sun", "Jianxin Li"], "title": "Rich-Media Re-Ranker: A User Satisfaction-Driven LLM Re-ranking Framework for Rich-Media Search", "comment": null, "summary": "Re-ranking plays a crucial role in modern information search systems by refining the ranking of initial search results to better satisfy user information needs. However, existing methods show two notable limitations in improving user search satisfaction: inadequate modeling of multifaceted user intents and neglect of rich side information such as visual perception signals. To address these challenges, we propose the Rich-Media Re-Ranker framework, which aims to enhance user search satisfaction through multi-dimensional and fine-grained modeling. Our approach begins with a Query Planner that analyzes the sequence of query refinements within a session to capture genuine search intents, decomposing the query into clear and complementary sub-queries to enable broader coverage of users' potential intents. Subsequently, moving beyond primary text content, we integrate richer side information of candidate results, including signals modeling visual content generated by the VLM-based evaluator. These comprehensive signals are then processed alongside carefully designed re-ranking principle that considers multiple facets, including content relevance and quality, information gain, information novelty, and the visual presentation of cover images. Then, the LLM-based re-ranker performs the holistic evaluation based on these principles and integrated signals. To enhance the scenario adaptability of the VLM-based evaluator and the LLM-based re-ranker, we further enhance their capabilities through multi-task reinforcement learning. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines. Notably, the proposed framework has been deployed in a large-scale industrial search system, yielding substantial improvements in online user engagement rates and satisfaction metrics.", "AI": {"tldr": "\u63d0\u51faRich-Media Re-Ranker\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7ef4\u5ea6\u7ec6\u7c92\u5ea6\u5efa\u6a21\u63d0\u5347\u641c\u7d22\u6ee1\u610f\u5ea6\uff0c\u7ed3\u5408\u67e5\u8be2\u610f\u56fe\u5206\u6790\u3001\u89c6\u89c9\u5185\u5bb9\u4fe1\u53f7\u548cLLM\u91cd\u6392\u5e8f\uff0c\u5df2\u5728\u5de5\u4e1a\u7cfb\u7edf\u90e8\u7f72\u5e76\u663e\u8457\u6539\u5584\u7528\u6237\u53c2\u4e0e\u5ea6\u3002", "motivation": "\u73b0\u6709\u91cd\u6392\u5e8f\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u5c40\u9650\uff1a1) \u5bf9\u591a\u9762\u7528\u6237\u610f\u56fe\u5efa\u6a21\u4e0d\u8db3\uff1b2) \u5ffd\u89c6\u89c6\u89c9\u611f\u77e5\u7b49\u4e30\u5bcc\u4fa7\u4fe1\u606f\u3002\u8fd9\u9650\u5236\u4e86\u641c\u7d22\u6ee1\u610f\u5ea6\u7684\u63d0\u5347\u3002", "method": "1) Query Planner\u5206\u6790\u4f1a\u8bdd\u4e2d\u7684\u67e5\u8be2\u5e8f\u5217\u6355\u83b7\u771f\u5b9e\u610f\u56fe\uff0c\u5206\u89e3\u4e3a\u4e92\u8865\u5b50\u67e5\u8be2\uff1b2) \u6574\u5408\u5019\u9009\u7ed3\u679c\u7684\u4e30\u5bcc\u4fa7\u4fe1\u606f\uff0c\u5305\u62ecVLM\u751f\u6210\u7684\u89c6\u89c9\u5185\u5bb9\u4fe1\u53f7\uff1b3) \u8bbe\u8ba1\u91cd\u6392\u5e8f\u539f\u5219\u8003\u8651\u5185\u5bb9\u76f8\u5173\u6027\u3001\u8d28\u91cf\u3001\u4fe1\u606f\u589e\u76ca\u3001\u65b0\u9896\u6027\u548c\u5c01\u9762\u89c6\u89c9\u5448\u73b0\uff1b4) LLM\u57fa\u4e8e\u8fd9\u4e9b\u539f\u5219\u548c\u4fe1\u53f7\u8fdb\u884c\u6574\u4f53\u8bc4\u4f30\uff1b5) \u901a\u8fc7\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u589e\u5f3aVLM\u8bc4\u4f30\u5668\u548cLLM\u91cd\u6392\u5e8f\u5668\u7684\u573a\u666f\u9002\u5e94\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u3002\u6846\u67b6\u5df2\u5728\u5927\u578b\u5de5\u4e1a\u641c\u7d22\u7cfb\u7edf\u90e8\u7f72\uff0c\u5728\u7ebf\u7528\u6237\u53c2\u4e0e\u7387\u548c\u6ee1\u610f\u5ea6\u6307\u6807\u83b7\u5f97\u5b9e\u8d28\u6027\u63d0\u5347\u3002", "conclusion": "Rich-Media Re-Ranker\u6846\u67b6\u901a\u8fc7\u591a\u7ef4\u5ea6\u7ec6\u7c92\u5ea6\u5efa\u6a21\u6709\u6548\u63d0\u5347\u641c\u7d22\u6ee1\u610f\u5ea6\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u610f\u56fe\u5efa\u6a21\u548c\u4fa7\u4fe1\u606f\u5229\u7528\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u5728\u5b9e\u9645\u5de5\u4e1a\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2602.05708", "categories": ["cs.DB", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05708", "abs": "https://arxiv.org/abs/2602.05708", "authors": ["Chuangtao Ma", "Zeyu Zhang", "Arijit Khan", "Sebastian Schelter", "Paul Groth"], "title": "Cost-Efficient RAG for Entity Matching with LLMs: A Blocking-based Exploration", "comment": null, "summary": "Retrieval-augmented generation (RAG) enhances LLM reasoning in knowledge-intensive tasks, but existing RAG pipelines incur substantial retrieval and generation overhead when applied to large-scale entity matching. To address this limitation, we introduce CE-RAG4EM, a cost-efficient RAG architecture that reduces computation through blocking-based batch retrieval and generation. We also present a unified framework for analyzing and evaluating RAG systems for entity matching, focusing on blocking-aware optimizations and retrieval granularity. Extensive experiments suggest that CE-RAG4EM can achieve comparable or improved matching quality while substantially reducing end-to-end runtime relative to strong baselines. Our analysis further reveals that key configuration parameters introduce an inherent trade-off between performance and overhead, offering practical guidance for designing efficient and scalable RAG systems for entity matching and data integration.", "AI": {"tldr": "CE-RAG4EM\uff1a\u4e00\u79cd\u7528\u4e8e\u5b9e\u4f53\u5339\u914d\u7684\u6210\u672c\u9ad8\u6548RAG\u67b6\u6784\uff0c\u901a\u8fc7\u57fa\u4e8e\u5206\u5757\u7684\u6279\u91cf\u68c0\u7d22\u548c\u751f\u6210\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff0c\u5728\u4fdd\u6301\u5339\u914d\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u7aef\u5230\u7aef\u8fd0\u884c\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u7684RAG\u7ba1\u9053\u5728\u5927\u89c4\u6a21\u5b9e\u4f53\u5339\u914d\u5e94\u7528\u4e2d\u5b58\u5728\u663e\u8457\u7684\u68c0\u7d22\u548c\u751f\u6210\u5f00\u9500\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5e73\u8861\u6027\u80fd\u548c\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u63d0\u51faCE-RAG4EM\u67b6\u6784\uff0c\u91c7\u7528\u57fa\u4e8e\u5206\u5757\u7684\u6279\u91cf\u68c0\u7d22\u548c\u751f\u6210\u7b56\u7565\uff1b\u5efa\u7acb\u7edf\u4e00\u7684RAG\u7cfb\u7edf\u5206\u6790\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u91cd\u70b9\u5173\u6ce8\u5206\u5757\u611f\u77e5\u4f18\u5316\u548c\u68c0\u7d22\u7c92\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCE-RAG4EM\u80fd\u591f\u8fbe\u5230\u53ef\u6bd4\u6216\u6539\u8fdb\u7684\u5339\u914d\u8d28\u91cf\uff0c\u540c\u65f6\u76f8\u5bf9\u4e8e\u5f3a\u57fa\u7ebf\u663e\u8457\u51cf\u5c11\u7aef\u5230\u7aef\u8fd0\u884c\u65f6\u95f4\uff1b\u5206\u6790\u63ed\u793a\u4e86\u5173\u952e\u914d\u7f6e\u53c2\u6570\u5728\u6027\u80fd\u548c\u5f00\u9500\u4e4b\u95f4\u7684\u56fa\u6709\u6743\u8861\u3002", "conclusion": "CE-RAG4EM\u4e3a\u5b9e\u4f53\u5339\u914d\u548c\u6570\u636e\u96c6\u6210\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u6269\u5c55\u7684RAG\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u5173\u952e\u914d\u7f6e\u53c2\u6570\u7684\u6743\u8861\u5206\u6790\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2602.05790", "categories": ["cs.IT", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.05790", "abs": "https://arxiv.org/abs/2602.05790", "authors": ["Alina Harbuzova", "Or Ordentlich", "Yury Polyanskiy"], "title": "Price of universality in vector quantization is at most 0.11 bit", "comment": "41 page, 1 figure", "summary": "Fast computation of a matrix product $W^\\top X$ is a workhorse of modern LLMs. To make their deployment more efficient, a popular approach is that of using a low-precision approximation $\\widehat W$ in place of true $W$ (\"weight-only quantization''). Information theory demonstrates that an optimal algorithm for reducing precision of $W$ depends on the (second order) statistics of $X$ and requires a careful alignment of vector quantization codebook with PCA directions of $X$ (a process known as \"waterfilling allocation''). Dependence of the codebook on statistics of $X$, however, is highly impractical. This paper proves that there exist a universal codebook that is simultaneously near-optimal for all possible statistics of $X$, in the sense of being at least as good as an $X$-adapted waterfilling codebook with rate reduced by 0.11 bit per dimension. Such universal codebook would be an ideal candidate for the low-precision storage format, a topic of active modern research, but alas the existence proof is non-constructive.\n  Equivalently, our result shows existence of a net in $\\mathbb{R}^n$ that is a nearly-optimal covering of a sphere simultaneously with respect to all Hilbert norms.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u5b58\u5728\u4e00\u4e2a\u901a\u7528\u7801\u672c\uff0c\u5bf9\u4e8e\u6240\u6709\u53ef\u80fd\u7684\u8f93\u5165\u7edf\u8ba1\u7279\u6027\u90fd\u8fd1\u4f3c\u6700\u4f18\uff0c\u6bd4\u9488\u5bf9\u7279\u5b9a\u7edf\u8ba1\u7279\u6027\u8bbe\u8ba1\u7684\u6700\u4f18\u7801\u672c\u4ec5\u591a\u6d88\u80170.11\u6bd4\u7279/\u7ef4\u5ea6\u7684\u989d\u5916\u7801\u7387\u3002", "motivation": "\u5728LLM\u90e8\u7f72\u4e2d\uff0c\u4f4e\u7cbe\u5ea6\u8fd1\u4f3c\uff08\u4ec5\u6743\u91cd\u91cf\u5316\uff09\u662f\u63d0\u9ad8\u6548\u7387\u7684\u6d41\u884c\u65b9\u6cd5\u3002\u4fe1\u606f\u8bba\u8868\u660e\uff0c\u6700\u4f18\u7684\u91cf\u5316\u7b97\u6cd5\u4f9d\u8d56\u4e8e\u8f93\u5165X\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u9700\u8981\u5c06\u77e2\u91cf\u91cf\u5316\u7801\u672c\u4e0eX\u7684PCA\u65b9\u5411\u5bf9\u9f50\uff08\u6c34\u586b\u5145\u5206\u914d\uff09\u3002\u4f46\u8fd9\u79cd\u5bf9X\u7edf\u8ba1\u7279\u6027\u7684\u4f9d\u8d56\u5728\u5b9e\u9645\u4e2d\u4e0d\u5207\u5b9e\u9645\uff0c\u56e0\u6b64\u9700\u8981\u5bfb\u627e\u4e0d\u4f9d\u8d56\u7edf\u8ba1\u7279\u6027\u7684\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u7684\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5b58\u5728\u4e00\u4e2a\u901a\u7528\u7801\u672c\uff0c\u8be5\u7801\u672c\u5bf9\u6240\u6709\u53ef\u80fd\u7684\u8f93\u5165\u7edf\u8ba1\u7279\u6027\u90fd\u540c\u65f6\u8fd1\u4f3c\u6700\u4f18\u3002\u7b49\u4ef7\u5730\uff0c\u8bc1\u660e\u4e86\u5728\u211d\u207f\u4e2d\u5b58\u5728\u4e00\u4e2a\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u80fd\u591f\u540c\u65f6\u4ee5\u6240\u6709\u5e0c\u5c14\u4f2f\u7279\u8303\u6570\u8fd1\u4f3c\u6700\u4f18\u5730\u8986\u76d6\u7403\u9762\u3002", "result": "\u5b58\u5728\u4e00\u4e2a\u901a\u7528\u7801\u672c\uff0c\u5bf9\u4e8e\u6240\u6709\u53ef\u80fd\u7684\u8f93\u5165\u7edf\u8ba1\u7279\u6027\uff0c\u5176\u6027\u80fd\u81f3\u5c11\u4e0e\u9488\u5bf9\u7279\u5b9a\u7edf\u8ba1\u7279\u6027\u8bbe\u8ba1\u7684\u6c34\u586b\u5145\u7801\u672c\uff08\u7801\u7387\u51cf\u5c110.11\u6bd4\u7279/\u7ef4\u5ea6\uff09\u4e00\u6837\u597d\u3002\u8be5\u7ed3\u679c\u662f\u975e\u6784\u9020\u6027\u7684\u5b58\u5728\u6027\u8bc1\u660e\u3002", "conclusion": "\u867d\u7136\u5b58\u5728\u6027\u8bc1\u660e\u662f\u975e\u6784\u9020\u6027\u7684\uff0c\u4f46\u8be5\u7ed3\u679c\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u901a\u7528\u4f4e\u7cbe\u5ea6\u5b58\u50a8\u683c\u5f0f\u7684\u53ef\u80fd\u6027\uff0c\u8fd9\u4e3a\u73b0\u4ee3LLM\u90e8\u7f72\u4e2d\u7684\u9ad8\u6548\u91cf\u5316\u65b9\u6848\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7406\u8bba\u4f9d\u636e\uff0c\u662f\u5f53\u524d\u7814\u7a76\u7684\u70ed\u70b9\u8bdd\u9898\u3002"}}
{"id": "2602.05953", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2602.05953", "abs": "https://arxiv.org/abs/2602.05953", "authors": ["Lamya Alif", "Raian Tasnim Saoda", "Sumaiya Afrin", "Md. Rawha Siddiqi Riad", "Md. Tanzeem Rahat", "Md Manzurul Hasan"], "title": "Competitive Analysis of Online Facility Assignment Algorithms on Discrete Grid Graphs: Performance Bounds and Remediation Strategies", "comment": null, "summary": "We study the \\emph{Online Facility Assignment} (OFA) problem on a discrete $r\\times c$ grid graph under the standard model of Ahmed, Rahman, and Kobourov: a fixed set of facilities is given, each with limited capacity, and an online sequence of unit-demand requests must be irrevocably assigned upon arrival to an available facility, incurring Manhattan ($L_1$) distance cost. We investigate how the discrete geometry of grids interacts with capacity depletion by analyzing two natural baselines and one capacity-aware heuristic. First, we give explicit adversarial sequences on grid instances showing that purely local rules can be forced into large competitive ratios: (i) a capacity-sensitive weighted-Voronoi heuristic (\\textsc{CS-Voronoi}) can suffer cascading \\emph{region-collapse} effects when nearby capacity is exhausted; and (ii) nearest-available \\textsc{Greedy} (with randomized tie-breaking) can be driven into repeated long reassignments via an \\emph{oscillation} construction. These results formalize geometric failure modes that are specific to discrete $L_1$ metrics with hard capacities. Motivated by these lower bounds, we then discuss a semi-online extension in which the algorithm may delay assignment for up to $\u03c4$ time steps and solve each batch optimally via a min-cost flow computation. We present this batching framework as a remediation strategy and delineate the parameters that govern its performance, while leaving sharp competitive guarantees for this semi-online variant as an open direction.", "AI": {"tldr": "\u7814\u7a76\u7f51\u683c\u56fe\u4e0a\u7684\u5728\u7ebf\u8bbe\u65bd\u5206\u914d\u95ee\u9898\uff0c\u5206\u6790\u4e24\u79cd\u57fa\u7ebf\u7b97\u6cd5\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u63d0\u51fa\u534a\u5728\u7ebf\u6279\u5904\u7406\u6846\u67b6\u4f5c\u4e3a\u6539\u8fdb\u65b9\u6848", "motivation": "\u7814\u7a76\u79bb\u6563\u7f51\u683c\u51e0\u4f55\u4e0e\u5bb9\u91cf\u9650\u5236\u5982\u4f55\u5f71\u54cd\u5728\u7ebf\u8bbe\u65bd\u5206\u914d\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u63ed\u793a\u7279\u5b9a\u4e8eL1\u5ea6\u91cf\u548c\u786c\u5bb9\u91cf\u9650\u5236\u7684\u51e0\u4f55\u5931\u6548\u6a21\u5f0f", "method": "1) \u6784\u9020\u5bf9\u6297\u6027\u5e8f\u5217\u5c55\u793aCS-Voronoi\u7b97\u6cd5\u7684\u533a\u57df\u5d29\u6e83\u6548\u5e94\u548cGreedy\u7b97\u6cd5\u7684\u632f\u8361\u95ee\u9898\uff1b2) \u63d0\u51fa\u534a\u5728\u7ebf\u6269\u5c55\uff0c\u5141\u8bb8\u5ef6\u8fdf\u5206\u914d\u5e76\u901a\u8fc7\u6700\u5c0f\u6210\u672c\u6d41\u8ba1\u7b97\u6279\u91cf\u6700\u4f18\u89e3", "result": "\u8bc1\u660e\u4e86\u7eaf\u5c40\u90e8\u89c4\u5219\u5728\u7f51\u683c\u5b9e\u4f8b\u4e0a\u53ef\u80fd\u4ea7\u751f\u8f83\u5927\u7684\u7ade\u4e89\u6bd4\uff0c\u5f62\u5f0f\u5316\u4e86\u79bb\u6563L1\u5ea6\u91cf\u4e0b\u7684\u51e0\u4f55\u5931\u6548\u6a21\u5f0f\uff0c\u63d0\u51fa\u4e86\u6279\u5904\u7406\u6846\u67b6\u4f5c\u4e3a\u8865\u6551\u7b56\u7565", "conclusion": "\u79bb\u6563\u7f51\u683c\u51e0\u4f55\u4e0e\u5bb9\u91cf\u9650\u5236\u7684\u4ea4\u4e92\u4f1a\u5bfc\u81f4\u7279\u5b9a\u5931\u6548\u6a21\u5f0f\uff0c\u534a\u5728\u7ebf\u6279\u5904\u7406\u6846\u67b6\u662f\u6f5c\u5728\u7684\u6539\u8fdb\u65b9\u5411\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u7ade\u4e89\u6027\u4fdd\u8bc1"}}
{"id": "2602.05413", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05413", "abs": "https://arxiv.org/abs/2602.05413", "authors": ["Filip Ku\u010dera", "Christoph Mandl", "Isao Echizen", "Radu Timofte", "Timo Spinde"], "title": "SciDef: Automating Definition Extraction from Academic Literature with Large Language Models", "comment": "Under Review - Submitted to SIGIR 2026 Resources Track; 8 pages, 6 figures, 4 tables", "summary": "Definitions are the foundation for any scientific work, but with a significant increase in publication numbers, gathering definitions relevant to any keyword has become challenging. We therefore introduce SciDef, an LLM-based pipeline for automated definition extraction. We test SciDef on DefExtra & DefSim, novel datasets of human-extracted definitions and definition-pairs' similarity, respectively. Evaluating 16 language models across prompting strategies, we demonstrate that multi-step and DSPy-optimized prompting improve extraction performance. To evaluate extraction, we test various metrics and show that an NLI-based method yields the most reliable results. We show that LLMs are largely able to extract definitions from scientific literature (86.4% of definitions from our test-set); yet future work should focus not just on finding definitions, but on identifying relevant ones, as models tend to over-generate them.\n  Code & datasets are available at https://github.com/Media-Bias-Group/SciDef.", "AI": {"tldr": "SciDef\uff1a\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5b9a\u4e49\u63d0\u53d6\u7ba1\u9053\uff0c\u5728\u79d1\u5b66\u6587\u732e\u4e2d\u63d0\u53d6\u5b9a\u4e49\uff0c\u6027\u80fd\u8fbe86.4%\uff0c\u4f46\u5b58\u5728\u8fc7\u5ea6\u751f\u6210\u95ee\u9898", "motivation": "\u968f\u7740\u79d1\u5b66\u51fa\u7248\u7269\u6570\u91cf\u6fc0\u589e\uff0c\u624b\u52a8\u6536\u96c6\u76f8\u5173\u5b9a\u4e49\u53d8\u5f97\u56f0\u96be\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u63d0\u53d6\u79d1\u5b66\u6587\u732e\u4e2d\u7684\u5b9a\u4e49", "method": "\u5f00\u53d1SciDef\u7ba1\u9053\uff0c\u4f7f\u752816\u79cd\u8bed\u8a00\u6a21\u578b\u6d4b\u8bd5\u4e0d\u540c\u63d0\u793a\u7b56\u7565\uff08\u591a\u6b65\u548cDSPy\u4f18\u5316\uff09\uff0c\u521b\u5efaDefExtra\uff08\u5b9a\u4e49\u63d0\u53d6\uff09\u548cDefSim\uff08\u5b9a\u4e49\u76f8\u4f3c\u6027\uff09\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30", "result": "LLM\u80fd\u591f\u4ece\u79d1\u5b66\u6587\u732e\u4e2d\u63d0\u53d686.4%\u7684\u5b9a\u4e49\uff0c\u591a\u6b65\u548cDSPy\u4f18\u5316\u63d0\u793a\u7b56\u7565\u63d0\u5347\u6027\u80fd\uff0cNLI-based\u8bc4\u4f30\u65b9\u6cd5\u6700\u53ef\u9760\uff0c\u4f46\u6a21\u578b\u503e\u5411\u4e8e\u8fc7\u5ea6\u751f\u6210\u5b9a\u4e49", "conclusion": "LLM\u5728\u5b9a\u4e49\u63d0\u53d6\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u672a\u6765\u5de5\u4f5c\u5e94\u5173\u6ce8\u8bc6\u522b\u76f8\u5173\u5b9a\u4e49\u800c\u975e\u4ec5\u627e\u5230\u5b9a\u4e49\uff0c\u56e0\u4e3a\u6a21\u578b\u5b58\u5728\u8fc7\u5ea6\u751f\u6210\u503e\u5411"}}
{"id": "2602.05928", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.05928", "abs": "https://arxiv.org/abs/2602.05928", "authors": ["Rick van der Heijden", "Nikolay Yakovets", "Thekla Hamm"], "title": "Even Faster Geosocial Reachability Queries", "comment": null, "summary": "Geosocial reachability queries (\\textsc{RangeReach}) determine whether a given vertex in a geosocial network can reach any spatial vertex within a query region. The state-of-the-art 3DReach method answers such queries by encoding graph reachability through interval labelling and indexing spatial vertices in a 3D R-tree. We present 2DReach, a simpler approach that avoids interval labelling entirely. Like 3DReach, 2DReach collapses strongly connected components (SCCs) into a DAG, but instead of computing interval labels, it directly stores a 2D R-tree per component over all reachable spatial vertices. A query then reduces to a single 2D R-tree lookup. We further propose compressed variants that reduce storage by excluding spatial sinks and sharing R-trees between components with identical reachable sets. Experiments on four real-world datasets show that 2DReach achieves faster index construction than 3DReach, with the compressed variant yielding the smallest index size among all methods. 2DReach delivers competitive or superior query performance with more stable response times across varying query parameters.", "AI": {"tldr": "2DReach\uff1a\u4e00\u79cd\u66f4\u7b80\u5355\u7684\u5730\u793e\u4ea4\u7f51\u7edc\u53ef\u8fbe\u6027\u67e5\u8be2\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u7ec4\u4ef6\u5b58\u50a82D R-tree\uff0c\u907f\u514d\u590d\u6742\u7684\u533a\u95f4\u6807\u8bb0\uff0c\u5b9e\u73b0\u66f4\u5feb\u7684\u7d22\u5f15\u6784\u5efa\u548c\u66f4\u7a33\u5b9a\u7684\u67e5\u8be2\u6027\u80fd\u3002", "motivation": "\u73b0\u67093DReach\u65b9\u6cd5\u4f7f\u7528\u533a\u95f4\u6807\u8bb0\u548c3D R-tree\u5904\u7406\u5730\u793e\u4ea4\u7f51\u7edc\u53ef\u8fbe\u6027\u67e5\u8be2\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u8f83\u4e3a\u590d\u6742\u3002\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u66f4\u7b80\u5355\u7684\u65b9\u6cd5\u6765\u56de\u7b54\u5730\u793e\u4ea4\u7f51\u7edc\u53ef\u8fbe\u6027\u67e5\u8be2\u3002", "method": "2DReach\u5c06\u5f3a\u8fde\u901a\u5206\u91cf\u538b\u7f29\u4e3aDAG\uff0c\u4f46\u4e0d\u50cf3DReach\u90a3\u6837\u8ba1\u7b97\u533a\u95f4\u6807\u8bb0\uff0c\u800c\u662f\u4e3a\u6bcf\u4e2a\u7ec4\u4ef6\u76f4\u63a5\u5b58\u50a8\u4e00\u4e2a\u5305\u542b\u6240\u6709\u53ef\u8fbe\u7a7a\u95f4\u9876\u70b9\u76842D R-tree\u3002\u67e5\u8be2\u7b80\u5316\u4e3a\u5355\u4e2a2D R-tree\u67e5\u627e\u3002\u8fd8\u63d0\u51fa\u4e86\u538b\u7f29\u53d8\u4f53\uff0c\u901a\u8fc7\u6392\u9664\u7a7a\u95f4\u6c47\u70b9\u548c\u5728\u5177\u6709\u76f8\u540c\u53ef\u8fbe\u96c6\u7684\u7ec4\u4ef6\u4e4b\u95f4\u5171\u4eabR-tree\u6765\u51cf\u5c11\u5b58\u50a8\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c2DReach\u6bd43DReach\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u7d22\u5f15\u6784\u5efa\uff0c\u538b\u7f29\u53d8\u4f53\u5728\u6240\u6709\u65b9\u6cd5\u4e2d\u4ea7\u751f\u6700\u5c0f\u7684\u7d22\u5f15\u5927\u5c0f\u30022DReach\u63d0\u4f9b\u7ade\u4e89\u6027\u6216\u66f4\u4f18\u7684\u67e5\u8be2\u6027\u80fd\uff0c\u5728\u4e0d\u540c\u67e5\u8be2\u53c2\u6570\u4e0b\u5177\u6709\u66f4\u7a33\u5b9a\u7684\u54cd\u5e94\u65f6\u95f4\u3002", "conclusion": "2DReach\u901a\u8fc7\u907f\u514d\u590d\u6742\u7684\u533a\u95f4\u6807\u8bb0\uff0c\u4f7f\u7528\u66f4\u7b80\u5355\u76842D R-tree\u65b9\u6cd5\uff0c\u5728\u5730\u793e\u4ea4\u7f51\u7edc\u53ef\u8fbe\u6027\u67e5\u8be2\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u7d22\u5f15\u6784\u5efa\u548c\u66f4\u7a33\u5b9a\u7684\u67e5\u8be2\u6027\u80fd\uff0c\u540c\u65f6\u538b\u7f29\u53d8\u4f53\u663e\u8457\u51cf\u5c11\u4e86\u5b58\u50a8\u9700\u6c42\u3002"}}
{"id": "2602.05445", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.05445", "abs": "https://arxiv.org/abs/2602.05445", "authors": ["Sebastian Bruch", "Martino Fontana", "Franco Maria Nardini", "Cosimo Rulli", "Rossano Venturini"], "title": "Forward Index Compression for Learned Sparse Retrieval", "comment": null, "summary": "Text retrieval using learned sparse representations of queries and documents has, over the years, evolved into a highly effective approach to search. It is thanks to recent advances in approximate nearest neighbor search-with the emergence of highly efficient algorithms such as the inverted index-based Seismic and the graph-based Hnsw-that retrieval with sparse representations became viable in practice. In this work, we scrutinize the efficiency of sparse retrieval algorithms and focus particularly on the size of a data structure that is common to all algorithmic flavors and that constitutes a substantial fraction of the overall index size: the forward index. In particular, we seek compression techniques to reduce the storage footprint of the forward index without compromising search quality or inner product computation latency. In our examination with various integer compression techniques, we report that StreamVByte achieves the best trade-off between memory footprint, retrieval accuracy, and latency. We then improve StreamVByte by introducing DotVByte, a new algorithm tailored to inner product computation. Experiments on MsMarco show that our improvements lead to significant space savings while maintaining retrieval efficiency.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u7a00\u758f\u68c0\u7d22\u7b97\u6cd5\u4e2d\u524d\u5411\u7d22\u5f15\u7684\u538b\u7f29\u6280\u672f\uff0c\u63d0\u51faDotVByte\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u68c0\u7d22\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5b58\u50a8\u7a7a\u95f4", "motivation": "\u7a00\u758f\u68c0\u7d22\u7b97\u6cd5\u867d\u7136\u9ad8\u6548\uff0c\u4f46\u5176\u524d\u5411\u7d22\u5f15\u5360\u7528\u4e86\u5927\u91cf\u5b58\u50a8\u7a7a\u95f4\uff0c\u9700\u8981\u5728\u4e0d\u5f71\u54cd\u68c0\u7d22\u8d28\u91cf\u548c\u8ba1\u7b97\u5ef6\u8fdf\u7684\u60c5\u51b5\u4e0b\u538b\u7f29\u524d\u5411\u7d22\u5f15", "method": "\u9996\u5148\u8bc4\u4f30\u591a\u79cd\u6574\u6570\u538b\u7f29\u6280\u672f\uff0c\u53d1\u73b0StreamVByte\u6548\u679c\u6700\u4f73\uff1b\u7136\u540e\u63d0\u51fa\u4e13\u95e8\u9488\u5bf9\u5185\u79ef\u8ba1\u7b97\u7684DotVByte\u7b97\u6cd5\u8fdb\u884c\u6539\u8fdb", "result": "\u5728MsMarco\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0c\u6539\u8fdb\u540e\u7684\u65b9\u6cd5\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u7a7a\u95f4\u8282\u7701\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u68c0\u7d22\u6548\u7387", "conclusion": "DotVByte\u7b97\u6cd5\u4e3a\u7a00\u758f\u68c0\u7d22\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u524d\u5411\u7d22\u5f15\u538b\u7f29\u65b9\u6848\uff0c\u5728\u5b58\u50a8\u7a7a\u95f4\u548c\u68c0\u7d22\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861"}}
{"id": "2602.05944", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.05944", "abs": "https://arxiv.org/abs/2602.05944", "authors": ["Yichun Wang", "Kristina Irion", "Paul Groth", "Hazar Harmouch"], "title": "\"Detective Work We Shouldn't Have to Do\": Practitioner Challenges in Regulatory-Aligned Data Quality in Machine Learning Systems", "comment": null, "summary": "Ensuring data quality in machine learning (ML) systems has become increasingly complex as regulatory requirements expand. In the European Union (EU), frameworks such as the General Data Protection Regulation (GDPR) and the Artificial Intelligence Act (AI Act) articulate data quality requirements that closely parallel technical concerns in ML practice, while also extending to legal obligations related to accountability, risk management, and human rights protection. This paper presents a qualitative interview study with EU-based data practitioners working on ML systems in regulated contexts. Through semi-structured interviews, we investigate how practitioners interpret regulatory-aligned data quality, the challenges they encounter, and the supports they identify as necessary. Our findings reveal persistent gaps between legal principles and engineering workflows, fragmentation across data pipelines, limitations of existing tools, unclear responsibility boundaries between technical and legal teams, and a tendency toward reactive, audit-driven quality practices. We also identify practitioners' needs for compliance-aware tooling, clearer governance structures, and cultural shifts toward proactive data governance.", "AI": {"tldr": "\u6b27\u76df\u76d1\u7ba1\u6846\u67b6\uff08GDPR\u3001AI\u6cd5\u6848\uff09\u5bf9ML\u7cfb\u7edf\u6570\u636e\u8d28\u91cf\u63d0\u51fa\u6cd5\u5f8b\u8981\u6c42\uff0c\u4f46\u5b9e\u8df5\u4e2d\u6cd5\u5f8b\u539f\u5219\u4e0e\u5de5\u7a0b\u5de5\u4f5c\u6d41\u5b58\u5728\u5dee\u8ddd\uff0c\u9700\u8981\u5408\u89c4\u5de5\u5177\u3001\u6e05\u6670\u6cbb\u7406\u7ed3\u6784\u548c\u4e3b\u52a8\u6570\u636e\u6cbb\u7406\u6587\u5316\u3002", "motivation": "\u968f\u7740\u6b27\u76dfGDPR\u548cAI\u6cd5\u6848\u7b49\u76d1\u7ba1\u6846\u67b6\u5bf9\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u6570\u636e\u8d28\u91cf\u63d0\u51fa\u6cd5\u5f8b\u8981\u6c42\uff0c\u9700\u8981\u4e86\u89e3\u6570\u636e\u4ece\u4e1a\u8005\u5982\u4f55\u7406\u89e3\u76d1\u7ba1\u8981\u6c42\u3001\u9762\u4e34\u7684\u6311\u6218\u4ee5\u53ca\u6240\u9700\u652f\u6301\uff0c\u4ee5\u5f25\u5408\u6cd5\u5f8b\u539f\u5219\u4e0e\u5de5\u7a0b\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u91c7\u7528\u5b9a\u6027\u8bbf\u8c08\u7814\u7a76\u65b9\u6cd5\uff0c\u5bf9\u6b27\u76df\u5730\u533a\u5728\u53d7\u76d1\u7ba1\u73af\u5883\u4e2d\u4ece\u4e8b\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u6570\u636e\u4ece\u4e1a\u8005\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u63a2\u8ba8\u4ed6\u4eec\u5bf9\u76d1\u7ba1\u8981\u6c42\u7684\u6570\u636e\u8d28\u91cf\u7684\u7406\u89e3\u3001\u9047\u5230\u7684\u6311\u6218\u548c\u6240\u9700\u652f\u6301\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u6cd5\u5f8b\u539f\u5219\u4e0e\u5de5\u7a0b\u5de5\u4f5c\u6d41\u5b58\u5728\u6301\u7eed\u5dee\u8ddd\uff1b\u6570\u636e\u7ba1\u9053\u788e\u7247\u5316\uff1b\u73b0\u6709\u5de5\u5177\u5b58\u5728\u5c40\u9650\u6027\uff1b\u6280\u672f\u56e2\u961f\u4e0e\u6cd5\u5f8b\u56e2\u961f\u8d23\u4efb\u8fb9\u754c\u4e0d\u6e05\u6670\uff1b\u8d28\u91cf\u5b9e\u8df5\u503e\u5411\u4e8e\u88ab\u52a8\u3001\u5ba1\u8ba1\u9a71\u52a8\u7684\u65b9\u5f0f\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u5408\u89c4\u610f\u8bc6\u5de5\u5177\u3001\u5efa\u7acb\u66f4\u6e05\u6670\u7684\u6cbb\u7406\u7ed3\u6784\u3001\u63a8\u52a8\u6587\u5316\u8f6c\u53d8\u4ee5\u5b9e\u73b0\u4e3b\u52a8\u6570\u636e\u6cbb\u7406\uff0c\u4ee5\u5f25\u5408\u76d1\u7ba1\u8981\u6c42\u4e0e\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2602.05474", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05474", "abs": "https://arxiv.org/abs/2602.05474", "authors": ["Yicheng Di", "Zhanjie Zhang", "Yun Wangc", "Jinren Liue", "Jiaqi Yanf", "Jiyu Wei", "Xiangyu Chend", "Yuan Liu"], "title": "LMMRec: LLM-driven Motivation-aware Multimodal Recommendation", "comment": null, "summary": "Motivation-based recommendation systems uncover user behavior drivers. Motivation modeling, crucial for decision-making and content preference, explains recommendation generation. Existing methods often treat motivation as latent variables from interaction data, neglecting heterogeneous information like review text. In multimodal motivation fusion, two challenges arise: 1) achieving stable cross-modal alignment amid noise, and 2) identifying features reflecting the same underlying motivation across modalities. To address these, we propose LLM-driven Motivation-aware Multimodal Recommendation (LMMRec), a model-agnostic framework leveraging large language models for deep semantic priors and motivation understanding. LMMRec uses chain-of-thought prompting to extract fine-grained user and item motivations from text. A dual-encoder architecture models textual and interaction-based motivations for cross-modal alignment, while Motivation Coordination Strategy and Interaction-Text Correspondence Method mitigate noise and semantic drift through contrastive learning and momentum updates. Experiments on three datasets show LMMRec achieves up to a 4.98\\% performance improvement.", "AI": {"tldr": "\u63d0\u51faLMMRec\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u7ec6\u7c92\u5ea6\u52a8\u673a\uff0c\u901a\u8fc7\u53cc\u7f16\u7801\u5668\u67b6\u6784\u5b9e\u73b0\u8de8\u6a21\u6001\u5bf9\u9f50\uff0c\u89e3\u51b3\u52a8\u673a\u878d\u5408\u4e2d\u7684\u566a\u58f0\u548c\u8bed\u4e49\u6f02\u79fb\u95ee\u9898\uff0c\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe4.98%", "motivation": "\u73b0\u6709\u57fa\u4e8e\u52a8\u673a\u7684\u63a8\u8350\u7cfb\u7edf\u901a\u5e38\u5c06\u52a8\u673a\u89c6\u4e3a\u4ea4\u4e92\u6570\u636e\u4e2d\u7684\u6f5c\u5728\u53d8\u91cf\uff0c\u5ffd\u7565\u4e86\u8bc4\u8bba\u6587\u672c\u7b49\u591a\u6a21\u6001\u4fe1\u606f\u3002\u5728\u591a\u6a21\u6001\u52a8\u673a\u878d\u5408\u4e2d\u5b58\u5728\u4e24\u4e2a\u6311\u6218\uff1a1) \u5728\u566a\u58f0\u4e2d\u5b9e\u73b0\u7a33\u5b9a\u7684\u8de8\u6a21\u6001\u5bf9\u9f50\uff1b2) \u8bc6\u522b\u8de8\u6a21\u6001\u53cd\u6620\u76f8\u540c\u5e95\u5c42\u52a8\u673a\u7684\u7279\u5f81", "method": "\u63d0\u51faLMMRec\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u83b7\u53d6\u6df1\u5ea6\u8bed\u4e49\u5148\u9a8c\u548c\u52a8\u673a\u7406\u89e3\u3002\u4f7f\u7528\u601d\u7ef4\u94fe\u63d0\u793a\u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u7ec6\u7c92\u5ea6\u7528\u6237\u548c\u7269\u54c1\u52a8\u673a\u3002\u91c7\u7528\u53cc\u7f16\u7801\u5668\u67b6\u6784\u5efa\u6a21\u6587\u672c\u548c\u4ea4\u4e92\u52a8\u673a\uff0c\u901a\u8fc7\u52a8\u673a\u534f\u8c03\u7b56\u7565\u548c\u4ea4\u4e92-\u6587\u672c\u5bf9\u5e94\u65b9\u6cd5\uff0c\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548c\u52a8\u91cf\u66f4\u65b0\u6765\u7f13\u89e3\u566a\u58f0\u548c\u8bed\u4e49\u6f02\u79fb", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLMMRec\u5b9e\u73b0\u4e86\u6700\u9ad84.98%\u7684\u6027\u80fd\u63d0\u5347", "conclusion": "LMMRec\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u52a8\u673a\u611f\u77e5\u591a\u6a21\u6001\u63a8\u8350\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u6a21\u6001\u52a8\u673a\u878d\u5408\u4e2d\u7684\u5bf9\u9f50\u548c\u7279\u5f81\u8bc6\u522b\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd"}}
{"id": "2602.05663", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.05663", "abs": "https://arxiv.org/abs/2602.05663", "authors": ["Shiteng Cao", "Junda She", "Ji Liu", "Bin Zeng", "Chengcheng Guo", "Kuo Cai", "Qiang Luo", "Ruiming Tang", "Han Li", "Kun Gai", "Zhiheng Li", "Cheng Yang"], "title": "GLASS: A Generative Recommender for Long-sequence Modeling via SID-Tier and Semantic Search", "comment": "10 pages,3 figures", "summary": "Leveraging long-term user behavioral patterns is a key trajectory for enhancing the accuracy of modern recommender systems. While generative recommender systems have emerged as a transformative paradigm, they face hurdles in effectively modeling extensive historical sequences. To address this challenge, we propose GLASS, a novel framework that integrates long-term user interests into the generative process via SID-Tier and Semantic Search. We first introduce SID-Tier, a module that maps long-term interactions into a unified interest vector to enhance the prediction of the initial SID token. Unlike traditional retrieval models that struggle with massive item spaces, SID-Tier leverages the compact nature of the semantic codebook to incorporate cross features between the user's long-term history and candidate semantic codes. Furthermore, we present semantic hard search, which utilizes generated coarse-grained semantic ID as dynamic keys to extract relevant historical behaviors, which are then fused via an adaptive gated fusion module to recalibrate the trajectory of subsequent fine-grained tokens. To address the inherent data sparsity in semantic hard search, we propose two strategies: semantic neighbor augmentation and codebook resizing. Extensive experiments on two large-scale real-world datasets, TAOBAO-MM and KuaiRec, demonstrate that GLASS outperforms state-of-the-art baselines, achieving significant gains in recommendation quality. Our codes are made publicly available to facilitate further research in generative recommendation.", "AI": {"tldr": "GLASS\u662f\u4e00\u4e2a\u751f\u6210\u5f0f\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7SID-Tier\u548c\u8bed\u4e49\u641c\u7d22\u5c06\u957f\u671f\u7528\u6237\u5174\u8da3\u6574\u5408\u5230\u751f\u6210\u8fc7\u7a0b\u4e2d\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u751f\u6210\u63a8\u8350\u7cfb\u7edf\u96be\u4ee5\u5efa\u6a21\u957f\u5386\u53f2\u5e8f\u5217\u7684\u95ee\u9898\u3002", "motivation": "\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u4f5c\u4e3a\u53d8\u9769\u6027\u8303\u5f0f\uff0c\u5728\u6709\u6548\u5efa\u6a21\u957f\u5386\u53f2\u5e8f\u5217\u65b9\u9762\u9762\u4e34\u6311\u6218\u3002\u4f20\u7edf\u68c0\u7d22\u6a21\u578b\u96be\u4ee5\u5904\u7406\u5927\u89c4\u6a21\u7269\u54c1\u7a7a\u95f4\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u6574\u5408\u957f\u671f\u7528\u6237\u884c\u4e3a\u6a21\u5f0f\u3002", "method": "1. SID-Tier\u6a21\u5757\uff1a\u5c06\u957f\u671f\u4ea4\u4e92\u6620\u5c04\u4e3a\u7edf\u4e00\u5174\u8da3\u5411\u91cf\uff0c\u589e\u5f3a\u521d\u59cbSID\u4ee4\u724c\u9884\u6d4b\uff1b2. \u8bed\u4e49\u786c\u641c\u7d22\uff1a\u4f7f\u7528\u751f\u6210\u7684\u7c97\u7c92\u5ea6\u8bed\u4e49ID\u4f5c\u4e3a\u52a8\u6001\u952e\u63d0\u53d6\u76f8\u5173\u5386\u53f2\u884c\u4e3a\uff1b3. \u81ea\u9002\u5e94\u95e8\u63a7\u878d\u5408\u6a21\u5757\uff1a\u91cd\u65b0\u6821\u51c6\u540e\u7eed\u7ec6\u7c92\u5ea6\u4ee4\u724c\u8f68\u8ff9\uff1b4. \u8bed\u4e49\u90bb\u5c45\u589e\u5f3a\u548c\u7801\u672c\u8c03\u6574\u7b56\u7565\u89e3\u51b3\u6570\u636e\u7a00\u758f\u6027\u3002", "result": "\u5728TAOBAO-MM\u548cKuaiRec\u4e24\u4e2a\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGLASS\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u63a8\u8350\u8d28\u91cf\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "conclusion": "GLASS\u901a\u8fc7\u6574\u5408\u957f\u671f\u7528\u6237\u5174\u8da3\u5230\u751f\u6210\u8fc7\u7a0b\u4e2d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u5904\u7406\u957f\u5386\u53f2\u5e8f\u5217\u7684\u6311\u6218\uff0c\u4e3a\u751f\u6210\u5f0f\u63a8\u8350\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2602.05734", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05734", "abs": "https://arxiv.org/abs/2602.05734", "authors": ["Niall McCarroll", "Kevin Curran", "Eugene McNamee", "Angela Clist", "Andrew Brammer"], "title": "Evaluating the impact of word embeddings on similarity scoring in practical information retrieval", "comment": null, "summary": "Search behaviour is characterised using synonymy and polysemy as users often want to search information based on meaning. Semantic representation strategies represent a move towards richer associative connections that can adequately capture this complex usage of language. Vector Space Modelling (VSM) and neural word embeddings play a crucial role in modern machine learning and Natural Language Processing (NLP) pipelines. Embeddings use distributional semantics to represent words, sentences, paragraphs or entire documents as vectors in high dimensional spaces. This can be leveraged by Information Retrieval (IR) systems to exploit the semantic relatedness between queries and answers.\n  This paper evaluates an alternative approach to measuring query statement similarity that moves away from the common similarity measure of centroids of neural word embeddings. Motivated by the Word Movers Distance (WMD) model, similarity is evaluated using the distance between individual words of queries and statements. Results from ranked query and response statements demonstrate significant gains in accuracy using the combined approach of similarity ranking through WMD with the word embedding techniques. The top performing WMD + GloVe combination outperforms all other state-of-the-art retrieval models including Doc2Vec and the baseline LSA model. Along with the significant gains in performance of similarity ranking through WMD, we conclude that the use of pre-trained word embeddings, trained on vast amounts of data, result in domain agnostic language processing solutions that are portable to diverse business use-cases.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u8bcd\u79fb\u8ddd\u79bb\uff08WMD\uff09\u7ed3\u5408\u8bcd\u5d4c\u5165\u6280\u672f\u6765\u6539\u8fdb\u67e5\u8be2-\u8bed\u53e5\u76f8\u4f3c\u6027\u5ea6\u91cf\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u8bcd\u5411\u91cf\u8d28\u5fc3\u65b9\u6cd5\uff0c\u5728\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u8bcd\u5d4c\u5165\u8d28\u5fc3\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u6355\u6349\u67e5\u8be2\u548c\u8bed\u53e5\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u8054\u3002\u53d7\u8bcd\u79fb\u8ddd\u79bb\uff08WMD\uff09\u6a21\u578b\u542f\u53d1\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u901a\u8fc7\u8ba1\u7b97\u67e5\u8be2\u548c\u8bed\u53e5\u4e2d\u5355\u4e2a\u8bcd\u8bed\u4e4b\u95f4\u7684\u8ddd\u79bb\u6765\u66f4\u7cbe\u786e\u5730\u8bc4\u4f30\u8bed\u4e49\u76f8\u4f3c\u6027\u3002", "method": "\u91c7\u7528\u8bcd\u79fb\u8ddd\u79bb\uff08WMD\uff09\u6a21\u578b\u6765\u8bc4\u4f30\u67e5\u8be2\u548c\u8bed\u53e5\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u8be5\u65b9\u6cd5\u8ba1\u7b97\u67e5\u8be2\u548c\u8bed\u53e5\u4e2d\u5355\u4e2a\u8bcd\u8bed\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u800c\u4e0d\u662f\u4f7f\u7528\u5e38\u89c1\u7684\u8bcd\u5d4c\u5165\u8d28\u5fc3\u76f8\u4f3c\u6027\u5ea6\u91cf\u3002\u5c06WMD\u4e0e\u9884\u8bad\u7ec3\u7684\u8bcd\u5d4c\u5165\u6280\u672f\uff08\u5982GloVe\uff09\u7ed3\u5408\u4f7f\u7528\u3002", "result": "WMD+GloVe\u7ec4\u5408\u5728\u67e5\u8be2\u548c\u54cd\u5e94\u8bed\u53e5\u7684\u6392\u5e8f\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6700\u4f73\u6027\u80fd\uff0c\u663e\u8457\u8d85\u8d8a\u4e86\u6240\u6709\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u68c0\u7d22\u6a21\u578b\uff0c\u5305\u62ecDoc2Vec\u548c\u57fa\u7ebfLSA\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u5728\u76f8\u4f3c\u6027\u6392\u5e8f\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u4f7f\u7528\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\u7684\u8bcd\u5d4c\u5165\u7ed3\u5408\u8bcd\u79fb\u8ddd\u79bb\u65b9\u6cd5\uff0c\u53ef\u4ee5\u521b\u5efa\u9886\u57df\u65e0\u5173\u7684\u8bed\u8a00\u5904\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u8fd9\u4e9b\u65b9\u6848\u53ef\u79fb\u690d\u5230\u591a\u6837\u5316\u7684\u5546\u4e1a\u5e94\u7528\u573a\u666f\u4e2d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4fe1\u606f\u68c0\u7d22\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2602.05787", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05787", "abs": "https://arxiv.org/abs/2602.05787", "authors": ["Hengran Zhang", "Keping Bi", "Jiafeng Guo", "Jiaming Zhang", "Wenbo Yang", "Daiting Shi", "Xueqi Cheng"], "title": "Bagging-Based Model Merging for Robust General Text Embeddings", "comment": "12 pages, 4 figures", "summary": "General-purpose text embedding models underpin a wide range of NLP and information retrieval applications, and are typically trained on large-scale multi-task corpora to encourage broad generalization. However, it remains unclear how different multi-task training strategies compare in practice, and how to efficiently adapt embedding models as new domains and data types continually emerge. In this work, we present a systematic study of multi-task training for text embeddings from two perspectives: data scheduling and model merging. We compare batch-level shuffling, sequential training variants, two-stage training, and multiple merging granularities, and find that simple batch-level shuffling consistently yields the strongest overall performance, suggesting that task conflicts are limited and training datasets are largely complementary. Despite its effectiveness, batch-level shuffling exhibits two practical limitations: suboptimal out-of-domain (OOD) generalization and poor suitability for incremental learning due to expensive full retraining. To address these issues, we propose Bagging-based rObust mOdel Merging (\\modelname), which trains multiple embedding models on sampled subsets and merges them into a single model, improving robustness while retaining single-model inference efficiency. Moreover, \\modelname naturally supports efficient incremental updates by training lightweight update models on new data with a small historical subset and merging them into the existing model. Experiments across diverse embedding benchmarks demonstrate that \\modelname consistently improves both in-domain and OOD performance over full-corpus batch-level shuffling, while substantially reducing training cost in incremental learning settings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u591a\u4efb\u52a1\u8bad\u7ec3\u7b56\u7565\uff0c\u53d1\u73b0\u7b80\u5355\u7684\u6279\u91cf\u7ea7\u6df7\u6d17\u6548\u679c\u6700\u597d\u4f46\u5b58\u5728\u57df\u5916\u6cdb\u5316\u4e0d\u8db3\u548c\u589e\u91cf\u5b66\u4e60\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eBagging\u7684\u9c81\u68d2\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "motivation": "\u901a\u7528\u6587\u672c\u5d4c\u5165\u6a21\u578b\u5e7f\u6cdb\u5e94\u7528\u4e8eNLP\u548c\u4fe1\u606f\u68c0\u7d22\uff0c\u901a\u5e38\u901a\u8fc7\u591a\u4efb\u52a1\u8bad\u7ec3\u5b9e\u73b0\u6cdb\u5316\u3002\u7136\u800c\uff0c\u4e0d\u540c\u591a\u4efb\u52a1\u8bad\u7ec3\u7b56\u7565\u7684\u5b9e\u9645\u6548\u679c\u6bd4\u8f83\u4e0d\u660e\u786e\uff0c\u4e14\u968f\u7740\u65b0\u9886\u57df\u548c\u6570\u636e\u7c7b\u578b\u7684\u4e0d\u65ad\u51fa\u73b0\uff0c\u5982\u4f55\u9ad8\u6548\u9002\u5e94\u5d4c\u5165\u6a21\u578b\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u4ece\u6570\u636e\u8c03\u5ea6\u548c\u6a21\u578b\u5408\u5e76\u4e24\u4e2a\u89d2\u5ea6\u7cfb\u7edf\u7814\u7a76\u591a\u4efb\u52a1\u8bad\u7ec3\uff1a\u6bd4\u8f83\u6279\u91cf\u7ea7\u6df7\u6d17\u3001\u987a\u5e8f\u8bad\u7ec3\u53d8\u4f53\u3001\u4e24\u9636\u6bb5\u8bad\u7ec3\u548c\u591a\u79cd\u5408\u5e76\u7c92\u5ea6\u3002\u63d0\u51faBagging-based rObust mOdel Merging (BOOM)\u65b9\u6cd5\uff0c\u8bad\u7ec3\u591a\u4e2a\u5d4c\u5165\u6a21\u578b\u5728\u91c7\u6837\u5b50\u96c6\u4e0a\u5e76\u5408\u5e76\u4e3a\u5355\u4e00\u6a21\u578b\uff0c\u540c\u65f6\u652f\u6301\u901a\u8fc7\u8bad\u7ec3\u8f7b\u91cf\u66f4\u65b0\u6a21\u578b\u5b9e\u73b0\u9ad8\u6548\u589e\u91cf\u66f4\u65b0\u3002", "result": "\u6279\u91cf\u7ea7\u6df7\u6d17\u59cb\u7ec8\u4ea7\u751f\u6700\u5f3a\u7684\u6574\u4f53\u6027\u80fd\uff0c\u8868\u660e\u4efb\u52a1\u51b2\u7a81\u6709\u9650\u4e14\u8bad\u7ec3\u6570\u636e\u57fa\u672c\u4e92\u8865\u3002\u4f46\u5b58\u5728\u57df\u5916\u6cdb\u5316\u4e0d\u8db3\u548c\u589e\u91cf\u5b66\u4e60\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002BOOM\u65b9\u6cd5\u5728\u591a\u6837\u5316\u5d4c\u5165\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u5168\u8bed\u6599\u6279\u91cf\u7ea7\u6df7\u6d17\u6301\u7eed\u63d0\u5347\u57df\u5185\u548c\u57df\u5916\u6027\u80fd\uff0c\u540c\u65f6\u5728\u589e\u91cf\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u3002", "conclusion": "\u6279\u91cf\u7ea7\u6df7\u6d17\u662f\u6709\u6548\u7684\u591a\u4efb\u52a1\u8bad\u7ec3\u7b56\u7565\uff0c\u4f46\u5b58\u5728\u5b9e\u9645\u9650\u5236\u3002\u63d0\u51fa\u7684BOOM\u65b9\u6cd5\u901a\u8fc7\u6a21\u578b\u5408\u5e76\u548cBagging\u6280\u672f\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u6027\u80fd\u9c81\u68d2\u6027\uff0c\u8fd8\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u589e\u91cf\u5b66\u4e60\uff0c\u4e3a\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u6301\u7eed\u9002\u5e94\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05945", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.05945", "abs": "https://arxiv.org/abs/2602.05945", "authors": ["Zhouhang Xie", "Bo Peng", "Zhankui He", "Ziqi Chen", "Alice Han", "Isabella Ye", "Benjamin Coleman", "Noveen Sachdeva", "Fernando Pereira", "Julian McAuley", "Wang-Cheng Kang", "Derek Zhiyuan Cheng", "Beidou Wang", "Randolph Brown"], "title": "AgenticTagger: Structured Item Representation for Recommendation with LLM Agents", "comment": null, "summary": "High-quality representations are a core requirement for effective recommendation. In this work, we study the problem of LLM-based descriptor generation, i.e., keyphrase-like natural language item representation generation frameworks with minimal constraints on downstream applications. We propose AgenticTagger, a framework that queries LLMs for representing items with sequences of text descriptors. However, open-ended generation provides little control over the generation space, leading to high cardinality, low-performance descriptors that renders downstream modeling challenging. To this end, AgenticTagger features two core stages: (1) a vocabulary building stage where a set of hierarchical, low-cardinality, and high-quality descriptors is identified, and (2) a vocabulary assignment stage where LLMs assign in-vocabulary descriptors to items. To effectively and efficiently ground vocabulary in the item corpus of interest, we design a multi-agent reflection mechanism where an architect LLM iteratively refines the vocabulary guided by parallelized feedback from annotator LLMs that validates the vocabulary against item data. Experiments on public and private data show AgenticTagger brings consistent improvements across diverse recommendation scenarios, including generative and term-based retrieval, ranking, and controllability-oriented, critique-based recommendation.", "AI": {"tldr": "AgenticTagger\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u751f\u6210\u5f0f\u63cf\u8ff0\u7b26\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u65b9\u6cd5\uff08\u8bcd\u6c47\u6784\u5efa\u548c\u8bcd\u6c47\u5206\u914d\uff09\u4e3a\u63a8\u8350\u7cfb\u7edf\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u4f4e\u57fa\u6570\u7684\u6587\u672c\u63cf\u8ff0\u7b26\u3002", "motivation": "\u9ad8\u8d28\u91cf\u7684\u8868\u793a\u662f\u6709\u6548\u63a8\u8350\u7684\u6838\u5fc3\u9700\u6c42\u3002\u5f53\u524dLLM\u751f\u6210\u63cf\u8ff0\u7b26\u7684\u65b9\u6cd5\u5b58\u5728\u5f00\u653e\u751f\u6210\u7a7a\u95f4\u96be\u4ee5\u63a7\u5236\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u63cf\u8ff0\u7b26\u57fa\u6570\u9ad8\u3001\u8d28\u91cf\u4f4e\uff0c\u7ed9\u4e0b\u6e38\u5efa\u6a21\u5e26\u6765\u6311\u6218\u3002", "method": "\u63d0\u51faAgenticTagger\u6846\u67b6\uff1a1) \u8bcd\u6c47\u6784\u5efa\u9636\u6bb5\uff1a\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u53cd\u601d\u673a\u5236\uff0c\u67b6\u6784LLM\u5728\u6807\u6ce8LLM\u7684\u5e76\u884c\u53cd\u9988\u6307\u5bfc\u4e0b\u8fed\u4ee3\u4f18\u5316\uff0c\u6784\u5efa\u5c42\u6b21\u5316\u3001\u4f4e\u57fa\u6570\u3001\u9ad8\u8d28\u91cf\u7684\u63cf\u8ff0\u7b26\u8bcd\u6c47\u8868\uff1b2) \u8bcd\u6c47\u5206\u914d\u9636\u6bb5\uff1aLLM\u5c06\u8bcd\u6c47\u8868\u4e2d\u7684\u63cf\u8ff0\u7b26\u5206\u914d\u7ed9\u9879\u76ee\u3002", "result": "\u5728\u516c\u5f00\u548c\u79c1\u6709\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAgenticTagger\u5728\u591a\u79cd\u63a8\u8350\u573a\u666f\u4e2d\u5e26\u6765\u4e00\u81f4\u6539\u8fdb\uff0c\u5305\u62ec\u751f\u6210\u5f0f\u548c\u57fa\u4e8e\u672f\u8bed\u7684\u68c0\u7d22\u3001\u6392\u5e8f\uff0c\u4ee5\u53ca\u9762\u5411\u53ef\u63a7\u6027\u7684\u57fa\u4e8e\u6279\u8bc4\u7684\u63a8\u8350\u3002", "conclusion": "AgenticTagger\u901a\u8fc7\u63a7\u5236\u751f\u6210\u7a7a\u95f4\u548c\u964d\u4f4e\u63cf\u8ff0\u7b26\u57fa\u6570\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u751f\u6210\u63cf\u8ff0\u7b26\u7684\u6311\u6218\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u7684\u6587\u672c\u8868\u793a\u3002"}}
{"id": "2602.05975", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05975", "abs": "https://arxiv.org/abs/2602.05975", "authors": ["Tiansheng Hu", "Yilun Zhao", "Canyu Zhang", "Arman Cohan", "Chen Zhao"], "title": "SAGE: Benchmarking and Improving Retrieval for Deep Research Agents", "comment": "Submission to ACL ARR 2026 January", "summary": "Deep research agents have emerged as powerful systems for addressing complex queries. Meanwhile, LLM-based retrievers have demonstrated strong capability in following instructions or reasoning. This raises a critical question: can LLM-based retrievers effectively contribute to deep research agent workflows? To investigate this, we introduce SAGE, a benchmark for scientific literature retrieval comprising 1,200 queries across four scientific domains, with a 200,000 paper retrieval corpus.We evaluate six deep research agents and find that all systems struggle with reasoning-intensive retrieval. Using DR Tulu as backbone, we further compare BM25 and LLM-based retrievers (i.e., ReasonIR and gte-Qwen2-7B-instruct) as alternative search tools. Surprisingly, BM25 significantly outperforms LLM-based retrievers by approximately 30%, as existing agents generate keyword-oriented sub-queries. To improve performance, we propose a corpus-level test-time scaling framework that uses LLMs to augment documents with metadata and keywords, making retrieval easier for off-the-shelf retrievers. This yields 8% and 2% gains on short-form and open-ended questions, respectively.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86SAGE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u5728\u79d1\u5b66\u6587\u732e\u68c0\u7d22\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u7cfb\u7edf\u5728\u5904\u7406\u63a8\u7406\u5bc6\u96c6\u578b\u68c0\u7d22\u65f6\u8868\u73b0\u4e0d\u4f73\uff0cBM25\u68c0\u7d22\u5668\u4f18\u4e8eLLM\u68c0\u7d22\u5668\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8eLLM\u7684\u6587\u6863\u589e\u5f3a\u6846\u67b6\u6765\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u5728\u590d\u6742\u67e5\u8be2\u5904\u7406\u4e2d\u7684\u5174\u8d77\uff0c\u4ee5\u53caLLM\u68c0\u7d22\u5668\u5728\u6307\u4ee4\u9075\u5faa\u548c\u63a8\u7406\u65b9\u9762\u7684\u5f3a\u5927\u80fd\u529b\uff0c\u7814\u7a76LLM\u68c0\u7d22\u5668\u80fd\u5426\u6709\u6548\u8d21\u732e\u4e8e\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002", "method": "1) \u5f15\u5165SAGE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b4\u4e2a\u79d1\u5b66\u9886\u57df\u76841200\u4e2a\u67e5\u8be2\u548c20\u4e07\u7bc7\u8bba\u6587\u7684\u68c0\u7d22\u8bed\u6599\u5e93\uff1b2) \u8bc4\u4f306\u4e2a\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\uff1b3) \u6bd4\u8f83BM25\u548cLLM\u68c0\u7d22\u5668(ReasonIR\u548cgte-Qwen2-7B-instruct)\uff1b4) \u63d0\u51fa\u8bed\u6599\u5e93\u7ea7\u6d4b\u8bd5\u65f6\u6269\u5c55\u6846\u67b6\uff0c\u4f7f\u7528LLM\u901a\u8fc7\u5143\u6570\u636e\u548c\u5173\u952e\u8bcd\u589e\u5f3a\u6587\u6863\u3002", "result": "1) \u6240\u6709\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u68c0\u7d22\u4e2d\u90fd\u8868\u73b0\u4e0d\u4f73\uff1b2) BM25\u68c0\u7d22\u5668\u663e\u8457\u4f18\u4e8eLLM\u68c0\u7d22\u5668\u7ea630%\uff1b3) \u63d0\u51fa\u7684\u6587\u6863\u589e\u5f3a\u6846\u67b6\u5728\u7b80\u77ed\u95ee\u9898\u548c\u5f00\u653e\u5f0f\u95ee\u9898\u4e0a\u5206\u522b\u5e26\u67658%\u548c2%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u5f53\u524d\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u503e\u5411\u4e8e\u751f\u6210\u5173\u952e\u8bcd\u5bfc\u5411\u7684\u5b50\u67e5\u8be2\uff0c\u9650\u5236\u4e86LLM\u68c0\u7d22\u5668\u7684\u4f18\u52bf\u3002\u901a\u8fc7LLM\u589e\u5f3a\u6587\u6863\u5185\u5bb9\uff0c\u53ef\u4ee5\u4f7f\u73b0\u6210\u68c0\u7d22\u5668\u66f4\u5bb9\u6613\u627e\u5230\u76f8\u5173\u4fe1\u606f\uff0c\u6709\u6548\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u3002"}}
