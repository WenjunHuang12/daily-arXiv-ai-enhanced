<div id=toc></div>

# Table of Contents

- [cs.DS](#cs.DS) [Total: 2]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.DB](#cs.DB) [Total: 4]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.IT](#cs.IT) [Total: 4]


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [1] [Almost-Optimal Approximation Algorithms for Global Minimum Cut in Directed Graphs](https://arxiv.org/abs/2512.09080)
*Ron Mosenzon*

Main category: cs.DS

TL;DR: 提出新的(1+ε)-近似算法，用于有向加权图中的全局最小边割和顶点割问题，运行时间达到几乎最优的O(m^{1+o(1)}/ε)


<details>
  <summary>Details</summary>
Motivation: 现有算法在运行时间上仍有改进空间，特别是对于加权图的最小割问题，需要更高效的近似算法

Method: 扩展Chuzhoy等人提出的框架，并针对全局最小顶点割问题开发了新的黑盒归约方法，将其转化为根版本问题

Result: 算法运行时间达到O(m^{1+o(1)}/ε)，相比之前最好的结果有显著改进，特别是对于常数ε>0的情况，达到几乎最优的O(m^{1+o(1)})

Conclusion: 提出了更高效的最小割近似算法，改进了现有最佳结果，并扩展了算法框架的应用范围

Abstract: We develop new $(1+ε)$-approximation algorithms for finding the global minimum edge-cut in a directed edge-weighted graph, and for finding the global minimum vertex-cut in a directed vertex-weighted graph. Our algorithms are randomized, and have a running time of $O\left(m^{1+o(1)}/ε\right)$ on any $m$-edge $n$-vertex input graph, assuming all edge/vertex weights are polynomially-bounded. In particular, for any constant $ε>0$, our algorithms have an almost-optimal running time of $O\left(m^{1+o(1)}\right)$. The fastest previously-known running time for this setting, due to (Cen et al., FOCS 2021), is $\tilde{O}\left(\min\left\{n^2/ε^2,m^{1+o(1)}\sqrt{n}\right\}\right)$ for Minimum Edge-Cut, and $\tilde{O}\left(n^2/ε^2\right)$ for Minimum Vertex-Cut. Our results further extend to the rooted variants of the Minimum Edge-Cut and Minimum Vertex-Cut problems, where the algorithm is additionally given a root vertex $r$, and the goal is to find a minimum-weight cut separating any vertex from the root $r$. In terms of techniques, we build upon and extend a framework that was recently introduced by (Chuzhoy et al., SODA 2026) for solving the Minimum Vertex-Cut problem in unweighted directed graphs. Additionally, in order to obtain our result for the Global Minimum Vertex-Cut problem, we develop a novel black-box reduction from this problem to its rooted variant. Prior to our work, such reductions were only known for more restricted settings, such as when all vertex-weights are unit.

</details>


### [2] [Dynamic Graph Coloring: Sequential, Parallel, and Distributed](https://arxiv.org/abs/2512.09218)
*Mohsen Ghaffari,Jaehyun Koo*

Main category: cs.DS

TL;DR: 提出一种简单随机算法，能在图动态更新（边插入/删除）时高效维持(Δ+1)染色，在顺序、并行和分布式模型中均有优异表现。


<details>
  <summary>Details</summary>
Motivation: 动态图染色是图论中的基础问题，现有算法在处理边更新时存在时间复杂度高（O(log Δ)）或仅为摊销保证的局限。需要一种简单高效、能跨模型统一应用的算法。

Method: 采用随机化算法，核心思想是通过随机颜色选择和局部调整来维持染色。算法能批量处理更新，利用并行性提高效率，在分布式环境中通过有限的消息传递实现颜色恢复。

Result: 1) 顺序模型：每次更新O(1)期望时间（最坏情况），优于之前的摊销保证；2) 并行模型：批量更新O(1)每更新工作量，poly(log n)深度；3) 分布式模型：每次更新最多O(1)节点失色，O(log n)轮内恢复，O(1)期望消息复杂度。

Conclusion: 该算法提供了一个统一的动态图染色框架，在顺序、并行和分布式模型中均达到近乎最优的性能，解决了现有算法的局限性，为动态图算法设计提供了新思路。

Abstract: We present a simple randomized algorithm that can efficiently maintain a $(Δ+1)$ coloring as the graph undergoes edge insertion and deletion updates, where $Δ$ denotes an upper bound on the maximum degree. A key advantage is the algorithm's ability to process many updates simultaneously, which makes it naturally adaptable to the parallel and distributed models. Concretely, it gives a unified framework across the models, leading to the following results:
  - In the sequential setting, the algorithm processes each update in $O(1)$ expected time, worst-case. This matches and strengthens the results of Henzinger and Peng [TALG 2022] and Bhattacharya et al. [TALG 2022], who achieved an $O(1)$ bound but amortized (in expectation and with high probability, respectively), whose work was an improvement of the $O(\log Δ)$ expected amortized bound of Bhattacharya et al. [SODA'18].
  - In the parallel setting, the algorithm processes each (arbitrary size) batch of updates using $O(1)$ work per update in the batch in expectation, and in $\text{poly}(\log n)$ depth with high probability. This is, in a sense, an ideal parallelization of the above results.
  - In the distributed setting, the algorithm can maintain a coloring of the network graph as (potentially many) edges are added or deleted. The maintained coloring is always proper; it may become partial upon updates, i.e., some nodes may temporarily lose their colors, but quickly converges to a full, proper coloring. Concretely, each insertion and deletion causes at most $O(1)$ nodes to become uncolored, but this is resolved within $O(\log n)$ rounds with high probability (e.g., in the absence of further updates nearby--the precise guarantee is stronger, but technical). Importantly, the algorithm incurs only $O(1)$ expected message complexity and computation per update.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [3] [The Illusion of Rationality: Tacit Bias and Strategic Dominance in Frontier LLM Negotiation Games](https://arxiv.org/abs/2512.09254)
*Manuel S. Ríos,Ruben F. Manrique,Nicanor Quijano,Luis F. Giraldo*

Main category: cs.GT

TL;DR: 研究发现前沿大语言模型在谈判博弈中表现出模型特定的战略均衡、锚定效应和系统性优势模式，而非收敛到理性最优行为，揭示了部署谈判代理的风险。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地被部署为自主谈判代理，需要了解其战略行为以避免在现实经济、政治和社会场景中带来风险。

Method: 使用NegotiationArena框架，在三种多轮议价游戏（买方-卖方、多轮最后通牒、资源交换）中对多种前沿大语言模型进行受控模拟实验。

Result: 模型并未收敛到统一最优行为，而是分化成模型特定的战略均衡；存在强烈的数值和语义锚定效应；某些模型系统性获得更高收益，表现出优势模式。

Conclusion: 研究结果强调了在现实场景部署此类系统前，迫切需要开发机制来缓解这些谈判行为问题。

Abstract: Large language models (LLMs) are increasingly being deployed as autonomous agents on behalf of institutions and individuals in economic, political, and social settings that involve negotiation. Yet this trend carries significant risks if their strategic behavior is not well understood. In this work, we revisit the NegotiationArena framework and run controlled simulation experiments on a diverse set of frontier LLMs across three multi turn bargaining games: Buyer Seller, Multi turn Ultimatum, and Resource Exchange. We ask whether improved general reasoning capabilities lead to rational, unbiased, and convergent negotiation strategies. Our results challenge this assumption. We find that models diverge into distinct, model specific strategic equilibria rather than converging to a unified optimal behavior. Moreover, strong numerical and semantic anchoring effects persist: initial offers are highly predictive of final agreements, and models consistently generate biased proposals by collapsing diverse internal valuations into rigid, generic price points. More concerningly, we observe dominance patterns in which some models systematically achieve higher payoffs than their counterparts. These findings underscore an urgent need to develop mechanisms to mitigate these issues before deploying such systems in real-world scenarios.

</details>


### [4] [Procurement Auctions with Predictions: Improved Frugality for Facility Location](https://arxiv.org/abs/2512.09367)
*Eric Balkanski,Nicholas DeFilippis,Vasilis Gkatzelis,Xizhi Tan*

Main category: cs.GT

TL;DR: 本文研究了战略性无容量设施选址问题的采购拍卖设计，结合学习增强框架，利用成本预测来改进支付效率，在预测准确时显著降低支付成本，同时保持对错误预测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在战略性设施选址问题中，公司需要从战略性的设施所有者处采购设施来服务客户。每个所有者有私有成本，需要设计真实拍卖机制来最小化总成本（支付给所有者的费用加上客户的连接成本）。传统VCG拍卖的节俭比为3，需要改进支付效率。

Method: 首先分析经典VCG拍卖的性能，证明其节俭比为3。然后利用学习增强框架，设计基于所有者私有成本预测的拍卖机制。提出一系列学习增强拍卖，在预测准确时显著降低支付，同时保持对错误预测的鲁棒性。最后提供"误差容忍"拍卖族，即使预测只有近似准确性也能保持改进的节俭比。

Result: VCG拍卖的节俭比恰好为3。学习增强拍卖在预测准确时能显著降低支付，获得更好的节俭比。这些拍卖对错误预测具有鲁棒性，即使在对抗性选择的预测下也能保持合理的节俭比。误差容忍拍卖能根据预测误差函数提供节俭比的上界。

Conclusion: 学习增强框架能有效改进战略性设施选址采购拍卖的支付效率，在利用预测信息降低支付成本的同时保持机制鲁棒性，为实际应用提供了灵活的设计方案。

Abstract: We study the problem of designing procurement auctions for the strategic uncapacitated facility location problem: a company needs to procure a set of facility locations in order to serve its customers and each facility location is owned by a strategic agent. Each owner has a private cost for providing access to their facility (e.g., renting it or selling it to the company) and needs to be compensated accordingly. The goal is to design truthful auctions that decide which facilities the company should procure and how much to pay the corresponding owners, aiming to minimize the total cost, i.e., the monetary cost paid to the owners and the connection cost suffered by the customers (their distance to the nearest facility). We evaluate the performance of these auctions using the \emph{frugality ratio}.
  We first analyze the performance of the classic VCG auction in this context and prove that its frugality ratio is exactly $3$. We then leverage the learning-augmented framework and design auctions that are augmented with predictions regarding the owners' private costs. Specifically, we propose a family of learning-augmented auctions that achieve significant payment reductions when the predictions are accurate, leading to much better frugality ratios. At the same time, we demonstrate that these auctions remain robust even if the predictions are arbitrarily inaccurate, and maintain reasonable frugality ratios even under adversarially chosen predictions. We finally provide a family of ``error-tolerant'' auctions that maintain improved frugality ratios even if the predictions are only approximately accurate, and we provide upper bounds on their frugality ratio as a function of the prediction error.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [5] [CUBE: A Cardinality Estimator Based on Neural CDF](https://arxiv.org/abs/2512.09622)
*Xiao Yan,Tiezheng Nie,Boyang Fang,Derong Shen,Kou Yue,Yu Ge*

Main category: cs.DB

TL;DR: 提出基于累积分布函数(CDF)的基数估计新方法，无需采样或积分，实现准确、可预测的估计结果，推理速度比现有最优方法快10倍以上，具有优秀的维度扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有基于概率模型的数据驱动基数估计方法存在推理延迟高、可扩展性差的问题，随着数据维度增加，优化时间可能超过实际查询执行时间，且采样或积分过程导致估计结果不可预测、性能不稳定。

Method: 基于累积分布函数(CDF)的基数估计方法，通过合并计算进行推理加速，无需采样或积分过程，直接计算范围查询的基数。

Result: 该方法在保持高精度的同时，实现了快速且接近恒定的推理速度，即使维度增加也能维持性能，比当前最先进的数据驱动基数估计器快10倍以上，展现出优秀的维度可扩展性。

Conclusion: 基于CDF的基数估计方法解决了现有方法的延迟和可扩展性问题，为实际数据库应用提供了准确、可预测且高效的基数估计解决方案。

Abstract: Modern database optimizer relies on cardinality estimator, whose accuracy directly affects the optimizer's ability to choose an optimal execution plan. Recent work on data-driven methods has leveraged probabilistic models to achieve higher estimation accuracy, but these approaches cannot guarantee low inference latency at the same time and neglect scalability. As data dimensionality grows, optimization time can even exceed actual query execution time. Furthermore, inference with probabilistic models by sampling or integration procedures unpredictable estimation result and violate stability, which brings unstable performance with query execution and make database tuning hard for database users. In this paper, we propose a novel approach to cardinality estimation based on cumulative distribution function(CDF), which calculates range query cardinality without sampling or integration, ensuring accurate and predictable estimation results. With inference acceleration by merging calculations, we can achieve fast and nearly constant inference speed while maintaining high accuracy, even as dimensionality increases, which is over 10x faster than current state-of-the-art data-driven cardinality estimator. This demonstrates its excellent dimensional scalability, making it well-suited for real-world database applications.

</details>


### [6] [Exqutor: Extended Query Optimizer for Vector-augmented Analytical Queries](https://arxiv.org/abs/2512.09695)
*Hyunjoon Kim,Chaerim Lim,Hyeonjun An,Rathijit Sen,Kwanghyun Park*

Main category: cs.DB

TL;DR: Exqutor是一个可插拔的基数估计框架，用于优化向量增强分析查询，通过精确基数查询优化和自适应采样技术提高向量搜索的基数估计准确性。


<details>
  <summary>Details</summary>
Motivation: 随着RAG扩展到表格增强生成，整合表格和向量搜索的工作负载越来越普遍，但由于向量搜索组件的基数估计不准确导致查询计划次优，需要解决这一问题。

Method: 提出Exqutor框架：1）当向量索引可用时，采用精确基数查询优化技术；2）无索引时，使用基于采样的方法，通过自适应采样大小调整平衡估计精度和开销。

Result: 将Exqutor集成到pgvector、VBASE和DuckDB中，在向量增强分析查询上实现了高达四个数量级的性能提升。

Conclusion: Exqutor通过改进向量搜索的基数估计，有效解决了向量增强分析查询的优化挑战，显著提升了查询性能。

Abstract: Vector similarity search is becoming increasingly important for data science pipelines, particularly in Retrieval-Augmented Generation (RAG), where it enhances large language model inference by enabling efficient retrieval of relevant external knowledge. As RAG expands with table-augmented generation to incorporate structured data, workloads integrating table and vector search are becoming more prevalent. However, efficiently executing such queries remains challenging due to inaccurate cardinality estimation for vector search components, leading to suboptimal query plans. In this paper, we propose Exqutor, an extended query optimizer for vector-augmented analytical queries. Exqutor is a pluggable cardinality estimation framework designed to address this issue, leveraging exact cardinality query optimization techniques to enhance estimation accuracy when vector indexes (e.g., HNSW, IVF) are available. In scenarios lacking these indexes, we employ a sampling-based approach with adaptive sampling size adjustment, dynamically tuning the sample size to balance estimation accuracy and sampling overhead. This allows Exqutor to efficiently approximate vector search cardinalities while minimizing computational costs. We integrate our framework into pgvector, VBASE, and DuckDB, demonstrating performance improvements of up to four orders of magnitude on vector-augmented analytical queries.

</details>


### [7] [Baseline: Operation-Based Evolution and Versioning of Data](https://arxiv.org/abs/2512.09762)
*Jonathan Edwards,Tomas Petricek*

Main category: cs.DB

TL;DR: Baseline平台通过操作差分技术实现多维度数据变更管理，支持时间突变、空间协作和设计演化，提供无仓库、分支即复制的简化版本控制模型。


<details>
  <summary>Details</summary>
Motivation: 解决传统数据版本控制在面对结构转换（如模式变更）时难以进行细粒度差异比较和合并的问题，为编程语言和关系数据库数据结构提供更好的版本控制方案。

Method: 基于操作差分技术，将数据管理表示为包含重构和模式变更的高级操作序列，实现操作化版本控制。查询被操作化为模式和数据操作序列，在分支上推测执行。

Result: 开发了支持细粒度差异比较和合并的数据版本控制系统，即使存在结构转换也能工作。查询能够"免费"适应模式变更，解决了最近论文中提出的八个模式演化挑战问题中的四个。

Conclusion: 操作差分技术为数据结构版本控制提供了简化而强大的方法，支持灵活的分支共享和查询操作化，显著改进了模式演化场景下的数据管理能力。

Abstract: Baseline is a platform for richly structured data supporting change in multiple dimensions: mutation over time, collaboration across space, and evolution through design changes. It is built upon Operational Differencing, a new technique for managing data in terms of high-level operations that include refactorings and schema changes. We use operational differencing to construct an operation-based form of version control on data structures used in programming languages and relational databases. This approach to data version control does fine-grained diffing and merging despite intervening structural transformations like schema changes. It offers users a simplified conceptual model of version control for ad hoc usage: There is no repo; Branching is just copying. The informaton maintained in a repo can be synthesized more precisely from the append-only histories of branches. Branches can be flexibly shared as is commonly done with document files, except with the added benefit of diffing and merging. We conjecture that queries can be operationalized into a sequence of schema and data operations. We develop that idea on a query language fragment containing selects and joins. Operationalized queries are represented as a future timeline that is speculatively executed as a branch off of the present state, returning a value from its hypothetical future. Operationalized queries get rewritten to accommodate schema change "for free" by the machinery of operational differencing. Altogether we develop solutions to four of the eight challenge problems of schema evolution identified in a recent paper.

</details>


### [8] [Fast Factorized Learning: Powered by In-Memory Database Systems](https://arxiv.org/abs/2512.09836)
*Bernhard Stöckl,Maximilian E. Schüle*

Main category: cs.DB

TL;DR: 在内存数据库系统中实现因子化学习，相比非因子化学习性能提升70%，相比磁盘数据库系统提升100倍


<details>
  <summary>Details</summary>
Motivation: 先前研究在传统磁盘数据库系统上探索因子化学习的性能增益，但由于缺乏公开代码，无法在内存数据库系统上复现实验。本研究旨在实现内存数据库系统中的因子化学习。

Method: 实现因子化学习的开源实现，在PostgreSQL（磁盘数据库）和HyPer（内存数据库引擎）上对因子化连接的线性回归学习进行基准测试。

Result: 评估显示，在内存数据库系统上，因子化学习相比非因子化学习性能提升70%，相比磁盘数据库系统提升100倍。

Conclusion: 现代数据库引擎可以通过在数据提取前预计算聚合来加速机器学习训练，为机器学习流程做出贡献。

Abstract: Learning models over factorized joins avoids redundant computations by identifying and pre-computing shared cofactors. Previous work has investigated the performance gain when computing cofactors on traditional disk-based database systems. Due to the absence of published code, the experiments could not be reproduced on in-memory database systems. This work describes the implementation when using cofactors for in-database factorized learning. We benchmark our open-source implementation for learning linear regression on factorized joins with PostgreSQL -- as a disk-based database system -- and HyPer -- as an in-memory engine. The evaluation shows a performance gain of factorized learning on in-memory database systems by 70\% to non-factorized learning and by a factor of 100 compared to disk-based database systems. Thus, modern database engines can contribute to the machine learning pipeline by pre-computing aggregates prior to data extraction to accelerate training.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [9] [Meta Lattice: Model Space Redesign for Cost-Effective Industry-Scale Ads Recommendations](https://arxiv.org/abs/2512.09200)
*Liang Luo,Yuxin Chen,Zhengyu Zhang,Mengyue Hang,Andrew Gu,Buyun Zhang,Boyang Liu,Chen Chen,Chengze Fan,Dong Liang,Fan Yang,Feifan Gu,Huayu Li,Jade Nie,Jiayi Xu,Jiyan Yang,Jongsoo Park,Laming Chen,Longhao Jin,Qianru Li,Qin Huang,Shali Jiang,Shiwen Shen,Shuaiwen Wang,Sihan Zeng,Siyang Yuan,Tongyi Tang,Weilin Zhang,Wenjun Wang,Xi Liu,Xiaohan Wei,Xiaozhen Xia,Yuchen Hao,Yunlong He,Yasmine Badr,Zeliang Chen,Maxim Naumov,Yantao Yao,Wenlin Chen,Santanu Kolay,GP Musumeci,Ellie Dingqiao Wen*

Main category: cs.IR

TL;DR: Lattice是一个推荐框架，通过模型空间重新设计解决跨域数据碎片化和基础设施成本问题，在Meta部署实现了显著的质量提升和成本节约。


<details>
  <summary>Details</summary>
Motivation: 产品和政策快速变化导致数据碎片化，基础设施成本上升阻碍推荐模型在工业规模部署和持续质量改进。

Method: 通过模型空间重新设计，结合跨域知识共享、数据整合、模型统一、蒸馏和系统优化，扩展多域多目标学习。

Result: 在Meta部署实现了10%收入驱动指标提升、11.5%用户满意度改善、6%转化率提升，同时节省20%容量。

Conclusion: Lattice框架通过全面的模型空间重新设计，有效解决了工业规模推荐系统面临的跨域数据碎片化和成本挑战，实现了质量和效率的双重提升。

Abstract: The rapidly evolving landscape of products, surfaces, policies, and regulations poses significant challenges for deploying state-of-the-art recommendation models at industry scale, primarily due to data fragmentation across domains and escalating infrastructure costs that hinder sustained quality improvements.
  To address this challenge, we propose Lattice, a recommendation framework centered around model space redesign that extends Multi-Domain, Multi-Objective (MDMO) learning beyond models and learning objectives. Lattice addresses these challenges through a comprehensive model space redesign that combines cross-domain knowledge sharing, data consolidation, model unification, distillation, and system optimizations to achieve significant improvements in both quality and cost-efficiency.
  Our deployment of Lattice at Meta has resulted in 10% revenue-driving top-line metrics gain, 11.5% user satisfaction improvement, 6% boost in conversion rate, with 20% capacity saving.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [10] [SURA: Secure Unsourced Random Access](https://arxiv.org/abs/2512.09104)
*Mohammad Javad Ahmadi,Rafael F. Schaefer,H. Vincent Poor*

Main category: cs.IT

TL;DR: 该论文提出了一种基于物理层技术的无源随机接入安全方案，利用反馈信号生成密钥和人工噪声，在不改变原有系统结构的情况下实现保密通信。


<details>
  <summary>Details</summary>
Motivation: 无源随机接入（URA）系统通常缺乏安全机制，而传统安全方案会增加系统开销和延迟。本文旨在为URA系统提供物理层安全保护，同时保持其低成本、低延迟和最小信令开销的优势。

Method: 利用基站广播的反馈信号（依赖于BS-用户信道）为每个用户生成私密密钥和人工噪声序列。通过三个步骤实现安全传输：1）使用密钥加密数据；2）仅发送LDPC编码密钥的校验位；3）用人工噪声掩盖这些校验位。设计了合法用户的接收算法，并进行了信息泄漏分析。

Result: 仿真结果表明，该方案在不改变URA系统结构的情况下实现了有意义的保密性，对标准性能的影响可以忽略不计。

Conclusion: 该研究成功地将物理层安全技术集成到URA系统中，通过利用现有反馈机制实现了安全通信，同时保持了URA系统的低成本优势，为大规模物联网设备的安全接入提供了可行方案。

Abstract: This work introduces security for unsourced random access (URA) by employing wiretap-inspired physical layer techniques. To achieve confidentiality, the proposed system opportunistically exploits intrinsic features of feedback-aided URA without adding any overhead or altering its original structure or operational characteristics. As a result, the proposed system preserves the low-cost advantages of URA, including low delay and minimal signaling overhead, while providing secure communication. To secure transmission, each user generates a secret key and an artificial noise sequence from the feedback signal that the BS broadcasts in previous transmission rounds. This feedback depends on the BS-user channel, making it a private signal for each user. The secure transmission is performed by three actions: encrypting the data using the secret key, sending only the parity bits of the LDPC encoded secret key to allow the legitimate receiver to recover it, and masking these parity bits with the artificial noise. For reception, a receiver algorithm is designed for the legitimate user, and a leakage analysis is provided to quantify the information available to the eavesdropper. The simulation results show that meaningful secrecy is achieved in URA without modifying its structure and with negligible impact on standard performance.

</details>


### [11] [$t$-Fold $s$-Blocking Sets and $s$-Minimal Codes](https://arxiv.org/abs/2512.09457)
*Hao Chen,Xu Pan,Conghui Xie*

Main category: cs.IT

TL;DR: 本文研究了阻塞集与极小码的新下界，推广了Ashikhmin-Barg条件，并构造了满足/违反该条件的无限族s-极小码


<details>
  <summary>Details</summary>
Motivation: 阻塞集和极小码在射影几何和编码理论中已研究多年，但现有结果存在限制条件（如t≤q），需要更一般的下界和理论推广

Method: 1. 建立了无t≤q条件的t-fold s-阻塞集新下界；2. 推导了射影s-极小码长度的下界；3. 证明了(s+1)-极小码一定是s-极小码；4. 将Ashikhmin-Barg条件推广到s-极小码；5. 构造了满足和违反该条件的无限族s-极小码；6. 给出了二进制极小码但不是2-极小码的例子

Result: 1. 获得了比Beutelspacher(1983)更强的阻塞集下界；2. 得到了射影s-极小码长度的新下界；3. 建立了s-极小码的层次关系；4. 成功推广了Ashikhmin-Barg条件；5. 构造了丰富的s-极小码实例

Conclusion: 本文在阻塞集和极小码理论方面取得了重要进展，突破了传统限制条件，建立了更一般的理论框架，并为s-极小码的构造提供了系统方法

Abstract: Blocking sets and minimal codes have been studied for many years in projective geometry and coding theory. In this paper, we provide a new lower bound on the size of $t$-fold $s$-blocking sets without the condition $t \leq q$, which is stronger than the classical result of Beutelspacher in 1983. Then a lower bound on lengths of projective $s$-minimal codes is also obtained. It is proved that $(s+1)$-minimal codes are certainly $s$-minimal codes. We generalize the Ashikhmin-Barg condition for minimal codes to $s$-minimal codes. Many infinite families of $s$-minimal codes satisfying and violating this generalized Ashikhmin-Barg condition are constructed. We also give several examples which are binary minimal codes, but not $2$-minimal codes.

</details>


### [12] [Binary and Non-Binary Self-Dual Sequences and Maximum Period Single-Track Gray Codes](https://arxiv.org/abs/2512.09655)
*Tuvi Etzion*

Main category: cs.IT

TL;DR: 该论文研究了二进制和非二进制自对偶序列的结构与递归构造，探讨了生成这些序列的反馈移位寄存器，并构建了周期为p^{p^t}的最大周期非二进制单轨格雷码无限族。


<details>
  <summary>Details</summary>
Motivation: 受单轨格雷码构造的启发，研究二进制和非二进制自对偶序列的结构与递归构造，探索这些序列与最大周期单轨码之间的联系。

Method: 分析自对偶序列的结构，提出递归构造方法，讨论生成这些序列的反馈移位寄存器，并构建最大周期非二进制单轨格雷码。

Result: 构建了长度为p^t、周期为p^{p^t}的最大周期非二进制单轨格雷码，这是文献中首次提出的最大周期码无限族。

Conclusion: 论文成功建立了自对偶序列与单轨格雷码之间的联系，提出了第一个最大周期非二进制单轨格雷码的无限族构造，为相关应用提供了理论基础。

Abstract: Binary self-dual sequences have been considered and analyzed throughout the years, and they were used for various applications. Motivated by a construction for single-track Gray codes, we examine the structure and recursive constructions for binary and non-binary self-dual sequences. The feedback shift registers that generate such sequences are discussed. The connections between these sequences and maximum period single-track codes are discussed. Maximum period non-binary single-track Gray codes of length $p^t$ and period $p^{p^t}$ are constructed. These are the first infinite families of maximum period codes presented in the literature.

</details>


### [13] [Typical Solutions of Multi-User Linearly-Decomposable Distributed Computing](https://arxiv.org/abs/2512.09858)
*Ali Khalesi,Mohammad Reza Deylam Salehi*

Main category: cs.IT

TL;DR: 本文解决了典型意义下的多发送者线性可分解分布式计算问题，建立了编码器/解码器和需求矩阵的实值模型，通过阈值化图编辑距离评估结构保真度，获得了闭式二阶矩风险、GED与范数误差的确定性联系、高斯代理模型等结果。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决tessellated分布式计算中提出的多发送者线性可分解分布式计算问题，建立实值模型来更准确地反映实际系统，并通过结构保真度评估来保证计算质量。

Method: 采用实值编码器/解码器和需求矩阵建模，使用阈值化图编辑距离(GED)评估需求支持与计算乘积两跳支持之间的结构保真度，分析尖峰-平板集合下的二阶矩风险，建立GED与范数误差的确定性联系，提出高斯代理模型。

Result: 获得了尖峰-平板集合下的闭式二阶矩(Frobenius)风险；建立了阈值化GED与范数误差的确定性联系；提出了具有次指数尾的高斯代理模型，揭示了显式召回线；证明了GED的集中性和算子范数控制；设计了具有可见拐点的计算上限方案。

Conclusion: 本文在典型意义下解决了多发送者线性可分解分布式计算问题，建立了完整的理论框架和分析工具，并将规则映射到航空和卫星网络中，为实际分布式系统设计提供了理论基础。

Abstract: We solve, in the typical-case sense, the multi-sender linearly-decomposable distributed computing problem introduced by tessellated distributed computing. We model real-valued encoders/decoders and demand matrices, and assess structural fidelity via a thresholded graph edit distance between the demand support and the two-hop support of the computed product. Our analysis yields: a closed-form second-moment (Frobenius) risk under spike-and-slab ensembles; deterministic links between thresholded GED and norm error; a Gaussian surrogate with sub-exponential tails that exposes explicit recall lines; concentration of GED and operator-norm control; and a compute-capped design with a visible knee. We map the rules to aeronautical and satellite networks.

</details>
