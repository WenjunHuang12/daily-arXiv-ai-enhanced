<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 3]
- [cs.IR](#cs.IR) [Total: 4]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.IT](#cs.IT) [Total: 5]
- [cs.DS](#cs.DS) [Total: 6]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [RAG-Driven Data Quality Governance for Enterprise ERP Systems](https://arxiv.org/abs/2511.16700)
*Sedat Bin Vedat,Enes Kutay Yarkan,Meftun Akarsu,Recep Kaan Karaman,Arda Sar,Ã‡aÄŸrÄ± Ã‡elikbilek,SavaÅŸ SaygÄ±lÄ±*

Main category: cs.DB

TL;DR: æå‡ºäº†ä¸€ä¸ªç»“åˆè‡ªåŠ¨åŒ–æ•°æ®æ¸…ç†å’ŒLLMé©±åŠ¨SQLæŸ¥è¯¢ç”Ÿæˆçš„ç«¯åˆ°ç«¯ç®¡é“ï¼Œç”¨äºè§£å†³ä¼ä¸šERPç³»ç»Ÿä¸­å¤šè¯­è¨€æ‰‹åŠ¨å½•å…¥çš„æ•°æ®è´¨é‡é—®é¢˜ï¼Œåœ¨24ä¸‡å‘˜å·¥è®°å½•çš„ç”Ÿäº§ç³»ç»Ÿä¸­éƒ¨ç½²6ä¸ªæœˆï¼Œæ˜¾è‘—æå‡äº†æŸ¥è¯¢æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚


<details>
  <summary>Details</summary>
Motivation: ä¼ä¸šERPç³»ç»Ÿé¢ä¸´å¤šè¯­è¨€æ‰‹åŠ¨å½•å…¥å¯¼è‡´çš„æ•°æ®è´¨é‡é—®é¢˜ï¼Œéœ€è¦è§£å†³äººåŠ›èµ„æºéƒ¨é—¨åˆ†æ•£å½•å…¥æ—¶çš„ç¿»è¯‘æ ‡å‡†åŒ–ã€æ‹¼å†™çº æ­£å’Œå®ä½“å»é‡ç­‰æŒ‘æˆ˜ï¼ŒåŒæ—¶éœ€è¦å°†è‡ªç„¶è¯­è¨€é—®é¢˜å¿«é€Ÿè½¬æ¢ä¸ºæœ‰æ•ˆçš„SQLæŸ¥è¯¢ã€‚

Method: é‡‡ç”¨ä¸¤é˜¶æ®µé›†æˆæ–¹æ³•ï¼šå¤šé˜¶æ®µæ¸…ç†ç®¡é“ï¼ˆç¿»è¯‘æ ‡å‡†åŒ–ã€æ‹¼å†™çº æ­£ã€å®ä½“å»é‡ï¼‰å’ŒåŸºäºGPT-4oçš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ï¼Œä½¿ç”¨LangChainç¼–æ’ã€FAISSå‘é‡ç›¸ä¼¼æ€§æœç´¢å’Œ500+éªŒè¯ç¤ºä¾‹çš„å°‘æ ·æœ¬å­¦ä¹ ã€‚

Result: åœ¨2847ä¸ªç”Ÿäº§æŸ¥è¯¢ä¸­è¾¾åˆ°92.5%æŸ¥è¯¢æœ‰æ•ˆæ€§ã€95.1%æ¨¡å¼åˆè§„æ€§å’Œ90.7%è¯­ä¹‰å‡†ç¡®æ€§ï¼ŒæŸ¥è¯¢å‘¨è½¬æ—¶é—´ä»2.3å¤©å‡å°‘åˆ°5ç§’ä»¥å†…ï¼Œç³»ç»Ÿå¯ç”¨æ€§è¾¾99.2%ï¼ŒGPT-4oç›¸æ¯”GPT-3.5å»¶è¿Ÿé™ä½46%ã€æˆæœ¬å‡å°‘68%ã€‚

Conclusion: è¯¥æ¨¡å—åŒ–æ¶æ„ä¸ºä¼ä¸šAIåŸç”Ÿæ•°æ®æ²»ç†æä¾›äº†å¯å¤ç°æ¡†æ¶ï¼Œåœ¨ä¼ä¸šè§„æ¨¡ä¸‹è¯æ˜äº†å®é™…å¯è¡Œæ€§ï¼Œç”¨æˆ·æ»¡æ„åº¦è¾¾4.3/5.0ã€‚

Abstract: Enterprise ERP systems managing hundreds of thousands of employee records face critical data quality challenges when human resources departments perform decentralized manual entry across multiple languages. We present an end-to-end pipeline combining automated data cleaning with LLM-driven SQL query generation, deployed on a production system managing 240,000 employee records over six months.
  The system operates in two integrated stages: a multi-stage cleaning pipeline that performs translation normalization, spelling correction, and entity deduplication during periodic synchronization from Microsoft SQL Server to PostgreSQL; and a retrieval-augmented generation framework powered by GPT-4o that translates natural-language questions in Turkish, Russian, and English into validated SQL queries. The query engine employs LangChain orchestration, FAISS vector similarity search, and few-shot learning with 500+ validated examples.
  Our evaluation demonstrates 92.5% query validity, 95.1% schema compliance, and 90.7\% semantic accuracy on 2,847 production queries. The system reduces query turnaround time from 2.3 days to under 5 seconds while maintaining 99.2% uptime, with GPT-4o achieving 46% lower latency and 68% cost reduction versus GPT-3.5. This modular architecture provides a reproducible framework for AI-native enterprise data governance, demonstrating real-world viability at enterprise scale with 4.3/5.0 user satisfaction.

</details>


### [2] [LinkML: An Open Data Modeling Framework](https://arxiv.org/abs/2511.16935)
*Sierra A. T. Moxon,Harold Solbrig,Nomi L. Harris,Patrick Kalita,Mark A. Miller,Sujay Patil,Kevin Schaper,Chris Bizon,J. Harry Caufield,Silvano Cirujano Cuesta,Corey Cox,Frank Dekervel,Damion M. Dooley,William D. Duncan,Tim Fliss,Sarah Gehrke,Adam S. L. Graefe,Harshad Hegde,AJ Ireland,Julius O. B. Jacobsen,Madan Krishnamurthy,Carlo Kroll,David Linke,Ryan Ly,Nicolas Matentzoglu,James A. Overton,Jonny L. Saunders,Deepak R. Unni,Gaurav Vaidya,Wouter-Michiel A. M. Vierdag,LinkML Community Contributors,Oliver Ruebel,Christopher G. Chute,Matthew H. Brush,Melissa A. Haendel,Christopher J. Mungall*

Main category: cs.DB

TL;DR: LinkMLæ˜¯ä¸€ä¸ªå¼€æ”¾çš„æ•°æ®å»ºæ¨¡æ¡†æ¶ï¼Œé€šè¿‡æ ‡å‡†åŒ–æ•°æ®ç»“æ„å’Œè¯­ä¹‰æè¿°ï¼Œè§£å†³ç§‘å­¦æ•°æ®ç¼ºä¹ç»“æ„åŒ–å’Œäº’æ“ä½œæ€§çš„é—®é¢˜ã€‚


<details>
  <summary>Details</summary>
Motivation: ç§‘å­¦æ•°æ®é€šå¸¸å­˜å‚¨åœ¨éç»“æ„åŒ–æ ¼å¼ä¸­ï¼Œå¦‚è‡ªç”±æ–‡æœ¬å®éªŒå®¤ç¬”è®°æœ¬ã€éæ ‡å‡†åŒ–ç”µå­è¡¨æ ¼ç­‰ï¼Œè¿™å¯¼è‡´æ•°æ®é›†æˆã€éªŒè¯å’Œé‡ç”¨å›°éš¾ï¼Œç¼ºä¹äº’æ“ä½œæ€§ã€‚

Method: LinkMLæä¾›äº†ä¸€ç§å¯è®¿é—®çš„è¯­æ³•æ¥æè¿°æ¨¡å¼ã€ç±»å’Œå…³ç³»ï¼Œæ”¯æŒä»ç®€å•åˆ—è¡¨åˆ°å¤æ‚äº’ç›¸å…³è”çš„æ•°æ®ç»“æ„ï¼ŒåŒ…æ‹¬å¤šæ€æ€§å’Œå¤åˆç»§æ‰¿ã€‚å®ƒå¯ä»¥ä¸ç°æœ‰æ¡†æ¶æ— ç¼é›†æˆï¼Œå¹¶å…è®¸æ¨¡å¼ä¹‹é—´çš„å¯¼å…¥ã€‚

Result: LinkMLå‡å°‘äº†å¼‚æ„æ€§ã€å¤æ‚æ€§å’Œä¸€æ¬¡æ€§æ•°æ®æ¨¡å‹çš„æ‰©æ•£ï¼ŒåŒæ—¶æ”¯æŒFAIRæ•°æ®æ ‡å‡†ã€‚å·²åœ¨ç”Ÿç‰©å­¦ã€åŒ–å­¦ã€ç”Ÿç‰©åŒ»å­¦ã€é‡‘èç­‰å¤šä¸ªé¢†åŸŸå¾—åˆ°åº”ç”¨ã€‚

Conclusion: LinkMLä½¿éšå¼æ¨¡å‹å˜å¾—æ˜¾å¼å¯è®¡ç®—ï¼Œå…è®¸åœ¨æ•°æ®æºå¤´è¿›è¡Œæ ‡å‡†åŒ–ï¼Œä¸ºè·¨å­¦ç§‘åä½œæä¾›äº†å¯é çš„æ•°æ®è¯­ä¹‰å®šä¹‰å’Œå…±äº«å¹³å°ã€‚

Abstract: Scientific research relies on well-structured, standardized data; however, much of it is stored in formats such as free-text lab notebooks, non-standardized spreadsheets, or data repositories. This lack of structure challenges interoperability, making data integration, validation, and reuse difficult. LinkML (Linked Data Modeling Language) is an open framework that simplifies the process of authoring, validating, and sharing data. LinkML can describe a range of data structures, from flat, list-based models to complex, interrelated, and normalized models that utilize polymorphism and compound inheritance. It offers an approachable syntax that is not tied to any one technical architecture and can be integrated seamlessly with many existing frameworks. The LinkML syntax provides a standard way to describe schemas, classes, and relationships, allowing modelers to build well-defined, stable, and optionally ontology-aligned data structures. Once defined, LinkML schemas may be imported into other LinkML schemas. These key features make LinkML an accessible platform for interdisciplinary collaboration and a reliable way to define and share data semantics.
  LinkML helps reduce heterogeneity, complexity, and the proliferation of single-use data models while simultaneously enabling compliance with FAIR data standards. LinkML has seen increasing adoption in various fields, including biology, chemistry, biomedicine, microbiome research, finance, electrical engineering, transportation, and commercial software development. In short, LinkML makes implicit models explicitly computable and allows data to be standardized at its origin. LinkML documentation and code are available at linkml.io.

</details>


### [3] [Anomaly Pattern-guided Transaction Bug Testing in Relational Databases](https://arxiv.org/abs/2511.17377)
*Huicong Xu,Shuang Liu,Xianyu Zhu,Qiyu Zhuang,Wei Lu,Xiaoyong Du*

Main category: cs.DB

TL;DR: æå‡ºäº†ä¸€ç§åŸºäºå¼‚å¸¸æ¨¡å¼æŒ‡å¯¼çš„æµ‹è¯•æ–¹æ³•APTransï¼Œç”¨äºå‘ç°RDBMSä¸­çš„äº‹åŠ¡å¤„ç†bugï¼Œåœ¨ä¸‰ä¸ªä¸»æµæ•°æ®åº“ç³»ç»Ÿä¸­å‘ç°äº†13ä¸ªæœªçŸ¥bug


<details>
  <summary>Details</summary>
Motivation: æµ‹è¯•ä¸åŒéš”ç¦»çº§åˆ«ä¸‹çš„äº‹åŠ¡è¡Œä¸ºå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºè‡ªåŠ¨ç”Ÿæˆèƒ½æš´éœ²bugçš„æµ‹è¯•äº‹åŠ¡å¾ˆå›°éš¾ï¼Œä¸”æ£€æµ‹äº‹åŠ¡ç»“æœä¸­çš„é€»è¾‘å¼‚å¸¸ä¹Ÿå¾ˆå›°éš¾

Method: é‡‡ç”¨å¼‚å¸¸æ¨¡å¼æŒ‡å¯¼çš„æµ‹è¯•ç”¨ä¾‹ç”ŸæˆæŠ€æœ¯ï¼Œä»¥åŠåŒ…å«æ˜¾å¼å’Œéšå¼é”™è¯¯æ£€æµ‹çš„ä¸¤é˜¶æ®µæ£€æµ‹è¿‡ç¨‹

Result: åœ¨MySQLã€MariaDBå’ŒOceanBaseä¸‰ä¸ªRDBMSä¸­æˆåŠŸè¯†åˆ«å‡º13ä¸ªä¹‹å‰æœªçŸ¥çš„äº‹åŠ¡ç›¸å…³bugï¼Œå…¶ä¸­11ä¸ªå·²è¢«å¼€å‘å›¢é˜Ÿç¡®è®¤

Conclusion: APTransæ–¹æ³•æœ‰æ•ˆè§£å†³äº†äº‹åŠ¡æµ‹è¯•ä¸­çš„æŒ‘æˆ˜ï¼Œèƒ½å¤Ÿå¯é åœ°å‘ç°RDBMSä¸­çš„äº‹åŠ¡å¤„ç†bug

Abstract: Concurrent transaction processing is a fundamental capability of Relational Database Management Systems (RDBMSs), widely utilized in applications requiring high levels of parallel user interaction, such as banking systems, e-commerce platforms, and telecommunications infrastructure. Isolation levels offer a configurable mechanism to manage the interaction between concurrent transactions, enabling varying degrees of consistency and performance trade-offs. These isolation guarantees are supported by all major RDBMSs. However, testing transaction behavior under different isolation levels remains a significant challenge due to two primary reasons. First, automatically generating test transactions that can effectively expose bugs in transaction handling logic is non-trivial, as such bugs are typically triggered under specific transactional constraints. Second, detecting logic anomalies in transaction outcomes is difficult because the correct execution results are often unknown for randomly generated transactions. To address these challenges, we propose an anomaly pattern-guided testing approach for uncovering transaction bugs in RDBMSs. Our solution tackles the first challenge by introducing a test case generation technique guided by predefined anomaly patterns, which increases the likelihood of exposing transactional bugs. For the second challenge, we present a two-phase detection process, involving explicit error detection and implicit error detection, to identify bugs in transaction execution. We have implemented our approach in a tool, APTrans, and evaluated it on three widely-used RDBMSs: MySQL, MariaDB, and OceanBase. APTrans successfully identified 13 previously unknown transaction-related bugs, 11 of which have been confirmed by the respective development teams.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [4] [Î´-EMG: A Monotonic Graph Index for Approximate Nearest Neighbor Search](https://arxiv.org/abs/2511.16921)
*Liming Xiang,Jing Feng,Ziqi Yin,Zijian Li,Daihao Xue,Hongchao Qin,Ronghua Li,Guoren Wang*

Main category: cs.IR

TL;DR: æœ¬æ–‡æå‡ºäº†ä¸€ç§è¯¯å·®æœ‰ç•Œçš„è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢æ–¹æ³•ï¼Œé€šè¿‡Î´-EMGå›¾ç»“æ„ç¡®ä¿è¿”å›ç»“æœæ˜¯çœŸå®å€¼çš„(1/Î´)è¿‘ä¼¼ï¼Œç›¸æ¯”ä¼ ç»Ÿçš„åŸºäºå¬å›ç‡çš„è¯„ä¼°æ–¹æ³•æä¾›äº†æ›´å¼ºçš„ç†è®ºä¿è¯ã€‚


<details>
  <summary>Details</summary>
Motivation: å½“å‰è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ç®—æ³•ä¸»è¦åŸºäºÎµ-å¬å›ç‡åŸåˆ™ï¼Œåªå…³æ³¨æ­£ç¡®ç»“æœçš„å¬å›ç‡ï¼Œæ— æ³•ä¿è¯é”™è¯¯ç»“æœçš„åå·®èŒƒå›´ã€‚æœ¬æ–‡æ—¨åœ¨è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæä¾›å…·æœ‰ç†è®ºä¿è¯çš„è¯¯å·®æœ‰ç•Œè¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ã€‚

Method: æå‡ºÎ´-EMGï¼ˆè¯¯å·®æœ‰ç•Œå•è°ƒå›¾ï¼‰æ¡†æ¶ï¼Œé€šè¿‡åœ¨å›¾ä¸­å¼ºåˆ¶Î´-å•è°ƒå‡ ä½•çº¦æŸï¼Œç¡®ä¿è´ªå¿ƒæœç´¢æ”¶æ•›åˆ°(1/Î´)è¿‘ä¼¼é‚»å±…è€Œæ— éœ€å›æº¯ã€‚è¿›ä¸€æ­¥è®¾è®¡äº†è¯¯å·®æœ‰ç•Œtop-kæœç´¢ç®—æ³•å’ŒÎ´-EMQGï¼ˆè¯¯å·®æœ‰ç•Œå•è°ƒé‡åŒ–å›¾ï¼‰å®ç°é«˜æ•ˆæ‰©å±•ã€‚

Result: åœ¨ANN-Benchmarksæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œåœ¨å¬å›ç‡è¦æ±‚ä¸º0.99æ—¶ï¼Œè¯¥æ–¹æ³•åœ¨SIFT1Mæ•°æ®é›†ä¸Šè¾¾åˆ°19,000 QPSï¼Œæ¯”å…¶ä»–æ–¹æ³•æ€§èƒ½æå‡è¶…è¿‡40%ã€‚

Conclusion: æœ¬æ–‡æå‡ºçš„è¯¯å·®æœ‰ç•Œè¿‘ä¼¼æœ€è¿‘é‚»æœç´¢æ¡†æ¶ä¸ä»…æä¾›äº†æ›´å¼ºçš„ç†è®ºä¿è¯ï¼Œåœ¨å®é™…æ€§èƒ½ä¸Šä¹Ÿæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºé«˜ç»´ç©ºé—´æ£€ç´¢ç³»ç»Ÿæä¾›äº†æ›´å¯é çš„è§£å†³æ–¹æ¡ˆã€‚

Abstract: Approximate nearest neighbor (ANN) search in high-dimensional spaces is a foundational component of many modern retrieval and recommendation systems. Currently, almost all algorithms follow an $Îµ$-Recall-Bounded principle when comparing performance: they require the ANN search results to achieve a recall of more than $1-Îµ$ and then compare query-per-second (QPS) performance. However, this approach only accounts for the recall of true positive results and does not provide guarantees on the deviation of incorrect results. To address this limitation, we focus on an Error-Bounded ANN method, which ensures that the returned results are a $(1/Î´)$-approximation of the true values. Our approach adopts a graph-based framework. To enable Error-Bounded ANN search, we propose a $Î´$-EMG (Error-bounded Monotonic Graph), which, for the first time, provides a provable approximation for arbitrary queries. By enforcing a $Î´$-monotonic geometric constraint during graph construction, $Î´$-EMG ensures that any greedy search converges to a $(1/Î´)$-approximate neighbor without backtracking. Building on this foundation, we design an error-bounded top-$k$ ANN search algorithm that adaptively controls approximation accuracy during query time. To make the framework practical at scale, we introduce $Î´$-EMQG (Error-bounded Monotonic Quantized Graph), a localized and degree-balanced variant with near-linear construction complexity. We further integrate vector quantization to accelerate distance computation while preserving theoretical guarantees. Extensive experiments on the ANN-Benchmarks dataset demonstrate the effectiveness of our approach. Under a recall requirement of 0.99, our algorithm achieves 19,000 QPS on the SIFT1M dataset, outperforming other methods by more than 40\%.

</details>


### [5] [RASTP: Representation-Aware Semantic Token Pruning for Generative Recommendation with Semantic Identifiers](https://arxiv.org/abs/2511.16943)
*Tianyu Zhan,Kairui Fu,Zheqi Lv,Shengyu Zhang*

Main category: cs.IR

TL;DR: RASTPæ˜¯ä¸€ç§é€šè¿‡å‰ªæè¯­ä¹‰æ ‡è¯†ç¬¦ä¸­ä¿¡æ¯é‡è¾ƒå°‘çš„tokenæ¥å‡å°‘ç”Ÿæˆå¼æ¨èç³»ç»Ÿè®¡ç®—å¤æ‚åº¦å’Œå†…å­˜æ¶ˆè€—çš„æ–¹æ³•ï¼Œåœ¨ä¿æŒæ¨èæ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½è®­ç»ƒæ—¶é—´ã€‚


<details>
  <summary>Details</summary>
Motivation: ç”Ÿæˆå¼æ¨èç³»ç»Ÿä½¿ç”¨è¯­ä¹‰æ ‡è¯†ç¬¦(SIDs)è¡¨ç¤ºç‰©å“ï¼Œä½†å¤šä¸ªSIDsä¼šæ˜¾è‘—å¢åŠ è¾“å…¥åºåˆ—é•¿åº¦ï¼Œå¯¼è‡´è®¡ç®—å¤æ‚åº¦å’Œå†…å­˜æ¶ˆè€—å¤§å¹…ä¸Šå‡ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¼˜åŒ–æ³¨æ„åŠ›è®¡ç®—å’ŒKVç¼“å­˜ï¼Œä½†è¾“å…¥åºåˆ—é•¿åº¦ä»æ˜¯ä¸»è¦ç“¶é¢ˆã€‚

Method: æå‡ºRASTPæ–¹æ³•ï¼Œé€šè¿‡ç»“åˆè¯­ä¹‰æ˜¾è‘—æ€§å’Œæ³¨æ„åŠ›ä¸­å¿ƒæ€§æ¥è¯„ä¼°tokené‡è¦æ€§ï¼ŒåŠ¨æ€å‰ªæä¿¡æ¯é‡è¾ƒä½æˆ–ä¸ç›¸å…³çš„è¯­ä¹‰tokenã€‚è¯­ä¹‰æ˜¾è‘—æ€§é€šè¿‡è¡¨ç¤ºå¹…åº¦è¡¡é‡ï¼Œæ³¨æ„åŠ›ä¸­å¿ƒæ€§é€šè¿‡ç´¯ç§¯æ³¨æ„åŠ›æƒé‡è®¡ç®—ã€‚

Result: åœ¨ä¸‰ä¸ªçœŸå®ä¸–ç•ŒAmazonæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒRASTPå°†è®­ç»ƒæ—¶é—´å‡å°‘äº†26.7%ï¼ŒåŒæ—¶ä¿æŒæˆ–ç•¥å¾®æ”¹å–„äº†æ¨èæ€§èƒ½ã€‚

Conclusion: RASTPé€šè¿‡ç›´æ¥å‰ªæè¾“å…¥åºåˆ—ä¸­çš„ä½ä¿¡æ¯tokenï¼Œæœ‰æ•ˆè§£å†³äº†ç”Ÿæˆå¼æ¨èç³»ç»Ÿçš„è®¡ç®—æ•ˆç‡é—®é¢˜ï¼Œåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶æ˜¾è‘—æå‡äº†è®­ç»ƒæ•ˆç‡ã€‚

Abstract: Generative recommendation systems typically leverage Semantic Identifiers (SIDs), which represent each item as a sequence of tokens that encode semantic information. However, representing item ID with multiple SIDs significantly increases input sequence length, which is a major determinant of computational complexity and memory consumption. While existing efforts primarily focus on optimizing attention computation and KV cache, we propose RASTP (Representation-Aware Semantic Token Pruning), which directly prunes less informative tokens in the input sequence. Specifically, RASTP evaluates token importance by combining semantic saliency, measured via representation magnitude, and attention centrality, derived from cumulative attention weights. Since RASTP dynamically prunes low-information or irrelevant semantic tokens, experiments on three real-world Amazon datasets show that RASTP reduces training time by 26.7\%, while maintaining or slightly improving recommendation performance. The code has been open-sourced at https://github.com/Yuzt-zju/RASTP.

</details>


### [6] [CLLMRec: LLM-powered Cognitive-Aware Concept Recommendation via Semantic Alignment and Prerequisite Knowledge Distillation](https://arxiv.org/abs/2511.17041)
*Xiangrui Xiong,Yichuan Lu,Zifei Pan,Chang Sun*

Main category: cs.IR

TL;DR: CLLMRecæ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„MOOCæ¦‚å¿µæ¨èæ¡†æ¶ï¼Œé€šè¿‡è¯­ä¹‰å¯¹é½å’Œå…ˆéªŒçŸ¥è¯†è’¸é¦æŠ€æœ¯ï¼Œæ— éœ€ä¾èµ–ç»“æ„åŒ–çŸ¥è¯†å›¾è°±å³å¯ç”Ÿæˆè®¤çŸ¥æ„ŸçŸ¥çš„ä¸ªæ€§åŒ–æ¦‚å¿µæ¨èã€‚


<details>
  <summary>Details</summary>
Motivation: è§£å†³ç°æœ‰MOOCæ¦‚å¿µæ¨èæ–¹æ³•å¯¹é«˜è´¨é‡ç»“æ„åŒ–çŸ¥è¯†å›¾è°±çš„ä¾èµ–é—®é¢˜ï¼Œè¿™äº›å›¾è°±åœ¨ç°å®æ•™è‚²åœºæ™¯ä¸­å¾€å¾€ç¨€ç¼ºã€‚

Method: ä½¿ç”¨è¯­ä¹‰å¯¹é½æ„å»ºç»Ÿä¸€è¡¨ç¤ºç©ºé—´ï¼Œé€šè¿‡æ•™å¸ˆ-å­¦ç”Ÿæ¶æ„çš„å…ˆéªŒçŸ¥è¯†è’¸é¦æå–æ¦‚å¿µå…ˆå†³å…³ç³»ï¼Œç»“åˆæ·±åº¦çŸ¥è¯†è¿½è¸ªå»ºæ¨¡å­¦ä¹ è€…å®æ—¶è®¤çŸ¥çŠ¶æ€ã€‚

Result: åœ¨ä¸¤ä¸ªçœŸå®MOOCæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCLLMRecåœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚

Conclusion: CLLMRecèƒ½å¤Ÿåœ¨ä¸ä¾èµ–æ˜¾å¼ç»“æ„å…ˆéªŒçš„æƒ…å†µä¸‹ï¼Œç”ŸæˆçœŸæ­£è®¤çŸ¥æ„ŸçŸ¥å’Œä¸ªæ€§åŒ–çš„æ¦‚å¿µæ¨èã€‚

Abstract: The growth of Massive Open Online Courses (MOOCs) presents significant challenges for personalized learning, where concept recommendation is crucial. Existing approaches typically rely on heterogeneous information networks or knowledge graphs to capture conceptual relationships, combined with knowledge tracing models to assess learners' cognitive states. However, these methods face significant limitations due to their dependence on high-quality structured knowledge graphs, which are often scarce in real-world educational scenarios. To address this fundamental challenge, this paper proposes CLLMRec, a novel framework that leverages Large Language Models through two synergistic technical pillars: Semantic Alignment and Prerequisite Knowledge Distillation. The Semantic Alignment component constructs a unified representation space by encoding unstructured textual descriptions of learners and concepts. The Prerequisite Knowledge Distillation paradigm employs a teacher-student architecture, where a large teacher LLM (implemented as the Prior Knowledge Aware Component) extracts conceptual prerequisite relationships from its internalized world knowledge and distills them into soft labels to train an efficient student ranker. Building upon these foundations, our framework incorporates a fine-ranking mechanism that explicitly models learners' real-time cognitive states through deep knowledge tracing, ensuring recommendations are both structurally sound and cognitively appropriate. Extensive experiments on two real-world MOOC datasets demonstrate that CLLMRec significantly outperforms existing baseline methods across multiple evaluation metrics, validating its effectiveness in generating truly cognitive-aware and personalized concept recommendations without relying on explicit structural priors.

</details>


### [7] [Parametric Retrieval-Augmented Generation using Latent Routing of LoRA Adapters](https://arxiv.org/abs/2511.17044)
*Zhan Su,Fengran Mo,Jian-yun Nie*

Main category: cs.IR

TL;DR: æå‡ºPoly-PRAGæ–¹æ³•ï¼Œé€šè¿‡æ½œåœ¨è·¯ç”±ç¼–ç è¿‡ç¨‹è§£å†³ä¼ ç»ŸPRAGä¸­ä¸€å¯¹ä¸€æ–‡æ¡£ç¼–ç æ–¹æ¡ˆçš„æ•°æ®ç¨€ç¼ºå’Œé«˜æ¨ç†å¼€é”€é—®é¢˜ï¼Œä½¿ç”¨å°‘é‡æ½œåœ¨LoRAé€‚é…å™¨ç¼–ç æ•´ä¸ªæ–‡æ¡£ç©ºé—´ã€‚


<details>
  <summary>Details</summary>
Motivation: ä¼ ç»ŸPRAGæ–¹æ³•é‡‡ç”¨ä¸€å¯¹ä¸€æ–‡æ¡£ç¼–ç æ–¹æ¡ˆï¼Œæ¯ä¸ªæ–‡æ¡£ä½¿ç”¨ä¸“ç”¨LoRAé€‚é…å™¨ï¼Œå¯¼è‡´æ•°æ®ç¨€ç¼ºå’Œæ¨ç†æ—¶çš„é«˜è®¡ç®—å¼€é”€ã€‚

Method: å°†æ–‡æ¡£é›†ç¼–ç è§†ä¸ºå¤šä»»åŠ¡å­¦ä¹ è¿‡ç¨‹ï¼Œæ¯ä¸ªæ®µè½åˆ†é…å”¯ä¸€ä»»åŠ¡æ ‡è¯†ç¬¦ï¼Œé€šè¿‡è·¯ç”±å‡½æ•°ä½¿ç”¨å°‘é‡æ½œåœ¨LoRAé€‚é…å™¨ç¼–ç æ•´ä¸ªæ®µè½ç©ºé—´ï¼Œåœ¨çº¿æ¨ç†æ—¶æ ¹æ®æŸ¥è¯¢é€‰æ‹©æ€§æ¿€æ´»æ½œåœ¨ä¸“å®¶å­é›†ã€‚

Result: åœ¨å¤šä¸ªçŸ¥è¯†å¯†é›†å‹NLPä»»åŠ¡ä¸Šçš„ç»¼åˆè¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å››ä¸ªä¸åŒæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚

Conclusion: Poly-PRAGé€šè¿‡æ½œåœ¨è·¯ç”±ç¼–ç èŒƒå¼æœ‰æ•ˆè§£å†³äº†ä¼ ç»ŸPRAGæ–¹æ³•çš„å±€é™æ€§ï¼Œæ˜¾è‘—æå‡äº†æ•ˆç‡å’Œæ€§èƒ½ã€‚

Abstract: Parametric Retrieval-Augmented Generation (PRAG) is a novel RAG paradigm that integrates external knowledge directly into a Large Language Model (LLM) by parameterizing documents using LoRA adapters, demonstrating reduced inference costs compared to traditional RAG approaches. However, current PRAG approaches adopt a \textbf{one-to-one} document encoding scheme, using a dedicated LoRA adapter for each individual document. This scheme introduces two major limitations: First, it leads to data scarcity, as the training datasets for individual LoRA adapters are limited. Second, it incurs high overhead during inference, requiring the merging of LLM weights with a new LoRA adapter for every candidate passage, which is computationally inefficient. To overcome these challenges, we propose a novel paradigm for encoding passages in PRAG that utilizes a latent routing encoding process (Poly-PRAG). During offline encoding, we treat the encoding of a set of documents as a multi-task learning process, where each passage is assigned a unique task identifier. By employing a routing function, we use a small set of latent LoRA adapters to encode the entire passage space. During online inference, this routing function selectively activates a subset of latent experts based on the input query. We conduct comprehensive evaluations of Poly-PRAG across multiple knowledge-intensive NLP tasks. Our extensive experiments demonstrate the effectiveness of the proposed method, achieving state-of-the-art results on four distinct datasets.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [8] [Near-Optimal Dropout-Robust Sortition](https://arxiv.org/abs/2511.16897)
*Maya Pal Gambhir,Bailey Flanigan,Aaron Roth*

Main category: cs.GT

TL;DR: æå‡ºä¸€ç§é«˜æ•ˆç®—æ³•æ¥è§£å†³å…¬æ°‘è®®ä¼šä¸­æˆå‘˜ä¸´æ—¶é€€å‡ºçš„é—®é¢˜ï¼Œé€šè¿‡æœ€å°åŒ–åšå¼ˆæ¡†æ¶ç¡®ä¿é€€å‡ºåçš„é¢æ¿ä»å…·æœ‰ä»£è¡¨æ€§å’Œé€‚å½“è§„æ¨¡ã€‚


<details>
  <summary>Details</summary>
Motivation: å…¬æ°‘è®®ä¼šä¸­æˆå‘˜ä¸´æ—¶é€€å‡ºä¼šå½±å“é¢æ¿è§„æ¨¡å’Œä»£è¡¨æ€§ï¼Œéœ€è¦åœ¨ä¸é¢„çŸ¥é€€å‡ºæƒ…å†µçš„å‰æä¸‹é€‰æ‹©æˆå‘˜ï¼Œç¡®ä¿é€€å‡ºåä»æ»¡è¶³ä»£è¡¨æ€§è¦æ±‚ã€‚

Method: å°†é—®é¢˜å»ºæ¨¡ä¸ºæœ€å°åŒ–åšå¼ˆï¼Œä½¿ç”¨æŠ•å½±æ¢¯åº¦ä¸‹é™å­ç¨‹åºä¸è®¡ç®—æœ€ä½³å“åº”é€€å‡ºåˆ†å¸ƒçš„é«˜æ•ˆç®—æ³•è¿›è¡Œè¿­ä»£ï¼Œç¡®ä¿æ¯ä¸ªæ½œåœ¨æˆå‘˜è¢«é€‰ä¸­çš„æ¦‚ç‡ç›¸å¯¹å‡ç­‰ã€‚

Result: å¼€å‘å‡ºé«˜æ•ˆçš„æŸå¤±æœ€å°åŒ–ç®—æ³•ï¼Œåœ¨çœŸå®æ•°æ®é›†ä¸Šä¼˜äºç°æœ‰åŸºå‡†ï¼Œé¦–æ¬¡åˆ»ç”»äº†é²æ£’æ€§ã€æŸå¤±å’Œå¹³ç­‰æ€§ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚

Conclusion: è¯¥ç®—æ³•æœ‰æ•ˆè§£å†³äº†å…¬æ°‘è®®ä¼šæˆå‘˜é€€å‡ºçš„ä»£è¡¨æ€§é—®é¢˜ï¼Œä¸ºå®è·µä¸­ç®¡ç†é€€å‡ºé£é™©æä¾›äº†ç†è®ºå’Œæ–¹æ³•æ”¯æŒã€‚

Abstract: Citizens' assemblies - small panels of citizens that convene to deliberate on policy issues - often face the issue of panelists dropping out at the last-minute. Without intervention, these dropouts compromise the size and representativeness of the panel, prompting the question: Without seeing the dropouts ahead of time, can we choose panelists such that after dropouts, the panel will be representative and appropriately-sized? We model this problem as a minimax game: the minimizer aims to choose a panel that minimizes the loss, i.e., the deviation of the ultimate panel from predefined representation targets. Then, an adversary defines a distribution over dropouts from which the realized dropouts are drawn. Our main contribution is an efficient loss-minimizing algorithm, which remains optimal as we vary the maximizer's power from worst case to average case. Our algorithm - which iteratively plays a projected gradient descent subroutine against an efficient algorithm for computing the best-response dropout distribution - also addresses a key open question in the area: how to manage dropouts while ensuring that each potential panelist is chosen with relatively equal probabilities. Using real-world datasets, we compare our algorithms to existing benchmarks, and we offer the first characterizations of tradeoffs between robustness, loss, and equality in this problem.

</details>


### [9] [The Effects of Latency on a Progressive Second-Price Auction](https://arxiv.org/abs/2511.17424)
*Jordana Blazek,Eric Olson,Fredrick C. Harris*

Main category: cs.GT

TL;DR: è¯¥è®ºæ–‡ç ”ç©¶äº†æ¸è¿›ç¬¬äºŒä»·æ ¼æ‹å–ä¸­å»¶è¿Ÿã€å¼‚æ­¥åˆ†æå’Œéšæœºåˆå§‹å‡ºä»·å¯¹Îµ-çº³ä»€å‡è¡¡çš„å½±å“ï¼Œæå‡ºäº†æœ€å°æ”¶ç›Šå‡è¡¡çŠ¶æ€ç®—æ³•ï¼Œå¹¶å±•ç¤ºäº†è®¾ç½®ç•¥ä½äºæ¸…ç®—ä»·çš„ä¿ç•™ä»·æ ¼å¯ä»¥ç¨³å®šå–æ–¹æ”¶ç›ŠåŒæ—¶ä¿æŒæ•ˆç‡ã€‚


<details>
  <summary>Details</summary>
Motivation: ç ”ç©¶å»¶è¿Ÿæ¥æ”¶å‡ºä»·ä¿¡æ¯ã€ä¹°å®¶å¼‚æ­¥åˆ†æå¸‚åœºä»¥åŠåˆå§‹å‡ºä»·çš„éšæœºæ€§å¦‚ä½•å½±å“é€šè¿‡çœŸå®Îµ-æœ€ä½³å“åº”æ–¹æ³•è·å¾—çš„Îµ-çº³ä»€å‡è¡¡ï¼Œé‡ç‚¹å…³æ³¨å¼¹æ€§éœ€æ±‚å‡è®¾ä¸‹çš„æ•ˆç”¨é—®é¢˜ã€‚

Method: å¼•å…¥äº†ä¸€ç§å¯»æ‰¾æœ€å°æ”¶ç›Šå‡è¡¡çŠ¶æ€çš„ç®—æ³•ï¼Œå¹¶å±•ç¤ºäº†è®¾ç½®ç•¥ä½äºæ¸…ç®—ä»·çš„ä¿ç•™ä»·æ ¼çš„æ–¹æ³•ã€‚

Result: è®¾ç½®ä¿ç•™ä»·æ ¼å¯ä»¥ç¨³å®šå–æ–¹æ”¶ç›ŠåŒæ—¶ä¿æŒæ•ˆç‡ã€‚è™½ç„¶ä¸€äº›ä¹°å®¶åœ¨ä¸ªä½“åˆ†é…çš„ä»·å€¼å’Œæˆæœ¬æ–¹é¢ç»å†äº†ä¸å¯é¢„æµ‹æ€§ï¼Œä½†å„è‡ªçš„æ•ˆç”¨æ˜¯å¯é¢„æµ‹çš„ã€‚

Conclusion: åœ¨æ¸è¿›ç¬¬äºŒä»·æ ¼æ‹å–ä¸­ï¼Œé€šè¿‡é€‚å½“çš„ä¿ç•™ä»·æ ¼è®¾ç½®ï¼Œå¯ä»¥åœ¨ä¿æŒæ•ˆç‡çš„åŒæ—¶ç¨³å®šå–æ–¹æ”¶ç›Šï¼Œä¸”ä¹°å®¶æ•ˆç”¨å…·æœ‰å¯é¢„æµ‹æ€§ã€‚

Abstract: The progressive second-price auction of Lazar and Semret is a decentralized mechanism for the allocation and real-time pricing of a divisible resource. Our focus is on how delays in the receipt of bid messages, asynchronous analysis by buyers of the market and randomness in the initial bids affect the $\varepsilon$-Nash equilibria obtained by the method of truthful $\varepsilon$-best reply. We introduce an algorithm for finding minimal-revenue equilibrium states and then show that setting a reserve price just below clearing stabilizes seller revenue while maintaining efficiency. Utility is of primary interest given the assumption of elastic demand. Although some buyers experienced unpredictability in the value and cost of their individual allocations, their respective utilities were predictable.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [10] [Functional uniqueness and stability of Gaussian priors in optimal L1 estimation](https://arxiv.org/abs/2511.16864)
*Leighton Barnes,Alex Dytso*

Main category: cs.IT

TL;DR: æœ¬æ–‡ç ”ç©¶äº†é«˜æ–¯å…ˆéªŒåœ¨æœ€ä¼˜L1ä¼°è®¡ä¸­çš„å‡½æ•°å”¯ä¸€æ€§å’Œç¨³å®šæ€§ï¼Œå»ºç«‹äº†å®šé‡ç¨³å®šæ€§ç†è®ºï¼Œè¯æ˜é«˜æ–¯åˆ†å¸ƒæ˜¯å”¯ä¸€ç¨³å®šçš„è§£ã€‚


<details>
  <summary>Details</summary>
Motivation: è™½ç„¶å·²çŸ¥é«˜æ–¯å…ˆéªŒåœ¨é«˜æ–¯å™ªå£°ä¸‹å”¯ä¸€äº§ç”Ÿçº¿æ€§æ¡ä»¶å‡å€¼ï¼Œä½†å¯¹äºæ¡ä»¶ä¸­ä½æ•°ï¼ˆç»å¯¹è¯¯å·®æŸå¤±ä¸‹çš„æœ€ä¼˜ä¼°è®¡å™¨ï¼‰çš„ç±»ä¼¼é—®é¢˜æœ€è¿‘æ‰å¾—åˆ°è§£å†³ã€‚æœ¬æ–‡åŸºäºè¿™ä¸€å”¯ä¸€æ€§ç»“æœï¼Œç ”ç©¶è¿‘ä¼¼çº¿æ€§æœ€ä¼˜ä¼°è®¡å™¨å¦‚ä½•çº¦æŸå…ˆéªŒåˆ†å¸ƒã€‚

Method: å¯¹äºL2æŸå¤±ï¼Œæ¨å¯¼äº†æ¡ä»¶å‡å€¼æ¥è¿‘çº¿æ€§æ—¶å…ˆéªŒåˆ†å¸ƒä¸é«˜æ–¯åˆ†å¸ƒåœ¨LÃ©vyåº¦é‡ä¸‹æ¥è¿‘çš„æ˜¾å¼é€Ÿç‡ã€‚å¯¹äºL1æŸå¤±ï¼Œå¼•å…¥Hermiteå±•å¼€æ¡†æ¶å¹¶åˆ†æçº¿æ€§å®šä¹‰ç®—å­çš„ä¼´éšç®—å­ã€‚

Result: è¯æ˜äº†é«˜æ–¯åˆ†å¸ƒåœ¨L1æŸå¤±ä¸‹ä»ç„¶æ˜¯å”¯ä¸€ç¨³å®šçš„è§£ï¼Œå»ºç«‹äº†æ›´å®Œæ•´çš„å‡½æ•°åˆ†æç†è§£ã€‚

Conclusion: è¿™äº›ç»“æœä¸ºé«˜æ–¯å™ªå£°ä¸‹è´å¶æ–¯ä¼°è®¡ä¸­çš„çº¿æ€§å’Œç¨³å®šæ€§æä¾›äº†æ›´å…¨é¢çš„å‡½æ•°åˆ†æç†è§£ï¼Œè¡¨æ˜é«˜æ–¯å…ˆéªŒåœ¨æœ€ä¼˜ä¼°è®¡ä¸­å…·æœ‰ç‹¬ç‰¹çš„ç¨³å®šæ€§ç‰¹å¾ã€‚

Abstract: This paper studies the functional uniqueness and stability of Gaussian priors in optimal $L^1$ estimation. While it is well known that the Gaussian prior uniquely induces linear conditional means under Gaussian noise, the analogous question for the conditional median (i.e., the optimal estimator under absolute-error loss) has only recently been settled. Building on the prior work establishing this uniqueness, we develop a quantitative stability theory that characterizes how approximate linearity of the optimal estimator constrains the prior distribution. For $L^2$ loss, we derive explicit rates showing that near-linearity of the conditional mean implies proximity of the prior to the Gaussian in the LÃ©vy metric. For $L^1$ loss, we introduce a Hermite expansion framework and analyze the adjoint of the linearity-defining operator to show that the Gaussian remains the unique stable solution. Together, these results provide a more complete functional-analytic understanding of linearity and stability in Bayesian estimation under Gaussian noise.

</details>


### [11] [The Star Product of Uniformly Random Codes](https://arxiv.org/abs/2511.17236)
*Johan V. Dinesen,Ragnar Freij-Hollanti,Camilla Hollanti,Benjamin Jany,Alberto Ravagnani*

Main category: cs.IT

TL;DR: æœ¬æ–‡ç ”ç©¶äº†ä¸¤ä¸ªéšæœºçº¿æ€§ç çš„æ˜Ÿç§¯çš„æœŸæœ›ç»´åº¦é—®é¢˜ï¼Œé€šè¿‡å»ºç«‹æ˜Ÿç§¯ä¸åŒçº¿æ€§å½¢å¼è¯„ä¼°çš„å¯¹åº”å…³ç³»ï¼Œç»™å‡ºäº†æ˜Ÿç§¯ç»´åº¦çš„ä¸‹ç•Œï¼Œå¹¶è¯æ˜åœ¨åŸŸå¤§å°å’Œç ç»´åº¦çš„æ¸è¿‘æ„ä¹‰ä¸‹ï¼ŒæœŸæœ›ç»´åº¦è¾¾åˆ°æœ€å¤§å€¼ã€‚


<details>
  <summary>Details</summary>
Motivation: ç ”ç©¶éšæœºçº¿æ€§ç æ˜Ÿç§¯çš„æœŸæœ›ç»´åº¦ï¼Œè¿™å¯¹äºç†è§£ç çš„ç»„åˆæ€§è´¨åŠå…¶åœ¨ä¿¡æ¯è®ºå’Œå¯†ç å­¦ä¸­çš„åº”ç”¨å…·æœ‰é‡è¦æ„ä¹‰ã€‚

Method: é€šè¿‡å»ºç«‹æ˜Ÿç§¯ä¸åŒçº¿æ€§å½¢å¼è¯„ä¼°çš„å¯¹åº”å…³ç³»ï¼Œæä¾›æ˜Ÿç§¯ç»´åº¦çš„ä¸‹ç•Œåˆ†æã€‚

Result: åœ¨åŸŸå¤§å°qå’Œä¸¤ä¸ªç ç»´åº¦çš„æ¸è¿‘æ„ä¹‰ä¸‹ï¼Œæ˜Ÿç§¯çš„æœŸæœ›ç»´åº¦è¾¾åˆ°æœ€å¤§å€¼ã€‚

Conclusion: è¯¥ç»“æœåœ¨ç§æœ‰ä¿¡æ¯æ£€ç´¢ã€å®‰å…¨åˆ†å¸ƒå¼çŸ©é˜µä¹˜æ³•ã€é‡å­çº é”™ç ç­‰é¢†åŸŸæœ‰åº”ç”¨ä»·å€¼ï¼Œå¹¶å¯èƒ½ç”¨äºå¯†ç åˆ†æã€‚

Abstract: We consider the problem of determining the expected dimension of the star product of two uniformly random linear codes that are not necessarily of the same dimension. We achieve this by establishing a correspondence between the star product and the evaluation of bilinear forms, which we use to provide a lower bound on the expected star product dimension. We show that asymptotically in both the field size q and the dimensions of the two codes, the expected dimension reaches its maximum. Lastly, we discuss some implications related to private information retrieval, secure distributed matrix multiplication, quantum error correction, and the potential for exploiting the results in cryptanalysis.

</details>


### [12] [Structured Approximation of Toeplitz Matrices and Subspaces](https://arxiv.org/abs/2511.17239)
*Albert Fannjiang,Weilin Li*

Main category: cs.IT

TL;DR: æœ¬æ–‡ç ”ç©¶äº†ä¸¤ä¸ªç»“æ„åŒ–é€¼è¿‘é—®é¢˜ï¼šæ¢å¤æŸåçš„ä½ç§©ToeplitzçŸ©é˜µå’Œä»å•æ¬¡è§‚æµ‹ä¸­æ¢å¤å‚…é‡Œå¶çŸ©é˜µçš„èŒƒå›´ã€‚é€šè¿‡åº”ç”¨Gradient-MUSICè°±ä¼°è®¡ç®—æ³•ï¼Œå¯ä»¥é«˜æ•ˆä¸”æœ€ä¼˜åœ°è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ã€‚


<details>
  <summary>Details</summary>
Motivation: ToeplitzçŸ©é˜µæ¢å¤å’Œå‚…é‡Œå¶çŸ©é˜µèŒƒå›´æ¢å¤éƒ½æ˜¯è®¡ç®—ä¸Šå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œå› ä¸ºç»“æ„çº¦æŸéš¾ä»¥ç›´æ¥å®æ–½ã€‚éœ€è¦æ‰¾åˆ°æ—¢èƒ½ä¿æŒç»“æ„åˆèƒ½é«˜æ•ˆæ±‚è§£çš„æ–¹æ³•ã€‚

Method: ä½¿ç”¨Gradient-MUSICè°±ä¼°è®¡ç®—æ³•æ¥å¤„ç†è¿™ä¸¤ä¸ªç»“æ„åŒ–é€¼è¿‘é—®é¢˜ã€‚å¯¹äºç§©ä¸ºrçš„ToeplitzçŸ©é˜µï¼Œåœ¨æ»¡è¶³æ­£åˆ™æ€§å‡è®¾ä¸”è¢«ä»»æ„çŸ©é˜µEæŸåçš„æƒ…å†µä¸‹ï¼Œç®—æ³•è¾“å‡ºç§©æ°å¥½ä¸ºrçš„ToeplitzçŸ©é˜µä¼°è®¡ã€‚

Result: å¯¹äºç§©rçš„ToeplitzçŸ©é˜µTï¼Œå½“â€–Eâ€–â‚‚â‰¤Î±næ—¶ï¼Œç®—æ³•è¾“å‡ºç§©æ°å¥½ä¸ºrçš„ToeplitzçŸ©é˜µÅ¤ï¼Œæ»¡è¶³â€–T-Å¤â€–â‚‚ â‰¤ Câˆšrâ€–Eâ€–â‚‚ï¼Œå…¶ä¸­C,Î±>0æ˜¯ç»å¯¹å¸¸æ•°ã€‚è¯¥æ€§èƒ½ä¿è¯åœ¨nå’Œâ€–Eâ€–â‚‚æ–¹é¢æ˜¯æœ€å°æœ€å¤§æœ€ä¼˜çš„ã€‚

Conclusion: Gradient-MUSICç®—æ³•èƒ½å¤Ÿé«˜æ•ˆä¸”æœ€ä¼˜åœ°è§£å†³ToeplitzçŸ©é˜µæ¢å¤å’Œå‚…é‡Œå¶çŸ©é˜µèŒƒå›´æ¢å¤é—®é¢˜ï¼Œå»ºç«‹äº†è¿™ä¸¤ä¸ªé—®é¢˜ä¸è°±ä¼°è®¡ä¹‹é—´çš„å®šé‡è”ç³»ã€‚ç»“æœåŒæ ·é€‚ç”¨äºHankelçŸ©é˜µã€‚

Abstract: This paper studies two structured approximation problems: (1) Recovering a corrupted low-rank Toeplitz matrix and (2) recovering the range of a Fourier matrix from a single observation. Both problems are computationally challenging because the structural constraints are difficult to enforce directly. We show that both tasks can be solved efficiently and optimally by applying the Gradient-MUSIC algorithm for spectral estimation. For a rank $r$ Toeplitz matrix ${\boldsymbol T}\in {\mathbb C}^{n\times n}$ that satisfies a regularity assumption and is corrupted by an arbitrary ${\boldsymbol E}\in {\mathbb C}^{n\times n}$ such that $\|{\boldsymbol E}\|_2\leq Î±n$, our algorithm outputs a Toeplitz matrix $\widehat{\boldsymbol T}$ of rank exactly $r$ such that $\|{\boldsymbol T}-\widehat{\boldsymbol T}\|_2 \leq C \sqrt r \, \|{\boldsymbol E}\|_2$, where $C,Î±>0$ are absolute constants. This performance guarantee is minimax optimal in $n$ and $\|{\boldsymbol E}\|_2$. We derive optimal results for the second problem as well. Our analysis provides quantitative connections between these two problems and spectral estimation. Our results are equally applicable to Hankel matrices with superficial modifications.

</details>


### [13] [Fast Decoding for Non-Adaptive Learning of ErdÅ‘s--RÃ©nyi Random Graphs](https://arxiv.org/abs/2511.17240)
*Hoang Ta,Jonathan Scarlett*

Main category: cs.IT

TL;DR: æå‡ºäº†ä¸€ç§éè‡ªé€‚åº”ç¾¤æŸ¥è¯¢ä¸­å­¦ä¹ ErdÅ‘s-RÃ©nyiå›¾çš„é«˜æ•ˆæ–¹æ³•ï¼Œåœ¨ä¿æŒæœ€ä¼˜æµ‹è¯•æ¬¡æ•°O(ğ‘˜Ì„ log n)çš„åŒæ—¶ï¼Œå°†è§£ç æ—¶é—´ä»Î©(nÂ²)æ˜¾è‘—é™ä½åˆ°O(ğ‘˜Ì„^{1+Î´} log n)ã€‚


<details>
  <summary>Details</summary>
Motivation: ç°æœ‰æ–¹æ³•åœ¨å­¦ä¹ ERå›¾æ—¶é¢ä¸´è§£ç æ—¶é—´è¿‡é«˜çš„é—®é¢˜ï¼Œè¦ä¹ˆéœ€è¦Î©(nÂ²)è§£ç æ—¶é—´ï¼Œè¦ä¹ˆéœ€è¦é¢å¤–çš„æµ‹è¯•æ¬¡æ•°å› å­ã€‚éœ€è¦è®¾è®¡æ—¢èƒ½ä¿æŒæœ€ä¼˜æµ‹è¯•æ¬¡æ•°åˆèƒ½å®ç°äºšçº¿æ€§è§£ç æ—¶é—´çš„æ–¹æ¡ˆã€‚

Method: å°†éè‡ªé€‚åº”ç¾¤æµ‹è¯•ä¸­çš„äºŒåˆ†æœç´¢æ–¹æ³•æ‰©å±•åˆ°ERå›¾å­¦ä¹ åœºæ™¯ï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æµ‹è¯•-è§£ç æ–¹æ¡ˆæ¥é«˜æ•ˆè¯†åˆ«å›¾ä¸­çš„è¾¹ã€‚

Result: æå‡ºçš„æ–¹æ³•èƒ½ä»¥é«˜æ¦‚ç‡æ¢å¤è¾¹é›†ï¼Œä½¿ç”¨O(ğ‘˜Ì„ log n)æ¬¡æµ‹è¯•ï¼Œè§£ç æ—¶é—´ä¸ºO(ğ‘˜Ì„^{1+Î´} log n)ï¼Œå…¶ä¸­Î´>0ä¸ºä»»æ„å›ºå®šå¸¸æ•°ã€‚

Conclusion: è¯¥æ–¹æ³•åœ¨ä¿æŒæœ€ä¼˜æµ‹è¯•å¤æ‚åº¦çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼Œä¸ºå¤§è§„æ¨¡å›¾å­¦ä¹ æä¾›äº†å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚

Abstract: We study the problem of learning an unknown graph via group queries on node subsets, where each query reports whether at least one edge is present among the queried nodes. In general, learning arbitrary graphs with \(n\) nodes and \(k\) edges is hard in the non-adaptive setting, requiring \(Î©\big(\min\{k^2\log n,\,n^2\}\big)\) tests even when a small error probability is allowed. We focus on learning ErdÅ‘s--RÃ©nyi (ER) graphs \(G\sim\ER(n,q)\) in the non-adaptive setting, where the expected number of edges is \(\bar{k}=q\binom{n}{2}\), and we aim to design an efficient testing--decoding scheme achieving asymptotically vanishing error probability. Prior work (Li--Fresacher--Scarlett, NeurIPS 2019) presents a testing--decoding scheme that attains an order-optimal number of tests \(O(\bar{k}\log n)\) but incurs \(Î©(n^2)\) decoding time, whereas their proposed sublinear-time algorithm incurs an extra \((\log \bar{k})(\log n)\) factor in the number of tests. We extend the binary splitting approach, recently developed for non-adaptive group testing, to the ER graph learning setting, and prove that the edge set can be recovered with high probability using \(O(\bar{k}\log n)\) tests while attaining decoding time \(O(\bar{k}^{1+Î´}\log n)\) for any fixed \(Î´>0\).

</details>


### [14] [Fluid Antenna System-Enabled UAV-to-Ground Communications](https://arxiv.org/abs/2511.17416)
*Xusheng Zhu,Kai-Kit Wong,Qingqing Wu,Hyundong Shin,Yangyang Zhang*

Main category: cs.IT

TL;DR: æœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨åŒé˜´å½±è¡°è½ä¿¡é“ä¸‹ï¼Œé…å¤‡æµä½“å¤©çº¿ç³»ç»Ÿçš„æ— äººæœºåˆ°åœ°é¢é“¾è·¯çš„æ€§èƒ½åˆ†ææ¡†æ¶ï¼Œæ¨å¯¼äº†ç«¯åˆ°ç«¯ä¿¡å™ªæ¯”ç»Ÿè®¡ç‰¹æ€§ï¼Œå¹¶æ­ç¤ºäº†ç³»ç»Ÿå¯è·å¾—MÃ—dçš„ä¹˜æ€§åˆ†é›†é˜¶æ•°ã€‚


<details>
  <summary>Details</summary>
Motivation: æµä½“å¤©çº¿ç³»ç»Ÿ(FAS)åœ¨ç´§å‡‘å°ºå¯¸å†…æä¾›å¢å¼ºçš„ç©ºé—´åˆ†é›†ï¼Œè€Œæ— äººæœº(UAV)åœ¨æœªæ¥ç½‘ç»œä¸­è‡³å…³é‡è¦ï¼Œéœ€è¦åŒæ—¶è€ƒè™‘å¤šå¾„è¡°è½å’Œé˜´å½±æ•ˆåº”çš„ä¿¡é“æ¨¡å‹ã€‚

Method: é‡‡ç”¨åŸºäºç‰¹å¾å€¼çš„ç›¸å…³FASç«¯å£è¿‘ä¼¼æ–¹æ³•ï¼Œæ¨å¯¼äº†ç«¯åˆ°ç«¯ä¿¡å™ªæ¯”çš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°å’Œæ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œå¹¶åŸºäºæ­¤ç»™å‡ºäº†ä¸­æ–­æ¦‚ç‡ã€å¹³å‡è¯¯ç ç‡å’Œå¹³å‡ä¿¡é“å®¹é‡çš„ç²¾ç¡®ç§¯åˆ†è¡¨è¾¾å¼ã€‚

Result: å¯¹äºå®é™…çš„åŒç§©ç‹¬ç«‹ä½†éåŒåˆ†å¸ƒæƒ…å†µï¼Œæ¨å¯¼äº†å¹³å‡è¯¯ç ç‡å’Œå®¹é‡çš„é—­å¼è§£ã€‚æ¸è¿‘åˆ†æè¡¨æ˜ç³»ç»Ÿå¯è·å¾—MÃ—dçš„ä¹˜æ€§åˆ†é›†é˜¶æ•°ï¼Œå…¶ä¸­Mä¸ºFASç©ºé—´ç§©ï¼Œdä¸ºå›ºæœ‰ä¿¡é“åˆ†é›†é˜¶æ•°ã€‚

Conclusion: ç†è®ºæ¡†æ¶å…·æœ‰é«˜ç²¾åº¦ï¼Œä»¿çœŸç»“æœéªŒè¯äº†åˆ†æçš„æ­£ç¡®æ€§ï¼ŒFASä¸UAVç»“åˆå¯åœ¨åŒé˜´å½±è¡°è½ä¿¡é“ä¸‹å®ç°æ˜¾è‘—æ€§èƒ½æå‡ã€‚

Abstract: Fluid antenna systems (FAS) have emerged as a revolutionary technology offering enhanced spatial diversity within a compact form factor. Concurrently, unmanned aerial vehicles (UAVs) are integral to future networks, necessitating channel models that capture both multipath fading and shadowing. This letter presents a novel performance analysis of a UAV-to-ground link, where the receiver is equipped with an $N$-port FAS operating over the challenging double-shadowing fading channel. By adapting a tractable eigenvalue-based approximation for the correlated FAS ports, we derive new analytical expressions for the end-to-end signal-to-noise ratio statistics, namely the cumulative distribution function and the probability density function. Based on these statistics, we present exact integral expressions for the outage probability, average bit error rate, and average channel capacity. We further derive new, tractable closed-form solutions for the average bit error rate and capacity for the practical dual-rank, independent but non-identically distributed case. Finally, a key asymptotic analysis reveals that the system achieves a multiplicative diversity order of $G_d = M \times d$, which is precisely the product of the FAS spatial rank $M$ and the intrinsic channel diversity order $d$. Simulation results are provided to validate the high accuracy of our entire theoretical framework.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [15] [Efficient Algorithms and Implementations for Extracting Maximum-Size $(k,\ell)$-Sparse Subgraphs](https://arxiv.org/abs/2511.16877)
*PÃ©ter Madarasi*

Main category: cs.DS

TL;DR: æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªé«˜æ•ˆçš„å¢å¼ºè·¯å¾„æ–¹æ³•å®ç°ï¼Œç”¨äºå¯»æ‰¾æœ€å¤§è§„æ¨¡çš„(k,â„“)-ç¨€ç–å­å›¾ï¼Œé€šè¿‡å¤šç§å¯å‘å¼ç­–ç•¥æ˜¾è‘—æå‡æ€§èƒ½ï¼Œå¹¶åœ¨3Dåˆšæ€§ç†è®ºä¸­æå‡ºäº†æ›´å¿«çš„ç®—æ³•ã€‚


<details>
  <summary>Details</summary>
Motivation: åœ¨åˆšæ€§ç†è®ºå’Œç»„åˆä¼˜åŒ–ä¸­ï¼Œå¯»æ‰¾æœ€å¤§è§„æ¨¡çš„(k,â„“)-ç¨€ç–å­å›¾æ˜¯ä¸€ä¸ªç»å…¸é—®é¢˜ï¼Œç°æœ‰ç®—æ³•è™½ç„¶æœ‰å¤šé¡¹å¼æ—¶é—´å¤æ‚åº¦ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­æ•ˆç‡ä»æœ‰æå‡ç©ºé—´ã€‚

Method: é‡‡ç”¨å¢å¼ºè·¯å¾„æ–¹æ³•ï¼Œç»“åˆè¾¹æ’åºã€èŠ‚ç‚¹æ’åºã€ä¸¤é˜¶æ®µç­–ç•¥å’ŒåŸºäºä¼ªæ£®æ—çš„åˆå§‹åŒ–ç­‰å¯å‘å¼ç­–ç•¥ï¼Œå‡å°‘è¿è¡Œæ—¶é—´åŒæ—¶ä¿è¯æœ€ä¼˜æ€§ã€‚

Result: åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œå›¾ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼Œè¯¥å®ç°æ¯”ç°æœ‰å·¥å…·å¿«å‡ ä¸ªæ•°é‡çº§ï¼Œå¹¶æä¾›äº†å…¬å¼€å¯ç”¨çš„å·¥ç¨‹åŒ–å®ç°ã€‚

Conclusion: æå‡ºçš„æ–¹æ³•åœ¨æ•ˆç‡å’Œçµæ´»æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨3Dåˆšæ€§ç†è®ºä¸­æå‡ºçš„æ–°ç®—æ³•å…·æœ‰æ¸è¿›æ›´å¿«çš„æ€§èƒ½ã€‚

Abstract: A multigraph $G = (V, E)$ is $(k, \ell)$-sparse if every subset $X \subseteq V$ induces at most $\max\{k|X| - \ell, 0\}$ edges. Finding a maximum-size $(k, \ell)$-sparse subgraph is a classical problem in rigidity theory and combinatorial optimization, with known polynomial-time algorithms. This paper presents a highly efficient and flexible implementation of an augmenting path method, enhanced with a range of powerful practical heuristics that significantly reduce running time while preserving optimality. These heuristics $\unicode{x2013}$ including edge-ordering, node-ordering, two-phase strategies, and pseudoforest-based initialization $\unicode{x2013}$ steer the algorithm toward accepting more edges early in the execution and avoiding costly augmentations. A comprehensive experimental evaluation on both synthetic and real-world graphs demonstrates that our implementation outperforms existing tools by several orders of magnitude. We also propose an asymptotically faster algorithm for extracting an inclusion-wise maximal $(k,2k)$-sparse subgraph with the sparsity condition required only for node sets of size at least three, which is particularly relevant to 3D rigidity when $k = 3$. We provide a carefully engineered implementation, which is publicly available online and is proposed for inclusion in the LEMON graph library.

</details>


### [16] [Low-Sensitivity Matching via Sampling from Gibbs Distributions](https://arxiv.org/abs/2511.16918)
*Yuichi Yoshida,Zihan Zhang*

Main category: cs.DS

TL;DR: æœ¬æ–‡ç ”ç©¶äº†æœ€å¤§åŒ¹é…é—®é¢˜çš„æ•æ„Ÿæ€§åˆ†æï¼Œæå‡ºäº†é’ˆå¯¹ä¸åŒå›¾ç±»çš„å¤šé¡¹å¼æ—¶é—´(1-Îµ)è¿‘ä¼¼ç®—æ³•ï¼Œæ˜¾è‘—æ”¹è¿›äº†æ•æ„Ÿæ€§è¾¹ç•Œå’Œè¿è¡Œæ—¶é—´ã€‚


<details>
  <summary>Details</summary>
Motivation: ç ”ç©¶æœ€å¤§åŒ¹é…ç®—æ³•çš„æ•æ„Ÿæ€§ï¼Œå³å½“å›¾ä¸­åˆ é™¤ä¸€æ¡è¾¹æ—¶ï¼Œç®—æ³•è¾“å‡ºåˆ†å¸ƒçš„å˜åŒ–ç¨‹åº¦ï¼Œè¿™å¯¹äºç®—æ³•çš„é²æ£’æ€§å’Œéšç§ä¿æŠ¤å…·æœ‰é‡è¦æ„ä¹‰ã€‚

Method: åŸºäºå‰å¸ƒæ–¯åˆ†å¸ƒé‡‡æ ·åŒ¹é…ï¼Œé’ˆå¯¹ä¸åŒå›¾ç±»ï¼ˆä¸€èˆ¬å›¾ã€å¹³é¢å›¾ã€äºŒåˆ†å›¾ï¼‰è®¾è®¡äº†é«˜æ•ˆçš„é‡‡æ ·ç®—æ³•ï¼Œå¹¶åˆ©ç”¨Wassersteinè·ç¦»åº¦é‡æ•æ„Ÿæ€§ã€‚

Result: å¯¹äºæœ€å¤§åº¦ä¸ºÎ”çš„å›¾ï¼Œå¾—åˆ°æ•æ„Ÿæ€§ä¸ºÎ”^O(1/Îµ)çš„ç®—æ³•ï¼›å¯¹äºå¹³é¢å›¾å’ŒäºŒåˆ†å›¾ï¼Œè¿è¡Œæ—¶é—´æ”¹è¿›ä¸ºpoly(n/Îµ)ï¼›å¯¹äºæ— ç•Œåº¦å›¾ï¼Œæ•æ„Ÿæ€§æ”¹è¿›ä¸ºâˆšnÂ·(Îµ^-1 log n)^O(1/Îµ)ã€‚

Conclusion: æœ¬æ–‡æ˜¾è‘—æ”¹è¿›äº†æœ€å¤§åŒ¹é…è¿‘ä¼¼ç®—æ³•çš„æ•æ„Ÿæ€§è¾¹ç•Œï¼Œä¸ºä¸åŒå›¾ç±»æä¾›äº†é«˜æ•ˆä¸”æ•æ„Ÿçš„ç®—æ³•è®¾è®¡æ¡†æ¶ã€‚

Abstract: In this work, we study the maximum matching problem from the perspective of sensitivity. The sensitivity of an algorithm $A$ on a graph $G$ is defined as the maximum Wasserstein distance between the output distributions of $A$ on $G$ and on $G - e$, where $G - e$ is the graph obtained by deleting an edge $e$ from $G$. The maximum is taken over all edges $e$, and the underlying metric for the Wasserstein distance is the Hamming distance.
  We first show that for any $\varepsilon > 0$, there exists a polynomial-time $(1 - \varepsilon)$-approximation algorithm with sensitivity $Î”^{O(1/\varepsilon)}$, where $Î”$ is the maximum degree of the input graph. The algorithm is based on sampling from the Gibbs distribution over matchings and runs in time $O_{\varepsilon, Î”}(m \log m)$, where $m$ is the number of edges in the graph. This result significantly improves the previously known sensitivity bounds.
  Next, we present significantly faster algorithms for planar and bipartite graphs as a function of $\varepsilon$ and $Î”$, which run in time $\mathrm{poly}(n/\varepsilon)$. This improvement is achieved by designing a more efficient algorithm for sampling matchings from the Gibbs distribution in these graph classes, which improves upon the previous best in terms of running time.
  Finally, for general graphs with potentially unbounded maximum degree, we show that there exists a polynomial-time $(1 - \varepsilon)$-approximation algorithm with sensitivity $\sqrt{n} \cdot (\varepsilon^{-1} \log n)^{O(1/\varepsilon)}$, improving upon the previous best bound of $O(n^{1/(1+\varepsilon^2)})$.

</details>


### [17] [Merging RLBWTs adaptively](https://arxiv.org/abs/2511.16953)
*Travis Gagie*

Main category: cs.DS

TL;DR: æå‡ºäº†ä¸€ç§å¿«é€Ÿåˆå¹¶è¿è¡Œé•¿åº¦å‹ç¼©çš„Burrows-Wheelerå˜æ¢(RLBWTs)çš„æ–¹æ³•ï¼Œæ—¶é—´å¤æ‚åº¦ä¸º$	ilde{O}(L + Ïƒ + R)$ï¼Œç©ºé—´å¤æ‚åº¦ä¸º$O(R)$ï¼Œå…¶ä¸­$R$æ˜¯æ€»è¿è¡Œæ•°ï¼Œ$L$æ˜¯è¾¹ç•Œå¤„æœ€é•¿å…¬å…±å‰ç¼€å€¼çš„æ€»å’Œï¼Œ$Ïƒ$æ˜¯å­—æ¯è¡¨å¤§å°ã€‚


<details>
  <summary>Details</summary>
Motivation: å½“åŸå§‹å­—ç¬¦ä¸²é›†å…·æœ‰é‡å¤æ€§ä½†å½¼æ­¤ä¸åŒæ—¶ï¼Œéœ€è¦é«˜æ•ˆåœ°åˆå¹¶å…¶RLBWTè¡¨ç¤ºï¼Œä»¥æ”¯æŒå¤§è§„æ¨¡å­—ç¬¦ä¸²é›†åˆçš„å¤„ç†å’Œåˆ†æã€‚

Method: åŸºäºåˆå¹¶çš„æ‰©å±•Burrows-Wheelerå˜æ¢(eBWT)ä¸­è¾¹ç•Œå¤„çš„å­—ç¬¦å—ï¼Œåˆ©ç”¨æœ€é•¿å…¬å…±å‰ç¼€(LCP)å€¼æ¥æŒ‡å¯¼åˆå¹¶è¿‡ç¨‹ï¼Œé‡ç‚¹å…³æ³¨è¾¹ç•Œå¤„çš„Lå€¼æ€»å’Œã€‚

Result: å®ç°äº†åœ¨$	ilde{O}(L + Ïƒ + R)$æ—¶é—´å†…åˆå¹¶RLBWTsï¼Œå…¶ä¸­$L$åœ¨é‡å¤ä½†ä¸åŒçš„å­—ç¬¦ä¸²é›†ä¸Šå¾€å¾€è¾ƒå°ï¼Œä»è€Œä¿è¯äº†é«˜æ•ˆæ€§ã€‚

Conclusion: è¯¥æ–¹æ³•ä¸ºå¤„ç†å¤§è§„æ¨¡é‡å¤å­—ç¬¦ä¸²é›†åˆæä¾›äº†é«˜æ•ˆçš„RLBWTåˆå¹¶æ–¹æ¡ˆï¼Œç‰¹åˆ«é€‚ç”¨äºåŸºå› ç»„å­¦ç­‰é¢†åŸŸçš„å­—ç¬¦ä¸²é›†åˆåˆ†æã€‚

Abstract: We show how to merge run-length compressed Burrows-Wheeler Transforms (RLBWTs) quickly and in $O (R)$ space, where $R$ is the total number of runs in them, when a certain parameter is small. Specifically, we consider the boundaries in their combined extended Burrows-Wheeler Transform (eBWT) between blocks of characters from the same original RLBWT, and denote by $L$ the sum of the longest common prefix (LCP) values at those boundaries. We show how to merge the RLBWTs in $\tilde{O} (L + Ïƒ+ R)$ time, where $Ïƒ$ is the alphabet size. We conjecture that $L$ tends to be small when the strings (or sets of strings) underlying the original RLBWTs are repetitive but dissimilar.

</details>


### [18] [Triangle Detection in H-Free Graphs](https://arxiv.org/abs/2511.17224)
*Amir Abboud,Ron Safier,Nathan Wallheimer*

Main category: cs.DS

TL;DR: æœ¬æ–‡ç ”ç©¶äº†åœ¨ç¦æ­¢ç‰¹å®šå­å›¾Hçš„å›¾ä¸­æ£€æµ‹ä¸‰è§’å½¢çš„ç»„åˆç®—æ³•ï¼Œæ—¨åœ¨åˆ†ç±»å“ªäº›æ¨¡å¼å…è®¸äºšç«‹æ–¹åŠ é€Ÿï¼Œå¹¶å»ºç«‹äºŒåˆ†å®šç†ã€‚


<details>
  <summary>Details</summary>
Motivation: ç ”ç©¶ç›®æ ‡æ˜¯åœ¨ä¸ä½¿ç”¨å¿«é€ŸçŸ©é˜µä¹˜æ³•çš„æƒ…å†µä¸‹ï¼Œä»…é€šè¿‡ç»„åˆæ–¹æ³•åœ¨ç¦æ­¢ç‰¹å®šå­å›¾Hçš„å›¾ä¸­æ£€æµ‹ä¸‰è§’å½¢ï¼Œæ¢ç´¢å“ªäº›æ¨¡å¼èƒ½å®ç°äºšç«‹æ–¹åŠ é€Ÿã€‚

Method: é‡‡ç”¨åµŒå…¥æ–¹æ³•å¼€å‘ç»„åˆç®—æ³•ï¼Œå¯¹äºå¯åµŒå…¥æ¨¡å¼å¤§å°ä¸ºkçš„æƒ…å†µï¼Œç®—æ³•è¿è¡Œæ—¶é—´ä¸ºÃ•(n^{3-1/2^{k-3}})ã€‚è¿˜æä¾›äº†å¯¹å¥‡æ•°ç¯çš„ç‰¹æ®Šå¤„ç†ç®—æ³•ã€‚

Result: å¯¹äºä¸å¯3ç€è‰²æˆ–åŒ…å«å¤šä¸ªä¸‰è§’å½¢çš„æ¨¡å¼ï¼Œé—®é¢˜å¤æ‚åº¦ä¸å˜ï¼›å¯¹äºå¯åµŒå…¥æ¨¡å¼ï¼Œå®ç°äº†å¼ºäºšç«‹æ–¹ç®—æ³•ï¼›å¯¹å¥‡æ•°ç¯æä¾›äº†æ›´é«˜æ•ˆçš„ä¸“é—¨ç®—æ³•ã€‚

Conclusion: å»ºç«‹äº†ä¸‰è§’å½¢æ£€æµ‹åœ¨H-freeå›¾ä¸­çš„ç»„åˆç®—æ³•åˆ†ç±»æ¡†æ¶ï¼Œä¸ºå°æ¨¡å¼æä¾›äº†å®Œæ•´çš„äºŒåˆ†å®šç†ï¼Œå¹¶ä¸ºå¥‡æ•°ç¯æä¾›äº†é«˜æ•ˆç®—æ³•ã€‚

Abstract: We initiate the study of combinatorial algorithms for Triangle Detection in $H$-free graphs. The goal is to decide if a graph that forbids a fixed pattern $H$ as a subgraph contains a triangle, using only "combinatorial" methods that notably exclude fast matrix multiplication. Our work aims to classify which patterns admit a subcubic speedup, working towards a dichotomy theorem. On the lower bound side, we show that if $H$ is not $3$-colorable or contains more than one triangle, the complexity of the problem remains unchanged, and no combinatorial speedup is likely possible. On the upper bound side, we develop an embedding approach that results in a strongly subcubic, combinatorial algorithm for a rich class of "embeddable" patterns. Specifically, for an embeddable pattern of size $k$, our algorithm runs in $\tilde O(n^{3-\frac{1}{2^{k-3}}})$ time, where $\tilde O(\cdot)$ hides poly-logarithmic factors. This algorithm also extends to listing all the triangles within the same time bound. We supplement this main result with two generalizations: 1) A generalization to patterns that are embeddable up to a single obstacle that arises from a triangle in the pattern. This completes our classification for small patterns, yielding a dichotomy theorem for all patterns of size up to eight. 2) An $H$-sensitive algorithm for embeddable patterns, which runs faster when the number of copies of $H$ is significantly smaller than the maximum possible $Î©(n^k)$. Finally, we focus on the special case of odd cycles. We present specialized Triangle Detection algorithms that are very efficient: 1) A combinatorial algorithm for $C_{2k+1}$-free graphs that runs in $\tilde O(m+n^{1+2/k})$ time for every $k\geq2$, where $m$ is the number of edges in the graph. 2) A combinatorial $C_5$-sensitive algorithm that runs in $\tilde O(n^2+n^{4/3}t^{1/3})$ time, where $t$ is the number of $5$-cycles in the graph.

</details>


### [19] [Spectral Clustering with Side Information](https://arxiv.org/abs/2511.17326)
*Hendrik Fichtenberger,Michael Kapralov,Ekaterina Kochetkova,Silvio Lattanzi,Davide Mazzali,Weronika Wrzos-Kaminska*

Main category: cs.DS

TL;DR: æœ¬æ–‡ç ”ç©¶å¸¦æ ‡ç­¾ä¿¡æ¯çš„å›¾èšç±»é—®é¢˜ï¼Œæå‡ºç»“åˆå›¾ç»“æ„å’Œé¡¶ç‚¹æ ‡ç­¾çš„ç®—æ³•ï¼Œåœ¨äºšçº¿æ€§æ—¶é—´å†…å®ç°è¿‘ä¼¼æœ€ä¼˜çš„è¯¯åˆ†ç±»ç‡ï¼Œå¹¶ç»™å‡ºå¤šé¡¹å¼æ—¶é—´ç®—æ³•ä¼˜åŒ–ç¤¾åŒºç»“æ„ã€‚


<details>
  <summary>Details</summary>
Motivation: ä¼ ç»Ÿå›¾èšç±»å‡è®¾ç¤¾åŒºå†…éƒ¨è¿é€šæ€§å¥½ä¸”ç¤¾åŒºé—´è¾¹ç¨€ç–ï¼Œä½†å®è·µä¸­é¡¶ç‚¹é€šå¸¸å¸¦æœ‰å¯èƒ½è¢«å™ªå£°ç ´åçš„æ ‡ç­¾ä¿¡æ¯ã€‚å¦‚ä½•ç»“åˆå›¾ç»“æ„å’Œæ ‡ç­¾ä¿¡æ¯æ¥æ˜¾è‘—é™ä½è¯¯åˆ†ç±»ç‡æ˜¯ä¸€ä¸ªé‡è¦é—®é¢˜ã€‚

Method: æå‡ºäºšçº¿æ€§æ—¶é—´ç®—æ³•ï¼Œåˆ©ç”¨"è°±æ¨¡ç³Š"é¡¶ç‚¹çš„æ–°è§‚å¯Ÿæ¥ç»“åˆå›¾ç»“æ„å’Œæ ‡ç­¾ä¿¡æ¯ï¼›åŒæ—¶ç»™å‡ºå¤šé¡¹å¼æ—¶é—´ç®—æ³•ï¼Œé€šè¿‡é‡æ–°åŠ æƒè¾¹æ¥ä¼˜åŒ–ç¤¾åŒºç»“æ„ã€‚

Result: äºšçº¿æ€§æ—¶é—´ç®—æ³•å®ç°è¿‘ä¼¼æœ€ä¼˜çš„O(ÎµÎ´)è¯¯åˆ†ç±»ç‡ï¼›å¤šé¡¹å¼æ—¶é—´ç®—æ³•å°†å›¾è½¬åŒ–ä¸º(k, O(ÎµÎ´), Î©(1))-å¯èšç±»å›¾ï¼Œæ˜¾è‘—æ”¹å–„åˆ‡å‰²ç¨€ç–æ€§å¹¶ä¿æŒç¤¾åŒºæ‰©å±•æ€§ã€‚

Conclusion: æˆåŠŸè¯æ˜å¯ä»¥ç»“åˆå›¾ç»“æ„å’Œæ ‡ç­¾ä¿¡æ¯å®ç°è¿‘ä¼¼æœ€ä¼˜çš„è¯¯åˆ†ç±»ç‡ï¼Œä¸ºå¸¦æ ‡ç­¾çš„å›¾èšç±»é—®é¢˜æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

Abstract: In the graph clustering problem with a planted solution, the input is a graph on $n$ vertices partitioned into $k$ clusters, and the task is to infer the clusters from graph structure. A standard assumption is that clusters induce well-connected subgraphs (i.e. $Î©(1)$-expanders), and form $Îµ$-sparse cuts. Such a graph defines the clustering uniquely up to $\approx Îµ$ misclassification rate, and efficient algorithms for achieving this rate are known. While this vanilla version of graph clustering is well studied, in practice, vertices of the graph are typically equipped with labels that provide additional information on cluster ids of the vertices. For example, each vertex could have a cluster label that is corrupted independently with probability $Î´$. Using only one of the two sources of information leads to misclassification rate $\min\{Îµ, Î´\}$, but can they be combined to achieve a rate of $\approx ÎµÎ´$?
  In this paper, we give an affirmative answer to this question and present a sublinear-time algorithm in the number of vertices $n$. Our key algorithmic insight is a new observation on ``spectrally ambiguous'' vertices in a well-clusterable graph.
  While our sublinear-time classifier achieves the nearly optimal $\approx \widetilde O(ÎµÎ´)$ misclassification rate, the approximate clusters that it outputs do not necessarily induce expanders in the graph $G$. In our second result, we give a polynomial-time algorithm that reweights edges of the original $(k, Îµ, Î©(1))$-clusterable graph to transform it into a $(k, \widetilde O(ÎµÎ´), Î©(1))$-clusterable one (for constant $k$), improving sparsity of cuts nearly optimally and preserving expansion properties of the communities - an algorithm for refining community structure of the input graph.

</details>


### [20] [Relative Error Streaming Quantiles with Seamless Mergeability via Adaptive Compactors](https://arxiv.org/abs/2511.17396)
*TomÃ¡Å¡ Domes,Pavel VeselÃ½*

Main category: cs.DS

TL;DR: æœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›çš„ReqSketchç®—æ³•ï¼Œé€šè¿‡å¼•å…¥è‡ªé€‚åº”å‹ç¼©å™¨ç®€åŒ–äº†ç›¸å¯¹è¯¯å·®ä¿è¯çš„è¯æ˜ï¼ŒåŒæ—¶ä¿æŒäº†åŸæœ‰çš„ç©ºé—´å¤æ‚åº¦ã€æ›´æ–°æ—¶é—´å’Œç®—æ³•ç®€æ´æ€§ã€‚


<details>
  <summary>Details</summary>
Motivation: åŸå§‹çš„ReqSketchç®—æ³•è™½ç„¶å…·æœ‰ç›¸å¯¹è¯¯å·®ä¿è¯å’Œå¯åˆå¹¶æ€§ç­‰ä¼˜ç‚¹ï¼Œä½†å…¶å¯åˆå¹¶æ€§è¯æ˜è¿‡äºå¤æ‚ï¼Œéœ€è¦ç¹ççš„æ”¶è´¹è®ºè¯å’Œæ–¹å·®åˆ†æã€‚

Method: å¼€å‘äº†è‡ªé€‚åº”å‹ç¼©å™¨æŠ€æœ¯ï¼Œæ”¹è¿›äº†ReqSketchç®—æ³•ï¼Œä½¿å…¶åœ¨ä¿æŒåŸæœ‰æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—ç®€åŒ–äº†ç›¸å¯¹è¯¯å·®ä¿è¯çš„è¯æ˜è¿‡ç¨‹ã€‚

Result: æ”¹è¿›åçš„ç®—æ³•åœ¨ä¿æŒåŸå§‹ç©ºé—´å¤æ‚åº¦ã€æ›´æ–°æ—¶é—´å’Œç®—æ³•ç®€æ´æ€§çš„åŒæ—¶ï¼Œæä¾›äº†æ›´ç®€åŒ–çš„è¯æ˜ï¼Œå¹¶åœ¨ç‰¹å®šåœºæ™¯ä¸‹ï¼ˆå¦‚åˆå¹¶å¤§å°ç›¸å½“çš„è‰å›¾æ—¶ï¼‰å®ç°äº†æ¥è¿‘æœ€ä¼˜çš„ç©ºé—´å¤æ‚åº¦ã€‚

Conclusion: é€šè¿‡è‡ªé€‚åº”å‹ç¼©å™¨æŠ€æœ¯ï¼ŒæˆåŠŸç®€åŒ–äº†ReqSketchç®—æ³•çš„ç†è®ºè¯æ˜ï¼ŒåŒæ—¶ä¿æŒäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„é«˜æ•ˆæ€§èƒ½ã€‚

Abstract: Quantile summaries provide a scalable way to estimate the distribution of individual attributes in large datasets that are often distributed across multiple machines or generated by sensor networks. ReqSketch (arXiv:2004.01668) is currently the most space-efficient summary with two key properties: relative error guarantees, offering increasingly higher accuracy towards the distribution's tails, and mergeability, allowing distributed or parallel processing of datasets. Due to these features and its simple algorithm design, ReqSketch has been adopted in practice, via implementation in the Apache DataSketches library. However, the proof of mergeability in ReqSketch is overly complicated, requiring an intricate charging argument and complex variance analysis.
  In this paper, we provide a refined version of ReqSketch, by developing so-called adaptive compactors. This enables a significantly simplified proof of relative error guarantees in the most general mergeability setting, while retaining the original space bound, update time, and algorithmic simplicity. Moreover, the adaptivity of our sketch, together with the proof technique, yields near-optimal space bounds in specific scenarios - particularly when merging sketches of comparable size.

</details>
