<div id=toc></div>

# Table of Contents

- [cs.GT](#cs.GT) [Total: 5]
- [cs.DS](#cs.DS) [Total: 7]
- [cs.IR](#cs.IR) [Total: 13]
- [cs.IT](#cs.IT) [Total: 50]
- [cs.DB](#cs.DB) [Total: 7]


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [1] [Coalition Tactics: Bribery and Control in Parliamentary Elections](https://arxiv.org/abs/2601.07279)
*Hodaya Barr,Eden Hartman,Yonatan Aumann,Sarit Kraus*

Main category: cs.GT

TL;DR: 研究议会选举中的策略操纵问题，关注提升联盟整体席位而非单个政党，分析贿赂和控制两种操纵方式的计算复杂性


<details>
  <summary>Details</summary>
Motivation: 传统选举操纵研究关注提升单个候选人，但议会选举中选民更关心执政联盟的整体席位分布。本文研究如何操纵议会选举以提升联盟整体席位的新问题

Method: 研究比例代表制选举中的两种操纵方式：贿赂（修改选民偏好）和控制（改变选民和政党集合）。分析两种变体：最大化联盟总席位，以及同时提升联盟和联盟内特定政党的相对权力

Result: 对于贿赂问题，部分变体有多项式时间算法，其他变体是NP难的。对于控制问题，添加和删除选民有多项式时间算法，但添加和删除政党要么不可能（免疫），要么是计算困难的（W[1]-难）

Conclusion: 议会选举中的联盟席位操纵问题在计算复杂性上呈现多样性，某些操纵方式可行且高效，而其他方式则计算困难或不可能实现

Abstract: Strategic manipulation of elections is typically studied in the context of promoting individual candidates.
  In parliamentary elections, however, the focus shifts: voters may care more about the overall governing coalition than the individual parties' seat counts.
  This paper studies this new problem: manipulating parliamentary elections with the goal of promoting the collective seat count of a coalition of parties.
  We focus on proportional representation elections, and consider two variants of the problem; one in which the sole goal is to maximize the total number of seats held by the desired coalition, and the other with a dual objective of both promoting the coalition and promoting the relative power of some favorite party within the coalition.
  We examine two types of strategic manipulations:
  \emph{bribery}, which allows modifying voters' preferences, and \emph{control}, which allows
  changing the sets of voters and parties.
  We consider multiple bribery types, presenting polynomial-time algorithms for some, while proving NP-hardness for others.
  For control, we provide polynomial-time algorithms for control by adding and deleting voters. In contrast, control by adding and deleting parties, we show, is either impossible (i.e., the problem is immune to control) or computationally hard, in particular, W[1]-hard when parameterized by the number of parties that can be added or deleted.

</details>


### [2] [Machine Learning Model Trading with Verification under Information Asymmetry](https://arxiv.org/abs/2601.07510)
*Xiang Li,Jianwei Huang,Kai Yang,Chenyou Fan*

Main category: cs.GT

TL;DR: 本文提出了一种基于博弈论的机器学习模型交易机制，通过引入验证步骤来解决信息不对称问题，分析了卖方可能进行模型欺骗的概率，并设计了最优定价方案。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型交易中存在信息不对称问题，导致卖方可能虚假宣传模型性能以获取更高收益，现有文献未能完全解决这一问题。

Method: 采用博弈论方法，在ML模型市场中添加验证步骤，允许买家在购买前检查模型质量，并设计考虑异质买家策略行为的最优定价方案。

Result: 分析显示卖方会基于验证概率进行模型欺骗，欺骗概率随验证准确度降低而增加，随验证成本增加而增加。减少信息不对称对买卖双方都有利，而保护买家订单信息对双方收益无改善。

Conclusion: 减少信息不对称在ML模型交易中至关重要，这为未来研究开辟了新方向。验证机制和定价策略设计能有效缓解模型欺骗问题。

Abstract: Machine learning (ML) model trading, known for its role in protecting data privacy, faces a major challenge: information asymmetry. This issue can lead to model deception, a problem that current literature has not fully solved, where the seller misrepresents model performance to earn more. We propose a game-theoretic approach, adding a verification step in the ML model market that lets buyers check model quality before buying. However, this method can be expensive and offers imperfect information, making it harder for buyers to decide. Our analysis reveals that a seller might probabilistically conduct model deception considering the chance of model verification. This deception probability decreases with the verification accuracy and increases with the verification cost. To maximize seller payoff, we further design optimal pricing schemes accounting for heterogeneous buyers' strategic behaviors. Interestingly, we find that reducing information asymmetry benefits both the seller and buyer. Meanwhile, protecting buyer order information doesn't improve the payoff for the buyer or the seller. These findings highlight the importance of reducing information asymmetry in ML model trading and open new directions for future research.

</details>


### [3] [Enforcing Priority in Schedule-based User Equilibrium Transit Assignment](https://arxiv.org/abs/2601.07712)
*Liyang Feng,Hanlin Sun,Yu Marco Nie,Jun Xie,Jiayang Li*

Main category: cs.GT

TL;DR: 提出基于非线性互补问题(NCP)的公交分配模型，通过可用容量概念编码登车优先级，捕捉因拒载导致的排队延迟和出发时间偏移，改进了Nguyen等人的隐式优先级框架。


<details>
  <summary>Details</summary>
Motivation: 现有基于时刻表的公交分配模型通过显式动态加载和群体期望成本来执行连续优先级和先到先服务规则，但离散车辆运行会导致群体内成本差异，影响行为一致性。Nguyen等人的隐式优先级框架缺乏明确的数学公式和精确计算方法。

Method: 推导出等效的非线性互补问题(NCP)公式，建立均衡存在性条件。提出改进的弧级NCP公式，对应更严格的行为一致均衡概念。将NCP重构为连续可微的带均衡约束数学规划(MPEC)，并开发两种求解算法。

Result: 证明了在温和条件下均衡的存在性，但可能存在多个均衡（包括行为上可疑的）。改进的弧级NCP公式能排除这些伪均衡，计算更易处理。数值研究验证了模型能重现连续优先级和FCFS排队，捕捉因竞争登车优先级导致的出发时间偏移。

Conclusion: 提出的NCP框架为公交分配中的优先级规则提供了严格的数学基础，改进了隐式优先级方法，能更准确地模拟乘客对拒载的行为响应，包括出发时间调整和路径选择变化。

Abstract: Denied boarding in congested transit systems induces queuing delays and departure-time shifts that can reshape passenger flows. Correctly modeling these responses in transit assignment hinges on the enforcement of two priority rules: continuance priority for onboard passengers and first-come-first-served (FCFS) boarding among waiting passengers. Existing schedule-based models typically enforce these rules through explicit dynamic loading and group-level expected costs, yet discrete vehicle runs can induce nontrivial within-group cost differences that undermine behavioral consistency. We revisit the implicit-priority framework of Nguyen et al. (2001), which, by encoding boarding priority through the notion of available capacity, characterizes route and departure choices based on realized personal (rather than group-averaged) travel experiences. However, the framework lacks an explicit mathematical formulation and exact computational methods for finding equilibria. Here, we derive an equivalent nonlinear complementarity problem (NCP) formulation and establish equilibrium existence under mild conditions. We also show that multiple equilibria may exist, including behaviorally questionable ones. To rule out these artifacts, we propose a refined arc-level NCP formulation that not only corresponds to a tighter, behaviorally consistent equilibrium concept but also is more computationally tractable. We reformulate the NCP as a continuously differentiable mathematical program with equilibrium constraints (MPEC) and propose two solution algorithms. Numerical studies on benchmark instances and a Hong Kong case study demonstrate that the model reproduces continuance priority and FCFS queuing and captures departure-time shifts driven by the competition for boarding priority.

</details>


### [4] [Structural Approach to Guiding a Present-Biased Agent](https://arxiv.org/abs/2601.07763)
*Tatiana Belova,Yuriy Dementiev,Artur Ignatiev,Danil Sagunov*

Main category: cs.GT

TL;DR: 本文全面分析了行为经济学中时间不一致性问题的计算复杂性，针对有偏见的代理人在任务图中的导航问题，提出了基于树宽和路径成本数量的固定参数可解算法，并给出了紧致的硬度结果。


<details>
  <summary>Details</summary>
Motivation: 时间不一致行为（如拖延症、放弃长期目标）在现实生活中普遍存在，Kleinberg和Oren的模型描述了有偏见的代理人在任务图中的决策问题。Belova等人的扩展模型引入了完全知情的主体来引导有偏见的代理人完成关键任务而不导致放弃。本文旨在对这一问题的计算复杂性进行全面算法刻画。

Method: 采用参数化算法框架，分析任务图的自然图参数（如树宽、顶点覆盖、反馈顶点集）。主要结果是基于树宽和不同(v,t)路径成本数量的固定参数可解算法。该算法涵盖了多种输入设置，如有限边成本和受限任务图结构。

Result: 提出了基于树宽和路径成本数量的固定参数可解算法，为多种配置提供了高效算法。同时给出了紧致的硬度结果，表明即使在节点数有限、参数值为常数的简单图上，问题也极其困难。划定了问题的可解和不可解区域，回答了Belova等人的开放问题。

Conclusion: 本文对时间不一致行为中的主体-代理人动态问题提供了全面的算法刻画，通过参数化分析揭示了问题的计算复杂性边界，为行为经济学中的计算问题提供了理论工具和算法解决方案。

Abstract: Time-inconsistent behavior, such as procrastination or abandonment of long-term goals, arises when agents evaluate immediate outcomes disproportionately higher than future ones. This leads to globally suboptimal behavior, where plans are frequently revised or abandoned entirely. In the influential model of Kleinberg and Oren (2014) such behavior is modeled by a present-biased agent navigating a task graph toward a goal, making locally optimal decisions at each step based on discounted future costs. As a result, the agent may repeatedly deviate from initial plans. Recent work by Belova et al. (2024) introduced a two-agent extension of this model, where a fully-aware principal attempts to guide the present-biased agent through a specific set of critical tasks without causing abandonment. This captures a rich class of principal-agent dynamics in behavioral settings.
  In this paper, we provide a comprehensive algorithmic characterization of this problem. We analyze its computational complexity through the framework of parameterized algorithms, focusing on graph parameters that naturally emerge in this setting, such as treewidth, vertex cover, and feedback vertex set. Our main result is a fixed-parameter tractable algorithm when parameterized by the treewidth of the task graph and the number of distinct (v,t)-path costs. Our algorithm encaptures several input settings, such as bounded edge costs and restricted task graph structure. We demonstrate that our main result yields efficient algorithms for a number of such configurations.
  We complement this with tight hardness results, that highlight the extreme difficulty of the problem even on simplest graphs with bounded number of nodes and constant parameter values, and motivate our choice of parameters. We delineate tractable and intractable regions of the problem landscape, which include answers to open questions of Belova et al. (2024).

</details>


### [5] [The Complexity of Games with Randomised Control](https://arxiv.org/abs/2601.07775)
*Sarvin Bahmani,Rasmus Ibsen-Jensen,Soumyajit Paul,Sven Schewe,Friedrich Slivovsky,Qiyi Tang,Dominik Wojtczak,Shufang Zhu*

Main category: cs.GT

TL;DR: 研究两种随机控制节点分配机制下无限时长游戏的复杂性：首次访问时随机分配（机制1）和游戏前预先分配（机制2）。对于可达性、奇偶性和能量目标，定性问题均为NL完全，机制1的定量问题为PSPACE完全，机制2的精确计算为sharp-P完全，并提出随机近似方案。


<details>
  <summary>Details</summary>
Motivation: 经典随机轮转游戏中，每次访问节点时都会随机分配控制权。本文研究两种自然变体：1）首次访问时随机分配控制权且不再改变；2）游戏开始前预先为所有节点分配控制权。这些变体更贴近某些实际应用场景，需要分析其计算复杂性。

Method: 研究两种控制分配机制下的无限时长游戏：机制1（首次访问时随机分配）和机制2（游戏前预先分配）。分析三种目标函数（可达性、奇偶性、能量）的复杂性。使用复杂性理论分析定性问题和定量问题，提出随机近似方案估计获胜概率。

Result: 所有变体和目标的定性问题均为NL完全。机制1下，判断最大化者以至少给定概率获胜的定量问题对所有目标均为PSPACE完全。机制2下，精确计算获胜概率对所有目标均为sharp-P完全。提出并实证验证了随机近似方案的有效收敛性。

Conclusion: 两种随机控制分配机制下的无限时长游戏具有不同的计算复杂性特征。机制1的定量决策更困难（PSPACE完全），而机制2的精确计算更困难（sharp-P完全）。提出的随机近似方案为机制2提供了实用的近似计算方法，在有限条件下能有效估计获胜概率。

Abstract: We study the complexity of solving two-player infinite duration games played on a fixed finite graph, where the control of a node is not predetermined but rather assigned randomly. In classic random-turn games, control of each node is assigned randomly every time the node is visited during a play. In this work, we study two natural variants of this where control of each node is assigned only once: (i) control is assigned randomly during a play when a node is visited for the first time and does not change for the rest of the play and (ii) control is assigned a priori before the game starts for every node by independent coin tosses and then the game is played. We investigate the complexity of computing the winning probability with three kinds of objectives-reachability, parity, and energy. We show that the qualitative questions on all variants and all objectives are NL-complete. For the quantitative questions, we show that deciding whether the maximiser can win with probability at least a given threshold for every objective is PSPACE-complete under the first mechanism, and that computing the exact winning probability for every objective is sharp-P-complete under the second. To complement our hardness results for the second mechanism, we propose randomised approximation schemes that efficiently estimate the winning probability for all three objectives, assuming a bounded number of parity colours and unary-encoded weights for energy objectives, and we empirically demonstrate their fast convergence.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [6] [Lower Bounds for the Algorithmic Complexity of Learned Indexes](https://arxiv.org/abs/2601.06629)
*Luis Alberto Croquevielle,Roman Sokolovskii,Thomas Heinis*

Main category: cs.DS

TL;DR: 该论文提出了一个用于证明学习索引查询时间下界的通用框架，通过近似理论工具分析空间-时间权衡，揭示了学习索引结构的核心限制。


<details>
  <summary>Details</summary>
Motivation: 学习索引结构在实践中有效，但其理论局限性尚未完全理解。需要建立理论框架来分析学习索引的查询时间下界，以理解其根本限制。

Method: 提出两步骤框架：1) 使用概率工具控制数据库属性从概率分布采样时的效应；2) 分析用给定模型类近似累积分布函数的最优表示问题。利用近似理论工具如量化和Kolmogorov宽度来分析空间-时间权衡。

Result: 推导了在各种建模和分布假设下的下界，特别关注实践中常见的分段线性和分段常数模型类。揭示了学习索引结构的核心局限性。

Conclusion: 该框架为学习索引提供了理论基础，展示了近似理论工具如何形式化学习索引的空间-时间权衡，为理解这些方法的根本限制提供了理论依据。

Abstract: Learned index structures aim to accelerate queries by training machine learning models to approximate the rank function associated with a database attribute. While effective in practice, their theoretical limitations are not fully understood. We present a general framework for proving lower bounds on query time for learned indexes, expressed in terms of their space overhead and parameterized by the model class used for approximation. Our formulation captures a broad family of learned indexes, including most existing designs, as piecewise model-based predictors.
  We solve the problem of lower bounding query time in two steps: first, we use probabilistic tools to control the effect of sampling when the database attribute is drawn from a probability distribution. Then, we analyze the approximation-theoretic problem of how to optimally represent a cumulative distribution function with approximators from a given model class. Within this framework, we derive lower bounds under a range of modeling and distributional assumptions, paying particular attention to the case of piecewise linear and piecewise constant model classes, which are common in practical implementations.
  Our analysis shows how tools from approximation theory, such as quantization and Kolmogorov widths, can be leveraged to formalize the space-time tradeoffs inherent to learned index structures. The resulting bounds illuminate core limitations of these methods.

</details>


### [7] [Approximating Matroid Basis Testing for Partition Matroids using Budget-In-Expectation](https://arxiv.org/abs/2601.06723)
*Lisa Hellerstein,Benedikt M. Plank,Kevin Schewior*

Main category: cs.DS

TL;DR: 本文研究了随机布尔函数评估问题，针对分区拟阵提出了首个多项式时间常数因子近似算法，通过结合新技巧与现有技术，自适应地交错解决多个新型随机查询问题实例。


<details>
  <summary>Details</summary>
Motivation: 研究随机布尔函数评估问题，该问题与文献中的多个问题密切相关。当拟阵是均匀拟阵时，该问题已得到很好解决，但对于分区拟阵，先前方法无法给出常数因子近似，因此需要开发新的算法。

Method: 提出多项式时间常数因子近似算法，通过自适应地交错解决多个新型随机查询问题实例来生成随机策略。这种新型问题具有期望成本约束，结合了新技巧与多个成熟技术。

Result: 针对分区拟阵的随机布尔函数评估问题，获得了首个多项式时间常数因子近似算法，解决了先前方法无法给出常数因子近似的问题。

Conclusion: 提出的新型随机查询问题具有独立研究价值，有望激发后续工作并具有额外应用潜力。算法成功结合新技巧与现有技术，为分区拟阵问题提供了有效解决方案。

Abstract: We consider the following Stochastic Boolean Function Evaluation problem, which is closely related to several problems from the literature. A matroid $\mathcal{M}$ (in compact representation) on ground set $E$ is given, and each element $i\in E$ is active independently with known probability $p_i\in(0,1)$. The elements can be queried, upon which it is revealed whether the respective element is active or not. The goal is to find an adaptive querying strategy for determining whether there is a basis of $\mathcal{M}$ in which all elements are active, with the objective of minimizing the expected number of queries.
  When $\mathcal{M}$ is a uniform matroid, this is the problem of evaluating a $k$-of-$n$ function, first studied in the 1970s. This problem is well-understood, and has an optimal adaptive strategy that can be computed in polynomial time.
  Taking $\mathcal{M}$ to instead be a partition matroid, we show that previous approaches fail to give a constant-factor approximation. Our main result is a polynomial-time constant-factor approximation algorithm producing a randomized strategy for this partition matroid problem. We obtain this result by combining a new technique with several well-established techniques. Our algorithm adaptively interleaves solutions to several instances of a novel type of stochastic querying problem, with a constraint on the $\textit{expected}$ cost. We believe that this type of problem is of independent interest, will spark follow-up work, and has the potential for additional applications.

</details>


### [8] [Algorithmic Reductions: Network Flow and NP-Completeness in Real-World Scheduling Problems](https://arxiv.org/abs/2601.06737)
*Anay Sinhal,Arpana Sinhal,Amit Sinhal,Amit Hirawat*

Main category: cs.DS

TL;DR: 论文通过多项式时间归约解决两个实际调度问题：医院床位分配（归约为最大二分图匹配）和大学课程排课（证明为NP完全问题并提供贪心近似算法），Python实现验证了理论复杂度分析。


<details>
  <summary>Details</summary>
Motivation: 解决两个实际应用中的调度优化问题：医院患者床位分配和大学课程时间安排，这些是医疗和教育领域的关键资源分配挑战。

Method: 1. 医院床位分配问题归约为最大二分图匹配，使用网络流算法求解；2. 大学课程排课问题通过从图着色问题归约证明为NP完全，并提供贪心近似算法。

Result: 网络流解决方案实现O(n^2.51)经验复杂度，贪心着色算法展示O(n^2)行为，近似比始终低于理论Δ+1界限，Python实现验证了理论分析。

Conclusion: 通过多项式时间归约有效解决实际调度问题，网络流算法和贪心近似算法在实际应用中表现良好，为类似资源分配问题提供了可行的解决方案框架。

Abstract: This paper presents two real-world scheduling problems and their algorithmic solutions through polynomial-time reductions. First, we address the Hospital Patient-to-Bed Assignment problem, demonstrating its reduction to Maximum Bipartite Matching and solution via Network Flow algorithms. Second, we tackle the University Course Scheduling problem, proving its NP-Completeness through reduction from Graph Coloring and providing greedy approximation algorithms. Both problems are implemented in Python, with experimental results validating theoretical complexity analyses. Our Network Flow solution achieves O(n2.51) empirical complexity, while the greedy coloring algorithms demonstrate O(n2) behavior with approximation ratios consistently below the theoretical delta + 1 bound.

</details>


### [9] [Spectral Shadows: When Communication Complexity Meets Linear Invariance Testing](https://arxiv.org/abs/2601.06828)
*Swarnalipa Datta,Arijit Ghosh,Chandrima Kayal,Manaswi Paraashar,Manmatha Roy*

Main category: cs.DS

TL;DR: 本文首次在通信复杂度框架下研究线性同构测试问题，发现近似谱范数在该问题的通信复杂度中起核心作用，设计了基于近似谱范数的确定性/随机协议，并给出了匹配的下界。


<details>
  <summary>Details</summary>
Motivation: 线性同构测试问题是经典等式问题的线性代数推广，在算法设计、电路设计、复杂性理论和密码学中有重要应用，但此前在通信复杂度领域尚未被研究。

Method: 1. 将线性同构测试问题引入通信复杂度框架；2. 设计确定性协议，通信成本与近似谱范数多项式相关；3. 设计随机协议（私币），获得对近似谱范数的二次改进依赖；4. 建立布尔函数近似谱范数小的新junta定理作为核心技术工具。

Result: 1. 确定性协议通信成本与近似谱范数多项式相关，下界匹配（最多二次差距）；2. 随机协议对近似谱范数依赖二次改进，且这种依赖本质上不可避免；3. 近似谱范数被确立为通信复杂度框架中测试线性不变性的关键复杂度度量。

Conclusion: 近似谱范数是通信复杂度中测试线性不变性的核心复杂度度量，本文结果填补了该问题在通信复杂度领域的研究空白，建立的新junta定理在傅里叶分析和学习理论中可能有独立价值。

Abstract: In this short note, we initiate the study of the Linear Isomorphism Testing Problem in the setting of communication complexity, a natural linear algebraic generalization of the classical Equality problem. Given Boolean functions $f, g : \mathbb{F}_2^n \to \{-1, +1\}$, Alice and Bob are tasked with determining whether $f$ and $g$ are equivalent up to a nonsingular linear transformation of the input variables, or far from being so. This problem has been extensively investigated in several models of computation, including standard algorithmic and property testing frameworks, owing to its fundamental connections with combinatorial circuit design, complexity theory, and cryptography. However, despite its broad relevance, it has remained unexplored in the context of communication complexity, a gap we address in this work.
  Our main results demonstrate that the approximate spectral norm of the input functions plays a central role in governing the communication complexity of this problem. We design a simple deterministic protocol whose communication cost is polynomial in the approximate spectral norm, and complement it with nearly matching lower bounds (up to a quadratic gap). In the randomised setting with private coins, we present an even more efficient protocol, though equally simple, that achieves a quadratically improved dependence on the approximate spectral norm compared to the deterministic case, and we prove that such a dependence is essentially unavoidable.
  These results identify the approximate spectral norm as a key complexity measure for testing linear invariance in the communication complexity framework. As a core technical ingredient, we establish new junta theorems for Boolean functions with small approximate spectral norm, which may be of independent interest in Fourier analysis and learning theory.

</details>


### [10] [Optimal Extended Formulations from Optimal Dynamic Programming Algorithms](https://arxiv.org/abs/2601.06947)
*Mateus de Oliveira Oliveira,Wim Van den Broeck*

Main category: cs.DS

TL;DR: 该论文建立了顶点子集问题中动态规划与线性规划之间的紧密联系，证明了基于树分解的动态规划算法产生的表格大小与解多面体的扩展复杂度之间的最优对应关系。


<details>
  <summary>Details</summary>
Motivation: 顶点子集问题（VSPs）通常通过树分解动态规划或线性规划两种方法求解。研究这两种看似不同的方法之间的理论联系，有助于理解算法的本质特性并建立统一的理论框架。

Method: 通过理论分析证明：如果顶点子集问题Π存在解保持的动态规划算法，在宽度为k的树分解上产生大小为α(k,n)的表格，那么解多面体P_Π(G)的扩展复杂度最多为O(α(k,n)·n)。该上界在指数时间假设（ETH）下是最优的。

Result: 建立了动态规划表格大小与解多面体扩展复杂度之间的精确对应关系，证明了ETH最优的动态规划算法产生最优大小的参数化扩展公式，同时扩展公式理论中的下界也对应动态规划表格复杂度的下界。

Conclusion: 该研究为顶点子集问题的两种主要求解方法建立了深刻的理论联系，为算法设计提供了新的视角，并揭示了动态规划与线性规划之间的内在统一性。

Abstract: Vertex Subset Problems (VSPs) are a class of combinatorial optimization problems on graphs where the goal is to find a subset of vertices satisfying a predefined condition. Two prominent approaches for solving VSPs are dynamic programming over tree-like structures, such as tree decompositions or clique decompositions, and linear programming. In this work, we establish a sharp connection between both approaches by showing that if a vertex-subset problem $Π$ admits a solution-preserving dynamic programming algorithm that produces tables of size at most $α(k,n)$ when processing a tree decomposition of width at most $k$ of an $n$-vertex graph $G$, then the polytope $P_Π(G)$ defined as the convex-hull of solutions of $Π$ in $G$ has extension complexity at most $O(α(k,n)\cdot n)$. Additionally, this upper bound is optimal under the exponential time hypothesis (ETH).
  On the one hand, our results imply that ETH-optimal solution-preserving dynamic programming algorithms for combinatorial problems yield optimal-size parameterized extended formulations for the solution polytopes associated with instances of these problems. On the other hand, unconditional lower bounds obtained in the realm of the theory of extended formulations yield unconditional lower bounds on the table complexity of solution-preserving dynamic programming algorithms.

</details>


### [11] [The Secretary Problem with Predictions and a Chosen Order](https://arxiv.org/abs/2601.07482)
*Helia Karisani,Mohammadreza Daneshvaramoli,Hedyeh Beyhaghi,Mohammad Hajiesmaili,Cameron Musco*

Main category: cs.DS

TL;DR: 论文研究学习增强的秘书问题，提出新算法平衡预测准确性和鲁棒性，在随机顺序和选择顺序两种模型中都改进了竞争比。


<details>
  <summary>Details</summary>
Motivation: 传统秘书问题中，决策者需要在候选人随机到达时在线选择最佳人选。近年来，机器学习预测为这类在线决策问题提供了额外信息。核心挑战是如何平衡一致性和鲁棒性：当预测准确时，算法应选择接近最优的候选人；当预测不准确时，仍能保证有界的竞争比。

Method: 提出适用于随机顺序秘书问题(ROSP)和选择顺序秘书问题(COSP)的新随机算法。算法采用切换策略：初始信任预测，一旦检测到较大预测偏差，就切换到基于阈值的规则。设ε∈[0,1]表示最大乘法预测误差。

Result: 对于ROSP，算法达到竞争比max{0.221, (1-ε)/(1+ε)}，优于之前的max{0.215, (1-ε)/(1+ε)}。对于COSP，达到max{0.262, (1-ε)/(1+ε)}，超越了先前方法的0.25最坏情况界限，更接近经典秘书问题的1/e≈0.368基准。

Conclusion: 研究结果表明，在在线决策中将预测与到达顺序控制相结合具有显著优势。新算法在两种秘书问题模型中都能更好地平衡一致性和鲁棒性，为学习增强的在线算法设计提供了新思路。

Abstract: We study a learning-augmented variant of the secretary problem, recently introduced by Fujii and Yoshida (2023), in which the decision-maker has access to machine-learned predictions of candidate values. The central challenge is to balance consistency and robustness: when predictions are accurate, the algorithm should select a near-optimal secretary, while under inaccurate predictions it should still guarantee a bounded competitive ratio.
  We consider both the classical Random Order Secretary Problem (ROSP), where candidates arrive in a uniformly random order, and a more natural learning-augmented model in which the decision-maker may choose the arrival order based on predicted values. We call this model the Chosen Order Secretary Problem (COSP), capturing scenarios such as interview schedules set in advance.
  We propose a new randomized algorithm applicable to both ROSP and COSP. Our method switches from fully trusting predictions to a threshold-based rule once a large prediction deviation is detected. Let $ε\in [0,1]$ denote the maximum multiplicative prediction error. For ROSP, our algorithm achieves a competitive ratio of $\max\{0.221, (1-ε)/(1+ε)\}$, improving upon the prior bound of $\max\{0.215, (1-ε)/(1+ε)\}$. For COSP, we achieve $\max\{0.262, (1-ε)/(1+ε)\}$, surpassing the $0.25$ worst-case bound for prior approaches and moving closer to the classical secretary benchmark of $1/e \approx 0.368$. These results highlight the benefit of combining predictions with arrival-order control in online decision-making.

</details>


### [12] [Dynamic $(Δ+ 1)$ Vertex Coloring](https://arxiv.org/abs/2601.07566)
*Noam Benson-Tilsen*

Main category: cs.DS

TL;DR: 该论文综述了动态和亚线性图着色领域的最新进展，重点介绍了从O(Δ)到O(log Δ)再到O(1)高概率更新时间的(Δ+1)-着色算法改进，以及从无意识对手到自适应对手的扩展。


<details>
  <summary>Details</summary>
Motivation: 图着色问题在网络拓扑控制、约束满足和实时资源调度等领域有广泛应用。动态图着色算法需要高效处理图结构的实时变化，而传统算法在更新效率上存在局限，需要更优的动态着色方案。

Method: 论文采用综述方法，系统分析多个关键研究成果：1) 定义动态模型和性能度量；2) 总结arXiv:1708.09080中的近似最优动态顶点着色器；3) 分析arXiv:1711.04355和arXiv:1910.02063中从O(Δ)到O(log Δ)再到O(1)高概率更新时间的改进；4) 介绍arXiv:2411.04418中将无意识对手扩展到自适应对手的亚线性算法。

Result: 动态(Δ+1)-着色算法取得了显著进展：从朴素算法的O(Δ)期望摊销更新时间，改进到O(log Δ)，最终达到O(1)高概率更新时间。最新研究还将算法扩展到能处理自适应对手的场景。

Conclusion: 动态图着色领域在算法效率方面取得了重要突破，从多项式时间改进到常数时间，并且算法鲁棒性从无意识对手扩展到自适应对手，为实际应用提供了更强大的理论基础。

Abstract: Several recent results from dynamic and sublinear graph coloring are surveyed. This problem is widely studied and has motivating applications like network topology control, constraint satisfaction, and real-time resource scheduling. Graph coloring algorithms are called colorers. In §1 are defined graph coloring, the dynamic model, and the notion of performance of graph algorithms in the dynamic model. In particular $(Δ+ 1)$-coloring, sublinear performance, and oblivious and adaptive adversaries are noted and motivated. In §2 the pair of approximately optimal dynamic vertex colorers given in arXiv:1708.09080 are summarized as a warmup for the $(Δ+ 1)$-colorers. In §3 the state of the art in dynamic $(Δ+ 1)$-coloring is presented. This section comprises a pair of papers (arXiv:1711.04355 and arXiv:1910.02063) that improve dynamic $(Δ+ 1)$-coloring from the naive algorithm with $O(Δ)$ expected amortized update time to $O(\log Δ)$, then to $O(1)$ with high probability. In §4 the results in arXiv:2411.04418, which gives a sublinear algorithm for $(Δ+ 1)$-coloring that generalizes oblivious adversaries to adaptive adversaries, are presented.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [13] [Towards Building efficient Routed systems for Retrieval](https://arxiv.org/abs/2601.06389)
*Ramnath Kumar,Prateek Jain,Cho-Jui Hsieh*

Main category: cs.IR

TL;DR: FastLane是一个新型检索框架，通过动态路由查询到最有信息量的表示，消除冗余token比较，将延迟交互模型与近似最近邻搜索结合，实现可扩展的低延迟检索。


<details>
  <summary>Details</summary>
Motivation: 延迟交互检索模型（如ColBERT）虽然通过token级交互实现了高精度，但计算成本高，阻碍了可扩展性和与近似最近邻搜索（ANNS）的集成。

Method: FastLane采用可学习的路由机制，与嵌入模型联合优化，利用自注意力和可微分选择来最大化效率，动态路由查询到最有信息量的表示。

Result: 计算复杂度降低高达30倍，同时保持有竞争力的检索性能，使大规模应用（如搜索引擎、推荐系统、问答平台）成为可能。

Conclusion: FastLane为多语言、多模态和长上下文检索开辟了道路，推动了高效自适应信息检索的前沿发展。

Abstract: Late-interaction retrieval models like ColBERT achieve superior accuracy by enabling token-level interactions, but their computational cost hinders scalability and integration with Approximate Nearest Neighbor Search (ANNS). We introduce FastLane, a novel retrieval framework that dynamically routes queries to their most informative representations, eliminating redundant token comparisons. FastLane employs a learnable routing mechanism optimized alongside the embedding model, leveraging self-attention and differentiable selection to maximize efficiency. Our approach reduces computational complexity by up to 30x while maintaining competitive retrieval performance. By bridging late-interaction models with ANNS, FastLane enables scalable, low-latency retrieval, making it feasible for large-scale applications such as search engines, recommendation systems, and question-answering platforms. This work opens pathways for multi-lingual, multi-modal, and long-context retrieval, pushing the frontier of efficient and adaptive information retrieval.

</details>


### [14] [PixRec: Leveraging Visual Context for Next-Item Prediction in Sequential Recommendation](https://arxiv.org/abs/2601.06458)
*Sayak Chakrabarty,Souradip Pal*

Main category: cs.IR

TL;DR: PixRec是一个视觉语言推荐框架，通过结合文本属性和产品图像，在序列推荐任务中显著优于纯文本推荐器


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的序列推荐方法主要依赖文本信息，忽视了现实推荐场景（特别是电商）中丰富的视觉信息。产品图像包含重要特征，可以帮助区分文本描述相似的商品

Method: 提出PixRec视觉语言框架，采用视觉语言模型骨干网络联合处理图像-文本序列，保持双塔结构和混合训练目标，同时对齐多模态特征投影以处理商品-商品和用户-商品交互

Result: 在Amazon Reviews数据集（增强产品图像）上的实验显示，相比纯文本推荐器，在top-rank准确率上提升3倍，在top-10准确率上提升40%，表明视觉特征能有效区分文本描述相似的商品

Conclusion: 视觉信息在序列推荐中具有重要价值，特别是在电商等实际应用中。该工作为构建利用视觉信息的软件系统迈出了一步，并指出了扩展多模态推荐器训练、增强视觉-文本特征融合和评估推理时性能的未来方向

Abstract: Large Language Models (LLMs) have recently shown strong potential for usage in sequential recommendation tasks through text-only models, which combine advanced prompt design, contrastive alignment, and fine-tuning on downstream domain-specific data. While effective, these approaches overlook the rich visual information present in many real-world recommendation scenarios, particularly in e-commerce. This paper proposes PixRec - a vision-language framework that incorporates both textual attributes and product images into the recommendation pipeline. Our architecture leverages a vision-language model backbone capable of jointly processing image-text sequences, maintaining a dual-tower structure and mixed training objective while aligning multi-modal feature projections for both item-item and user-item interactions. Using the Amazon Reviews dataset augmented with product images, our experiments demonstrate $3\times$ and 40% improvements in top-rank and top-10 rank accuracy over text-only recommenders respectively, indicating that visual features can help distinguish items with similar textual descriptions. Our work outlines future directions for scaling multi-modal recommenders training, enhancing visual-text feature fusion, and evaluating inference-time performance. This work takes a step toward building software systems utilizing visual information in sequential recommendation for real-world applications like e-commerce.

</details>


### [15] [L-RAG: Balancing Context and Retrieval with Entropy-Based Lazy Loading](https://arxiv.org/abs/2601.06551)
*Sergii Voloshyn*

Main category: cs.IR

TL;DR: L-RAG：基于熵门控的自适应检索增强生成框架，通过分层上下文管理和条件检索减少计算开销，在保持准确性的同时显著降低检索频率和延迟。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统采用"总是检索"的静态策略，无论查询复杂度如何都会查询向量数据库，导致高计算开销和推理延迟，尤其在高吞吐量生产部署中问题显著。

Method: L-RAG采用两层架构：首先使用紧凑文档摘要处理查询，仅当模型预测熵超过校准阈值时才触发昂贵的分块检索。通过熵门控机制实现自适应检索决策。

Result: 在SQuAD 2.0数据集上，L-RAG在保守阈值下达到78.2%准确率（匹配标准RAG的77.8%），减少8%检索；平衡阈值下减少26%检索，准确率76.0%。延迟分析显示每查询节省80-210ms。

Conclusion: L-RAG提供了一种无需训练的高效RAG部署方案，通过熵作为可靠的置信度信号，为系统架构师提供了可配置的精度-吞吐量权衡工具。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as the predominant paradigm for grounding Large Language Model outputs in factual knowledge, effectively mitigating hallucinations. However, conventional RAG systems operate under a "retrieve-always" assumption, querying vector databases for every input regardless of query complexity. This static approach incurs substantial computational overhead and inference latency, particularly problematic for high-throughput production deployments. We introduce L-RAG (Lazy Retrieval-Augmented Generation), an adaptive framework that implements hierarchical context management through entropy-based gating. L-RAG employs a two-tier architecture: queries are first processed with a compact document summary, and expensive chunk retrieval is triggered only when the model's predictive entropy exceeds a calibrated threshold, signaling genuine uncertainty. Through experiments on SQuAD 2.0 (N=500) using the Phi-2 model, we demonstrate that L-RAG provides a tunable accuracy-efficiency trade-off: at a conservative threshold (tau=0.5), L-RAG achieves 78.2% accuracy, matching Standard RAG (77.8%), with 8% retrieval reduction; at a balanced threshold (tau=1.0), retrieval reduction increases to 26% with modest accuracy trade-off (76.0%). Latency analysis shows that L-RAG saves 80-210ms per query when retrieval latency exceeds 500ms. Analysis of entropy distributions reveals statistically significant separation (p < 0.001) between correct predictions (H=1.72) and errors (H=2.20), validating entropy as a reliable uncertainty signal. L-RAG offers a practical, training-free approach toward more efficient RAG deployment, providing system architects with a configurable knob to balance accuracy and throughput requirements.

</details>


### [16] [Industrial Semantics-Aware Digital Twins: A Hybrid Graph Matching Approach for Asset Administration Shells](https://arxiv.org/abs/2601.06613)
*Ariana Metović,Nicolai Maisch,Samed Ajdinović,Armin Lechler,Andreas Wortmann,Oliver Riedel*

Main category: cs.IR

TL;DR: 提出一种混合图匹配方法，结合基于规则的SPARQL预过滤和基于RDF2vec嵌入的相似度计算，实现数字孪生表示之间的语义感知比较


<details>
  <summary>Details</summary>
Motivation: 资产管理壳(AAS)标准虽然提供了工业资产的结构化表示，但由于使用不同词汇和建模实践，语义可比性仍然是一个主要挑战。工程领域需要检索与目标相似的现有AAS模型以重用子模型、参数和元数据，但异构词汇和不同建模惯例阻碍了自动化内容级比较

Method: 混合图匹配方法：1) 使用SPARQL进行基于规则的预过滤；2) 利用RDF2vec进行嵌入式相似度计算，捕捉AAS模型之间的结构和语义关系

Result: 该方法能够实现数字孪生表示之间的语义感知比较，为增强数字孪生网络中的发现、重用和自动配置提供了基础

Conclusion: 提出的混合图匹配方法解决了AAS模型语义可比性的挑战，通过结合规则和嵌入技术，为数字孪生网络的互操作性和重用性提供了有效解决方案

Abstract: Although the Asset Administration Shell (AAS) standard provides a structured and machine-readable representation of industrial assets, their semantic comparability remains a major challenge, particularly when different vocabularies and modeling practices are used. Engineering would benefit from retrieving existing AAS models that are similar to the target in order to reuse submodels, parameters, and metadata. In practice, however, heterogeneous vocabularies and divergent modeling conventions hinder automated, content-level comparison across AAS. This paper proposes a hybrid graph matching approach to enable semantics-aware comparison of Digital Twin representations. The method combines rule-based pre-filtering using SPARQL with embedding-based similarity calculation leveraging RDF2vec to capture both structural and semantic relationships between AAS models. This contribution provides a foundation for enhanced discovery, reuse, and automated configuration in Digital Twin networks.

</details>


### [17] [Unleashing the Native Recommendation Potential: LLM-Based Generative Recommendation via Structured Term Identifiers](https://arxiv.org/abs/2601.06798)
*Zhiyang Zhang,Junda She,Kuo Cai,Bo Chen,Shiyao Wang,Xinchen Luo,Qiang Luo,Ruiming Tang,Han Li,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: GRLM框架使用术语ID(TIDs)作为项目标识符，通过上下文感知术语生成和集成指令微调，解决现有生成推荐系统中项目标识符构建的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成推荐方法面临项目标识符构建瓶颈：基于文本的方法引入LLM巨大输出空间导致幻觉，基于语义ID的方法存在语义鸿沟需要昂贵的词汇扩展和对齐训练。

Method: 提出术语ID(TIDs)作为项目标识符，开发GRLM框架：1)上下文感知术语生成将项目元数据转换为标准化TIDs；2)集成指令微调协同优化术语内化和序列推荐；3)弹性标识符接地实现稳健项目映射。

Result: 在真实世界数据集上的广泛实验表明，GRLM在多个场景中显著优于基线方法。

Conclusion: GRLM为通用化和高性能生成推荐系统指出了有前景的方向，通过TIDs解决了项目标识符构建的关键瓶颈。

Abstract: Leveraging the vast open-world knowledge and understanding capabilities of Large Language Models (LLMs) to develop general-purpose, semantically-aware recommender systems has emerged as a pivotal research direction in generative recommendation. However, existing methods face bottlenecks in constructing item identifiers. Text-based methods introduce LLMs' vast output space, leading to hallucination, while methods based on Semantic IDs (SIDs) encounter a semantic gap between SIDs and LLMs' native vocabulary, requiring costly vocabulary expansion and alignment training. To address this, this paper introduces Term IDs (TIDs), defined as a set of semantically rich and standardized textual keywords, to serve as robust item identifiers. We propose GRLM, a novel framework centered on TIDs, employs Context-aware Term Generation to convert item's metadata into standardized TIDs and utilizes Integrative Instruction Fine-tuning to collaboratively optimize term internalization and sequential recommendation. Additionally, Elastic Identifier Grounding is designed for robust item mapping. Extensive experiments on real-world datasets demonstrate that GRLM significantly outperforms baselines across multiple scenarios, pointing a promising direction for generalizable and high-performance generative recommendation systems.

</details>


### [18] [Applying Embedding-Based Retrieval to Airbnb Search](https://arxiv.org/abs/2601.06873)
*Mustafa Abdool,Soumyadip Banerjee,Moutupsi Paul,Do-kyum Kim,Xioawei Liu,Bin Xu,Tracy Yu,Hui Gao,Karen Ouyang,Huiji Gao,Liwei He,Stephanie Moyerman,Sanjeev Katariya*

Main category: cs.IR

TL;DR: Airbnb构建了一个嵌入式检索系统来解决房源搜索匹配问题，该系统在多种使用场景中显著提升了预订转化率。


<details>
  <summary>Details</summary>
Motivation: Airbnb搜索面临巨大挑战：热门地点有数十万可用房源，用户偏好多样，新产品功能（如灵活日期搜索）进一步增加了每查询的合格房源数量，需要低延迟、高质量的检索系统与整体排序栈集成。

Method: 构建嵌入式检索系统，针对双边市场的独特挑战（库存动态性、多阶段用户漏斗、多种产品界面）进行建模，建立稳健的评估系统，并设计在线服务架构。

Result: EBR系统已投入生产，支持常规搜索、灵活日期搜索和营销推广邮件等多种用例，通过A/B测试在预订转化率等关键指标上实现了统计显著的提升。

Conclusion: 成功构建了高效高质量的检索系统，解决了Airbnb搜索中的复杂匹配问题，为双边市场平台提供了实用的嵌入检索解决方案。

Abstract: The goal of Airbnb search is to match guests with the ideal accommodation that fits their travel needs. This is a challenging problem, as popular search locations can have around a hundred thousand available homes, and guests themselves have a wide variety of preferences. Furthermore, the launch of new product features, such as \textit{flexible date search,} significantly increased the number of eligible homes per search query. As such, there is a need for a sophisticated retrieval system which can provide high-quality candidates with low latency in a way that integrates with the overall ranking stack.
  This paper details our journey to build an efficient and high-quality retrieval system for Airbnb search. We describe the key unique challenges we encountered when implementing an Embedding-Based Retrieval (EBR) system for a two sided marketplace like Airbnb -- such as the dynamic nature of the inventory, a lengthy user funnel with multiple stages, and a variety of product surfaces. We cover unique insights when modeling the retrieval problem, how to build robust evaluation systems, and design choices for online serving. The EBR system was launched to production and powers several use-cases such as regular search, flexible date and promotional emails for marketing campaigns. The system demonstrated statistically-significant improvements in key metrics, such as booking conversion, via A/B testing.

</details>


### [19] [FinCARDS: Card-Based Analyst Reranking for Financial Document Question Answering](https://arxiv.org/abs/2601.06992)
*Yixi Zhou,Fan Zhang,Yu Chen,Haipeng Zhang,Preslav Nakov,Zhuohan Xie*

Main category: cs.IR

TL;DR: FinCards是一个针对金融问答的结构化重排序框架，将证据选择重新定义为金融感知模式下的约束满足问题，通过多阶段锦标赛重排序提高检索稳定性并生成可审计的决策轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的重排序器主要优化语义相关性，导致在长文档上的排名不稳定且决策不透明，而金融问答需要对实体、财务指标、会计期间和数值值有严格约束。

Method: FinCards使用对齐的模式字段（实体、指标、期间、数值跨度）表示文件块和问题，通过确定性字段级匹配和多阶段锦标赛重排序进行证据选择，采用稳定性感知聚合生成可审计的决策轨迹。

Result: 在两个企业文件问答基准测试中，FinCards显著提高了早期排名检索性能，优于词汇和基于LLM的重排序基线，同时减少了排名方差，无需模型微调或不可预测的推理预算。

Conclusion: FinCards通过结构化重排序框架有效解决了金融问答中的证据选择问题，提供稳定、可审计的检索结果，为金融文档分析提供了实用解决方案。

Abstract: Financial question answering (QA) over long corporate filings requires evidence to satisfy strict constraints on entities, financial metrics, fiscal periods, and numeric values. However, existing LLM-based rerankers primarily optimize semantic relevance, leading to unstable rankings and opaque decisions on long documents. We propose FinCards, a structured reranking framework that reframes financial evidence selection as constraint satisfaction under a finance-aware schema. FinCards represents filing chunks and questions using aligned schema fields (entities, metrics, periods, and numeric spans), enabling deterministic field-level matching. Evidence is selected via a multi-stage tournament reranking with stability-aware aggregation, producing auditable decision traces. Across two corporate filing QA benchmarks, FinCards substantially improves early-rank retrieval over both lexical and LLM-based reranking baselines, while reducing ranking variance, without requiring model fine-tuning or unpredictable inference budgets. Our code is available at https://github.com/XanderZhou2022/FINCARDS.

</details>


### [20] [ReinPool: Reinforcement Learning Pooling Multi-Vector Embeddings for Retrieval System](https://arxiv.org/abs/2601.07125)
*Sungguk Cha,DongWook Kim,Mintae Kim,Youngsub Han,Byoung-Ki Jeon,Sangyeob Lee*

Main category: cs.IR

TL;DR: ReinPool使用强化学习动态筛选和池化多向量嵌入，将存储压缩746-1249倍，同时恢复76-81%的检索性能，相比静态平均池化提升22-33% NDCG@3。


<details>
  <summary>Details</summary>
Motivation: 多向量嵌入模型虽然能保留细粒度视觉和文本细节，但存储每个token的嵌入会使索引大小膨胀1000倍以上，严重限制可扩展性。需要一种方法在保持检索性能的同时大幅压缩表示。

Method: 提出ReinPool强化学习框架，通过逆检索目标和基于NDCG的奖励训练，动态筛选和池化多向量嵌入为紧凑的检索优化表示。该方法自动识别并保留最具区分性的向量，无需人工重要性标注。

Result: 在Vidore V2基准测试中，ReinPool将多向量表示压缩746-1249倍为单向量，恢复76-81%的全多向量检索性能。相比静态平均池化基线，NDCG@3绝对提升22-33%。

Conclusion: 学习型选择策略显著优于启发式聚合方法，ReinPool能够在保持检索性能的同时实现大规模压缩，解决了多向量嵌入模型的存储可扩展性问题。

Abstract: Multi-vector embedding models have emerged as a powerful paradigm for document retrieval, preserving fine-grained visual and textual details through token-level representations. However, this expressiveness comes at a staggering cost: storing embeddings for every token inflates index sizes by over $1000\times$ compared to single-vector approaches, severely limiting scalability. We introduce \textbf{ReinPool}, a reinforcement learning framework that learns to dynamically filter and pool multi-vector embeddings into compact, retrieval-optimized representations. By training with an inverse retrieval objective and NDCG-based rewards, ReinPool identifies and retains only the most discriminative vectors without requiring manual importance annotations. On the Vidore V2 benchmark across three vision-language embedding models, ReinPool compresses multi-vector representations by $746$--$1249\times$ into single vectors while recovering 76--81\% of full multi-vector retrieval performance. Compared to static mean pooling baselines, ReinPool achieves 22--33\% absolute NDCG@3 improvement, demonstrating that learned selection significantly outperforms heuristic aggregation.

</details>


### [21] [Towards Multi-Behavior Multi-Task Recommendation via Behavior-informed Graph Embedding Learning](https://arxiv.org/abs/2601.07294)
*Wenhao Lai,Weike Pan,Zhong Ming*

Main category: cs.IR

TL;DR: 提出BiGEL方法解决多行为多任务推荐问题，通过级联图范式结合三个关键模块提升各行为任务的推荐性能


<details>
  <summary>Details</summary>
Motivation: 现有多行为推荐方法主要关注目标行为（如购买）性能，但忽略了辅助行为（如点击、收藏）的推荐质量。现实场景需要同时处理多种行为类型并为每种行为生成个性化推荐列表，即多行为多任务推荐问题。

Method: 提出行为感知图嵌入学习（BiGEL）方法：1）使用级联图范式获得行为感知嵌入；2）级联门控反馈模块通过目标行为反馈优化辅助行为偏好；3）全局上下文增强模块整合全局上下文保持用户整体偏好；4）对比偏好对齐模块通过对比学习对齐目标行为偏好与全局偏好

Result: 在两个真实世界数据集上的广泛实验表明，BiGEL相比十种竞争方法具有显著优势

Conclusion: BiGEL通过级联图范式结合三个关键模块，有效解决了多行为多任务推荐问题，在提升目标行为性能的同时也改善了辅助行为的推荐质量

Abstract: Multi-behavior recommendation (MBR) aims to improve the performance w.r.t. the target behavior (i.e., purchase) by leveraging auxiliary behaviors (e.g., click, favourite). However, in real-world scenarios, a recommendation method often needs to process different types of behaviors and generate personalized lists for each task (i.e., each behavior type). Such a new recommendation problem is referred to as multi-behavior multi-task recommendation (MMR). So far, the most powerful MBR methods usually model multi-behavior interactions using a cascading graph paradigm. Although significant progress has been made in optimizing the performance of the target behavior, it often neglects the performance of auxiliary behaviors. To compensate for the deficiencies of the cascading paradigm, we propose a novel solution for MMR, i.e., behavior-informed graph embedding learning (BiGEL). Specifically, we first obtain a set of behavior-aware embeddings by using a cascading graph paradigm. Subsequently, we introduce three key modules to improve the performance of the model. The cascading gated feedback (CGF) module enables a feedback-driven optimization process by integrating feedback from the target behavior to refine the auxiliary behaviors preferences. The global context enhancement (GCE) module integrates the global context to maintain the user's overall preferences, preventing the loss of key preferences due to individual behavior graph modeling. Finally, the contrastive preference alignment (CPA) module addresses the potential changes in user preferences during the cascading process by aligning the preferences of the target behaviors with the global preferences through contrastive learning. Extensive experiments on two real-world datasets demonstrate the effectiveness of our BiGEL compared with ten very competitive methods.

</details>


### [22] [RLPO: Residual Listwise Preference Optimization for Long-Context Review Ranking](https://arxiv.org/abs/2601.07449)
*Hao Jiang,Zhi Yang,Annan Wang,Yichi Zhang,Weisi Lin*

Main category: cs.IR

TL;DR: RLPO提出了一种新的长上下文评论排序方法，通过结合点式评分和列表式残差修正，在保持计算效率的同时提升排序质量。


<details>
  <summary>Details</summary>
Motivation: 现有评论排序方法在长上下文场景下面临权衡：点式评分效率高但忽略列表级交互，导致top-k排序不准；列表式方法能利用全局上下文但计算昂贵且不稳定。需要一种兼顾效率和效果的方法。

Method: RLPO首先使用强大的点式LLM评分器生成校准的点式分数和项目表示，然后通过轻量级编码器在表示层面预测列表式分数残差，避免完整的token级列表式处理。

Result: 实验表明RLPO在NDCG@k指标上优于强大的点式和列表式基线方法，并且随着列表长度增加仍保持鲁棒性。

Conclusion: RLPO通过点式评分与列表式残差修正的结合，有效解决了长上下文评论排序中的效率与效果权衡问题，为大规模电商评论排序提供了实用解决方案。

Abstract: Review ranking is pivotal in e-commerce for prioritizing diagnostic and authentic feedback from the deluge of user-generated content. While large language models have improved semantic assessment, existing ranking paradigms face a persistent trade-off in long-context settings. Pointwise scoring is efficient but often fails to account for list-level interactions, leading to miscalibrated top-$k$ rankings. Listwise approaches can leverage global context, yet they are computationally expensive and become unstable as candidate lists grow. To address this, we propose Residual Listwise Preference Optimization (RLPO), which formulates ranking as listwise representation-level residual correction over a strong pointwise LLM scorer. RLPO first produces calibrated pointwise scores and item representations, then applies a lightweight encoder over the representations to predict listwise score residuals, avoiding full token-level listwise processing. We also introduce a large-scale benchmark for long-context review ranking with human verification. Experiments show RLPO improves NDCG@k over strong pointwise and listwise baselines and remains robust as list length increases.

</details>


### [23] [Loci Similes: A Benchmark for Extracting Intertextualities in Latin Literature](https://arxiv.org/abs/2601.07533)
*Julian Schelb,Michael Wittweiler,Marie Revellio,Barbara Feichtinger,Andreas Spitz*

Main category: cs.IR

TL;DR: 该论文介绍了Loci Similes基准数据集，用于拉丁语互文性检测，包含约17.2万文本片段和545个专家验证的互文链接，为基于语言模型的互文性研究提供了标准化评估框架。


<details>
  <summary>Details</summary>
Motivation: 历史文本间的互文连接研究对重建作者虚拟图书馆和识别创作来源很重要，但目前缺乏标准化基准和易用数据集，阻碍了新方法的发展。

Method: 创建Loci Similes基准数据集，包含约172k拉丁语文本片段和545个专家验证的互文链接，涵盖晚期古典作者与古典作者之间的互文关系，并基于最先进的语言模型建立检索和分类基线。

Result: 建立了包含大量文本片段和专家验证互文链接的标准化数据集，为拉丁语互文性检测提供了可靠的评估基准，并展示了语言模型在该任务上的基线性能。

Conclusion: Loci Similes基准填补了拉丁语互文性研究的数据空白，为基于语言模型的互文性检测方法发展提供了重要基础设施，有助于推动该领域的研究进展。

Abstract: Tracing connections between historical texts is an important part of intertextual research, enabling scholars to reconstruct the virtual library of a writer and identify the sources influencing their creative process. These intertextual links manifest in diverse forms, ranging from direct verbatim quotations to subtle allusions and paraphrases disguised by morphological variation. Language models offer a promising path forward due to their capability of capturing semantic similarity beyond lexical overlap. However, the development of new methods for this task is held back by the scarcity of standardized benchmarks and easy-to-use datasets. We address this gap by introducing Loci Similes, a benchmark for Latin intertextuality detection comprising of a curated dataset of ~172k text segments containing 545 expert-verified parallels linking Late Antique authors to a corpus of classical authors. Using this data, we establish baselines for retrieval and classification of intertextualities with state-of-the-art LLMs.

</details>


### [24] [GAP-Net: Calibrating User Intent via Gated Adaptive Progressive Learning for CTR Prediction](https://arxiv.org/abs/2601.07613)
*Ke Shenqiang,Wei Jianxiong,Hua Qingsong*

Main category: cs.IR

TL;DR: GAP-Net提出三重门控架构解决CTR预测中的注意力沉没、静态查询假设和刚性视图聚合三大瓶颈，通过稀疏门控注意力、级联查询校准和上下文门控融合实现噪声抑制和意图对齐。


<details>
  <summary>Details</summary>
Motivation: 解决CTR预测中序列用户行为建模的三个核心瓶颈：1) 注意力沉没现象（Softmax将概率分配给噪声行为）；2) 静态查询假设（忽略实时上下文驱动的用户意图动态变化）；3) 刚性视图聚合（无法根据决策上下文自适应加权异质时序信号）。

Method: 提出GAP-Net统一框架，采用"三重门控"架构：1) 自适应稀疏门控注意力（ASGA）进行微观级门控实现稀疏化，抑制噪声激活；2) 门控级联查询校准（GCQC）通过中观级级联通道动态对齐用户意图，桥接实时触发和长期记忆；3) 上下文门控去噪融合（CGDF）进行宏观级调制，协调多视图序列的聚合。

Result: 在工业数据集上的大量实验表明，GAP-Net相比最先进的基线方法取得了显著改进，在交互噪声和意图漂移方面表现出优越的鲁棒性。

Conclusion: GAP-Net通过三重门控架构有效解决了CTR预测中的三个关键瓶颈，实现了从微观特征到宏观视图的渐进式信息精炼，为序列用户行为建模提供了统一且鲁棒的解决方案。

Abstract: Sequential user behavior modeling is pivotal for Click-Through Rate (CTR) prediction yet is hindered by three intrinsic bottlenecks: (1) the "Attention Sink" phenomenon, where standard Softmax compels the model to allocate probability mass to noisy behaviors; (2) the Static Query Assumption, which overlooks dynamic shifts in user intent driven by real-time contexts; and (3) Rigid View Aggregation, which fails to adaptively weight heterogeneous temporal signals according to the decision context. To bridge these gaps, we propose GAP-Net (Gated Adaptive Progressive Network), a unified framework establishing a "Triple Gating" architecture to progressively refine information from micro-level features to macro-level views. GAP-Net operates through three integrated mechanisms: (1) Adaptive Sparse-Gated Attention (ASGA) employs micro-level gating to enforce sparsity, effectively suppressing massive noise activations; (2) Gated Cascading Query Calibration (GCQC) dynamically aligns user intent by bridging real-time triggers and long-term memories via a meso-level cascading channel; and (3) Context-Gated Denoising Fusion (CGDF) performs macro-level modulation to orchestrate the aggregation of multi-view sequences. Extensive experiments on industrial datasets demonstrate that GAP-Net achieves substantial improvements over state-of-the-art baselines, exhibiting superior robustness against interaction noise and intent drift.

</details>


### [25] [AptaFind: A lightweight local interface for automated aptamer curation from scientific literature](https://arxiv.org/abs/2601.07684)
*Geoffrey Taghon*

Main category: cs.IR

TL;DR: AptaFind是一个用于加速适配体研究的智能文献挖掘平台，通过三层架构提供序列提取、研究线索和文献发现，显著提高研究效率


<details>
  <summary>Details</summary>
Motivation: 适配体研究人员面临文献分散、搜索耗时的问题，需要花费大量时间在不同出版物、补充材料和数据库中搜索信息，这些时间本可用于实验工作

Method: 采用三层智能架构：1) 直接序列提取；2) 当提取失败时提供策划的研究线索；3) 全面的文献发现以增加置信度。结合本地语言模型进行语义理解和确定性算法确保可靠性，无需云依赖或订阅障碍

Result: 在300个德克萨斯大学适配体数据库目标上验证：84%找到相关文献，84%获得策划研究线索，79%实现直接序列提取，笔记本电脑计算速度超过900个目标/小时

Conclusion: 即使直接序列提取失败，自动化仍能通过快速缩小搜索范围到高质量参考文献，为研究人员提供可操作的情报，证明文献挖掘是一个连续谱而非二元成功/失败

Abstract: Aptamer researchers face a literature landscape scattered across publications, supplements, and databases, with each search consuming hours that could be spent at the bench. AptaFind transforms this navigation problem through a three-tier intelligence architecture that recognizes research mining is a spectrum, not a binary success or failure. The system delivers direct sequence extraction when possible, curated research leads when extraction fails, and exhaustive literature discovery for additional confidence. By combining local language models for semantic understanding with deterministic algorithms for reliability, AptaFind operates without cloud dependencies or subscription barriers. Validation across 300 University of Texas Aptamer Database targets demonstrates 84 % with some literature found, 84 % with curated research leads, and 79 % with a direct sequence extraction, at a laptop-compute rate of over 900 targets an hour. The platform proves that even when direct sequence extraction fails, automation can still deliver the actionable intelligence researchers need by rapidly narrowing the search to high quality references.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [26] [Context Video Semantic Transmission with Variable Length and Rate Coding over MIMO Channels](https://arxiv.org/abs/2601.06059)
*Bingyan Xie,Yongpeng Wu,Wenjun Zhang,Derrick Wing Kwan Ng,Merouane Debbah*

Main category: cs.IT

TL;DR: 提出CVST框架，在MIMO信道下实现视频语义传输，通过上下文-信道关联映射和多参考熵编码机制，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信方案主要针对简单信道（AWGN或Rayleigh衰落）优化，忽略了实际部署中普遍存在的MIMO环境，这严重阻碍了实用化部署。

Method: 提出CVST框架：1) 学习上下文-信道关联映射，显式建模特征组与MIMO子信道关系；2) 设计多参考熵编码机制，实现信道状态感知的变长编码；3) 采用棋盘式特征调制策略，在单一训练模型中实现多码率点。

Result: CVST在各种标准化分离编码方法和近期无线视频语义通信方法上表现出显著的性能提升。

Conclusion: CVST框架有效解决了MIMO环境下的视频语义传输问题，通过上下文-信道关联和多参考变长码率编码机制，实现了实用化部署的灵活性和性能优势。

Abstract: The evolution of semantic communications has profoundly impacted wireless video transmission, whose applications dominate driver of modern bandwidth consumption. However, most existing schemes are predominantly optimized for simple additive white Gaussian noise or Rayleigh fading channels, neglecting the ubiquitous multiple-input multiple-output (MIMO) environments that critically hinder practical deployment. To bridge this gap, we propose the context video semantic transmission (CVST) framework under MIMO channels. Building upon an efficient contextual video transmission backbone, CVST effectively learns a context-channel correlation map to explicitly formulate the relationships between feature groups and MIMO subchannels. Leveraging these channel-aware features, we design a multi-reference entropy coding mechanism, enabling channel state-aware variable length coding. Furthermore, CVST incorporates a checkerboard-based feature modulation strategy to achieve multiple rate points within a single trained model, thereby enhancing deployment flexibility. These innovations constitute our multi-reference variable length and rate coding (MR-VLRC) scheme. By integrating contextual transmission with MR-VLRC, CVST demonstrates substantial performance gains over various standardized separated coding methods and recent wireless video semantic communication approaches. The code is available at https://github.com/xie233333/CVST.

</details>


### [27] [Jamming Detection in Cell-Free MIMO with Dynamic Graphs](https://arxiv.org/abs/2601.06075)
*Ali Hossary,Laura Crosara,Stefano Tomasin*

Main category: cs.IT

TL;DR: 提出基于动态图和图卷积神经网络的干扰检测框架，用于无蜂窝大规模MIMO系统中的干扰攻击检测


<details>
  <summary>Details</summary>
Motivation: 干扰攻击对无线网络构成严重威胁，特别是在无蜂窝大规模MIMO系统中，分布式接入点和用户设备形成复杂时变拓扑，需要有效的检测方法

Method: 将网络建模为动态图以捕捉通信链路演化，使用GCN-Transformer模型学习图嵌入，通过监督学习识别恶意干扰

Result: 在模拟场景中评估性能，包括移动用户设备、不同干扰条件和信道衰落，通过准确率和F1分数指标展示了方法的有效性

Conclusion: 提出的动态图与GCN结合的方法能够有效检测无蜂窝大规模MIMO系统中的干扰攻击，取得了有前景的结果

Abstract: Jamming attacks pose a critical threat to wireless networks, particularly in cell-free massive MIMO systems, where distributed access points and user equipment (UE) create complex, time-varying topologies. This paper proposes a novel jamming detection framework leveraging dynamic graphs and graph convolutional neural networks (GCN) to address this challenge. By modeling the network as a dynamic graph, we capture evolving communication links and detect jamming attacks as anomalies in the graph evolution. A GCN-Transformer-based model, trained with supervised learning, learns graph embeddings to identify malicious interference. Performance evaluation in simulated scenarios with moving UEs, varying jamming conditions and channel fadings, demonstrates the method's effectiveness, which is assessed through accuracy and F1 score metrics, achieving promising results for effective jamming detection.

</details>


### [28] [One if by Land, Two if by Sea, Three if by Four Seas, and More to Come -- Values of Perception, Prediction, Communication, and Common Sense in Decision Making](https://arxiv.org/abs/2601.06077)
*Aolin Xu*

Main category: cs.IT

TL;DR: 该论文为决策中的感知、预测、通信和常识价值提供了严格的决策论定义，这些定义具有信息论类比，并揭示了感知与预测结合的重要性。


<details>
  <summary>Details</summary>
Motivation: 为自主决策系统设计中的实际问题提供理论基础，如是否需要观察和预测特定代理的行为、其重要性如何、以及观察和预测的最佳顺序等。同时为认知科学和神经科学提供见解，理解自然决策者如何利用不同来源和操作的信息。

Method: 采用决策论框架严格定义感知、预测、通信和常识的价值，这些定义具有信息论类比，与香农熵和互信息共享关键数学特性，并在特定设置下可简化为这些信息量。

Result: 发现无预测的感知价值可能为负，而感知与预测结合的价值以及单独预测的价值总是非负。这些定义为自主决策系统设计提供了量化指导，并揭示了信息处理顺序的重要性。

Conclusion: 该研究为决策中的信息价值提供了严格的数学框架，不仅有助于自主系统的设计优化，也为理解自然决策过程提供了理论工具，强调了预测在信息处理中的关键作用。

Abstract: This work aims to rigorously define the values of perception, prediction, communication, and common sense in decision making. The defined quantities are decision-theoretic, but have information-theoretic analogues, e.g., they share some simple but key mathematical properties with Shannon entropy and mutual information, and can reduce to these quantities in particular settings. One interesting observation is that, the value of perception without prediction can be negative, while the value of perception together with prediction and the value of prediction alone are always nonnegative. The defined quantities suggest answers to practical questions arising in the design of autonomous decision-making systems. Example questions include: Do we need to observe and predict the behavior of a particular agent? How important is it? What is the best order to observe and predict the agents? The defined quantities may also provide insights to cognitive science and neural science, toward the understanding of how natural decision makers make use of information gained from different sources and operations.

</details>


### [29] [Deep Q-Network Based Resilient Drone Communication:Neutralizing First-Order Markov Jammers](https://arxiv.org/abs/2601.06095)
*Andrii Grekhov,Volodymyr Kharchenko,Vasyl Kondratiuk*

Main category: cs.IT

TL;DR: 基于深度强化学习的抗干扰通信方案，使用跳频扩频技术，通过DQN智能体学习均匀随机跳频策略来对抗预测性干扰


<details>
  <summary>Details</summary>
Motivation: 现代电子战场景中需要自主弹性通信系统，传统跳频技术面临预测性干扰的威胁，需要智能抗干扰策略

Method: 采用深度Q网络（DQN）的发射机在16信道环境中连续选择跳频信道，对抗一阶反应式干扰；通过自训练学习均匀随机跳频策略；结合BCH前向纠错码评估抗干扰性能

Result: 智能体成功学习到有效中和干扰预测优势的策略；即使中等冗余度的BCH码也能显著减少丢包率；在瑞利衰落和加性噪声环境下验证了方案的鲁棒性

Conclusion: 该深度强化学习框架为现代电子战场景提供了实用的自主弹性通信解决方案，能够有效对抗预测性干扰

Abstract: Deep Reinforcement Learning based solution for jamming communications using Frequency Hopping Spread Spectrum technology in a 16 channel radio environment is presented. Deep Q Network based transmitter continuously selects the next frequency hopping channel while facing first order reactive jamming, which uses observed transition statistics to predict and interrupt transmissions. Through self training, the proposed agent learns a uniform random frequency hopping policy that effectively neutralizes the predictive advantage of the jamming. In the presence of Rayleigh fading and additive noise, the impact of forward error correction Bose Chaudhuri Hocquenghem type codes is systematically evaluated, demonstrating that even moderate redundancy significantly reduces packet loss. Extensive visualization of the learning dynamics, channel utilization distribution, epsilon greedy decay, cumulative reward, BER and SNR evolution, and detailed packet loss tables confirms convergence to a near optimal jamming strategy. The results provide a practical framework for autonomous resilient communications in modern electronic warfare scenarios.

</details>


### [30] [Optimal Beamforming for Uplink Covert Communication in MIMO GEO Satellite-Terrestrial Systems](https://arxiv.org/abs/2601.06110)
*Zewei Guo,Ranran Sun,Yulong Shen,Xiaohong Jiang*

Main category: cs.IT

TL;DR: 该论文研究了MIMO卫星地面系统中上行链路隐蔽通信，通过波束成形和天线方向优化来最大化隐蔽速率，考虑了完美和不完美信道估计两种场景。


<details>
  <summary>Details</summary>
Motivation: 随着卫星通信的普及，卫星链路上的隐蔽通信需求日益增长。在存在多个卫星监视器的情况下，如何实现可靠的上行链路隐蔽传输是一个重要挑战。论文旨在通过优化波束成形和天线方向来提升MIMO卫星地面系统的隐蔽通信性能。

Method: 1. 提出基于波束成形和默认天线方向的Alice-Bob上行隐蔽传输方案
2. 在完美信道估计场景下，建立检测错误概率、传输中断概率和隐蔽速率的理论模型
3. 设计最优波束成形以及联合最优波束成形和天线方向优化方案
4. 扩展到不完美信道估计场景，进行相关性能建模和优化设计
5. 应用半定松弛、交替优化、罗德里格斯旋转公式和一维搜索算法求解优化问题

Result: 1. 建立了MIMO卫星地面系统上行隐蔽通信的理论性能模型
2. 开发了高效的优化算法解决波束成形和天线方向设计问题
3. 数值结果表明所提方案能有效支持MIMO GEO卫星地面系统的上行隐蔽通信
4. 验证了波束成形和天线方向设计对提升隐蔽通信性能的重要性

Conclusion: 该论文成功解决了MIMO卫星地面系统中的上行隐蔽通信问题，通过优化波束成形和天线方向设计，在存在多个卫星监视器的情况下实现了隐蔽速率最大化。所提方案和算法为卫星隐蔽通信提供了有效的技术解决方案。

Abstract: This paper investigates the uplink covert communication in a multiple-input multiple-output (MIMO) satellite-terrestrial system consisting of an Earth station transmitter Alice, a geosynchronous Earth orbit (GEO) satellite receiver Bob, and multiple GEO satellite wardens around Bob, where each node in the system is equipped with an array of directional antennas. Based on beamforming and the default antenna orientation setting, we first propose a scheme for covert Alice-Bob uplink transmission. Under the perfect channel estimation scenario, we provide theoretical modeling for the system performance in terms of detection error probability (DEP), transmission outage probability (TOP) and covert rate (CR), and then explore the optimal beamforming (OB) design as well as the joint optimal beamforming and antenna orientation (JO-BA) design for CR maximization. We then extend our study to the imperfect channel estimation scenario, and conduct related performance modeling and OB/JO-BA designs for CR maximization. We also apply the techniques of semidefinite relaxation, alternating optimization, Rodrigues' rotation formula and 1-D search algorithm to develop efficient algorithms to solve the above optimization problems. Finally, extensive numerical results are presented to verify our theoretical results and to illustrate the efficiency of beamforming and antenna orientation design for supporting the uplink covert communication in MIMO GEO satellite-terrestrial systems.

</details>


### [31] [Range-Coder with fast Adaptation and Table-Based Decoding](https://arxiv.org/abs/2601.06120)
*Tilo Strutz,Roman Rischke*

Main category: cs.IT

TL;DR: 提出一种基于环形缓冲区的自适应表解码方法，通过位运算替代除法，显著加速区间编码过程


<details>
  <summary>Details</summary>
Motivation: 传统区间编码方法中，解码器的符号确定需要搜索过程，虽然可以用O(1)复杂度的表方法替代，但符号统计的自适应更新因表调整耗时而不切实际

Method: 采用环形缓冲区技术实现自适应表解码过程，同时在编码器和解码器核心例程中用位运算替代除法操作

Result: 静态模式下编码时间减少约40%；自适应模式下，对于12-64个符号的字母表，整体编码+解码时间比其他方法更快

Conclusion: 提出的环形缓冲区自适应表解码方法能显著加速区间编码过程，在静态和自适应模式下都表现出优越性能

Abstract: The transmission or storage of signals typically involves data compression. The final processing step in compression systems is generally an entropy coding stage, which converts symbols into a bit stream based on their probability distribution. A distinct class of entropy coding methods operates not by mapping input symbols to discrete codewords but by operating on intervals or ranges. This approach enables a more accurate approximation of the source entropy, particularly for sources with highly skewed or varying symbol distributions. Representative techniques in this category include traditional arithmetic coding, range coding, and methods based on asymmetric numeral systems (ANS). The complexity of these methods depends mainly on three processing steps: the core routines of encoding and decoding doing the calculations, the interval-based determination of the correct symbol at decoder, and the efforts of keeping updated with respect to the varying symbol distribution.
  The interval-based symbol determination at decoder typically demands for a searching procedure. In previous literature, it could be shown that the search can be replaced by a table-based approach with only O(1)-complexity but having the side-effect that the adaptation of the symbols statistic becomes infeasible because of the high time-consumption of adapting the table.
  We propose an adaptation process using a ring-buffer technique enabling the adaptive table-based decoding procedure as well as the replacement of a division by a bit-shift operation at encoder and decoder core routines. This accelerates the coding process significantly. In static (non-adaptive) mode, the coding time can be reduced by about 40 percent. In adaptive mode, the proposed technique is faster than alternative approaches for alphabets from about 12 to 64 different symbol when comparing the overall encoder+decoder time.

</details>


### [32] [Extended Target Adaptive Beamforming for ISAC:A Perspective of Predictive Error Ellipse](https://arxiv.org/abs/2601.06125)
*Shengcai Zhou,Luping Xiang,Yi Wang,Kun Yang,Kai Kit Wong,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 该论文推导了OFDM波形和UPA配置下雷达参数估计的CRB，并针对NR-V2X通信提出了两种波束赋形方案：基于预测误差椭圆并集的初始波束建立方案，以及利用散射体和通信接收机位置的自适应最窄波束调整策略。


<details>
  <summary>Details</summary>
Motivation: 利用通信信号提取运动参数已成为V2X网络的关键方向。准确建模通信信号与感知性能之间的关系对这类系统的发展至关重要。现有工作主要依赖定性分析，缺乏定量性能界限。

Method: 1. 推导OFDM波形和UPA配置下雷达参数估计的Cramér-Rao界；2. 提出两种NR-V2X兼容的波束赋形方案：初始波束建立阶段采用基于预测误差椭圆并集的方案，通过时间辅助波束训练增强散射体定位；波束调整阶段采用自适应最窄波束策略，利用散射体和通信接收机位置进行有效跟踪；3. 使用最小包围椭圆算法和定制天线控制方法解决波束设计问题。

Result: 仿真验证了所提方法的有效性：在相同SNR条件下，与传统的波束扫描相比，32*32发射天线阵列可实现率提升达32.4%，8*8阵列提升5.2%。

Conclusion: 该研究为V2X网络中的通信感知一体化提供了理论性能界限和实用的波束赋形方案，显著提升了系统性能，特别是在大规模天线阵列配置下效果更为明显。

Abstract: Utilizing communication signals to extract motion parameters has emerged as a key direction in Vehicle-to- Everything (V2X) networks. Accurately modeling the relationship between communication signals and sensing performance is critical for the advancement of such systems. Unlike prior work that relies primarily on qualitative analysis, this paper derives the Cramér-Rao Bound (CRB) for radar parameter estimation in the context of Orthogonal Frequency Division Multiplexing (OFDM) waveforms and Uniform Planar Array (UPA) configurations. Recognizing that vehicles may act as extended targets, we propose two New Radio (NR)-V2X-compatible beamforming schemes tailored to different phases of the communication process. During the initial beam establishment phase, we develop a beamforming approach based on the union of predictive error ellipses, which enhances scatterer localization through temporally assisted beam training. In the beam adjustment phase, we introduce an adaptive narrowest-beam strategy that leverages the positions of scatterers and the communication receiver (CR), enabling effective tracking with reduced complexity. The beam design problem is addressed using the minimum enclosing ellipse algorithm and tailored antenna control methods. Simulation results validate the proposed approach, showing up to a 32.4% improvement in achievable rate with a 32*32 transmit antenna array and a 5.2% gain with an 8*8 array, compared to conventional beam sweeping under identical SNR conditions.

</details>


### [33] [Channel Knowledge Map Construction via Guided Flow Matching](https://arxiv.org/abs/2601.06156)
*Ziyu Huang,Yong Zeng,Shen Fu,Xiaoli Xu,Hongyang Du*

Main category: cs.IT

TL;DR: 提出基于线性传输引导流匹配(LT-GFM)的CKM构建框架，相比扩散模型大幅提升推理速度25倍，同时保持高保真度


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的CKM构建方法依赖迭代随机采样，推理速度过慢，无法满足实时无线应用需求

Method: 采用线性最优传输路径的确定性ODE建模，提出统一架构支持CGM和SCM构建，集成环境语义和Hermitian对称性约束

Result: LT-GFM在FID指标上表现更优，推理速度比DDPM快25倍，能有效构建高保真CKM

Conclusion: LT-GFM框架成功解决了CKM构建中高保真与高效率的矛盾，为实时环境感知无线网络提供了可行方案

Abstract: The efficient construction of accurate channel knowledge maps (CKMs) is crucial for unleashing the full potential of environment-aware wireless networks, yet it remains a difficult ill-posed problem due to the sparsity of available location-specific channel knowledge data. Although diffusion-based methods such as denoising diffusion probabilistic models (DDPMs) have been exploited for CKM construction, they rely on iterative stochastic sampling, rendering them too slow for real-time wireless applications. To bridge the gap between high fidelity and efficient CKM construction, this letter introduces a novel framework based on linear transport guided flow matching (LT-GFM). Deviating from the noise-removal paradigm of diffusion models, our approach models the CKM generation process as a deterministic ordinary differential equation (ODE) that follows linear optimal transport paths, thereby drastically reducing the number of required inference steps. We propose a unified architecture that is applicable to not only the conventional channel gain map (CGM) construction, but also the more challenging spatial correlation map (SCM) construction. To achieve physics-informed CKM constructions, we integrate environmental semantics (e.g., building masks) for edge recovery and enforce Hermitian symmetry for property of the SCM. Simulation results verify that LT-GFM achieves superior distributional fidelity with significantly lower Fréchet Inception Distance (FID) and accelerates inference speed by a factor of 25 compared to DDPMs.

</details>


### [34] [Large Multimodal Model-Aided Scheduling for 6G Autonomous Communications](https://arxiv.org/abs/2601.06211)
*Sunwoo Kim,Byonghyo Shim*

Main category: cs.IT

TL;DR: 提出基于大型多模态模型(LMM)的调度技术，利用视觉传感信息和导频信号预测未来信道参数，实现预判性调度决策，在6G环境中获得超过30%的吞吐量增益。


<details>
  <summary>Details</summary>
Motivation: 随着AI功能在自主设备中的指数级增长，中央处理单元需要处理大型多模态模型来控制这些设备。在6G环境中，用户微小移动可能导致信道突变，传统调度技术难以应对这种挑战。

Method: 利用LMM分析视觉传感信息和导频信号，预测未来信道参数（距离、角度、路径增益等）。通过LMM从视觉信息中预测可靠路径存在和用户几何信息，结合导频信号的过去信道状态，准确预测未来信道参数，从而做出预判性的信道感知调度决策。

Result: 数值评估显示，所提出的技术相比传统调度技术实现了超过30%的吞吐量增益。

Conclusion: 基于LMM的调度技术能够有效应对6G环境中信道突变挑战，通过预判性调度显著提升系统吞吐量性能。

Abstract: Recently, large language models (LLMs) have gained significant attention for their ability to generate fast and accurate answer to the given query. These models have evolved into large multimodal models (LMMs), which can interpret and analyze multimodal inputs such as images and text. With the exponential growth of AI functionalities in autonomous devices, the central unit (CU), a digital processing unit performing AI inference, needs to handle LMMs to effectively control these devices. To ensure seamless command delivery to devices, the CU must perform the scheduling, which involves resource block (RB) allocation for data transmission and modulation and coding scheme (MCS) index selection based on the channel conditions. This task is challenging in many practical environments in 6G, where even small user movement can cause abrupt channel changes. In this paper, we propose a novel LMM-based scheduling technique to address this challenge. Our key idea is to leverage LMM to predict future channel parameters (e.g., distance, angles, and path gain) by analyzing the visual sensing information as well as pilot signals. By exploiting LMMs to predict the presence of reliable path and geometric information of users from the visual sensing information, and then combining these with past channel states from pilot signals, we can accurately predict future channel parameters. Using these predictions, we can preemptively make channel-aware scheduling decisions. From the numerical evaluations, we show that the proposed technique achieves more than 30% throughput gain over the conventional scheduling techniques.

</details>


### [35] [Robust and Secure Blockage-Aware Pinching Antenna-assisted Wireless Communication](https://arxiv.org/abs/2601.06430)
*Ruotong Zhao,Shaokang Hu,Deepak Mishra,Derrick Wing Kwan Ng*

Main category: cs.IT

TL;DR: 提出一种抗阻塞的捏合天线系统，通过联合优化波束成形、人工噪声、天线功率分配和位置，在信道状态信息不完美情况下提升安全无线通信的系统和速率。


<details>
  <summary>Details</summary>
Motivation: 传统线性CSI误差边界对空间分布天线架构过于保守，且现有系统未充分考虑阻塞效应，导致性能下降和安全保障不足。

Method: 开发几何感知的不确定性集合来联合表征窃听者位置和阵列方向误差，采用块坐标下降、惩罚方法、主化最小化、S-过程和Lipschitz基代理函数等技术的低复杂度迭代算法。

Result: 所提算法相比传统固定天线系统提升4.7dB的和速率，自适应天线位置能保持对合法用户的视距连接，同时利用波导几何破坏窃听者信道。

Conclusion: 阻塞效应在捏合天线系统设计中至关重要，忽略该效应会导致性能下降和安全保障不足，所提方法能有效提升安全通信性能。

Abstract: In this work, we investigate a blockage-aware pinching antenna (PA) system designed for secure and robust wireless communication. The considered system comprises a base station equipped with multiple waveguides, each hosting multiple PAs, and serves multiple single-antenna legitimate users in the presence of multi-antenna eavesdroppers under imperfect channel state information (CSI). To safeguard confidential transmissions, artificial noise (AN) is deliberately injected to degrade the eavesdropping channels. Recognizing that conventional linear CSI-error bounds become overly conservative for spatially distributed PA architectures, we develop new geometry-aware uncertainty sets that jointly characterize eavesdroppers position and array-orientation errors. Building upon these sets, we formulate a robust joint optimization problem that determines per-waveguide beamforming and AN covariance, individual PA power-ratio allocation, and PA positions to maximize the system sum rate subject to secrecy constraints. The highly non-convex design problem is efficiently addressed via a low computational complexity iterative algorithm that capitalizes on block coordinate descent, penalty-based methods, majorization-minimization, the S-procedure, and Lipschitz-based surrogate functions. Simulation results demonstrate that sum rates for the proposed algorithm outperforms conventional fixed antenna systems by 4.7 dB, offering substantially improved rate and secrecy performance. In particular, (i) adaptive PA positioning preserves LoS to legitimate users while effectively exploiting waveguide geometry to disrupt eavesdropper channels, and (ii) neglecting blockage effects in the PA system significantly impacts the system design, leading to performance degradation and inadequate secrecy guarantees.

</details>


### [36] [Error correction methods based on two-faced processes](https://arxiv.org/abs/2601.06447)
*Boris Ryabko*

Main category: cs.IT

TL;DR: 提出一种通过增加符号间相互依赖性来增强信道纠错能力的新方法，编码和解码复杂度为线性


<details>
  <summary>Details</summary>
Motivation: 传统信道纠错方法可能无法充分利用符号间的相互依赖性，需要一种能显著提高纠错性能同时保持低复杂度的新方法

Method: 通过变换输入序列显著增加符号间的相互依赖性，在信道传输后利用这种特性进行纠错，编码和解码复杂度均为线性

Result: 剩余错误率显著降低，同时保持了线性的编码和解码复杂度

Conclusion: 提出的新方法通过增强符号间相互依赖性有效提高了信道纠错性能，在保持线性复杂度的情况下显著降低了错误率

Abstract: A new approach to the problem of error correction in communication channels is proposed, in which the input sequence is transformed in such a way that the interdependence of symbols is significantly increased. Then, after the sequence is transmitted over the channel, this property is used for error correction so that the remaining error rate is significantly reduced. The complexity of encoding and decoding is linear.

</details>


### [37] [Function-Correcting Partition codes](https://arxiv.org/abs/2601.06450)
*Charul Rajput,B. Sundar Rajan,Ragnar Freij-Hollanti,Camilla Hollanti*

Main category: cs.IT

TL;DR: 本文提出了函数校正划分码(FCPCs)，作为函数校正码(FCCs)的自然推广，通过划分域来构造能同时保护多个函数的编码方案。


<details>
  <summary>Details</summary>
Motivation: 现有的函数校正码(FCCs)只能保护单个函数，而实际应用中通常需要同时保护多个函数。为了更高效地利用带宽，需要一种能够同时保护多个函数的编码方案。

Method: 1. 引入函数校正划分码(FCPCs)，直接在域划分上定义编码；2. 使用划分的连接构造能同时保护多个函数的单一编码；3. 定义划分冗余增益和划分率增益来衡量带宽节省；4. 针对线性函数，通过核的交集的陪集划分进行专门处理；5. 建立划分图理论，通过寻找合适团来达到最优冗余；6. 引入块保持收缩概念来简化寻找最优冗余的问题。

Result: 1. 证明了FCPCs是FCCs的自然推广；2. 展示了如何构造能同时保护多个函数的单一编码；3. 在权重划分和支持划分的划分图中证明了全尺寸团的存在；4. 提出的方法能提供部分隐私保护，因为只需要向发送者揭示函数的域划分。

Conclusion: FCPCs为同时保护多个函数提供了有效的编码框架，相比为每个函数单独构造FCCs能显著节省带宽，同时提供了一定程度的隐私保护。该方法在编码理论和实际应用中都很有价值。

Abstract: We introduce function-correcting partition codes (FCPCs) that are a natural generalization of function-correcting codes (FCCs). A $t$-error function-correcting partition code is an $(\mathcal{P},t)$-encoding defined directly on a partition $\mathcal{P}$ of $\mathbb{F}_q^k$. For a partition $\mathcal{P}=\{P_1,P_2,\ldots,P_E\}$ a systematic mapping $\mathcal{C}_{\mathcal{P}} : \mathbb{F}_q^k \rightarrow \mathbb{F}_q^{k+r}$ is called a \emph{$(\mathcal{P},t)$-encoding} if for all $u\in P_i$ and $v\in P_j$ with $i\neq j$, $d\big(\mathcal{C}_{\mathcal{P}}(u), \mathcal{C}_{\mathcal{P}}(v)\big)\ge 2t+1.$ We show that any $t$-error correcting code for a function $f$, denoted by $(f,t)$-FCC is exactly an FCPC with respect to the domain partition induced by $f$, which makes these codes a natural generalization of FCCs. We use the join of domain partitions to construct a single code that protects multiple functions simultaneously. We define the notion of partition redundancy gain and partition rate gain to measure the bandwidth saved by using a single FCPC for multiple functions instead of constructing separate FCCs for each function. We specialize this to linear functions via coset partition of the intersection of their kernels. Then, we associate a partition graph to any given partition of $\mathbb{F}_q^k$, and show that the existence of a suitable clique in this graph yields a set of representative information vectors that achieves the optimal redundancy. We showed the existence of a full-size clique in the partition graphs of weight partition and support partition. Finally, we introduce the notion of a block-preserving contraction for a partition, which helps reduce the problem of finding optimal redundancy for an FCPC. We observe that FCPCs naturally provide a form of partial privacy, in the sense that only the domain partition of the function needs to be revealed to the transmitter.

</details>


### [38] [Algorithms for Computing the Petz-Augustin Capacity](https://arxiv.org/abs/2601.06492)
*Chun-Neng Chu,Wei-Fu Tseng,Yen-Huan Li*

Main category: cs.IT

TL;DR: 提出了首个具有非渐进收敛保证的算法来计算Petz-Augustin容量，该容量推广了信道容量并刻画了经典-量子信道编码中的最优错误指数。


<details>
  <summary>Details</summary>
Motivation: Petz-Augustin容量是经典-量子信道编码中关键的性能指标，但之前缺乏具有非渐进收敛保证的高效计算算法。该容量可以表示为两种互信息推广形式的最大化问题，需要开发有效的优化方法。

Method: 针对Petz-Rényi信息最大化，将其建模为凸Hölder-光滑优化问题，应用Nesterov的通用快速梯度法。针对Petz-Augustin信息最大化，采用双层方法：证明目标函数相对于负香农熵是光滑的，可用熵镜像下降法优化；每次迭代需要计算Petz-Augustin信息，为此提出了基于Thompson度量的收缩性定点算法。

Result: 为Petz-Augustin容量计算提供了首个具有非渐进收敛保证的算法，将Blahut-Arimoto算法的镜像下降解释推广到量子信息论领域。

Conclusion: 该工作填补了经典-量子信道编码中关键容量计算的理论空白，为量子信息处理提供了实用的数值工具，并建立了量子信息论与经典优化理论之间的新联系。

Abstract: We propose the first algorithms with non-asymptotic convergence guarantees for computing the Petz-Augustin capacity, which generalizes the channel capacity and characterizes the optimal error exponent in classical-quantum channel coding. This capacity can be equivalently expressed as the maximization of two generalizations of mutual information: the Petz-Rényi information and the Petz-Augustin information. To maximize the Petz-Rényi information, we show that it corresponds to a convex Hölder-smooth optimization problem, and hence the universal fast gradient method of Nesterov (2015), along with its convergence guarantees, readily applies. Regarding the maximization of the Petz-Augustin information, we adopt a two-layered approach: we show that the objective function is smooth relative to the negative Shannon entropy and can be efficiently optimized by entropic mirror descent; each iteration of entropic mirror descent requires computing the Petz-Augustin information, for which we propose a novel fixed-point algorithm and establish its contractivity with respect to the Thompson metric. Notably, this two-layered approach can be viewed as a generalization of the mirror-descent interpretation of the Blahut-Arimoto algorithm due to He et al. (2024).

</details>


### [39] [On the Number of Subsequences in the Nonbinary Deletion Channel](https://arxiv.org/abs/2601.06493)
*Han Li,Xiang Wang,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 研究删除信道中非二进制字符串的子序列数量，针对具有r个run的字符串，提出了改进的边界，并找到了在任意t次删除下具有最大子序列数量的字符串族。


<details>
  <summary>Details</summary>
Motivation: 在删除信道中，确定长度为n的字符串U经过t次删除后产生的子序列数量是一个重要问题。已知子序列数量与字符串中run的数量（即相同字符的最大连续子串）密切相关。本文旨在研究非二进制字符串在此场景下的子序列数量。

Method: 研究非二进制字符串在删除信道中的子序列数量，提出改进的边界。特别地，刻画了一族具有r个run的非二进制字符串，这些字符串在任意t次删除下具有最大数量的子序列。

Result: 展示了具有最大子序列数量的字符串族可以在多项式时间内计算出来，为r-run非二进制字符串的子序列数量提供了改进的边界。

Conclusion: 本文解决了非二进制字符串在删除信道中子序列数量的优化问题，找到了具有最大子序列数量的字符串族，并提供了多项式时间的计算方法。

Abstract: In the deletion channel, an important problem is to determine the number of subsequences derived from a string $U$ of length $n$ when subjected to $t$ deletions. It is well-known that the number of subsequences in the setting exhibits a strong dependence on the number of runs in the string $U$, where a run is defined as a maximal substring of identical characters. In this paper we study the number of subsequences of a non-binary string in this scenario, and propose some improved bounds on the number of subsequences of $r$-run non-binary strings. Specifically, we characterize a family of $r$-run non-binary strings with the maximum number of subsequences under any $t$ deletions, and show that this number can be computed in polynomial time.

</details>


### [40] [Coding for Fading Channels with Imperfect CSI at the Transmitter and Quantized Feedback](https://arxiv.org/abs/2601.06501)
*Yuhan Yang,Haoheng Yuan,Chao Qi,Fan Cheng,Bin Dai*

Main category: cs.IT

TL;DR: 本文研究了如何将经典的Schalkwijk-Kailath (SK)方案扩展到具有记忆的信道模型，特别是多径衰落信道，提出了基于放大转发和中继策略的SK型方案。


<details>
  <summary>Details</summary>
Motivation: 经典的SK方案在高斯噪声信道中具有极低的编码复杂度和双指数衰减的解码错误率，但如何将其扩展到具有记忆的信道模型（如多径衰落信道）尚未解决。

Method: 1. 针对2路径准静态衰落信道，将第二路径信号视为中继，采用放大转发(AF)中继策略；2. 针对任意多径衰落信道，提出SK型方案，将时域信道转换为频域MIMO信道。

Result: 研究表明，对于2路径信道，干扰路径信号可以帮助提高传输速率；对于多径衰落信道，提出的SK型方案能够有效处理信道记忆问题。

Conclusion: 本文成功将SK方案扩展到具有记忆的多径衰落信道，通过中继策略和频域转换方法，为这类信道提供了高效的编码方案。

Abstract: The classical Schalkwijk-Kailath (SK) scheme for the additive Gaussian noise channel with noiseless feedback is highly efficient since its coding complexity is extremely low and the decoding error doubly exponentially decays as the coding blocklength tends to infinity. However, how to extend the SK scheme to channel models with memory has yet to be solved. In this paper, we first investigate how to design SK-type scheme for the 2-path quasi-static fading channel with noiseless feedback. By viewing the signal of the second path as a relay and adopting an amplify-and-forward (AF) relay strategy, we show that the interference path signal can help to enhance the transmission rate. Besides this, for arbitrary multi-path fading channel with feedback, we also present an SK-type scheme for such a model, which
  transforms the time domain channel into a frequency domain MIMO channel.

</details>


### [41] [Some New Results on Sequence Reconstruction Problem for Deletion Channels](https://arxiv.org/abs/2601.06503)
*Xiang Wang,Weijun Fang,Han Li,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 该论文解决了序列重构问题中的一个开放性问题，证明了当n≥13时，N(n,3,4)=20n-166，并给出了N(n,3,t)的下界。


<details>
  <summary>Details</summary>
Motivation: 解决Pham、Goyal和Kiah提出的开放性问题，确定N(n,3,4)的确切值，并为更一般情况下的N(n,3,t)提供下界。

Method: 采用组合数学方法，通过分析序列重构问题中等价于度量球交集最大尺寸的问题，推导出N(n,3,t)的下界，并证明当t=4时该下界是紧的。

Result: 证明了对于n≥13和t≥4，N(n,3,t)的下界；特别地，当t=4时，证明了N(n,3,4)=20n-166，解决了开放性问题。

Conclusion: 该研究完全解决了关于N(n,3,4)的开放性问题，为序列重构问题提供了重要的理论进展，并为更一般情况下的N(n,3,t)提供了基础结果。

Abstract: Levenshtein first introduced the sequence reconstruction problem in $2001$. In the realm of combinatorics, the sequence reconstruction problem is equivalent to determining the value of $N(n,d,t)$, which represents the maximum size of the intersection of two metric balls of radius $t$, given that the distance between their centers is at least $d$ and the sequence length is $n$. In this paper, We present a lower bound on $N(n,3,t)$ for $n\geq 13$ and $t \geq 4$. For $t=4$, we prove that this lower bound is tight. This settles an open question posed by Pham, Goyal, and Kiah, confirming that $N(n,3,4)=20n-166$ for all $n \geq 13$.

</details>


### [42] [Visible Light Communication using Led-Based AR Markers for Robot Localization](https://arxiv.org/abs/2601.06527)
*Wataru Uemura,Shogo Kawasaki*

Main category: cs.IT

TL;DR: 提出一种将ArUco标记以照明形式实现的方法，使用LED阵列按标记网格排列，通过不同闪烁频率编码黑白信息，使人眼看到均匀亮光而相机能识别标记信息。


<details>
  <summary>Details</summary>
Motivation: 在移动机器人日益普及的背景下，传统视觉标记在与人协作的环境中显得突兀。为了在工厂单元制造系统或家庭伴侣机器人等场景中，让标记既自然又不引人注目，需要设计更人性化的标记方案。

Method: 将LED按照ArUco标记的网格模式排列，根据每个网格单元的黑白状态设置相应LED的闪烁频率。这样人眼看到的是均匀的亮光，而相机通过捕捉闪烁频率差异来重建黑白图案，从而识别标记的标签信息。

Result: 开发了原型系统，并通过实验评估了在不同距离和视角下对ArUco标记的识别准确性。实验结果表明该方法在保持人眼舒适的同时，能够有效识别标记信息。

Conclusion: 提出的照明式ArUco标记方法成功实现了在与人协作环境中更自然、不突兀的标记设计，为移动机器人定位提供了更人性化的解决方案。

Abstract: A method of information transmission using visual markers has been widely studied. In this approach, information or identifiers (IDs) are encoded in the black-and-white pattern of each marker. By analyzing the geometric properties of the marker frame - such as its size, distortion, and coordinates - the relative position and orientation between the camera and the marker can be estimated. Furthermore, by associating the positional information of each marker with its corresponding ID, the position of the camera that takes the image picture can be calculated. In the field of mobile robotics, such markers are commonly utilized for robot localization. As mobile robots become more widely used in everyday environments, such visual markers are expected to be utilized across various contexts. In environments where robots collaborate with humans - such as in cell-based manufacturing systems in factories or in domestic settings with partner robots - it is desirable for such markers to be designed in a manner that appears natural and unobtrusive to humans. In this paper, we propose a method for implementing an ArUco marker in the form of illumination. In the proposed method, LEDs are arranged in accordance with the grid pattern of the marker, and the blinking frequency of each LED is determined based on the corresponding black or white cell. As a result, the illumination appears uniformly bright to the human eye, while the camera can capture variations in the blinking frequency. From these differences, the black-and-white pattern can be reconstructed, enabling the identification of the marker's tag information. We develop a prototype system, and conduct experiments which are conducted to evaluate its performance in terms of recognition accuracy under varying distances and viewing angles with respect to the ArUco marker.

</details>


### [43] [Hard Thresholding Pursuit Algorithms for Least Absolute Deviations Problem](https://arxiv.org/abs/2601.06558)
*Jiao Xu,Peng Li,Bing Zheng*

Main category: cs.IT

TL;DR: GFHTP₁算法在LAD准则下对异常值具有鲁棒性，无需信号稀疏度先验信息且无参数设计，在计算效率和鲁棒性方面优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 研究自适应迭代硬阈值算法的鲁棒性，特别是在存在异常值污染的场景下。LAD准则在少数测量值被任意幅度异常值污染时具有统计最优性，因此需要探索基于LAD的算法在稀疏信号恢复中的表现。

Method: 采用分级快速硬阈值追踪（GFHTP₁）算法，这是一种自适应迭代硬阈值算法的变体。该算法基于最小绝对偏差（LAD）准则，无需信号稀疏度先验信息，且设计为无参数算法，简化了实现过程并避免了参数优化复杂性。

Result: 数值实验表明，GFHTP₁算法在鲁棒性和计算效率方面持续优于竞争算法。该算法对异常值具有更强的鲁棒性，同时在计算性能上表现更优。

Conclusion: GFHTP₁算法是一种有效的稀疏信号恢复方法，在存在异常值污染的场景下表现出色。其无参数设计和无需稀疏度先验信息的特点使其在实际应用中具有显著优势，为鲁棒稀疏信号恢复提供了有前景的解决方案。

Abstract: Least absolute deviations (LAD) is a statistical optimality criterion widely utilized in scenarios where a minority of measurements are contaminated by outliers of arbitrary magnitudes. In this paper, we delve into the robustness of the variant of adaptive iterative hard thresholding to outliers, known as graded fast hard thresholding pursuit (GFHTP$_1$) algorithm. Unlike the majority of the state-of-the-art algorithms in this field, GFHTP$_1$ does not require prior information about the signal's sparsity. Moreover, its design is parameterless, which not only simplifies the implementation process but also removes the intricacies of parameter optimization. Numerical experiments reveal that the GFHTP$_1$ algorithm consistently outperforms competing algorithms in terms of both robustness and computational efficiency.

</details>


### [44] [TCLNet: A Hybrid Transformer-CNN Framework Leveraging Language Models as Lossless Compressors for CSI Feedback](https://arxiv.org/abs/2601.06588)
*Zijiu Yang,Qianqian Yang,Shunpu Tang,Tingting Yang,Zhiguo Shi*

Main category: cs.IT

TL;DR: TCLNet是一个用于FDD大规模MIMO系统CSI压缩的统一框架，结合了Transformer-CNN混合架构进行有损压缩，以及语言模型和因子化模型进行无损压缩，显著提升了压缩效率和重建精度。


<details>
  <summary>Details</summary>
Motivation: FDD大规模MIMO系统中，下行链路CSI反馈开销随着天线数量增加成为主要瓶颈。现有的深度学习CSI压缩方法在捕捉CSI的局部和全局特征方面存在局限，限制了压缩效率。

Method: 提出TCLNet统一框架：1）有损模块采用Transformer-CNN混合架构，联合利用局部特征和全局上下文；2）无损模块采用混合语言模型和因子化模型设计，自适应切换上下文感知编码和平行编码以优化率失真复杂度权衡。

Result: 在真实世界和模拟数据集上的实验表明，TCLNet在重建精度和传输效率方面优于现有方法，在不同场景下实现了高达5dB的性能增益。此外，研究还展示了大型语言模型可以通过精心设计的提示作为零样本CSI无损压缩器。

Conclusion: TCLNet通过集成Transformer-CNN架构和混合无损压缩设计，有效解决了CSI压缩中的局部-全局特征捕捉问题，显著提升了FDD大规模MIMO系统的CSI反馈效率，为实际部署提供了有前景的解决方案。

Abstract: In frequency division duplexing (FDD) massive multiple-input multiple-output (MIMO) systems, downlink channel state information (CSI) plays a crucial role in achieving high spectrum and energy efficiency. However, the CSI feedback overhead becomes a major bottleneck as the number of antennas increases. Although existing deep learning-based CSI compression methods have shown great potential, they still face limitations in capturing both local and global features of CSI, thereby limiting achievable compression efficiency. To address these issues, we propose TCLNet, a unified CSI compression framework that integrates a hybrid Transformer-CNN architecture for lossy compression with a hybrid language model (LM) and factorized model (FM) design for lossless compression. The lossy module jointly exploits local features and global context, while the lossless module adaptively switches between context-aware coding and parallel coding to optimize the rate-distortion-complexity (RDC) trade-off. Extensive experiments on both real-world and simulated datasets demonstrate that the proposed TCLNet outperforms existing approaches in terms of reconstruction accuracy and transmission efficiency, achieving up to a 5 dB performance gain across diverse scenarios. Moreover, we show that large language models (LLMs) can be leveraged as zero-shot CSI lossless compressors via carefully designed prompts.

</details>


### [45] [Symplectic Hulls over a Non-Unital Ring](https://arxiv.org/abs/2601.06609)
*Anup Kushwaha,Om Prakash*

Main category: cs.IT

TL;DR: 研究非幺环E上辛壳的结构与性质，包括生成矩阵刻画、辛壳秩扩展方法、置换等价性，并应用于小长度最优码分类


<details>
  <summary>Details</summary>
Motivation: 研究非幺环E上线性码的辛壳性质，为环上编码理论提供新的结构分析工具，并应用于最优码分类

Method: 首先识别左、右和双边辛壳的剩余码和挠码，刻画自由E-线性码双边辛壳的生成矩阵；探索两个自由E-线性码和的辛壳；提出两种扩展技术将较小长度和辛壳秩的码扩展到更大长度和辛壳秩；研究置换等价性和辛壳变化问题

Result: 建立了非幺环E上辛壳的完整理论框架，包括生成矩阵刻画、扩展技术、置换等价性分析，并应用于小长度自由E-线性最优码的分类

Conclusion: 该研究为非幺环上的编码理论提供了系统的辛壳分析工具，扩展了环上编码理论的研究范围，并为最优码分类提供了新方法

Abstract: This paper presents the study of the symplectic hulls over a non-unital ring $ E= \langle κ,τ\mid 2 κ=2 τ=0,~ κ^2=κ,~ τ^2=τ,~ κτ=κ,~ τκ=τ\rangle$. We first identify the residue and torsion codes of the left, right, and two-sided symplectic hulls, and characterize the generator matrix of the two-sided symplectic hull of a free $E$-linear code. Then, we explore the symplectic hull of the sum of two free $E$-linear codes. Subsequently, we provide two build-up techniques that extend a free $E$-linear code of smaller length and symplectic hull-rank to one of larger length and symplectic hull-rank. Further, for free $E$-linear codes, we discuss the permutation equivalence and investigate the symplectic hull-variation problem. An application of this study is given by classifying the free $E$-linear optimal codes for smaller lengths.

</details>


### [46] [The Sample Complexity of Lossless Data Compression](https://arxiv.org/abs/2601.06688)
*Terence Viaud,Ioannis Kontoyiannis*

Main category: cs.IT

TL;DR: 论文提出了一种新的无损数据压缩极限分析框架，强调非渐近结果，定义了"样本复杂度"作为在指定压缩率和超率概率下压缩给定源的最小块长度。


<details>
  <summary>Details</summary>
Motivation: 现有数据压缩理论主要关注渐近性能，缺乏对实际有限块长场景的精确分析。作者希望建立类似于统计学和计算机科学中的样本复杂度概念，为非渐近压缩性能提供理论基础。

Method: 引入样本复杂度作为核心度量，将其与假设检验问题联系起来。通过分析变长编码、前缀码和定长编码的关系，推导出样本复杂度的精确表征，特别是使用Rényi熵（阶数为1/2）来描述无记忆源和马尔可夫源的压缩性能。

Result: 1) 任意源的变长编码样本复杂度与前缀码和定长编码紧密耦合；2) 无记忆源的样本复杂度由1/2阶Rényi熵决定而非香农熵；3) 获得了具有显式常数的非渐近界；4) 马尔可夫源的样本复杂度由1/2阶Rényi熵率决定；5) 建立了通用数据压缩的样本复杂度界，由源族与均匀分布的最小1/2阶Rényi散度表征。

Conclusion: 该框架为无损数据压缩提供了非渐近性能分析的新视角，揭示了Rényi熵在有限块长压缩中的核心作用，建立了压缩理论与假设检验之间的联系，为实际压缩系统设计提供了理论指导。

Abstract: A new framework is introduced for examining and evaluating the fundamental limits of lossless data compression, that emphasizes genuinely non-asymptotic results. The {\em sample complexity} of compressing a given source is defined as the smallest blocklength at which it is possible to compress that source at a specified rate and to within a specified excess-rate probability. This formulation parallels corresponding developments in statistics and computer science, and it facilitates the use of existing results on the sample complexity of various hypothesis testing problems. For arbitrary sources, the sample complexity of general variable-length compressors is shown to be tightly coupled with the sample complexity of prefix-free codes and fixed-length codes. For memoryless sources, it is shown that the sample complexity is characterized not by the source entropy, but by its Rényi entropy of order~$1/2$. Nonasymptotic bounds on the sample complexity are obtained, with explicit constants. Generalizations to Markov sources are established, showing that the sample complexity is determined by the source's Rényi entropy rate of order~$1/2$. Finally, bounds on the sample complexity of universal data compression are developed for arbitrary families of memoryless sources. There, the sample complexity is characterized by the minimum Rényi divergence of order~$1/2$ between elements of the family and the uniform distribution. The connection of this problem with identity testing and with the associated separation rates is explored and discussed.

</details>


### [47] [Study of Adaptive Reliability-Driven Conditional Innovation Decoding for LDPC Codes](https://arxiv.org/abs/2601.06732)
*Hassan Touati,Rodrigo C. de Lamare*

Main category: cs.IT

TL;DR: 提出一种自适应可靠性驱动的条件创新（AR-CID）解码算法用于LDPC码，该算法通过消息质量检查和消息传递精炼两阶段，在残差置信传播框架下实现，具有快速收敛特性，适合低延迟应用。


<details>
  <summary>Details</summary>
Motivation: 现有LDPC解码算法在低延迟应用场景中可能收敛速度不够快，需要开发一种既能保持良好纠错性能又能快速收敛的解码算法，特别适合对延迟敏感的应用。

Method: 提出AR-CID解码算法，包含两个阶段：1）消息质量检查阶段，评估消息可靠性；2）消息传递精炼阶段，在残差置信传播框架下优化消息传递。算法还分析了计算复杂度和延迟特性。

Result: 仿真结果表明，AR-CID算法在多种LDPC码（包括短码和中长码）和广泛信道条件下，性能优于现有解码技术，且具有极快的收敛速度。

Conclusion: AR-CID解码算法是一种高效、快速收敛的LDPC解码方案，特别适合低延迟应用场景，在保持良好纠错性能的同时显著提升解码速度。

Abstract: In this work, we present an adaptive reliability-driven conditional innovation (AR-CID) decoding algorithm for low-density parity check (LDPC) codes. The proposed AR-CID decoding algorithm consists of one stage of message quality checking and another stage of message passing refinement, which are incorporated into a residual belief propagation decoding strategy. An analysis of the AR-CID decoding algorithm is carried out along with a study of its computational complexity and latency characteristics. Simulation results for several examples of LDPC codes, including short and medium-length codes over an extended range of channel conditions, indicate that the proposed AR-CID decoding algorithm outperforms competing decoding techniques and has an extremely fast convergence, making it particularly suitable for low-delay applications.

</details>


### [48] [Optimal Rate Region for Multi-server Secure Aggregation with User Collusion](https://arxiv.org/abs/2601.06836)
*Zhou Li,Xiang Zhang,Kai Wan,Hua Sun,Mingyue Ji,Giuseppe Caire*

Main category: cs.IT

TL;DR: 该论文研究了多服务器安全聚合问题，在存在用户共谋的两跳网络中，完全刻画了最优速率区域，发现多服务器架构相比单服务器能显著降低所需密钥随机性。


<details>
  <summary>Details</summary>
Motivation: 安全聚合是隐私保护分布式学习系统中的基本原语。现有研究主要关注单服务器场景，而多服务器架构在实际系统中更为常见。论文旨在研究存在用户共谋的多服务器安全聚合问题，从信息论角度完整刻画其性能极限。

Method: 采用信息论安全框架，允许最多T个用户与任意服务器共谋。通过线性密钥构造实现方案，确保正确性和对共谋用户的安全性。逆证明基于正确性和安全性约束推导的紧熵界。

Result: 完全刻画了最优速率区域：最小通信速率和个体密钥速率均为每个输入符号1个符号，最优源密钥速率为min{U+V+T-2, UV-1}，其中U为服务器数量，V为每服务器用户数。多服务器架构相比单服务器能显著降低所需密钥随机性。

Conclusion: 该研究揭示了安全性与密钥效率之间的基本权衡，表明多服务器架构在存在用户共谋的安全聚合中具有显著优势，为多服务器系统的安全聚合提供了完整的信息论特征刻画。

Abstract: Secure aggregation is a fundamental primitive in privacy-preserving distributed learning systems, where an aggregator aims to compute the sum of users' inputs without revealing individual data. In this paper, we study a multi-server secure aggregation problem in a two-hop network consisting of multiple aggregation servers and multiple users per server, under the presence of user collusion. Each user communicates only with its associated server, while the servers exchange messages to jointly recover the global sum. We adopt an information-theoretic security framework, allowing up to $T$ users to collude with any server.
  We characterize the complete optimal rate region in terms of user-to-server communication rate, server-to-server communication rate, individual key rate, and source key rate. Our main result shows that the minimum communication and individual key rates are all one symbol per input symbol, while the optimal source key rate is given by $\min\{U+V+T-2,\, UV-1\}$, where $U$ denotes the number of servers and $V$ the number of users per server. The achievability is established via a linear key construction that ensures correctness and security against colluding users, while the converse proof relies on tight entropy bounds derived from correctness and security constraints.
  The results reveal a fundamental tradeoff between security and key efficiency and demonstrate that the multi-server architecture can significantly reduce the required key randomness compared to single-server secure aggregation. Our findings provide a complete information-theoretic characterization of secure aggregation in multi-server systems with user collusion.

</details>


### [49] [Large Artificial Intelligence Models for Future Wireless Communications](https://arxiv.org/abs/2601.06906)
*Chong Huang,Gaojie Chen,Pei Xiao,Zhu Han,Rahim Tafazolli*

Main category: cs.IT

TL;DR: 本文探讨了将大型AI模型集成到无线通信中的潜力与挑战，提出了未来无线通信中大型AI模型的架构，并讨论了其在数据分析、资源分配和实时适应方面的优势，以及能源、隐私、安全等挑战和解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着无线网络日益复杂，传统优化管理方法面临挑战。大型AI模型具有广泛的参数空间和增强的学习能力，能够为这些挑战提供创新解决方案，并能实时学习、适应和优化。

Method: 提出未来无线通信中大型AI模型的架构，分析其在数据分析和资源分配方面的优势，探讨能源、架构设计、隐私、安全、伦理和监管等方面的挑战及相应解决方案。

Result: 确立了大型AI模型在无线通信中的集成潜力，识别了关键挑战领域，并提出了解决这些挑战的框架，为未来研究奠定了基础。

Conclusion: 大型AI模型与无线通信的集成将带来变革性影响，虽然面临能源、隐私等多方面挑战，但通过适当的架构设计和解决方案，有望推动无线通信进入新的发展阶段。

Abstract: The anticipated integration of large artificial intelligence (AI) models with wireless communications is estimated to usher a transformative wave in the forthcoming information age. As wireless networks grow in complexity, the traditional methodologies employed for optimization and management face increasingly challenges. Large AI models have extensive parameter spaces and enhanced learning capabilities and can offer innovative solutions to these challenges. They are also capable of learning, adapting and optimizing in real-time. We introduce the potential and challenges of integrating large AI models into wireless communications, highlighting existing AIdriven applications and inherent challenges for future large AI models. In this paper, we propose the architecture of large AI models for future wireless communications, introduce their advantages in data analysis, resource allocation and real-time adaptation, discuss the potential challenges and corresponding solutions of energy, architecture design, privacy, security, ethical and regulatory. In addition, we explore the potential future directions of large AI models in wireless communications, laying the groundwork for forthcoming research in this area.

</details>


### [50] [Caching Yields up to 5x Spectral Efficiency in Multi-Beam Satellite Communications](https://arxiv.org/abs/2601.06925)
*Hui Zhao,Dirk Slock,Petros Elia*

Main category: cs.IT

TL;DR: 将向量编码缓存(VCC)集成到多波束卫星通信系统中，即使有限的接收端缓存也能显著提升频谱效率，通过缓存内容抑制干扰，实现资源利用率的倍增提升。


<details>
  <summary>Details</summary>
Motivation: 卫星通信系统需要提高频谱效率以缩小与有线网络的性能差距，传统方法受限于多播、预取和文件流行度等因素，需要一种纯粹的物理层解决方案。

Method: 将向量编码缓存(VCC)集成到多波束卫星通信系统，利用Rician-shadowed衰落模型建模卫星-地面信道，考虑匹配滤波预编码、CSI获取开销和CSI不完美等实际因素，推导平均和速率和频谱效率增益的闭式表达式。

Result: VCC相比传统多用户MISO卫星通信系统，在相同资源下可获得300%到550%的频谱效率增益，这些增益与多播、预取或文件流行度无关。

Conclusion: VCC作为一种纯粹的物理层解决方案，能显著提升未来高吞吐量卫星通信系统的性能，大大缩小卫星网络与有线网络之间的性能差距。

Abstract: This paper examines the integration of vector coded caching (VCC) into multi-beam satellite communications (SATCOM) systems and demonstrates that even limited receiver-side caching can substantially enhance spectral efficiency. By leveraging cached content to suppress interference, VCC enables the concurrent transmission of multiple precoded signal vectors that would otherwise require separate transmission resources. This leads to a multiplicative improvement in resource utilization in SATCOM. To characterize this performance, we model the satellite-to-ground channel using Rician-shadowed fading and after incorporating practical considerations such as matched-filter precoding, channel state information (CSI) acquisition overhead as well as CSI imperfections at the transmitter, we here derive closed-form expressions for the average sum rate and spectral efficiency gain of VCC in SATCOM. Our analysis, tightly validated through numerical simulations, reveals that VCC can yield spectral efficiency gains of 300% to 550% over traditional multi-user MISO SATCOM with the same resources. These gains -- which have nothing to do with multicasting, prefetching gains nor file popularity -- highlight VCC as a pure physical-layer solution for future high-throughput SATCOM systems, significantly narrowing the performance gap between satellite and wired networks.

</details>


### [51] [Generalization Bounds for Transformer Channel Decoders](https://arxiv.org/abs/2601.06969)
*Qinshan Zhang,Bin Chen,Yong Jiang,Shu-Tao Xia*

Main category: cs.IT

TL;DR: 本文首次为Transformer信道解码器（ECCT）提供了理论泛化保证，通过建立乘性噪声估计误差与误码率之间的联系，推导出基于比特级Rademacher复杂度的泛化上界。


<details>
  <summary>Details</summary>
Motivation: Transformer信道解码器（如ECCT）在信道解码中表现出强大的经验性能，但其泛化行为在理论上尚不明确，需要从学习理论角度研究其泛化性能。

Method: 通过建立乘性噪声估计误差与误码率之间的联系，推导出基于比特级Rademacher复杂度的泛化上界；分析奇偶校验掩码注意力引入的稀疏性如何减少覆盖数，从而获得更紧的泛化界。

Result: 得到了表征码长、模型参数和训练集大小依赖关系的泛化上界，适用于单层和多层ECCT；证明了奇偶校验掩码注意力通过引入稀疏性减少覆盖数，获得更紧的泛化界。

Conclusion: 本文首次为Transformer信道解码器提供了理论泛化保证，为这类解码器的理论理解奠定了基础，并展示了结构稀疏性对泛化性能的积极影响。

Abstract: Transformer channel decoders, such as the Error Correction Code Transformer (ECCT), have shown strong empirical performance in channel decoding, yet their generalization behavior remains theoretically unclear. This paper studies the generalization performance of ECCT from a learning-theoretic perspective. By establishing a connection between multiplicative noise estimation errors and bit-error-rate (BER), we derive an upper bound on the generalization gap via bit-wise Rademacher complexity. The resulting bound characterizes the dependence on code length, model parameters, and training set size, and applies to both single-layer and multi-layer ECCTs. We further show that parity-check-based masked attention induces sparsity that reduces the covering number, leading to a tighter generalization bound. To the best of our knowledge, this work provides the first theoretical generalization guarantees for this class of decoders.

</details>


### [52] [Quantum Optical Integrated Sensing and Communication with Homodyne BPSK Detection](https://arxiv.org/abs/2601.07034)
*Ioannis Krikidis*

Main category: cs.IT

TL;DR: 提出一种量子集成传感与通信方案，使用BPSK调制和零差检测，在未知相位旋转的高斯信道中实现联合符号检测和相位估计


<details>
  <summary>Details</summary>
Motivation: 在量子光学链路中，需要同时实现可靠的通信和精确的传感，但传统方法难以在未知相位旋转的信道中平衡这两个目标

Method: 采用二进制相移键控调制和零差检测，设计最小化误码率同时满足Fisher信息约束的优化问题，开发包含内层期望最大化循环和外层本地振荡器相位自适应调谐的迭代算法

Result: 数值结果验证了所提方法的有效性，并展示了通信可靠性和传感精度之间的基本权衡关系

Conclusion: 该方案成功实现了量子集成传感与通信，在未知相位旋转的量子光学链路中平衡了通信性能和传感精度

Abstract: In this letter, we propose a quantum integrated sensing and communication scheme for a quantum optical link using binary phase-shift keying modulation and homodyne detection. The link operates over a phase-insensitive Gaussian channel with an unknown deterministic phase rotation, where the homodyne receiver jointly carries out symbol detection and phase estimation. We formulate a design problem that minimizes the bit-error rate subject to a Fisher information-based constraint on estimation accuracy. To solve it, we develop an iterative algorithm composed of an inner expectation-maximization loop for joint detection and estimation and an outer loop that adaptively retunes the local oscillator phase. Numerical results confirm the effectiveness of the proposed approach and demonstrate a fundamental trade-off between communication reliability and sensing accuracy.

</details>


### [53] [Random Access in DNA Storage: Algorithms, Constructions, and Bounds](https://arxiv.org/abs/2601.07053)
*Chen Wang,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 提出新算法计算DNA数据存储随机访问问题的精确期望读取次数，复杂度O(n)，推导显式公式，改进码构造和理论下界


<details>
  <summary>Details</summary>
Motivation: DNA数据存储走向实际应用，需要最小化测序覆盖深度以降低成本和检索延迟，解决随机访问问题

Method: 提出计算期望读取次数的新算法，复杂度O(n)；推导平均和最大期望读取次数的显式公式；搜索最优生成矩阵；提出新的码构造

Result: 改进已知上界：k=3时从0.8815k到0.8811k，k=4时达到0.8629k；建立更紧的理论下界；证明n=k+1时简单奇偶校验码的最优性

Conclusion: 新算法高效计算期望读取次数，新码构造改进性能，理论下界更紧，为DNA数据存储随机访问问题提供重要进展

Abstract: As DNA data storage moves closer to practical deployment, minimizing sequencing coverage depth is essential to reduce both operational costs and retrieval latency. This paper addresses the recently studied Random Access Problem, which evaluates the expected number of read samples required to recover a specific information strand from $n$ encoded strands. We propose a novel algorithm to compute the exact expected number of reads, achieving a computational complexity of $O(n)$ for fixed field size $q$ and information length $k$. Furthermore, we derive explicit formulas for the average and maximum expected number of reads, enabling an efficient search for optimal generator matrices under small parameters. Beyond theoretical analysis, we present new code constructions that improve the best-known upper bound from $0.8815k$ to $0.8811k$ for $k=3$, and achieve an upper bound of $0.8629k$ for $k=4$ for sufficiently large $q$. We also establish a tighter theoretical lower bound on the expected number of reads that improves upon state-of-the-art bounds. In particular, this bound establishes the optimality of the simple parity code for the case of $n=k+1$ across any alphabet $q$.

</details>


### [54] [Score-Based VAMP with Fisher-Information-Based Onsager Correction](https://arxiv.org/abs/2601.07095)
*Tadashi Wadayama,Takumi Takahashi*

Main category: cs.IT

TL;DR: 提出SC-VAMP方法，通过条件Fisher信息表达Onsager修正，实现无雅可比矩阵计算，结合学习得分函数构建非线性MMSE估计器，扩展VAMP到复杂黑盒推理问题。


<details>
  <summary>Details</summary>
Motivation: 传统VAMP方法需要解析导数，限制了在复杂黑盒推理问题中的应用。需要一种能够处理非线性、结构化或相关传感设置的方法，避免对先验或似然函数的显式建模。

Method: 1) 使用条件Fisher信息表达和计算Onsager修正，实现无雅可比矩阵实现；2) 利用学习得分函数通过Tweedie公式构建非线性MMSE估计器；3) 从得分-范数统计推导相应Onsager项；4) 结合随机正交/酉混合处理非理想传感设置。

Result: SC-VAMP扩展了VAMP到复杂黑盒推理问题，避免了显式建模需求。通过信息论视角分析高斯近似，提供了超越理想i.i.d.设置的解耦原理洞察，包括非线性机制。

Conclusion: SC-VAMP为向量近似消息传递提供了无雅可比矩阵的实现框架，能够处理传统VAMP难以应对的复杂推理问题，并通过信息论分析增强了理论基础。

Abstract: We propose score-based VAMP (SC-VAMP), a variant of vector approximate message passing (VAMP) in which the Onsager correction is expressed and computed via conditional Fisher information, thereby enabling a Jacobian-free implementation. Using learned score functions, SC-VAMP constructs nonlinear MMSE estimators through Tweedie's formula and derives the corresponding Onsager terms from the score-norm statistics, avoiding the need for analytical derivatives of the prior or likelihood. When combined with random orthogonal/unitary mixing to mitigate non-ideal, structured or correlated sensing settings, the proposed framework extends VAMP to complex black-box inference problems where explicit modeling is intractable. Finally, by leveraging the entropic CLT, we provide an information-theoretic perspective on the Gaussian approximation underlying SE, offering insight into the decoupling principle beyond idealized i.i.d. settings, including nonlinear regimes.

</details>


### [55] [PASS-Enabled Covert Communications With Distributed Cooperative Wardens](https://arxiv.org/abs/2601.07147)
*Ji He*

Main category: cs.IT

TL;DR: 该论文研究了在分布式监控下的PASS使能下行隐蔽通信，通过双波导架构同时传输隐蔽信息和随机干扰，分析了三种PASS功率辐射定律，推导了系统级检测错误概率的闭式解，并提出了优化隐蔽速率的算法。


<details>
  <summary>Details</summary>
Motivation: 在分布式监控环境下，多个看守者通过多数投票规则融合本地检测结果，传统隐蔽通信面临严峻挑战。需要研究如何在多看守者协同监控下实现可靠的隐蔽通信，同时考虑PASS（可编程天线表面）的不同功率辐射特性。

Method: 采用双波导架构同时传输隐蔽信息和随机干扰；推导了本地虚警和漏检概率的闭式表达式；利用概率生成函数和初等对称多项式框架，结合基于断点的阈值域划分，得到非独立同分布多数投票融合下的系统级检测错误概率闭式解；提出MM-BCD-SCA算法优化隐蔽速率。

Result: 获得了系统级检测错误概率的闭式表达式；提出的MM-BCD-SCA算法能有效解决非凸优化问题；数值结果验证了理论分析，展示了协同监控和PASS辐射定律对隐蔽性-速率权衡的影响。

Conclusion: 该研究为分布式监控环境下的隐蔽通信提供了理论框架和实用算法，证明了PASS双波导架构在对抗多看守者协同检测方面的有效性，为未来隐蔽通信系统设计提供了重要参考。

Abstract: This paper investigates PASS-enabled downlink covert communication in the presence of distributed surveillance, where multiple wardens perform signal detection and fuse their local binary decisions via majority-voting rule. We consider a dual-waveguide architecture that simultaneously delivers covert information and randomized jamming to hide the transmission footprint, incorporating three representative PASS power-radiation laws-general, proportional, and equal. To characterize the system-level detectability, we derive closed-form expressions for local false-alarm and miss-detection probabilities. By leveraging a probability-generating-function (PGF) and elementary-symmetric-polynomial (ESP) framework, combined with a breakpoint-based partition of the threshold domain, we obtain explicit closed-form characterizations of the system-level detection error probability (DEP) under non-i.i.d. majority-voting fusion. Building on this analytical framework, we formulate a robust optimization problem to maximize the average covert rate subject to covertness constraint. To solve the resulting nonconvex design, we develop an MM-BCD-SCA algorithm that produces tractable alternating updates for power/radiation variables and PA positions via convex surrogates and inner approximations of the DEP value function. Numerical results validate the theoretical analysis and demonstrate the impact of cooperative monitoring and PASS radiation laws on the covertness-rate tradeoff.

</details>


### [56] [Sentiment Analysis on Movie Reviews: A Deep Dive into Modern Techniques and Open Challenges](https://arxiv.org/abs/2601.07235)
*Agnivo Gosai,Shuvodeep De,Karun Thankachan*

Main category: cs.IT

TL;DR: 该论文是关于电影评论情感分析方法的全面综述，涵盖了从早期基于词典的方法到现代深度学习和大语言模型的技术演进，重点关注领域特定挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 电影评论情感分析作为自然语言处理的基准任务，在技术发展中扮演核心角色。现有综述主要关注文本处理流程，而本文旨在提供更全面的分析，包括多模态方法、可解释性、公平性等新兴问题。

Method: 采用文献综述方法，系统回顾情感分析技术的演进：从基于词典和传统机器学习方法到深度学习和大型语言模型。特别关注IMDb、Rotten Tomatoes、SST-2等数据集，以及从朴素贝叶斯、支持向量机到LSTM、BERT和注意力变换器等模型。

Result: 提供了技术演进的全面梳理，识别了领域特定挑战（如讽刺、否定、上下文歧义、领域迁移），并分析了不同建模范式如何应对这些挑战。同时总结了多模态情感分析的最新进展，以及可解释性、公平性、鲁棒性等新兴问题。

Conclusion: 本文为电影评论情感分析领域提供了领域聚焦的路线图，既总结了现有解决方案，也指出了未解决的挑战。未来研究方向包括零样本/少样本学习、混合符号-神经模型、实时部署考虑等，目标是构建更准确、可泛化和可解释的情感分析系统。

Abstract: This paper presents a comprehensive survey of sentiment analysis methods for movie reviews, a benchmark task that has played a central role in advancing natural language processing. We review the evolution of techniques from early lexicon-based and classical machine learning approaches to modern deep learning architectures and large language models, covering widely used datasets such as IMDb, Rotten Tomatoes, and SST-2, and models ranging from Naive Bayes and support vector machines to LSTM networks, BERT, and attention-based transformers. Beyond summarizing prior work, this survey differentiates itself by offering a comparative, challenge-driven analysis of how these modeling paradigms address domain-specific issues such as sarcasm, negation, contextual ambiguity, and domain shift, which remain open problems in existing literature. Unlike earlier reviews that focus primarily on text-only pipelines, we also synthesize recent advances in multimodal sentiment analysis that integrate textual, audio, and visual cues from movie trailers and clips. In addition, we examine emerging concerns related to interpretability, fairness, and robustness that are often underexplored in prior surveys, and we outline future research directions including zero-shot and few-shot learning, hybrid symbolic--neural models, and real-time deployment considerations. Overall, this abstract provides a domain-focused roadmap that highlights both established solutions and unresolved challenges toward building more accurate, generalizable, and explainable sentiment analysis systems for movie review data.

</details>


### [57] [Bias-Aware BP Decoding of Quantum Codes via Directional Degeneracy](https://arxiv.org/abs/2601.07240)
*Mohammad Rowshan*

Main category: cs.IT

TL;DR: 本文提出了一种针对量子CSS码的定向信念传播解码方法，利用各向异性Tanner图结构和偏置噪声，通过方向权重和退化枚举器来提升解码性能。


<details>
  <summary>Details</summary>
Motivation: 量子CSS码的Tanner图通常具有各向异性结构，且量子噪声可能呈现方向性偏置。传统解码方法未充分利用这些结构特征，导致解码性能受限。本文旨在开发能够利用方向性信息来提升解码性能的方法。

Method: 1. 在Tanner图边上分配方向权重，聚合成每个量子位的方向权重；2. 定义方向退化枚举器来量化退化沿特定方向的集中程度；3. 引入偏置参数β将方向权重映射为位置相关的对数似然比，作为各向异性先验信息；4. 将各向异性先验直接集成到标准BP→OSD解码器中，无需改变码构造。

Result: 1. 推导了方向距离与汉明距离之间的关系界限；2. 基于距离、码率和方向偏置，给出了每个校验子对应的退化错误类数量的上界；3. 提供了方向枚举器的MacWilliams型表达式；4. 有限长度仿真显示在中等物理错误率下，逻辑错误率显著降低（通常降低一个数量级）。

Conclusion: 适度的各向异性是获得硬件感知解码增益的简单有效途径。该方法通过利用量子码的方向性结构特征，显著提升了BP解码性能，且无需改变码构造，可直接集成到现有解码框架中。

Abstract: We study directionally informed belief propagation (BP) decoding for quantum CSS codes, where anisotropic Tanner-graph structure and biased noise concentrate degeneracy along preferred directions. We formalize this by placing orientation weights on Tanner-graph edges, aggregating them into per-qubit directional weights, and defining a \emph{directional degeneracy enumerator} that summarizes how degeneracy concentrates along those directions. A single bias parameter~$β$ maps these weights into site-dependent log-likelihood ratios (LLRs), yielding anisotropic priors that plug directly into standard BP$\rightarrow$OSD decoders without changing the code construction. We derive bounds relating directional and Hamming distances, upper bound the number of degenerate error classes per syndrome as a function of distance, rate, and directional bias, and give a MacWilliams-type expression for the directional enumerator. Finite-length simulations under code-capacity noise show significant logical error-rate reductions -- often an order of magnitude at moderate physical error rates -- confirming that modest anisotropy is a simple and effective route to hardware-aware decoding gains.

</details>


### [58] [Rate-distortion Theory on Non-compact Spaces: A Concentration-compactness Approach](https://arxiv.org/abs/2601.07246)
*Jiayang Zou,Luyao Fan,Jiayang Gao,Jia Wang*

Main category: cs.IT

TL;DR: 该论文将集中紧致原理引入率失真理论，在非紧致空间上建立了最优重建分布的存在性定理，克服了经典方法对紧致性假设的依赖。


<details>
  <summary>Details</summary>
Motivation: 经典率失真理论的存在性结果依赖于紧致性假设，这在非紧致空间中常常不成立。作者旨在解决一般源在非紧致空间上的率失真问题中，最优重建分布的存在性问题。

Method: 将集中紧致原理引入率失真泛函的分析中，在失真函数满足温和的强制性条件下，建立最优重建的存在性。

Result: 在非紧致空间上建立了统一且透明的率失真问题存在性定理，放宽了对紧致性的要求。

Conclusion: 通过引入集中紧致原理，成功解决了非紧致空间中率失真问题的最优重建存在性，为一般源的率失真理论提供了更广泛适用的理论框架。

Abstract: In this paper, we study rate-distortion theory for general sources with an emphasis on the existence of optimal reconstruction distributions. Classical existence results rely on compactness assumptions that are often violated in non-compact settings. By introducing the concentration-compactness principle into the analysis of the rate-distortion functional, we establish the existence of optimal reconstructions under mild coercivity conditions on the distortion function. Our results provide a unified and transparent existence theorem for rate-distortion problems on general non-compact spaces.

</details>


### [59] [Engineering Favorable Propagation: Near-Field IRS Deployment for Spatial Multiplexing](https://arxiv.org/abs/2601.07317)
*Yuxuan Chen,Qingqing Wu,Guangji Chen,Qiaoyan Peng,Wen Chen*

Main category: cs.IT

TL;DR: 利用稀疏阵列的大孔径产生近场球面波，通过IRS近场部署解决远场级联信道秩不足问题，提升空间复用能力


<details>
  <summary>Details</summary>
Motivation: IRS辅助MIMO系统中，强视距链路会导致级联信道秩不足，限制空间复用能力，需要解决这一根本问题

Method: 提出确定性部署准则，将IRS战略性地部署在基站近场区域，利用稀疏阵列产生的球面波前设计去相关信道，并基于统计CSI联合优化IRS相移和功率分配

Result: 建立了几何驱动的部署规则，显著降低用户间信道相关性，增强有效自由度，MRT预编码方案在统计CSI下实现高效优化

Conclusion: 通过近场部署IRS并利用稀疏阵列的球面波特性，从根本上解决了级联信道秩不足问题，为IRS-MIMO系统提供了有效的部署和优化框架

Abstract: In intelligent reflecting surface IRS assisted multiple input multiple output MIMO systems, a strong line of sight LoS link is required to compensate for the severe cascaded path loss. However, such a link renders the effective channel highly rank deficient and fundamentally limits spatial multiplexing. To overcome this limitation, this paper leverages the large aperture of sparse arrays to harness near field spherical wavefronts, and establishes a deterministic deployment criterion that strategically positions the IRS in the near field of a base station BS. This placement exploits the spherical wavefronts of the BS IRS link to engineer decorrelated channels, thereby fundamentally overcoming the rank deficiency issue in far field cascaded channels. Based on a physical channel model for the sparse BS array and the IRS, we characterize the rank properties and inter user correlation of the cascaded BS IRS user channel. We further derive a closed form favorable propagation metric that reveals how the sparse array geometry and the IRS position can be tuned to reduce inter user channel correlation. The resulting geometry driven deployment rule provides a simple guideline for creating a favorable propagation environment with enhanced effective degrees of freedom. The favorable channel statistics induced by our deployment criterion enable a low complexity maximum ratio transmission MRT precoding scheme. This serves as the foundation for an efficient algorithm that jointly optimizes the IRS phase shifts and power allocation based solely on long term statistical channel state information CSI. Simulation results validate the effectiveness of our deployment criterion and demonstrate that our optimization framework achieves significant performance gains over benchmark schemes.

</details>


### [60] [Performance Bounds of Joint Detection with Kalman Filtering and Channel Decoding for Wireless Networked Control Systems](https://arxiv.org/abs/2601.07322)
*Jinnan Piao,Dong Li,Zhibo Li,Ming Yang,Xueting Yu,Jincheng Dai*

Main category: cs.IT

TL;DR: 该论文将联合检测视为最大后验解码，推导了考虑系统干扰、量化间隔和权重分布的成对错误概率上下界，并通过无限状态马尔可夫链分析控制系统的连续丢包，最终将MAP界近似为从无丢包状态到连续单包丢失状态的转移概率界。


<details>
  <summary>Details</summary>
Motivation: 传统联合检测使用卡尔曼滤波估计控制输出的先验概率来辅助信道解码，但需要更精确的性能界限分析。论文旨在为控制系统的联合检测建立理论性能界限，特别是在考虑系统干扰、量化效应和连续丢包模式的情况下。

Method: 1. 将联合检测建模为最大后验解码问题；2. 基于成对错误概率推导考虑系统干扰、量化间隔和权重分布的上下界；3. 分析SNR趋于无穷和系统干扰趋于零时的极限界；4. 构建无限状态马尔可夫链描述控制系统的连续丢包模式；5. 将MAP界近似为从无丢包状态到连续单包丢失状态的转移概率界。

Result: 仿真结果显示：(64,16)极化码和16位CRC的MAP性能在SNR增加时与极限上界一致，在块错误率10^{-3}时比有限块率正态近似有3.0dB的性能增益。

Conclusion: 该研究为控制系统中的联合检测提供了理论性能界限框架，通过MAP解码方法和马尔可夫链建模，能够准确分析连续丢包模式下的性能，所提方法在实际编码方案中表现出优于传统近似方法的性能。

Abstract: The joint detection uses Kalman filtering (KF) to estimate the prior probability of control outputs to assist channel decoding. In this paper, we regard the joint detection as maximum a posteriori (MAP) decoding and derive the lower and upper bounds based on the pairwise error probability considering system interference, quantization interval, and weight distribution. We first derive the limiting bounds as the signal-to-noise ratio (SNR) goes to infinity and the system interference goes to zero. Then, we construct an infinite-state Markov chain to describe the consecutive packet losses of the control systems to derive the MAP bounds. Finally, the MAP bounds are approximated as the bounds of the transition probability from the state with no packet loss to the state with consecutive single packet loss. The simulation results show that the MAP performance of $\left(64,16\right)$ polar code and 16-bit CRC coincides with the limiting upper bound as the SNR increases and has $3.0$dB performance gain compared with the normal approximation of the finite block rate at block error rate $10^{-3}$.

</details>


### [61] [On the Extremal Source Key Rates for Secure Storage over Graphs](https://arxiv.org/abs/2601.07340)
*Zhou Li*

Main category: cs.IT

TL;DR: 该论文研究图上的安全存储编码，其中多个独立源符号在满足边级正确性和安全性约束的条件下被编码存储在图的节点上。论文研究了源密钥容量的极值，并对几种基本设置提供了完整的图特征描述。


<details>
  <summary>Details</summary>
Motivation: 研究图结构上安全存储编码的极限性能，特别是源密钥容量（源符号大小与源密钥大小的比率）的极值问题。理解在哪些图结构下可以实现最优的安全存储，以及何时可以完全不需要源密钥。

Method: 采用图论和编码理论相结合的方法，分析安全存储系统在不同设置下的源密钥容量。首先处理每个边关联单个源符号的情况，然后推广到每个边关联多个源符号的情况。通过图结构特征来描述容量极值。

Result: 1. 对于每个边关联单个源符号的情况，完全刻画了源密钥容量等于1的所有图结构。2. 对于每个边关联多个源符号的情况，在温和的结构条件下，识别了一大类达到相应极值容量的图。3. 刻画了所有不需要使用任何源密钥就能实现安全存储的图。

Conclusion: 论文为图上的安全存储编码提供了完整的理论框架，通过图结构特征描述了源密钥容量的极值行为。这些结果为设计高效的安全存储系统提供了理论基础，特别是揭示了图拓扑结构与安全存储性能之间的深刻联系。

Abstract: This paper investigates secure storage codes over graphs, where multiple independent source symbols are encoded and stored at graph nodes subject to edge-wise correctness and security constraints. For each edge, a specified subset of source symbols must be recoverable from its two incident nodes, while no information about the remaining sources is revealed. To meet the security requirement, a shared source key may be employed. The ratio between the source symbol size and the source key size defines the source key rate, and the supremum of all achievable rates is referred to as the source key capacity.
  We study extremal values of the source key capacity in secure storage systems and provide complete graph characterizations for several fundamental settings. For the case where each edge is associated with a single source symbol, we characterize all graphs whose source key capacity equals one. We then generalize this result to the case where each edge is associated with multiple source symbols and identify a broad class of graphs that achieve the corresponding extremal capacity under a mild structural condition. In addition, we characterize all graphs for which secure storage can be achieved without using any source key.

</details>


### [62] [Fast and Provable Nonconvex Robust Matrix Completion](https://arxiv.org/abs/2601.07355)
*Yichen Fu,Tianming Wang,Ke Wei*

Main category: cs.IT

TL;DR: 提出了一种名为ARMC的高效非凸鲁棒矩阵补全方法，通过引入子空间投影改进奇异值阈值方法，在理论和实验上均优于现有方法


<details>
  <summary>Details</summary>
Motivation: 鲁棒矩阵补全问题在存在离群值和噪声的情况下具有重要应用价值，现有方法在理论保证和计算效率方面存在改进空间

Method: ARMC方法在更新低秩部分时引入子空间投影到奇异值阈值方法中，采用非凸优化框架，结合留一法技术进行理论分析

Result: 在合成和真实数据上的数值实验表明ARMC优于现有非凸RMC方法；理论分析建立了对稀疏离群值和随机噪声的理论保证，样本复杂度和离群值稀疏度界限优于凸方法

Conclusion: ARMC是一种计算高效且理论保证优越的鲁棒矩阵补全方法，在理论和实验性能上均超越现有方法

Abstract: This paper studies the robust matrix completion problem and a computationally efficient non-convex method called ARMC has been proposed. This method is developed by introducing subspace projection to a singular value thresholding based method when updating the low rank part. Numerical experiments on synthetic and real data show that ARMC is superior to existing non-convex RMC methods. Through a refined analysis based on the leave-one-out technique, we have established the theoretical guarantee for ARMC subject to both sparse outliers and stochastic noise. The established bounds for the sample complexity and outlier sparsity are better than those established for a convex approach that also considers both outliers and stochastic noise.

</details>


### [63] [Novel Decoding Algorithm for Noiseless Non-Adaptive Group Testing](https://arxiv.org/abs/2601.07388)
*Manuel Franco-Vivo*

Main category: cs.IT

TL;DR: 提出W-SCOMP算法改进非自适应群组检测，在无噪声条件下优于现有方法，减少测试次数并提高识别成功率


<details>
  <summary>Details</summary>
Motivation: COVID-19疫情凸显了非自适应群组检测的时间效率优势，需要提升现有方案的性能。群组检测在传染病筛查、药物发现和质量控制等实际应用中具有重要价值

Method: 提出加权顺序组合正交匹配追踪(W-SCOMP)算法，改进现有检测程序效率。建立模拟框架对群组检测过程建模，并进行算法比较评估

Result: 理论证明W-SCOMP在无噪声非自适应群组检测中优于其他算法。实证结果与理论发现一致，扩展了解码算法范围

Conclusion: W-SCOMP算法提升了无噪声非自适应群组检测性能，为实际应用提供更有效的解决方案，推动了该领域的发展

Abstract: Group testing enables the identification of a small subset of defective items within a larger population by performing tests on pools of items rather than on each item individually. Over the years, it has not only attracted attention from the academic community, but has also demonstrated its potential in addressing real-world problems such as infectious disease screening, drug discovery and manufacturing quality control. With the emergence of the COVID-19 pandemic, interest in group testing has grown further, particularly in non-adaptive testing, due to its time efficiency compared to adaptive approaches. This highlights the importance of improving the performance currently achievable in such a scheme. This article focuses on advancing the field of noiseless non-adaptive group testing. The main objective of this work is to study and maximize the probability of successfully identifying the subset of defective items while performing as few tests as possible. To this end, we first note current well-known decoding algorithms, as well as established test design strategies for assigning items to pools. From this review, we identify key opportunities for improvement that inform the development of new decoding algorithms. Specifically, we propose a novel method, Weighted Sequential Combinatorial Orthogonal Matching Pursuit (W-SCOMP), to enhance the efficiency of existing detection procedures. Theoretical results demonstrate that W-SCOMP outperforms other algorithms in noiseless non-adaptive group testing. Furthermore, we develop a simulation framework to model the group testing process and conduct comparative evaluations between the proposed and existing algorithms. The empirical results are consistent with the theoretical findings. Overall, our work expands the range of available decoding algorithms and contributes to the broader understanding of noiseless non-adaptive group testing.

</details>


### [64] [Center-Fed Pinching Antenna System (C-PASS) Aided Wireless Communications](https://arxiv.org/abs/2601.07424)
*Xu Gan,Yuanwei Liu*

Main category: cs.IT

TL;DR: C-PASS天线系统通过可控功率分裂实现双自由度，提出PS、DS、TS三种协议，并分别优化波束赋形以最大化和速率。


<details>
  <summary>Details</summary>
Motivation: 传统PASS天线系统自由度有限，C-PASS通过中心馈电和可控功率分裂实现双倍自由度，提升通信性能。

Method: 提出C-PASS基本信号模型和三种协议：功率分裂(PS)、方向切换(DS)、时间切换(TS)。分别采用加权最小均方误差重构、惩罚算法和迭代分解方法优化波束赋形。

Result: 数值结果显示：低功率时TS最优，高功率时PS和DS因增强的自由度而获得显著更高的速率。

Conclusion: C-PASS架构通过双自由度设计有效提升通信性能，三种协议在不同功率场景下各有优势，为未来天线系统设计提供新思路。

Abstract: The novel architecture of the center-fed pinching antenna system (C-PASS) is investigated, where the waveguide-fed signal is divided into two propagation directions through controllable power splitting. By doing so, a doubled degree of freedom (DoF) is achieved compared to conventional PASS. Based on the new designed basic signal model of C-PASS, three practical operating protocols for C-PASS are proposed, namely power splitting (PS), direction switching (DS), and time switching (TS). Then, the sum-rate maximization problem for the joint optimization of transmit and pinching beamforming is formulated for each of the proposed protocols. 1) For PS, the highly coupled non-convex problem is first transformed into a tractable form via the weighted minimum mean square error reformulation and solved using the alternating optimization framework; 2) For DS, the above approach is subsequently extended to solve the mixed-integer constraints inherent for DS via the penalty-based algorithm; 3) For TS, the optimization problem can be decomposed into two subproblems and solved using the similar iterative techniques, while its optimal time allocation ratio is derived in closed form. Finally, numerical results reveal that TS is superior in the low-power regime, while PS and DS achieve significantly higher rates in the high-power regime due to the enhanced DoF.

</details>


### [65] [Secure Joint Source-Channel Coding for the AWGN Channel with Feedback: A Finite Blocklength Analysis](https://arxiv.org/abs/2601.07472)
*Sheng Su,Yuhan Yang,Chao Qi,Xuan He,Bin Dai,Xiaohu Tang*

Main category: cs.IT

TL;DR: 本文研究AWGN窃听信道在有限码长下的反馈方案，证明经典SK方案非最优，提出改进方案并建立有限码长逆定理。


<details>
  <summary>Details</summary>
Motivation: 在无限码长下，AWGN窃听信道在无噪声反馈下的保密容量等于无保密约束时的容量，且经典SK方案可达该容量。但在有限码长下，经典SK方案是否最优尚不明确，需要研究有限码长下的最优方案和性能界限。

Method: 提出改进的SK方案，可能优于经典方案；建立AWGN窃听信道反馈模型的有限码长逆定理，该逆定理也可视为无保密约束模型的逆定理。

Result: 证明在有限码长下经典SK方案非最优；改进的SK方案可能表现更好；建立了首个有限码长逆定理，并通过数值算例进一步解释结果。

Conclusion: 本文首次解决了AWGN窃听信道在有限码长下的反馈方案优化问题，证明了经典SK方案在有限码长下的非最优性，提出了改进方案并建立了理论界限，为有限码长下的安全通信设计提供了新见解。

Abstract: In the literature, it has been shown that the secrecy capacity of the additive white Gaussian noise (AWGN) wiretap channel with noise-free feedback equals the capacity of the same model without secrecy constraint, and the classical Schalkwijk-Kailath (SK) scheme achieves the secrecy capacity. In this paper, we show that in finite blocklength regime, the SK scheme is not optimal, and propose a modified SK scheme which may perform better than the classical one. Besides this, this paper establishes a finite blocklength converse for the AWGN wiretap channel with feedback, which can also be viewed as a converse for the same model without secrecy constraint. To the best of the authors' knowledge, this is the first paper to address such a problem, and the results of this paper are further explained via numerical examples.

</details>


### [66] [Frequency-Adaptive Multi-Band Architecture for Upper Mid-Band MIMO Systems](https://arxiv.org/abs/2601.07489)
*Emiel Vanspranghels,Zhuangzhuang Cui,Sofie Pollin*

Main category: cs.IT

TL;DR: 该论文研究了FR3频段（7-24GHz）在6G中的传播特性和MIMO性能，并提出了一种频率自适应的多频段MIMO架构，通过动态资源重用来优化频谱增益和MIMO增益的权衡。


<details>
  <summary>Details</summary>
Motivation: FR3频段（上中频段）被认为是6G的潜力频谱，但其传播特性和MIMO性能随频率和环境变化显著，且频谱可用性可能因现有用户而间歇性受限。需要深入理解该频段的特性并设计适应其动态特性的系统架构。

Method: 使用Sionna RT射线追踪在典型室内外场景中评估7、10、14、20和24GHz频段的SISO和MIMO配置。基于分析结果，提出了一种全数字频率自适应多频段MIMO架构，通过开关机制在FR3子频段间重新分配ADC/DAC和基带处理资源。

Result: FR3表现出介于sub-6GHz和毫米波之间的传播特性，同时支持有意义的空间复用，但具有强烈的场景依赖性。仿真结果表明，利用额外频谱通常是最优选择，而当子频段不可用或复用增益集中在特定频率时，自适应资源重用变得有益。

Conclusion: FR3频段为6G提供了有前景的频谱资源，其自适应多频段MIMO架构能够动态权衡带宽（频谱增益）和天线整合（MIMO增益），适应频谱可用性和信道约束，为6G系统设计提供了重要指导。

Abstract: FR3 ($\approx$7-24 GHz), also referred to as the upper mid-band, has recently emerged as promising spectrum for 6G; however, its propagation and MIMO characteristics vary significantly with frequency and environment, and spectrum availability may be intermittent due to incumbents. Using site-specific ray tracing (Sionna RT) in representative indoor and outdoor scenarios, we evaluate 7, 10, 14, 20, and 24 GHz under SISO and MIMO configurations. The results show that FR3 exhibits propagation characteristics intermediate between sub-6 GHz and mmWave bands while supporting meaningful spatial multiplexing, albeit with strong site dependence. Motivated by these findings, we propose a fully digital frequency-adaptive multi-band MIMO architecture that repurposes ADCs/DACs and baseband processing resources across FR3 subbands via switching, enabling dynamic trade-offs between bandwidth (spectrum gain) and antenna consolidation (MIMO gain) under availability and channel constraints. Simulation results demonstrate that exploiting additional spectrum is often optimal, while adaptive resource repurposing becomes beneficial when subbands are unavailable or when multiplexing gains are concentrated at specific frequencies.

</details>


### [67] [A Parity-Consistent Decomposition Method for the Weight Distribution of Pre-Transformed Polar Codes](https://arxiv.org/abs/2601.07515)
*Yang Liu,Bolin Wu,Yuxin Han,Kai Niu*

Main category: cs.IT

TL;DR: 提出基于奇偶一致性分解的高效算法，用于计算预变换极化码的汉明重量分布，通过构建扩展信息集和等价类理论显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 预变换极化码中预变换矩阵引入了比特依赖性，使得传统的重量分布计算方法变得复杂且计算量大，需要开发更高效的确定性算法。

Method: 1. 提出迭代算法构建扩展信息集，通过将信息比特扩展为0和1来消除比特相关性，从而利用奇偶一致性分解方法递归计算汉明重量分布。2. 建立预变换极化码的等价类理论，同一等价类中的码具有相同的重量分布但对应不同的扩展信息集大小，选择最小化扩展信息集大小的预变换矩阵来优化计算过程。

Result: 数值结果表明，与现有确定性算法相比，所提方法显著降低了计算复杂度。

Conclusion: 该论文提出的基于奇偶一致性分解的算法能够高效计算预变换极化码的重量分布，通过扩展信息集和等价类优化有效解决了比特依赖性问题并降低了计算复杂度。

Abstract: This paper introduces an efficient algorithm based on the Parity-Consistent Decomposition (PCD) method to determine the WD of pre-transformed polar codes. First, to address the bit dependencies introduced by the pre-transformation matrix, we propose an iterative algorithm to construct an \emph{Expanded Information Set}. By expanding the information bits within this set into 0s and 1s, we eliminate the correlations among information bits, thereby enabling the recursive calculation of the Hamming weight distribution using the \emph{PCD method}. Second, to further reduce computational complexity, we establish the theory of equivalence classes for pre-transformed polar codes. Codes within the same equivalence class share an identical weight distribution but correspond to different \emph{Expanded Information Set} sizes. By selecting the pre-transformation matrix that minimizes the \emph{Expanded Information Set} size within an equivalence class, we optimize the computation process. Numerical results demonstrate that the proposed method significantly reduces computational complexity compared to existing deterministic algorithms.

</details>


### [68] [Sparse Point-wise Privacy Leakage: Mechanism Design and Fundamental Limits](https://arxiv.org/abs/2601.07523)
*Amirreza Zamani,Sajad Daei,Parastoo Sadeghi,Mikael Skoglund*

Main category: cs.IT

TL;DR: 该论文研究信息论隐私机制设计问题，提出稀疏点式隐私泄露准则，在高隐私机制下将设计问题转化为稀疏二次最大化问题，并提出可多项式时间求解的凸半定规划松弛方法。


<details>
  <summary>Details</summary>
Motivation: 研究隐私机制设计问题，其中代理观察与敏感数据X相关的有用数据Y，需要设计从Y生成的披露数据U。现有隐私标准可能不足，需要新的隐私准则来同时约束每个披露符号与敏感数据的关系。

Method: 引入稀疏点式隐私泄露准则，在高隐私机制下使用信息几何概念获得互信息的局部二次近似。当泄露矩阵可逆时，将设计问题转化为带ℓ₀约束的稀疏二次最大化问题（Rayleigh商问题）。提出凸半定规划松弛方法，可在多项式时间内求解。

Result: 证明了对于近似问题，可以无损失最优性地限制在具有均匀分布的二元释放变量U上。对于小字母大小，可以通过组合支持枚举计算精确稀疏约束最优解。对于一般维度，提出可多项式时间求解的SDP松弛方法，并识别出稀疏最优解饱和于无约束谱值的稀疏阈值。

Conclusion: 该论文提出了新的稀疏点式隐私泄露准则，将隐私机制设计问题转化为可处理的优化问题，并提供了有效的求解方法，为高隐私机制下的信息论隐私设计提供了理论框架和实用工具。

Abstract: We study an information-theoretic privacy mechanism design problem, where an agent observes useful data $Y$ that is arbitrarily correlated with sensitive data $X$, and design disclosed data $U$ generated from $Y$ (the agent has no direct access to $X$). We introduce \emph{sparse point-wise privacy leakage}, a worst-case privacy criterion that enforces two simultaneous constraints for every disclosed symbol $u\in\mathcal{U}$: (i) $u$ may be correlated with at most $N$ realizations of $X$, and (ii) the total leakage toward those realizations is bounded. In the high-privacy regime, we use concepts from information geometry to obtain a local quadratic approximation of mutual information which measures utility between $U$ and $Y$. When the leakage matrix $P_{X|Y}$ is invertible, this approximation reduces the design problem to a sparse quadratic maximization, known as the Rayleigh-quotient problem, with an $\ell_0$ constraint. We further show that, for the approximated problem, one can without loss of optimality restrict attention to a binary released variable $U$ with a uniform distribution. For small alphabet sizes, the exact sparsity-constrained optimum can be computed via combinatorial support enumeration, which quickly becomes intractable as the dimension grows. For general dimensions, the resulting sparse Rayleigh-quotient maximization is NP-hard and closely related to sparse principal component analysis (PCA). We propose a convex semidefinite programming (SDP) relaxation that is solvable in polynomial time and provides a tractable surrogate for the NP-hard design, together with a simple rounding procedure to recover a feasible leakage direction. We also identify a sparsity threshold beyond which the sparse optimum saturates at the unconstrained spectral value and the SDP relaxation becomes tight.

</details>


### [69] [Estimators for Substitution Rates in Genomes from Read Data](https://arxiv.org/abs/2601.07546)
*Shiv Pratap Singh Rathore,Navin Kashyap*

Main category: cs.IT

TL;DR: 提出在测序读段噪声下估计序列间突变率的方法，扩展了传统需要完整序列的比对自由方法


<details>
  <summary>Details</summary>
Motivation: 现有比对自由方法通常假设能直接访问完整序列，但在实际测序场景中只能观测到带噪声的读段，需要扩展这些方法以适应测序框架

Method: 使用简单模型，假设突变和测序错误都是替换类型；提出多个估计器，为其中一个提供理论保证，并通过模拟评估其他估计器

Result: 论文提出了适用于测序读段噪声环境的突变率估计方法，其中一个估计器有理论保证，其他估计器通过模拟验证了有效性

Conclusion: 成功将比对自由突变率估计方法扩展到测序框架，为只能获得噪声读段的实际应用场景提供了可行的解决方案

Abstract: We study the problem of estimating the mutation rate between two sequences from noisy sequencing reads. Existing alignment-free methods typically assume direct access to the full sequences. We extend these methods to the sequencing framework, where only noisy reads from the sequences are observed. We use a simple model in which both mutations and sequencing errors are substitutions. We propose multiple estimators, provide theoretical guarantees for one of them, and evaluate the others through simulations.

</details>


### [70] [On the Sequence Reconstruction Problem for the Single-Deletion Two-Substitution Channel](https://arxiv.org/abs/2601.07547)
*Wentu Song,Kui Cai,Tony Q. S. Quek*

Main category: cs.IT

TL;DR: 研究了单删除双替换信道下的序列重构问题，证明了当两个q元长度为n的序列汉明距离d≥2时，其错误球交集大小的上界为(q²-1)n²-(3q²+5q-5)n+O_q(1)，且该上界是紧的（相差一个常数项）。


<details>
  <summary>Details</summary>
Motivation: 现有序列重构研究主要关注单一错误类型（插入、删除或替换），对于混合错误类型（如同时允许删除和替换）的研究相对较少。本文研究单删除双替换信道下的序列重构问题，旨在确定该信道下保证正确重构所需的最小错误副本数。

Method: 研究单删除双替换信道（允许一次删除和最多两次替换）下的序列重构问题。通过分析两个q元长度n序列在汉明距离d≥2条件下，其错误球交集的最大可能大小。采用理论分析方法推导上界。

Result: 证明了两个q元长度n序列（汉明距离d≥2）在单删除双替换信道下的错误球交集上界为(q²-1)n²-(3q²+5q-5)n+O_q(1)，其中O_q(1)是与n无关但依赖于q的常数。同时证明该上界是紧的（相差一个常数项）。

Conclusion: 本文解决了单删除双替换信道下序列重构的基本问题，确定了错误球交集的最大可能大小，为混合错误类型信道下的序列重构理论提供了重要进展。该结果为确定保证正确重构所需的最小错误副本数奠定了基础。

Abstract: The Levenshtein sequence reconstruction problem studies the reconstruction of a transmitted sequence from multiple erroneous copies of it. A fundamental question in this field is to determine the minimum number of erroneous copies required to guarantee correct reconstruction of the original sequence. This problem is equivalent to determining the maximum possible intersection size of two error balls associated with the underlying channel. Existing research on the sequence reconstruction problem has largely focused on channels with a single type of error, such as insertions, deletions, or substitutions alone. However, relatively little is known for channels that involve a mixture of error types, for instance, channels allowing both deletions and substitutions. In this work, we study the sequence reconstruction problem for the single-deletion two-substitution channel, which allows one deletion and at most two substitutions applied to the transmitted sequence. Specifically, we prove that if two $q$-ary length-$n$ sequences have the Hamming distance $d\geq 2$, where $q\geq 2$ is any fixed integer, then the intersection size of their error balls under the single-deletion two-substitution channel is upper bounded by $(q^2-1)n^2-(3q^2+5q-5)n+O_q(1)$, where $O_q(1)$ is a constant independent from $n$ but dependent on $q$. Moreover, we show that this upper bound is tight up to an additive constant.

</details>


### [71] [A $q$-Polymatroid Framework for Information Leakage in Secure Linear Network Coding](https://arxiv.org/abs/2601.07567)
*Eimear Byrne,Johan Vester Dinesen,Ragnar Freij-Hollanti,Camilla Hollanti*

Main category: cs.IT

TL;DR: 研究基于嵌套秩度量码的安全线性网络编码方案中的信息泄露问题，建立了信息泄露量与相关q-多拟阵条件秩函数的关系，并推广了经典访问结构理论到秩度量场景。


<details>
  <summary>Details</summary>
Motivation: 研究安全线性网络编码方案中的信息泄露问题，特别是在基于嵌套秩度量码的方案中，当攻击者观察到网络链路子集时，需要量化信息泄露量并建立理论框架。

Method: 将信息泄露问题与可表示q-多拟阵的条件秩函数联系起来，引入q-多拟阵端口和q-访问结构概念，并将Massey对应关系和Brickell-Davenport定理推广到秩度量设置。

Result: 证明了信息泄露量由底层秩度量码对所关联的可表示q-多拟阵的条件秩函数刻画，建立了q-多拟阵端口和q-访问结构的结构性质，并证明了秩度量设置下的q-模拟Brickell-Davenport定理。

Conclusion: 该研究为安全线性网络编码中的信息泄露分析提供了统一的q-多拟阵理论框架，将经典访问结构理论成功推广到秩度量场景，为设计更安全的网络编码方案奠定了理论基础。

Abstract: We study information leakage in secure linear network coding schemes based on nested rank-metric codes. We show that the amount of information leaked to an adversary that observes a subset of network links is characterized by the conditional rank function of a representable $q$-polymatroid associated with the underlying rank-metric code pair. Building on this connection, we introduce the notions of $q$-polymatroid ports and $q$-access structures and describe their structural properties. Moreover, we extend Massey's correspondence between minimal codewords and minimal access sets to the rank-metric setting and prove a $q$-analogue of the Brickell--Davenport theorem.

</details>


### [72] [Clipped Affine Policy: Low-Complexity Near-Optimal Online Power Control for Energy Harvesting Communications over Fading Channels](https://arxiv.org/abs/2601.07622)
*Hao Wu,Shengtian Yang,Huiguo Gao,Diao Wang,Jun Chen,Guanding Yu*

Main category: cs.IT

TL;DR: 论文提出基于线性策略的近似方法，推导出乐观和鲁棒两种裁剪仿射功率控制策略，并结合强化学习实现在线功率控制，在复杂度和最优性间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 研究无线衰落信道中点对点能量收集通信的在线功率控制问题，旨在解决传统方法在计算复杂度和性能之间的权衡问题。

Method: 推导Bellman方程中相对值函数的线性策略近似，得到乐观和鲁棒两种裁剪仿射功率控制策略（电池水平与信道信噪比系数倒数的裁剪仿射函数），并提出领域知识增强的强化学习算法。

Result: 鲁棒裁剪仿射策略（结合RL，最多使用5个参数）在各种场景下优于现有方法，相对于最优策略的性能损失小于2%。

Conclusion: 提出的方法在计算复杂度和最优性之间取得了良好平衡，鲁棒裁剪仿射策略结合强化学习是有效的在线功率控制解决方案。

Abstract: This paper investigates online power control for point-to-point energy harvesting communications over wireless fading channels. A linear-policy-based approximation is derived for the relative-value function in the Bellman equation of the power control problem. This approximation leads to two fundamental power control policies: optimistic and robust clipped affine policies, both taking the form of a clipped affine function of the battery level and the reciprocal of channel signal-to-noise ratio coefficient. They are essentially battery-limited weighted directional waterfilling policies operating between adjacent time slots. By leveraging the relative-value approximation and derived policies, a domain-knowledge-enhanced reinforcement learning (RL) algorithm is proposed for online power control. The proposed approach is further extended to scenarios with energy and/or channel lookahead. Comprehensive simulation results demonstrate that the proposed methods achieve a good balance between computational complexity and optimality. In particular, the robust clipped affine policy (combined with RL, using at most five parameters) outperforms all existing approaches across various scenarios, with less than 2\% performance loss relative to the optimal policy.

</details>


### [73] [New $X$-Secure $T$-Private Information Retrieval Schemes via Rational Curves and Hermitian Curves](https://arxiv.org/abs/2601.07676)
*Yuan Gao,Weijun Fang,Jingke Xu,Jiejing Wen*

Main category: cs.IT

TL;DR: 本文提出了一种新的XSTPIR方案构建方法，通过提高已有曲线上有理点的利用效率，而不是追求更高亏格和更多有理点的曲线，从而获得更高的最大PIR率。


<details>
  <summary>Details</summary>
Motivation: 现有XSTPIR方案主要通过使用更高亏格、更多有理点的曲线（如Hermitian曲线）来提高PIR率。本文提出不同思路：在已有曲线上，通过提高有理点的利用效率来达到相同目标。

Method: 引入多项式空间span_{F_q}{1,x,...,x^{k-1}}的一组新基替代拉格朗日插值基，基于有理曲线和Hermitian曲线分别构建了两个新的XSTPIR方案族。

Result: 新方案性能优于现有方案：当q^2≥14^2且X+T≥4q时，基于Hermitian曲线的方案提供已知最大PIR率；当q^2≥28^2且X+T≥4时，两个方案共同提供已知最大PIR率。

Conclusion: 通过提高有理点利用效率而非追求更高亏格曲线，可以构建性能更优的XSTPIR方案，为XSTPIR方案设计提供了新方向。

Abstract: $X$-secure and $T$-private information retrieval (XSTPIR) is a variant of private information retrieval where data security is guaranteed against collusion among up to $X$ servers and the user's retrieval privacy is guaranteed against collusion among up to $T$ servers. Recently, researchers have constructed XSTPIR schemes through the theory of algebraic geometry codes and algebraic curves, with the aim of obtaining XSTPIR schemes that have higher maximum PIR rates for fixed field size and $X,T$ (the number of servers $N$ is not restricted). The mainstream approach is to employ curves of higher genus that have more rational points, evolving from rational curves to elliptic curves to hyperelliptic curves and, most recently, to Hermitian curves.
  In this paper, we propose a different perspective: with the shared goal of constructing XSTPIR schemes with higher maximum PIR rates, we move beyond the mainstream approach of seeking curves with higher genus and more rational points. Instead, we aim to achieve this goal by enhancing the utilization efficiency of rational points on curves that have already been considered in previous work. By introducing a family of bases for the polynomial space $\text{span}_{\mathbb{F}_q}\{1,x,\dots,x^{k-1}\}$ as an alternative to the Lagrange interpolation basis, we develop two new families of XSTPIR schemes based on rational curves and Hermitian curves, respectively. Parameter comparisons demonstrate that our schemes achieve superior performance. Specifically, our Hermitian-curve-based XSTPIR scheme provides the largest known maximum PIR rates when the field size $q^2\geq 14^2$ and $X+T\geq 4q$. Moreover, for any field size $q^2\geq 28^2$ and $X+T\geq 4$, our two XSTPIR schemes collectively provide the largest known maximum PIR rates.

</details>


### [74] [Weak Composition Lattices and Ring-Linear Anticodes](https://arxiv.org/abs/2601.07725)
*Jessica Bariffi,Drisana Bhatia,Giuseppe Cotardo,Violetta Weger*

Main category: cs.IT

TL;DR: 论文研究环线性码的Lee度量，引入并刻画了最优Lee度量反码，建立了反码格与弱组合格之间的双射，并用于定义新的编码不变量。


<details>
  <summary>Details</summary>
Motivation: 格和偏序集在编码理论中日益重要，为研究纠错码的结构和代数性质提供了组合框架。受近期连接格理论、反码和编码理论不变量的研究启发，本文研究带有Lee度量的环线性码。

Method: 引入并刻画了环ℤ/p^sℤ上的最优Lee度量反码，展示了这类反码可以自然地按子类型划分，并在包含关系下形成格。建立了该格与按支配序排列的弱组合格之间的双射。

Result: 证明了最优Lee度量反码家族形成格结构，并建立了与弱组合格的同构对应关系。利用这一对应关系，通过反码方法为Lee度量码引入了新的不变量。

Conclusion: 通过建立Lee度量反码格与弱组合格之间的对应关系，为Lee度量编码理论提供了新的组合工具和不变分析方法，扩展了格理论在编码理论中的应用。

Abstract: Lattices and partially ordered sets have played an increasingly important role in coding theory, providing combinatorial frameworks for studying structural and algebraic properties of error-correcting codes. Motivated by recent works connecting lattice theory, anticodes, and coding-theoretic invariants, we investigate ring-linear codes endowed with the Lee metric. We introduce and characterize optimal Lee-metric anticodes over the ring $\mathbb{Z}/p^s\mathbb{Z}$. We show that the family of such anticodes admits a natural partition into subtypes and forms a lattice under inclusion. We establish a bijection between this lattice and a lattice of weak compositions ordered by dominance. As an application, we use this correspondence to introduce new invariants for Lee-metric codes via an anticode approach.

</details>


### [75] [Lossy Source Coding with Broadcast Side Information](https://arxiv.org/abs/2601.07797)
*Yiqi Chen,Holger Boche,Marc Geitz*

Main category: cs.IT

TL;DR: 研究带有广播边信息的信源编码问题，边信息通过有噪广播信道发送给两个接收器，给出了RDB四元组的外界和可实现的分离方案，并在高斯二次情况下比较了分离方案与未编码方案。


<details>
  <summary>Details</summary>
Motivation: 研究广播边信息场景下的信源编码问题，其中边信息通过有噪广播信道传输给多个接收器，需要分析速率-失真-带宽之间的权衡关系。

Method: 提出了RDB四元组的外界，给出了基于分离方案的可实现RDB四元组，并在一些特殊情况下提供了完整刻画，最后在二次高斯情况下比较了分离方案与未编码方案。

Result: 获得了广播边信息信源编码问题的RDB外界和可实现区域，在某些特殊情况下实现了完整刻画，并在高斯二次情况下分析了分离方案与未编码方案的性能比较。

Conclusion: 该论文为广播边信息场景下的信源编码问题提供了理论框架和分析工具，揭示了分离方案与未编码方案在不同条件下的性能表现。

Abstract: This paper considers the source coding problem with broadcast side information. The side information is sent to two receivers through a noisy broadcast channel. We provide an outer bound of the rate--distortion--bandwidth (RDB) quadruples and achievable RDB quadruples when the helper uses a separation-based scheme. Some special cases with full characterization are also provided. We then compare the separation-based scheme with the uncoded scheme in the quadratic Gaussian case.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [76] [Reflective Reasoning for SQL Generation](https://arxiv.org/abs/2601.06678)
*Isabelle Mohr,Joao Gandarela,John Dujany,Andre Freitas*

Main category: cs.DB

TL;DR: 提出一个基于反射式精炼的受控文本到SQL框架，通过将生成分解为类型化阶段并应用反馈作为阶段级生成机制的持久更新，解决现有方法中的语法语义漂移、修正不可迁移和上下文窗口扩展问题


<details>
  <summary>Details</summary>
Motivation: 现有文本到SQL系统在处理复杂真实数据库时仍然脆弱：迭代精炼常引入语法和语义漂移，修正难以跨查询迁移，简单使用大上下文窗口扩展性差

Method: 提出反射式精炼框架，将SQL生成分解为类型化阶段，应用反馈作为阶段级生成机制的持久更新。通过反射-精炼循环定位违规到责任阶段，最大化保留已验证约束，支持查询集的单调改进。结合基于解释器的检查和基于LLM的语义覆盖验证作为认知判断，无需黄金SQL

Result: 在Spider和BIRD数据集上的实验显示，相比强提示基线获得一致增益，在小精炼预算内实现稳健收敛，在前沿和开源模型家族中均提高执行准确率

Conclusion: 提出的受控文本到SQL框架通过反射式精炼有效解决了现有方法的局限性，实现了更稳健和可扩展的复杂数据库查询生成

Abstract: Robust text-to-SQL over complex, real-world databases remains brittle even with modern LLMs: iterative refinement often introduces syntactic and semantic drift, corrections tend to be non-transferable across queries, and naive use of large context windows scales poorly. We propose a controlled text-to-SQL framework built around reflective refinement. Instead of repeatedly rewriting the current SQL instance, the system decomposes generation into typed stages and applies feedback as persistent updates to the stage-level generation mechanism. A Reflection-Refinement Loop localizes violations to the responsible stage maximize preservation of previously validated constraints and support monotonic improvement over a query set. The method operates without gold SQL by combining interpreter-based checks with LLM-based semantic coverage verification as epistemic judges. Experiments on Spider and BIRD demonstrate consistent gains over strong prompting baselines, robust convergence within a small refinement budget, and improved execution accuracy across both frontier and open-weight model families.

</details>


### [77] [Algorithm Support for Graph Databases, Done Right](https://arxiv.org/abs/2601.06705)
*Daan de Graaf,Robert Brijder,Soham Chakraborty,George Fletcher,Bram van de Wall,Nikolay Yakovets*

Main category: cs.DB

TL;DR: GraphAlg是一个用于图算法的领域特定语言，可将图算法编译为关系代数，实现与查询处理管道的无缝集成，解决了现有图数据库在表达复杂算法方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有图数据库查询语言无法表达PageRank等复杂算法，导致需要昂贵的数据处理。现有的算法库、顶点中心API和递归CTE等解决方案在表达能力、性能和易用性方面存在不足，需要一种统一的解决方案。

Method: GraphAlg基于线性代数基础，提供直观的矩阵操作，可编译为关系代数。系统支持稀疏性分析、循环不变代码移动和原地聚合等激进优化技术，在AvantGraph中实现。

Result: 在LDBC Graphalytics基准测试中表现出色，相比SQL/Python和Pregel显著减少了代码复杂度，同时保持了优异的性能。

Conclusion: GraphAlg证明了图数据库可以作为查询和分析的统一平台，为图算法提供了表达能力强、性能优异且易于使用的解决方案。

Abstract: Graph database query languages cannot express algorithms like PageRank, forcing costly data wrangling, while existing solutions such as algorithm libraries, vertex-centric APIs, and recursive CTEs lack the necessary combination of expressiveness, performance, and usability. We present GraphAlg: a domain-specific language for graph algorithms that compiles to relational algebra, enabling seamless integration with query processing pipelines. Built on linear algebra foundations, GraphAlg provides intuitive matrix operations that are amenable to aggressive optimization including sparsity analysis, loop-invariant code motion, and in-place aggregation. Our implementation in AvantGraph demonstrates significant code complexity reduction compared to SQL/Python and Pregel while achieving excellent performance on LDBC Graphalytics benchmarks. GraphAlg establishes that graph databases can serve as unified platforms for both queries and analytics.

</details>


### [78] [Vextra: A Unified Middleware Abstraction for Heterogeneous Vector Database Systems](https://arxiv.org/abs/2601.06727)
*Chandan Suri,Gursifath Bhasin*

Main category: cs.DB

TL;DR: Vextra是一个解决向量数据库API碎片化问题的中间件抽象层，提供统一的高层API和可插拔适配器架构


<details>
  <summary>Details</summary>
Motivation: 向量搜索在AI应用中的快速集成催生了多样化的专用向量数据库生态系统，但这也导致了严重的API碎片化问题。开发者面临分散、专有且不稳定的API合约，这阻碍了应用可移植性，增加了维护成本，并导致供应商锁定。

Method: Vextra引入了一个中间件抽象层，提供统一的高层API用于核心数据库操作（数据插入、相似性搜索、元数据过滤），并采用可插拔的适配器架构将这些统一API调用转换为各种后端数据库的本机协议。

Result: Vextra能够解决向量数据库生态系统中的API碎片化问题，促进互操作性，支持更高级的查询优化，同时只带来最小的性能开销。

Conclusion: 这样的抽象层是向量数据库生态系统成熟的关键一步，有助于解决当前的碎片化问题，为开发者提供更好的可移植性和更低的维护成本。

Abstract: The rapid integration of vector search into AI applications, particularly for Retrieval Augmented Generation (RAG), has catalyzed the emergence of a diverse ecosystem of specialized vector databases. While this innovation offers a rich choice of features and performance characteristics, it has simultaneously introduced a significant challenge: severe API fragmentation. Developers face a landscape of disparate, proprietary, and often volatile API contracts, which hinders application portability, increases maintenance overhead, and leads to vendor lock-in. This paper introduces Vextra, a novel middleware abstraction layer designed to address this fragmentation. Vextra presents a unified, high-level API for core database operations, including data upsertion, similarity search, and metadata filtering. It employs a pluggable adapter architecture to translate these unified API calls into the native protocols of various backend databases. We argue that such an abstraction layer is a critical step towards maturing the vector database ecosystem, fostering interoperability, and enabling higher-level query optimization, while imposing minimal performance overhead.

</details>


### [79] [The Complexity of Finding Missing Answer Repairs](https://arxiv.org/abs/2601.06764)
*Jesse Comer,Val Tannen*

Main category: cs.DB

TL;DR: 本文研究了数据库查询答案中缺失元组的修复问题，确定了哪些查询类可以在多项式时间内找到最小修复，哪些是NP难的，并分析了数据复杂度和组合复杂度的差异。


<details>
  <summary>Details</summary>
Motivation: 研究数据库查询答案中缺失元组的修复问题，旨在确定在什么条件下可以高效地找到数据库修复，以及不同查询语言的复杂性影响。

Method: 通过理论分析，研究不同查询类（包括带否定原子的合取查询并集、允许投影和连接操作的查询等）的修复存在性问题和最小修复问题的计算复杂性。

Result: 1. 当查询作为输入时，修复存在性问题的多项式时间可解性等价于允许弱形式投影和选择的查询类的可满足性问题；2. 对于允许投影和连接的查询，最小修复问题是NP难的且难以近似；3. 带否定原子的合取查询并集的最小修复大小计算是OptP[log(n)]-完全的；4. 允许递归时复杂性显著增加（EXP下界），但从数据复杂度角度看，半正datalog程序的所有查询都可以在多项式时间内找到最小修复。

Conclusion: 数据库修复问题的复杂性高度依赖于查询语言的特征，某些查询类可以在多项式时间内解决，而其他类则是计算困难的，数据复杂度通常比组合复杂度更友好。

Abstract: We investigate the problem of identifying database repairs for missing tuples in query answers. We show that when the query is part of the input - the combined complexity setting - determining whether or not a repair exists is polynomial-time is equivalent to the satisfiability problem for classes of queries admitting a weak form of projection and selection. We then identify the sub-classes of unions of conjunctive queries with negated atoms, defined by the relational algebra operations permitted to appear in the query, for which the minimal repair problem can be solved in polynomial time. In contrast, we show that the problem is NP-hard, as well as set cover-hard to approximate via strict reductions, whenever both projection and join are permitted in the input query. Additionally, we show that finding the size of a minimal repair for unions of conjunctive queries (with negated atoms permitted) is OptP[log(n)]-complete, while computing a minimal repair is possible with O($n^2$) queries to an NP oracle. With recursion permitted, the combined complexity of all of these variants increases significantly, with an EXP lower bound. However, from the data complexity perspective, we show that minimal repairs can be identified in polynomial time for all queries expressible as semi-positive datalog programs.

</details>


### [80] [VISTA: Knowledge-Driven Interpretable Vessel Trajectory Imputation via Large Language Models](https://arxiv.org/abs/2601.06940)
*Hengyu Liu,Tianyi Li,Haoyu Wang,Kristian Torp,Tiancheng Zhang,Yushuai Li,Christian S. Jensen*

Main category: cs.DB

TL;DR: VISTA：首个知识驱动的可解释船舶轨迹补全框架，结合结构化数据知识和LLM知识，通过数据-知识-数据循环实现高效补全，提升下游任务性能


<details>
  <summary>Details</summary>
Motivation: 现有船舶轨迹补全方法主要关注轨迹恢复，缺乏可解释性，无法为下游任务（如异常检测和航线规划）提供底层知识支持

Method: 1) 定义底层知识为结构化数据知识（从AIS数据提取）和隐式LLM知识（从大规模互联网语料获取）；2) 开发数据-知识-数据循环，使用结构化知识图谱进行知识提取和知识驱动的轨迹补全；3) 引入工作流管理层协调端到端流程，支持并行知识提取和轨迹补全

Result: 在两个大型AIS数据集上，VISTA达到最先进的补全精度和计算效率，比基线方法提升5%-94%，时间成本降低51%-93%，同时产生可解释的知识线索

Conclusion: VISTA是首个提供可解释性的轨迹补全框架，不仅能准确补全轨迹，还能提供底层知识支持下游分析任务，代码已公开

Abstract: The Automatic Identification System provides critical information for maritime navigation and safety, yet its trajectories are often incomplete due to signal loss or deliberate tampering. Existing imputation methods emphasize trajectory recovery, paying limited attention to interpretability and failing to provide underlying knowledge that benefits downstream tasks such as anomaly detection and route planning. We propose knowledge-driven interpretable vessel trajectory imputation (VISTA), the first trajectory imputation framework that offers interpretability while simultaneously providing underlying knowledge to support downstream analysis. Specifically, we first define underlying knowledge as a combination of Structured Data-derived Knowledge (SDK) distilled from AIS data and Implicit LLM Knowledge acquired from large-scale Internet corpora. Second, to manage and leverage the SDK effectively at scale, we develop a data-knowledge-data loop that employs a Structured Data-derived Knowledge Graph for SDK extraction and knowledge-driven trajectory imputation. Third, to efficiently process large-scale AIS data, we introduce a workflow management layer that coordinates the end-to-end pipeline, enabling parallel knowledge extraction and trajectory imputation with anomaly handling and redundancy elimination. Experiments on two large AIS datasets show that VISTA is capable of state-of-the-art imputation accuracy and computational efficiency, improving over state-of-the-art baselines by 5%-94% and reducing time cost by 51%-93%, while producing interpretable knowledge cues that benefit downstream tasks. The source code and implementation details of VISTA are publicly available.

</details>


### [81] [Jasper: ANNS Quantized for Speed, Built for Change on GPU](https://arxiv.org/abs/2601.07048)
*Hunter McCoy,Zikun Wang,Prashant Pandey*

Main category: cs.DB

TL;DR: Jasper是一个GPU原生的近似最近邻搜索系统，通过改进Vamana图索引，实现了高查询吞吐量和可更新性，解决了现有GPU ANNS系统的三个关键限制。


<details>
  <summary>Details</summary>
Motivation: GPU在ANNS中具有巨大潜力，但现有GPU加速系统面临三个关键问题：1) 对动态数据集缺乏快速批量更新能力；2) 高维向量导致内存带宽压力，缺乏高效量化技术；3) 贪婪搜索的数据依赖内存访问难以实现计算与内存重叠。

Method: 基于Vamana图索引，提出三个创新：1) CUDA批量并行构建算法实现无锁流式插入；2) GPU高效的RaBitQ量化技术，减少8倍内存占用且避免随机访问惩罚；3) 优化的贪婪搜索内核，提高计算利用率。

Result: 在五个数据集上的评估显示：查询吞吐量比CAGRA高1.93倍，屋顶模型测量达到80%峰值利用率；构建速度平均比CAGRA快2.4倍；相比最快的GPU Vamana实现BANG，查询速度快19-131倍。

Conclusion: Jasper成功解决了GPU ANNS系统的关键限制，实现了高查询吞吐量和可更新性，为动态数据集的高性能近似最近邻搜索提供了有效的GPU原生解决方案。

Abstract: Approximate nearest neighbor search (ANNS) is a core problem in machine learning and information retrieval applications. GPUs offer a promising path to high-performance ANNS: they provide massive parallelism for distance computations, are readily available, and can co-locate with downstream applications.
  Despite these advantages, current GPU-accelerated ANNS systems face three key limitations. First, real-world applications operate on evolving datasets that require fast batch updates, yet most GPU indices must be rebuilt from scratch when new data arrives. Second, high-dimensional vectors strain memory bandwidth, but current GPU systems lack efficient quantization techniques that reduce data movement without introducing costly random memory accesses. Third, the data-dependent memory accesses inherent to greedy search make overlapping compute and memory difficult, leading to reduced performance.
  We present Jasper, a GPU-native ANNS system with both high query throughput and updatability. Jasper builds on the Vamana graph index and overcomes existing bottlenecks via three contributions: (1) a CUDA batch-parallel construction algorithm that enables lock-free streaming insertions, (2) a GPU-efficient implementation of RaBitQ quantization that reduces memory footprint up to 8x without the random access penalties, and (3) an optimized greedy search kernel that increases compute utilization, resulting in better latency hiding and higher throughput.
  Our evaluation across five datasets shows that Jasper achieves up to 1.93x higher query throughput than CAGRA and achieves up to 80% peak utilization as measured by the roofline model. Jasper's construction scales efficiently and constructs indices an average of 2.4x faster than CAGRA while providing updatability that CAGRA lacks. Compared to BANG, the previous fastest GPU Vamana implementation, Jasper delivers 19-131x faster queries.

</details>


### [82] [RAIRS: Optimizing Redundant Assignment and List Layout for IVF-Based ANN Search](https://arxiv.org/abs/2601.07183)
*Zehai Yang,Shimin Chen*

Main category: cs.DB

TL;DR: RAIRS提出了一种优化的冗余分配IVF方法，通过AIR指标改进列表选择策略，并利用SEIL布局减少重复距离计算，在欧几里得空间中显著提升查询性能。


<details>
  <summary>Details</summary>
Motivation: 现有IVF方法中的冗余分配策略存在两个主要问题：1) 在欧几里得空间中没有优化的列表选择方法，现有基于距离的朴素策略效果不佳；2) 搜索时可能多次访问同一向量，导致重复距离计算，降低查询吞吐量。

Method: 提出RAIRS框架：1) 针对列表选择问题，设计了AIR指标，不仅考虑距离还考虑方向，以支持更接近数据向量但远离第一个选定列表质心的查询；2) 针对重复计算问题，提出SEIL布局，利用共享单元格减少IVF搜索中的重复距离计算。

Result: 在代表性真实数据集上的实验表明，RAIRS优于现有的冗余分配解决方案，相比性能最佳的IVF方法（IVF-PQ Fast Scan with refinement）实现了最高1.33倍的性能提升。

Conclusion: RAIRS通过优化的列表选择指标AIR和减少重复计算的SEIL布局，有效解决了IVF冗余分配中的两个关键挑战，在欧几里得空间中显著提升了近似最近邻搜索的性能。

Abstract: IVF is one of the most widely used ANNS (Approximate Nearest Neighbors Search) methods in vector databases. The idea of redundant assignment is to assign a data vector to more than one IVF lists for reducing the chance of missing true neighbors in IVF search. However, the naive strategy, which selects the second IVF list based on the distance between a data vector and the list centroids, performs poorly. Previous work focuses only on the inner product distance, while there is no optimized list selection study for the most popular Euclidean space. Moreover, the IVF search may access the same vector in more than one lists, resulting in redundant distance computation and decreasing query throughput. In this paper, we present RAIRS to address the above two challenges. For the challenge of the list selection, we propose an optimized AIR metric for the Euclidean space. AIR takes not only distances but also directions into consideration in order to support queries that are closer to the data vector but father away from the first chosen list's centroid. For the challenge of redundant distance computation, we propose SEIL, an optimized list layout that exploits shared cells to reduce repeated distance computations for IVF search. Our experimental results using representative real-world data sets show that RAIRS out-performs existing redundant assignment solutions and achieves up to 1.33x improvement over the best-performing IVF method, IVF-PQ Fast Scan with refinement.

</details>
