<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 1]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.DS](#cs.DS) [Total: 14]
- [cs.IT](#cs.IT) [Total: 3]
- [cs.IR](#cs.IR) [Total: 5]
- [cs.MM](#cs.MM) [Total: 4]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [DynaQuery: A Self-Adapting Framework for Querying Structured and Multimodal Data](https://arxiv.org/abs/2510.18029)
*Aymane Hassini*

Main category: cs.DB

TL;DR: DynaQuery是一个统一的自适应框架，通过Schema Introspection and Linking Engine (SILE)解决混合数据库的自然语言查询问题，相比传统RAG方法显著提高了可靠性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在复杂混合数据库上进行自然语言查询时面临的挑战：需要同时处理结构化多关系模式和链接的非结构化内容的语义推理。

Method: 提出DynaQuery框架，核心是Schema Introspection and Linking Engine (SILE)，将模式链接提升为查询规划的一等公民，建立了结构感知的架构。

Result: 相比非结构化检索增强生成(RAG)范式，SILE设计显著更鲁棒，几乎消除了SCHEMA_HALLUCINATION等灾难性上下文故障，在复杂基准测试中展现出从纯模式感知到整体语义感知的关键泛化原则。

Conclusion: 该研究为开发鲁棒、自适应且可预测一致的自然语言数据库接口提供了经过验证的架构基础。

Abstract: The rise of Large Language Models (LLMs) has accelerated the long-standing
goal of enabling natural language querying over complex, hybrid databases. Yet,
this ambition exposes a dual challenge: reasoning jointly over structured,
multi-relational schemas and the semantic content of linked unstructured
assets. To overcome this, we present DynaQuery - a unified, self-adapting
framework that serves as a practical blueprint for next-generation "Unbound
Databases." At the heart of DynaQuery lies the Schema Introspection and Linking
Engine (SILE), a novel systems primitive that elevates schema linking to a
first-class query planning phase. We conduct a rigorous, multi-benchmark
empirical evaluation of this structure-aware architecture against the prevalent
unstructured Retrieval-Augmented Generation (RAG) paradigm. Our results
demonstrate that the unstructured retrieval paradigm is architecturally
susceptible to catastrophic contextual failures, such as SCHEMA_HALLUCINATION,
leading to unreliable query generation. In contrast, our SILE-based design
establishes a substantially more robust foundation, nearly eliminating this
failure mode. Moreover, end-to-end validation on a complex, newly curated
benchmark uncovers a key generalization principle: the transition from pure
schema-awareness to holistic semantics-awareness. Taken together, our findings
provide a validated architectural basis for developing natural language
database interfaces that are robust, adaptable, and predictably consistent.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [2] [On Condorcet's Jury Theorem with Abstention](https://arxiv.org/abs/2510.18062)
*Reshef Meir,Ganesh Ghalme*

Main category: cs.GT

TL;DR: 研究在投票成本不对称情况下，选民基于启发式信念的投票行为如何影响选举结果，发现弱消失关键性会导致多重稳定均衡，而强消失关键性则导致唯一平凡均衡。


<details>
  <summary>Details</summary>
Motivation: 探讨在选民面临不同参与成本且使用启发式信念评估自身关键性的情况下，如何影响多数原则下的选举结果，特别是对Condorcet陪审团定理的适用性进行扩展分析。

Method: 建立成本投票模型，选民在参与成本大于关键性估计时弃权，分析弱消失关键性和强消失关键性两种信念特性对均衡的影响。

Result: 弱消失关键性产生多重稳定均衡，选举结果接近平局；强消失关键性产生唯一平凡均衡，只有零成本选民参与。存在一个尖锐阈值，低于该值时多数偏好候选人以概率1获胜，高于该值时两候选人获胜概率相等。

Conclusion: 选民的关键性信念特性对选举均衡有重要影响，弱消失关键性支持Condorcet陪审团定理的扩展版本，而强消失关键性则导致其失效。

Abstract: The well-known Condorcet Jury Theorem states that, under majority rule, the
better of two alternatives is chosen with probability approaching one as the
population grows. We study an asymmetric setting where voters face varying
participation costs and share a possibly heuristic belief about their
pivotality (ability to influence the outcome).
  In a costly voting setup where voters abstain if their participation cost is
greater than their pivotality estimate, we identify a single property of the
heuristic belief -- weakly vanishing pivotality -- that gives rise to multiple
stable equilibria in which elections are nearly tied. In contrast, strongly
vanishing pivotality (as in the standard Calculus of Voting model) yields a
unique, trivial equilibrium where only zero-cost voters participate as the
population grows. We then characterize when nontrivial equilibria satisfy a
version of the Jury Theorem: below a sharp threshold, the majority-preferred
candidate wins with probability approaching one; above it, both candidates
either win with equal probability.

</details>


### [3] [Contextual Search in Principal-Agent Games: The Curse of Degeneracy](https://arxiv.org/abs/2510.18567)
*Yiding Feng,Mengfan Ma,Bo Peng,Zongqi Wan*

Main category: cs.GT

TL;DR: 该论文研究了主从博弈中的上下文搜索问题，建立了指数级T^{1-Θ(1/d)}的悲观Stackelberg遗憾上界，并发现了与上下文定价问题的双指数难度分离现象。


<details>
  <summary>Details</summary>
Motivation: 研究主从博弈中基于上下文信息的合同设计问题，其中委托人在不知道代理人真实成本或收益的情况下，根据上下文信息和历史反馈反复提供合同。

Method: 通过建立上下文搜索模型，分析主从博弈中的学习难度，识别出上下文动作退化现象，并证明即使在三维动作和二维上下文的特殊情况下也存在双指数难度分离。

Result: 建立了T^{1-Θ(1/d)}的悲观Stackelberg遗憾上界和Ω(T^{1/2-1/2d})的经典Stackelberg遗憾下界，揭示了与上下文定价问题的显著难度差异。

Conclusion: 上下文动作退化现象是导致学习难度显著增加的根本原因，敌意选择的上下文会使某些动作严格占优，从而阻碍委托人的探索和学习能力。

Abstract: In this work, we introduce and study contextual search in general
principal-agent games, where a principal repeatedly interacts with agents by
offering contracts based on contextual information and historical feedback,
without knowing the agents' true costs or rewards. Our model generalizes
classical contextual pricing by accommodating richer agent action spaces. Over
$T$ rounds with $d$-dimensional contexts, we establish an asymptotically tight
exponential $T^{1 - \Theta(1/d)}$ bound in terms of the pessimistic Stackelberg
regret, benchmarked against the best utility for the principal that is
consistent with the observed feedback.
  We also establish a lower bound of $\Omega(T^{\frac{1}{2}-\frac{1}{2d}})$ on
the classic Stackelberg regret for principal-agent games, demonstrating a
surprising double-exponential hardness separation from the contextual pricing
problem (a.k.a, the principal-agent game with two actions), which is known to
admit a near-optimal $O(d\log\log T)$ regret bound [Kleinberg and Leighton,
2003, Leme and Schneider, 2018, Liu et al., 2021]. In particular, this
double-exponential hardness separation occurs even in the special case with
three actions and two-dimensional context. We identify that this significant
increase in learning difficulty arises from a structural phenomenon that we
call contextual action degeneracy, where adversarially chosen contexts can make
some actions strictly dominated (and hence unincentivizable), blocking the
principal's ability to explore or learn about them, and fundamentally limiting
learning progress.

</details>


### [4] [Likelihood of the Existence of Average Justified Representation](https://arxiv.org/abs/2510.18718)
*Qishen Han,Biaoshuai Tao,Lirong Xia,Chengkai Zhang,Houyu Zhou*

Main category: cs.GT

TL;DR: 本文研究了基于批准的多赢家选举中平均合理代表(AJR)公理的存在概率，使用Erdős–Rényi模型分析，发现了两个相变点p1和p2，完全刻画了AJR委员会的存在概率。


<details>
  <summary>Details</summary>
Motivation: 研究多赢家选举中AJR公理的存在性问题，因为已知AJR委员会不一定在所有选举实例中存在，需要分析其在随机模型下的存在概率。

Method: 使用Erdős–Rényi随机模型，参数p控制选民批准候选人的概率，分析当候选人数m固定、选民数n趋于无穷时AJR委员会的存在概率。

Result: 发现两个相变点p1和p2：当p<p1或p>p2时，AJR委员会以概率1-o(1)存在；当p1<p<p2时，以概率o(1)存在；在p=p1或p2时，存在概率既不趋近0也不趋近1。

Conclusion: 对Erdős–Rényi模型下AJR委员会的存在性给出了完整的相变特征描述，揭示了参数p对AJR存在性的关键影响。

Abstract: We study the approval-based multi-winner election problem where $n$ voters
jointly decide a committee of $k$ winners from $m$ candidates. We focus on the
axiom \emph{average justified representation} (AJR) proposed by Fernandez,
Elkind, Lackner, Garcia, Arias-Fisteus, Basanta-Val, and Skowron (2017). AJR
postulates that every group of voters with a common preference should be
sufficiently represented in that their average satisfaction should be no less
than their Hare quota. Formally, for every group of
$\lceil\ell\cdot\frac{n}{k}\rceil$ voters with $\ell$ common approved
candidates, the average number of approved winners for this group should be at
least $\ell$. It is well-known that a winning committee satisfying AJR is not
guaranteed to exist for all multi-winner election instances. In this paper, we
study the likelihood of the existence of AJR under the Erd\H{o}s--R\'enyi
model. We consider the Erd\H{o}s--R\'enyi model parameterized by $p\in[0,1]$
that samples multi-winner election instances from the distribution where each
voter approves each candidate with probability $p$ (and the events that voters
approve candidates are independent), and we provide a clean and complete
characterization of the existence of AJR committees in the case where $m$ is a
constant and $n$ tends to infinity. We show that there are two phase transition
points $p_1$ and $p_2$ (with $p_1\leq p_2$) for the parameter $p$ such that: 1)
when $p<p_1$ or $p>p_2$, an AJR committee exists with probability $1-o(1)$, 2)
when $p_1<p<p_2$, an AJR committee exists with probability $o(1)$, and 3) when
$p=p_1$ or $p=p_2$, the probability that an AJR committee exists is bounded
away from both $0$ and $1$.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [5] [Assignment-Routing Optimization with Cutting-Plane Subtour Elimination: Solver and Benchmark Dataset](https://arxiv.org/abs/2510.17888)
*Qilong Yuan*

Main category: cs.DS

TL;DR: 提出了一种使用精确MIP公式和Gurobi求解器解决联合路由分配优化问题的方法，包括割平面子回路消除技术


<details>
  <summary>Details</summary>
Motivation: 研究物品与占位符一对一配对同时确定访问所有节点一次的哈密顿回路的联合优化问题，最小化总旅行成本

Method: 使用精确MIP公式和Gurobi求解器，包含割平面子回路消除技术

Result: 通过计算复杂度分析和大量实验，分析了该方法在问题规模增大时的计算局限性

Conclusion: 揭示了大规模实例需要更高效算法的挑战，提供的数据集、公式和实验结果可作为该研究领域的基准

Abstract: We study a joint routing-assignment optimization problem in which a set of
items must be paired one-to-one with a set of placeholders while simultaneously
determining a Hamiltonian cycle that visits every node exactly once. Both the
assignment and routing decisions are optimized jointly to minimize the total
travel cost. In this work, we propose a method to solve this problem using an
exact MIP formulation with Gurobi, including cutting-plane subtour elimination.
With analysis of the computational complexity and through extensive
experiments, we analyze the computational limitations of this approach as the
problem size grows and reveal the challenges associated with the need for more
efficient algorithms for larger instances. The dataset, formulations, and
experimental results provided here can serve as benchmarks for future studies
in this research area. GitHub repository:
https://github.com/QL-YUAN/Joint-Assignment-Routing-Optimization

</details>


### [6] [Online Randomness Extraction: Simulating Barely Random Algorithms in the Random Order Arrival Model](https://arxiv.org/abs/2510.18049)
*Allan Borodin,Christodoulos Karavasilis,David Zhang*

Main category: cs.DS

TL;DR: 本文研究如何利用随机顺序模型中的随机到达顺序来提取随机比特，以去随机化算法。提出了三种1比特随机性提取过程，最佳过程在最坏情况下偏差为0.585，并应用于多个在线算法问题。


<details>
  <summary>Details</summary>
Motivation: 探索随机顺序模型中随机到达顺序提取随机比特的能力，以增强对随机化在线算法与确定性ROM算法相对强度的理解，并研究是否存在随机化算法优于任何确定性ROM算法的应用场景。

Method: 提出了三种1比特随机性提取过程，其中最佳过程在输入中至少存在两个不同项的条件下运行，返回具有最坏情况偏差0.585的比特。将这些过程应用于加权区间选择、背包问题、二进制字符串猜测和作业调度等问题的算法模拟。

Result: 开发了偏差为2-√2≈0.585的随机比特提取过程，并成功应用于多个在线算法问题的去随机化，包括加权区间选择、背包问题和作业调度等。

Conclusion: 通过随机顺序模型中的随机到达顺序提取随机比特是可行的，这为理解随机化在线算法与确定性ROM算法之间的关系提供了建设性方法，并展示了随机比特提取在算法去随机化中的实际应用价值。

Abstract: Interest in the random order model (ROM) leads us to initiate a study of
utilizing random-order arrivals to extract random bits with the goal of
de-randomizing algorithms. Besides producing simple algorithms, simulating
random bits through random arrivals enhances our understanding of the
comparative strength of randomized online algorithms (with adversarial input
sequence) and deterministic algorithms in the ROM. We consider three $1$-bit
randomness extraction processes. Our best extraction process returns a bit with
a worst-case bias of $2 - \sqrt{2} \approx 0.585$ and operates under the mild
assumption that there exist at least two distinct items in the input. We
motivate the applicability of this process by using it to simulate a number of
barely random algorithms for weighted interval selection (single-length
arbitrary weights, as well as monotone, C-benevolent and D-benevolent weighted
instances), the proportional and general knapsack problems, binary string
guessing, and unweighted job throughput scheduling.
  It is well known that there are many applications where a deterministic ROM
algorithm significantly outperforms any randomized online algorithm (in terms
of competitive ratios). The classic example is that of the secretary problem.
We ask the following fundamental question: Is there any application for which a
randomized algorithm outperforms any deterministic ROM algorithm? Motivated by
this question, we view our randomness extraction applications as a constructive
approach towards understanding the relation between randomized online
algorithms and deterministic ROM algorithms.

</details>


### [7] [Fast Agnostic Learners in the Plane](https://arxiv.org/abs/2510.18057)
*Talya Eden,Ludmila Glinskih,Sofya Raskhodnikova*

Main category: cs.DS

TL;DR: 本文研究了平面几何概念类的不可知学习计算效率，改进了三角形、凸多边形和凸集的学习算法运行时间，同时提出了关于样本复杂度和时间复杂度之间差距的根本问题。


<details>
  <summary>Details</summary>
Motivation: 不可知学习的样本复杂度已有深入研究，但其时间复杂度研究较少。本文旨在提高几何概念类不可知学习的计算效率，特别是三角形、凸多边形和凸集等基础几何概念。

Method: 使用计算几何的数据结构和算法，结合几何和概率组合工具进行分析。设计了合适的不可知学习器，包括三角形、4边形、5边形和正方形中凸集的学习器。

Result: 三角形学习器运行时间从Õ(ε⁻¹⁰)改进到Õ(ε⁻⁶)；4边形从O(ε⁻¹²)改进到Õ(ε⁻⁸)；5边形改进到Õ(ε⁻¹⁰)；凸集学习器运行时间从Õ(ε⁻⁸)改进到Õ(ε⁻⁵)。

Conclusion: 研究结果表明几何概念类的不可知学习在计算效率上可以显著改进，但提出了样本复杂度和时间复杂度之间是否存在固有差距的根本问题。

Abstract: We investigate the computational efficiency of agnostic learning for several
fundamental geometric concept classes in the plane. While the sample complexity
of agnostic learning is well understood, its time complexity has received much
less attention. We study the class of triangles and, more generally, the class
of convex polygons with $k$ vertices for small $k$, as well as the class of
convex sets in a square. We present a proper agnostic learner for the class of
triangles that has optimal sample complexity and runs in time $\tilde
O({\epsilon^{-6}})$, improving on the algorithm of Dobkin and Gunopulos (COLT
`95) that runs in time $\tilde O({\epsilon^{-10}})$. For 4-gons and 5-gons, we
improve the running time from $O({\epsilon^{-12}})$, achieved by Fischer and
Kwek (eCOLT `96), to $\tilde O({\epsilon^{-8}})$ and $\tilde
O({\epsilon^{-10}})$, respectively.
  We also design a proper agnostic learner for convex sets under the uniform
distribution over a square with running time $\tilde O({\epsilon^{-5}})$,
improving on the previous $\tilde O(\epsilon^{-8})$ bound at the cost of
slightly higher sample complexity. Notably, agnostic learning of convex sets in
$[0,1]^2$ under general distributions is impossible because this concept class
has infinite VC-dimension. Our agnostic learners use data structures and
algorithms from computational geometry and their analysis relies on tools from
geometry and probabilistic combinatorics. Because our learners are proper, they
yield tolerant property testers with matching running times. Our results raise
a fundamental question of whether a gap between the sample and time complexity
is inherent for agnostic learning of these and other natural concept classes.

</details>


### [8] [A Generalization of Distance Domination](https://arxiv.org/abs/2510.18066)
*Alicia Muth,E. Dov Neimand*

Main category: cs.DS

TL;DR: 提出了一种二次复杂度的算法，用于寻找树的最小故障集基数，即满足所有距离超过l的顶点簇不超过基数阈值的最小顶点子集大小。


<details>
  <summary>Details</summary>
Motivation: 扩展图论中的k分量阶连通性和距离l支配概念，解决服务选址问题，确保没有大邻域被排除在服务范围之外，同时减少距离支配问题中的冗余。

Method: 基于图论的k分量阶连通性和距离l支配理论，开发了二次复杂度的算法来寻找树结构中的最小故障集基数。

Result: 成功设计出多项式时间算法，能够有效计算树的最小故障集基数，为服务选址等实际问题提供解决方案。

Conclusion: 该算法扩展了图论概念的应用范围，为服务选址等优化问题提供了有效的计算工具，同时减少了传统距离支配问题中的冗余性。

Abstract: Expanding on the graph theoretic ideas of k-component order connectivity and
distance-l domination, we present a quadratic-complexity algorithm that finds a
tree's minimum failure-set cardinality, i.e., the minimum cardinality any
subset of the tree's vertices must have so that all clusters of vertices
further away than some l do not exceed a cardinality threshold. Applications of
solutions to the expanded problems include choosing service center locations so
that no large neighborhoods are excluded from service, while reducing the
redundancy inherent in distance domination problems.

</details>


### [9] [LatticeHashForest: An Efficient Data Structure for Repetitive Data and Operations](https://arxiv.org/abs/2510.18496)
*Anamitra Ghorui,Uday P. Khedker*

Main category: cs.DS

TL;DR: 提出了一种新颖的数据结构LatticeHashForest(LHF)，用于在编译器和程序优化场景中高效存储和操作信息，消除冗余计算和重复数据，在指针分析中实现了显著的内存使用减少和超过4倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 在程序分析中，特别是指针分析，存在大量重复数据的传播和低层数据结构操作的重复执行，导致组合爆炸问题。传统方法如hash-consing、ZDDs和BDDs在处理大型聚合结构时效率有限。

Method: 设计LatticeHashForest数据结构，支持高效操作大型聚合结构，并能在修改元素时立即进行去重。提供嵌套构建元素的能力，在多个层次进行去重，减少额外嵌套计算。

Result: 在指针分析用例中，内存使用减少到几乎可忽略的程度，对于接近1000万输入规模的情况，相比其他实现速度提升超过4倍。提供了完整的C++实现、API文档和用户手册。

Conclusion: LHF是一种有效解决程序分析中冗余计算和重复数据问题的通用数据结构，在指针分析等场景中表现出显著的性能优势。

Abstract: Analysis of entire programs as a single unit, or whole-program analysis,
involves propagation of large amounts of information through the control flow
of the program. This is especially true for pointer analysis, where, unless
significant compromises are made in the precision of the analysis, there is a
combinatorial blowup of information. One of the key problems we observed in our
own efforts is that a lot of duplicate data was being propagated, and many
low-level data structure operations were repeated a large number of times.
  We present what we consider to be a novel and generic data structure,
LatticeHashForest (LHF), to store and operate on such information in a manner
that eliminates a majority of redundant computations and duplicate data in
scenarios similar to those encountered in compilers and program optimization.
LHF differs from similar work in this vein, such as hash-consing, ZDDs, and
BDDs, by not only providing a way to efficiently operate on large, aggregate
structures, but also modifying the elements of such structures in a manner that
they can be deduplicated immediately. LHF also provides a way to perform a
nested construction of elements such that they can be deduplicated at multiple
levels, cutting down the need for additional, nested computations.
  We provide a detailed structural description, along with an abstract model of
this data structure. An entire C++ implementation of LHF is provided as an
artifact along with evaluations of LHF using examples and benchmark programs.
We also supply API documentation and a user manual for users to make
independent applications of LHF. Our main use case in the realm of pointer
analysis shows memory usage reduction to an almost negligible fraction, and
speedups beyond 4x for input sizes approaching 10 million when compared to
other implementations.

</details>


### [10] [Fingerprint Filters Are Optimal](https://arxiv.org/abs/2510.18129)
*William Kuszmaul,Jingxun Liang,Renfei Zhou*

Main category: cs.DS

TL;DR: 该论文证明了动态过滤器的最小空间下界为n log ε⁻¹ + n log e - o(n)比特，解决了该领域几十年的开放性问题。


<details>
  <summary>Details</summary>
Motivation: 动态过滤器支持对动态集合进行近似成员查询，允许小错误率ε。已知构造都使用指纹技术，其空间需求为n log ε⁻¹ + n log e - o(n)比特。这个下界是否对所有动态过滤器都最优，是该领域几十年的核心开放问题。

Method: 通过理论证明，建立了动态过滤器的严格下界，不依赖于具体实现技术。

Result: 证明了无论操作时间如何，动态过滤器的最小空间下界为n log ε⁻¹ + n log e - o(n)比特，当ε=o(1)时。

Conclusion: 解决了动态过滤器空间复杂度的长期开放问题，确认了指纹技术达到的空间复杂度是最优的。

Abstract: Dynamic filters are data structures supporting approximate membership queries
to a dynamic set $S$ of $n$ keys, allowing a small false-positive error rate
$\varepsilon$, under insertions and deletions to the set $S$. Essentially all
known constructions for dynamic filters use a technique known as
fingerprinting. This technique, which was first introduced by Carter et al. in
1978, inherently requires $$\log \binom{n \varepsilon^{-1}}{n} = n \log
\varepsilon^{-1} + n \log e - o(n)$$ bits of space when $\varepsilon = o(1)$.
Whether or not this bound is optimal for all dynamic filters (rather than just
for fingerprint filters) has remained for decades as one of the central open
questions in the area. We resolve this question by proving a sharp lower bound
of $n \log \varepsilon^{-1} + n \log e - o(n)$ bits for $\varepsilon = o(1)$,
regardless of operation time.

</details>


### [11] [A Simpler Exponential-Time Approximation Algorithm for MAX-k-SAT](https://arxiv.org/abs/2510.18164)
*Harry Buhrman,Sevag Gharibian,Zeph Landau,François Le Gall,Norbert Schuch,Suguru Tamaki*

Main category: cs.DS

TL;DR: 提出了一种极其简单的多项式空间指数时间(1-ε)近似算法用于MAX-k-SAT问题，比之前已知的算法略快。


<details>
  <summary>Details</summary>
Motivation: 寻找更简单高效的近似算法来解决MAX-k-SAT问题，改进之前Hirsch和Escoffier等人的方法。

Method: 重复均匀随机采样赋值，直到找到满足足够大比例子句的赋值。通过证明在MAX-k-SAT（或更一般的MAXCSP）实例中，有指数数量的赋值满足接近最优值的子句比例。

Result: 该算法在多项式空间下实现了(1-ε)近似，且比之前已知的算法略快。

Conclusion: 证明了这种简单随机采样方法的有效性，为MAX-k-SAT问题提供了更简洁的近似算法解决方案。

Abstract: We present an extremely simple polynomial-space exponential-time
$(1-\varepsilon)$-approximation algorithm for MAX-k-SAT that is (slightly)
faster than the previous known polynomial-space $(1-\varepsilon)$-approximation
algorithms by Hirsch (Discrete Applied Mathematics, 2003) and Escoffier,
Paschos and Tourniaire (Theoretical Computer Science, 2014). Our algorithm
repeatedly samples an assignment uniformly at random until finding an
assignment that satisfies a large enough fraction of clauses. Surprisingly, we
can show the efficiency of this simpler approach by proving that in any
instance of MAX-k-SAT (or more generally any instance of MAXCSP), an
exponential number of assignments satisfy a fraction of clauses close to the
optimal value.

</details>


### [12] [Coloring Graphs with Few Colors in the Streaming Model](https://arxiv.org/abs/2510.18177)
*Sepehr Assadi,Janani Sundaresan,Helia Yazdanyar*

Main category: cs.DS

TL;DR: 该论文研究了流式模型中的图着色问题，重点关注使用少量颜色（如常数个颜色）对图进行着色的空间复杂度，在对抗流、随机顺序流和动态流三种模型下建立了上下界。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注使用大量颜色进行图着色，而本文探索相反方向：判断输入图是否可以用少量颜色（如常数个颜色）着色，为这个新方向奠定基础。

Method: 开发了新的技术工具：簇打包图（Ruzsa-Szemerédi图的推广）、基于簇打包图的玩家消除框架，以及针对图着色的新边和顶点采样引理。

Result: 在对抗流中，区分q-可着色与2^Ω(q)-可着色图需要n^{2-o(1)}空间；在随机顺序流中，区分q-可着色与q^t-可着色图可用Õ(n^{1+1/t})空间；在动态流中，区分q-可着色与q·t-可着色图需要Õ(n^2/t^2)空间。

Conclusion: 本文为流式模型中的少量颜色图着色问题建立了理论基础，展示了不同流模型下的空间复杂度界限，并开发了新的技术工具来支持这些结果。

Abstract: We study graph coloring problems in the streaming model, where the goal is to
process an $n$-vertex graph whose edges arrive in a stream, using a limited
space that is smaller than the trivial $O(n^2)$ bound. While prior work has
largely focused on coloring graphs with a large number of colors, we explore
the opposite end of the spectrum: deciding whether the input graph can be
colored using only a few, say, a constant number of colors. We are interested
in each of the adversarial, random order, or dynamic streams.
  Our work lays the foundation for this new direction by establishing upper and
lower bounds on space complexity of key variants of the problem. Some of our
main results include:
  - Adversarial: for distinguishing between $q$- vs $2^{\Omega(q)}$-colorable
graphs, lower bounds of $n^{2-o(1)}$ space for $q$ up to
$(\log{n})^{1/2-o(1)}$, and $n^{1+\Omega(1/\log\log{n})}$ space for $q$ further
up to $(\log{n})^{1-o(1)}$.
  - Random order: for distinguishing between $q$- vs $q^t$-colorable graphs for
$q,t \geq 2$, an upper bound of $\tilde{O}(n^{1+1/t})$ space. Specifically,
distinguishing between $q$-colorable graphs vs ones that are not even
poly$(q)$-colorable can be done in $n^{1+o(1)}$ space unlike in adversarial
streams. Although, distinguishing between $q$-colorable vs
$\Omega(q^2)$-colorable graphs requires $\Omega(n^2)$ space even in random
order streams for constant $q$.
  - Dynamic: for distinguishing between $q$- vs $q \cdot t$-colorable graphs
for any $q \geq 3$ and $t \geq 1$, nearly optimal upper and lower bounds of
$\tilde{\Theta}(n^2/t^2)$ space.
  We develop several new technical tools along the way: cluster packing graphs,
a generalization of Ruzsa-Szemer\'edi graphs; a player elimination framework
based on cluster packing graphs; and new edge and vertex sampling lemmas
tailored to graph coloring.

</details>


### [13] [Nearly Space-Optimal Graph and Hypergraph Sparsification in Insertion-Only Data Streams](https://arxiv.org/abs/2510.18180)
*Vincent Cohen-Addad,David P. Woodruff,Shenghao Xie,Samson Zhou*

Main category: cs.DS

TL;DR: 该论文研究了在插入流数据模型下的图和超图稀疏化问题，提出了高效的流式算法，在空间复杂度上达到或接近最优。


<details>
  <summary>Details</summary>
Motivation: 传统超图稀疏化算法需要存储整个图结构，不适用于大规模流数据场景。研究如何在有限空间内实现高效的超图稀疏化具有重要理论和应用价值。

Method: 提出基于流式处理的超图稀疏化算法，通过精心设计的采样和近似技术，在插入流中维护超图的稀疏表示。

Result: 实现了(1+ε)近似的超图稀疏化，空间复杂度为O(rn/ε² log²n logr poly(loglogm))，与最佳离线算法匹配；图稀疏化空间复杂度改进为O(n/ε² logn poly(loglogn))；同时提供了滑动窗口模型和对抗鲁棒性算法。

Conclusion: 该工作为流数据下的图和超图稀疏化提供了高效解决方案，在空间复杂度上达到或接近理论下界，具有重要的理论和实践意义。

Abstract: We study the problem of graph and hypergraph sparsification in insertion-only
data streams. The input is a hypergraph $H=(V, E, w)$ with $n$ nodes, $m$
hyperedges, and rank $r$, and the goal is to compute a hypergraph $\widehat{H}$
that preserves the energy of each vector $x \in \mathbb{R}^n$ in $H$, up to a
small multiplicative error. In this paper, we give a streaming algorithm that
achieves a $(1+\varepsilon)$-approximation, using $\frac{rn}{\varepsilon^2}
\log^2 n \log r \cdot\text{poly}(\log \log m)$ bits of space, matching the
sample complexity of the best known offline algorithm up to $\text{poly}(\log
\log m)$ factors. Our approach also provides a streaming algorithm for graph
sparsification that achieves a $(1+\varepsilon)$-approximation, using
$\frac{n}{\varepsilon^2} \log n \cdot\text{poly}(\log\log n)$ bits of space,
improving the current bound by $\log n$ factors. Furthermore, we give a
space-efficient streaming algorithm for min-cut approximation. Along the way,
we present an online algorithm for $(1+\varepsilon)$-hypergraph sparsification,
which is optimal up to poly-logarithmic factors. As a result, we achieve
$(1+\varepsilon)$-hypergraph sparsification in the sliding window model, with
space optimal up to poly-logarithmic factors. Lastly, we give an adversarially
robust algorithm for hypergraph sparsification using $\frac{n}{\varepsilon^2}
\cdot\text{poly}(r, \log n, \log r, \log \log m)$ bits of space.

</details>


### [14] [Static Retrieval Revisited: To Optimality and Beyond](https://arxiv.org/abs/2510.18237)
*Yang Hu,William Kuszmaul,Jingxun Liang,Huacheng Yu,Junkai Zhang,Renfei Zhou*

Main category: cs.DS

TL;DR: 本文研究了静态检索问题的空间-时间权衡，发现在大值情况下无法同时实现O(1)查询时间和nv+o(n)位空间，但提出了与另一个数据结构组合存储的解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决静态检索问题中对于较大值大小(v=Θ(log n))是否能在O(1)查询时间下仅使用nv+o(n)位空间这一开放问题。

Method: 通过严格的下界分析和匹配的上界构造，研究了检索问题的空间-时间权衡，并提出了组合数据结构的方法来规避限制。

Result: 证明当v=Θ(log n)时，无法在O(1)查询时间下使用nv+o(n)位空间；但通过组合存储，可以在总空间为nv+Space(D₂)+n^0.67位的情况下实现D₁的O(1)查询。

Conclusion: 静态检索问题存在固有的空间-时间权衡，但通过巧妙的数据结构组合可以规避这一限制，为低冗余存储应用提供了实用解决方案。

Abstract: In the static retrieval problem, a data structure must answer retrieval
queries mapping a set of $n$ keys in a universe $[U]$ to $v$-bit values.
Information-theoretically, retrieval data structures can use as little as $nv$
bits of space. For small value sizes $v$, it is possible to achieve $O(1)$
query time while using space $nv + o(n)$ bits -- whether or not such a result
is possible for larger values of $v$ (e.g., $v = \Theta(\log n)$) has remained
open.
  In this paper, we obtain a tight lower bound (as well as matching upper
bounds) for the static retrieval problem. In the case where values are large,
we show that there is actually a significant tension between time and space. It
is not possible, for example, to get $O(1)$ query time using $nv + o(n)$ bits
of space, when $v = \Theta(\log n)$ (and assuming the word RAM model with
$O(\log n)$-bit words).
  At first glance, our lower bound would seem to render retrieval unusable in
many settings that aim to achieve very low redundancy. However, our second
result offers a way around this: We show that, whenever a retrieval data
structure $D_1$ is stored along with another data structure $D_2$ (whose size
is similar to or larger than the size of $D_1$), it is possible to implement
the combined data structure $D_1 \cup D_2$ so that queries to $D_1$ take $O(1)$
time, operations on $D_2$ take the same asymptotic time as if $D_2$ were stored
on its own, and the total space is $nv + \mathrm{Space}(D_2) + n^{0.67}$ bits.

</details>


### [15] [Minimum $s$--$t$ Cuts with Fewer Cut Queries](https://arxiv.org/abs/2510.18274)
*Yonggang Jiang,Danupon Nanongkai,Pachara Sawettamalya*

Main category: cs.DS

TL;DR: 本文提出了一种新的随机算法，将最小s-t割的割查询复杂度从之前的O(n^{5/3})改进到O(n^{8/5})，并基于此获得了一个确定性的两方通信协议，通信复杂度为O(n^{11/7})。


<details>
  <summary>Details</summary>
Motivation: 在割查询模型中，之前的工作需要O(n^{5/3})次查询才能计算最小s-t割，而学习整个图需要O(n^2)次查询。本文旨在进一步降低查询复杂度，并探索其在通信复杂度中的应用。

Method: 提出了一种新的随机算法，核心是一个查询高效的子程序，能够以比传统增广路径方法更快的速率逐步揭示图结构，同时增加已学习子图中的最大s-t流。算法采用递归贪心策略，是纯组合的。

Result: 将最小s-t割的割查询复杂度改进到O(n^{8/5})，并获得了确定性的两方通信协议，通信复杂度为O(n^{11/7})，优于之前的O(n^{5/3})。

Conclusion: 本文通过新的组合方法显著改进了最小s-t割问题的割查询复杂度，并为通信复杂度提供了更好的确定性协议，展示了组合方法在优化问题中的有效性。

Abstract: We study the problem of computing a minimum $s$--$t$ cut in an unweighted,
undirected graph via \emph{cut queries}. In this model, the input graph is
accessed through an oracle that, given a subset of vertices $S \subseteq V$,
returns the size of the cut $(S, V \setminus S)$.
  This line of work was initiated by Rubinstein, Schramm, and Weinberg (ITCS
2018), who gave a randomized algorithm that computes a minimum $s$--$t$ cut
using $\widetilde{O}(n^{5/3})$ queries, thereby showing that one can avoid
spending $\widetilde{\Theta}(n^2)$ queries required to learn the entire graph.
A recent result by Anand, Saranurak, and Wang (SODA 2025) also matched this
upper bound via a deterministic algorithm based on blocking flows.
  In this work, we present a new randomized algorithm that improves the
cut-query complexity to $\widetilde{O}(n^{8/5})$. At the heart of our approach
is a query-efficient subroutine that incrementally reveals the graph
edge-by-edge while increasing the maximum $s$--$t$ flow in the learned subgraph
at a rate faster than classical augmenting-path methods. Notably, our algorithm
is simple, purely combinatorial, and can be naturally interpreted as a
recursive greedy procedure.
  As a further consequence, we obtain a \emph{deterministic} and
\emph{combinatorial} two-party communication protocol for computing a minimum
$s$--$t$ cut using $\widetilde{O}(n^{11/7})$ bits of communication. This
improves upon the previous best bound of $\widetilde{O}(n^{5/3})$, which was
obtained via reductions from the aforementioned cut-query algorithms. In
parallel, it has been observed that an $\widetilde{O}(n^{3/2})$-bit randomized
protocol can be achieved via continuous optimization techniques; however, these
methods are fundamentally different from our combinatorial approach.

</details>


### [16] [Uniformity Testing under User-Level Local Privacy](https://arxiv.org/abs/2510.18379)
*Clément L. Canonne,Abigail Gentle,Vikrant Singhal*

Main category: cs.DS

TL;DR: 该论文首次研究了在用户级本地差分隐私下的分布测试问题，其中每个用户贡献多个样本，比传统的本地隐私设置更具挑战性。


<details>
  <summary>Details</summary>
Motivation: 用户级本地差分隐私设置虽然很自然，但由于隐私保证需要应用于完整批次的数据点，比通常的本地隐私设置更具挑战性。尽管最近有工作考虑用户级设置下的分布学习，但对于最基本的测试任务（均匀性测试和身份测试）仍一无所知。

Method: 提供了（几乎）样本最优的用户级LDP算法用于均匀性测试和身份测试，主要关注私有硬币对称设置，不需要用户共享公共随机种子或具有全局唯一标识符。

Result: 填补了用户级本地差分隐私下分布测试的空白，为均匀性测试和身份测试提供了样本最优的算法。

Conclusion: 这是用户级本地差分隐私下分布测试的首个研究，解决了该领域的一个重要空白，并提供了实用的算法解决方案。

Abstract: We initiate the study of distribution testing under \emph{user-level} local
differential privacy, where each of $n$ users contributes $m$ samples from the
unknown underlying distribution. This setting, albeit very natural, is
significantly more challenging that the usual locally private setting, as for
the same parameter $\varepsilon$ the privacy guarantee must now apply to a full
batch of $m$ data points. While some recent work consider distribution
\emph{learning} in this user-level setting, nothing was known for even the most
fundamental testing task, uniformity testing (and its generalization, identity
testing).
  We address this gap, by providing (nearly) sample-optimal user-level LDP
algorithms for uniformity and identity testing. Motivated by practical
considerations, our main focus is on the private-coin, symmetric setting, which
does not require users to share a common random seed nor to have been assigned
a globally unique identifier.

</details>


### [17] [Odd and Even Harder Problems on Cycle-Factors](https://arxiv.org/abs/2510.18393)
*Florian Hörsch,Csaba Király,Mirabel Mendoza-Cadena,Gyula Pap,Eszter Szabó,Yutaro Yamaguchi*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: For a graph (undirected, directed, or mixed), a cycle-factor is a collection
of vertex-disjoint cycles covering the entire vertex set. Cycle-factors subject
to parity constraints arise naturally in the study of structural graph theory
and algorithmic complexity. In this work, we study four variants of the problem
of finding a cycle-factor subject to parity constraints: (1) all cycles are
odd, (2) all cycles are even, (3) at least one cycle is odd, and (4) at least
one cycle is even. These variants are considered in the undirected, directed,
and mixed settings. We show that all but the fourth problem are NP-complete in
all settings, while the complexity of the fourth one remains open for the
directed and undirected cases. We also show that in mixed graphs, even deciding
the existence of any cycle factor is NP-complete.

</details>


### [18] [An optimal algorithm for average distance in typical regular graphs](https://arxiv.org/abs/2510.18722)
*Alexandros Eskenazis,Manor Mendel,Assaf Naor*

Main category: cs.DS

TL;DR: 提出了一种确定性算法，在典型常数度正则图中使用O(n)距离查询即可输出平均距离的常数因子近似，同时证明了对于所有常数度图，要达到小于4的近似比必须查询Ω(n²)距离。


<details>
  <summary>Details</summary>
Motivation: 解决MN14中提出的问题：能否在常数度正则图中用O(n)距离查询获得平均距离的常数因子近似。

Method: 结合MN14的方法构造关于非正曲率度量空间的扩展图序列，并提出了非正曲率度量空间度量变换的新刚性定理。

Result: 对于典型（均匀随机）常数度正则图，算法成功输出常数因子近似；但对于所有常数度图，要达到小于2(k+1)的近似比必须查询Ω(n^{1+1/k})距离。

Conclusion: 在典型常数度正则图中可以实现O(n)查询的常数因子近似，但对于所有常数度图存在查询复杂度的基本限制，近似比与查询复杂度之间存在权衡关系。

Abstract: We design a deterministic algorithm that, given $n$ points in a
\emph{typical} constant degree regular~graph, queries $O(n)$ distances to
output a constant factor approximation to the average distance among those
points, thus answering a question posed in~\cite{MN14}. Our algorithm uses the
method of~\cite{MN14} to construct a sequence of constant degree graphs that
are expanders with respect to certain nonpositively curved metric spaces,
together with a new rigidity theorem for metric transforms of nonpositively
curved metric spaces. The fact that our algorithm works for typical (uniformly
random) constant degree regular graphs rather than for all constant degree
graphs is unavoidable, thanks to the following impossibility result that we
obtain: For every fixed $k\in \N$, the approximation factor of any algorithm
for average distance that works for all constant degree graphs and queries
$o(n^{1+1/k})$ distances must necessarily be at least $2(k+1)$. This matches
the upper bound attained by the algorithm that was designed for general finite
metric spaces in~\cite{BGS}. Thus, any algorithm for average distance in
constant degree graphs whose approximation guarantee is less than $4$ must
query $\Omega(n^2)$ distances, any such algorithm whose approximation guarantee
is less than $6$ must query $\Omega(n^{3/2})$ distances, any such algorithm
whose approximation guarantee less than $8$ must query $\Omega(n^{4/3})$
distances, and so forth, and furthermore there exist algorithms achieving those
parameters.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [19] [Information Capacity of EEG: Theoretical and Computational Limits of Recoverable Neural Information](https://arxiv.org/abs/2510.17841)
*Ishir Rao*

Main category: cs.IT

TL;DR: EEG的信息容量有限，每个样本仅能传递数十比特关于低维神经活动的信息，信息在64-128个电极时饱和，且随信噪比对数增长。


<details>
  <summary>Details</summary>
Motivation: 量化脑电图(EEG)的信息容量，了解其从皮层源到头皮记录的信息传递能力。

Method: 结合信息论和合成前向建模，使用高斯通道理论和经验模拟来估计皮层源与EEG记录之间的互信息。

Result: 头皮EEG每个样本仅传递数十比特信息，信息在64-128电极时饱和，线性解码器几乎能捕获所有可线性恢复的方差，但远低于分析通道容量。

Conclusion: 测量物理特性而非算法复杂性是主要限制因素，这界定了从EEG推断大脑状态或思维内容结构的内在上限。

Abstract: Electroencephalography (EEG) is widely used to study human brain dynamics,
yet its quantitative information capacity remains unclear. Here, we combine
information theory and synthetic forward modeling to estimate the mutual
information between latent cortical sources and EEG recordings. Using
Gaussian-channel theory and empirical simulations, we find that scalp EEG
conveys only tens of bits per sample about low-dimensional neural activity.
Information saturates with approximately 64-128 electrodes and scales
logarithmically with signal-to-noise ratio (SNR). Linear decoders capture
nearly all variance that is linearly recoverable, but the mutual information
they recover remains far below the analytic channel capacity, indicating that
measurement physics - not algorithmic complexity - is the dominant limitation.
These results outline the intrinsic ceiling on how much structure about brain
state or thought content can be inferred from EEG.

</details>


### [20] [Performance of Modified Fractional Frequency Reuse Algorithm in Random Ultra Dense Networks](https://arxiv.org/abs/2510.18440)
*Bach Hung Luu,Samuel Harry Gardner,Sinh Cong Lam,Trong Minh Hoang*

Main category: cs.IT

TL;DR: 本文提出了一种改进的分数频率复用算法，通过使用服务基站与第二近基站信号功率比来分类小区边缘用户和中心用户，以减轻5G及B5G网络中的小区间干扰。


<details>
  <summary>Details</summary>
Motivation: 在5G及B5G高密度基站网络中，传统基于下行SINR或距离的用户分类方法存在局限性，需要更有效的干扰管理方法来提升用户性能。

Method: 使用服务基站与第二近基站的信号功率比作为用户分类标准，当功率比低于预设阈值时，将用户分类为小区边缘用户并分配更高的传输功率。

Result: 仿真结果显示，增加传输功率能提升小区边缘用户性能，但会降低典型用户性能；在障碍物密集环境中，频率复用算法能有效抑制小区间干扰。

Conclusion: 基于功率比的用户分类方法在密集障碍物环境中具有可行性，能有效管理小区间干扰，但需要在边缘用户和典型用户性能之间进行权衡。

Abstract: Mitigating intercell interference by employing fractional frequency reuse
algorithms is one of the important approaches to improving user performance in
5G and Beyond 5G cellular network systems, which typically have a high density
of Base Stations (BSs). While most frequency reuse algorithms are based on the
downlink Signal-to-Interference-plus-Noise Ratio (SINR) or the distance between
the user and its serving BS to classify Cell-Edge Users (CEUs) and Cell-Center
Users (CCUs), this paper discusses a modified algorithm that uses the power
ratio between the signal strengths from the serving BS and the second nearest
BS for user classification. Specifically, if the power ratio is below a
predefined threshold, the user is classified as a CEU and is served with higher
transmission power. Simulation results show that increasing transmission power
is necessary to enhance CEU performance, but it also degrades the performance
of typical users. The use of frequency reuse algorithms is particularly
feasible in environments with a high density of obstacles, where intercell
interference can be effectively suppressed.

</details>


### [21] [A Markov-Chain Characterization of Finite-State Dimension and a Generalization of Agafonov's Theorem](https://arxiv.org/abs/2510.18736)
*Laurent Bienvenu,Hugo Gimbert,Subin Pulari*

Main category: cs.IT

TL;DR: 本文扩展了有限状态维度与马尔可夫链模拟之间的关系，提供了有限状态维度的新信息论特征，并推广了Agafonov定理。


<details>
  <summary>Details</summary>
Motivation: 有限状态维度量化了有限自动机感知的无限序列中的渐近信息率。Schnorr和Stimm(1972)证明了实数Borel正规当且仅当对于每个有限状态不可约马尔可夫链，使用该数的二进制展开模拟链时，状态的实证分布收敛到其平稳分布。本文旨在将这种对应关系扩展到正规数之外。

Method: 通过条件Kullback-Leibler散度来表征序列的有限状态维度，该散度衡量了使用给定序列模拟马尔可夫链时产生的极限分布与其平稳分布之间的差异。

Result: 证明了序列的有限状态维度可以通过马尔可夫链模拟中产生的极限分布与平稳分布之间的条件Kullback-Leibler散度来表征，这提供了有限状态维度的新信息论特征。

Conclusion: 本文成功扩展了Schnorr-Stimm结果，提供了有限状态维度的新信息论特征，并证明了Agafonov定理的推广，建立了序列与其自动子序列的有限状态维度之间的紧密定量关系。

Abstract: Finite-state dimension quantifies the asymptotic rate of information in an
infinite sequence as perceived by finite automata. For a fixed alphabet, the
infinite sequences that have maximal finite-state dimension are exactly those
that are Borel normal, i.e., in which all words of any given length appear with
the same frequency. A theorem of Schnorr and Stimm (1972) shows that a real
number is Borel normal if and only if, for every finite-state irreducible
Markov chain with fair transitions, when the chain is simulated using the
binary expansion of the given number, the empirical distribution of states
converges to its stationary distribution. In this paper we extend this
correspondence beyond normal numbers. We show that the finite-state dimension
of a sequence can be characterized in terms of the conditional Kullback-Leibler
divergence between the limiting distributions arising from the simulation of
Markov chains using the given sequence and their stationary distributions. This
provides a new information-theoretic characterization of finite-state dimension
which generalizes the Schnorr-Stimm result.
  As an application, we prove a generalization of Agafonov's theorem for normal
numbers. Agafonov's theorem states that a sequence is normal if and only if
every subsequence selected by a finite automaton is also normal. We extend this
to arbitrary sequences by establishing a tight quantitative relationship
between the finite-state dimension of a sequence and the finite-state
dimensions of its automatic subsequences.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [22] [From AutoRecSys to AutoRecLab: A Call to Build, Evaluate, and Govern Autonomous Recommender-Systems Research Labs](https://arxiv.org/abs/2510.18104)
*Joeran Beel,Bela Gipp,Tobias Vente,Moritz Baumgart,Philipp Meister*

Main category: cs.IR

TL;DR: 提出从狭窄的AutoRecSys工具转向端到端自动化的自主推荐系统研究实验室(AutoRecLab)，包括问题构思、文献分析、实验设计执行、结果解释、论文草拟和溯源记录。


<details>
  <summary>Details</summary>
Motivation: 推荐系统研究在模型和评估方面取得进展，但忽视了研究过程本身的自动化。当前工具主要关注算法选择和超参数调优，缺乏端到端自动化。

Method: 借鉴自动化科学的最新进展，提出构建结合LLM驱动构思和报告与自动化实验的AutoRecLab原型，建立评估代理产生可重复发现的基准，创建AI生成提交的评审渠道，定义归因和可重复性标准，促进跨学科伦理对话。

Result: 推进这一议程可以提高研究吞吐量，发现非显而易见的见解，使推荐系统为新兴的人工研究智能做出贡献。

Conclusion: 呼吁组织社区研讨会来协调后续步骤，并共同制定负责任整合自动化研究系统的指南。

Abstract: Recommender-systems research has accelerated model and evaluation advances,
yet largely neglects automating the research process itself. We argue for a
shift from narrow AutoRecSys tools -- focused on algorithm selection and
hyper-parameter tuning -- to an Autonomous Recommender-Systems Research Lab
(AutoRecLab) that integrates end-to-end automation: problem ideation,
literature analysis, experimental design and execution, result interpretation,
manuscript drafting, and provenance logging. Drawing on recent progress in
automated science (e.g., multi-agent AI Scientist and AI Co-Scientist systems),
we outline an agenda for the RecSys community: (1) build open AutoRecLab
prototypes that combine LLM-driven ideation and reporting with automated
experimentation; (2) establish benchmarks and competitions that evaluate agents
on producing reproducible RecSys findings with minimal human input; (3) create
review venues for transparently AI-generated submissions; (4) define standards
for attribution and reproducibility via detailed research logs and metadata;
and (5) foster interdisciplinary dialogue on ethics, governance, privacy, and
fairness in autonomous research. Advancing this agenda can increase research
throughput, surface non-obvious insights, and position RecSys to contribute to
emerging Artificial Research Intelligence. We conclude with a call to organise
a community retreat to coordinate next steps and co-author guidance for the
responsible integration of automated research systems.

</details>


### [23] [LIME: Link-based user-item Interaction Modeling with decoupled xor attention for Efficient test time scaling](https://arxiv.org/abs/2510.18239)
*Yunjiang Jiang,Ayush Agarwal,Yang Liu,Bi Xue*

Main category: cs.IR

TL;DR: LIME是一种新颖的推荐系统架构，通过低秩链接嵌入和线性注意力机制LIME-XOR，显著降低了计算复杂度，在保持与最先进Transformer性能相近的同时，实现了10倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在推荐系统中面临计算成本随用户历史长度和候选集规模线性或二次增长的瓶颈，限制了系统扩展能力。

Method: 采用低秩链接嵌入解耦用户和候选交互，实现注意力权重的预计算；使用LIME-XOR线性注意力机制将复杂度从O(N²)降低到O(N)。

Result: 在公开和工业数据集上，LIME在大型候选集或长序列上实现10倍推理加速，在主要推荐平台上提升了用户参与度。

Conclusion: LIME为高效且表达能力强的推荐系统建立了新范式，解决了计算复杂度与性能之间的权衡问题。

Abstract: Scaling large recommendation systems requires advancing three major
frontiers: processing longer user histories, expanding candidate sets, and
increasing model capacity. While promising, transformers' computational cost
scales quadratically with the user sequence length and linearly with the number
of candidates. This trade-off makes it prohibitively expensive to expand
candidate sets or increase sequence length at inference, despite the
significant performance improvements.
  We introduce \textbf{LIME}, a novel architecture that resolves this
trade-off. Through two key innovations, LIME fundamentally reduces
computational complexity. First, low-rank ``link embeddings" enable
pre-computation of attention weights by decoupling user and candidate
interactions, making the inference cost nearly independent of candidate set
size. Second, a linear attention mechanism, \textbf{LIME-XOR}, reduces the
complexity with respect to user sequence length from quadratic ($O(N^2)$) to
linear ($O(N)$).
  Experiments on public and industrial datasets show LIME achieves near-parity
with state-of-the-art transformers but with a 10$\times$ inference speedup on
large candidate sets or long sequence lengths. When tested on a major
recommendation platform, LIME improved user engagement while maintaining
minimal inference costs with respect to candidate set size and user history
length, establishing a new paradigm for efficient and expressive recommendation
systems.

</details>


### [24] [Enhancing Hotel Recommendations with AI: LLM-Based Review Summarization and Query-Driven Insights](https://arxiv.org/abs/2510.18277)
*Nikolaos Belibasakis,Anastasios Giannaros,Ioanna Giannoukou,Spyros Sioutas*

Main category: cs.IR

TL;DR: 开发了一个名为instaGuide的Web应用，利用大型语言模型自动总结Booking.com平台的用户评论，帮助用户快速获取关键信息，提高短租公寓选择的决策效率。


<details>
  <summary>Details</summary>
Motivation: 随着预订平台数据量的增加，用户难以高效浏览住宿选项和分析评论。虽然平台提供了基于星级、设施、价格等的过滤功能，但最有价值的见解来自非结构化的文本评论，而逐条阅读这些评论非常耗时。

Method: 开发instaGuide Web应用，从Booking.com平台提取房产的文本评论，使用多种LLM模型进行评论总结和关键信息挖掘，并允许用户查询房产的特定方面。评估了不同LLM模型在准确性、成本和响应质量方面的表现。

Result: LLM驱动的总结显著减少了用户寻找合适短租公寓所需的时间，改善了整体决策过程。不同LLM模型在准确性、成本和响应质量方面表现各异。

Conclusion: LLM技术可以有效提升短租公寓推荐系统的效率，通过自动总结用户评论帮助用户快速获取关键信息，优化决策流程。

Abstract: The increasing number of data a booking platform such as Booking.com and
AirBnB offers make it challenging for interested parties to browse through the
available accommodations and analyze reviews in an efficient way. Efforts have
been made from the booking platform providers to utilize recommender systems in
an effort to enable the user to filter the results by factors such as stars,
amenities, cost but most valuable insights can be provided by the unstructured
text-based reviews. Going through these reviews one-by-one requires a
substantial amount of time to be devoted while a respectable percentage of the
reviews won't provide to the user what they are actually looking for.
  This research publication explores how Large Language Models (LLMs) can
enhance short rental apartments recommendations by summarizing and mining key
insights from user reviews. The web application presented in this paper, named
"instaGuide", automates the procedure of isolating the text-based user reviews
from a property on the Booking.com platform, synthesizing the summary of the
reviews, and enabling the user to query specific aspects of the property in an
effort to gain feedback on their personal questions/criteria.
  During the development of the instaGuide tool, numerous LLM models were
evaluated based on accuracy, cost, and response quality. The results suggest
that the LLM-powered summarization reduces significantly the amount of time the
users need to devote on their search for the right short rental apartment,
improving the overall decision-making procedure.

</details>


### [25] [Evaluating LLM-Based Mobile App Recommendations: An Empirical Study](https://arxiv.org/abs/2510.18364)
*Quim Motger,Xavier Franch,Vincenzo Gervasi,Jordi Marco*

Main category: cs.IR

TL;DR: 本文对大型语言模型在移动应用推荐中的表现进行实证分析，揭示了其推荐标准与传统应用商店优化指标的部分不一致性，并开发了评估框架来检验推荐的一致性和对明确排名指令的响应性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地通过自然语言提示来推荐移动应用，这些推荐背后的推理过程变得不透明，引发了对其一致性、可解释性以及与标准ASO指标对齐性的质疑。

Method: 通过构建16个通用排名标准的分类法，开发系统性评估框架来分析推荐一致性及对明确排名指令的响应性，并提供可复现的研究包。

Result: 发现LLMs依赖广泛但分散的排名标准，仅部分与标准ASO指标对齐。排名靠前的应用在不同运行中较为一致，但随着排名深度和搜索特异性增加，变异性增大。LLMs对明确排名指令的敏感性各不相同。

Conclusion: 研究结果旨在帮助终端用户、应用开发者和推荐系统研究人员在对话式应用发现的新兴领域中导航，揭示了LLMs在对话式应用推荐中复杂的推理动态。

Abstract: Large Language Models (LLMs) are increasingly used to recommend mobile
applications through natural language prompts, offering a flexible alternative
to keyword-based app store search. Yet, the reasoning behind these
recommendations remains opaque, raising questions about their consistency,
explainability, and alignment with traditional App Store Optimization (ASO)
metrics. In this paper, we present an empirical analysis of how widely-used
general purpose LLMs generate, justify, and rank mobile app recommendations.
Our contributions are: (i) a taxonomy of 16 generalizable ranking criteria
elicited from LLM outputs; (ii) a systematic evaluation framework to analyse
recommendation consistency and responsiveness to explicit ranking instructions;
and (iii) a replication package to support reproducibility and future research
on AI-based recommendation systems. Our findings reveal that LLMs rely on a
broad yet fragmented set of ranking criteria, only partially aligned with
standard ASO metrics. While top-ranked apps tend to be consistent across runs,
variability increases with ranking depth and search specificity. LLMs exhibit
varying sensitivity to explicit ranking instructions - ranging from substantial
adaptations to near-identical outputs - highlighting their complex reasoning
dynamics in conversational app discovery. Our results aim to support end-users,
app developers, and recommender-systems researchers in navigating the emerging
landscape of conversational app discovery.

</details>


### [26] [LLMs as Sparse Retrievers:A Framework for First-Stage Product Search](https://arxiv.org/abs/2510.18527)
*Hongru Song,Yu-an Liu,Ruqing Zhang,Jiafeng Guo,Maarten de Rijke,Sen Li,Wenjun Peng,Fuyu Lv,Xueqi Cheng*

Main category: cs.IR

TL;DR: PROSPER是一个利用大语言模型作为稀疏检索器的产品搜索框架，通过字面残差网络缓解幻觉问题，使用词汇聚焦窗口实现从粗到细的稀疏化策略，显著提升了产品搜索的召回性能。


<details>
  <summary>Details</summary>
Motivation: 产品搜索中稀疏检索方法存在严重的词汇不匹配问题，导致性能不理想。大语言模型具有语义分析潜力，但直接应用会面临幻觉问题和训练初始化困难。

Method: 提出PROSPER框架，包含：(1)字面残差网络，通过残差补偿机制强化被低估的字面词项；(2)词汇聚焦窗口，通过从粗到细的稀疏化策略实现有效的训练初始化。

Result: 离线和在线实验表明，PROSPER显著优于稀疏基线方法，召回性能与先进的稠密检索器相当，并在在线环境中实现了收入增长。

Conclusion: PROSPER成功解决了LLM在稀疏检索中的幻觉和训练初始化问题，为产品搜索提供了高效且高性能的解决方案。

Abstract: Product search is a crucial component of modern e-commerce platforms, with
billions of user queries every day. In product search systems, first-stage
retrieval should achieve high recall while ensuring efficient online
deployment. Sparse retrieval is particularly attractive in this context due to
its interpretability and storage efficiency. However, sparse retrieval methods
suffer from severe vocabulary mismatch issues, leading to suboptimal
performance in product search scenarios.With their potential for semantic
analysis, large language models (LLMs) offer a promising avenue for mitigating
vocabulary mismatch issues and thereby improving retrieval quality. Directly
applying LLMs to sparse retrieval in product search exposes two key
challenges:(1)Queries and product titles are typically short and highly
susceptible to LLM-induced hallucinations, such as generating irrelevant
expansion terms or underweighting critical literal terms like brand names and
model numbers;(2)The large vocabulary space of LLMs leads to difficulty in
initializing training effectively, making it challenging to learn meaningful
sparse representations in such ultra-high-dimensional spaces.To address these
challenges, we propose PROSPER, a framework for PROduct search leveraging LLMs
as SParsE Retrievers. PROSPER incorporates: (1)A literal residual network that
alleviates hallucination in lexical expansion by reinforcing underweighted
literal terms through a residual compensation mechanism; and (2)A lexical
focusing window that facilitates effective training initialization via a
coarse-to-fine sparsification strategy.Extensive offline and online experiments
show that PROSPER significantly outperforms sparse baselines and achieves
recall performance comparable to advanced dense retrievers, while also
achieving revenue increments online.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [27] [EVER: Edge-Assisted Auto-Verification for Mobile MR-Aided Operation](https://arxiv.org/abs/2510.18224)
*Jiangong Chen,Mingyu Zhu,Bin Li*

Main category: cs.MM

TL;DR: EVER是一个边缘辅助的移动混合现实操作自动验证系统，通过分割模型和渲染管道处理物理与虚拟对象差异，使用IoU指标进行阈值验证，在100毫秒内达到90%以上的验证准确率。


<details>
  <summary>Details</summary>
Motivation: 解决混合现实中用户是否遵循MR指导的自动验证问题，现有方法无法处理物理与虚拟对象之间的差异（如不完美的3D建模或光照估计）。

Method: 利用分割模型和渲染管道处理物理和虚拟帧的独特属性，采用基于IoU指标的阈值策略进行验证，并将计算密集型任务卸载到边缘服务器。

Result: 在公共数据集和自定义数据集上评估，EVER在100毫秒内达到90%以上的验证准确率，显著快于人类平均反应时间（约273毫秒），且仅消耗极少额外计算资源和能量。

Conclusion: EVER系统能够快速、准确地自动验证混合现实操作，在保持低能耗的同时显著优于传统方法。

Abstract: Mixed Reality (MR)-aided operation overlays digital objects on the physical
world to provide a more immersive and intuitive operation process. A primary
challenge is the precise and fast auto-verification of whether the user follows
MR guidance by comparing frames before and after each operation. The
pre-operation frame includes virtual guiding objects, while the post-operation
frame contains physical counterparts. Existing approaches fall short of
accounting for the discrepancies between physical and virtual objects due to
imperfect 3D modeling or lighting estimation. In this paper, we propose EVER:
an edge-assisted auto-verification system for mobile MR-aided operations.
Unlike traditional frame-based similarity comparisons, EVER leverages the
segmentation model and rendering pipeline adapted to the unique attributes of
frames with physical pieces and those with their virtual counterparts; it
adopts a threshold-based strategy using Intersection over Union (IoU) metrics
for accurate auto-verification. To ensure fast auto-verification and low energy
consumption, EVER offloads compute-intensive tasks to an edge server. Through
comprehensive evaluations of public datasets and custom datasets with practical
implementation, EVER achieves over 90% verification accuracy within 100
milliseconds (significantly faster than average human reaction time of
approximately 273 milliseconds), while consuming only minimal additional
computational resources and energy compared to a system without
auto-verification.

</details>


### [28] [How2Compress: Scalable and Efficient Edge Video Analytics via Adaptive Granular Video Compression](https://arxiv.org/abs/2510.18409)
*Yuheng Wu,Thanh-Tung Nguyen,Lucas Liebe,Quang Tau,Pablo Espinosa Campos,Jinghan Cheng,Dongman Lee*

Main category: cs.MM

TL;DR: How2Compress是一个简单有效的视频压缩框架，通过宏块级精细质量控制在保持分析精度的同时显著降低比特率，在H.264编解码器上实现最高50.4%的比特率节省。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的自适应视频压缩框架未能充分利用现代块基视频编解码器的精细质量控制能力，导致压缩效率未被充分挖掘。

Method: 提出How2Compress框架，在宏块级别进行精确的精细质量控制，作为即插即用模块可无缝集成到现有边缘视频分析流水线中。

Result: 在H.264编解码器上的实验结果显示，How2Compress实现最高50.4%的比特率节省，性能优于基线方法最高3.01倍，且不损失分析精度。

Conclusion: How2Compress证明了通过宏块级精细质量控制可显著提升视频压缩效率，具有实际有效性和高效性。

Abstract: With the rapid proliferation of the Internet of Things, video analytics has
become a cornerstone application in wireless multimedia sensor networks. To
support such applications under bandwidth constraints, learning-based adaptive
quantization for video compression have demonstrated strong potential in
reducing bitrate while maintaining analytical accuracy. However, existing
frameworks often fail to fully exploit the fine-grained quality control enabled
by modern blockbased video codecs, leaving significant compression efficiency
untapped.
  In this paper, we present How2Compress, a simple yet effective framework
designed to enhance video compression efficiency through precise, fine-grained
quality control at the macroblock level. How2Compress is a plug-and-play module
and can be seamlessly integrated into any existing edge video analytics
pipelines. We implement How2Compress on the H.264 codec and evaluate its
performance across diverse real-world scenarios. Experimental results show that
How2Compress achieves up to $50.4\%$ bitrate savings and outperforms baselines
by up to $3.01\times$ without compromising accuracy, demonstrating its
practical effectiveness and efficiency. Code is available at
https://github.com/wyhallenwu/how2compress and a reproducible docker image at
https://hub.docker.com/r/wuyuheng/how2compress.

</details>


### [29] [DeLoad: Demand-Driven Short-Video Preloading with Scalable Watch-Time Estimation](https://arxiv.org/abs/2510.18459)
*Tong Liu,Zhiwei Fan,Guanyan Peng,Haodan Zhang,Yucheng Zhang,Zhen Wang,Pengjin Xie,Liang Liu*

Main category: cs.MM

TL;DR: DeLoad是一个针对短视频流媒体的预加载框架，通过动态任务大小调整和多维度观看时间估计，结合深度强化学习优化下载决策，显著提升用户体验并降低带宽消耗。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个关键限制：(1)下载任务大小无法适应动态条件；(2)观看时间预测模型难以大规模可靠部署。需要设计能平衡QoE和带宽效率的预加载策略。

Method: 提出DeLoad框架，包含动态任务大小调整、实用的多维度观看时间估计方法，以及使用深度强化学习训练代理来自适应优化下载范围决策。

Result: 离线测试显示QoE指标提升34.4%至87.4%；实际部署后用户总观看时间增加0.09%，同时减少卡顿事件和3.76%带宽消耗。

Conclusion: DeLoad有效解决了短视频流媒体预加载的关键挑战，在提升用户体验的同时实现了带宽效率的优化，具有实际商业部署价值。

Abstract: Short video streaming has become a dominant paradigm in digital media,
characterized by rapid swiping interactions and diverse media content. A key
technical challenge is designing an effective preloading strategy that
dynamically selects and prioritizes download tasks from an evolving playlist,
balancing Quality of Experience (QoE) and bandwidth efficiency under practical
commercial constraints. However, real world analysis reveals critical
limitations of existing approaches: (1) insufficient adaptation of download
task sizes to dynamic conditions, and (2) watch time prediction models that are
difficult to deploy reliably at scale. In this paper, we propose DeLoad, a
novel preloading framework that addresses these issues by introducing dynamic
task sizing and a practical, multi dimensional watch time estimation method.
Additionally, a Deep Reinforcement Learning (DRL) enhanced agent is trained to
optimize the download range decisions adaptively. Extensive evaluations
conducted on an offline testing platform, leveraging massive real world network
data, demonstrate that DeLoad achieves significant improvements in QoE metrics
(34.4% to 87.4% gain). Furthermore, after deployment on a large scale
commercial short video platform, DeLoad has increased overall user watch time
by 0.09% while simultaneously reducing rebuffering events and 3.76% bandwidth
consumption.

</details>


### [30] [PIRA: Pan-CDN Intra-video Resource Adaptation for Short Video Streaming](https://arxiv.org/abs/2510.18606)
*Chunyu Qiao,Tong Liu,Yucheng Zhang,Zhiwei Fan,Pengjin Xie,Zhen Wang,Liang Liu*

Main category: cs.MM

TL;DR: PIRA是一个动态CDN资源选择算法，在短视频播放过程中实时优化用户体验质量和成本，通过数学建模和控制理论方法平衡QoE与成本。


<details>
  <summary>Details</summary>
Motivation: 在大型短视频平台中，CDN资源选择对维持用户体验质量和控制流量成本至关重要。研究发现提供更高平均QoE的CDN通常成本更高，且连接质量在单个视频播放期间也会波动，需要在QoE和成本之间进行动态权衡。

Method: 提出PIRA算法，通过数学模型正式整合QoE和成本，采用视频内控制理论CDN资源选择方法，在网络动态变化下平衡QoE和成本。为降低计算开销，使用状态空间剪枝和自适应参数调整来高效解决高维优化问题。

Result: 在涉及45万用户的两周大规模生产实验中，PIRA优于生产基线，实现了启动延迟减少2.1%，卡顿时间缩短15.2%，平均单位流量成本降低10%。

Conclusion: PIRA在大规模环境下有效平衡了用户体验和财务成本，证明了其在短视频流媒体CDN选择中的实用性。

Abstract: In large scale short video platforms, CDN resource selection plays a critical
role in maintaining Quality of Experience (QoE) while controlling escalating
traffic costs. To better understand this phenomenon, we conduct in the wild
network measurements during video playback in a production short video system.
The results reveal that CDNs delivering higher average QoE often come at
greater financial cost, yet their connection quality fluctuates even within a
single video underscoring a fundamental and dynamic trade off between QoE and
cost. However, the problem of sustaining high QoE under cost constraints
remains insufficiently investigated in the context of CDN selection for short
video streaming. To address this, we propose PIRA, a dynamic resource selection
algorithm that optimizes QoE and cost in real time during video playback. PIRA
formally integrating QoE and cost by a mathematical model, and introduce a
intra video control theoretic CDN resource selection approach which can balance
QoE and cost under network dynamics. To reduce the computation overheads, PIRA
employs state space pruning and adaptive parameter adjustment to efficiently
solve the high dimensional optimization problem. In large scale production
experiments involving 450,000 users over two weeks, PIRA outperforms the
production baseline, achieving a 2.1% reduction in start up delay, 15.2%
shorter rebuffering time, and 10% lower average unit traffic cost,
demonstrating its effectiveness in balancing user experience and financial cost
at scale.

</details>
