<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 10]
- [cs.MM](#cs.MM) [Total: 2]
- [cs.DS](#cs.DS) [Total: 3]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.IT](#cs.IT) [Total: 6]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [BiCoRec: Bias-Mitigated Context-Aware Sequential Recommendation Model](https://arxiv.org/abs/2512.13848)
*Mufhumudzi Muthivhi,Terence L van Zyl,Hairong Wang*

Main category: cs.IR

TL;DR: BiCoRec是一个新颖的序列推荐框架，通过自适应处理用户对热门和冷门物品的偏好变化，使用协同注意力机制和一致性损失函数来缓解流行度偏差，特别提升了对冷门物品偏好用户的推荐性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的序列推荐模型存在固有的流行度偏差问题，无法很好地适应用户对热门和冷门物品的偏好变化。需要开发能够自适应处理用户偏好变化的框架，特别是提升对偏好冷门物品用户的推荐性能。

Method: 提出BiCoRec框架：1) 使用协同注意力机制获取流行度加权的用户序列表示；2) 引入新的训练方案，通过一致性损失函数从未来偏好中学习；3) 自适应适应用户对热门和冷门物品的偏好变化。

Result: 对于偏好冷门物品的用户，BiCoRec在NDCG@10指标上比现有最佳基线平均提升26.00%。在完整物品集合排序中，在Movies、Fashion、Games和Music数据集上的NDCG@10得分分别为0.0102、0.0047、0.0021和0.0005。

Conclusion: BiCoRec通过自适应处理流行度偏差，有效提升了序列推荐性能，特别改善了偏好冷门物品用户的推荐效果，为解决推荐系统中的流行度偏差问题提供了新思路。

Abstract: Sequential recommendation models aim to learn from users evolving preferences. However, current state-of-the-art models suffer from an inherent popularity bias. This study developed a novel framework, BiCoRec, that adaptively accommodates users changing preferences for popular and niche items. Our approach leverages a co-attention mechanism to obtain a popularity-weighted user sequence representation, facilitating more accurate predictions. We then present a new training scheme that learns from future preferences using a consistency loss function. BiCoRec aimed to improve the recommendation performance of users who preferred niche items. For these users, BiCoRec achieves a 26.00% average improvement in NDCG@10 over state-of-the-art baselines. When ranking the relevant item against the entire collection, BiCoRec achieves NDCG@10 scores of 0.0102, 0.0047, 0.0021, and 0.0005 for the Movies, Fashion, Games and Music datasets.

</details>


### [2] [Intent-Guided Reasoning for Sequential Recommendation](https://arxiv.org/abs/2512.14034)
*Yifan Shao,Peilin Zhou*

Main category: cs.IR

TL;DR: 提出IGR-SR框架，通过显式提取高层意图来增强序列推荐中的推理过程，解决现有推理增强方法的不稳定性和表面推理问题。


<details>
  <summary>Details</summary>
Motivation: 现有推理增强方法仅以下一个目标商品作为监督，导致两个关键问题：1) 推理不稳定——过程对近期行为和偶然点击等虚假交互过于敏感；2) 表面推理——模型记忆商品间转移而非理解内在行为模式。

Method: 提出意图引导推理框架IGR-SR，包含三个核心组件：1) 潜在意图蒸馏器(LID)，使用冻结编码器和可学习令牌高效提取多层面意图；2) 意图感知审慎推理器(IDR)，通过双注意力架构将推理解耦为意图审慎和决策制定；3) 意图一致性正则化(ICR)，通过强制不同意图视图间表示一致性确保鲁棒性。

Result: 在三个公开数据集上的实验显示，IGR-SR相比最先进基线平均提升7.13%。在20%行为噪声下，IGR-SR仅退化10.4%，而竞争方法退化16.2%和18.6%，验证了意图引导推理的有效性和鲁棒性。

Conclusion: IGR-SR通过显式提取和利用高层意图，有效解决了序列推荐中推理增强方法的不稳定性和表面推理问题，显著提升了推荐性能和鲁棒性。

Abstract: Sequential recommendation systems aim to capture users' evolving preferences from their interaction histories. Recent reasoningenhanced methods have shown promise by introducing deliberate, chain-of-thought-like processes with intermediate reasoning steps. However, these methods rely solely on the next target item as supervision, leading to two critical issues: (1) reasoning instability--the process becomes overly sensitive to recent behaviors and spurious interactions like accidental clicks, and (2) surface-level reasoning--the model memorizes item-to-item transitions rather than understanding intrinsic behavior patterns. To address these challenges, we propose IGR-SR, an Intent-Guided Reasoning framework for Sequential Recommendation that anchors the reasoning process to explicitly extracted high-level intents. Our framework comprises three key components: (1) a Latent Intent Distiller (LID) that efficiently extracts multi-faceted intents using a frozen encoder with learnable tokens, (2) an Intent-aware Deliberative Reasoner (IDR) that decouples reasoning into intent deliberation and decision-making via a dual-attention architecture, and (3) an Intent Consistency Regularization (ICR) that ensures robustness by enforcing consistent representations across different intent views. Extensive experiments on three public datasets demonstrate that IGR-SR achieves an average 7.13% improvement over state-of-the-art baselines. Critically, under 20% behavioral noise, IGR-SR degrades only 10.4% compared to 16.2% and 18.6% for competing methods, validating the effectiveness and robustness of intent-guided reasoning.

</details>


### [3] [DTRec: Learning Dynamic Reasoning Trajectories for Sequential Recommendation](https://arxiv.org/abs/2512.14036)
*Yifan Shao,Peilin Zhou,Shoujin Wang,Weizhi Zhang,Xu Cai,Sunghun Kim*

Main category: cs.IR

TL;DR: DTRec：一种动态推理轨迹的序列推荐框架，通过分层过程监督和自适应推理停止机制，在方向和深度上优化推理过程，显著提升性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的推理增强序列推荐方法存在两个关键限制：1）静态推理方向，使用扁平监督信号，与人类分层推理不匹配；2）固定推理深度，对所有用户应用相同计算量，不考虑行为模式复杂度差异。这些刚性导致性能次优和计算浪费。

Method: 提出DTRec框架，包含两个核心组件：1）分层过程监督（HPS），提供从粗到细的监督信号，模拟人类认知过程的渐进细化；2）自适应推理停止（ARH）机制，通过联合监控三个指标动态调整推理步数。

Result: 在三个真实世界数据集上的实验表明，该方法相比强基线性能提升高达24.5%，同时计算成本降低高达41.6%。

Conclusion: DTRec通过动态调整推理轨迹的方向和深度，有效解决了现有方法的刚性限制，在提升推荐性能的同时显著降低了计算开销，为推理增强的序列推荐提供了新思路。

Abstract: Inspired by advances in LLMs, reasoning-enhanced sequential recommendation performs multi-step deliberation before making final predictions, unlocking greater potential for capturing user preferences. However, current methods are constrained by static reasoning trajectories that are ill-suited for the diverse complexity of user behaviors. They suffer from two key limitations: (1) a static reasoning direction, which uses flat supervision signals misaligned with human-like hierarchical reasoning, and (2) a fixed reasoning depth, which inefficiently applies the same computational effort to all users, regardless of pattern complexity. These rigidity lead to suboptimal performance and significant computational waste. To overcome these challenges, we propose DTRec, a novel and effective framework that explores the Dynamic reasoning Trajectory for Sequential Recommendation along both direction and depth. To guide the direction, we develop Hierarchical Process Supervision (HPS), which provides coarse-to-fine supervisory signals to emulate the natural, progressive refinement of human cognitive processes. To optimize the depth, we introduce the Adaptive Reasoning Halting (ARH) mechanism that dynamically adjusts the number of reasoning steps by jointly monitoring three indicators. Extensive experiments on three real-world datasets demonstrate the superiority of our approach, achieving up to a 24.5% performance improvement over strong baselines while simultaneously reducing computational cost by up to 41.6%.

</details>


### [4] [From Feature Interaction to Feature Generation: A Generative Paradigm of CTR Prediction Models](https://arxiv.org/abs/2512.14041)
*Mingjia Yin,Junwei Pan,Hao Wang,Ximei Wang,Shangyu Zhang,Jie Jiang,Defu Lian,Enhong Chen*

Main category: cs.IR

TL;DR: 提出SFG框架，将CTR预测从判别式"特征交互"范式转向生成式"特征生成"范式，解决嵌入维度坍缩和信息冗余问题


<details>
  <summary>Details</summary>
Motivation: 现有CTR预测模型主要采用判别式范式，过度依赖原始ID嵌入的特征交互，导致嵌入维度坍缩和信息冗余两个关键问题

Method: 提出监督特征生成(SFG)框架，包含编码器构建特征隐藏嵌入和解码器从隐藏表示重构特征嵌入，使用监督损失而非自监督损失

Result: SFG能有效缓解嵌入坍缩、减少信息冗余，在各种数据集和基础模型上带来显著性能提升，具有良好的通用性

Conclusion: SFG框架成功将CTR预测范式从判别式转向生成式，解决了现有模型的局限性，具有广泛适用性和实际应用价值

Abstract: Click-Through Rate (CTR) prediction, a core task in recommendation systems, aims to estimate the probability of users clicking on items. Existing models predominantly follow a discriminative paradigm, which relies heavily on explicit interactions between raw ID embeddings. However, this paradigm inherently renders them susceptible to two critical issues: embedding dimensional collapse and information redundancy, stemming from the over-reliance on feature interactions \emph{over raw ID embeddings}. To address these limitations, we propose a novel \emph{Supervised Feature Generation (SFG)} framework, \emph{shifting the paradigm from discriminative ``feature interaction" to generative ``feature generation"}. Specifically, SFG comprises two key components: an \emph{Encoder} that constructs hidden embeddings for each feature, and a \emph{Decoder} tasked with regenerating the feature embeddings of all features from these hidden representations. Unlike existing generative approaches that adopt self-supervised losses, we introduce a supervised loss to utilize the supervised signal, \ie, click or not, in the CTR prediction task. This framework exhibits strong generalizability: it can be seamlessly integrated with most existing CTR models, reformulating them under the generative paradigm. Extensive experiments demonstrate that SFG consistently mitigates embedding collapse and reduces information redundancy, while yielding substantial performance gains across various datasets and base models. The code is available at https://github.com/USTC-StarTeam/GE4Rec.

</details>


### [5] [AsarRec: Adaptive Sequential Augmentation for Robust Self-supervised Sequential Recommendation](https://arxiv.org/abs/2512.14047)
*Kaike Zhang,Qi Cao,Fei Sun,Xinran Liu*

Main category: cs.IR

TL;DR: 提出AsarRec框架，通过自适应增强解决序列推荐中噪声问题，相比静态增强方法表现更优


<details>
  <summary>Details</summary>
Motivation: 现实用户行为存在噪声（人为错误、不确定性、行为模糊性），导致推荐性能下降。现有基于对比学习的自监督学习方法依赖预定义的静态增强策略，存在两个关键挑战：1）最优增强类型在不同场景差异大；2）不合适的增强可能损害推荐性能

Method: 提出自适应增强框架AsarRec：1）将现有基本增强操作统一为结构化变换矩阵；2）通过学习生成变换矩阵，将用户序列编码为概率转移矩阵，通过可微分的Semi-Sinkhorn算法投影为硬半双随机矩阵；3）联合优化多样性、语义不变性和信息性三个目标

Result: 在三个基准数据集上不同噪声水平下的广泛实验验证了AsarRec的有效性，展示了其优越的鲁棒性和一致的性能提升

Conclusion: AsarRec通过自适应增强策略克服了静态增强的局限性，在噪声环境下实现了更鲁棒的序列推荐

Abstract: Sequential recommender systems have demonstrated strong capabilities in modeling users' dynamic preferences and capturing item transition patterns. However, real-world user behaviors are often noisy due to factors such as human errors, uncertainty, and behavioral ambiguity, which can lead to degraded recommendation performance. To address this issue, recent approaches widely adopt self-supervised learning (SSL), particularly contrastive learning, by generating perturbed views of user interaction sequences and maximizing their mutual information to improve model robustness. However, these methods heavily rely on their pre-defined static augmentation strategies~(where the augmentation type remains fixed once chosen) to construct augmented views, leading to two critical challenges: (1) the optimal augmentation type can vary significantly across different scenarios; (2) inappropriate augmentations may even degrade recommendation performance, limiting the effectiveness of SSL. To overcome these limitations, we propose an adaptive augmentation framework. We first unify existing basic augmentation operations into a unified formulation via structured transformation matrices. Building on this, we introduce AsarRec (Adaptive Sequential Augmentation for Robust Sequential Recommendation), which learns to generate transformation matrices by encoding user sequences into probabilistic transition matrices and projecting them into hard semi-doubly stochastic matrices via a differentiable Semi-Sinkhorn algorithm. To ensure that the learned augmentations benefit downstream performance, we jointly optimize three objectives: diversity, semantic invariance, and informativeness. Extensive experiments on three benchmark datasets under varying noise levels validate the effectiveness of AsarRec, demonstrating its superior robustness and consistent improvements.

</details>


### [6] [SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions](https://arxiv.org/abs/2512.14277)
*Panayiotis Smeros,Vincent Emonet,Ruijie Wang,Ana-Claudia Sima,Tarcisio Mendes de Farias*

Main category: cs.IR

TL;DR: SPARQL-LLM：一个基于轻量级元数据的开源、三元存储无关方法，用于从自然语言生成SPARQL查询，在准确性、多语言支持、联邦查询能力、速度和成本方面都有显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型方法主要关注单一数据源的响应准确性，忽略了联邦查询能力、运行时性能和成本等评估标准，导致难以在生产环境中部署到（可能联邦的）知识图谱上。

Method: 扩展先前工作，提出SPARQL-LLM架构，包含元数据索引、提示构建、查询生成和执行等专用组件，使用轻量级元数据支持，是开源且三元存储无关的方法。

Result: 在最新挑战中F1分数提升24%，支持英语和西班牙语等高资源语言，能够生成复杂的联邦生物信息学查询，比其他系统快达36倍，每个问题成本最高仅0.01美元。

Conclusion: SPARQL-LLM适合实时、低成本的文本到SPARQL应用，已在真实世界的去中心化知识图谱上部署（如https://www.expasy.org/chat）。

Abstract: The advent of large language models is contributing to the emergence of novel approaches that promise to better tackle the challenge of generating structured queries, such as SPARQL queries, from natural language. However, these new approaches mostly focus on response accuracy over a single source while ignoring other evaluation criteria, such as federated query capability over distributed data stores, as well as runtime and cost to generate SPARQL queries. Consequently, they are often not production-ready or easy to deploy over (potentially federated) knowledge graphs with good accuracy. To mitigate these issues, in this paper, we extend our previous work and describe and systematically evaluate SPARQL-LLM, an open-source and triplestore-agnostic approach, powered by lightweight metadata, that generates SPARQL queries from natural language text. First, we describe its architecture, which consists of dedicated components for metadata indexing, prompt building, and query generation and execution. Then, we evaluate it based on a state-of-the-art challenge with multilingual questions, and a collection of questions from three of the most prevalent knowledge graphs within the field of bioinformatics. Our results demonstrate a substantial increase of 24% in the F1 Score on the state-of-the-art challenge, adaptability to high-resource languages such as English and Spanish, as well as ability to form complex and federated bioinformatics queries. Furthermore, we show that SPARQL-LLM is up to 36x faster than other systems participating in the challenge, while costing a maximum of $0.01 per question, making it suitable for real-time, low-cost text-to-SPARQL applications. One such application deployed over real-world decentralized knowledge graphs can be found at https://www.expasy.org/chat.

</details>


### [7] [Dynamic Context Selection for Retrieval-Augmented Generation: Mitigating Distractors and Positional Bias](https://arxiv.org/abs/2512.14313)
*Malika Iratni,Mohand Boughanem,Taoufiq Dkaki*

Main category: cs.IR

TL;DR: 该论文分析了RAG系统中固定top-k检索策略的问题，提出动态预测最优检索文档数量的方法，以解决信息遗漏和干扰文档的问题。


<details>
  <summary>Details</summary>
Motivation: 标准RAG系统使用固定的top-k检索策略存在两个主要问题：1) 可能遗漏相关信息；2) 可能引入语义不相关的干扰文档，降低输出质量。此外，检索到的文档在输入上下文中的位置会影响模型注意力，出现"lost in the middle"现象。

Method: 首先系统分析干扰文档对生成质量的影响，量化不同条件下的效果。然后研究相关文档在上下文窗口中的位置如何影响生成效果。基于这些分析，提出一个上下文大小分类器，能够根据查询特定的信息需求动态预测最优检索文档数量，并将该方法集成到完整的RAG流程中。

Result: 提出的动态预测最优检索文档数量的方法在完整RAG流程中表现出优于固定k基线的性能。

Conclusion: 通过动态调整检索文档数量来适应查询特定的信息需求，可以有效解决固定top-k检索策略的问题，提高RAG系统的生成质量。

Abstract: Retrieval Augmented Generation (RAG) enhances language model performance by incorporating external knowledge retrieved from large corpora, which makes it highly suitable for tasks such as open domain question answering. Standard RAG systems typically rely on a fixed top k retrieval strategy, which can either miss relevant information or introduce semantically irrelevant passages, known as distractors, that degrade output quality. Additionally, the positioning of retrieved passages within the input context can influence the model attention and generation outcomes. Context placed in the middle tends to be overlooked, which is an issue known as the "lost in the middle" phenomenon. In this work, we systematically analyze the impact of distractors on generation quality, and quantify their effects under varying conditions. We also investigate how the position of relevant passages within the context window affects their influence on generation. Building on these insights, we propose a context-size classifier that dynamically predicts the optimal number of documents to retrieve based on query-specific informational needs. We integrate this approach into a full RAG pipeline, and demonstrate improved performance over fixed k baselines.

</details>


### [8] [PushGen: Push Notifications Generation with LLM](https://arxiv.org/abs/2512.14490)
*Shifu Bie,Jiangxia Cao,Zixiao Luo,Yichuan Zou,Lei Liang,Lu Zhang,Linxun Chen,Zhaojie Liu,Xuanping Li,Guorui Zhou,Kaiqiao Zhan,Kun Gai*

Main category: cs.IR

TL;DR: PushGen是一个自动生成高质量推送通知的框架，通过可控类别提示和奖励模型确保内容质量，已在大规模工业应用中部署


<details>
  <summary>Details</summary>
Motivation: 随着生成模型的兴起，利用LLM生成推送内容变得流行，但LLM在风格控制和可靠质量评估方面存在挑战，这两者直接影响用户参与度

Method: PushGen结合两个关键组件：(1)可控类别提示技术，引导LLM输出符合期望风格；(2)奖励模型，对生成候选内容进行排名和选择

Result: 广泛的离线和在线实验证明了其有效性，已在大规模工业应用中部署，每天为数亿用户提供服务

Conclusion: PushGen框架成功解决了LLM生成推送内容时的风格控制和质量评估问题，能够生成与人工制作内容相媲美的高质量推送通知

Abstract: We present PushGen, an automated framework for generating high-quality push notifications comparable to human-crafted content. With the rise of generative models, there is growing interest in leveraging LLMs for push content generation. Although LLMs make content generation straightforward and cost-effective, maintaining stylistic control and reliable quality assessment remains challenging, as both directly impact user engagement. To address these issues, PushGen combines two key components: (1) a controllable category prompt technique to guide LLM outputs toward desired styles, and (2) a reward model that ranks and selects generated candidates. Extensive offline and online experiments demonstrate its effectiveness, which has been deployed in large-scale industrial applications, serving hundreds of millions of users daily.

</details>


### [9] [RecGPT-V2 Technical Report](https://arxiv.org/abs/2512.14503)
*Chao Yi,Dian Chen,Gaoyang Guo,Jiakai Tang,Jian Wu,Jing Yu,Mao Zhang,Wen Chen,Wenjun Yang,Yujie Luo,Yuning Jiang,Zhujin Gao,Bo Zheng,Binbin Cao,Changfa Wu,Dixuan Wang,Han Wu,Haoyi Hu,Kewei Zhu,Lang Tian,Lin Yang,Qiqi Huang,Siqi Yang,Wenbo Su,Xiaoxiao He,Xin Tong,Xu Chen,Xunke Xi,Xiaowei Huang,Yaxuan Wu,Yeqiu Yang,Yi Hu,Yujin Yuan,Yuliang Yan,Zile Zhou*

Main category: cs.IR

TL;DR: RecGPT-V2通过分层多智能体系统、元提示框架、约束强化学习和智能体作为裁判框架，解决了V1版本的计算效率、解释多样性、泛化能力和评估标准问题，在淘宝A/B测试中显著提升了各项指标。


<details>
  <summary>Details</summary>
Motivation: RecGPT-V1虽然成功将LLM推理引入推荐系统，但存在四大局限：1) 多推理路径导致计算效率低下和认知冗余；2) 固定模板生成导致解释多样性不足；3) 监督学习范式下泛化能力有限；4) 结果导向评估未能匹配人类标准。需要解决这些问题以实现LLM驱动的意图推理在工业规模上的部署。

Method: 1) 分层多智能体系统：通过协调协作重构意图推理，消除认知重复同时实现多样化意图覆盖；2) 混合表示推理：压缩用户行为上下文，降低GPU消耗；3) 元提示框架：动态生成上下文自适应提示，提升解释多样性；4) 约束强化学习：缓解多奖励冲突；5) 智能体作为裁判框架：将评估分解为多步推理。

Result: GPU消耗降低60%，专属召回率从9.39%提升至10.99%；解释多样性提升+7.3%；标签预测提升+24.1%，解释接受度提升+13.0%；淘宝在线A/B测试显示：CTR提升+2.98%，IPV提升+3.71%，TV提升+2.19%，NER提升+11.46%。

Conclusion: RecGPT-V2证明了LLM驱动的意图推理在技术可行性和商业可行性上的双重成功，弥合了认知探索与工业效用之间的差距，为大规模部署提供了有效解决方案。

Abstract: Large language models (LLMs) have demonstrated remarkable potential in transforming recommender systems from implicit behavioral pattern matching to explicit intent reasoning. While RecGPT-V1 successfully pioneered this paradigm by integrating LLM-based reasoning into user interest mining and item tag prediction, it suffers from four fundamental limitations: (1) computational inefficiency and cognitive redundancy across multiple reasoning routes; (2) insufficient explanation diversity in fixed-template generation; (3) limited generalization under supervised learning paradigms; and (4) simplistic outcome-focused evaluation that fails to match human standards.
  To address these challenges, we present RecGPT-V2 with four key innovations. First, a Hierarchical Multi-Agent System restructures intent reasoning through coordinated collaboration, eliminating cognitive duplication while enabling diverse intent coverage. Combined with Hybrid Representation Inference that compresses user-behavior contexts, our framework reduces GPU consumption by 60% and improves exclusive recall from 9.39% to 10.99%. Second, a Meta-Prompting framework dynamically generates contextually adaptive prompts, improving explanation diversity by +7.3%. Third, constrained reinforcement learning mitigates multi-reward conflicts, achieving +24.1% improvement in tag prediction and +13.0% in explanation acceptance. Fourth, an Agent-as-a-Judge framework decomposes assessment into multi-step reasoning, improving human preference alignment. Online A/B tests on Taobao demonstrate significant improvements: +2.98% CTR, +3.71% IPV, +2.19% TV, and +11.46% NER. RecGPT-V2 establishes both the technical feasibility and commercial viability of deploying LLM-powered intent reasoning at scale, bridging the gap between cognitive exploration and industrial utility.

</details>


### [10] [Pairwise Comparison for Bias Identification and Quantification](https://arxiv.org/abs/2512.14565)
*Fabian Haak,Philipp Schaer*

Main category: cs.IR

TL;DR: 本文提出利用成对比较进行偏见标注的方法，通过模拟环境评估多种评分技术和成本感知替代方案，为创建高质量基准数据集和量化偏见提供基础。


<details>
  <summary>Details</summary>
Motivation: 在线新闻和社交媒体中的语言偏见普遍存在但难以测量，主要挑战包括主观性、上下文依赖性和高质量标注数据集的稀缺。需要减少标注工作量并提高偏见量化的可行性。

Method: 采用成对比较进行偏见标注，通过模拟环境评估多种评分技术和三种成本感知替代方案的参数。模拟包括潜在严重程度分布、距离校准噪声和合成标注者偏见。最后在人类标注的偏见基准数据集上评估最有前景的设置。

Result: 研究发现成对比较可作为量化主观语言方面的实用基础，支持可重复的偏见分析。与大型语言模型直接评估和未修改的成对比较基线相比，优化方法表现良好。

Conclusion: 成对比较方法为量化偏见和其他主观语言特征提供了实用框架，贡献包括比较和匹配组件的优化、端到端评估以及成本感知大规模标注的实现蓝图。

Abstract: Linguistic bias in online news and social media is widespread but difficult to measure. Yet, its identification and quantification remain difficult due to subjectivity, context dependence, and the scarcity of high-quality gold-label datasets. We aim to reduce annotation effort by leveraging pairwise comparison for bias annotation. To overcome the costliness of the approach, we evaluate more efficient implementations of pairwise comparison-based rating. We achieve this by investigating the effects of various rating techniques and the parameters of three cost-aware alternatives in a simulation environment. Since the approach can in principle be applied to both human and large language model annotation, our work provides a basis for creating high-quality benchmark datasets and for quantifying biases and other subjective linguistic aspects.
  The controlled simulations include latent severity distributions, distance-calibrated noise, and synthetic annotator bias to probe robustness and cost-quality trade-offs. In applying the approach to human-labeled bias benchmark datasets, we then evaluate the most promising setups and compare them to direct assessment by large language models and unmodified pairwise comparison labels as baselines. Our findings support the use of pairwise comparison as a practical foundation for quantifying subjective linguistic aspects, enabling reproducible bias analysis. We contribute an optimization of comparison and matchmaking components, an end-to-end evaluation including simulation and real-data application, and an implementation blueprint for cost-aware large-scale annotation

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [11] [Generative AI for Video Translation: A Scalable Architecture for Multilingual Video Conferencing](https://arxiv.org/abs/2512.13904)
*Amirkia Rafiei Oskooei,Eren Caglar,Ibrahim Sahin,Ayse Kayabay,Mehmet S. Aktas*

Main category: cs.MM

TL;DR: 提出一个系统级框架来解决级联生成式AI流水线在实时视频翻译应用中的延迟和可扩展性问题，通过轮转机制和分段处理实现线性复杂度和实时体验。


<details>
  <summary>Details</summary>
Motivation: 级联生成式AI流水线在实时视频翻译应用中面临系统级挑战：序列模型推理的累积延迟和二次方计算复杂度导致多用户视频会议应用无法扩展。

Method: 提出包含轮转机制（将计算复杂度从二次方降至线性）和分段处理协议（管理推理延迟以实现感知实时体验）的系统架构。在多层级硬件上实现概念验证流水线并进行性能分析。

Result: 客观评估显示系统在现代硬件上实现实时吞吐量（τ<1.0）。主观用户研究验证了可预测的初始处理延迟对用户高度可接受，以换取流畅不间断的播放体验。

Conclusion: 提出了一个经过验证的端到端系统设计，为在多语言通信平台中部署可扩展的实时生成式AI应用提供了实用路线图。

Abstract: The real-time deployment of cascaded generative AI pipelines for applications like video translation is constrained by significant system-level challenges. These include the cumulative latency of sequential model inference and the quadratic ($\mathcal{O}(N^2)$) computational complexity that renders multi-user video conferencing applications unscalable. This paper proposes and evaluates a practical system-level framework designed to mitigate these critical bottlenecks. The proposed architecture incorporates a turn-taking mechanism to reduce computational complexity from quadratic to linear in multi-user scenarios, and a segmented processing protocol to manage inference latency for a perceptually real-time experience. We implement a proof-of-concept pipeline and conduct a rigorous performance analysis across a multi-tiered hardware setup, including commodity (NVIDIA RTX 4060), cloud (NVIDIA T4), and enterprise (NVIDIA A100) GPUs. Our objective evaluation demonstrates that the system achieves real-time throughput ($τ< 1.0$) on modern hardware. A subjective user study further validates the approach, showing that a predictable, initial processing delay is highly acceptable to users in exchange for a smooth, uninterrupted playback experience. The work presents a validated, end-to-end system design that offers a practical roadmap for deploying scalable, real-time generative AI applications in multilingual communication platforms.

</details>


### [12] [End-to-End Learning-based Video Streaming Enhancement Pipeline: A Generative AI Approach](https://arxiv.org/abs/2512.14185)
*Emanuele Artioli,Farzad Tashtarian,Christian Timmerer*

Main category: cs.MM

TL;DR: ELVIS是一个端到端学习型视频流增强框架，通过服务器端编码优化和客户端生成式修复技术来移除和重建冗余视频数据，在保持带宽不变的情况下提升视频质量。


<details>
  <summary>Details</summary>
Motivation: 传统编解码器需要在视频质量和流畅播放之间权衡，且必须编码和传输整个视频数据，无法利用上下文信息。需要一种新方法来在带宽限制下提升视频质量。

Method: ELVIS采用端到端架构，结合服务器端编码优化和客户端生成式修复技术。模块化设计支持集成不同编解码器、修复模型和质量评估指标，具有良好适应性。

Result: 当前技术相比基准测试可提升高达11个VMAF点，显著改善视频质量。但实时应用仍面临计算需求大的挑战。

Conclusion: ELVIS是将生成式AI融入视频流管道的奠基性工作，能够在带宽不变的情况下实现更高质量的视频体验，为未来创新提供了灵活框架。

Abstract: The primary challenge of video streaming is to balance high video quality with smooth playback. Traditional codecs are well tuned for this trade-off, yet their inability to use context means they must encode the entire video data and transmit it to the client. This paper introduces ELVIS (End-to-end Learning-based VIdeo Streaming Enhancement Pipeline), an end-to-end architecture that combines server-side encoding optimizations with client-side generative in-painting to remove and reconstruct redundant video data. Its modular design allows ELVIS to integrate different codecs, inpainting models, and quality metrics, making it adaptable to future innovations. Our results show that current technologies achieve improvements of up to 11 VMAF points over baseline benchmarks, though challenges remain for real-time applications due to computational demands. ELVIS represents a foundational step toward incorporating generative AI into video streaming pipelines, enabling higher quality experiences without increased bandwidth requirements.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [13] [Finding $b$-colorings Using Feedback Edges](https://arxiv.org/abs/2512.14390)
*Jakub Balabán*

Main category: cs.DS

TL;DR: 本文研究了图b-染色问题的参数化复杂性，针对反馈边数和距离到共簇两个参数给出了FPT算法，并证明了在树深度参数下该问题是W[1]-难的。


<details>
  <summary>Details</summary>
Motivation: b-染色问题是NP完全的，虽然在树上有多项式时间算法，但在树宽参数下是W[t]-难的。目前只有很少的参数（如顶点覆盖数）已知有FPT算法。本文旨在寻找更多能实现FPT算法的参数。

Method: 结合参数化算法中的标准技术和树上的多项式时间算法思路，针对反馈边数参数设计FPT算法。同时针对距离到共簇参数也设计了FPT算法。基于已知结果进行观察分析。

Result: 1) 在反馈边数参数下，b-染色问题是固定参数可解的；2) 在距离到共簇参数下，b-染色问题也是固定参数可解的；3) 在树深度参数下，b-染色问题是W[1]-难的。

Conclusion: b-染色问题在反馈边数和距离到共簇这两个参数下是固定参数可解的，但在树深度参数下是W[1]-难的。这扩展了对该问题参数化复杂性的理解。

Abstract: A $b$-coloring of a graph is a proper vertex coloring such that each color class contains a vertex that sees all other colors in its neighborhood. The $b$-coloring problem, in which the task is to decide whether a graph admits a $b$-coloring with $k$ colors, is NP-complete in general but polytime solvable on trees. Moreover, it is known that $b$-coloring is in XP but W[$t$]-hard for all $t \in \mathbb{N}$ when parameterized by tree-width. In fact, only very few parameters, such as the vertex cover number, were known to admit an FPT algorithm for $b$-coloring. In this paper, we consider a more restrictive parameter measuring similarity to trees than tree-width, namely the feedback edge number, and show that $b$-coloring is fixed-parameter tractable under this parameterization. Our algorithm combines standard techniques used in parameterized algorithmics with the problem-specific ideas used in the polytime algorithm for trees. In addition, we present an FPT algorithm for $b$-coloring parameterized by distance to co-cluster, which is a parameter measuring similarity to complete multipartite graphs. Finally, we make several observations based on known results, including that $b$-coloring is W[$1$]-hard when parameterized by tree-depth.

</details>


### [14] [Cost-Free Neutrality for the River Method](https://arxiv.org/abs/2512.14409)
*Michelle Döring,Jannes Malanowski,Stefan Neubert*

Main category: cs.DS

TL;DR: River投票规则通过FUN算法在多项式时间内计算PUT下的获胜者，相比Ranked Pairs的NP完全问题具有显著优势


<details>
  <summary>Details</summary>
Motivation: 传统投票规则如Ranked Pairs使用平局打破机制会破坏中立性，而使用PUT恢复中立性会导致计算复杂度高（NP完全）。需要找到既能保持中立性又能在多项式时间内计算的投票方法。

Method: 提出Fused-Universe (FUN)算法，在单次遍历中模拟所有可能的平局打破情况，通过构建FUN图直接读取获胜者和获胜证书。

Result: 证明了River规则在PUT下可以在多项式时间内计算获胜者，相比Ranked Pairs的NP完全问题具有显著计算优势。

Conclusion: River规则在保持中立性的同时具有多项式时间计算复杂度，展现了优于Ranked Pairs的结构特性，为投票系统设计提供了更实用的选择。

Abstract: Recently, the River Method was introduced as novel refinement of the Split Cycle voting rule.
  The decision-making process of River is closely related to the well established Ranked Pairs Method.
  Both methods consider a margin graph computed from the voters' preferences and eliminate majority cycles in that graph to choose a winner.
  As ties can occur in the margin graph, a tiebreaker is required along with the preferences.
  While such a tiebreaker makes the computation efficient, it compromises the fundamental property of neutrality: the voting rule should not favor alternatives in advance.
  One way to reintroduce neutrality is to use Parallel-Universe Tiebreaking (PUT), where each alternative is a winner if it wins according to any possible tiebreaker.
  Unfortunately, computing the winners selected by Ranked Pairs with PUT is NP-complete.
  Given the similarity of River to Ranked Pairs, one might expect River to suffer from the same complexity.
  Surprisingly, we show the opposite:
  We present a polynomial-time algorithm for computing River winners with PUT, highlighting significant structural advantages of River over Ranked Pairs.
  Our Fused-Universe (FUN) algorithm simulates River for every possible tiebreaking in one pass.
  From the resulting FUN diagram one can then directly read off both the set of winners and, for each winner, a certificate that explains how this alternative dominates the others.

</details>


### [15] [An Improved Approximation Algorithm for Maximum Weight 3-Path Packing](https://arxiv.org/abs/2512.14457)
*Jingyang Zhao,Mingyu Xiao*

Main category: cs.DS

TL;DR: 提出了最大权重3-路径打包问题的10/17近似算法，改进了之前7/12的最好结果


<details>
  <summary>Details</summary>
Motivation: 最大权重3-路径打包问题与经典的最大权重匹配问题密切相关，但现有算法存在改进空间。该问题在n能被3整除的完全图中寻找n/3个顶点不相交的3-路径，使得总权重最大化。

Method: 通过三种算法的权衡：基于大小为n/2的最大权重匹配算法、基于大小为n/3的最大权重匹配算法，以及基于星形打包的近似算法。提出了新的分析方法——收费法，这对分析第二种算法至关重要。

Result: 获得了10/17近似比的算法，优于之前ESA 2015会议上提出的7/12近似算法。

Conclusion: 通过算法权衡和新分析方法，显著改进了最大权重3-路径打包问题的近似比，且分析方法可扩展到相关问题的算法分析。

Abstract: Given a complete graph with $n$ vertices and non-negative edge weights, where $n$ is divisible by 3, the maximum weight 3-path packing problem is to find a set of $n/3$ vertex-disjoint 3-paths such that the total weight of the 3-paths in the packing is maximized. This problem is closely related to the classic maximum weight matching problem. In this paper, we propose a $10/17$-approximation algorithm, improving the best-known $7/12$-approximation algorithm (ESA 2015). Our result is obtained by making a trade-off among three algorithms. The first is based on the maximum weight matching of size $n/2$, the second is based on the maximum weight matching of size $n/3$, and the last is based on an approximation algorithm for star packing. Our first algorithm is the same as the previous $7/12$-approximation algorithm, but we propose a new analysis method -- a charging method -- for this problem, which is not only essential to analyze our second algorithm but also may be extended to analyze algorithms for some related problems.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [16] [The Impact Market to Save Conference Peer Review: Decoupling Dissemination and Credentialing](https://arxiv.org/abs/2512.14104)
*Karthikeyan Sankaralingam*

Main category: cs.GT

TL;DR: 提出Impact Market系统，将论文发表与声望分离，通过投资市场机制解决学术会议评审中的主观性和等效类问题


<details>
  <summary>Details</summary>
Motivation: 顶级学术会议面临两个不可调和的角色冲突：快速传播所有可靠研究 vs 稀缺的声望认证。这导致了评审轮盘赌和匿名法庭模式，存在高风险主观性、地盘争夺和可靠研究的任意拒绝（等效类问题）

Method: 提出Impact Market三阶段系统：1) 发表阶段：所有可靠严谨论文通过程序委员会评审接受；2) 投资阶段：通过期货市场创建稀缺声望信号，资深社区成员投资代币创建透明的众包净投资分数；3) 校准阶段：3年回溯机制验证投资，计算抗操纵的多向量影响分数，调整投资者评级

Result: 基于代理的模拟显示，被动市场在低技能环境中与现有协议匹配，但引入投资者能动性和信念投注后，在相同条件下高影响力论文的检索率从28%提高到85%以上

Conclusion: Impact Market模型用透明、可问责、数据驱动的市场取代了隐藏的零成本攻击系统，将即时认证与长期验证影响对齐，激励性自我选择是扩展同行评审所需的机制

Abstract: Top-tier academic conferences are failing under the strain of two irreconcilable roles: (1) rapid dissemination of all sound research and (2) scarce credentialing for prestige and career advancement. This conflict has created a reviewer roulette and anonymous tribunal model - a zero-cost attack system - characterized by high-stakes subjectivity, turf wars, and the arbitrary rejection of sound research (the equivalence class problem). We propose the Impact Market (IM), a novel three-phase system that decouples publication from prestige. Phase 1 (Publication): All sound and rigorous papers are accepted via a PC review, solving the "equivalence class" problem. Phase 2 (Investment): An immediate, scarce prestige signal is created via a futures market. Senior community members invest tokens into published papers, creating a transparent, crowdsourced Net Invested Score (NIS). Phase 3 (Calibration): A 3-year lookback mechanism validates these investments against a manipulation-resistant Multi-Vector Impact Score (MVIS). This MVIS adjusts each investor's future influence (their Investor Rating), imposing a quantifiable cost on bad actors and rewarding accurate speculation. The IM model replaces a hidden, zero-cost attack system with a transparent, accountable, and data-driven market that aligns immediate credentialing with long-term, validated impact. Agent-based simulations demonstrate that while a passive market matches current protocols in low-skill environments, introducing investor agency and conviction betting increases the retrieval of high-impact papers from 28% to over 85% under identical conditions, confirming that incentivized self-selection is the mechanism required to scale peer review.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [17] [Time and Relations into Focus: Ontological Foundations of Object-Centric Event Data](https://arxiv.org/abs/2512.14425)
*Hosna Hooshyar,Mattia Fumagalli,Marco Montali,Giancarlo Guizzardi*

Main category: cs.DB

TL;DR: 该论文提出了一种基于本体论基础的对象中心事件数据(gOCED)元模型，通过gUFO本体增强OCED核心模型，解决了现有对象中心事件数据模型的模糊性和表达能力限制问题。


<details>
  <summary>Details</summary>
Motivation: 传统案例中心的事件数据模型无法处理多对象关联和对象间交互的复杂性。现有对象中心事件数据(OCED)模型虽然尝试简化，但仍存在固有模糊性，且缺乏对时间和动态关系的全面支持。

Method: 采用三步法：1)分析现有OCED元模型的关键问题；2)基于gUFO本体论增强OCED核心模型，提出gOCED元模型；3)展示gOCED如何覆盖现有模型特性并扩展关键功能。

Result: 提出的gOCED元模型既保留了现有模型的简洁性，又扩展了必要功能，解决了文献中报告的模糊性和表达能力问题，为对象中心过程挖掘提供了更完善的基础。

Conclusion: 通过将本体论基础引入对象中心事件数据，gOCED填补了现有模型的空白，为对象中心过程挖掘提供了更强大、更清晰的建模框架，有望成为该领域的新标准基础。

Abstract: Object-centric process mining is a new branch of process mining where events are associated with multiple objects, and where object-to-object interactions are essential to understand the process dynamics. Traditional event data models, also called case-centric, are unable to cope with the complexity introduced by these more refined relationships. Several models have been made to move from case-centric to Object-Centric Event Data (OCED), trying to retain simplicity as much as possible. Still, these suffer from inherent ambiguities, and lack a comprehensive support of essential dimensions related to time and (dynamic) relations. In this work, we propose to fill this gap by leveraging a well-founded ontology of events and bringing ontological foundations to OCED, with a three-step approach. First, we start from key open issues reported in the literature regarding current OCED metamodels, and witness their ambiguity and expressiveness limitations on illustrative and representative examples proposed therein. Second, we consider the OCED Core Model, currently proposed as the basis for defining a new standard for object-centric event data, and we enhance it by grounding it on a lightweight version of UFO-B called gUFO, a well-known foundational ontology tailored to the representation of objects, events, time, and their (dynamic) relations. This results in a new metamodel, which we call gOCED. The third contribution then shows how gOCED at once covers the features of existing metamodels preserving their simplicity, and extends them with the essential features needed to overcome the ambiguity and expressiveness issues reported in the literature.

</details>


### [18] [Beyond Text-to-SQL: Autonomous Research-Driven Database Exploration with DAR](https://arxiv.org/abs/2512.14622)
*Ostap Vykhopen,Viktoria Skorik,Maxim Tereschenko,Veronika Solopova*

Main category: cs.DB

TL;DR: DAR是一个多智能体系统，能够在没有人工查询的情况下自主进行数据库研究，比专业分析师快32倍


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型数据库查询系统大多是被动式的，依赖用户明确提示，缺乏主动探索数据的能力。需要从查询驱动的辅助转向自主、研究驱动的探索

Method: DAR采用三层多智能体架构：初始化层（意图推断和元数据提取）、执行层（SQL和AI查询合成与迭代验证）、合成层（报告生成与质量控制）。所有推理直接在BigQuery中使用原生生成AI函数执行

Result: 在真实的资产-事件数据集上，DAR在16分钟内完成完整分析任务，而专业分析师需要8.5小时（约快32倍），能产生有用的模式洞察和基于证据的建议

Conclusion: DAR在快速探索性分析方面表现出色，将数据库交互从查询驱动的辅助转向云数据仓库内的自主研究驱动探索。虽然人类专家仍能提供更深层次的上下文解释，但DAR在自动化分析方面具有显著优势

Abstract: Large language models can already query databases, yet most existing systems remain reactive: they rely on explicit user prompts and do not actively explore data. We introduce DAR (Data Agnostic Researcher), a multi-agent system that performs end-to-end database research without human-initiated queries. DAR orchestrates specialized AI agents across three layers: initialization (intent inference and metadata extraction), execution (SQL and AI-based query synthesis with iterative validation), and synthesis (report generation with built-in quality control). All reasoning is executed directly inside BigQuery using native generative AI functions, eliminating data movement and preserving data governance. On a realistic asset-incident dataset, DAR completes the full analytical task in 16 minutes, compared to 8.5 hours for a professional analyst (approximately 32x times faster), while producing useful pattern-based insights and evidence-grounded recommendations. Although human experts continue to offer deeper contextual interpretation, DAR excels at rapid exploratory analysis. Overall, this work shifts database interaction from query-driven assistance toward autonomous, research-driven exploration within cloud data warehouses.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [19] [Symbol Distributions in Semantic Communications: A Source-Channel Equilibrium Perspective](https://arxiv.org/abs/2512.14022)
*Hanju Yoo,Dongha Choi,Songkuk Kim,Chan-Byoung Chae,Robert W. Heath*

Main category: cs.IT

TL;DR: 该论文提出语义通信系统中符号分布的新解释：源编码与通信之间的固有权衡，导致符号呈现学生t分布，并通过实验验证了该理论框架。


<details>
  <summary>Details</summary>
Motivation: 当前语义通信系统使用端到端神经网络将输入数据映射为连续符号，这些符号具有固定维度和重尾分布，但其分布形成原因尚未得到充分探索。

Method: 提出信息论优化框架，将编码器视为平衡两个目标：为最小有效码长分配功率（源编码）和最大化互信息（通信），推导出符号分布遵循学生t分布。

Result: 通过图像语义系统的广泛研究，发现该框架能准确建模学习到的符号分布，并能预测形状参数随变长编码和数据集熵变异性的变化规律。

Conclusion: 语义符号分布源于源编码与通信的固有权衡，通过引入强制目标符号分布的规范化器（如高斯先验）可改善训练收敛性，验证了所提假设。

Abstract: Semantic communication systems often use an end-to-end neural network to map input data into continuous symbols. These symbols, which are essentially neural network features, usually have fixed dimensions and heavy-tailed distributions. However, due to the end-to-end training nature of the neural network encoder, the underlying reason for the symbol distribution remains underexplored. We propose a new explanation for the semantic symbol distribution: an inherent trade-off between source coding and communications. Specifically, the encoder balances two objectives: allocating power for minimum \emph{effective codelength} (for source coding) and maximizing mutual information (for communications). We formalize this trade-off via an information-theoretic optimization framework, which yields a Student's $t$-distribution as the resulting symbol distribution. Through extensive studies on image-based semantic systems, we find that our formulation models the learned symbols and predicts how the symbol distribution's shape parameter changes with respect to (i) the use of variable-length coding and (ii) the dataset's entropy variability. Furthermore, we demonstrate how introducing a regularizer that enforces a target symbol distribution, which guides the encoder towards a target prior (e.g., Gaussian), improves training convergence and supports our hypothesis.

</details>


### [20] [Complete weight enumerators and weight hierarchies for linear codes from quadratic forms](https://arxiv.org/abs/2512.14073)
*Xiumei Li,Xiaotong Sun,Min Sha*

Main category: cs.IT

TL;DR: 本文扩展了Xie等人的工作，为奇素数幂q构造了两类最多有四个非零权重的线性码，通过双变量二次型构造，确定了其完全重量枚举器和重量层次，多数码是最小且部分达到Griesmer界最优。


<details>
  <summary>Details</summary>
Motivation: 扩展Xie等人的线性码构造方法，通过双变量二次型构造具有良好重量特性的线性码，这些码在编码理论中具有重要应用价值。

Method: 使用双变量二次型构造两类线性码C_Q和C_Q'，通过指数和计算完全确定其完全重量枚举器和重量层次结构。

Result: 成功构造了两类最多有四个非零权重的线性码，确定了它们的完全重量枚举器和重量层次，多数码是最小的，部分码达到Griesmer界最优。同时确定了其下降码的重量层次。

Conclusion: 提出的构造方法有效产生了具有良好重量特性的线性码，这些码在编码理论中具有实际应用价值，扩展了现有线性码构造的研究范围。

Abstract: In this paper, for an odd prime power $q$, we extend the construction of Xie et al. \cite{XOYM2023} to propose two classes of linear codes $\mathcal{C}_{Q}$ and $\mathcal{C}_{Q}'$ over the finite field $\mathbb{F}_{q}$ with at most four nonzero weights. These codes are derived from quadratic forms through a bivariate construction. We completely determine their complete weight enumerators and weight hierarchies by employing exponential sums. Most of these codes are minimal and some are optimal in the sense that they meet the Griesmer bound. Furthermore, we also establish the weight hierarchies of $\mathcal{C}_{Q,N}$ and $\mathcal{C}_{Q,N}'$, which are the descended codes of $\mathcal{C}_{Q}$ and $\mathcal{C}_{Q}'$.

</details>


### [21] [Target Detection in Clustered Mobile Nanomachine Networks](https://arxiv.org/abs/2512.14105)
*Nithin V. Sabu,Kaushlendra Pandey,Abhishek K. Gupta,Sameer S. M*

Main category: cs.IT

TL;DR: 开发分析框架研究基于扩散辅助分子通信的纳米机器网络，采用聚类初始部署在三维环境中检测目标，分析检测概率及其边界。


<details>
  <summary>Details</summary>
Motivation: 研究纳米机器网络在三维介质中的目标检测问题，特别关注聚类部署对检测性能的影响，为纳米尺度和生物环境中的分子通信系统设计提供理论指导。

Method: 使用泊松聚类过程建模纳米机器的初始位置分布，推导目标检测概率的解析表达式及相关边界，分析单聚类场景，并通过粒子模拟验证所有推导结果。

Result: 聚类对检测概率有显著影响，不同的空间排列产生不同的性能表现；分析了每聚类平均纳米机器数量、聚类密度和空间扩展等关键参数对检测性能的影响。

Conclusion: 研究结果为纳米尺度和生物环境中分子通信系统的优化设计提供了更好的理解，有助于实现最优目标检测性能。

Abstract: This work focuses on the development of an analytical framework to study a diffusion-assisted molecular communication-based network of nano-machines (NMs) with a clustered initial deployment to detect a target in a three-dimensional (3D) medium. Leveraging the Poisson cluster process to model the initial locations of clustered NMs, we derive the analytical expression for the target detection probability with respect to time along with relevant bounds. We also investigate a single-cluster scenario. All the derived expressions are validated through extensive particle-based simulations. Furthermore, we analyze the impact of key parameters, such as the mean number of NMs per cluster, the density of the cluster, and the spatial spread, on the detection performance. Our results show that detection probability is greatly influenced by clustering, and different spatial arrangements produce varying performances. The results offer a better understanding of how molecular communication systems should be designed for optimal target detection in nanoscale and biological environments.

</details>


### [22] [Robust Beamforming for Multiuser MIMO Systems with Unknown Channel Statistics: A Hybrid Offline-Online Framework](https://arxiv.org/abs/2512.14165)
*Wenzhuo Zou,Ming-Min Zhao,An Liu,Min-Jian Zhao*

Main category: cs.IT

TL;DR: 提出混合离线-在线框架解决MU-MIMO系统中信道状态信息不完美下的鲁棒波束成形问题，通过深度神经网络学习信道估计误差协方差，结合稀疏增强低秩方法降低复杂度，并采用多基础模型无关元学习策略提升适应性。


<details>
  <summary>Details</summary>
Motivation: 传统模型驱动方法需要先验误差协方差矩阵知识，数据驱动的深度学习方法在未见信道条件下泛化能力差，需要一种既能有效离线学习又能快速在线适应的鲁棒波束成形方案。

Method: 1. 离线阶段：提出共享深度神经网络学习信道估计误差协方差，无需统计先验；采用稀疏增强低秩方法降低复杂度。2. 在线阶段：网络可快速微调；提出多基础模型无关元学习策略，维护多个元初始化并动态选择最佳方案。

Result: 仿真结果表明，所提离线-在线框架在不同信道条件下表现出强鲁棒性，能够显著优于现有最先进的基线方法。

Conclusion: 该混合框架成功解决了信道估计误差统计未知情况下的鲁棒波束成形问题，结合了离线学习和在线适应的优势，在复杂度和性能间取得良好平衡，为MU-MIMO系统提供了有效的解决方案。

Abstract: Robust beamforming design under imperfect channel state information (CSI) is a fundamental challenge in multiuser multiple-input multiple-output (MU-MIMO) systems, particularly when the channel estimation error statistics are unknown. Conventional model-driven methods usually rely on prior knowledge of the error covariance matrix and data-driven deep learning approaches suffer from poor generalization capability to unseen channel conditions. To address these limitations, this paper proposes a hybrid offline-online framework that achieves effective offline learning and rapid online adaptation. In the offline phase, we propose a shared (among users) deep neural network (DNN) that is able to learn the channel estimation error covariance from observed samples, thus enabling robust beamforming without statistical priors. Meanwhile, to facilitate real-time deployment, we propose a sparse augmented low-rank (SALR) method to reduce complexity while maintaining comparable performance. In the online phase, we show that the proposed network can be rapidly fine-tuned with minimal gradient steps. Furthermore, a multiple basis model-agnostic meta-learning (MB-MAML) strategy is further proposed to maintain multiple meta-initializations and by dynamically selecting the best one online, we can improve the adaptation and generalization capability of the proposed framework under unseen or non-stationary channels. Simulation results demonstrate that the proposed offline-online framework exhibits strong robustness across diverse channel conditions and it is able to significantly outperform state-of-the-art (SOTA) baselines.

</details>


### [23] [Agile Affine Frequency Division Multiplexing](https://arxiv.org/abs/2512.14424)
*Yewen Cao,Yulin Shao*

Main category: cs.IT

TL;DR: Agile-AFDM：一种新型自适应波形框架，通过动态优化啁啾参数，实现功率效率、通信可靠性和感知精度的智能权衡，为6G提供灵活波形设计。


<details>
  <summary>Details</summary>
Motivation: 6G需要超越静态鲁棒性的智能自适应波形。传统AFDM的啁啾参数针对最坏情况优化，限制了其在动态环境中的性能。需要一种能够根据实时信道和数据信息自适应调整的波形框架。

Method: 提出Agile-AFDM框架，将啁啾参数重新定义为每个传输块的可优化变量。基于实时信道和数据信息，通过高效定制优化算法动态调整波形，实现PAPR最小化、ICI抑制或CRLB降低等目标。

Result: 综合仿真表明，Agile-AFDM在所有指标上都取得显著性能提升，超越传统OFDM和静态AFDM。实现了功率效率、通信可靠性和感知精度的智能权衡。

Conclusion: Agile-AFDM实现了从静态波形到上下文感知信号设计的范式转变，为6G及未来的敏捷波形设计提供了关键进展，使波形能够智能适应不同应用场景需求。

Abstract: The advancement to 6G calls for waveforms that transcend static robustness to achieve intelligent adaptability. Affine Frequency Division Multiplexing (AFDM), despite its strength in doubly-dispersive channels, has been confined by chirp parameters optimized for worst-case scenarios. This paper shatters this limitation with Agile-AFDM, a novel framework that endows AFDM with dynamic, data-aware intelligence. By redefining chirp parameters as optimizable variables for each transmission block based on real-time channel and data information, Agile-AFDM transforms into an adaptive platform. It can actively reconfigure its waveform to minimize peak-to-average power ratio (PAPR) for power efficiency, suppress inter-carrier interference (ICI) for communication reliability, or reduce Cramer-Rao bound (CRLB) for sensing accuracy. This paradigm shift from a static, one-size-fits-all waveform to a context-aware signal designer is made practical by efficient, tailored optimization algorithms. Comprehensive simulations demonstrate that this capability delivers significant performance gains across all metrics, surpassing conventional OFDM and static AFDM. Agile-AFDM, therefore, offers a crucial step forward in the design of agile waveforms for 6G and beyond.

</details>


### [24] [The Performance of Compression-Based Denoisers](https://arxiv.org/abs/2512.14539)
*Dan Song,Ayfer Özgür,Tsachy Weissman*

Main category: cs.IT

TL;DR: 提出一种基于压缩的去噪方法，通过选择与信道条件分布匹配的失真度量，将压缩去噪框架扩展到一般离散无记忆信道，并给出精确的性能表征。


<details>
  <summary>Details</summary>
Motivation: 现有的压缩去噪方法仅限于加性噪声信道，需要扩展到更一般的离散无记忆信道，以处理更广泛的去噪场景。

Method: 通过精心选择与信道条件分布匹配的失真度量，使用有损压缩器对通过无记忆噪声信道观测到的源样本进行压缩重建，并通过边界分析经验联合分布与马尔可夫性质的偏差来表征性能。

Result: 给出了这种去噪器所达到损失的精确表征，并在MSE和汉明损失等特殊情况下进行了明确展示，同时与间接率失真视角进行了比较。

Conclusion: 成功将压缩去噪框架扩展到一般离散无记忆信道，通过匹配信道特性的失真度量选择，实现了对去噪性能的精确理论分析。

Abstract: We consider a denoiser that reconstructs a stationary ergodic source by lossily compressing samples of the source observed through a memoryless noisy channel. Prior work on compression-based denoising has been limited to additive noise channels. We extend this framework to general discrete memoryless channels by deliberately choosing the distortion measure for the lossy compressor to match the channel conditional distribution. By bounding the deviation of the empirical joint distribution of the source, observation, and denoiser outputs from satisfying a Markov property, we give an exact characterization of the loss achieved by such a denoiser. Consequences of these results are explicitly demonstrated in special cases, including for MSE and Hamming loss. A comparison is made to an indirect rate-distortion perspective on the problem.

</details>
