<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 4]
- [cs.MM](#cs.MM) [Total: 4]
- [cs.IT](#cs.IT) [Total: 15]
- [cs.GT](#cs.GT) [Total: 13]
- [cs.DS](#cs.DS) [Total: 9]
- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Memelang: An Axial Grammar for LLM-Generated Vector-Relational Queries](https://arxiv.org/abs/2512.17967)
*Bri Holt*

Main category: cs.DB

TL;DR: 论文提出轴向语法和Memelang，一种紧凑的DSL中间表示，用于LLM工具使用，通过坐标分配实现确定性解析，支持相对引用、变量绑定和上下文传递。


<details>
  <summary>Details</summary>
Motivation: LLM工具使用需要紧凑的DSL中间表示（IR），能够直接生成并确定性解析。现有方法通常依赖括号或复杂的表面语法，而本文旨在设计一种更简洁、可确定性解析的IR表示方法。

Method: 提出轴向语法：线性令牌序列通过特定秩的分隔符令牌恢复多维结构。单次左到右扫描为每个令牌分配n维网格坐标，实现无需括号的确定性解析。实例化为Memelang，一种紧凑查询语言，固定坐标角色直接映射到表/列/值槽位。

Result: 开发了参考词法分析器/解析器和编译器，可生成参数化PostgreSQL SQL（可选使用pgvector操作符）。Memelang支持坐标稳定相对引用、解析时变量绑定、隐式上下文传递，并通过内联标签支持分组、聚合和排序。

Conclusion: 轴向语法和Memelang为LLM工具使用提供了一种紧凑、可确定性解析的DSL中间表示，简化了查询生成，支持复杂操作，并可直接编译为SQL。

Abstract: Structured generation for LLM tool use highlights the value of compact DSL intermediate representations (IRs) that can be emitted directly and parsed deterministically. This paper introduces axial grammar: linear token sequences that recover multi-dimensional structure from the placement of rank-specific separator tokens. A single left-to-right pass assigns each token a coordinate in an n-dimensional grid, enabling deterministic parsing without parentheses or clause-heavy surface syntax. This grammar is instantiated in Memelang, a compact query language intended as an LLM-emittable IR whose fixed coordinate roles map directly to table/column/value slots. Memelang supports coordinate-stable relative references, parse-time variable binding, and implicit context carry-forward to reduce repetition in LLM-produced queries. It also encodes grouping, aggregation, and ordering via inline tags on value terms, allowing grouped execution plans to be derived in one streaming pass over the coordinate-indexed representation. Provided are a reference lexer/parser and a compiler that emits parameterized PostgreSQL SQL (optionally using pgvector operators).

</details>


### [2] [Sync Without Guesswork: Incomplete Time Series Alignment](https://arxiv.org/abs/2512.18238)
*Ding Jia,Jingyu Zhu,Yu Sun,Aoqian Zhang,Shaoxu Song,Haiwei Zhang,Xiaojie Yuan*

Main category: cs.DB

TL;DR: 提出基于约束的对齐框架处理不完整多元时间序列，避免插值并保证时空一致性，设计高效近似算法平衡精度与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 多元时间序列对齐对跨变量一致性分析至关重要，但缺失值和时间戳不一致使该任务极具挑战性。现有方法通常依赖先验插值，可能引入误差并导致次优对齐。

Method: 提出基于约束的对齐框架，避免插值并确保时间和结构一致性；设计三种高效近似算法平衡精度与效率。

Result: 在多个真实数据集上的实验表明，该方法在不同缺失率下相比现有方法获得更优的对齐质量，在对齐精度和对齐元组数量上均表现更好。

Conclusion: 该研究正式定义了不完整多元时序数据对齐问题，提出的约束对齐框架和近似算法能有效处理缺失数据，在真实场景中优于现有方法。

Abstract: Multivariate time series alignment is critical for ensuring coherent analysis across variables, but missing values and timestamp inconsistencies make this task highly challenging. Existing approaches often rely on prior imputation, which can introduce errors and lead to suboptimal alignments. To address these limitations, we propose a constraint-based alignment framework for incomplete multivariate time series that avoids imputation and ensures temporal and structural consistency. We further design efficient approximation algorithms to balance accuracy and scalability. Experiments on multiple real-world datasets demonstrate that our approach achieves superior alignment quality compared to existing methods under varying missing rates. Our contributions include: (1) formally defining incomplete multiple temporal data alignment problem; (2) proposing three approximation algorithms balancing accuracy and efficiency; and (3) validating our approach on diverse real-world datasets, where it consistently outperforms existing methods in alignment accuracy and the number of aligned tuples.

</details>


### [3] [Towards Scalable Visual Data Wrangling via Direct Manipulation](https://arxiv.org/abs/2512.18405)
*El Kindi Rezig,Mir Mahathir Mohammad,Nicolas Baret,Ricardo Mayerhofer,Andrew McNutt,Paul Rosen*

Main category: cs.DB

TL;DR: Buckaroo是一个可扩展的可视化数据整理系统，通过直接操作可视化图表来重构数据准备过程，支持用户自定义错误检测器和整理器，并生成可复现的脚本。


<details>
  <summary>Details</summary>
Motivation: 数据整理是数据科学工作流中的瓶颈，现有工具要么依赖容易出错且难以调试的手动脚本，要么通过不透明的黑盒管道自动化清理，提供有限的控制。

Method: 将数据准备重构为可视化图表的直接操作任务，通过协调的数据可视化探索和修复数据异常，支持用户定义的错误检测器和整理器，维护高效的索引数据结构和差异存储以最小化重新计算。

Result: Buckaroo与Hopara平移缩放引擎集成，支持大数据集的多层导航而不牺牲交互性，通过实证评估和专家评审证明系统使可视化数据整理具有可扩展性。

Conclusion: Buckaroo弥合了可视化检查和可编程修复之间的差距，使可视化数据整理变得可扩展，通过直接操作可视化图表来重构数据准备过程。

Abstract: Data wrangling - the process of cleaning, transforming, and preparing data for analysis - is a well-known bottleneck in data science workflows. Existing tools either rely on manual scripting, which is error-prone and hard to debug, or automate cleaning through opaque black-box pipelines that offer limited control. We present Buckaroo, a scalable visual data wrangling system that restructures data preparation as a direct manipulation task over visualizations. Buckaroo enables users to explore and repair data anomalies - such as missing values, outliers, and type mismatches - by interacting directly with coordinated data visualizations. The system extensibly supports user-defined error detectors and wranglers, tracks provenance for undo/redo, and generates reproducible scripts for downstream tasks. Buckaroo maintains efficient indexing data structures and differential storage to localize anomaly detection and minimize recomputation. To demonstrate the applicability of our model, Buckaroo is integrated with the \textit{Hopara} pan-and-zoom engine, which enables multi-layered navigation over large datasets without sacrificing interactivity. Through empirical evaluation and an expert review, we show that Buckaroo makes visual data wrangling scalable - bridging the gap between visual inspection and programmable repairs.

</details>


### [4] [A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback](https://arxiv.org/abs/2512.18622)
*Thanh Dat Hoang,Thanh Trung Huynh,Matthias Weidlich,Thanh Tam Nguyen,Tong Chen,Hongzhi Yin,Quoc Viet Hung Nguyen*

Main category: cs.DB

TL;DR: MATS是一个专为小型语言模型设计的Text2SQL框架，通过多智能体机制和强化学习训练，在单GPU服务器上实现与大型语言模型相当的准确率。


<details>
  <summary>Details</summary>
Motivation: 企业因隐私和成本考虑无法使用基于外部大型语言模型的Text2SQL服务，而开源的小型语言模型又缺乏大型模型的泛化能力，难以处理复杂的Text2SQL任务。

Method: 提出MATS框架，采用多智能体机制为辅助智能体分配专门角色，减轻个体工作负担并促进交互；基于强化学习的训练方案在执行过程中获取反馈来对齐智能体。

Result: 在基准数据集上的评估显示，MATS部署在单GPU服务器上，使用显著更少的参数，实现了与大型语言模型相当的准确率。

Conclusion: MATS框架通过多智能体机制和强化学习训练，使小型语言模型能够在资源受限的环境中实现与大型语言模型竞争的性能，为Text2SQL任务提供了实用的解决方案。

Abstract: Text2SQL, the task of generating SQL queries from natural language text, is a critical challenge in data engineering. Recently, Large Language Models (LLMs) have demonstrated superior performance for this task due to their advanced comprehension and generation capabilities. However, privacy and cost considerations prevent companies from using Text2SQL solutions based on external LLMs offered as a service. Rather, small LLMs (SLMs) that are openly available and can hosted in-house are adopted. These SLMs, in turn, lack the generalization capabilities of larger LLMs, which impairs their effectiveness for complex tasks such as Text2SQL. To address these limitations, we propose MATS, a novel Text2SQL framework designed specifically for SLMs. MATS uses a multi-agent mechanism that assigns specialized roles to auxiliary agents, reducing individual workloads and fostering interaction. A training scheme based on reinforcement learning aligns these agents using feedback obtained during execution, thereby maintaining competitive performance despite a limited LLM size. Evaluation results using on benchmark datasets show that MATS, deployed on a single- GPU server, yields accuracy that are on-par with large-scale LLMs when using significantly fewer parameters. Our source code and data are available at https://github.com/thanhdath/mats-sql.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [5] [Layout-Aware Text Editing for Efficient Transformation of Academic PDFs to Markdown](https://arxiv.org/abs/2512.18115)
*Changxu Duan*

Main category: cs.MM

TL;DR: EditTrans：一种混合编辑-生成模型，通过从PDF中识别待编辑文本队列来加速学术文档向标记语言的转换，相比端到端解码器Transformer模型减少44.5%的延迟。


<details>
  <summary>Details</summary>
Motivation: PDF格式的学术文档包含复杂元素（数学公式、图表、表格等），现有端到端解码器Transformer模型在将文档截图转换为标记语言时效率低下，需要从头开始逐token解码，浪费大量推理步骤重新生成可直接从PDF复制的密集文本。

Method: 提出EditTrans混合编辑-生成模型，包含一个轻量级分类器（基于文档布局分析模型在162,127页arXiv文档上微调），能够在开始生成标记语言前识别PDF中的待编辑文本队列。

Result: EditTrans相比端到端解码器Transformer模型将转换延迟降低高达44.5%，同时保持转换质量。代码和可复现数据集生产脚本已开源。

Conclusion: EditTrans通过结合编辑和生成的方法，有效解决了现有模型在PDF到标记语言转换中的效率问题，为数字图书馆工作流程提供了更高效的解决方案。

Abstract: Academic documents stored in PDF format can be transformed into plain text structured markup languages to enhance accessibility and enable scalable digital library workflows. Markup languages allow for easier updates and customization, making academic content more adaptable and accessible to diverse usage, such as linguistic corpus compilation. Such documents, typically delivered in PDF format, contain complex elements including mathematical formulas, figures, headers, and tables, as well as densely layouted text. Existing end-to-end decoder transformer models can transform screenshots of documents into markup language. However, these models exhibit significant inefficiencies; their token-by-token decoding from scratch wastes a lot of inference steps in regenerating dense text that could be directly copied from PDF files. To solve this problem, we introduce EditTrans, a hybrid editing-generation model whose features allow identifying a queue of to-be-edited text from a PDF before starting to generate markup language. EditTrans contains a lightweight classifier fine-tuned from a Document Layout Analysis model on 162,127 pages of documents from arXiv. In our evaluations, EditTrans reduced the transformation latency up to 44.5% compared to end-to-end decoder transformer models, while maintaining transformation quality. Our code and reproducible dataset production scripts are open-sourced.

</details>


### [6] [Accelerating End-to-End PDF to Markdown Conversion Through Assisted Generation](https://arxiv.org/abs/2512.18122)
*Changxu Duan*

Main category: cs.MM

TL;DR: 提出Copy Lookup Decoding (CLD)方法，通过直接从PDF提取候选序列来加速PDF到Markdown的转换，相比传统解码方法提速1.70倍


<details>
  <summary>Details</summary>
Motivation: 现有端到端解码器Transformer模型虽然能将PDF截图转为Markdown，但逐token解码效率低下，特别是当密集文本可以直接从PDF复制时

Method: 修改Prompt Lookup Decoding (PLD)方法，直接从PDF文件提取候选序列，利用PDF与Markdown之间的高n-gram重叠，提出新的Copy Lookup Decoding (CLD)方法增强候选生成机制

Result: 实验表明CLD能将转换过程加速高达1.70倍，同时保持原始质量

Conclusion: CLD方法通过直接从PDF提取候选序列，显著提高了PDF到Markdown的转换效率，代码已在GitHub开源

Abstract: Converting data from machine-unreadable formats like PDFs into Markdown has the potential to enhance the accessibility of scientific research. Existing end-to-end decoder transformer models can transform screenshots of PDFs into Markdown, offering more flexibility than pipeline-based methods. Yet, decoding text token by token from scratch is inefficient, especially when dense text can be directly copied from the PDF. To address this challenge, this paper modifies Prompt Lookup Decoding (PLD) to extract candidate sequences directly from PDF files, leveraging the high n-gram overlap between PDFs and their Markdown equivalents. A new method, Copy Lookup Decoding (CLD), is introduced here to enhance PLD's candidate generation mechanism. Experiments demonstrate that CLD can accelerate the conversion process by up to 1.70$\times$ at original quality. The codebase for this paper is open-source on GitHub (https://github.com/Fireblossom/CopyLookup).

</details>


### [7] [Asynchronous Pipeline Parallelism for Real-Time Multilingual Lip Synchronization in Video Communication Systems](https://arxiv.org/abs/2512.18318)
*Eren Caglar,Amirkia Rafiei Oskooei,Mehmet Kutanoglu,Mustafa Keles,Mehmet S. Aktas*

Main category: cs.MM

TL;DR: 提出并行异步Transformer框架，用于实时视频会议中的多语言唇语同步，通过流水线并行和消息队列解耦，降低延迟3.1倍，适用于资源受限的AIoT场景。


<details>
  <summary>Details</summary>
Motivation: 解决传统顺序处理在实时视频会议中多语言唇语同步的高延迟问题，需要开发低延迟、资源高效的多模态通信框架，适用于资源受限的IoT场景如远程医疗、多语言信息亭等。

Method: 采用并行异步Transformer架构，集成翻译、语音处理和唇语同步模块，通过流水线并行设计和基于消息队列的解耦实现并发执行。使用低层图编译、混合精度量化和硬件加速核融合优化推理流程，并加入上下文自适应静音检测组件。

Result: 相比传统顺序方法，端到端延迟降低达3.1倍，在处理速度、同步稳定性和资源利用率方面表现更优，同时保持模型准确性和视觉质量。

Conclusion: 该工作推进了低延迟、资源高效的多模态通信框架发展，适用于下一代AIoT系统，模块化消息导向设计使其在资源受限的IoT通信场景中具有广泛应用前景。

Abstract: This paper introduces a parallel and asynchronous Transformer framework designed for efficient and accurate multilingual lip synchronization in real-time video conferencing systems. The proposed architecture integrates translation, speech processing, and lip-synchronization modules within a pipeline-parallel design that enables concurrent module execution through message-queue-based decoupling, reducing end-to-end latency by up to 3.1 times compared to sequential approaches. To enhance computational efficiency and throughput, the inference workflow of each module is optimized through low-level graph compilation, mixed-precision quantization, and hardware-accelerated kernel fusion. These optimizations provide substantial gains in efficiency while preserving model accuracy and visual quality. In addition, a context-adaptive silence-detection component segments the input speech stream at semantically coherent boundaries, improving translation consistency and temporal alignment across languages. Experimental results demonstrate that the proposed parallel architecture outperforms conventional sequential pipelines in processing speed, synchronization stability, and resource utilization. The modular, message-oriented design makes this work applicable to resource-constrained IoT communication scenarios including telemedicine, multilingual kiosks, and remote assistance systems. Overall, this work advances the development of low-latency, resource-efficient multimodal communication frameworks for next-generation AIoT systems.

</details>


### [8] [D$^{2}$Stream: Decoupled Dual-Stream Temporal-Speaker Interaction for Audio-Visual Speaker Detection](https://arxiv.org/abs/2512.19130)
*Junhao Xiao,Shun Feng,Zhiyu Wu,Jianjun Li,Zhiyuan Ma,Yi Chen*

Main category: cs.MM

TL;DR: D²Stream：解耦双流框架，将跨帧时序建模与帧内说话人区分分离，在AVA-ActiveSpeaker上达到95.6% mAP新SOTA，计算量减少80%，参数减少30%


<details>
  <summary>Details</summary>
Motivation: 现有音视频说话人检测方法存在计算效率低或性能不佳的问题，主要原因是同时建模时序和说话人交互。需要一种更高效且性能更优的解决方案。

Method: 提出解耦双流框架：1）通过跨模态注意力对齐音视频特征；2）轻量级时序交互流捕获长程时序依赖；3）说话人交互流建模每帧内的人际关系；4）两个流通过交叉注意力交互；5）轻量级语音门控模块减少非语音面部运动的误报

Result: 在AVA-ActiveSpeaker数据集上达到95.6% mAP的新SOTA，相比基于GNN的模型计算量减少80%，相比基于注意力的替代方案参数减少30%，在Columbia ASD上也有良好泛化性能

Conclusion: D²Stream通过解耦时序建模和说话人区分，实现了高效且高性能的音视频说话人检测，为实际应用提供了有前景的解决方案

Abstract: Audio-visual speaker detection aims to identify the active speaker in videos by leveraging complementary audio and visual cues. Existing methods often suffer from computational inefficiency or suboptimal performance due to joint modeling of temporal and speaker interactions. We propose D$^{2}$Stream, a decoupled dual-stream framework that separates cross-frame temporal modeling from within-frame speaker discrimination. Audio and visual features are first aligned via cross-modal attention, then fed into two lightweight streams: a Temporal Interaction Stream captures long-range temporal dependencies, while a Speaker Interaction Stream models per-frame inter-person relationships. The temporal and relational features extracted by the two streams interact via cross-attention to enrich representations. A lightweight Voice Gate module further mitigates false positives from non-speech facial movements. On AVA-ActiveSpeaker, D$^{2}$Stream achieves a new state-of-the-art at 95.6% mAP, with 80% reduction in computation compared to GNN-based models and 30% fewer parameters than attention-based alternatives, while also generalizing well on Columbia ASD. Source code is available at https://anonymous.4open.science/r/D2STREAM.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [9] [Scalable Multiterminal Key Agreement via Error-Correcting Codes](https://arxiv.org/abs/2512.18025)
*Benjamin D. Kim,Daniel Alabi,Lav R. Varshney*

Main category: cs.IT

TL;DR: 该论文探索了秘密共享与密钥协商之间的联系，提出了一种基于纠错码的简单可扩展多终端密钥协商协议，并推导了相关容量界限。


<details>
  <summary>Details</summary>
Motivation: 探索秘密共享与密钥协商之间的理论联系，旨在设计一种简单且可扩展的多终端密钥协商协议，同时建立相关的理论界限。

Method: 使用纠错码（特别是具有阈值重构功能的Reed-Solomon码）构建协议，确保窃听者无法获取信息。利用密钥容量与多元互信息的对偶性推导理论界限。

Result: 提出了一个基于纠错码的多终端密钥协商协议，并推导了全秩最大距离可分码和该方案密钥容量的新界限。

Conclusion: 该研究建立了秘密共享与密钥协商之间的理论桥梁，提出的协议简单且可扩展，同时提供了相关的理论容量界限，为多终端安全通信提供了新方法。

Abstract: We explore connections between secret sharing and secret key agreement, which yield a simple and scalable multiterminal key agreement protocol. In our construction, we use error-correcting codes, specifically Reed-Solomon codes with threshold reconstruction, to ensure no information is leaked to an eavesdropper. We then derive novel bounds for both full-rank maximum distance separable codes and our scheme's secret key capacity, using key capacity's duality with multivariate mutual information.

</details>


### [10] [Implementing Transport Coding in OMNeT++ for Message Delay Reduction](https://arxiv.org/abs/2512.18332)
*Ilya Petrovanov,Anton Sergeev*

Main category: cs.IT

TL;DR: 传输编码通过引入受控冗余减少网络延迟：将k个原始包编码为n≥k个编码包，接收端收到任意k个包即可重构消息，将延迟从最大包延迟转移到第k个顺序统计量。


<details>
  <summary>Details</summary>
Motivation: 在分组交换网络中，传输编码通过引入受控冗余来减少消息延迟，将延迟从最大包延迟转移到第k个顺序统计量，这对于低延迟服务具有重要意义。

Method: 在OMNeT++中实现简洁可复现的离散事件传输编码模拟，包括多跳Kleinrock型网络、FIFO队列、指数服务延迟和链路延迟，以及显式的接收端重构机制。

Result: 模拟结果显示，在适度冗余下，平均延迟和延迟交付概率持续降低，同时保持饱和吞吐量接近未编码基线，为低延迟服务中的冗余调优提供了透明桥梁。

Conclusion: 传输编码在适度冗余下能有效降低延迟和延迟交付概率，同时保持吞吐量，提出的模型为分析传输编码公式与可执行模拟之间提供了透明桥梁，可用于低延迟服务的冗余调优。

Abstract: Transport coding reduces message delay in packet-switched networks by introducing controlled redundancy at the transport layer: $k$ original packets are encoded into $n\ge k$ coded packets, and the message is reconstructed after the first $k$ successful deliveries, effectively shifting latency from the maximum packet delay to the $k$-th order statistic. We present a concise, reproducible discrete-event implementation of transport coding in OMNeT++, including a multi-hop Kleinrock-type network, FIFO queues, exponential service and link delays, and explicit receiver-side reconstruction that records message delay and deadline violations. Using paired uncoded ($n{=}k$) and coded ($n{>}k$) configurations at the same message generation rate, we compare delay, reliability, and saturation effects across code rates and input loads. Simulation results show consistent reductions of average delay and late-delivery probability for moderate redundancy, while keeping the saturation throughput close to the uncoded baseline. The proposed model provides a transparent bridge between analytical transport-coding formulas and executable simulation for tuning redundancy in low-latency services.

</details>


### [11] [Downlink Power Allocation for STAR-RIS-Assisted Cell-Free Massive MIMO with Multi-antenna Users](https://arxiv.org/abs/2512.18359)
*Jun Qian,Ross Murch,Khaled B. Letaief*

Main category: cs.IT

TL;DR: 该论文研究了STAR-RIS辅助的无蜂窝大规模MIMO系统中多天线用户的下行功率分配问题，提出了基于ADMM的分数规划算法来最大化系统和速率，相比现有方法可获得超过20%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 在STAR-RIS辅助的无蜂窝大规模MIMO系统中，多天线用户的下行功率分配是一个关键问题。现有研究通常考虑单天线用户，而多天线用户能显著提升系统性能，但需要有效的功率分配算法来最大化系统和速率。

Method: 1) 推导了使用线性MMSE检测器的下行频谱效率闭式表达式；2) 将下行功率分配问题建模为和速率最大化问题；3) 提出了基于ADMM的分数规划算法来求解该优化问题。

Result: 1) 多天线用户显著提升频谱效率：天线数从1增加到6时，至少获得20%的SE提升；2) 提出的ADMM-FP算法优于现有分数功率控制方法，带来超过20%的SE提升；3) 验证了多天线用户和高效功率分配算法在STAR-RIS辅助无蜂窝大规模MIMO系统中的必要性。

Conclusion: 在STAR-RIS辅助的无蜂窝大规模MIMO系统中，采用多天线用户和基于ADMM的分数规划功率分配算法能显著提升系统性能，为未来无线通信系统设计提供了重要指导。

Abstract: This paper investigates the downlink power allocation of the simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS)-assisted cell-free massive multiple-input multiple-output (MIMO) system with multi-antenna users. We introduce downlink spectral efficiency (SE) and derive novel closed-form SE expressions using linear minimum mean squared error (MMSE) detectors. We also address the downlink power allocation via a sum SE maximization problem framed within an alternating direction method of multipliers (ADMM)-based fractional programming (FP) algorithm. Numerical results demonstrate that systems utilizing multi-antenna users significantly enhance SE, achieving at least a 20% SE increase as the number of antennas increases from one to six. Additionally, our proposed ADMM-based FP algorithm outperforms existing fractional power control approaches, yielding a more than 20% SE increase. These results highlight the necessity for adopting multi-antenna users and efficient power allocation algorithms in STAR-RIS-assisted cell-free massive MIMO systems.

</details>


### [12] [Age of Information with Age-Dependent Server Selection](https://arxiv.org/abs/2512.18457)
*Nail Akar,Ismail Cosandal,Sennur Ulukus*

Main category: cs.IT

TL;DR: 本文研究单源多服务器状态更新系统，提出基于AoI阈值的服务器选择策略，使用多体制吸收马尔可夫链框架精确分析AoI分布，优化传输成本约束下的AoI成本。


<details>
  <summary>Details</summary>
Motivation: 在多服务器状态更新系统中，不同服务器具有异构的服务时间和传输成本。现有研究缺乏基于年龄信息(AoI)的服务器选择策略分析，需要开发精确的分析框架来优化AoI成本并满足传输成本约束。

Method: 提出多体制吸收马尔可夫链(MR-AMC)框架，用于分析离散时间非抢占式状态更新系统。系统采用基于AoI阈值的服务器选择策略：当传输完成时，根据当前AoI值决定等待或选择特定服务器传输。服务器具有异构的离散相位型(DPH)服务时间和传输成本。

Result: 通过MR-AMC框架精确获得了AoI的分布，进而计算出AoI成本和传输成本。对于少量服务器的情况，可以通过穷举搜索获得最优阈值。数值验证了分析模型的有效性，并展示了基于AoI的服务器选择策略的优势。

Conclusion: 提出的MR-AMC框架为分析多服务器状态更新系统提供了有效的工具，能够精确分析AoI分布并优化服务器选择策略。基于AoI的阈值策略在优化AoI成本同时满足传输成本约束方面具有显著优势。

Abstract: In this paper, we consider a single-source multi-server generate-at-will discrete-time non-preemptive status update system where update packets are transmitted using {\em only one} of the available servers, according to a server selection policy. In particular, when a transmission is complete, the update system makes a threshold-based decision on whether to wait or transmit, and if latter, which server to use for transmissions, on the basis of the instantaneous value of the age of information (AoI) process. In our setting, servers have general heterogeneous discrete phase-type (DPH) distributed service times, and also heterogeneous transmission costs. The goal is to find an age-dependent multi-threshold policy that minimizes the AoI cost with a constraint on transmission costs, the former cost defined in terms of the time average of an arbitrary function of AoI. For this purpose, we propose a novel tool called \emph{multi-regime absorbing Markov chain} (MR-AMC) in discrete time. Using the MR-AMC framework, we exactly obtain the distribution of AoI, and subsequently the costs associated with AoI and transmissions. With the exact analysis in hand, optimum thresholds can be obtained in the case of a few servers, by exhaustive search. We validate the proposed analytical model, and also demonstrate the benefits of age-dependent server selection, with numerical examples.

</details>


### [13] [Protecting Human Activity Signatures in Compressed IEEE 802.11 CSI Feedback](https://arxiv.org/abs/2512.18529)
*Mohamed Seif,Atsutse Kludze,Yasaman Ghasempour,H. Vincent Poor,Doru Calin,Andrea J. Goldsmith*

Main category: cs.IT

TL;DR: 提出一种符合802.11标准的差分隐私量化机制，通过随机量化Givens参数保护CSI反馈中的用户隐私


<details>
  <summary>Details</summary>
Motivation: IEEE 802.11中的显式CSI反馈通过报告量化后的Givens旋转和相位角来传输波束成形方向，这些角度编码了传播环境的细粒度空间特征。已有研究表明，明文CSI反馈可能无意中向被动窃听者泄露用户活动、身份和位置信息。

Method: 引入一种符合标准的差分隐私量化机制，用ε-DP随机量化器替代确定性的角度量化，直接应用于传输波束成形矩阵的Givens参数。该机制保留了802.11反馈结构，为角度表示提供了闭式敏感度边界，并支持有原则的隐私校准。

Result: 数值模拟显示，该机制在提供强大隐私保证的同时，对波束成形性能的影响最小。

Conclusion: 提出的差分隐私量化机制能够在保护用户隐私的同时，保持与现有802.11标准的兼容性，实现隐私保护与波束成形性能的良好平衡。

Abstract: Explicit channel state information (CSI) feedback in IEEE~802.11 conveys \emph{transmit beamforming directions} by reporting quantized Givens rotation and phase angles that parametrize the right-singular subspace of the channel matrix. Because these angles encode fine-grained spatial signatures of the propagation environment, recent work have shown that plaintext CSI feedback can inadvertently reveal user activity, identity, and location to passive eavesdroppers. In this work, we introduce a standards-compatible \emph{differentially private (DP) quantization mechanism} that replaces deterministic angular quantization with an $\varepsilon$-DP stochastic quantizer applied directly to the Givens parameters of the transmit beamforming matrix. The mechanism preserves the 802.11 feedback structure, admits closed-form sensitivity bounds for the angular representation, and enables principled privacy calibration. Numerical simulations demonstrate strong privacy guarantees with minimal degradation in beamforming performance.

</details>


### [14] [Integrated Control and Communication in LQG Systems](https://arxiv.org/abs/2512.18535)
*Sepehr Jahangiri,H. Ali Talebi*

Main category: cs.IT

TL;DR: 研究MIMO向量状态LQG系统中通过控制信号传输信息的ICAC问题，给出了可计算的容量表达式，并证明可在保持最优控制成本的同时实现非零速率数据传输。


<details>
  <summary>Details</summary>
Motivation: 探索在控制约束下的MIMO向量状态LQG系统中，如何通过控制信号从控制器/编码器向观测器/解码器传输信息，实现通信与控制的一体化。

Method: 使用半定规划方法推导可计算的容量表达式，分析在保持最优控制成本的前提下通过控制信号传输信息的可行性。

Result: 获得了ICAC问题的可计算容量表达式，证明了在LQG系统中可以在不增加最优控制成本的情况下实现非零速率的数据传输。

Conclusion: 该框架将通信与控制相结合，可推广到带反馈的MIMO高斯信道通信（包括有/无符号间干扰的情况），为集成通信与控制提供了理论支持。

Abstract: In this paper, we study the Integrated Communication and Control (ICAC) problem. Specifically, we investigate how messages can be transmitted from the controller/encoder to the observer/decoder through the control signal in Multiple-Input Multiple-Output (MIMO) vector-state Linear Quadratic Gaussian (LQG) systems under control constraints. We provide a computable capacity expression using semidefinite programming. We further show that it is possible to transmit data at a nonzero rate over an LQG system while maintaining the same optimal control cost as in the case where no information message are transmitted. Finally, we discuss how this framework generalizes communication over MIMO Gaussian channels with feedback, both with and without InterSymbol Interference (ISI).

</details>


### [15] [Embracing Beam-Squint Effects for Wideband LEO Satellite Communications: A 3D Rainbow Beamforming Approach](https://arxiv.org/abs/2512.18600)
*Juha Park,Seokho Kim,Wonjae Shin,H. Vincent Poor*

Main category: cs.IT

TL;DR: 提出3D彩虹波束赋形技术，利用波束倾斜效应作为资产而非缺陷，通过联合相位时间阵列天线实现频率依赖波束指向，使LEO卫星能在单个时隙服务整个覆盖区域，显著提升上行吞吐量和降低延迟。


<details>
  <summary>Details</summary>
Motivation: 传统LEO卫星通信中，波束跳变技术受限于时域切换机制，每个时隙只能覆盖小部分服务区域，随着用户密度增加会加剧上行吞吐量瓶颈和延迟问题。同时，宽带系统中的波束倾斜效应通常被视为性能障碍。

Method: 提出3D彩虹波束赋形技术，采用联合相位时间阵列天线和真时延单元，有意扩大波束倾斜角度，使频率依赖波束指向分布式方向。通过新颖的联合交替和分解优化框架解决JPTA波束赋形器的非凸优化问题。

Result: 数值评估显示，在真实3D LEO卫星通信几何环境下，所提出的彩虹波束赋形技术相比传统波束跳变系统，可实现高达2.8倍的上行吞吐量提升。

Conclusion: 该研究将波束倾斜从性能障碍转变为资产，实现了LEO卫星在单个时隙内服务整个覆盖区域的能力，为6G宽带LEO卫星通信带来了重大突破。

Abstract: Low Earth Orbit (LEO) satellite communications (SATCOM) offers high-throughput, low-latency global connectivity to a very large number of users. To accommodate this demand with limited hardware resources, beam hopping (BH) has emerged as a prominent approach in LEO SATCOM. However, its time-domain switching mechanism confines coverage to a small fraction of the service area during each time slot, exacerbating uplink throughput bottlenecks and latency issues as the user density increases. Meanwhile, wideband systems experience the beam-squint effect, where analog beamforming (BF) directions vary with subcarrier frequencies, potentially causing misalignment at certain frequencies, thereby hindering the performance of wideband SATCOM. In this paper, we aim to shift the paradigm in wideband LEO SATCOM from beam-squint as an impairment to beam-squint as an asset. Specifically, we put forth 3D rainbow BF employing a joint phase-time array (JPTA) antenna with true time delay (TTD) to intentionally widen the beam-squint angle, steering frequency-dependent beams toward distributed directions. This novel approach enables the satellite to serve its entire coverage area in a single time slot. By doing so, the satellite simultaneously receives uplink signals from a massive number of users, significantly boosting throughput and reducing latency. To realize 3D rainbow BF, we formulate a JPTA beamformer optimization problem and address the non-convex nature of the optimization problem through a novel joint alternating and decomposition-based optimization framework. Through numerical evaluations incorporating realistic 3D LEO SATCOM geometry, our numerical results demonstrate that the proposed rainbow BF-empowered LEO SATCOM achieves up to 2.8-fold increase in uplink throughput compared to conventional BH systems. These results mark a significant breakthrough for 6G wideband LEO SATCOM.

</details>


### [16] [Real-Time Remote Monitoring of Correlated Markovian Sources](https://arxiv.org/abs/2512.18698)
*Mehrdad Salimnejad,Marios Kountouris,Nikolaos Pappas*

Main category: cs.IT

TL;DR: 提出一种基于错误感知的联合采样与传输策略，用于在共享无线信道上实时跟踪两个相关随机过程，通过概率采样减少重建错误并优化采样成本。


<details>
  <summary>Details</summary>
Motivation: 研究如何在共享无线信道上实时跟踪两个相关的随机过程，这些过程来自同一底层现象（如同一源的不同特征），每个监视器只关注其对应特征。现有方法在重建错误和采样成本之间存在权衡，需要设计更高效的策略。

Method: 提出错误感知的联合采样与传输策略：每个采样器仅在当前过程状态与其对应监视器最近重建状态不同时，以概率方式生成样本。将过程建模为二维离散时间马尔可夫链，采用时间平均重建错误作为性能指标，并建立优化问题以最小化重建错误并满足平均采样成本约束。

Result: 推导了所提策略和基准策略的时间平均重建错误的闭式表达式。分析表明，所提策略在考虑的所有方案中实现了最小的时间平均重建错误，同时有效利用了采样预算。在过程间相关性强、跟踪要求严格的场景下，性能提升尤为显著。

Conclusion: 错误感知的联合采样与传输策略能够有效平衡重建精度和采样成本，特别适用于相关过程的高精度跟踪场景。该策略通过智能采样决策，在有限资源下实现了最优的性能表现。

Abstract: We investigate real-time tracking of two correlated stochastic processes over a shared wireless channel. The joint evolution of the processes is modeled as a two-dimensional discrete-time Markov chain. Each process is observed by a dedicated sampler and independently reconstructed at a remote monitor according to a task-specific objective. Although both processes originate from a common underlying phenomenon (e.g., distinct features of the same source), each monitor is interested only in its corresponding feature. A reconstruction error is incurred when the true and reconstructed states mismatch at one or both monitors. To address this problem, we propose an error-aware joint sampling and transmission policy, under which each sampler probabilistically generates samples only when the current process state differs from the most recently reconstructed state at its corresponding monitor. We adopt the time-averaged reconstruction error as the primary performance metric and benchmark the proposed policy against state-of-the-art joint sampling and transmission schemes. For each policy, we derive closed-form expressions for the resulting time-averaged reconstruction error. We further formulate and solve an optimization problem that minimizes the time-averaged reconstruction error subject to an average sampling cost constraint. Analytical and numerical results demonstrate that the proposed error-aware policy achieves the minimum time-averaged reconstruction error among the considered schemes while efficiently utilizing the sampling budget. The performance gains are particularly pronounced in regimes with strong inter-process correlation and stringent tracking requirements, where frequent sampling by both samplers is necessary.

</details>


### [17] [A Quantitative Entropy Power Inequality for Dependent Random Vectors](https://arxiv.org/abs/2512.19002)
*Mokshay Madiman,James Melbourne,Cyril Roberto*

Main category: cs.IT

TL;DR: 本文提出了依赖随机向量的定量熵功率不等式，特别证明了对于联合密度为对数超模的随机向量，基于条件熵的熵功率不等式成立。


<details>
  <summary>Details</summary>
Motivation: 熵功率不等式是信息论的基础结果，与概率论和几何泛函分析有深刻联系。虽然已有针对依赖情况的扩展研究（如Takano、Johnson、Rioul的工作），但缺乏定量版本的依赖随机向量熵功率不等式。

Method: 扩展了Takano、Johnson和Rioul的工作，开发了依赖随机向量的定量熵功率不等式。特别关注联合密度为对数超模的随机向量。

Result: 建立了依赖随机向量的定量熵功率不等式，证明了对于联合密度为对数超模的随机向量，基于条件熵的熵功率不等式成立。

Conclusion: 本文成功扩展了熵功率不等式到依赖随机向量的定量版本，为对数超模联合密度的随机向量提供了基于条件熵的熵功率不等式，深化了对依赖情况下信息理论不等式的理解。

Abstract: The entropy power inequality for independent random vectors is a foundational result of information theory, with deep connections to probability and geometric functional analysis. Several extensions of the entropy power inequality have been developed for settings with dependence, including by Takano, Johnson, and Rioul. We extend these works by developing a quantitative version of the entropy power inequality for dependent random vectors. A notable consequence is that an entropy power inequality stated using conditional entropies holds for random vectors whose joint density is log-supermodular.

</details>


### [18] [On Cost-Aware Sequential Hypothesis Testing with Random Costs and Action Cancellation](https://arxiv.org/abs/2512.19067)
*George Vershinin,Asaf Cohen,Omer Gurewitz*

Main category: cs.IT

TL;DR: 研究带成本感知的顺序假设检验，决策者可通过设置每个动作的截止时间来中断高成本动作，分析两种成本揭示模型下的最优策略。


<details>
  <summary>Details</summary>
Motivation: 在顺序假设检验中，决策者需要以最小总成本识别真实假设，但动作成本是随机的。当某个动作成本过高时，决策者可能希望中断该动作以避免浪费资源。本文研究如何利用动作截止时间（deadline）这一中断选项来优化成本-误差权衡。

Method: 分析两种成本揭示模型：事后模型（成本在获得样本后揭示）和事前模型（成本在样本获取前累积）。研究每个动作的截止时间如何影响预期总成本，推导最优截止时间策略，并与基准情况（确定性成本或成本均值）进行比较。

Result: 在事后模型中，动作截止时间不影响预期总成本，成本-误差权衡与用成本均值替换确定性成本的基准情况一致。在事前模型中，截止时间会增加动作应用次数，但通过引入有效每动作成本，可将预期总成本降至恒定成本设置的水平。确定了截止时间有益的条件，并详细研究了几个具体模型族。

Conclusion: 动作截止时间在成本揭示时机不同的模型中具有不同效果：事后模型中无影响，事前模型中可通过优化截止时间策略降低总成本。研究结果为实际应用中如何设置中断机制以平衡成本与决策精度提供了理论指导。

Abstract: We study a variant of cost-aware sequential hypothesis testing in which a single active Decision Maker (DM) selects actions with positive, random costs to identify the true hypothesis under an average error constraint, while minimizing the expected total cost. The DM may abort an in-progress action, yielding no sample, by truncating its realized cost at a smaller, tunable deterministic limit, which we term a per-action deadline. We analyze how this cancellation option can be exploited under two cost-revelation models: ex-post, where the cost is revealed only after the sample is obtained, and ex-ante, where the cost accrues before sample acquisition.
  In the ex-post model, per-action deadlines do not affect the expected total cost, and the cost-error tradeoffs coincide with the baseline obtained by replacing deterministic costs with cost means. In the ex-ante model, we show how per-action deadlines inflate the expected number of times actions are applied, and that the resulting expected total cost can be reduced to the constant-cost setting by introducing an effective per-action cost. We characterize when deadlines are beneficial and study several families in detail.

</details>


### [19] [Low-Latency and Low-Complexity MLSE for Short-Reach Optical Interconnects](https://arxiv.org/abs/2512.19094)
*Mengqi Guo,Ji Zhou,Haide Wang,Changyuan Yu,Xiangjun Xin,Liangchuan Li*

Main category: cs.IT

TL;DR: 提出简化的分层两步最大似然序列估计(L2S-MLSE)算法，通过计算简化和状态减少，显著降低光学互连系统的延迟和复杂度，同时保持误码率性能。


<details>
  <summary>Details</summary>
Motivation: 为了满足光学互连对高速、低延迟和低复杂度的需求，需要开发简化的信号处理算法来降低传统MLSE方法的计算复杂度和延迟。

Method: 提出简化的L2S-MLSE方法，结合计算简化和状态减少技术。采用并行滑动块架构将延迟从线性阶降低到对数阶，计算简化将乘法器数量从指数阶减少到线性阶，结合状态减少进一步降低加法器和比较器数量。

Result: 在112-Gbit/s PAM4传输2公里单模光纤实验中，简化L2S-MLSE显著优于仅使用FFE的情况。相比简化1步MLSE，延迟从34个延迟单元(线性阶)降至7个延迟单元(对数阶)。乘法器从512个(指数阶)减少到33个(线性阶)，加法器和比较器分别减少到37.2%和8.4%，同时保持几乎相同的误码率性能。

Conclusion: 简化的L2S-MLSE方法通过显著降低计算复杂度和延迟，同时保持误码率性能，为高速光学互连系统提供了有效的解决方案。

Abstract: To meet the high-speed, low-latency, and low-complexity demand for optical interconnects, simplified layered 2-step maximum likelihood sequence estimation (L2S-MLSE) is proposed in this paper. Simplified L2S-MLSE combines computational simplification and reduced state in L2S-MLSE. L2S-MLSE with a parallel sliding block architecture reduces latency from linear order to logarithmic order. Computational simplification reduces the number of multipliers from exponential order to linear order. Incorporating the reduced state with computational simplification further decreases the number of adders and comparators. The simplified L2S-MLSE is evaluated in a 112-Gbit/s PAM4 transmission over 2-km standard single-mode fiber. Experimental results show that the simplified L2S-MLSE significantly outperforms the FFE-only case in bit error ratio (BER) performance. Compared with simplified 1-step MLSE, the latency of simplified L2S-MLSE is reduced from 34 delay units in linear order to 7 delay units in logarithmic order. The simplified scheme in L2S-MLSE reduces the number of variable multipliers from 512 in exponential order to 33 in linear order without BER performance deterioration, while reducing the number of adders and comparators to 37.2% and 8.4%, respectively, with nearly identical BER performance.

</details>


### [20] [On the construction of Cauchy MDS matrices over Galois rings via nilpotent elements and Frobenius maps](https://arxiv.org/abs/2512.19306)
*Shakir Ali,Atif Ahmad Khan,Abhishek Kesarwani*

Main category: cs.IT

TL;DR: 在伽罗瓦环上构造柯西MDS矩阵，利用幂零元和Teichmüller集减少矩阵元素数量，通过Frobenius自同构生成大量保持MDS性质的函数。


<details>
  <summary>Details</summary>
Motivation: 研究伽罗瓦环上MDS矩阵的构造问题，特别是柯西MDS矩阵的构建方法，旨在减少矩阵元素数量并生成更多具有MDS性质的矩阵。

Method: 利用伽罗瓦环的幂零元素和Teichmüller集来简化柯西MDS矩阵构造；通过Frobenius自同构生成大量保持MDS性质的函数；运用伽罗瓦环的自同构和同构理论生成新的柯西MDS矩阵。

Result: 成功构造了p^{(s-1)m}(p^m-1)个不同的函数，这些函数能够保持矩阵的MDS性质；证明了利用伽罗瓦环的自同构和同构可以生成新的柯西MDS矩阵。

Conclusion: 提出了一种在伽罗瓦环上构造柯西MDS矩阵的新方法，通过利用幂零元素、Teichmüller集和Frobenius自同构，不仅减少了矩阵元素数量，还能生成大量保持MDS性质的函数和矩阵。

Abstract: Let $s,m$ be the positive integers and $p$ be any prime number. Next, let $GR(p^s,p^{sm})$ be a Galois ring of characteristic $p^s$ and cardinality $p^{sm}$. In the present paper, we explore the construction of Cauchy MDS matrices over Galois rings. Moreover, we introduce a new approach that considers nilpotent elements and Teichmüller set of Galois ring $GR(p^s,p^{sm})$ to reduce the number of entries in these matrices. Furthermore, we construct $p^{(s-1)m}(p^m-1)$ distinct functions with the help of Frobenius automorphisms. These functions preserve MDS property of matrices. Finally, we prove some results using automorphisms and isomorphisms of the Galois rings that can be used to generate new Cauchy MDS matrices.

</details>


### [21] [Orthogonal Approximate Message Passing with Optimal Spectral Initializations for Rectangular Spiked Matrix Models](https://arxiv.org/abs/2512.19334)
*Haohua Chen,Songbin Liu,Junjie Ma*

Main category: cs.IT

TL;DR: 提出用于矩形尖峰矩阵模型的OAMP算法，建立精确的状态演化分析，构造迭代最优去噪器，性能与贝叶斯最优估计器一致。


<details>
  <summary>Details</summary>
Motivation: 解决矩形尖峰矩阵模型中信号估计问题，特别是在一般旋转不变噪声下的算法设计和性能分析挑战。

Method: 提出正交近似消息传递(OAMP)算法，建立严格的状态演化分析框架，构造迭代最优去噪器，处理多个信息异常值组合。

Result: 算法性能与贝叶斯最优估计器的副本对称预测一致，在广泛迭代估计方法中具有统计最优性。

Conclusion: 提出的最优OAMP算法在一般旋转不变噪声下具有统计最优性，为矩形尖峰矩阵模型提供了有效的信号估计框架。

Abstract: We propose an orthogonal approximate message passing (OAMP) algorithm for signal estimation in the rectangular spiked matrix model with general rotationally invariant (RI) noise. We establish a rigorous state evolution that precisely characterizes the algorithm's high-dimensional dynamics and enables the construction of iteration-wise optimal denoisers. Within this framework, we accommodate spectral initializations under minimal assumptions on the empirical noise spectrum. In the rectangular setting, where a single rank-one component typically generates multiple informative outliers, we further propose a procedure for combining these outliers under mild non-Gaussian signal assumptions. For general RI noise models, the predicted performance of the proposed optimal OAMP algorithm agrees with replica-symmetric predictions for the associated Bayes-optimal estimator, and we conjecture that it is statistically optimal within a broad class of iterative estimation methods.

</details>


### [22] [Enhancing PLS of Indoor IRS-VLC Systems for Colluding and Non-Colluding Eavesdroppers](https://arxiv.org/abs/2512.19339)
*Rashid Iqbal,Ahmed Zoha,Salama Ikki,Muhammad Ali Imran,Hanaa Abumarshoud*

Main category: cs.IT

TL;DR: 该论文提出使用智能反射表面(IRS)的时间延迟特性来增强室内可见光通信(VLC)的物理层安全，通过深度强化学习优化IRS元素分配，显著提升保密容量。


<details>
  <summary>Details</summary>
Motivation: 现有IRS辅助室内VLC研究大多忽略反射路径引入的时间延迟，而这些延迟在实际宽带系统中是固有的。本文采用更现实的假设，利用IRS诱导的时间延迟来增强物理层安全。

Method: 考虑室内VLC系统，使用IRS塑造信道，使反射信号在合法用户处建设性叠加，同时在窃听者处产生码间干扰。将保密容量最大化问题建模为复杂组合优化问题，采用近端策略优化(PPO)的深度强化学习方法求解。

Result: 在窃听者信道强于合法用户的最坏情况下，相比将所有IRS元素分配给合法用户，提出的PPO-based IRS分配在共谋和非共谋情况下分别提升保密容量107%和235%。

Conclusion: 基于时间延迟的IRS控制能在实际室内VLC场景中提供强大的保密优势，证明了考虑时间延迟的实际假设对物理层安全增强的重要性。

Abstract: Most intelligent reflecting surface (IRS)-aided indoor visible light communication (VLC) studies ignore the time delays introduced by reflected paths, even though these delays are inherent in practical wideband systems. In this work, we adopt a realistic assumption of IRS-induced time delay for physical layer security (PLS) enhancement. We consider an indoor VLC system where an IRS is used to shape the channel so that the reflected signals add constructively at the legitimate user and create intersymbol interference at eavesdroppers located inside the coverage area. The resulting secrecy capacity maximisation over the IRS element allocation is formulated as a complex combinatorial optimisation problem and is solved using deep reinforcement learning with proximal policy optimisation (PPO). The approach is evaluated for both colluding eavesdroppers, which combine their received signals, and non-colluding eavesdroppers, which act independently. Simulation results are shown for various simulation setups, which demonstrate significant secrecy capacity gains. In a worst-case scenario, where the eavesdroppers have stronger channels than the legitimate user, the proposed PPO-based IRS allocation improves secrecy capacity by 107\% and 235\% in the colluding and non-colluding cases, respectively, compared with allocating all IRS elements to the legitimate user. These results demonstrate that time-delay-based IRS control can provide a strong secrecy advantage in practical indoor VLC scenarios.

</details>


### [23] [Fully Asynchronous Unsourced Random Access over Fading Channels](https://arxiv.org/abs/2512.19468)
*Mert Ozates,Mohammad Kazemi,Gianluigi Liva,Deniz Gündüz*

Main category: cs.IT

TL;DR: 提出一种适用于完全异步场景的无源随机接入方案，采用导频序列+极化码结构，通过双滑动窗口解码器实现联合定时检测、信道估计和干扰消除，性能接近同步基准。


<details>
  <summary>Details</summary>
Motivation: 研究完全异步场景下的无源随机接入问题，其中活跃用户可以在任意时间开始传输，这在实际应用中比严格同步更实用，但技术挑战更大。

Method: 方案包含导频序列和极化码，极化码以开关模式分布在数据包中。接收端采用双滑动窗口解码器：内窗口进行迭代解码，联合执行定时检测、导频检测、信道估计、单用户解码和连续干扰消除；外窗口增强干扰消除效果。

Result: 数值结果表明，所提方案相比同步基准仅有轻微性能损失，同时在实践中更具适用性。

Conclusion: 该方案成功解决了完全异步无源随机接入的挑战，在保持接近同步性能的同时提高了实际部署的可行性。

Abstract: We examine unsourced random access in a fully asynchronous setup, where active users transmit their data without restriction on the start time over a fading channel. In the proposed scheme, the transmitted signal consists of a pilot sequence and a polar codeword, with the polar codeword distributed across the data part of the packet in an on-off pattern. The receiver uses a double sliding-window decoder, where the inner window employs iterative decoding with joint timing and pilot detection, channel estimation, single-user decoding, and successive interference cancellation to recover the message bits, while the outer window enhances interference cancellation. The numerical results indicate that the proposed scheme exhibits only a slight performance loss compared to the synchronous benchmark while being more applicable in practice.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [24] [Which Coauthor Should I Nominate in My 99 ICLR Submissions? A Mathematical Analysis of the ICLR 2026 Reciprocal Reviewer Nomination Policy](https://arxiv.org/abs/2512.17950)
*Zhao Song,Song Yue,Jiahao Zhang*

Main category: cs.GT

TL;DR: 研究作者提名审稿人政策，通过优化算法最小化论文被拒风险，提出基于贪心、最小成本流和线性规划的提名策略。


<details>
  <summary>Details</summary>
Motivation: AI会议投稿量激增导致审稿负担过重，ICLR 2026等会议引入作者提名审稿人政策，但提名不负责任的审稿人会导致论文被拒。需要研究如何优化提名策略来最小化作者被拒风险。

Method: 形式化三种桌面拒稿风险最小化问题：基础问题（最小化期望拒稿数）、硬提名限制和软提名限制变体。使用贪心算法解决基础问题，通过最小成本流和线性规划解决限制变体。

Result: 基础问题可通过简单贪心算法最优解决；限制变体可转化为经典优化框架问题，设计出高效、有原则的提名策略。

Conclusion: 首次从理论上研究审稿人提名政策，为作者提供了选择提名合作作者的策略指导，既有概念性见解也有实际应用方向。

Abstract: The rapid growth of AI conference submissions has created an overwhelming reviewing burden. To alleviate this, recent venues such as ICLR 2026 introduced a reviewer nomination policy: each submission must nominate one of its authors as a reviewer, and any paper nominating an irresponsible reviewer is desk-rejected. We study this new policy from the perspective of author welfare. Assuming each author carries a probability of being irresponsible, we ask: how can authors (or automated systems) nominate reviewers to minimize the risk of desk rejections? We formalize and analyze three variants of the desk-rejection risk minimization problem. The basic problem, which minimizes expected desk rejections, is solved optimally by a simple greedy algorithm. We then introduce hard and soft nomination limit variants that constrain how many papers may nominate the same author, preventing widespread failures if one author is irresponsible. These formulations connect to classical optimization frameworks, including minimum-cost flow and linear programming, allowing us to design efficient, principled nomination strategies. Our results provide the first theoretical study for reviewer nomination policies, offering both conceptual insights and practical directions for authors to wisely choose which co-author should serve as the nominated reciprocal reviewer.

</details>


### [25] [Will AI Trade? A Computational Inversion of the No-Trade Theorem](https://arxiv.org/abs/2512.17952)
*Hanyu Li,Xiaotie Deng*

Main category: cs.GT

TL;DR: AI代理的计算限制可能导致交易，即使信念相同，这与传统无交易定理相反


<details>
  <summary>Details</summary>
Motivation: 传统无交易定理将交易归因于异质信念，本研究重新审视AI代理是否可能因计算限制而产生交易

Method: 在展开博弈框架中建模代理的有界计算理性，计算能力决定策略复杂度

Result: 稳定无交易结果（纳什均衡）仅在"几乎理性"代理的计算能力略有差异时达成；计算能力相同时可能无法收敛到均衡，导致持续的策略调整（交易）；若代理能策略性地利用计算资源，在匹配硬币场景中完全消除均衡可能

Conclusion: AI代理固有的计算限制可能导致无法达到均衡，创造比传统模型预测的更活跃、不可预测的交易环境

Abstract: Classic no-trade theorems attribute trade to heterogeneous beliefs. We re-examine this conclusion for AI agents, asking if trade can arise from computational limitations, under common beliefs. We model agents' bounded computational rationality within an unfolding game framework, where computational power determines the complexity of its strategy. Our central finding inverts the classic paradigm: a stable no-trade outcome (Nash equilibrium) is reached only when "almost rational" agents have slightly different computational power. Paradoxically, when agents possess identical power, they may fail to converge to equilibrium, resulting in persistent strategic adjustments that constitute a form of trade. This instability is exacerbated if agents can strategically under-utilize their computational resources, which eliminates any chance of equilibrium in Matching Pennies scenarios. Our results suggest that the inherent computational limitations of AI agents can lead to situations where equilibrium is not reached, creating a more lively and unpredictable trade environment than traditional models would predict.

</details>


### [26] [Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis](https://arxiv.org/abs/2512.17979)
*Matthieu Mastio,Paul Saves,Benoit Gaudou,Nicolas Verstaevel*

Main category: cs.GT

TL;DR: 开发基于智能体的空间双拍卖市场模型，研究工业共生系统中企业如何通过强化学习自适应交易策略，在考虑运输成本、处置惩罚和资源稀缺条件下实现去中心化协调。


<details>
  <summary>Details</summary>
Motivation: 工业共生促进循环经济，但受到社会空间摩擦的限制。现有模型往往忽视空间结构、市场设计和自适应企业行为之间的相互作用，限制了我们对共生系统形成机制的理解。

Method: 开发基于智能体的模型，异质企业通过空间嵌入的双拍卖市场交易副产品。企业使用强化学习自适应调整投标策略以最大化利润，考虑运输成本、处置惩罚和资源稀缺。通过模拟实验、反事实遗憾分析和敏感性分析进行研究。

Result: 模拟实验揭示了去中心化交换收敛到稳定高效结果的经济和空间条件。反事实遗憾分析显示卖方策略接近纳什均衡，敏感性分析表明空间结构和市场参数共同影响循环性。

Conclusion: 该模型为探索政策干预提供了基础，展示了在空间约束市场中自适应智能体如何实现去中心化协调，有助于将企业激励与可持续发展目标对齐。

Abstract: Industrial symbiosis fosters circularity by enabling firms to repurpose residual resources, yet its emergence is constrained by socio-spatial frictions that shape costs, matching opportunities, and market efficiency. Existing models often overlook the interaction between spatial structure, market design, and adaptive firm behavior, limiting our understanding of where and how symbiosis arises. We develop an agent-based model where heterogeneous firms trade byproducts through a spatially embedded double-auction market, with prices and quantities emerging endogenously from local interactions. Leveraging reinforcement learning, firms adapt their bidding strategies to maximize profit while accounting for transport costs, disposal penalties, and resource scarcity. Simulation experiments reveal the economic and spatial conditions under which decentralized exchanges converge toward stable and efficient outcomes. Counterfactual regret analysis shows that sellers' strategies approach a near Nash equilibrium, while sensitivity analysis highlights how spatial structures and market parameters jointly govern circularity. Our model provides a basis for exploring policy interventions that seek to align firm incentives with sustainability goals, and more broadly demonstrates how decentralized coordination can emerge from adaptive agents in spatially constrained markets.

</details>


### [27] [Privacy Data Pricing: A Stackelberg Game Approach](https://arxiv.org/abs/2512.18296)
*Lijun Bo,Weiqiang Chang*

Main category: cs.GT

TL;DR: 该论文提出了一个Stackelberg博弈框架，用于在差分隐私约束下定价数据，平衡隐私保护与数据效用，为数据市场提供激励兼容的隐私感知定价机制。


<details>
  <summary>Details</summary>
Motivation: 传统数据定价模型主要关注价格一致性和利润最大化，但忽视了隐私约束和战略互动。随着差分隐私的广泛采用，需要在隐私保护（噪声添加）与数据准确性（市场价值）之间进行权衡，这需要新的定价框架。

Method: 采用Stackelberg博弈框架，市场制定者（领导者）设定价格函数，数据购买者（跟随者）在差分隐私约束下选择最优查询精度。分析了平衡定价函数（定价决策变量线性进入原始定价模型）下的均衡策略，并扩展到非线性幂定价函数。

Result: 推导出双方均衡策略的闭式解，包括最优方差和定价水平，确定了市场参与的边界条件。为线性平衡定价函数和扩展的非线性定价函数都提供了解决方案。

Conclusion: 该模型将差分隐私与经济机制设计相结合，为数据市场提供了激励兼容且隐私感知的统一定价基础，解决了隐私保护与数据效用之间的权衡问题。

Abstract: Data markets are emerging as key mechanisms for trading personal and organizational data. Traditional data pricing studies -- such as query-based or arbitrage-free pricing models -- mainly emphasize price consistency and profit maximization but often neglect privacy constraints and strategic interactions. The widespread adoption of differential privacy (DP) introduces a fundamental privacy-utility trade-off: noise protects individuals' privacy but reduces data accuracy and market value. This paper develops a Stackelberg game framework for pricing DP data, where the market maker (leader) sets the price function and the data buyer (follower) selects the optimal query precision under DP constraints. We derive the equilibrium strategies for both parties under a balanced pricing function where the pricing decision variable enters linearly into the original pricing model. We obtain closed-form solutions for the optimal variance and pricing level, and determine the boundary conditions for market participation. Furthermore, we extend the analysis to Stackelberg games involving nonlinear power pricing functions. The model bridges DP and economic mechanism design, offering a unified foundation for incentive-compatible and privacy-conscious data pricing in data markets.

</details>


### [28] [Snowveil: A Framework for Decentralised Preference Discovery](https://arxiv.org/abs/2512.18444)
*Grammateia Kotsialou*

Main category: cs.GT

TL;DR: 提出Snowveil框架解决去中心化偏好发现问题，使用基于八卦的迭代协议，通过随机抽样选民偏好逐步收敛到集体结果，证明系统几乎必然在有限时间内收敛到稳定获胜者。


<details>
  <summary>Details</summary>
Motivation: 传统基于中心权威的大规模群体主观偏好聚合存在局限性，需要解决审查抵抗、部分信息和异步通信约束下的集体意志确定问题。

Method: 提出Snowveil框架，使用迭代的基于八卦的协议，选民重复抽样随机子集的偏好；设计约束混合波达计数(CHB)聚合规则；应用势函数和亚鞅理论进行多级分析。

Result: 系统几乎必然在有限时间内收敛到稳定单获胜者，可迭代构建多获胜者场景；Snowveil具有O(n)可扩展性；CHB规则在广泛共识和强多数支持间取得平衡。

Conclusion: 该工作推进了对去中心化系统中如何从主观、复杂和多样化的偏好中涌现稳定共识的理解，为更广泛的DPD协议提供了形式化工具包。

Abstract: Aggregating subjective preferences of a large group is a fundamental challenge in computational social choice, traditionally reliant on central authorities. To address the limitations of this model, this paper introduces Decentralised Preference Discovery (DPD), the problem of determining the collective will of an electorate under constraints of censorship resistance, partial information, and asynchronous communication. We propose Snowveil, a novel framework for this task. Snowveil uses an iterative, gossip-based protocol where voters repeatedly sample the preferences of a small, random subset of the electorate to progressively converge on a collective outcome. We demonstrate the framework's modularity by designing the Constrained Hybrid Borda (CHB), a novel aggregation rule engineered to balance broad consensus with strong plurality support, and provide a rigorous axiomatic analysis of its properties. By applying a potential function and submartingale theory, we develop a multi-level analytical method to show that the system almost surely converges to a stable, single-winner in finite time, a process that can then be iterated to construct a set of winning candidates for multi-winner scenarios. This technique is largely agnostic to the specific aggregation rule, requiring only that it satisfies core social choice axioms like Positive Responsiveness, thus offering a formal toolkit for a wider class of DPD protocols. Furthermore, we present a comprehensive empirical analysis through extensive simulation, validating Snowveil's $O(n)$ scalability. Overall, this work advances the understanding of how a stable consensus can emerge from subjective, complex, and diverse preferences in decentralised systems for large electorates.

</details>


### [29] [Obnoxious Facility Location Problems: Strategyproof Mechanisms Optimizing $L_p$-Aggregated Utilities and Costs](https://arxiv.org/abs/2512.18620)
*Hau Chan,Jianan Lin,Chenhao Wang*

Main category: cs.GT

TL;DR: 研究在归一化线段[0,1]上定位单个厌恶设施的策略机制设计问题，考虑战略性代理的偏好，目标是设计(群体)策略证明机制来近似优化Lp聚合效用和成本目标。


<details>
  <summary>Details</summary>
Motivation: 在厌恶设施选址问题中，代理希望设施远离自己的位置，但可能策略性地报告位置以获得更好结果。需要设计机制确保真实报告，同时优化整体效用或成本。

Method: 采用机制设计方法，考虑确定性随机(群体)策略证明机制，分析Lp聚合效用最大化成本最小化问题，建立不同p值范围内的近似比上下界。

Result: 建立了确定性随机机制在Lp聚合目标下的近似比上下界，确定性机制的上下界是紧的，随机机制存在间隙。

Conclusion: 为厌恶设施选址问题提供了完整的机制设计分析框架，确定了不同机制类型在Lp聚合目标下的最优近似性能，为实际应用提供了理论指导。

Abstract: We study the problem of locating a single obnoxious facility on the normalized line segment $[0,1]$ with strategic agents from a mechanism design perspective. Each agent has a preference for the undesirable location of the facility and would prefer the facility to be far away from their location. We consider the utility of the agent, defined as the distance between the agent's location and the facility location, and the cost of each agent, equal to one minus the utility. Given this standard setting of obnoxious facility location problems, our goal is to design (group) strategyproof mechanisms to elicit agent locations truthfully and determine facility location approximately optimizing the $L_p$-aggregated utility and cost objectives, which generalizes the $L_p$-norm ($p\ge 1$) of the agents' utilities and agents' costs to any $p \in [-\infty, \infty]$, respectively. We establish upper and lower bounds on the approximation ratios of deterministic and randomized (group) strategyproof mechanisms for maximizing the $L_p$-aggregated utilities or minimizing the $L_p$-aggregated costs across the range of \(p\)-values. While there are gaps between upper and lower bounds for randomized mechanisms, our bounds for deterministic mechanisms are tight.

</details>


### [30] [Adapting Skill Ratings to Luck-Based Hidden-Information Games](https://arxiv.org/abs/2512.18858)
*Avirup Chakraborty,Shirsa Maitra,Tathagata Banerjee,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.GT

TL;DR: 本文针对传统Elo评分系统在随机性游戏中的局限性，提出了一种专门为Rummy设计的改进Elo框架，通过纳入得分指标和初始手牌质量建模来区分技能与运气。


<details>
  <summary>Details</summary>
Motivation: 传统Elo评分系统仅考虑游戏结果并假设玩家初始状态一致，这在部分随机、信息不完全的游戏（如Rummy）中存在方法学挑战。需要开发能够区分技能与运气的评分系统。

Method: 提出改进的Elo框架：1) 纳入基于得分的性能指标；2) 明确建模初始手牌质量的影响；3) 通过27万场游戏模拟，涉及六种不同复杂度的策略。

Result: 改进系统相比传统Elo实现了：1) 稳定收敛；2) 更强的区分能力；3) 更高的预测准确性；同时保持计算简单性。

Conclusion: 该框架有效捕捉了技能、策略和随机性的相互作用，适用于Rummy及其他随机竞争环境，为随机性游戏中的技能评估提供了实用解决方案。

Abstract: Rating systems play a crucial role in evaluating player skill across competitive environments. The Elo rating system, originally designed for deterministic and information-complete games such as chess, has been widely adopted and modified in various domains. However, the traditional Elo rating system only considers game outcomes for rating calculation and assumes uniform initial states across players. This raises important methodological challenges in skill modelling for popular partially randomized incomplete-information games such as Rummy. In this paper, we examine the limitations of conventional Elo ratings when applied to luck-driven environments and propose a modified Elo framework specifically tailored for Rummy. Our approach incorporates score-based performance metrics and explicitly models the influence of initial hand quality to disentangle skill from luck. Through extensive simulations involving 270,000 games across six strategies of varying sophistication, we demonstrate that our proposed system achieves stable convergence, superior discriminative power, and enhanced predictive accuracy compared to traditional Elo formulations. The framework maintains computational simplicity while effectively capturing the interplay of skill, strategy, and randomness, with broad applicability to other stochastic competitive environments.

</details>


### [31] [Considering the Difference in Utility Functions of Team Players in Adversarial Team Games](https://arxiv.org/abs/2512.18989)
*Youzhi Zhang*

Main category: cs.GT

TL;DR: 本文提出了一种新的对抗性团队博弈解决方案概念——合作竞争均衡（CoE），用于解决传统方法忽略团队成员效用函数差异的问题，确保计算出的均衡具有稳定性。


<details>
  <summary>Details</summary>
Motivation: 联合国2030年可持续发展议程要求各国合作对抗不利因素，这可以建模为AI中的对抗性团队博弈。然而，现有解决方案假设团队成员具有相同的效用函数，无法覆盖现实世界中各国效用函数不同的情况。忽略这种差异会导致计算出的均衡不稳定。

Method: 引入合作竞争均衡（CoE）作为对抗性团队博弈的新解决方案概念，其中具有不同效用函数的团队成员（合作）协调行动对抗对手（竞争）。进一步提出团队最大化CoE，即在所有CoE中最大化团队效用的均衡。

Result: CoE和团队最大化CoE都能克服忽略团队成员效用函数差异所引发的问题。论文展示了考虑这种差异带来的理论和算法贡献机会。

Conclusion: 研究对抗性团队博弈不应忽视团队成员效用函数的差异。提出的CoE概念为解决这一问题提供了新框架，为理论和算法研究开辟了新方向。

Abstract: The United Nations' 2030 Agenda for Sustainable Development requires that all countries collaborate to fight adversarial factors to achieve peace and prosperity for humans and the planet. This scenario can be formulated as an adversarial team game in AI literature, where a team of players play against an adversary. However, previous solution concepts for this game assume that team players have the same utility functions, which cannot cover the real-world case that countries do not always have the same utility function. This paper argues that studying adversarial team games should not ignore the difference in utility functions of team players. We show that ignoring the difference in utility functions of team players could cause the computed equilibrium to be unstable. To show the benefit of considering the difference in utility functions of team players, we introduce a novel solution concept called Co-opetition Equilibrium (CoE) for the adversarial team game. In this game, team players with different utility functions (i.e., cooperation between team players) correlate their actions to play against the adversary (i.e., competition between the team and the adversary). We further introduce the team-maximizing CoE, which is a CoE but maximizes the team's utility among all CoEs. Both equilibria can overcome the issue caused by ignoring the difference in utility functions of team players. We further show the opportunities for theoretical and algorithmic contributions based on our position of considering the difference in utility functions of team players.

</details>


### [32] [A Unified Framework and Comparative Study of Decentralized Finance Derivatives Protocols](https://arxiv.org/abs/2512.19113)
*Luca Pennella,Pietro Saggese,Fabio Pinelli,Letterio Galletta*

Main category: cs.GT

TL;DR: 本文系统分析了DeFi衍生品协议（永续合约、期权和合成资产），提出了统一的概念框架，并通过数值模拟评估了不同经济条件下的协议动态。


<details>
  <summary>Details</summary>
Motivation: DeFi衍生品协议在区块链上复制和扩展传统金融衍生品，但其研究相对不足，缺乏系统性的分析和统一的理论框架。

Method: 1. 对DeFi衍生品协议进行系统分类（永续合约、期权、合成资产）；2. 提出形式化描述和统一概念框架；3. 通过数值模拟评估协议在不同经济条件下的动态表现。

Result: 建立了DeFi衍生品协议的设计原则和核心架构的统一框架，揭示了协议在不同市场条件下的动态特性，包括资产价格变动、波动率、费用、杠杆等因素对清算和盈利能力的影响。

Conclusion: DeFi衍生品协议具有独特的架构和动态特性，需要系统性的理论框架来理解和分析，这对于DeFi生态的发展和风险管理具有重要意义。

Abstract: Decentralized Finance (DeFi) applications introduce novel financial instruments replicating and extending traditional ones through blockchain-based smart contracts. Among these, derivatives protocols enable the decentralized trading of cryptoassets that are the counterpart of derivative products available in traditional finance. Despite their growing significance, DeFi derivatives protocols remain relatively understudied compared to other DeFi instruments, such as lending protocols and decentralized exchanges with automated market makers. This paper systematically analyzes DeFi derivatives protocols - categorized into perpetual, options, and synthetics - in the field, highlighting similarities, differences, dynamics, and actors. As a result of our study, we provide a formal characterization of decentralized derivative products and introduce a unifying conceptual framework that captures the design principles and core architecture of such protocols. We complement our theoretical analysis with numerical simulations: we evaluate protocol dynamics under various economic conditions, including changes in underlying asset prices, volatility, protocol-specific fees, leverage, and their impact on liquidation and profitability.

</details>


### [33] [LOCO: A Low-Cost SNU-Self-Resilient Latch Using an Output-Split C-Element](https://arxiv.org/abs/2512.19292)
*Ruijun Ma,Xin Chen,Xiaoqing Wen,Hui Xu,Shengnan Ye,Chuanjian Zhang,Senling Wang*

Main category: cs.GT

TL;DR: 提出了一种新型输出分裂C单元(OSC)和低开销单节点翻转自恢复锁存器(LOCO)，用于在纳米级CMOS技术中防护软错误，显著降低了晶体管数量、功耗、延迟和功耗延迟积。


<details>
  <summary>Details</summary>
Motivation: 随着CMOS技术进入纳米尺度，集成电路对辐射引起的软错误越来越敏感，现有硬化设计中的滤波元件只能保护输入节点，输出节点仍易受攻击，需要额外滤波元件导致开销增加。

Method: 首先提出输出分裂C单元(OSC)同时保护输入和输出节点，然后基于OSC设计低开销单节点翻转自恢复锁存器(LOCO)，采用时钟门控降低功耗，高速路径减少延迟。

Result: 与最先进的SNU抗性硬化设计相比，LOCO锁存器平均减少19%晶体管、降低63.58%功耗、减少74%延迟、降低92%功耗延迟积，在PVT变化下表现出更好的稳定性。

Conclusion: 提出的OSC和LOCO设计有效解决了现有滤波元件只能保护输入的问题，实现了软错误防护和低开销的平衡，在纳米级CMOS集成电路中具有重要应用价值。

Abstract: As the CMOS technology enters nanometer scales, integrated circuits (ICs) become increasingly sensitive to radiation-induced soft errors, which can corrupt the state of storage elements and cause severe reliability issues. Many hardened designs have been proposed to mitigate soft errors by using filtering elements. However, existing filtering elements only protect their inputs against soft errors and leave their outputs unprotected. Therefore, additional filtering elements must be added to protect outputs, resulting in extra overhead. In this paper, we first propose a novel Output-Split C-element (OSC) to protect both its input and output nodes, and then a novel LOw-COst single-node-upset (SNU) self-resilient latch (LOCO) to use OSCs to achieve both soft error resilience and low overhead. The usage of OSCs effectively reduce the short-circuit current of the LOCO latch during switching activities. Furthermore, the usage of clock gating and high-speed path reduces power consumption and delay, respectively. Compared with state-of-the-art SNU-resilient hardened designs, the LOCO latch achieves 19% fewer transistors, 63.58% lower power, 74% less delay, and 92% lower power-delay-product (PDP) on average. In addition, the LOCO latch exhibits better stability under variations in PVT (Process, Voltage, and Temperature).

</details>


### [34] [Stochastic assignment games for Mobility-as-a-Service markets](https://arxiv.org/abs/2512.19328)
*Bingqing Liu,David Watling,Joseph Y. J. Chow*

Main category: cs.GT

TL;DR: 本文研究随机分配博弈，并将其扩展到多模式移动市场，建立了一个MaaS平台作为领导者的随机Stackelberg博弈模型，用于设计最大化平台收入的票价策略。


<details>
  <summary>Details</summary>
Motivation: 研究随机分配博弈并将其应用于多模式移动市场，为MaaS平台设计最大化收入的票价策略，同时考虑用户和运营商的异质性和自私行为，为公共机构管理多模式交通系统提供工具。

Method: 1. 提出一般形式的一对一和多对多随机分配博弈；2. 将多对多随机分配博弈扩展为随机Stackelberg博弈，平台为领导者，用户和运营商为跟随者；3. 建立双层优化问题：上层为票价调整最大化收入，下层为随机多对多分配博弈；4. 提出迭代平衡算法精确求解下层问题，使用迭代票价调整启发式算法求解双层问题。

Result: 1. 证明了随机分配博弈的核心定义和最优性条件；2. 下层随机多对多分配博弈可表示为联盟logit模型；3. 提出的迭代票价调整启发式算法在收敛时等价于原双层问题；4. 通过两个案例研究验证了模型的有效性。

Conclusion: 该模型可用于设计MaaS平台票价以最大化收入，同时预测用户和运营商的异质性和自私行为。公共机构也可使用该模型管理多模式交通系统，为城市移动市场提供有效的决策支持工具。

Abstract: We study the stochastic assignment game and extend it to model multimodal mobility markets with a regulator or a Mobility-as-a-Service (MaaS) platform. We start by presenting general forms of one-to-one and many-to-many stochastic assignment games. Optimality conditions are discussed. The core of stochastic assignment games is defined, with expected payoffs of sellers and buyers in stochastic assignment games as payoffs from a hypothetical "ideal matching" that represent sellers' and buyers' expectations under imperfect information. To apply stochastic assignment games to the urban mobility markets, we extend the general stochastic many-to-many assignment game into a stochastic Stackelberg game to model MaaS systems, where the platform is the leader, and users and operators are the followers. The platform sets fares to maximize revenue. Users and operator react to the fare settings to form a stochastic many-to-many assignment game considering both fixed-route services and Mobility-on-Demand (MOD). The Stackelberg game is formulated as a bilevel problem. The lower level is the stochastic many-to-many assignment game between users and operators, shown to yield a coalitional logit model. The upper-level problem is a fare adjustment problem maximizing revenue. An iterative balancing algorithm is proposed to solve the lower-level problem exactly. The bilevel problem is solved through an iterative fare adjusting heuristic, whose solution is shown to be equivalent to the bilevel problem with an additional condition when it converges. Two case studies are conducted. The model can be applied to design MaaS fares maximizing income of the platform while anticipating the selfish behavior and heterogeneity of users and operators. Public agencies can also use the model to manage multimodal transportation systems.

</details>


### [35] [Fair Team Contracts](https://arxiv.org/abs/2512.19388)
*Matteo Castiglioni,Junjie Chen,Yingkai Li*

Main category: cs.GT

TL;DR: 研究团队合作中的最优公平合同设计，在满足公平约束下激励代理人付出努力，为加性成功函数提供FPTAS，为次模函数提供常数近似算法，公平合同比非歧视合同可增加25%收入


<details>
  <summary>Details</summary>
Motivation: 委托人需要选择团队合作完成项目，希望在满足公平约束的前提下设计收入最优的合同，激励代理人付出成本努力，同时避免歧视性合同可能带来的问题

Method: 提出最优公平合同结构：确保存在最低份额，每个代理人获得不低于最低份额的线性合同以激励努力；基于此结构为加性成功函数设计FPTAS，为次模成功函数设计常数近似算法

Result: 最优公平合同具有最小份额结构；加性成功函数可获得FPTAS；次模成功函数可获得常数近似；即使对于加性函数，最优公平合同比最优非歧视合同能增加25%收入

Conclusion: 公平约束不仅具有伦理价值，还能提高委托人收入；提出的合同结构和算法为团队合作中的公平激励设计提供了有效解决方案

Abstract: A principal selects a team of agents for collaborating on a joint project. The principal aims to design a revenue-optimal contract that incentivize the team of agents to exert costly effort while satisfying fairness constraints. We show that the optimal fair contract ensures that there is a minimum share, and every agent receives a linear contract weakly higher than the minimum share that is sufficient to incentivize them to exert costly effort. We utilize this structure to design an FPTAS for additive success functions and a constant approximation algorithm for submodular success functions. Moreover, we show that adopting optimal fair contracts can lead to a 25% revenue increase compared to the optimal non-discriminatory contracts even for additive success functions.

</details>


### [36] [Three Tiers and Thresholds: Incentives in Private Market Investing](https://arxiv.org/abs/2512.19405)
*Jussi Keppo,Yingkai Li*

Main category: cs.GT

TL;DR: 研究私募市场投资中的最优合同设计，重点关注VC/PE公司内部决策。通过三层次合同激励代理人进行尽职调查和真实报告，在对称环境下可简化为阈值合同。


<details>
  <summary>Details</summary>
Motivation: 私募市场投资中，委托人依赖代理人进行成本高昂的尽职调查和投资建议。传统合同难以同时激励信息获取和真实报告，且无法奖励谨慎放弃投资的决定。

Method: 建立委托代理模型，代理人私下付出尽职调查成本后给出投资建议。利用可观察结果（即使放弃投资）设计补偿方案。采用三层次合同结构，支付取决于建议和实际回报。

Result: 证明三层次合同足以实现利润最大化，激励信息获取和真实报告。在满足单调似然比性质的对称环境中，最优合同简化为阈值合同，仅在建议与极端回报一致时支付。

Conclusion: 研究为基于绩效的薪酬设计提供指导，既能促进尽职筛选，又能限制过度风险承担。阈值合同简化了实际应用，有助于VC/PE公司优化内部激励机制。

Abstract: This paper studies optimal contract design in private market investing, focusing on internal decision making in venture capital and private equity firms. A principal relies on an agent who privately exerts costly due diligence effort and then recommends whether to invest. Outcomes are observable ex post even when an opportunity is declined, allowing compensation to reward both successful investments and prudent decisions to pass. We characterize profit maximizing contracts that induce information acquisition and truthful reporting. We show that three tier contracts are sufficient, with payments contingent on the agent's recommendation and the realized return. In symmetric environments satisfying the monotone likelihood ratio property, the optimal contract further simplifies to a threshold contract that pays only when the recommendation is aligned with an extreme realized return. These results provide guidance for performance based compensation that promotes diligent screening while limiting excessive risk taking.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [37] [Fast Rational Search via Stern-Brocot Tree](https://arxiv.org/abs/2512.18036)
*Connor Weyers,N. V. Vinodchandran*

Main category: cs.DS

TL;DR: 提出了一种基于Stern-Brocot树压缩遍历的新有理数搜索算法，解决了已知边界的有理数搜索问题，并扩展到无边界有理数搜索和仅使用比较查询的最优有理数逼近问题。


<details>
  <summary>Details</summary>
Motivation: 重新审视有理数搜索问题：在已知有理数边界n的情况下，通过比较查询识别未知有理数α。虽然该问题几十年前已被研究且有最优算法，但发现了一种基于Stern-Brocot树压缩遍历的新方法，该方法在文献中被忽视。同时，该方法自然扩展到两个相关问题：无边界有理数搜索（n未知）和仅使用比较查询计算未知实数的最优有理数逼近。

Method: 基于Stern-Brocot树的压缩遍历算法。Stern-Brocot树是一种表示所有有理数的二叉树结构。通过压缩遍历该树，可以高效地搜索未知有理数。该方法不仅适用于已知边界的有理数搜索，还能自然地扩展到无边界情况和实数的最优有理数逼近问题。

Result: 提出了一种新的有理数搜索算法，该方法在文献中似乎被忽视。算法基于Stern-Brocot树的压缩遍历，能够高效解决有理数搜索问题。更重要的是，该方法可以扩展到两个新问题：无边界有理数搜索和仅使用比较查询的最优有理数逼近，这两个问题据作者所知此前未被解决。

Conclusion: Stern-Brocot树的压缩遍历为有理数搜索问题提供了一个优雅且高效的解决方案，不仅重新发现了已知问题的更好算法，还自然地扩展到两个新的重要问题：无边界有理数搜索和仅使用比较查询的最优有理数逼近，填补了相关研究空白。

Abstract: We revisit the problem of rational search: given an unknown rational number $α= \frac{a}{b} \in (0,1)$ with $b \leq n$, the goal is to identify $α$ using comparison queries of the form ``$β\leq α$?''. The problem has been studied several decades ago and optimal query algorithms are known. We present a new algorithm for rational search based on a compressed traversal of the Stern--Brocot tree, which appeared to have been overlooked in the literature. This approach also naturally extends to two related problems that, to the best of our knowledge, have not been previously addressed: (i) unbounded rational search, where the bound $n$ is unknown, and (ii) computing the best (in a precise sense) rational approximation of an unknown real number using only comparison queries.

</details>


### [38] [Graph-based Nearest Neighbors with Dynamic Updates via Random Walks](https://arxiv.org/abs/2512.18060)
*Nina Mishra,Yonatan Naamad,Tal Wagner,Lichen Zhang*

Main category: cs.DS

TL;DR: 本文提出了一种新的基于随机游走的图近似最近邻搜索理论框架，并基于该框架开发了一种确定性删除算法，解决了HNSW不支持数据删除的问题，在查询延迟、召回率、删除时间和内存使用之间提供了更好的权衡。


<details>
  <summary>Details</summary>
Motivation: 当前广泛使用的分层可导航小世界（HNSW）图算法虽然支持数据插入，但不支持数据删除。现有的删除算法要么增加查询延迟，要么降低召回率，要么延长删除时间，需要一种更好的解决方案。

Method: 首先提出了一个基于随机游走的图近似最近邻搜索理论框架，然后利用该框架分析了一种随机删除方法，该方法能保持删除点前后的命中时间统计特性。最后将该理论框架转化为确定性删除算法。

Result: 通过大量实验证明，提出的确定性删除算法在查询延迟、召回率、删除时间和内存使用之间提供了更好的权衡，相比现有方法有显著改进。

Conclusion: 本文提出的基于随机游走理论框架的确定性删除算法有效解决了HNSW图的数据删除问题，为图基近似最近邻搜索系统提供了实用的删除功能，平衡了多个性能指标。

Abstract: Approximate nearest neighbor search (ANN) is a common way to retrieve relevant search results, especially now in the context of large language models and retrieval augmented generation. One of the most widely used algorithms for ANN is based on constructing a multi-layer graph over the dataset, called the Hierarchical Navigable Small World (HNSW). While this algorithm supports insertion of new data, it does not support deletion of existing data. Moreover, deletion algorithms described by prior work come at the cost of increased query latency, decreased recall, or prolonged deletion time. In this paper, we propose a new theoretical framework for graph-based ANN based on random walks. We then utilize this framework to analyze a randomized deletion approach that preserves hitting time statistics compared to the graph before deleting the point. We then turn this theoretical framework into a deterministic deletion algorithm, and show that it provides better tradeoff between query latency, recall, deletion time, and memory usage through an extensive collection of experiments.

</details>


### [39] [Constrained Cuts, Flows, and Lattice-Linearity](https://arxiv.org/abs/2512.18141)
*Robert Streit,Vijay K. Garg*

Main category: cs.DS

TL;DR: 该论文研究带容量有向图中的最小割问题，利用最小割形成的分配格结构，开发并行算法处理具有额外约束的最小割问题，包括格线性谓词、不可约元计算和精确算法。


<details>
  <summary>Details</summary>
Motivation: 最小割问题在带容量有向图中具有重要应用，已知所有最小割形成分配格。然而，处理具有额外约束的最小割问题（如格线性谓词编码的约束）需要高效的并行算法。本文旨在利用格结构特性，开发处理这类约束的并行算法，并探索更一般的约束情况。

Method: 1. 将最小割格描述为正则谓词，其禁止元素在预计算最大流后可在常数并行时间内推进；2. 利用格线性谓词编码额外约束；3. 计算满足正则谓词的最小割子格的不可约元，通过Birkhoff定理获得简洁表示；4. 引入k-转移谓词和强推进改进并行设置中格线性谓词算法的复杂度分析；5. 使用偏序集切片技术处理非格线性谓词编码的约束，获得比穷举搜索更好的复杂度。

Result: 1. 开发了处理格线性谓词编码约束的并行算法；2. 获得了满足正则谓词的最小割子格的不可约元计算方法，从而得到该子格的简洁表示和枚举算法；3. 证明了计算满足额外约束的最小割一般是NP难的，但通过偏序集切片技术获得了比穷举搜索更好的精确算法；4. 引入k-转移谓词和强推进改进了并行设置中格线性谓词算法的复杂度分析。

Conclusion: 本文利用最小割形成的分配格结构，成功开发了处理具有额外约束的最小割问题的并行算法框架。虽然一般约束情况是NP难的，但通过格线性谓词和偏序集切片技术，获得了比传统方法更高效的算法。所提出的k-转移谓词和强推进概念对并行格线性谓词算法的复杂度分析具有独立的理论价值。

Abstract: In a capacitated directed graph, it is known that the set of all min-cuts forms a distributive lattice [1], [2]. Here, we describe this lattice as a regular predicate whose forbidden elements can be advanced in constant parallel time after precomputing a max-flow, so as to obtain parallel algorithms for min-cut problems with additional constraints encoded by lattice-linear predicates [3]. Some nice algorithmic applications follow. First, we use these methods to compute the irreducibles of the sublattice of min-cuts satisfying a regular predicate. By Birkhoff's theorem [4] this gives a succinct representation of such cuts, and so we also obtain a general algorithm for enumerating this sublattice. Finally, though we prove computing min-cuts satisfying additional constraints is NP-hard in general, we use poset slicing [5], [6] for exact algorithms with constraints not necessarily encoded by lattice-linear predicates) with better complexity than exhaustive search. We also introduce $k$-transition predicates and strong advancement for improved complexity analyses of lattice-linear predicate algorithms in parallel settings, which is of independent interest.

</details>


### [40] [Learning Dependency Models for Subset Repair](https://arxiv.org/abs/2512.18204)
*Haoda Li,Jiahui Chen,Yu Sun,Shaoxu Song,Haiwei Zhang,Xiaojie Yuan*

Main category: cs.DS

TL;DR: 该论文提出了一种基于属性依赖关系的最优子集修复方法，解决了传统方法在存在多个最小修复集时难以决策的问题，通过整数线性规划、近似算法和概率方法实现高效修复。


<details>
  <summary>Details</summary>
Motivation: 现实应用中常遇到不一致数据，影响数据分析和决策。现有研究主要关注识别最小修复集，但可能存在多个最小修复集，难以进一步决策。传统基于最高频值的修复策略可能错误识别误差，需要更合适的修复方法。

Method: 1) 形式化基于属性依赖的最优子集修复问题并分析计算复杂度；2) 使用整数线性规划计算精确解；3) 基于团和LP松弛开发具有性能保证的近似算法；4) 设计具有近似界的概率方法提高效率。

Result: 在真实数据集上的实验验证了方法在子集修复性能和下游应用中的有效性，证明了基于属性依赖的修复策略优于传统方法。

Conclusion: 通过考虑属性值之间的依赖关系，提出了一种更合适的子集修复方法，解决了多个最小修复集存在的决策困难问题，为不一致数据修复提供了更准确高效的解决方案。

Abstract: Inconsistent values are commonly encountered in real-world applications, which can negatively impact data analysis and decision-making. While existing research primarily focuses on identifying the smallest removal set to resolve inconsistencies, recent studies have shown that multiple minimum removal sets may exist, making it difficult to make further decisions. While some approaches use the most frequent values as the guidance for the subset repair, this strategy has been criticized for its potential to inaccurately identify errors. To address these issues, we consider the dependencies between attribute values to determine a more appropriate subset repair. Our main contributions include (1) formalizing the optimal subset repair problem with attribute dependencies and analyzing its computational hardness; (2) computing the exact solution using integer linear programming; (3) developing an approximate algorithm with performance guarantees based on cliques and LP relaxation; and (4) designing a probabilistic approach with an approximation bound for efficiency. Experimental results on real-world datasets validate the effectiveness of our methods in both subset repair performance and downstream applications.

</details>


### [41] [Quantization for Vector Search under Streaming Updates](https://arxiv.org/abs/2512.18335)
*Ishaq Aden-Ali,Hakan Ferhatosmanoglu,Alexander Greaves-Tunnell,Nina Mishra,Tal Wagner*

Main category: cs.DS

TL;DR: 本文提出了一种支持流式更新的动态数据依赖量化方法，解决了传统ANN量化方法无法处理数据插入删除的问题，避免了昂贵的全局重建。


<details>
  <summary>Details</summary>
Motivation: 大规模向量数据库的近似最近邻搜索通常使用量化数据存储在内存中，而完整精度数据存储在远程磁盘上。现有的数据依赖量化方法高度依赖静态数据集，无法处理数据点的插入和删除，这会导致搜索质量随时间下降，或者需要昂贵的全局索引重建。

Method: 本文首先形式化研究了流式数据集更新下的数据依赖量化问题，建立了有限远程磁盘访问的计算模型，并定义了保证更新新鲜度的动态一致性属性。基于此，开发了一种实用的数据依赖量化方法，该方法能够自适应地随数据集演化而调整，并具有可证明的动态一致性。

Result: 理论上证明了静态数据依赖量化可以通过有界磁盘I/O更新实现动态化，同时保持ANN搜索的正式精度保证。实验结果表明，该方法在流式更新下的大规模最近邻搜索量化中优于基线方法。

Conclusion: 本文首次形式化研究了流式更新下的数据依赖量化问题，提出了一种动态一致的数据依赖量化方法，能够有效处理数据集演化，避免了昂贵的全局重建，同时保持了搜索质量。

Abstract: Large-scale vector databases for approximate nearest neighbor (ANN) search typically store a quantized dataset in main memory for fast access, and full precision data on remote disk. State-of-the-art ANN quantization methods are highly data-dependent, rendering them unable to handle point insertions and deletions. This either leads to degraded search quality over time, or forces costly global rebuilds of the entire search index. In this paper, we formally study data-dependent quantization under streaming dataset updates. We formulate a computation model of limited remote disk access and define a dynamic consistency property that guarantees freshness under updates. We use it to obtain the following results: Theoretically, we prove that static data-dependent quantization can be made dynamic with bounded disk I/O per update while retaining formal accuracy guarantees for ANN search. Algorithmically, we develop a practical data-dependent quantization method which is provably dynamically consistent, adapting itself to the dataset as it evolves over time. Our experiments show that the method outperforms baselines in large-scale nearest neighbor search quantization under streaming updates.

</details>


### [42] [Constant Approximation of Arboricity in Near-Optimal Sublinear Time](https://arxiv.org/abs/2512.18416)
*Jiangqi Dai,Mohsen Ghaffari,Julian Portmann*

Main category: cs.DS

TL;DR: 提出随机算法以常数近似计算图的树宽，使用近最优的$\tilde{O}(n/λ)$查询和时间复杂度，解决了之前$O(\log^2 n)$近似的开放问题。


<details>
  <summary>Details</summary>
Motivation: 解决Eden、Mossel和Ron在SODA'22提出的开放问题：是否能在保持近最优查询复杂度的同时，将树宽近似从$O(\log^2 n)$改进到常数近似。

Method: 采用并行递归方法，通过精心设计的调度机制管理多个递归进程的速度，以降低错误概率，同时保持查询复杂度与单个良好递归相当。

Result: 实现了常数近似算法，查询和时间复杂度为$\tilde{O}(n/λ)$，这是近最优的，显著改进了之前的$O(\log^2 n)$近似结果。

Conclusion: 该算法解决了树宽近似的重要开放问题，提出的并行递归和调度机制对依赖概率递归的亚线性算法具有广泛的应用潜力。

Abstract: We present a randomized algorithm that computes a constant approximation of a graph's arboricity, using $\tilde{O}(n/λ)$ queries to adjacency lists and in the same time bound. Here, $n$ and $λ$ denote the number of nodes and the graph's arboricity, respectively. The $\tilde{O}(n/λ)$ query complexity of our algorithm is nearly optimal. Our constant approximation settles a question of Eden, Mossel, and Ron [SODA'22], who achieved an $O(\log^2 n)$ approximation with the same query and time complexity and asked whether a better approximation can be achieved using near-optimal query complexity.
  A key technical challenge in the problem is due to recursive algorithms based on probabilistic samplings, each with a non-negligible error probability. In our case, many of the recursions invoked could have bad probabilistic samples and result in high query complexities. The particular difficulty is that those bad recursions are not easy or cheap to detect and discard. Our approach runs multiple recursions in parallel, to attenuate the error probability, using a careful \textit{scheduling mechanism} that manages the speed at which each of them progresses and makes our overall query complexity competitive with the single good recursion. We find this usage of parallelism and scheduling in a sublinear algorithm remarkable, and we are hopeful that similar ideas may find applications in a wider range of sublinear algorithms that rely on probabilistic recursions.

</details>


### [43] [Fare Zone Assignment](https://arxiv.org/abs/2512.19493)
*Martin Hoefer,Lennart Kauther,Philipp Pabst,Britta Peis,Khai Van Tran*

Main category: cs.DS

TL;DR: 公共交通网络分区定价优化问题：针对树形网络，提出近似算法和精确算法，分析计算复杂度


<details>
  <summary>Details</summary>
Motivation: 公共交通网络定价是一个重要挑战，分区定价（zoning）是常用方法。需要找到收益最优的分区方案，但该问题在树形网络中已具有非平凡的计算复杂性。

Method: 研究树形网络上的分区定价问题，提出近似算法（O(log n)和O(log n/log log n)近似），针对根节点需求实例提供精确算法，分析路径网络的强NP难性并设计PTAS，探索参数化复杂度。

Result: 1. 树形网络：提出高效近似算法；2. 根节点需求实例：可精确求解；3. 路径网络：证明强NP难性，设计PTAS；4. 参数化复杂度：对多个自然参数属于FPT或XP类。

Conclusion: 公共交通网络分区定价优化问题在树形网络中具有丰富的算法复杂性，提出了多种近似和精确算法，为实际应用提供了理论基础和计算工具。

Abstract: Tariff setting in public transportation networks is an important challenge. A popular approach is to partition the network into fare zones ("zoning") and fix journey prices depending on the number of traversed zones ("pricing"). In this paper, we focus on finding revenue-optimal solutions to the zoning problem for a given concave pricing function. We consider tree networks with $n$ vertices, since trees already pose non-trivial algorithmic challenges. Our main results are efficient algorithms that yield a simple $\mathcal{O}(\log n)$-approximation as well as a more involved $\mathcal{O}(\log n/\log \log n)$-approximation. We show how to solve the problem exactly on rooted instances, in which all demand arises at the same source. For paths, we prove strong NP-hardness and outline a PTAS. Moreover, we show that computing an optimal solution is in FPT or XP for several natural problem parameters.

</details>


### [44] [Near-optimal streaming approximation for Max-DICUT in sublinear space using two passes](https://arxiv.org/abs/2512.19521)
*Santhoshini Velusamy*

Main category: cs.DS

TL;DR: 本文改进了Max-DICUT问题在流式计算中的近似算法，针对任意图（无度数限制）提出了一个两遍流算法，在亚线性空间内达到(1/2-ε)近似比。


<details>
  <summary>Details</summary>
Motivation: Max-DICUT问题在流式计算中是一个典型问题，用于设计约束满足问题的流算法。之前的工作表明在单遍流中无法在亚线性空间内超越1/2近似比，而最近的研究针对有界度图实现了(1/2-ε)近似。但对于任意图（无度数限制），单遍流中的1/2近似问题仍然开放。

Method: 提出了一个两遍流算法：第一遍收集图的某些信息，第二遍基于这些信息计算近似解。算法在亚线性空间内运行，适用于任意图（无度数限制）。

Result: 对于任意常数ε>0，算法在亚线性空间内实现了(1/2-ε)近似比，这是对先前工作的改进，将近似比从1/2提升到了(1/2-ε)。

Conclusion: 本文在解决任意图Max-DICUT问题的单遍流亚线性空间1/2近似问题上取得了进展，通过两遍流算法实现了(1/2-ε)近似，向完全解决该开放问题迈进了一步。

Abstract: The Max-DICUT problem has gained a lot of attention in the streaming setting in recent years, and has so far served as a canonical problem for designing algorithms for general constraint satisfaction problems (CSPs) in this setting. A seminal result of Kapralov and Krachun [STOC 2019] shows that it is impossible to beat $1/2$-approximation for Max-DICUT in sublinear space in the single-pass streaming setting, even on bounded-degree graphs. In a recent work, Saxena, Singer, Sudan, and Velusamy [SODA 2025] prove that the above lower bound is tight by giving a single-pass algorithm for bounded-degree graphs that achieves $(1/2-ε)$-approximation in sublinear space, for every constant $ε>0$. For arbitrary graphs of unbounded degree, they give an $O(1/ε)$-pass $O(\log n)$ space algorithm. Their work left open the question of obtaining $1/2$-approximation for arbitrary graphs in the single-pass setting in sublinear space. We make progress towards this question and give a two-pass algorithm that achieves $(1/2-ε)$-approximation in sublinear space, for every constant $ε>0$.

</details>


### [45] [Clustering with Label Consistency](https://arxiv.org/abs/2512.19654)
*Diptarka Chakraborty,Hendrik Fichtenberger,Bernhard Haeupler,Silvio Lattanzi,Ashkan Norouzi-Fard,Ola Svensson*

Main category: cs.DS

TL;DR: 提出标签一致性度量聚类新概念，针对k-center和k-median问题设计新的近似算法


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法关注聚类中心的稳定性，但忽视了实际应用中点标签（点分配到命名集合）的稳定性需求

Method: 引入新的标签一致性概念，测量连续解之间的标签距离，基于此定义设计新的k-center和k-median近似算法

Result: 提出了标签一致性度量聚类的新框架，并设计了相应的近似算法

Conclusion: 填补了传统聚类方法在标签稳定性方面的空白，为实际应用提供了更符合需求的聚类解决方案

Abstract: Designing efficient, effective, and consistent metric clustering algorithms is a significant challenge attracting growing attention. Traditional approaches focus on the stability of cluster centers; unfortunately, this neglects the real-world need for stable point labels, i.e., stable assignments of points to named sets (clusters). In this paper, we address this gap by initiating the study of label-consistent metric clustering. We first introduce a new notion of consistency, measuring the label distance between two consecutive solutions. Then, armed with this new definition, we design new consistent approximation algorithms for the classical $k$-center and $k$-median problems.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [46] [Factorized Transport Alignment for Multimodal and Multiview E-commerce Representation Learning](https://arxiv.org/abs/2512.18117)
*Xiwen Chen,Yen-Chieh Lien,Susan Liu,María Castaños,Abolfazl Razi,Xiaoting Zhao,Congzhe Su*

Main category: cs.IR

TL;DR: 提出基于因子化传输的多视图多模态学习框架，用于电商搜索，通过轻量级最优传输近似统一多视图学习，在保持检索效率的同时显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型通常只对齐标题与主图（单视图），忽略了电商平台中非主图和辅助文本视图提供的丰富语义信息，需要更全面的多视图表示学习。

Method: 提出因子化传输框架，作为最优传输的轻量级近似，训练时强调主视图并随机采样辅助视图，将训练成本从视图数量的二次方降低为常数；推理时将所有视图融合为单个缓存嵌入。

Result: 在包含100万商品列表和30万交互的工业数据集上，该方法在跨视图和查询到商品检索中取得一致改进，Recall@500比强大多模态基线提升高达7.9%。

Conclusion: 该框架通过基于最优传输的学习实现了可扩展性，使多视图预训练在大规模电商搜索中变得实用，平衡了性能与效率。

Abstract: The rapid growth of e-commerce requires robust multimodal representations that capture diverse signals from user-generated listings. Existing vision-language models (VLMs) typically align titles with primary images, i.e., single-view, but overlook non-primary images and auxiliary textual views that provide critical semantics in open marketplaces such as Etsy or Poshmark. To this end, we propose a framework that unifies multimodal and multi-view learning through Factorized Transport, a lightweight approximation of optimal transport, designed for scalability and deployment efficiency. During training, the method emphasizes primary views while stochastically sampling auxiliary ones, reducing training cost from quadratic in the number of views to constant per item. At inference, all views are fused into a single cached embedding, preserving the efficiency of two-tower retrieval with no additional online overhead. On an industrial dataset of 1M product listings and 0.3M interactions, our approach delivers consistent improvements in cross-view and query-to-item retrieval, achieving up to +7.9% Recall@500 over strong multimodal baselines. Overall, our framework bridges scalability with optimal transport-based learning, making multi-view pretraining practical for large-scale e-commerce search.

</details>


### [47] [Improving Data Reusability in Interactive Information Retrieval: Insights from the Community](https://arxiv.org/abs/2512.18283)
*Tianji Jiang,Wenqi Li,Jiqun Liu*

Main category: cs.IR

TL;DR: 通过访谈21名IIR研究人员，探究其数据重用实践，识别评估数据可重用性时所需的信息特征及获取来源，为促进数据重用提供基础


<details>
  <summary>Details</summary>
Motivation: 当前对IIR研究人员数据重用实践了解有限，需要探索他们在数据重用中的信息获取行为，为设计标准、基础设施和政策提供依据，促进该领域数据共享和重用的可持续文化

Method: 采用半结构化访谈方法，对21名IIR研究人员进行访谈，分析他们在评估数据可重用性时所需的信息特征以及获取这些信息的常用来源

Result: 识别了IIR研究人员在评估数据可重用性时所需的共享数据特征信息，以及他们通常咨询的信息来源，为揭示数据重用实践提供了初步发现

Conclusion: 这是揭示IIR研究人员数据重用实践的第一步，识别了社区需要采取的措施来促进数据重用，希望激发更多人参与设计标准、基础设施和政策，培养数据共享和重用的可持续文化

Abstract: In this study, we conducted semi-structured interviews with 21 IIR researchers to investigate their data reuse practices. This study aims to expand upon current findings by exploring IIR researchers' information-obtaining behaviors regarding data reuse. We identified the information about shared data characteristics that IIR researchers need when evaluating data reusability, as well as the sources they typically consult to obtain this information. We consider this work to be an initial step toward revealing IIR researchers' data reuse practices and identifying what the community needs to do to promote data reuse. We hope that this study, as well as future research, will inspire more individuals to contribute to ongoing efforts aimed at designing standards, infrastructures, and policies, as well as fostering a sustainable culture of data sharing and reuse in this field.

</details>


### [48] [Datasets for machine learning and for assessing the intelligence level of automatic patent search systems](https://arxiv.org/abs/2512.18384)
*Boris Genin,Alexander Gorbunov,Dmitry Zolkin,Igor Nekrasov*

Main category: cs.IR

TL;DR: 该论文提出了一种用于专利现有技术搜索自动化研究的综合基础设施，包括基于语义集群概念的机器学习数据集生成器和搜索质量评估工具。


<details>
  <summary>Details</summary>
Motivation: 自动化专利现有技术搜索的关键在于开发大规模机器学习数据集并确保其可用性。当前缺乏用于该领域研究的综合基础设施，包括数据集和搜索质量评估工具。

Method: 1) 提出专利文档语义集群概念，将现有技术搜索定义为在特定主题的语义集群中识别相关文档；2) 开发基于美俄专利文档的用户可配置数据集生成器，创建语义集群链接数据库并生成JSON格式数据集；3) 开发考虑文档语义集群的搜索质量评估工具。

Result: 提供了完整的专利现有技术搜索研究基础设施：1) 定义了语义集群概念；2) 开发了可配置的数据集生成器；3) 创建了自动化搜索质量评估工具，能够计算考虑语义集群的搜索质量分数。

Conclusion: 该工作为专利现有技术搜索的自动化研究提供了全面的基础设施解决方案，包括数据集生成和评估工具，有助于推进该领域的人工智能应用发展。

Abstract: The key to success in automating prior art search in patent research using artificial intelligence lies in developing large datasets for machine learning and ensuring their availability. This work is dedicated to providing a comprehensive solution to the problem of creating infrastructure for research in this field, including datasets and tools for calculating search quality criteria. The paper discusses the concept of semantic clusters of patent documents that determine the state of the art in a given subject, as proposed by the authors. A definition of such semantic clusters is also provided. Prior art search is presented as the task of identifying elements within a semantic cluster of patent documents in the subject area specified by the document under consideration. A generator of user-configurable datasets for machine learning, based on collections of U.S. and Russian patent documents, is described. The dataset generator creates a database of links to documents in semantic clusters. Then, based on user-defined parameters, it forms a dataset of semantic clusters in JSON format for machine learning. To evaluate machine learning outcomes, it is proposed to calculate search quality scores that account for semantic clusters of the documents being searched. To automate the evaluation process, the paper describes a utility developed by the authors for assessing the quality of prior art document search.

</details>


### [49] [Efficient Optimization of Hierarchical Identifiers for Generative Recommendation](https://arxiv.org/abs/2512.18434)
*Federica Valeau,Odysseas Boufalis,Polytimi Gkotsi,Joshua Rosenthal,David Vos*

Main category: cs.IR

TL;DR: SEATER通过平衡树结构标识符和对比训练目标提升推荐效率和质量，但训练中的树构建步骤在大规模项目集上成为瓶颈。研究提出两种替代构建算法：贪婪方法大幅减少构建时间（<2%），混合方法保持质量的同时减少构建时间（5-8%）。


<details>
  <summary>Details</summary>
Motivation: SEATER模型在推荐系统中表现出色，但其训练过程中的树构建步骤随着项目数量增加成为主要瓶颈，需要更高效的构建算法来提升可扩展性。

Method: 1. 复现并验证SEATER在多个数据集上的性能；2. 扩展到Yambda大规模音乐推荐数据集；3. 实现两种替代树构建算法：贪婪方法（优化构建时间）和混合方法（结合贪婪聚类和高精度分组）。

Result: 贪婪方法将树构建时间减少到原始的2%以下，在最大项目集上仅有轻微质量下降；混合方法保持与原始相当甚至更好的检索质量，同时将构建时间减少到5-8%。

Conclusion: 提出的替代树构建算法显著提升了SEATER的可扩展性，解决了大规模推荐系统中的训练瓶颈问题，同时保持了检索质量。

Abstract: SEATER is a generative retrieval model that improves recommendation inference efficiency and retrieval quality by utilizing balanced tree-structured item identifiers and contrastive training objectives. We reproduce and validate SEATER's reported improvements in retrieval quality over strong baselines across all datasets from the original work, and extend the evaluation to Yambda, a large-scale music recommendation dataset. Our experiments verify SEATER's strong performance, but show that its tree construction step during training becomes a major bottleneck as the number of items grows. To address this, we implement and evaluate two alternative construction algorithms: a greedy method optimized for minimal build time, and a hybrid method that combines greedy clustering at high levels with more precise grouping at lower levels. The greedy method reduces tree construction time to less than 2% of the original with only a minor drop in quality on the dataset with the largest item collection. The hybrid method achieves retrieval quality on par with the original, and even improves on the largest dataset, while cutting construction time to just 5-8%. All data and code are publicly available for full reproducibility at https://github.com/joshrosie/re-seater.

</details>


### [50] [CIRR: Causal-Invariant Retrieval-Augmented Recommendation with Faithful Explanations under Distribution Shift](https://arxiv.org/abs/2512.18683)
*Sebastian Sun*

Main category: cs.IR

TL;DR: CIRR是一个因果不变性检索增强推荐框架，通过因果推理学习环境不变的用户偏好表示，并引入一致性约束确保检索证据、生成解释和推荐输出之间的忠实性，解决了现有RAG推荐系统在分布偏移下的脆弱性和缺乏可验证解释的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强生成(RAG)的推荐系统面临两个关键挑战：1) 在不同环境(如时间周期、用户群体)的分布偏移下表现脆弱，导致在分布外(OOD)场景中性能下降；2) 缺乏能够根据检索证据进行验证的忠实解释。

Method: 提出CIRR框架：1) 通过因果推理学习环境不变的用户偏好表示，指导去偏的检索过程从多源选择相关证据；2) 引入一致性约束，强制检索证据、生成解释和推荐输出之间的忠实性。

Result: 在两个真实世界数据集上的实验表明：CIRR在分布偏移下实现鲁棒性能，将OOD场景中的性能下降从基线15.4%降低到仅5.6%；同时提供更忠实和可解释的解释(忠实性得分提升26%)，优于最先进的基线方法。

Conclusion: CIRR框架成功解决了RAG推荐系统在分布偏移下的脆弱性和解释忠实性问题，通过因果不变性学习和一致性约束实现了鲁棒的推荐性能和可验证的解释生成。

Abstract: Recent advances in retrieval-augmented generation (RAG) have shown promise in enhancing recommendation systems with external knowledge. However, existing RAG-based recommenders face two critical challenges: (1) vulnerability to distribution shifts across different environments (e.g., time periods, user segments), leading to performance degradation in out-of-distribution (OOD) scenarios, and (2) lack of faithful explanations that can be verified against retrieved evidence. In this paper, we propose CIRR, a Causal-Invariant Retrieval-Augmented Recommendation framework that addresses both challenges simultaneously. CIRR learns environment-invariant user preference representations through causal inference, which guide a debiased retrieval process to select relevant evidence from multiple sources. Furthermore, we introduce consistency constraints that enforce faithfulness between retrieved evidence, generated explanations, and recommendation outputs. Extensive experiments on two real-world datasets demonstrate that CIRR achieves robust performance under distribution shifts, reducing performance degradation from 15.4% (baseline) to only 5.6% in OOD scenarios, while providing more faithful and interpretable explanations (26% improvement in faithfulness score) compared to state-of-the-art baselines.

</details>


### [51] [Modular Layout Synthesis (MLS): Front-end Code via Structure Normalization and Constrained Generation](https://arxiv.org/abs/2512.18996)
*Chong Liu,Ming Zhang,Fei Li,Hao Zhou,Xiaoshuang Chen,Ye Yuan*

Main category: cs.IR

TL;DR: MLS框架通过视觉语义编码和层次化结构规范化，将设计图转换为模块化、可维护的前端代码，支持React/Vue/Angular等现代框架


<details>
  <summary>Details</summary>
Motivation: 现有AI生成前端代码方案通常产生单一脚本，不支持现代框架如React/Vue/Angular，且代码模块化差难以维护

Method: 1) 视觉语义编码器将屏幕截图映射为序列化树拓扑；2) 启发式去重和模式识别分离可复用块；3) 基于约束的生成协议指导LLM合成生产就绪代码

Result: MLS显著优于现有基线，在多个框架中确保优越的代码可重用性和结构完整性

Conclusion: MLS框架成功解决了AI生成前端代码的模块化和框架支持问题，为自动化前端工程提供了有效解决方案

Abstract: Automated front-end engineering drastically reduces development cycles and minimizes manual coding overhead. While Generative AI has shown promise in translating designs to code, current solutions often produce monolithic scripts, failing to natively support modern ecosystems like React, Vue, or Angular. Furthermore, the generated code frequently suffers from poor modularity, making it difficult to maintain. To bridge this gap, we introduce Modular Layout Synthesis (MLS), a hierarchical framework that merges visual understanding with structural normalization. Initially, a visual-semantic encoder maps the screen capture into a serialized tree topology, capturing the essential layout hierarchy. Instead of simple parsing, we apply heuristic deduplication and pattern recognition to isolate reusable blocks, creating a framework-agnostic schema. Finally, a constraint-based generation protocol guides the LLM to synthesize production-ready code with strict typing and component props. Evaluations show that MLS significantly outperforms existing baselines, ensuring superior code reusability and structural integrity across multiple frameworks

</details>


### [52] [Generative vector search to improve pathology foundation models across multimodal vision-language tasks](https://arxiv.org/abs/2512.19360)
*Markus Ekvall,Ludvig Bergenstråhle,Patrick Truong,Ben Murrell,Joakim Lundeberg*

Main category: cs.IR

TL;DR: STHLM是一种生成式向量搜索方法，通过采样查询条件嵌入来增强检索性能，特别适用于生物医学等复杂多概念查询领域，相比传统向量检索提升10-30%性能，同时实现高达10倍的嵌入维度压缩。


<details>
  <summary>Details</summary>
Motivation: 传统基于嵌入的检索方法在处理生物医学等领域的多概念复杂查询时效果有限，无法捕捉高维生物数据（如组学数据集和临床报告）中分子、细胞和生理特征的复杂性。

Method: 提出随机潜在匹配（STHLM）方法，这是一种生成式向量搜索技术，能够从文本或图像输入中采样查询条件嵌入。类似于思维链推理让语言模型"思考更久"，STHLM让检索系统通过迭代采样"搜索更广"。

Result: 在科学文献、临床记录和组织图像等多个基准测试中，STHLM相比传统向量检索有显著改进，通过测试时计算（以延迟换取准确性）将检索性能提升10-30%，同时实现高达10倍的嵌入维度压缩。

Conclusion: STHLM为检索增强生成提供了更强大的检索基础，特别适用于处理生物医学等领域的复杂多概念查询，通过生成式向量搜索方法有效解决了传统嵌入检索的局限性。

Abstract: Retrieval-augmented generation improves large language models by grounding outputs in external knowledge sources, reducing hallucinations and addressing knowledge cutoffs. However, standard embedding-based retrieval fails to capture the complexity of multi-concept queries, particularly in domains like biomedicine, where biological data are inherently high-dimensional. For example,omics datasets, and clinical reports simultaneously exhibit numerous molecular, cellular, and physiological features. We present Stochastic Latent Matching (STHLM), a generative vector search method that samples query-conditioned embeddings from text or image inputs to enhance retrieval performance. Analogous to how Chain-of-Thought reasoning enables language models to "think longer" on complex problems, STHLM allows retrieval systems to "search wider" through iterative sampling. STHLM demonstrates critical improvements over classical vector retrieval across diverse benchmarks, including scientific literature, clinical notes, and tissue images, boosting retrieval performance by 10-30% through test-time compute (trading latency for accuracy), while enabling up to a 10-fold compression of embedding dimensions.

</details>
