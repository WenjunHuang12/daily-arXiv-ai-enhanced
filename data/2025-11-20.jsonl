{"id": "2511.14763", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14763", "abs": "https://arxiv.org/abs/2511.14763", "authors": ["Li Cuihong", "Huang Xiaowen", "Yin Chuanhuan", "Sang Jitao"], "title": "Membership Inference Attack against Large Language Model-based Recommendation Systems: A New Distillation-based Paradigm", "comment": null, "summary": "Membership Inference Attack (MIA) aims to determine if a data sample is used in the training dataset of a target model. Traditional MIA obtains feature of target model via shadow models and uses the feature to train attack model, but the scale and complexity of training or fine-tuning data for large language model (LLM)-based recommendation systems make shadow models difficult to construct. Knowledge distillation as a method for extracting knowledge contributes to construct a stronger reference model. Knowledge distillation enables separate distillation for member and non-member data during the distillation process, enhancing the model's discriminative capability between the two in MIA. This paper propose a knowledge distillation-based MIA paradigm to improve the performance of membership inference attacks on LLM-based recommendation systems. Our paradigm introduces knowledge distillation to obtain a reference model, which enhances the reference model's ability to distinguish between member and non-member data. We obtain individual features from the reference model and train our attack model with fused feature. Our paradigm improves the attack performance of MIA compared to shadow model-based attack."}
{"id": "2511.14764", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14764", "abs": "https://arxiv.org/abs/2511.14764", "authors": ["Mariya Hendriksen", "Svitlana Vakulenko", "Jordan Massiah", "Gabriella Kazai", "Emine Yilmaz"], "title": "Image-Seeking Intent Prediction for Cross-Device Product Search", "comment": "Oral at RecSys Gen AI for E-commerce 2025", "summary": "Large Language Models (LLMs) are transforming personalized search, recommendations, and customer interaction in e-commerce. Customers increasingly shop across multiple devices, from voice-only assistants to multimodal displays, each offering different input and output capabilities. A proactive suggestion to switch devices can greatly improve the user experience, but it must be offered with high precision to avoid unnecessary friction. We address the challenge of predicting when a query requires visual augmentation and a cross-device switch to improve product discovery. We introduce Image-Seeking Intent Prediction, a novel task for LLM-driven e-commerce assistants that anticipates when a spoken product query should proactively trigger a visual on a screen-enabled device. Using large-scale production data from a multi-device retail assistant, including 900K voice queries, associated product retrievals, and behavioral signals such as image carousel engagement, we train IRP (Image Request Predictor), a model that leverages user input query and corresponding retrieved product metadata to anticipate visual intent. Our experiments show that combining query semantics with product data, particularly when improved through lightweight summarization, consistently improves prediction accuracy. Incorporating a differentiable precision-oriented loss further reduces false positives. These results highlight the potential of LLMs to power intelligent, cross-device shopping assistants that anticipate and adapt to user needs, enabling more seamless and personalized e-commerce experiences."}
{"id": "2511.14765", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.14765", "abs": "https://arxiv.org/abs/2511.14765", "authors": ["Mohammad Usman Altam", "Md Imtiaz Habib", "Tuan Hoang"], "title": "Optimizing Agricultural Research: A RAG-Based Approach to Mycorrhizal Fungi Information", "comment": "10 pages, 4 figures, 1 table", "summary": "Retrieval-Augmented Generation (RAG) represents a transformative approach within natural language processing (NLP), combining neural information retrieval with generative language modeling to enhance both contextual accuracy and factual reliability of responses. Unlike conventional Large Language Models (LLMs), which are constrained by static training corpora, RAG-powered systems dynamically integrate domain-specific external knowledge sources, thereby overcoming temporal and disciplinary limitations. In this study, we present the design and evaluation of a RAG-enabled system tailored for Mycophyto, with a focus on advancing agricultural applications related to arbuscular mycorrhizal fungi (AMF). These fungi play a critical role in sustainable agriculture by enhancing nutrient acquisition, improving plant resilience under abiotic and biotic stresses, and contributing to soil health. Our system operationalizes a dual-layered strategy: (i) semantic retrieval and augmentation of domain-specific content from agronomy and biotechnology corpora using vector embeddings, and (ii) structured data extraction to capture predefined experimental metadata such as inoculation methods, spore densities, soil parameters, and yield outcomes. This hybrid approach ensures that generated responses are not only semantically aligned but also supported by structured experimental evidence. To support scalability, embeddings are stored in a high-performance vector database, allowing near real-time retrieval from an evolving literature base. Empirical evaluation demonstrates that the proposed pipeline retrieves and synthesizes highly relevant information regarding AMF interactions with crop systems, such as tomato (Solanum lycopersicum). The framework underscores the potential of AI-driven knowledge discovery to accelerate agroecological innovation and enhance decision-making in sustainable farming systems."}
{"id": "2511.14766", "categories": ["cs.IR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.14766", "abs": "https://arxiv.org/abs/2511.14766", "authors": ["Yang Li", "Yajiao Wang", "Wenhao Hu", "Zhixiong Zhang", "Mengting Zhang"], "title": "OTCR: Optimal Transmission, Compression and Representation for Multimodal Information Extraction", "comment": "5 pages, 3 figures", "summary": "Multimodal Information Extraction (MIE) requires fusing text and visual cues from visually rich documents. While recent methods have advanced multimodal representation learning, most implicitly assume modality equivalence or treat modalities in a largely uniform manner, still relying on generic fusion paradigms. This often results in indiscriminate incorporation of multimodal signals and insufficient control over task-irrelevant redundancy, which may in turn limit generalization. We revisit MIE from a task-centric view: text should dominate, vision should selectively support. We present OTCR, a two-stage framework. First, Cross-modal Optimal Transport (OT) yields sparse, probabilistic alignments between text tokens and visual patches, with a context-aware gate controlling visual injection. Second, a Variational Information Bottleneck (VIB) compresses fused features, filtering task-irrelevant noise to produce compact, task-adaptive representations. On FUNSD, OTCR achieves 91.95% SER and 91.13% RE, while on XFUND (ZH), it reaches 91.09% SER and 94.20% RE, demonstrating competitive performance across datasets. Feature-level analyses further confirm reduced modality redundancy and strengthened task signals. This work offers an interpretable, information-theoretic paradigm for controllable multimodal fusion in document AI."}
{"id": "2511.14849", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.14849", "abs": "https://arxiv.org/abs/2511.14849", "authors": ["Adeel Mahmood", "Aaron B. Wagner"], "title": "Channel Coding for Gaussian Channels with Multifaceted Power Constraints", "comment": null, "summary": "Motivated by refined asymptotic results based on the normal approximation, we study how higher-order coding performance depends on the mean power $Γ$ as well as on finer statistics of the input power. We introduce a multifaceted power model in which the expectation of an arbitrary number of arbitrary functions of the normalized average power is constrained. The framework generalizes existing models, recovering the standard maximal and expected power constraints and the recent mean and variance constraint as special cases. Under certain growth and continuity assumptions on the functions, our main theorem gives an exact characterization of the minimum average error probability for Gaussian channels as a function of the first- and second-order coding rates. The converse proof reduces the code design problem to minimization over a compact (under the Prokhorov metric) set of probability distributions, characterizes the extreme points of this set and invokes the Bauer's maximization principle."}
{"id": "2511.14762", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.14762", "abs": "https://arxiv.org/abs/2511.14762", "authors": ["Yongye Su", "Yucheng Zhang", "Zeru Shi", "Bruno Ribeiro", "Elisa Bertino"], "title": "Castle: Causal Cascade Updates in Relational Databases with Large Language Models", "comment": null, "summary": "This work introduces Castle, the first framework for schema-only cascade update generation using large language models (LLMs). Despite recent advances in LLMs for Text2SQL code generation, existing approaches focus primarily on SELECT queries, neglecting the challenges of SQL update operations and their ripple effects. Traditional CASCADE UPDATE constraints are static and unsuitable for modern, denormalized databases, which demand dynamic, context-aware updates. Castle enables natural language instructions to trigger multi-column, causally consistent SQL UPDATE statements, without revealing table content to the model. By framing UPDATE SQL generation as a divide-and-conquer task with LLMs' reasoning capacity, Castle can determine not only which columns must be directly updated, but also how those updates propagate through the schema, causing cascading updates -- all via nested queries and substructures that ensure data confidentiality. We evaluate it on real-world causal update scenarios, demonstrating its ability to produce accurate SQL updates, and thereby highlighting the reasoning ability of LLMs in automated DBMS."}
{"id": "2511.14995", "categories": ["cs.GT", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.14995", "abs": "https://arxiv.org/abs/2511.14995", "authors": ["Naonori Kakimura", "Yoshihiko Terai"], "title": "Computing Power Indices in Weighted Majority Games with Formal Power Series", "comment": null, "summary": "In this paper, we propose fast pseudo-polynomial-time algorithms for computing power indices in weighted majority games. We show that we can compute the Banzhaf index for all players in $O(n+q\\log (q))$ time, where $n$ is the number of players and $q$ is a given quota. Moreover, we prove that the Shapley--Shubik index for all players can be computed in $O(nq\\log (q))$ time. Our algorithms are faster than existing algorithms when $q=2^{o(n)}$. Our algorithms exploit efficient computation techniques for formal power series."}
{"id": "2511.15266", "categories": ["cs.MM", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15266", "abs": "https://arxiv.org/abs/2511.15266", "authors": ["Liangyu Chen", "Yichen Xu", "Jianzhe Ma", "Yuqi Liu", "Donglu Yang", "Liang Zhang", "Wenxuan Wang", "Qin Jin"], "title": "ChartEditor: A Reinforcement Learning Framework for Robust Chart Editing", "comment": "Accept to AAAI 2026 Main Track", "summary": "Chart editing reduces manual effort in visualization design. Typical benchmarks limited in data diversity and assume access to complete chart code, which is seldom in real-world scenarios. To address this gap, we present ChartEditVista, a comprehensive benchmark consisting of 7,964 samples spanning 31 chart categories. It encompasses diverse editing instructions and covers nearly all editable chart elements. The inputs in ChartEditVista include only the original chart image and natural language editing instructions, without the original chart codes. ChartEditVista is generated through a fully automated pipeline that produces, edits, and verifies charts, ensuring high-quality chart editing data. Besides, we introduce two novel fine-grained, rule-based evaluation metrics: the layout metric, which evaluates the position, size and color of graphical components; and the text metric, which jointly assesses textual content and font styling. Building on top of ChartEditVista, we present ChartEditor, a model trained using a reinforcement learning framework that incorporates a novel rendering reward to simultaneously enforce code executability and visual fidelity. Through extensive experiments and human evaluations, we demonstrate that ChartEditVista provides a robust evaluation, while ChartEditor consistently outperforms models with similar-scale and larger-scale on chart editing tasks."}
{"id": "2511.14882", "categories": ["cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14882", "abs": "https://arxiv.org/abs/2511.14882", "authors": ["Michael T. Goodrich", "Songyu Liu", "Ioannis Panageas"], "title": "Exact Learning of Weighted Graphs Using Composite Queries", "comment": "Full version of the paper published at IWOCA 2025", "summary": "In this paper, we study the exact learning problem for weighted graphs, where we are given the vertex set, $V$, of a weighted graph, $G=(V,E,w)$, but we are not given $E$. The problem, which is also known as graph reconstruction, is to determine all the edges of $E$, including their weights, by asking queries about $G$ from an oracle. As we observe, using simple shortest-path length queries is not sufficient, in general, to learn a weighted graph. So we study a number of scenarios where it is possible to learn $G$ using a subquadratic number of composite queries, which combine two or three simple queries."}
{"id": "2511.14767", "categories": ["cs.IR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.14767", "abs": "https://arxiv.org/abs/2511.14767", "authors": ["Minh-Thuan Nguyen", "Thien Vo-Thanh", "Thai-Duy Dinh", "Xuan-Quang Phan", "Tan-Ha Mai", "Lam-Son Lê"], "title": "An LLM-Powered Agent for Real-Time Analysis of the Vietnamese IT Job Market", "comment": "Accepted at ACOMPA 2025", "summary": "Individuals entering Vietnam's dynamic Information Technology (IT) job market face a critical gap in reliable career guidance. Existing market reports are often outdated, while the manual analysis of thousands of job postings is impractical for most. To address this challenge, we present the AI Job Market Consultant, a novel conversational agent that delivers deep, data-driven insights directly from the labor market in real-time. The foundation of our system is a custom-built dataset created via an automated pipeline that crawls job portals using Playwright and leverages the Large Language Model (LLM) to intelligently structure unstructured posting data. The core of our system is a tool-augmented AI agent, based on the ReAct agentic framework, which enables the ability of autonomously reasoning, planning, and executing actions through a specialized toolbox for SQL queries, semantic search, and data visualization. Our prototype successfully collected and analyzed 3,745 job postings, demonstrating its ability to answer complex, multi-step queries, generate on-demand visualizations, and provide personalized career advice grounded in real-world data. This work introduces a new paradigm for labor market analysis, showcasing how specialized agentic AI systems can democratize access to timely, trustworthy career intelligence for the next generation of professionals."}
{"id": "2511.14906", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.14906", "abs": "https://arxiv.org/abs/2511.14906", "authors": ["Yasser Al Eryani"], "title": "Beyond the \"G\" Frontier: A Time Traveler's Century-Long Vision for Wireless Intelligence", "comment": null, "summary": "This article travels one century into the future--from 2025 to 2125--through the analytical lens of the Information--Curvature Efficiency Law (ICEL). It contends that wireless evolution will not proceed through incremental generations such as 6G or 7G, but through a curvature-managed integration of electromagnetics, biology, thermodynamics, and cognition. The resulting infrastructure will constitute a global ecology of self-aware information flow, where geometry and communication converge to sustain both technological and biological life."}
{"id": "2511.15090", "categories": ["cs.DB", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.15090", "abs": "https://arxiv.org/abs/2511.15090", "authors": ["Wenhan Yu", "Wang Chen", "Guanqiang Qi", "Weikang Li", "Yang Li", "Lei Sha", "Deguo Xia", "Jizhou Huang"], "title": "BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning in Document Visual Question Answer", "comment": "22 pages, 4 figures", "summary": "Document Visual Question Answering (DocVQA) is a fundamental task for multimodal document understanding and a key testbed for vision language reasoning. However, most existing DocVQA datasets are limited to the page level and lack fine grained spatial grounding, constraining the interpretability and reasoning capability of Vision Language Models (VLMs). To address this gap, we introduce BBox DocVQA a large scale, bounding box grounded dataset designed to enhance spatial reasoning and evidence localization in visual documents. We further present an automated construction pipeline, Segment Judge and Generate, which integrates a segment model for region segmentation, a VLM for semantic judgment, and another advanced VLM for question answer generation, followed by human verification for quality assurance. The resulting dataset contains 3.6 K diverse documents and 32 K QA pairs, encompassing single and multi region as well as single and multi page scenarios. Each QA instance is grounded on explicit bounding boxes, enabling fine grained evaluation of spatial semantic alignment. Benchmarking multiple state of the art VLMs (e.g., GPT 5, Qwen2.5 VL, and InternVL) on BBox DocVQA reveals persistent challenges in spatial grounding and reasoning accuracy. Furthermore, fine tuning on BBox DocVQA substantially improves both bounding box localization and answer generation, validating its effectiveness for enhancing the reasoning ability of VLMs. Our dataset and code will be publicly released to advance research on interpretable and spatially grounded vision language reasoning."}
{"id": "2511.15441", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.15441", "abs": "https://arxiv.org/abs/2511.15441", "authors": ["Michele Aleandri", "Marco Dall'Aglio"], "title": "Coopetitive Index: a measure of cooperation and competition in coalition formation", "comment": "18 pages, No figures", "summary": "We extend the coopetition index introduced by Aleandri and Dall'Aglio (2025) for simple games to the broader class of monotone transferable utility (TU) games and to all non-empty coalitions, including singletons. The new formulation allows us to define an absolute coopetition index with a universal range in [-1,1], facilitating meaningful comparisons across coalitions.\n  We study several notable instances of the index, including the Banzhaf, Uniform Shapley, and Shapley-Owen coopetition indices, and we derive explicit formulas that connect coopetition to classical semivalues. Finally, we provide axiomatic characterizations of the Uniform Shapley and Shaple--Owen versions, showing that each is uniquely determined by linearity, symmetry over pure bargaining games, external null player neutrality, and a contraction axiom reflecting its internal distribution. These results position the coopetition index as a versatile tool for quantifying the cooperative and competitive tendencies of coalitions in TU-games."}
{"id": "2511.14766", "categories": ["cs.IR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.14766", "abs": "https://arxiv.org/abs/2511.14766", "authors": ["Yang Li", "Yajiao Wang", "Wenhao Hu", "Zhixiong Zhang", "Mengting Zhang"], "title": "OTCR: Optimal Transmission, Compression and Representation for Multimodal Information Extraction", "comment": "5 pages, 3 figures", "summary": "Multimodal Information Extraction (MIE) requires fusing text and visual cues from visually rich documents. While recent methods have advanced multimodal representation learning, most implicitly assume modality equivalence or treat modalities in a largely uniform manner, still relying on generic fusion paradigms. This often results in indiscriminate incorporation of multimodal signals and insufficient control over task-irrelevant redundancy, which may in turn limit generalization. We revisit MIE from a task-centric view: text should dominate, vision should selectively support. We present OTCR, a two-stage framework. First, Cross-modal Optimal Transport (OT) yields sparse, probabilistic alignments between text tokens and visual patches, with a context-aware gate controlling visual injection. Second, a Variational Information Bottleneck (VIB) compresses fused features, filtering task-irrelevant noise to produce compact, task-adaptive representations. On FUNSD, OTCR achieves 91.95% SER and 91.13% RE, while on XFUND (ZH), it reaches 91.09% SER and 94.20% RE, demonstrating competitive performance across datasets. Feature-level analyses further confirm reduced modality redundancy and strengthened task signals. This work offers an interpretable, information-theoretic paradigm for controllable multimodal fusion in document AI."}
{"id": "2511.14955", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2511.14955", "abs": "https://arxiv.org/abs/2511.14955", "authors": ["Ryan R. Curtin", "Fred Lu", "Edward Raff", "Priyanka Ranade"], "title": "Intermediate N-Gramming: Deterministic and Fast N-Grams For Large N and Large Datasets", "comment": "AAAI 2026", "summary": "The number of n-gram features grows exponentially in n, making it computationally demanding to compute the most frequent n-grams even for n as small as 3. Motivated by our production machine learning system built on n-gram features, we ask: is it possible to accurately, deterministically, and quickly recover the top-k most frequent n-grams? We devise a multi-pass algorithm called Intergrams that constructs candidate n-grams from the preceding (n - 1)-grams. By designing this algorithm with hardware in mind, our approach yields more than an order of magnitude speedup (up to 33x!) over the next known fastest algorithm, even when similar optimizations are applied to the other algorithm. Using the empirical power-law distribution over n-grams, we also provide theory to inform the efficacy of our multi-pass approach. Our code is available at https://github.com/rcurtin/Intergrams."}
{"id": "2511.14768", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14768", "abs": "https://arxiv.org/abs/2511.14768", "authors": ["Bhavika Jain", "Robert Pitsko", "Ananya Drishti", "Mahfuza Farooque"], "title": "Causally-Informed Reinforcement Learning for Adaptive Emotion-Aware Social Media Recommendation", "comment": null, "summary": "Social media recommendation systems play a central role in shaping users' emotional experiences. However, most systems are optimized solely for engagement metrics, such as click rate, viewing time, or scrolling, without accounting for users' emotional states. Repeated exposure to emotionally charged content has been shown to negatively affect users' emotional well-being over time. We propose an Emotion-aware Social Media Recommendation (ESMR) framework that personalizes content based on users' evolving emotional trajectories. ESMR integrates a Transformer-based emotion predictor with a hybrid recommendation policy: a LightGBM model for engagement during stable periods and a reinforcement learning agent with causally informed rewards when negative emotional states persist. Through behaviorally grounded evaluation over 30-day interaction traces, ESMR demonstrates improved emotional recovery, reduced volatility, and strong engagement retention. ESMR offers a path toward emotionally aware recommendations without compromising engagement performance."}
{"id": "2511.15041", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15041", "abs": "https://arxiv.org/abs/2511.15041", "authors": ["Jingchen Peng", "Chaowen Deng", "Yili Deng", "Boxiang Ren", "Lu Yang"], "title": "Hyper-VIB: A Hypernetwork-Enhanced Information Bottleneck Approach for Task-Oriented Communications", "comment": null, "summary": "This paper presents Hyper-VIB, a hypernetwork-enhanced information bottleneck (IB) approach designed to enable efficient task-oriented communications in 6G collaborative intelligent systems. Leveraging IB theory, our approach enables an optimal end-to-end joint training of device and network models, in terms of the maximal task execution accuracy as well as the minimal communication overhead, through optimizing the trade-off hyperparameter. To address computational intractability in high-dimensional IB optimization, a tractable variational upper-bound approximation is derived. Unlike conventional grid or random search methods that require multiple training rounds with substantial computational costs, Hyper-VIB introduces a hypernetwork that generates approximately optimal DNN parameters for different values of the hyperparameter within a single training phase. Theoretical analysis in the linear case validates the hypernetwork design. Experimental results demonstrate our Hyper-VIB's superior accuracy and training efficiency over conventional VIB approaches in both classification and regression tasks."}
{"id": "2511.15557", "categories": ["cs.DB", "cs.AI", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.15557", "abs": "https://arxiv.org/abs/2511.15557", "authors": ["Selim Furkan Tekin", "Rajesh Bordawekar"], "title": "B+ANN: A Fast Billion-Scale Disk-based Nearest-Neighbor Index", "comment": null, "summary": "Storing and processing of embedding vectors by specialized Vector databases (VDBs) has become the linchpin in building modern AI pipelines. Most current VDBs employ variants of a graph-based ap- proximate nearest-neighbor (ANN) index algorithm, HNSW, to an- swer semantic queries over stored vectors. Inspite of its wide-spread use, the HNSW algorithm suffers from several issues: in-memory design and implementation, random memory accesses leading to degradation in cache behavior, limited acceleration scope due to fine-grained pairwise computations, and support of only semantic similarity queries. In this paper, we present a novel disk-based ANN index, B+ANN, to address these issues: it first partitions input data into blocks containing semantically similar items, then builds an B+ tree variant to store blocks both in-memory and on disks, and finally, enables hybrid edge- and block-based in-memory traversals. As demonstrated by our experimantal evaluation, the proposed B+ANN disk-based index improves both quality (Recall value), and execution performance (Queries per second/QPS) over HNSW, by improving spatial and temporal locality for semantic operations, reducing cache misses (19.23% relative gain), and decreasing the memory consumption and disk-based build time by 24x over the DiskANN algorithm. Finally, it enables dissimilarity queries, which are not supported by similarity-oriented ANN indices."}
{"id": "2511.15606", "categories": ["cs.GT", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.15606", "abs": "https://arxiv.org/abs/2511.15606", "authors": ["Huan Peng", "Guanpu Chen", "Karl Henrik Johansson"], "title": "A Scenario Approach to the Robustness of Nonconvex-Nonconcave Minimax Problems", "comment": null, "summary": "This paper investigates probabilistic robustness of nonconvex-nonconcave minimax problems via the scenario approach. Inspired by recent advances in scenario optimization (Garatti and Campi, 2025), we obtain robustness results for key equilibria with nonconvex-nonconcave payoffs, overcoming the dependence on the non-degeneracy assumption. Specifically, under convex strategy sets for all players, we first establish a probabilistic robustness guarantee for an epsilon-stationary point by proving the monotonicity of the stationary residual in the number of scenarios. Moreover, under nonconvex strategy sets for all players, we derive a probabilistic robustness guarantee for a global minimax point by invoking the extreme value theorem and Berge's maximum theorem. A numerical experiment on a unit commitment problem corroborates our theoretical findings."}
{"id": "2511.14975", "categories": ["cs.DS", "cs.CG", "math.CO"], "pdf": "https://arxiv.org/pdf/2511.14975", "abs": "https://arxiv.org/abs/2511.14975", "authors": ["Sergio Cabello", "Alexander Dobler", "Gašper Fijavž", "Thekla Hamm", "Mirko H. Wagner"], "title": "A Dichotomy for 1-Planarity with Restricted Crossing Types Parameterized by Treewidth", "comment": "35 pages, 17 figures; preliminary version to be presented at ISAAC 2025", "summary": "A drawing of a graph is 1-planar if each edge participates in at most one crossing and adjacent edges do not cross. Up to symmetry, each crossing in a 1-planar drawing belongs to one out of six possible crossing types, where a type characterizes the subgraph induced by the four vertices of the crossing edges. Each of the 63 possible nonempty subsets $\\mathcal{S}$ of crossing types gives a recognition problem: does a given graph admit an $\\mathcal{S}$-restricted drawing, that is, a 1-planar drawing where the crossing type of each crossing is in $\\mathcal{S}$?\n  We show that there is a set $\\mathcal{S}_{\\rm bad}$ with three crossing types and the following properties: If $\\mathcal{S}$ contains no crossing type from $\\mathcal{S}_{\\rm bad}$, then the recognition of graphs that admit an $\\mathcal{S}$-restricted drawing is fixed-parameter tractable with respect to the treewidth of the input graph. If $\\mathcal{S}$ contains any crossing type from $\\mathcal{S}_{\\rm bad}$, then it is NP-hard to decide whether a graph has an $\\mathcal{S}$-restricted drawing, even when considering graphs of constant pathwidth.\n  We also extend this characterization of crossing types to 1-planar straight-line drawings and show the same complexity behaviour parameterized by treewidth."}
{"id": "2511.14769", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14769", "abs": "https://arxiv.org/abs/2511.14769", "authors": ["Yifan Xu", "Vipul Gupta", "Rohit Aggarwal", "Varsha Mahadevan", "Bhaskar Krishnamachari"], "title": "Cluster-based Adaptive Retrieval: Dynamic Context Selection for RAG Applications", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by pulling in external material, document, code, manuals, from vast and ever-growing corpora, to effectively answer user queries. The effectiveness of RAG depends significantly on aligning the number of retrieved documents with query characteristics: narrowly focused queries typically require fewer, highly relevant documents, whereas broader or ambiguous queries benefit from retrieving more extensive supporting information. However, the common static top-k retrieval approach fails to adapt to this variability, resulting in either insufficient context from too few documents or redundant information from too many. Motivated by these challenges, we introduce Cluster-based Adaptive Retrieval (CAR), an algorithm that dynamically determines the optimal number of documents by analyzing the clustering patterns of ordered query-document similarity distances. CAR detects the transition point within similarity distances, where tightly clustered, highly relevant documents shift toward less pertinent candidates, establishing an adaptive cut-off that scales with query complexity. On Coinbase's CDP corpus and the public MultiHop-RAG benchmark, CAR consistently picks the optimal retrieval depth and achieves the highest TES score, outperforming every fixed top-k baseline. In downstream RAG evaluations, CAR cuts LLM token usage by 60%, trims end-to-end latency by 22%, and reduces hallucinations by 10% while fully preserving answer relevance. Since integrating CAR into Coinbase's virtual assistant, we've seen user engagement jump by 200%."}
{"id": "2511.15051", "categories": ["cs.IT", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.15051", "abs": "https://arxiv.org/abs/2511.15051", "authors": ["Pengcheng Su", "Haibo Cheng", "Ping Wang"], "title": "Mutual Information Bounds in the Shuffle Model", "comment": null, "summary": "The shuffle model enhances privacy by anonymizing users' reports through random permutation. This paper presents the first systematic study of the single-message shuffle model from an information-theoretic perspective. We analyze two regimes: the shuffle-only setting, where each user directly submits its message ($Y_i=X_i$), and the shuffle-DP setting, where each user first applies a local $\\varepsilon_0$-differentially private mechanism before shuffling ($Y_i=\\mathcal{R}(X_i)$). Let $\\boldsymbol{Z} = (Y_{σ(i)})_i$ denote the shuffled sequence produced by a uniformly random permutation $σ$, and let $K = σ^{-1}(1)$ represent the position of user 1's message after shuffling.\n  For the shuffle-only setting, we focus on a tractable yet expressive \\emph{basic configuration}, where the target user's message follows $Y_1 \\sim P$ and the remaining users' messages are i.i.d.\\ samples from $Q$, i.e., $Y_2,\\dots,Y_n \\sim Q$. We derive asymptotic expressions for the mutual information quantities $I(Y_1;\\boldsymbol{Z})$ and $I(K;\\boldsymbol{Z})$ as $n \\to \\infty$, and demonstrate how this analytical framework naturally extends to settings with heterogeneous user distributions.\n  For the shuffle-DP setting, we establish information-theoretic upper bounds on total information leakage. When each user applies an $\\varepsilon_0$-DP mechanism, the overall leakage satisfies $I(K; \\boldsymbol{Z}) \\le 2\\varepsilon_0$ and $I(X_1; \\boldsymbol{Z}\\mid (X_i)_{i=2}^n) \\le (e^{\\varepsilon_0}-1)/(2n) + O(n^{-3/2})$. These results bridge shuffle differential privacy and mutual-information-based privacy."}
{"id": "2511.15585", "categories": ["cs.DB", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.15585", "abs": "https://arxiv.org/abs/2511.15585", "authors": ["Eugene Wu", "Yiru Chen", "Haneen Mohammed", "Zezhou Huang"], "title": "A Decade of Systems for Human Data Interaction", "comment": null, "summary": "Human-data interaction (HDI) presents fundamentally different challenges from traditional data management. HDI systems must meet latency, correctness, and consistency needs that stem from usability rather than query semantics; failing to meet these expectations breaks the user experience. Moreover, interfaces and systems are tightly coupled; neither can easily be optimized in isolation, and effective solutions demand their co-design. This dependence also presents a research opportunity: rather than adapt systems to interface demands, systems innovations and database theory can also inspire new interaction and visualization designs. We survey a decade of our lab's work that embraces this coupling and argue that HDI systems are the foundation for reliable, interactive, AI-driven applications."}
{"id": "2511.15142", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2511.15142", "abs": "https://arxiv.org/abs/2511.15142", "authors": ["Vincent Cohen-Addad", "Tommaso d'Orsi", "Anupam Gupta", "Guru Guruganesh", "Euiwoong Lee", "Debmalya Panigrahi", "Madhusudhan Reddy Pittu", "Jon Schneider", "David P. Woodruff"], "title": "Combinatorial Optimization using Comparison Oracles", "comment": null, "summary": "In a linear combinatorial optimization problem, we are given a family $\\mathcal{F} \\subseteq 2^U$ of feasible subsets of a ground set $U$ of $n$ elements, and aim to find $S^* = \\arg\\min_{S \\in \\mathcal{F}} \\langle w, \\mathbbm{1}_S \\rangle$. Traditionally, the weight vector is given, or a value oracle allows evaluating $w(S) := \\langle w, \\mathbbm{1}_S \\rangle$. Motivated by practical interest in pairwise comparisons, and by the theoretical quest to understand computational models, we study a weaker, more robust comparison oracle that for any $S, T \\in \\mathcal{F}$ reveals only whether $w(S) <, =, > w(T)$. We ask: when can we find $S^*$ using few comparison queries, and when can this be done efficiently?\n  We present three contributions: (1) We establish that the query complexity over any set system $\\mathcal{F} \\subseteq 2^U$ is $\\tilde O(n^2)$, using the inference dimension framework, highlighting a separation between information and computational complexity (runtime may still be exponential for NP-hard problems under ETH). (2) We introduce a Global Subspace Learning (GSL) framework for objective functions with discrete integer weights bounded by $B$, giving an algorithm to sort all feasible sets using $O(nB \\log(nB))$ queries, improving the $\\tilde O(n^2)$ bound when $B = o(n)$. For linear matroids, algebraic techniques yield efficient algorithms for problems including $k$-SUM, SUBSET-SUM, and $A{+}B$ sorting. (3) We give the first polynomial-time, low-query algorithms for classic combinatorial problems: minimum cuts, minimum weight spanning trees (and matroid bases), bipartite matching (and matroid intersection), and shortest $s$-$t$ paths.\n  Our work provides the first general query complexity bounds and efficient algorithms for this model, opening new directions for comparison-based optimization."}
{"id": "2511.14770", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14770", "abs": "https://arxiv.org/abs/2511.14770", "authors": ["Bo Ma", "LuYao Liu", "ZeHua Hu", "Simon Lau"], "title": "ExplainRec: Towards Explainable Multi-Modal Zero-Shot Recommendation with Preference Attribution and Large Language Models", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have opened new possibilities for recommendation systems, though current approaches such as TALLRec face challenges in explainability and cold-start scenarios. We present ExplainRec, a framework that extends LLM-based recommendation capabilities through preference attribution, multi-modal fusion, and zero-shot transfer learning. The framework incorporates four technical contributions: preference attribution tuning for explainable recommendations, zero-shot preference transfer for cold-start users and items, multi-modal enhancement leveraging visual and textual content, and multi-task collaborative optimization. Experimental evaluation on MovieLens-25M and Amazon datasets shows that ExplainRec outperforms existing methods, achieving AUC improvements of 0.7\\% on movie recommendation and 0.9\\% on cross-domain tasks, while generating interpretable explanations and handling cold-start scenarios effectively."}
{"id": "2511.15207", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15207", "abs": "https://arxiv.org/abs/2511.15207", "authors": ["Chaofeng Guan", "Gaojun Luo", "Lan Luo", "Yangyang Fei", "Hong Wang"], "title": "Generalized Repetition Codes and Their Application to HARQ", "comment": "15 pages, 5 figures", "summary": "The inherent uncertainty of communication channels implies that any coding scheme has a non-zero probability of failing to correct errors, making retransmission mechanisms essential. To ensure message reliability and integrity, a dual-layer redundancy framework is typically employed: error correction codes mitigate noise-induced impairments at the physical layer, while cyclic redundancy checks verify message integrity after decoding. Retransmission is initiated if verification fails. This operational model can be categorized into two types of repeated communication models: Type-I systems repeatedly transmit identical codewords, whereas Type-II systems transmit distinct coded representations of the same message. The core challenge lies in maximizing the probability of correct message decoding within a limited number of transmission rounds through verification-based feedback mechanisms.\n  In this paper, we consider a scenario where the same error-correcting code is used for repeated transmissions, and we specifically propose two classes of generalized repetition codes (GRCs), corresponding to the two repeated communication models. In contrast to classical theory, we regard GRCs as error-correcting codes under multiple metrics--that is, GRCs possess multiple minimum distances. This design enables GRCs to perform multi-round error correction under different metrics, achieving stronger error-correction capabilities than classical error-correcting codes. However, the special structure of GRCs makes their construction more challenging, as it requires simultaneously optimizing multiple minimum distances. To address this, we separately investigate the bounds and constructions for Type-I and Type-II GRCs, and obtain numerous optimal Type-I and Type-II GRCs."}
{"id": "2511.15623", "categories": ["cs.DB", "cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.15623", "abs": "https://arxiv.org/abs/2511.15623", "authors": ["Leopoldo Bertossi", "Nina Pardal"], "title": "Sufficient Explanations in Databases and their Connections to Necessary Explanations and Repairs", "comment": null, "summary": "The notion of cause, as formalized by Halpern and Pearl, has been recently applied to relational databases, to characterize and compute causal explanations for query answers. In this work we consider the alternative notion of sufficient explanation. We investigate its connections with database repairs as used for dealing with inconsistent databases, and with causality-based necessary explanations. We also obtain some computational results."}
{"id": "2511.15460", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2511.15460", "abs": "https://arxiv.org/abs/2511.15460", "authors": ["Tijn de Vos", "Mara Grilnberger"], "title": "Dynamic Matroids: Base Packing and Covering", "comment": null, "summary": "In this paper, we consider dynamic matroids, where elements can be inserted to or deleted from the ground set over time. The independent sets change to reflect the current ground set. As matroids are central to the study of many combinatorial optimization problems, it is a natural next step to also consider them in a dynamic setting. The study of dynamic matroids has the potential to generalize several dynamic graph problems, including, but not limited to, arboricity and maximum bipartite matching. We contribute by providing efficient algorithms for some fundamental matroid questions.\n  In particular, we study the most basic question of maintaining a base dynamically, providing an essential building block for future algorithms. We further utilize this result and consider the elementary problems of base packing and base covering. We provide a deterministic algorithm that maintains a $(1\\pm \\varepsilon)$-approximation of the base packing number $Φ$ in $O(Φ\\cdot \\text{poly}(\\log n, \\varepsilon^{-1}))$ queries per update. Similarly, we provide a deterministic algorithm that maintains a $(1\\pm \\varepsilon)$-approximation of the base covering number $β$ in $O(β\\cdot \\text{poly}(\\log n, \\varepsilon^{-1}))$ queries per update. Moreover, we give an algorithm that maintains a $(1\\pm \\varepsilon)$-approximation of the base covering number $β$ in $O(\\text{poly}(\\log n, \\varepsilon^{-1}))$ queries per update against an oblivious adversary.\n  These results are obtained by exploring the relationship between base collections, a generalization of tree-packings, and base packing and covering respectively. We provide structural theorems to formalize these connections, and show how they lead to simple dynamic algorithms."}
{"id": "2511.14881", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.14881", "abs": "https://arxiv.org/abs/2511.14881", "authors": ["Bi Xue", "Hong Wu", "Lei Chen", "Chao Yang", "Yiming Ma", "Fei Ding", "Zhen Wang", "Liang Wang", "Xiaoheng Mao", "Ke Huang", "Xialu Li", "Peng Xia", "Rui Jian", "Yanli Zhao", "Yanzun Huang", "Yijie Deng", "Harry Tran", "Ryan Chang", "Min Yu", "Eric Dong", "Jiazhou Wang", "Qianqian Zhang", "Keke Zhai", "Hongzhang Yin", "Pawel Garbacki", "Zheng Fang", "Yiyi Pan", "Min Ni", "Yang Liu"], "title": "SilverTorch: A Unified Model-based System to Democratize Large-Scale Recommendation on GPUs", "comment": null, "summary": "Serving deep learning based recommendation models (DLRM) at scale is challenging. Existing systems rely on CPU-based ANN indexing and filtering services, suffering from non-negligible costs and forgoing joint optimization opportunities. Such inefficiency makes them difficult to support more complex model architectures, such as learned similarities and multi-task retrieval.\n  In this paper, we propose SilverTorch, a model-based system for serving recommendation models on GPUs. SilverTorch unifies model serving by replacing standalone indexing and filtering services with layers of served models. We propose a Bloom index algorithm on GPUs for feature filtering and a tensor-native fused Int8 ANN kernel on GPUs for nearest neighbor search. We further co-design the ANN search index and filtering index to reduce GPU memory utilization and eliminate unnecessary computation. Benefit from SilverTorch's serving paradigm, we introduce a OverArch scoring layer and a Value Model to aggregate results across multi-tasks. These advancements improve the accuracy for retrieval and enable future studies for serving more complex models. For ranking, SilverTorch's design accelerates item embedding calculation by caching the pre-calculated embeddings inside the serving model.\n  Our evaluation on the industry-scale datasets show that SilverTorch achieves up to 5.6x lower latency and 23.7x higher throughput compared to the state-of-the-art approaches. We also demonstrate that SilverTorch's solution is 13.35x more cost-efficient than CPU-based solution while improving accuracy via serving more complex models. SilverTorch serves over hundreds of models online across major products and recommends contents for billions of daily active users."}
{"id": "2511.15255", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15255", "abs": "https://arxiv.org/abs/2511.15255", "authors": ["Yassine Hamdi", "Aaron B. Wagner", "Deniz Gündüz"], "title": "The Rate-Distortion-Perception Trade-Off with Algorithmic Realism", "comment": null, "summary": "Realism constraints (or constraints on perceptual quality) have received considerable recent attention within the context of lossy compression, particularly of images. Theoretical studies of lossy compression indicate that high-rate common randomness between the compressor and the decompressor is a valuable resource for achieving realism. On the other hand, the utility of significant amounts of common randomness has not been noted in practice. We offer an explanation for this discrepancy by considering a realism constraint that requires satisfying a universal critic that inspects realizations of individual compressed reconstructions, or batches thereof. We characterize the optimal rate-distortion trade-off under such a realism constraint, and show that it is asymptotically achievable without any common randomness, unless the batch size is impractically large."}
{"id": "2511.14995", "categories": ["cs.GT", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.14995", "abs": "https://arxiv.org/abs/2511.14995", "authors": ["Naonori Kakimura", "Yoshihiko Terai"], "title": "Computing Power Indices in Weighted Majority Games with Formal Power Series", "comment": null, "summary": "In this paper, we propose fast pseudo-polynomial-time algorithms for computing power indices in weighted majority games. We show that we can compute the Banzhaf index for all players in $O(n+q\\log (q))$ time, where $n$ is the number of players and $q$ is a given quota. Moreover, we prove that the Shapley--Shubik index for all players can be computed in $O(nq\\log (q))$ time. Our algorithms are faster than existing algorithms when $q=2^{o(n)}$. Our algorithms exploit efficient computation techniques for formal power series."}
{"id": "2511.15122", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15122", "abs": "https://arxiv.org/abs/2511.15122", "authors": ["Fuwei Zhang", "Xiaoyu Liu", "Dongbo Xi", "Jishen Yin", "Huan Chen", "Peng Yan", "Fuzhen Zhuang", "Zhao Zhang"], "title": "Multi-Aspect Cross-modal Quantization for Generative Recommendation", "comment": "Accepted by AAAI 2026 (Oral)", "summary": "Generative Recommendation (GR) has emerged as a new paradigm in recommender systems. This approach relies on quantized representations to discretize item features, modeling users' historical interactions as sequences of discrete tokens. Based on these tokenized sequences, GR predicts the next item by employing next-token prediction methods. The challenges of GR lie in constructing high-quality semantic identifiers (IDs) that are hierarchically organized, minimally conflicting, and conducive to effective generative model training. However, current approaches remain limited in their ability to harness multimodal information and to capture the deep and intricate interactions among diverse modalities, both of which are essential for learning high-quality semantic IDs and for effectively training GR models. To address this, we propose Multi-Aspect Cross-modal quantization for generative Recommendation (MACRec), which introduces multimodal information and incorporates it into both semantic ID learning and generative model training from different aspects. Specifically, we first introduce cross-modal quantization during the ID learning process, which effectively reduces conflict rates and thus improves codebook usability through the complementary integration of multimodal information. In addition, to further enhance the generative ability of our GR model, we incorporate multi-aspect cross-modal alignments, including the implicit and explicit alignments. Finally, we conduct extensive experiments on three well-known recommendation datasets to demonstrate the effectiveness of our proposed method."}
{"id": "2511.15404", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15404", "abs": "https://arxiv.org/abs/2511.15404", "authors": ["Zizhen Zhou", "Ying-Chang Liang", "Yanyu Cheng", "Wei Yang Bryan Lim"], "title": "Communication-Pipelined Split Federated Learning for Foundation Model Fine-Tuning in UAV Networks", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Deploying foundation models (FMs) on uncrewed aerial vehicles (UAVs) promises broad ``low-altitude economy'' applications. Split federated learning (SFL)-based fine-tuning leverages distributed data while keeping raw data local and reduces client-side burden by partitioning the model between client and server. However, the per-round training latency is dominated by stragglers. Training paradigms featuring parallel gradient transmission (GT) allocate dedicated portions of downlink communication resources to each client. They may leave resources idle and suffer from prolonged GT latency, especially in UAV networks, where the communication latency typically far exceeds the computation latency. To address this, we propose a sequential GT paradigm, where the server dedicates all downlink resources for the current GT. We further propose communication-pipelined SFL (CPSFL), characterized by downlink GT priority scheduling and intra-round asynchronous training. We investigate CPSFL-based LoRA fine-tuning of FMs in UAV networks and formulate an optimization problem to minimize a weighted sum of per-round training latency and worst-case client energy consumption by optimizing the split point selection (SPS) and the computing and communication resource allocation (CCRA) (the uplink bandwidth allocation and the server computing frequency allocation). To solve this problem, we develop an attention-based deep reinforcement learning (DRL) framework, where the base station agent decides the split point and the CCRA in each round by leveraging previous round information, including UAV trajectories. Simulation results show that the proposed DRL-based CPSFL scheme outperforms the parallel GT benchmarks, the ablation variants, the fixed CCRA scheme, while approaching the best fixed-SPS scheme."}
{"id": "2511.15557", "categories": ["cs.DB", "cs.AI", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.15557", "abs": "https://arxiv.org/abs/2511.15557", "authors": ["Selim Furkan Tekin", "Rajesh Bordawekar"], "title": "B+ANN: A Fast Billion-Scale Disk-based Nearest-Neighbor Index", "comment": null, "summary": "Storing and processing of embedding vectors by specialized Vector databases (VDBs) has become the linchpin in building modern AI pipelines. Most current VDBs employ variants of a graph-based ap- proximate nearest-neighbor (ANN) index algorithm, HNSW, to an- swer semantic queries over stored vectors. Inspite of its wide-spread use, the HNSW algorithm suffers from several issues: in-memory design and implementation, random memory accesses leading to degradation in cache behavior, limited acceleration scope due to fine-grained pairwise computations, and support of only semantic similarity queries. In this paper, we present a novel disk-based ANN index, B+ANN, to address these issues: it first partitions input data into blocks containing semantically similar items, then builds an B+ tree variant to store blocks both in-memory and on disks, and finally, enables hybrid edge- and block-based in-memory traversals. As demonstrated by our experimantal evaluation, the proposed B+ANN disk-based index improves both quality (Recall value), and execution performance (Queries per second/QPS) over HNSW, by improving spatial and temporal locality for semantic operations, reducing cache misses (19.23% relative gain), and decreasing the memory consumption and disk-based build time by 24x over the DiskANN algorithm. Finally, it enables dissimilarity queries, which are not supported by similarity-oriented ANN indices."}
{"id": "2511.15141", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15141", "abs": "https://arxiv.org/abs/2511.15141", "authors": ["Sunwoo Kim", "Geon Lee", "Kyungho Kim", "Jaemin Yoo", "Kijung Shin"], "title": "ItemRAG: Item-Based Retrieval-Augmented Generation for LLM-Based Recommendation", "comment": null, "summary": "Recently, large language models (LLMs) have been widely used as recommender systems, owing to their strong reasoning capability and their effectiveness in handling cold-start items. To better adapt LLMs for recommendation, retrieval-augmented generation (RAG) has been incorporated. Most existing RAG methods are user-based, retrieving purchase patterns of users similar to the target user and providing them to the LLM. In this work, we propose ItemRAG, an item-based RAG method for LLM-based recommendation that retrieves relevant items (rather than users) from item-item co-purchase histories. ItemRAG helps LLMs capture co-purchase patterns among items, which are beneficial for recommendations. Especially, our retrieval strategy incorporates semantically similar items to better handle cold-start items and uses co-purchase frequencies to improve the relevance of the retrieved items. Through extensive experiments, we demonstrate that ItemRAG consistently (1) improves the zero-shot LLM-based recommender by up to 43% in Hit-Ratio-1 and (2) outperforms user-based RAG baselines under both standard and cold-start item recommendation settings."}
{"id": "2511.15555", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15555", "abs": "https://arxiv.org/abs/2511.15555", "authors": ["Yajun Zhao", "Mengnan Jian", "Yifei Yuan"], "title": "RIS-Enabled UAV Communications and Sensing: Opportunities, Challenges, and Key Technologies", "comment": "21 pages, 9 figures. Submitted to TCCN", "summary": "Unmanned Aerial Vehicles (UAVs) play a pivotal role in the emerging low-altitude economy. However, they face significant challenges in achieving reliable network coverage during transit operations. This paper provides an in-depth investigation into the characteristics and challenges of communication networks tailored for UAVs. First, we outline typical operational scenarios, traffic patterns, and a dual-layer heterogeneous network topology. This topology is essential for enabling three-dimensional continuous coverage and ensuring seamless network coexistence between UAVs and other network entities. Moreover, the paper delves into the channel characteristics and specific challenges faced by UAV Integrated Sensing and Communication (ISAC) networks. It highlights the limitations of traditional Active Phased Array Antenna (APAA)-based networks, particularly regarding cost, complexity, and site deployment constraints. We then introduce Reconfigurable Intelligent Surface (RIS)-assisted networks as a promising solution for enhancing UAV signal coverage. The key technical features of RIS are discussed, including design principles, antenna tilt configurations, new beam types, and beam tracking mechanisms. In addition, we examine the impact of highfrequency bands and their absorption peaks on signal attenuation. The paper further explores network architecture designs aimed at improving UAV signal coverage, facilitating network coexistence, and supporting RIS-enhanced UAV sensing. Field trial results evaluating the effectiveness of RIS in improving UAV coverage are presented. Finally, we outline future technological trends and highlight potential advancements to further optimize UAV communication systems. We also emphasize the importance of engineering implementation and standardization efforts in RIS-based UAV-ISAC networks."}
{"id": "2511.15241", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.15241", "abs": "https://arxiv.org/abs/2511.15241", "authors": ["Mi Tian", "Kun Zhang", "Fei Liu", "Jinglong Li", "Yuxin Liao", "Chenxi Bai", "Zhengtao Tan", "Le Wu", "Richang Hong"], "title": "Selective Mixup for Debiasing Question Selection in Computerized Adaptive Testing", "comment": "Accepted by CIKM 2025", "summary": "Computerized Adaptive Testing (CAT) is a widely used technology for evaluating learners' proficiency in online education platforms. By leveraging prior estimates of proficiency to select questions and updating the estimates iteratively based on responses, CAT enables personalized learner modeling and has attracted substantial attention. Despite this progress, most existing works focus primarily on improving diagnostic accuracy, while overlooking the selection bias inherent in the adaptive process. Selection Bias arises because the question selection is strongly influenced by the estimated proficiency, such as assigning easier questions to learners with lower proficiency and harder ones to learners with higher proficiency. Since the selection depends on prior estimation, this bias propagates into the diagnosis model, which is further amplified during iterative updates, leading to misalignment and biased predictions. Moreover, the imbalanced nature of learners' historical interactions often exacerbates the bias in diagnosis models. To address this issue, we propose a debiasing framework consisting of two key modules: Cross-Attribute Examinee Retrieval and Selective Mixup-based Regularization. First, we retrieve balanced examinees with relatively even distributions of correct and incorrect responses and use them as neutral references for biased examinees. Then, mixup is applied between each biased examinee and its matched balanced counterpart under label consistency. This augmentation enriches the diversity of bias-conflicting samples and smooths selection boundaries. Finally, extensive experiments on two benchmark datasets with multiple advanced diagnosis models demonstrate that our method substantially improves both the generalization ability and fairness of question selection in CAT."}
{"id": "2511.15671", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15671", "abs": "https://arxiv.org/abs/2511.15671", "authors": ["Mihir Rao"], "title": "Information Efficiency of Scientific Automation", "comment": null, "summary": "Scientific discovery can be framed as a thermodynamic process in which an agent invests physical work to acquire information about an environment under a finite work budget. Using established results about the thermodynamics of computing, we derive finite-budget bounds on information gain over rounds of sequential Bayesian learning. We also propose a metric of information-work efficiency, and compare unpartitioned and federated learning strategies under matched work budgets. The presented results offer guidance in the form of bounds and an information efficiency metric for efforts in scientific automation at large."}
{"id": "2511.15389", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.15389", "abs": "https://arxiv.org/abs/2511.15389", "authors": ["Suyu Chen", "Yimeng Bai", "Yulong Huang", "Xiaoyan Zhao", "Yang Zhang"], "title": "Unveiling Inference Scaling for Difference-Aware User Modeling in LLM Personalization", "comment": null, "summary": "Large Language Models (LLMs) are increasingly integrated into users' daily lives, driving a growing demand for personalized outputs. Prior work has primarily leveraged a user's own history, often overlooking inter-user differences that are critical for effective personalization. While recent methods have attempted to model such differences, their feature extraction processes typically rely on fixed dimensions and quick, intuitive inference (System-1 thinking), limiting both the coverage and granularity of captured user differences. To address these limitations, we propose Difference-aware Reasoning Personalization (DRP), a framework that reconstructs the difference extraction mechanism by leveraging inference scaling to enhance LLM personalization. DRP autonomously identifies relevant difference feature dimensions and generates structured definitions and descriptions, enabling slow, deliberate reasoning (System-2 thinking) over user differences. Experiments on personalized review generation demonstrate that DRP consistently outperforms baseline methods across multiple metrics."}
{"id": "2511.15443", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15443", "abs": "https://arxiv.org/abs/2511.15443", "authors": ["Ao Xie", "Jiahui Chen", "Quanzhi Zhu", "Xiaoze Jiang", "Zhiheng Qin", "Enyun Yu", "Han Li"], "title": "CroPS: Improving Dense Retrieval with Cross-Perspective Positive Samples in Short-Video Search", "comment": "AAAI-2026, Oral", "summary": "Dense retrieval has become a foundational paradigm in modern search systems, especially on short-video platforms. However, most industrial systems adopt a self-reinforcing training pipeline that relies on historically exposed user interactions for supervision. This paradigm inevitably leads to a filter bubble effect, where potentially relevant but previously unseen content is excluded from the training signal, biasing the model toward narrow and conservative retrieval. In this paper, we present CroPS (Cross-Perspective Positive Samples), a novel retrieval data engine designed to alleviate this problem by introducing diverse and semantically meaningful positive examples from multiple perspectives. CroPS enhances training with positive signals derived from user query reformulation behavior (query-level), engagement data in recommendation streams (system-level), and world knowledge synthesized by large language models (knowledge-level). To effectively utilize these heterogeneous signals, we introduce a Hierarchical Label Assignment (HLA) strategy and a corresponding H-InfoNCE loss that together enable fine-grained, relevance-aware optimization. Extensive experiments conducted on Kuaishou Search, a large-scale commercial short-video search platform, demonstrate that CroPS significantly outperforms strong baselines both offline and in live A/B tests, achieving superior retrieval performance and reducing query reformulation rates. CroPS is now fully deployed in Kuaishou Search, serving hundreds of millions of users daily."}
