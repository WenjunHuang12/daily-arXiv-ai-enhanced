<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 6]
- [cs.DB](#cs.DB) [Total: 6]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.DS](#cs.DS) [Total: 5]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.IT](#cs.IT) [Total: 9]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [On Recommending Category: A Cascading Approach](https://arxiv.org/abs/2512.16033)
*Qihao Wang,Pritom Saha Akash,Varvara Kollia,Kevin Chen-Chuan Chang,Biwei Jiang,Vadim Von Brzeski*

Main category: cs.IR

TL;DR: 提出CCRec模型，使用变分自编码器编码商品级信息进行品类级推荐，解决了现有方法简单套用商品级模型的不足


<details>
  <summary>Details</summary>
Motivation: 电商平台开始关注品类级推荐以拓展用户兴趣，现有方法简单套用商品级模型，忽略了商品级和品类级推荐的关键差异

Method: 提出级联品类推荐器(CCRec)模型，使用变分自编码器(VAE)编码商品级信息进行品类级推荐

Result: 实验表明该模型优于为商品级推荐设计的方法

Conclusion: CCRec模型能有效进行品类级推荐，解决了现有方法简单套用商品级模型的局限性

Abstract: Recommendation plays a key role in e-commerce, enhancing user experience and boosting commercial success. Existing works mainly focus on recommending a set of items, but online e-commerce platforms have recently begun to pay attention to exploring users' potential interests at the category level. Category-level recommendation allows e-commerce platforms to promote users' engagements by expanding their interests to different types of items. In addition, it complements item-level recommendations when the latter becomes extremely challenging for users with little-known information and past interactions. Furthermore, it facilitates item-level recommendations in existing works. The predicted category, which is called intention in those works, aids the exploration of item-level preference. However, such category-level preference prediction has mostly been accomplished through applying item-level models. Some key differences between item-level recommendations and category-level recommendations are ignored in such a simplistic adaptation. In this paper, we propose a cascading category recommender (CCRec) model with a variational autoencoder (VAE) to encode item-level information to perform category-level recommendations. Experiments show the advantages of this model over methods designed for item-level recommendations.

</details>


### [2] [The Evolution of Reranking Models in Information Retrieval: From Heuristic Methods to Large Language Models](https://arxiv.org/abs/2512.16236)
*Tejul Pandit,Sakshi Mahendru,Meet Raval,Dhvani Upadhyay*

Main category: cs.IR

TL;DR: 本文是对信息检索中重排序技术的全面综述，系统梳理了从传统方法到现代神经架构再到大语言模型的发展历程，特别关注了在RAG管道中的应用。


<details>
  <summary>Details</summary>
Motivation: 重排序是信息检索系统中的关键环节，能显著提升最终结果的相关性。随着检索增强生成(RAG)等现代技术的发展，重排序方法也在快速演进，需要对这一领域进行全面梳理，为研究者和实践者提供清晰的路线图。

Method: 采用历史发展脉络的综述方法：1) 从传统基础方法开始；2) 探索神经架构如交叉编码器、T5等序列生成模型和图神经网络；3) 分析效率优化技术如知识蒸馏；4) 研究大语言模型在重排序中的集成，包括提示策略和微调技术。

Result: 提供了重排序技术的结构化综合，阐明了不同方法的基本思想、相对有效性、计算特征和实际权衡。特别强调了在RAG管道中重排序对输出质量的重要影响。

Conclusion: 本文系统梳理了重排序技术的发展历程，为研究者和实践者提供了全面的技术路线图，有助于理解不同方法的原理、优势和局限性，推动信息检索系统重排序技术的进一步发展。

Abstract: Reranking is a critical stage in contemporary information retrieval (IR) systems, improving the relevance of the user-presented final results by honing initial candidate sets. This paper is a thorough guide to examine the changing reranker landscape and offer a clear view of the advancements made in reranking methods. We present a comprehensive survey of reranking models employed in IR, particularly within modern Retrieval Augmented Generation (RAG) pipelines, where retrieved documents notably influence output quality.
  We embark on a chronological journey through the historical trajectory of reranking techniques, starting with foundational approaches, before exploring the wide range of sophisticated neural network architectures such as cross-encoders, sequence-generation models like T5, and Graph Neural Networks (GNNs) utilized for structural information. Recognizing the computational cost of advancing neural rerankers, we analyze techniques for enhancing efficiency, notably knowledge distillation for creating competitive, lighter alternatives. Furthermore, we map the emerging territory of integrating Large Language Models (LLMs) in reranking, examining novel prompting strategies and fine-tuning tactics. This survey seeks to elucidate the fundamental ideas, relative effectiveness, computational features, and real-world trade-offs of various reranking strategies. The survey provides a structured synthesis of the diverse reranking paradigms, highlighting their underlying principles and comparative strengths and weaknesses.

</details>


### [3] [From Flows to Functions: Macroscopic Behavioral Fingerprinting of IoT Devices via Network Services](https://arxiv.org/abs/2512.16348)
*Shayan Azizi,Norihiro Okui,Masataka Nakahara,Ayumu Kubota,Hassan Habibi Gharakheili*

Main category: cs.IR

TL;DR: 提出一种基于网络服务使用模式的宏观、轻量级、可解释的IoT设备行为指纹识别方法，替代传统基于细粒度流量特征的机器学习方法


<details>
  <summary>Details</summary>
Motivation: 现有IoT设备识别方法依赖细粒度流量特征的机器学习，计算开销大、对测量误差敏感且推理不透明，需要更宏观、轻量、可解释的替代方案

Method: 基于IoT设备长期使用的网络服务模式（如TCP/80、UDP/53）构建服务级指纹，提出可配置粒度的通用表示方法，并在13种消费级IoT设备上进行验证

Result: IoT设备在网络服务使用上表现出稳定且可区分的模式，服务级指纹在封闭集和开放集场景下都能有效识别设备，基于1.5年收集的约1000万条IPFIX流记录验证

Conclusion: 服务级指纹提供了一种计算效率高、对测量误差鲁棒、可解释性强的IoT设备识别方法，为网络安全管理提供了实用工具

Abstract: Identifying devices such as cameras, printers, voice assistants, or health monitoring sensors, collectively known as the Internet of Things (IoT), within a network is a critical operational task, particularly to manage the cyber risks they introduce. While behavioral fingerprinting based on network traffic analysis has shown promise, most existing approaches rely on machine learning (ML) techniques applied to fine-grained features of short-lived traffic units (packets and/or flows). These methods tend to be computationally expensive, sensitive to traffic measurement errors, and often produce opaque inferences. In this paper, we propose a macroscopic, lightweight, and explainable alternative to behavioral fingerprinting focusing on the network services (e.g., TCP/80, UDP/53) that IoT devices use to perform their intended functions over extended periods. Our contributions are threefold. (1) We demonstrate that IoT devices exhibit stable and distinguishable patterns in their use of network services over a period of time. We formalize the notion of service-level fingerprints and derive a generalized method to represent network behaviors using a configurable granularity parameter. (2) We develop a procedure to extract service-level fingerprints, apply it to traffic from 13 consumer IoT device types in a lab testbed, and evaluate the resulting representations in terms of their convergence and recurrence properties. (3) We validate the efficacy of service-level fingerprints for device identification in closed-set and open-set scenarios. Our findings are based on a large dataset comprising about 10 million IPFIX flow records collected over a 1.5-year period.

</details>


### [4] [Introducing ORKG ASK: an AI-driven Scholarly Literature Search and Exploration System Taking a Neuro-Symbolic Approach](https://arxiv.org/abs/2512.16425)
*Allard Oelen,Mohamad Yaser Jaradeh,Sören Auer*

Main category: cs.IR

TL;DR: ASK是一个基于神经符号方法的AI驱动学术文献搜索与探索系统，结合向量搜索、大语言模型和知识图谱，通过RAG方法帮助研究者用自然语言提问并获取相关文献和答案。


<details>
  <summary>Details</summary>
Motivation: 随着学术文献数量不断增长，寻找相关文献变得越来越困难。生成式AI和大语言模型的兴起为文献发现和探索提供了新的可能性。

Method: 采用神经符号方法，结合向量搜索、大语言模型和知识图谱。系统允许用户用自然语言输入研究问题，使用检索增强生成（RAG）方法自动提取关键信息并生成答案。

Result: 对ASK系统进行了可用性和有用性评估，结果表明系统用户友好，用户在使用过程中普遍感到满意。

Conclusion: ASK系统成功展示了AI驱动学术文献搜索的潜力，通过结合多种AI技术为研究者提供主动支持，改善了文献发现和探索的体验。

Abstract: As the volume of published scholarly literature continues to grow, finding relevant literature becomes increasingly difficult. With the rise of generative Artificial Intelligence (AI), and particularly Large Language Models (LLMs), new possibilities emerge to find and explore literature. We introduce ASK (Assistant for Scientific Knowledge), an AI-driven scholarly literature search and exploration system that follows a neuro-symbolic approach. ASK aims to provide active support to researchers in finding relevant scholarly literature by leveraging vector search, LLMs, and knowledge graphs. The system allows users to input research questions in natural language and retrieve relevant articles. ASK automatically extracts key information and generates answers to research questions using a Retrieval-Augmented Generation (RAG) approach. We present an evaluation of ASK, assessing the system's usability and usefulness. Findings indicate that the system is user-friendly and users are generally satisfied while using the system.

</details>


### [5] [InfoDCL: Informative Noise Enhanced Diffusion Based Contrastive Learning](https://arxiv.org/abs/2512.16576)
*Xufeng Liang,Zhida Qin,Chong Zhang,Tianyu Huang,Gangyi Ding*

Main category: cs.IR

TL;DR: InfoDCL是一个基于扩散的对比学习推荐框架，通过整合辅助语义信息生成对比视图，并采用协同训练策略提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习方法通过随机扰动交互图构建稀疏视图，无法捕捉真实用户偏好，且推荐数据稀疏性导致语义信息不足。需要一种能生成更真实用户偏好视图的方法。

Method: 1. 使用单步扩散过程整合噪声与辅助语义信息生成信号，输入标准扩散过程生成真实用户偏好作为对比视图；2. 基于生成与偏好学习的相互影响分析，构建协同训练目标策略；3. 仅在推理阶段使用多层GCN整合高阶共现信息。

Result: 在五个真实世界数据集上的实验表明，InfoDCL显著优于最先进的方法，为提升推荐性能提供了有效解决方案。

Conclusion: InfoDCL为增强推荐性能提供了有效方案，并为在对比学习框架中应用扩散方法提出了新范式，能更好地捕捉真实用户偏好。

Abstract: Contrastive learning has demonstrated promising potential in recommender systems. Existing methods typically construct sparser views by randomly perturbing the original interaction graph, as they have no idea about the authentic user preferences. Owing to the sparse nature of recommendation data, this paradigm can only capture insufficient semantic information. To address the issue, we propose InfoDCL, a novel diffusion-based contrastive learning framework for recommendation. Rather than injecting randomly sampled Gaussian noise, we employ a single-step diffusion process that integrates noise with auxiliary semantic information to generate signals and feed them to the standard diffusion process to generate authentic user preferences as contrastive views. Besides, based on a comprehensive analysis of the mutual influence between generation and preference learning in InfoDCL, we build a collaborative training objective strategy to transform the interference between them into mutual collaboration. Additionally, we employ multiple GCN layers only during inference stage to incorporate higher-order co-occurrence information while maintaining training efficiency. Extensive experiments on five real-world datasets demonstrate that InfoDCL significantly outperforms state-of-the-art methods. Our InfoDCL offers an effective solution for enhancing recommendation performance and suggests a novel paradigm for applying diffusion method in contrastive learning frameworks.

</details>


### [6] [Microsoft Academic Graph Information Retrieval for Research Recommendation and Assistance](https://arxiv.org/abs/2512.16661)
*Jacob Reiss,Shikshya Shiwakoti,Samuel Goldsmith,Ujjwal Pandit*

Main category: cs.IR

TL;DR: 提出基于注意力的子图检索器，结合图神经网络和大型语言模型进行科学文献检索与推理


<details>
  <summary>Details</summary>
Motivation: 当前科学文献获取容易但筛选困难，需要有效方法从海量研究中进行信息检索和推理

Method: 使用图神经网络作为检索器，通过注意力机制剪枝提取精炼子图，然后将子图输入大型语言模型进行知识推理

Result: 未在摘要中明确说明具体实验结果，但暗示该方法能有效处理大规模信息数据库检索

Conclusion: 提出的注意力子图检索器结合了GNN和LLM的优势，为科学文献检索和知识推理提供了有效解决方案

Abstract: In today's information-driven world, access to scientific publications has become increasingly easy. At the same time, filtering through the massive volume of available research has become more challenging than ever. Graph Neural Networks (GNNs) and graph attention mechanisms have shown strong effectiveness in searching large-scale information databases, particularly when combined with modern large language models. In this paper, we propose an Attention-Based Subgraph Retriever, a GNN-as-retriever model that applies attention-based pruning to extract a refined subgraph, which is then passed to a large language model for advanced knowledge reasoning.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [7] [DP-Bench: A Benchmark for Evaluating Data Product Creation Systems](https://arxiv.org/abs/2512.15798)
*Faisal Chowdhury,Sola Shirai,Sarthak Dash,Nandana Mihindukulasooriya,Horst Samulowitz*

Main category: cs.DB

TL;DR: 提出了首个用于评估自动数据产品创建的基准DP-Bench，基于现有ELT和Text-to-SQL基准构建，并提供了基于LLM的基线方法。


<details>
  <summary>Details</summary>
Motivation: 数据产品旨在解决特定业务问题并提供深度洞察，但现有研究缺乏评估自动创建数据产品的基准，限制了该领域的发展。

Method: 利用现有ELT和Text-to-SQL基准构建DP-Bench，并提出多种基于大语言模型的基线方法来自动生成数据产品。

Result: 创建了首个数据产品自动生成基准DP-Bench，并在HuggingFace上开源了基准数据集和补充材料。

Conclusion: DP-Bench填补了数据产品自动创建评估的空白，为未来研究提供了标准测试平台和基线方法。

Abstract: A data product is created with the intention of solving a specific problem, addressing a specific business usecase or meeting a particular need, going beyond just serving data as a raw asset. Data products enable end users to gain greater insights about their data. Since it was first introduced over a decade ago, there has been considerable work, especially in industry, to create data products manually or semi-automatically. However, there exists hardly any benchmark to evaluate automatic data product creation. In this work, we present a benchmark, first of its kind, for this task. We call it DP-Bench. We describe how this benchmark was created by taking advantage of existing work in ELT (Extract-Load-Transform) and Text-to-SQL benchmarks. We also propose a number of LLM based approaches that can be considered as baselines for generating data products automatically. We make the DP-Bench and supplementary materials available in https://huggingface.co/datasets/ibm-research/dp-bench .

</details>


### [8] [Implementing a Scalable, Redeployable and Multitiered Repository for FAIR and Secure Scientific Data Sharing: The BIG-MAP Archive](https://arxiv.org/abs/2512.15815)
*Valeria Granata,Francois Liot,Xing Wang,Steen Lysgaard,Ivano E. Castelli,Tejs Vegge,Nicola Marzari,Giovanni Pizzi*

Main category: cs.DB

TL;DR: BIG-MAP Archive是一个基于云的私有存储库，专为大型联盟数据共享设计，提供可扩展架构、用户友好界面和细粒度权限控制，支持安全协作并易于重新部署。


<details>
  <summary>Details</summary>
Motivation: 大型联盟（如研究合作或行业伙伴关系）中的数据共享面临组织和技术的双重挑战，需要通用平台来促进协作、促进发现交流，并确保对敏感数据的安全访问。

Method: 基于InvenioRDM构建云端的学科性私有存储库，提供可扩展架构、用户友好界面、细粒度权限控制和正式化上传流程，支持灵活访问控制。

Result: BIG-MAP Archive成功实现了大型联盟内的安全可控数据共享，确保数据机密性的同时支持基于权限的灵活访问，并已证明可轻松重新部署到其他联盟。

Conclusion: 该存储库为大型联盟提供了定制化的数据共享解决方案，相比通用存储库更符合联盟特定需求，能够有效促进协作并保护敏感数据，具有广泛适用性。

Abstract: Data sharing in large consortia, such as research collaborations or industry partnerships, requires addressing both organizational and technical challenges. A common platform is essential to promote collaboration, facilitate exchange of findings, and ensure secure access to sensitive data. Key technical challenges include creating a scalable architecture, a user-friendly interface, and robust security and access control. The BIG-MAP Archive is a cloud-based, disciplinary, private repository designed to address these challenges. Built on InvenioRDM, it leverages platform functionalities to meet consortium-specific needs, providing a tailored solution compared to general repositories. Access can be restricted to members of specific communities or open to the entire consortium, such as the BATTERY 2030+, a consortium accelerating advanced battery technologies. Uploaded data and metadata are controlled via fine grained permissions, allowing access to individual project members or the full initiative. The formalized upload process ensures data are formatted and ready for publication in open repositories when needed. This paper reviews the repository's key features, showing how the BIG-MAP Archive enables secure, controlled data sharing within large consortia. It ensures data confidentiality while supporting flexible, permissions-based access and can be easily redeployed for other consortia, including MaterialsCommons4.eu and RAISE (Resource for AI Science in Europe).

</details>


### [9] [Scaling Text2SQL via LLM-efficient Schema Filtering with Functional Dependency Graph Rerankers](https://arxiv.org/abs/2512.16083)
*Thanh Dat Hoang,Thanh Tam Nguyen,Thanh Trung Huynh,Hongzhi Yin,Quoc Viet Hung Nguyen*

Main category: cs.DB

TL;DR: 提出GRaST-SQL框架，通过查询感知的列排序、基于功能依赖的图变换器重排序和Steiner树启发式算法，在保持连接性的同时压缩Text2SQL提示，解决大型数据库模式超出LLM上下文限制的问题。


<details>
  <summary>Details</summary>
Motivation: 现有Text2SQL系统在处理大型真实数据库时面临挑战，因为完整模式（包含数百个表和数万个列）会超出LLM的上下文限制。现有缓解方法要么依赖昂贵的多步提示管道，要么独立过滤列而忽略列间结构关系。

Method: 1) 使用查询感知的LLM编码器（包含值和元数据）对列进行排序；2) 通过基于功能依赖的轻量级图变换器对互连列进行重排序；3) 使用Steiner树启发式算法选择保持连接性的子模式。

Result: 在真实数据集上，GRaST-SQL实现了接近完美的召回率和比CodeS、SchemaExP、Qwen重排序器和嵌入检索器更高的精度，同时保持亚秒级中位延迟，并能扩展到包含23,000+列的模式。

Conclusion: GRaST-SQL是一个开源、LLM高效的模式过滤框架，能够有效压缩Text2SQL提示，解决大型数据库模式超出LLM上下文限制的问题，为现有系统提供可扩展的解决方案。

Abstract: Most modern Text2SQL systems prompt large language models (LLMs) with entire schemas -- mostly column information -- alongside the user's question. While effective on small databases, this approach fails on real-world schemas that exceed LLM context limits, even for commercial models. The recent Spider 2.0 benchmark exemplifies this with hundreds of tables and tens of thousands of columns, where existing systems often break. Current mitigations either rely on costly multi-step prompting pipelines or filter columns by ranking them against user's question independently, ignoring inter-column structure. To scale existing systems, we introduce \toolname, an open-source, LLM-efficient schema filtering framework that compacts Text2SQL prompts by (i) ranking columns with a query-aware LLM encoder enriched with values and metadata, (ii) reranking inter-connected columns via a lightweight graph transformer over functional dependencies, and (iii) selecting a connectivity-preserving sub-schema with a Steiner-tree heuristic. Experiments on real datasets show that \toolname achieves near-perfect recall and higher precision than CodeS, SchemaExP, Qwen rerankers, and embedding retrievers, while maintaining sub-second median latency and scaling to schemas with 23,000+ columns. Our source code is available at https://github.com/thanhdath/grast-sql.

</details>


### [10] [ModelTables: A Corpus of Tables about Models](https://arxiv.org/abs/2512.16106)
*Zhengyuan Dong,Victor Zhong,Renée J. Miller*

Main category: cs.DB

TL;DR: ModelTables是一个模型湖中表格的基准数据集，专注于AI模型性能与配置表格的结构化语义，包含60K模型和90K表格，用于评估表格搜索方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本检索方法忽视了模型性能与配置表格的结构化语义，需要专门的基准来支持模型湖中结构化数据的检索、比较和组织。

Method: 从Hugging Face模型卡片、GitHub READMEs和相关论文构建表格语料库，建立多源真实标签（论文引用、模型链接/继承、共享训练数据集），评估多种表格搜索方法。

Result: 基于联合的语义表格检索达到54.8% P@1，基于表格的密集检索达到66.5% P@1，元数据混合检索达到54.1%，表明表格搜索方法仍有改进空间。

Conclusion: ModelTables是首个大规模AI模型结构化数据基准，为开发更准确的语义检索、结构化比较和模型知识组织提供了基础。

Abstract: We present ModelTables, a benchmark of tables in Model Lakes that captures the structured semantics of performance and configuration tables often overlooked by text only retrieval. The corpus is built from Hugging Face model cards, GitHub READMEs, and referenced papers, linking each table to its surrounding model and publication context. Compared with open data lake tables, model tables are smaller yet exhibit denser inter table relationships, reflecting tightly coupled model and benchmark evolution. The current release covers over 60K models and 90K tables. To evaluate model and table relatedness, we construct a multi source ground truth using three complementary signals: (1) paper citation links, (2) explicit model card links and inheritance, and (3) shared training datasets. We present one extensive empirical use case for the benchmark which is table search. We compare canonical Data Lake search operators (unionable, joinable, keyword) and Information Retrieval baselines (dense, sparse, hybrid retrieval) on this benchmark. Union based semantic table retrieval attains 54.8 % P@1 overall (54.6 % on citation, 31.3 % on inheritance, 30.6 % on shared dataset signals); table based dense retrieval reaches 66.5 % P@1, and metadata hybrid retrieval achieves 54.1 %. This evaluation indicates clear room for developing better table search methods. By releasing ModelTables and its creation protocol, we provide the first large scale benchmark of structured data describing AI model. Our use case of table discovery in Model Lakes, provides intuition and evidence for developing more accurate semantic retrieval, structured comparison, and principled organization of structured model knowledge. Source code, data, and other artifacts have been made available at https://github.com/RJMillerLab/ModelTables.

</details>


### [11] [Multi-granularity Spatiotemporal Flow Patterns](https://arxiv.org/abs/2512.16255)
*Chrysanthi Kosyfaki,Nikos Mamoulis,Reynold Cheng,Ben Kai*

Main category: cs.DB

TL;DR: 提出一种从不同时空粒度分析客流移动模式的方法，定义ODT模式并提出高效枚举算法


<details>
  <summary>Details</summary>
Motivation: 分析不同时空粒度下的对象或数据流动可以揭示有趣的洞察或趋势，例如交通公司通过聚合乘客出行数据可以分析移动行为

Method: 定义ODT（起点、终点、时间）模式，提出自底向上的枚举算法，采用优化技术减少搜索空间和计算成本，提出约束模式和top-k模式变体，以及基于生成-测试的近似解决方案

Result: 在三个真实数据集上评估方法的效率和有效性，展示了其中有趣的ODT流动模式

Conclusion: 提出的ODT模式分析方法能够有效发现不同时空粒度下的重要客流移动趋势，为交通分析等应用提供有价值的洞察

Abstract: Analyzing flow of objects or data at different granularities of space and time can unveil interesting insights or trends. For example, transportation companies, by aggregating passenger travel data (e.g., counting passengers traveling from one region to another), can analyze movement behavior. In this paper, we study the problem of finding important trends in passenger movements between regions at different granularities. We define Origin (O), Destination (D), and Time (T ) patterns (ODT patterns) and propose a bottom-up algorithm that enumerates them. We suggest and employ optimizations that greatly reduce the search space and the computational cost of pattern enumeration. We also propose pattern variants (constrained patterns and top-k patterns) that could be useful to differ- ent applications scenarios. Finally, we propose an approximate solution that fast identifies ODT patterns of specific sizes, following a generate-and-test approach. We evaluate the efficiency and effectiveness of our methods on three real datasets and showcase interesting ODT flow patterns in them.

</details>


### [12] [Subset Sampling over Joins](https://arxiv.org/abs/2512.16321)
*Aryan Esmailpour,Xiao Hu,Jinchao Huang,Stavros Sintos*

Main category: cs.DB

TL;DR: 本文提出了在关系连接上进行子集采样的高效算法，解决了从隐式连接结果中随机采样的计算挑战，避免了物化指数级增长的连接结果。


<details>
  <summary>Details</summary>
Motivation: 现代应用（如关系数据上的机器学习）经常需要从关系连接隐式定义的集合中进行采样。由于连接结果可能比输入数据指数级增长，物化所有连接结果进行采样的朴素方法计算不可行，需要高效算法。

Method: 针对无环连接，提出了三种算法：(1) 用于生成多个独立样本的静态索引；(2) 用于生成单个样本的一次性算法；(3) 支持元组插入的动态索引。算法基于输入元组权重通过可分解函数（如乘积、求和、最小值、最大值）计算概率。

Result: 提出的技术在输入大小和期望样本大小方面实现了近乎最优的时间和空间复杂度，是连接上子集采样的首个高效算法。

Conclusion: 本文解决了关系连接上子集采样的重要问题，为大数据分析中的高效近似处理提供了理论基础和实用算法，特别适用于机器学习等现代应用场景。

Abstract: Subset sampling (also known as Poisson sampling), where the decision to include any specific element in the sample is made independently of all others, is a fundamental primitive in data analytics, enabling efficient approximation by processing representative subsets rather than massive datasets. While sampling from explicit lists is well-understood, modern applications -- such as machine learning over relational data -- often require sampling from a set defined implicitly by a relational join. In this paper, we study the problem of \emph{subset sampling over joins}: drawing a random subset from the join results, where each join result is included independently with some probability. We address the general setting where the probability is derived from input tuple weights via decomposable functions (e.g., product, sum, min, max). Since the join size can be exponentially larger than the input, the naive approach of materializing all join results to perform subset sampling is computationally infeasible. We propose the first efficient algorithms for subset sampling over acyclic joins: (1) a \emph{static index} for generating multiple (independent) subset samples over joins; (2) a \emph{one-shot} algorithm for generating a single subset sample over joins; (3) a \emph{dynamic index} that can support tuple insertions, while maintaining a one-shot sample or generating multiple (independent) samples. Our techniques achieve near-optimal time and space complexity with respect to the input size and the expected sample size.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [13] [A Tri-Dynamic Preprocessing Framework for UGC Video Compression](https://arxiv.org/abs/2512.16101)
*Fei Zhao,Mengxi Guo,Shijie Zhao,Junlin Li,Li Zhang,Xiaodong Xie*

Main category: cs.MM

TL;DR: 提出Tri-Dynamic Preprocessing框架，通过自适应因子、量化水平和lambda权衡来优化UGC视频编码，解决UGC视频多样性对机器学习编码优化的挑战。


<details>
  <summary>Details</summary>
Motivation: 用户生成内容（UGC）已成为互联网流量的主导，但UGC视频相比传统测试视频具有更高的变异性和多样性特征，这种差异挑战了数据驱动机器学习算法在更广泛UGC场景中优化编码的有效性。

Method: 提出Tri-Dynamic Preprocessing框架：1）使用自适应因子调节预处理强度；2）使用自适应量化水平微调编解码器模拟器；3）使用自适应lambda权衡调整率失真损失函数。

Result: 在大规模测试集上的实验结果表明，该方法取得了卓越的性能表现。

Conclusion: 提出的Tri-Dynamic Preprocessing框架有效解决了UGC视频多样性对编码优化的挑战，通过三重自适应机制实现了优异的编码性能。

Abstract: In recent years, user generated content (UGC) has become the dominant force in internet traffic. However, UGC videos exhibit a higher degree of variability and diverse characteristics compared to traditional encoding test videos. This variance challenges the effectiveness of data-driven machine learning algorithms for optimizing encoding in the broader context of UGC scenarios. To address this issue, we propose a Tri-Dynamic Preprocessing framework for UGC. Firstly, we employ an adaptive factor to regulate preprocessing intensity. Secondly, an adaptive quantization level is employed to fine-tune the codec simulator. Thirdly, we utilize an adaptive lambda tradeoff to adjust the rate-distortion loss function. Experimental results on large-scale test sets demonstrate that our method attains exceptional performance.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [14] [Improved Lower Bounds for Privacy under Continual Release](https://arxiv.org/abs/2512.15981)
*Bardiya Aryanfard,Monika Henzinger,David Saulpic,A. R. Sricharan*

Main category: cs.DS

TL;DR: 该论文研究了在差分隐私下持续发布演化数据集统计信息的问题，针对插入式图问题（如最大匹配、度直方图、k-核）首次证明了多项式级别的加法误差下界，这是对之前对数多项式下界的指数级改进。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解在持续发布设置下，插入式更新与完全动态更新之间的差异如何影响差分隐私机制的误差界限。之前的研究认为插入式更新会导致对数多项式误差，而完全动态更新会导致多项式误差，但本文发现这种直觉并不完全正确。

Method: 研究方法包括：1）为插入式图问题建立多项式加法误差下界；2）分析乘法近似对误差的影响；3）将技术扩展到同时范数估计问题；4）在项目级设置中证明乘法误差和加法误差乘积的下界。

Result: 主要结果：1）对插入式最大匹配、度直方图、k-核问题证明了多项式加法误差下界；2）发现允许小的乘法近似可以将加法误差降低到对数多项式级别；3）为同时单调对称范数估计提供了第一个具有对数多项式加法误差的持续机制；4）在项目级设置中证明了图问题的乘法误差和加法误差乘积的下界。

Conclusion: 结论表明：插入式更新与完全动态更新之间的差异并不是导致多项式误差与对数多项式误差差距的主要原因，而是是否允许乘法近似决定了误差界限。该研究为差分隐私持续发布机制的设计提供了新的理论见解。

Abstract: We study the problem of continually releasing statistics of an evolving dataset under differential privacy. In the event-level setting, we show the first polynomial lower bounds on the additive error for insertions-only graph problems such as maximum matching, degree histogram and $k$-core. This is an exponential improvement on the polylogarithmic lower bounds of Fichtenberger et al.[ESA 2021] for the former two problems, and are the first continual release lower bounds for the latter. Our results run counter to the intuition that the difference between insertions-only vs fully dynamic updates causes the gap between polylogarithmic and polynomial additive error. We show that for maximum matching and $k$-core, allowing small multiplicative approximations is what brings the additive error down to polylogarithmic.
  Beyond graph problems, our techniques also show that polynomial additive error is unavoidable for Simultaneous Norm Estimation in the insertions-only setting. When multiplicative approximations are allowed, we circumvent this lower bound by giving the first continual mechanism with polylogarithmic additive error under $(1+ζ)$ multiplicative approximations, for $ζ>0$, for estimating all monotone symmetric norms simultaneously.
  In the item-level setting, we show polynomial lower bounds on the product of the multiplicative and the additive error of continual mechanisms for a large range of graph problems. To the best of our knowledge, these are the first lower bounds for any differentially private continual release mechanism with multiplicative error. To obtain this, we prove a new lower bound on the product of multiplicative and additive error for 1-Way-Marginals, from which we reduce to continual graph problems. This generalizes the lower bounds of Hardt and Talwar[STOC 2010] and Bun et al.[STOC 2014] on the additive error for mechanisms with no multiplicative error.

</details>


### [15] [Instance Optimality in PageRank Centrality Estimation](https://arxiv.org/abs/2512.16087)
*Mikkel Thorup,Hanzhi Wang*

Main category: cs.DS

TL;DR: 该论文研究了一种自适应变体的PageRank中心性估计算法，证明了该算法在大多数稀疏图中达到实例最优（相差对数因子）。


<details>
  <summary>Details</summary>
Motivation: 研究PageRank中心性估计的算法效率问题，特别是针对不同图结构（尤其是稀疏图）寻找最优的估计算法。

Method: 分析一个简单的经典PageRank估计算法的自适应变体，研究其在各种图结构上的性能表现。

Result: 该算法在最大入度和出度最多为常数比例n的有向图中达到实例最优（相差对数因子）；对于最多有对数个无界度顶点的图也成立，覆盖了所有稀疏图；但对于度大多等于n的图不是实例最优。

Conclusion: 该自适应PageRank估计算法在大多数实际相关的稀疏图结构中接近最优，但在稠密图或高度正则图中可能不是最优的。

Abstract: We study an adaptive variant of a simple, classic algorithm for estimating a vertex's PageRank centrality within a constant relative error, with constant probability. We show that this algorithm is instance-optimal up to a polylogarithmic factor for any directed graph of order $n$ whose maximal in- and out-degrees are at most a constant fraction of $n$. The instance-optimality also extends to graphs in which up to a polylogarithmic number of vertices have unbounded degree, thereby covering all sparse graphs with $\widetilde{O}(n)$ edges. Finally, we provide a counterexample showing that the algorithm is not instance-optimal for graphs with degrees mostly equal to $n$.

</details>


### [16] [Conquering the Multiverse: The River Voting Method with Efficient Parallel Universe Tiebreaking](https://arxiv.org/abs/2512.16414)
*Jannes Malanowski*

Main category: cs.DS

TL;DR: River投票方法配合Parallel Universe Tiebreaking可在多项式时间内计算，解决了Ranked Pairs的NP-hard问题，同时保持了中立性等优良性质。


<details>
  <summary>Details</summary>
Motivation: 现有投票方法如Ranked Pairs在平局处理时面临计算复杂性问题（NP-hard），需要找到既能保持中立性等重要性质，又能在多项式时间内计算的投票方法。

Method: 提出River投票方法配合Parallel Universe Tiebreaking（PUT），通过构造特殊的边排序，使用semi-River图包含所有可能的River图边，并应用改进的Prim算法变体计算获胜者。

Result: 证明River with PUT可在多项式最坏情况下运行时间内计算，将算法复杂度从O(n⁴)优化到O(n² log n)，其中n为候选者数量。

Conclusion: River with PUT在保持中立性等理想性质的同时，解决了计算可行性问题，为公平选举和AI训练等应用提供了实用的投票方法。

Abstract: Democracy relies on making collective decisions through voting. In addition, voting procedures have further applications, for example in the training of artificial intelligence. An essential criterion for determining the winner of a fair election is that all alternatives are treated equally: this is called neutrality. The established Ranked Pairs voting method cannot simultaneously guarantee neutrality and be computationally tractable for election with ties. River, the recently introduced voting method, shares desirable properties with Ranked Pairs and has further advantages, such as a new property related to resistance against manipulation. Both Ranked Pairs and River use a weighted margin graph to model the election. Ties in the election can lead to edges of equal margin. To order the edges in such a case, a tiebreaking scheme must be employed. Many tiebreaks violate neutrality or other important properties. A tiebreaking scheme that preserves neutrality is Parallel Universe Tiebreaking (PUT). Ranked Pairs with PUT is NP-hard to compute.
  The main result of this thesis shows that River with PUT can be computed in polynomial worst-case runtime: We can check whether an alternative is a River PUT winner, by running River with a specially constructed ordering of the edges. To construct this ordering, we introduce the semi-River diagram which contains the edges that can appear in any River diagram for some arbitrary tiebreak. On this diagram we can compute the River winners, by applying a variant of Prims algorithm per alternative. Additionally, we give an algorithm improve the previous naive runtime of River from $\mathcal{O}(n^4)$ to $\mathcal{O}(n^2 \log n)$, where n is the number of alternatives.

</details>


### [17] [Fully Dynamic Algorithms for Chamfer Distance](https://arxiv.org/abs/2512.16639)
*Gramoz Goranci,Shaofeng Jiang,Peter Kiss,Eva Szilagyi,Qiaoyuan Yang*

Main category: cs.DS

TL;DR: 提出了首个动态维护Chamfer距离近似值的算法，支持ℓ₁和ℓ₂范数，通过近似最近邻搜索实现高效更新。


<details>
  <summary>Details</summary>
Motivation: Chamfer距离是点云分析中广泛使用的差异度量，在机器学习等领域需要频繁评估动态变化的数据集。现有方法无法高效处理动态更新的点集，需要开发支持插入和删除操作的动态算法。

Method: 将Chamfer距离维护问题简化为近似最近邻搜索问题，通过标准ANN边界实现高效更新。算法支持ℓ₁和ℓ₂范数，提供两种精度-时间权衡方案。

Result: 实现了(1+ε)-近似在Õ(ε^{-d})更新时间和O(1/ε)-近似在Õ(d n^{ε^2} ε^{-4})更新时间。在真实数据集上验证了算法性能，表现优于自然基线方法。

Conclusion: 提出了首个动态Chamfer距离近似算法，通过将问题简化为ANN搜索实现了高效更新，为动态点云分析提供了实用解决方案。

Abstract: We study the problem of computing Chamfer distance in the fully dynamic setting, where two set of points $A, B \subset \mathbb{R}^{d}$, each of size up to $n$, dynamically evolve through point insertions or deletions and the goal is to efficiently maintain an approximation to $\mathrm{dist}_{\mathrm{CH}}(A,B) = \sum_{a \in A} \min_{b \in B} \textrm{dist}(a,b)$, where $\textrm{dist}$ is a distance measure. Chamfer distance is a widely used dissimilarity metric for point clouds, with many practical applications that require repeated evaluation on dynamically changing datasets, e.g., when used as a loss function in machine learning. In this paper, we present the first dynamic algorithm for maintaining an approximation of the Chamfer distance under the $\ell_p$ norm for $p \in \{1,2 \}$. Our algorithm reduces to approximate nearest neighbor (ANN) search with little overhead. Plugging in standard ANN bounds, we obtain $(1+ε)$-approximation in $\tilde{O}(ε^{-d})$ update time and $O(1/ε)$-approximation in $\tilde{O}(d n^{ε^2} ε^{-4})$ update time. We evaluate our method on real-world datasets and demonstrate that it performs competitively against natural baselines.

</details>


### [18] [Learning Confidence Ellipsoids and Applications to Robust Subspace Recovery](https://arxiv.org/abs/2512.16875)
*Chao Gao,Liren Shan,Vaidehi Srinivas,Aravindan Vijayaraghavan*

Main category: cs.DS

TL;DR: 提出多项式时间算法，在有限条件数β约束下，找到体积近似最优的置信椭球，并证明其计算复杂度下界。


<details>
  <summary>Details</summary>
Motivation: 高维分布中寻找置信椭球是经典的最小体积估计问题，但当条件数β趋于无穷时，获得非平凡体积近似是NP难的，因此研究在有限条件数约束下的高效算法。

Method: 利用最小体积包围椭球的原始-对偶结构和几何Brascamp-Lieb不等式，设计多项式时间算法。

Result: 算法找到的椭球体积在O(β^{γd})倍内近似最优β条件椭球，同时覆盖至少1-O(α/γ)概率质量；并证明这种指数依赖在常数上是必要的。

Conclusion: 首次为鲁棒子空间恢复问题的最坏情况实例提供了具有近似保证的多项式时间算法，解决了高维置信椭球计算难题。

Abstract: We study the problem of finding confidence ellipsoids for an arbitrary distribution in high dimensions. Given samples from a distribution $D$ and a confidence parameter $α$, the goal is to find the smallest volume ellipsoid $E$ which has probability mass $\Pr_{D}[E] \ge 1-α$. Ellipsoids are a highly expressive class of confidence sets as they can capture correlations in the distribution, and can approximate any convex set. This problem has been studied in many different communities. In statistics, this is the classic minimum volume estimator introduced by Rousseeuw as a robust non-parametric estimator of location and scatter. However in high dimensions, it becomes NP-hard to obtain any non-trivial approximation factor in volume when the condition number $β$ of the ellipsoid (ratio of the largest to the smallest axis length) goes to $\infty$. This motivates the focus of our paper: can we efficiently find confidence ellipsoids with volume approximation guarantees when compared to ellipsoids of bounded condition number $β$?
  Our main result is a polynomial time algorithm that finds an ellipsoid $E$ whose volume is within a $O(β^{γd})$ multiplicative factor of the volume of best $β$-conditioned ellipsoid while covering at least $1-O(α/γ)$ probability mass for any $γ< α$. We complement this with a computational hardness result that shows that such a dependence seems necessary up to constants in the exponent. The algorithm and analysis uses the rich primal-dual structure of the minimum volume enclosing ellipsoid and the geometric Brascamp-Lieb inequality. As a consequence, we obtain the first polynomial time algorithm with approximation guarantees on worst-case instances of the robust subspace recovery problem.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [19] [Algorithmic Monetary Policies for Blockchain Participation Games](https://arxiv.org/abs/2512.16514)
*Diodato Ferraioli,Paolo Penna,Manvir Schneider,Carmine Ventre*

Main category: cs.GT

TL;DR: 论文提出了一种区块链代币经济学的算法货币政策框架，旨在平衡短期性能激励与长期去中心化目标。通过重复参与博弈模型，分析不同代理行为（短视与远见）下的均衡，并探讨虚拟股权作为替代方法。


<details>
  <summary>Details</summary>
Motivation: 区块链代币经济学面临的核心挑战是如何在短期性能激励与长期去中心化目标之间取得平衡。当前政策往往偏向性能优化，可能导致中心化风险，需要系统性的框架来协调这一矛盾。

Method: 提出重复参与博弈框架：代理根据类型（能力）和股权选择参与或弃权；政策算法性地选择高类型代理执行任务（最大化吞吐量），同时分配奖励以维持去中心化。分析两种代理行为下的均衡：短视（最大化短期效用）和远见（多轮规划）。进一步探讨虚拟股权（类型与股权的混合）作为替代方法。

Result: 对于短视代理，性能中心化政策可能导致中心化风险；而对于远见代理，可以实现稳定的去中心化，但代币价值会有一定波动。虚拟股权的初始分布对长期结果有决定性影响，表明政策需要间接管理去中心化。

Conclusion: 算法货币政策需要在性能与去中心化之间进行权衡。代理的远见行为有助于实现稳定去中心化，而虚拟股权的初始分布是关键设计参数。政策应通过间接机制管理去中心化，而非直接控制。

Abstract: A central challenge in blockchain tokenomics is aligning short-term performance incentives with long-term decentralization goals. We propose a framework for algorithmic monetary policies that navigates this tradeoff in repeated participation games. Agents, characterized by type (capability) and stake, choose to participate or abstain at each round; the policy (probabilistically) selects high-type agents for task execution (maximizing throughput) while distributing rewards to sustain decentralization. We analyze equilibria under two agent behaviors: myopic (short-term utility maximization) and foresighted (multi-round planning). For myopic agents, performance-centric policies risk centralization, but foresight enables stable decentralization with some volatility to the token value. We further discuss virtual stake--a hybrid of type and stake--as an alternative approach. We show that the initial virtual stake distribution critically impacts long-term outcomes, suggesting that policies must indirectly manage decentralization.

</details>


### [20] [Online Resource Allocation via Static Bundle Pricing](https://arxiv.org/abs/2512.16570)
*Dimitris Fotakis,Charalampos Platanos,Thanos Tolias*

Main category: cs.GT

TL;DR: 提出针对互补性估值的在线资源分配统一技术，为三种场景设计静态匿名捆绑定价机制，竞争比随容量指数级改善，并给出信息论下界。


<details>
  <summary>Details</summary>
Motivation: 在线资源分配中，当买家估值存在互补性时，标准单品定价机制无法利用物品多重性，而现有静态捆绑定价机制依赖特定问题论证，缺乏通用性。

Method: 开发统一技术处理互补性在线资源分配，针对三种场景：(1)最大捆绑大小为d的单需求组合拍卖，(2)一般单需求组合拍卖，(3)基于图的带容量路由模型。采用静态匿名捆绑定价机制。

Result: 对于d-单需求设置（最小物品容量B），获得O(d^{1/B})-竞争比；对于一般单需求组合拍卖和图路由模型，获得O(m^{1/(B+1)})-竞争比。给出信息论下界：一般单需求Ω((m/ln m)^{1/(B+2)})，d-单需求Ω((d/ln d)^{1/(B+1)})。

Conclusion: 提出处理互补性在线资源分配的通用框架，机制性能随容量指数级改善，揭示了与定性独立划分极值组合问题的深刻联系。

Abstract: Online Resource Allocation addresses the problem of efficiently allocating limited resources to buyers with incomplete knowledge of future requests. In our setting, buyers arrive sequentially demanding a set of items, each with a value drawn from a known distribution. We study environments where buyers' valuations exhibit complementarities. In such settings, standard item-pricing mechanisms fail to leverage item multiplicities, while existing static bundle-pricing mechanisms rely on problem-specific arguments that do not generalize.
  We develop a unified technique for online resource allocation with complementarities for three domains: (i) single-minded combinatorial auctions with maximum bundle size $d$, (ii) general single-minded combinatorial auctions, and (iii) a graph-based routing model in which buyers request to route a unit of flow from a source node $s$ to a target node $t$ in a capacitated graph. Our approach yields static and anonymous bundle-pricing mechanisms whose performance improves exponentially with item capacities. For the $d$-single-minded setting with minimum item capacity $B$, we obtain an $O(d^{1/B})$-competitive mechanism, recovering the known $O(d)$ bound for unit capacities ($B=1$) and achieving exponentially better guarantees as capacities grow. For general single-minded combinatorial auctions and the graph-routing model, we obtain $O(m^{1/(B+1)})$-competitive mechanisms, where $m$ is the number of items.
  We complement these results with information-theoretic lower bounds. We show that no online algorithm can achieve a competitive ratio better than $Ω((m/\ln m)^{1/(B+2)})$ in the general single-minded setting and $Ω((d/\ln d)^{1/(B+1)})$ in the $d$-single-minded setting. In doing so, we reveal a deep connection to the extremal combinatorics problem of determining the maximum number of qualitatively independent partitions of a ground set.

</details>


### [21] [On the Edge of Core (Non-)Emptiness: An Automated Reasoning Approach to Approval-Based Multi-Winner Voting](https://arxiv.org/abs/2512.16895)
*Ratip Emin Berker,Emanuel Tewolde,Vincent Conitzer,Mingyu Guo,Marijn Heule,Lirong Xia*

Main category: cs.GT

TL;DR: 该论文提出了一种基于混合整数线性规划的方法，用于判断核心稳定委员会是否总是存在，解决了多赢家投票中公平性的核心稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 在多赢家投票中，核心稳定性是群体公平性的重要概念，但当前主要开放问题是：在选民对候选人采用批准/不批准投票的情况下，核心稳定委员会是否总是存在。现有SAT方法受限于选民数量，需要更有效的计算方法。

Method: 开发基于混合整数线性规划的方法，能够独立于选民数量，针对特定候选人数量生成证明。该方法支持对偶性重构核心稳定性问题，并揭示核心稳定性与其他期望属性之间的关系。

Result: 该方法在计算上比SAT方法更高效，能够产生独立于选民数量的证明。通过对偶性重构获得了特殊情况下新的存在性结果，并揭示了核心稳定性与价格能力等属性之间先前未知的关系。

Conclusion: 混合整数线性规划方法为解决核心稳定性存在性问题提供了有效的计算框架，不仅提高了计算效率，还通过数学重构获得了新的理论见解，深化了对多赢家投票中公平性概念的理解。

Abstract: Core stability is a natural and well-studied notion for group fairness in multi-winner voting, where the task is to select a committee from a pool of candidates. We study the setting where voters either approve or disapprove of each candidate; here, it remains a major open problem whether a core-stable committee always exists. In this work, we develop an approach based on mixed-integer linear programming for deciding whether and when core-stable committees are guaranteed to exist. In contrast to SAT-based approaches popular in computational social choice, our method can produce proofs for a specific number of candidates independent of the number of voters. In addition to these computational gains, our program lends itself to a novel duality-based reformulation of the core stability problem, from which we obtain new existence results in special cases. Further, we use our framework to reveal previously unknown relationships between core stability and other desirable properties, such as notions of priceability.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [22] [Information theory and discriminative sampling for model discovery](https://arxiv.org/abs/2512.16000)
*Yuxuan Bao,J. Nathan Kutz*

Main category: cs.IT

TL;DR: 该论文将费舍尔信息矩阵（FIM）与SINDy数据驱动框架结合，通过信息模式可视化改进混沌/非混沌系统的采样效率，利用信息度量提升数据效率。


<details>
  <summary>Details</summary>
Motivation: 费舍尔信息和香农熵是理解动力系统的互补工具，但如何将其有效整合到数据驱动的非线性动力学识别框架中，以提升采样效率和模型性能，是本研究的主要动机。

Method: 将费舍尔信息矩阵（FIM）整合到稀疏识别非线性动力学（SINDy）的数据驱动框架中，可视化混沌和非混沌系统的信息模式，分析单轨迹和多初始条件，并通过FIM谱分析阐明统计装袋的好处。

Result: 展示了信息模式可视化如何改进采样效率和增强模型性能，通过优先处理信息量更大的数据。在三种场景中（单轨迹、可调控制参数、多轨迹自由初始化）证明了费舍尔信息和熵度量能促进数据效率。

Conclusion: 在数据驱动模型发现日益重要的背景下，基于可量化信息度量的原则性采样策略为提高学习效率和减少数据需求提供了有力方法。

Abstract: Fisher information and Shannon entropy are fundamental tools for understanding and analyzing dynamical systems from complementary perspectives. They can characterize unknown parameters by quantifying the information contained in variables, or measure how different initial trajectories or temporal segments of a trajectory contribute to learning or inferring system dynamics. In this work, we leverage the Fisher Information Matrix (FIM) within the data-driven framework of {\em sparse identification of nonlinear dynamics} (SINDy). We visualize information patterns in chaotic and non-chaotic systems for both single trajectories and multiple initial conditions, demonstrating how information-based analysis can improve sampling efficiency and enhance model performance by prioritizing more informative data. The benefits of statistical bagging are further elucidated through spectral analysis of the FIM. We also illustrate how Fisher information and entropy metrics can promote data efficiency in three scenarios: when only a single trajectory is available, when a tunable control parameter exists, and when multiple trajectories can be freely initialized. As data-driven model discovery continues to gain prominence, principled sampling strategies guided by quantifiable information metrics offer a powerful approach for improving learning efficiency and reducing data requirements.

</details>


### [23] [Optimal Key Rates for Decentralized Secure Aggregation with Arbitrary Collusion and Heterogeneous Security Constraints](https://arxiv.org/abs/2512.16112)
*Zhou Li,Xiang Zhang,Giuseppe Caire*

Main category: cs.IT

TL;DR: 该论文研究了具有任意合谋和异构安全约束的去中心化安全聚合问题，通过安全集合和合谋集合的框架，表征了最优通信和源密钥速率。


<details>
  <summary>Details</summary>
Motivation: 传统去中心化安全聚合需要大量密钥来保护除输入总和及合谋用户信息外的所有信息。为降低源密钥开销，研究具有任意合谋和异构安全约束的去中心化安全聚合。

Method: 提出安全集合和合谋集合的框架，其中安全集合包含需要保护的用户子集，合谋集合包含可能合谋的用户子集。通过线性规划方法表征最优源密钥速率。

Result: 表征了具有任意合谋和异构安全约束的去中心化安全聚合的最优通信和源密钥速率，最优源密钥速率的表征可简化为求解线性规划问题。

Conclusion: 该工作为去中心化安全聚合提供了更灵活的框架，通过异构安全约束降低了密钥开销，最优源密钥速率的线性规划表征为实际应用提供了理论基础。

Abstract: Decentralized secure aggregation (DSA) considers a fully-connected network of $K$ users, where each pair of users can communicate bidirectionally over an error-free channel. Each user holds a private input, and the goal is for each user to compute the sum of all inputs without revealing any additional information, even in the presence of collusion among up to $T$ users. Traditional DSA typically requires large key sizes to protect all information except for the input sum and the information of colluding users. To mitigate the source keys overhead, we study decentralized secure aggregation with arbitrary collusion and heterogeneous security constraints. In this setting, the inputs of a predefined collection of user subsets, called the \emph{security set} $\bm{\mathcal{S}}$, must be protected from another predefined collection, the \emph{collusion set} $\bm{\mathcal{T}}$. For an arbitrary security set $\mathcal{S}\in \bm{\mathcal{S}}$ and an arbitrary collusion set $\mathcal{T}\in \bm{\mathcal{T}}$, we characterize the optimal communication and source key rates. A key contribution of this work is the characterization of the optimal source key rate, i.e., the minimum number of key bits per input bit that must be shared among users for decentralized secure aggregation with arbitrary collusion and heterogeneous security constraints to be feasible. In general, this characterization reduces to solving a linear program.

</details>


### [24] [New Quantum Stabilizer Codes from generalized Monomial-Cartesian Codes constructed using two different generalized Reed-Solomon codes](https://arxiv.org/abs/2512.16482)
*Oisin Campion,Fernando Hernando,Gary McGuire*

Main category: cs.IT

TL;DR: 提出广义单项式笛卡尔码(GMCC)，作为广义Reed-Solomon码的自然扩展，通过组合两个不同的广义Reed-Solomon码构建GMCC，并建立GMCC为Hermitian自正交码的充分条件，从而获得新的量子码构造。


<details>
  <summary>Details</summary>
Motivation: 扩展广义Reed-Solomon码到更一般的广义单项式笛卡尔码(GMCC)，为量子码构造提供新的代数编码框架。

Method: 定义GMCC作为广义Reed-Solomon码的自然扩展，描述如何将两个不同的广义Reed-Solomon码组合构建一个GMCC，并建立GMCC为Hermitian自正交码的充分条件。

Result: 获得了新的量子码构造方法，通过GMCC的Hermitian自正交性质推导出相应的量子码。

Conclusion: GMCC为广义Reed-Solomon码的有意义扩展，其Hermitian自正交性质为量子码构造提供了新的代数编码工具。

Abstract: In this work, we define Generalized Monomial Cartesian Codes (GMCC), which constitute a natural extension of generalized Reed-Solomon codes. We describe how two different generalized Reed-Solomon codes can be combined to construct one GMCC. We further establish sufficient conditions ensuring that the GMCC are Hermitian self-orthogonal, thus leading to new constructions of quantum codes.

</details>


### [25] [Novel Inconsistency Results for Partial Information Decomposition](https://arxiv.org/abs/2512.16662)
*Philip Hendrik Matthias,Abdullah Makkeh,Michael Wibral,Aaron J. Gutknecht*

Main category: cs.IT

TL;DR: PID框架中三个经典信息论属性（非负性、链式法则、可逆变换不变性）无法同时满足，揭示了任何PID方案都必须牺牲至少一个基本属性。


<details>
  <summary>Details</summary>
Motivation: 尽管部分信息分解（PID）在多个领域得到广泛应用，但寻找一个唯一、普遍接受的解决方案仍然困难重重，存在许多相互竞争的不同分解方案。需要通过建立不一致性结果来澄清可能性范围，并迫使研究者认识到必须在基本属性之间做出选择。

Method: 利用最近发展的部分信息分解的纯粹学方法，建立新颖的不一致性结果。主要定理证明三个经典信息论属性在PID设置下变得互不兼容，同时强化了Rauh等人的经典结果。

Result: 主要定理表明：非负性、链式法则和可逆变换不变性这三个经典信息论属性在PID框架中无法同时满足。任何PID框架都必须牺牲至少一个看似基本的信息论属性。此外，强化了Rauh等人的结果，显示非负性、恒等性质和Williams-Beer公理也无法共存。

Conclusion: 部分信息分解领域不存在能够同时满足所有理想属性的完美解决方案。研究者必须认识到在基本属性之间做出权衡的必要性，这些不一致性结果为PID理论的发展提供了重要的约束和指导。

Abstract: Partial Information Decomposition (PID) seeks to disentangle how information about a target variable is distributed across multiple sources, separating redundant, unique, and synergistic contributions. Despite extensive theoretical development and applications across diverse fields, the search for a unique, universally accepted solution remains elusive, with numerous competing proposals offering different decompositions. A promising but underutilized strategy for making progress is to establish inconsistency results, proofs that certain combinations of intuitively appealing axioms cannot be simultaneously satisfied. Such results clarify the landscape of possibilities and force us to recognize where fundamental choices must be made. In this work, we leverage the recently developed mereological approach to PID to establish novel inconsistency results with far-reaching implications. Our main theorem demonstrates that three cornerstone properties of classical information theory, namely non-negativity, the chain rule, and invariance under invertible transformations, become mutually incompatible when extended to the PID setting. This result reveals that any PID framework must sacrifice at least one property that seems fundamental to information theory itself. Additionally, we strengthen the classical result of Rauh et al., which showed that non-negativity, the identity property, and the Williams and Beer axioms cannot coexist.

</details>


### [26] [Confusions and Erasures of Error-Bounded Block Decoders with Finite Blocklength](https://arxiv.org/abs/2512.16665)
*Bin Han,Yao Zhu,Rafael F. Schaefer,Giuseppe Caire,Anke Schmeink,H. Vincent Poor,Hans D. Schotten*

Main category: cs.IT

TL;DR: 该论文首次在有限块长（FBL）体制下，系统分析了AWGN信道中块解码器的两种错误类型：未检测错误（混淆）和擦除，为上层协议普遍假设的物理层错误表现为包擦除而非未检测损坏提供了理论验证。


<details>
  <summary>Details</summary>
Motivation: 上层协议（MAC和网络层）普遍假设物理层错误表现为包擦除而非未检测损坏，但这一假设缺乏严格的物理层验证。块错误率（BLER）作为常用指标无法区分混淆和擦除，而这两种错误在跨层协议设计中影响显著不同。

Method: 在BLER约束的最大似然（ML）解码下，通过球堆积分析，为块混淆和擦除概率提供解析边界，并推导这些边界对块长和信噪比（SNR）的敏感性。

Result: 分析表明，对于实际的FBL码，块混淆相比块擦除可以忽略不计，特别是在大块长和高SNR情况下。这为MAC和网络层协议常用的块擦除信道抽象提供了理论验证。

Conclusion: 该研究首次在FBL体制下系统分析了混淆和擦除错误，验证了上层协议假设的合理性，即物理层错误主要表现为擦除而非未检测损坏，为跨层协议设计提供了重要理论依据。

Abstract: This paper investigates two distinct types of block errors - undetected errors (confusions) and erasures - in additive white Gaussian noise (AWGN) channels with error-bounded block decoders operating in the finite blocklength (FBL) regime. While block error rate (BLER) is a common metric, it does not distinguish between confusions and erasures, which can have significantly different impacts in cross-layer protocol design, despite upper-layer protocols universally assuming physical (PHY) errors manifest as packet erasures rather than undetected corruptions - an assumption lacking rigorous PHY-layer validation. We present a systematic analysis of confusions and erasures under BLER-constrained maximum likelihood (ML) decoding. Through sphere-packing analysis, we provide analytical bounds for both block confusion and erasure probabilities, and derive the sensitivities of these bounds to blocklength and signal-to-noise ratio (SNR). To the best of our knowledge, this is the first study on this topic in the FBL regime. Our findings provide theoretical validation for the block erasure channel abstraction commonly assumed in medium access control (MAC) and network layer protocols, confirming that, for practical FBL codes, block confusions are negligible compared to block erasures, especially at large blocklengths and high SNR.

</details>


### [27] [Secure Event-triggered MolecularvCommunication - Information Theoretic Perspective and Optimal Performance](https://arxiv.org/abs/2512.16761)
*Wafa Labidi,Vida Gholamian,Yaning Zhao,Christian Deppe,Holger Boche*

Main category: cs.IT

TL;DR: 该论文研究分子通信中的随机识别和安全随机识别，针对离散时间泊松信道推导容量公式，相比传统香农传输能效更高且满足生物纳米物联网的安全需求。


<details>
  <summary>Details</summary>
Motivation: 分子通信是研究人体细胞通信的新兴领域，旨在开发纳米机器辅助疗法。由于细胞通过释放分子进行通信，通常用泊松信道建模。传统香农通信不适合事件驱动的分子通信，而识别框架更高效。此外，生物纳米物联网概念要求体内通信必须安全，防止窃听。

Method: 采用Ahlswede和Dueck提出的识别框架，研究离散时间泊松信道。首先分析随机识别，然后扩展到安全随机识别。使用随机编码，推导两种场景下的容量公式。

Result: 推导出离散时间泊松信道的随机识别和安全随机识别的容量公式，为分子通信的性能和安全提供了全面的理论分析框架。

Conclusion: 识别框架相比传统香农传输在分子通信中更高效，能显著降低能耗和硬件要求。安全随机识别为生物纳米物联网的体内通信提供了安全保障，具有重要的医疗应用价值。

Abstract: Molecular Communication (MC) is an emerging field of research focused on understanding how cells in the human body communicate and exploring potential medical applications. In theoretical analysis, the goal is to investigate cellular communication mechanisms and develop nanomachine-assisted therapies to combat diseases. Since cells transmit information by releasing molecules at varying intensities, this process is commonly modeled using Poisson channels. In our study, we consider a discrete-time Poisson channel (DTPC). MC is often event-driven, making traditional Shannon communication an unsuitable performance metric. Instead, we adopt the identification framework introduced by Ahlswede and Dueck. In this approach, the receiver is only concerned with detecting whether a specific message of interest has been transmitted. Unlike Shannon transmission codes, the size of identification (ID) codes for a discrete memoryless channel (DMC) increases doubly exponentially with blocklength when using randomized encoding. This remarkable property makes the ID paradigm significantly more efficient than classical Shannon transmission in terms of energy consumption and hardware requirements. Another critical aspect of MC, influenced by the concept of the Internet of Bio-NanoThings, is security. In-body communication must be protected against potential eavesdroppers. To address this, we first analyze the DTPC for randomized identification (RI) and then extend our study to secure randomized identification (SRI). We derive capacity formulas for both RI and SRI, providing a comprehensive understanding of their performance and security implications.

</details>


### [28] [Thermodynamics a la Souriau on Kähler Non Compact Symmetric Spaces for Cartan Neural Networks](https://arxiv.org/abs/2512.16772)
*Pietro G. Fré,Alexander S. Sorin,Mario Trigiante*

Main category: cs.IT

TL;DR: 论文澄清了非紧致对称空间U/H上热力学的抽象几何表述问题，证明了只有Kähler型U/H支持Gibbs分布，并解决了温度空间的确定问题。


<details>
  <summary>Details</summary>
Motivation: 研究非紧致对称空间U/H上的热力学几何表述，这是Cartan神经网络隐藏层的数学模型。区分动力系统相关的广义热力学与Souriau提出的U/H上Gibbs概率分布，解决温度空间的确定问题。

Method: 采用抽象几何方法，利用李群U和子群H的结构，通过伴随作用和Cartan子代数分析温度空间。特别关注Kähler流形，利用Paint Group对称性将Poincaré和Siegel平面的构造扩展到Calabi-Vesentini流形类。

Result: 证明了只有Kähler型U/H支持Gibbs分布；确定了广义温度空间是U的伴随作用下Cartan子代数中正性域的轨道；展示了信息几何与热力学几何的等价性；证明了Gibbs分布在U对称变换下的协变性。

Conclusion: 建立了非紧致对称空间上热力学的完整几何框架，统一了信息几何与热力学几何，为Cartan神经网络提供了数学基础，Gibbs分布具有完全的U对称协变性。

Abstract: In this paper, we clarify several issues concerning the abstract geometrical formulation of thermodynamics on non compact symmetric spaces $\mathrm{U/H}$ that are the mathematical model of hidden layers in the new paradigm of Cartan Neural Networks. We introduce a distinction between the generalized thermodynamics associated with Dynamical Systems and the challenging proposal of Gibbs probability distributions on $\mathrm{U/H}$ provided by generalized thermodynamics {à} la Souriau. Main result is the proof that $\mathrm{U/H}$.s supporting Gibbs distributions are only the Kähler ones. For the latter, we solve the problem of determining the space of temperatures, namely of Lie algebra elements for which the partition function converges. The space of generalized temperatures is the orbit under the adjoint action of $\mathrm{U}$ of a positivity domain in the Cartan subalgebra $C_c\subset\mathbb{H}$ of the maximal compact subalgebra $\mathbb{H}\subset\mathbb{U}$. We illustrate how our explicit constructions for the Poincaré and Siegel planes might be extended to the whole class of Calabi-Vesentini manifolds utilizing Paint Group symmetry. Furthermore we claim that Rao's, Chentsov's, Amari's Information Geometry and the thermodynamical geometry of Ruppeiner and Lychagin are the very same thing. The most important property of the Gibbs probability distributions provided by the here introduced setup is their covariance with respect to the action of the full group of symmetries $\mathrm{U}$. The partition function is invariant against $\mathrm{U}$ transformations and the set of its arguments, namely the generalized temperatures, can be always reduced to a minimal set whose cardinality is equal to the rank of the compact denominator group $\mathrm{H}\subset \mathrm{U}$.

</details>


### [29] [An Extension of Enumerative Sphere Shaping for Arbitrary Channel Input Distributions](https://arxiv.org/abs/2512.16808)
*Frederik Ritter,Andrej Rode,Laurent Schmalen*

Main category: cs.IT

TL;DR: 本文提出了一种广义枚举球面成形（ESS）方法，能够生成任意离散信道输入分布，相比传统固定分布的ESS，可适用于更多类型的信道。


<details>
  <summary>Details</summary>
Motivation: 传统ESS只能产生固定的信道输入符号分布，限制了其在具有高斯类容量实现输入分布的信道中的应用。许多信道（如无放大相干光链路）具有非高斯容量实现输入分布，需要更灵活的分布成形算法。

Method: 将传统ESS中的固定权重替换为依赖于期望信道输入分布的权重，从而实现对任意离散信道输入分布的生成。结合概率幅度成形（PAS）技术，在256符号序列上进行传输仿真。

Result: 在无放大相干光链路简化模型仿真中，广义ESS在帧错误率低于10^{-4}时，相比CCDM将最大传输速率提高了0.0425比特/符号。

Conclusion: 广义ESS扩展了传统ESS的应用范围，使其能够适应更多类型的信道，特别是那些具有非高斯容量实现输入分布的信道，从而在多种通信场景中实现更高的传输速率。

Abstract: A non-uniform channel input distribution is key for achieving the capacity of arbitrary channels. However, message bits are generally assumed to follow a uniform distribution which must first be transformed to a non-uniform distribution by using a distribution matching algorithm. One such algorithm is enumerative sphere shaping (ESS). Compared to algorithms such as constant composition distribution matching (CCDM), ESS can utilize more channel input symbol sequences, allowing it to achieve a comparably low rate loss. However, the distribution of channel input symbols produced by ESS is fixed, restricting the utility of ESS to channels with Gaussian-like capacity-achieving input distributions. In this paper, we generalize ESS to produce arbitrary discrete channel input distributions, making it usable on most channels. Crucially, our generalization replaces fixed weights used internally by ESS with weights depending on the desired channel input distribution. We present numerical simulations using generalized ESS with probabilistic amplitude shaping (PAS) to transmit sequences of 256 symbols over a simplified model of an unamplified coherent optical link, a channel with a distinctly non-Gaussian capacity-achieving input distribution. In these simulations, we found that generalized ESS improves the maximum transmission rate by 0.0425 bit/symbol at a frame error rate below 10^{-4} compared to CCDM.

</details>


### [30] [Toward 6G Downlink NOMA: CRC-Aided GRAND for Noise-Resilient NOMA Decoding in Beyond-5G Networks](https://arxiv.org/abs/2512.16860)
*Emirhan Zor,Bora Bozkurt,Ferkan Yilmaz*

Main category: cs.IT

TL;DR: 提出一种结合CRC辅助GRAND解码与SIC的两用户下行功率域NOMA方案，通过噪声中心策略减少错误传播，提升BER性能


<details>
  <summary>Details</summary>
Motivation: 传统SIC方法在用户间功率差异较小时容易产生错误传播问题，需要更鲁棒的解码方案来提升NOMA系统性能

Method: 提出CRC辅助的GRAND解码与SIC结合的NOMA框架，利用GRAND的噪声中心策略系统性地测试候选错误模式，CRC不仅用于检错还辅助解码过程

Result: 在AWGN和Rayleigh衰落信道下，不同功率分配和用户距离条件下，CRC-aided GRAND-NOMA方案相比现有NOMA解码技术显著改善了BER性能

Conclusion: 将GRAND等通用解码方法集成到干扰受限的多用户环境中，对构建鲁棒的未来无线网络具有重要潜力

Abstract: Non-Orthogonal Multiple Access (NOMA) technology has emerged as a promising technology to enable massive connectivity and enhanced spectral efficiency in next-generation wireless networks. In this study, we propose a novel two-user downlink power-domain NOMA framework that integrates a Cyclic Redundancy Check (CRC)-aided Guessing Random Additive Noise Decoding (GRAND) with successive interference cancellation (SIC). Unlike conventional SIC methods, which are susceptible to error propagation when there is low power disparity between users, the proposed scheme leverages GRAND's noise-centric strategy to systematically rank and test candidate error patterns until the correct codeword is identified. In this architecture, CRC is utilized not only to detect errors but also to aid the decoding process, effectively eliminating the need for separate Forward Error Correction (FEC) codes and reducing overall system overhead. Furthermore, the strong user enhances its decoding performance by applying SIC that is reinforced by GRAND-based decoding of the weaker user's signals, thereby minimizing error propagation and increasing throughput. Comprehensive simulation results over both Additive White Gaussian Noise (AWGN) and Rayleigh fading channels, under varying power allocations and user distances, show that the CRC-aided GRAND-NOMA approach significantly improves the Bit Error Rate (BER) performance compared to state-of-the-art NOMA decoding techniques. These findings underscore the potential of integrating universal decoding methods like GRAND into interference-limited multiuser environments for robust future wireless networks.

</details>
