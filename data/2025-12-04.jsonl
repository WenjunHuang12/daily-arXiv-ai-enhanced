{"id": "2512.03124", "categories": ["cs.DS", "cs.CG"], "pdf": "https://arxiv.org/pdf/2512.03124", "abs": "https://arxiv.org/abs/2512.03124", "authors": ["Michael Souza", "Júlio Araújo", "John Kesley Costa", "Carlile Lavor"], "title": "On the Complexity of the Ordered Covering Problem in Distance Geometry", "comment": null, "summary": "The Ordered Covering Problem (OCP) arises in the context of the Discretizable Molecular Distance Geometry Problem (DMDGP), where the ordering of pruning edges significantly impacts the performance of the SBBU algorithm for protein structure determination. In recent work, Souza et al. (2023) formalized OCP as a hypergraph covering problem with ordered, exponential costs, and proposed a greedy heuristic that outperforms the original SBBU ordering by orders of magnitude. However, the computational complexity of finding optimal solutions remained open. In this paper, we prove that OCP is NP-complete through a polynomial-time reduction from the strongly NP-complete 3-Partition problem. Our reduction constructs a tight budget that forces optimal solutions to correspond exactly to valid 3-partitions. This result establishes a computational barrier for optimal edge ordering and provides theoretical justification for the heuristic approaches currently used in practice."}
{"id": "2512.03275", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.03275", "abs": "https://arxiv.org/abs/2512.03275", "authors": ["Aditya Anand", "Vincent Cohen-Addad", "Tommaso d'Orsi", "Anupam Gupta", "Euiwoong Lee", "Debmalya Panigrahi", "Sijin Peng"], "title": "Complexity of Local Search for CSPs Parameterized by Constraint Difference", "comment": "IPEC 2025", "summary": "In this paper, we study the parameterized complexity of local search, whose goal is to find a good nearby solution from the given current solution. Formally, given an optimization problem where the goal is to find the largest feasible subset $S$ of a universe $U$, the new input consists of a current solution $P$ (not necessarily feasible) as well as an ordinary input for the problem.\n  Given the existence of a feasible solution $S^*$, the goal is to find a feasible solution as good as $S^*$ in parameterized time $f(k) \\cdot n^{O(1)}$, where $k$ denotes the distance $|PΔS^*|$. This model generalizes numerous classical parameterized optimization problems whose parameter $k$ is the minimum number of elements removed from $U$ to make it feasible, which corresponds to the case $P = U$.\n  We apply this model to widely studied Constraint Satisfaction Problems (CSPs), where $U$ is the set of constraints, and a subset $U'$ of constraints is feasible if there is an assignment to the variables satisfying all constraints in $U'$. We give a complete characterization of the parameterized complexity of all boolean-alphabet symmetric CSPs, where the predicate's acceptance depends on the number of true literals."}
{"id": "2512.03304", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.03304", "abs": "https://arxiv.org/abs/2512.03304", "authors": ["Mirosław Kowaluk", "Andrzej Lingas", "Mia Persson"], "title": "Fast approximate $\\ell$-center clustering in high dimensional spaces", "comment": "18 pages", "summary": "We study the design of efficient approximation algorithms for the\n  $\\ell$-center clustering and minimum-diameter $\\ell$-clustering\n  problems in high dimensional Euclidean and Hamming spaces. Our main\n  tool is randomized dimension reduction. First, we present a general\n  method of reducing the dependency of the running time of a\n  hypothetical algorithm for the $\\ell$-center problem in a high\n  dimensional Euclidean space on the dimension size. Utilizing in\n  part this method, we provide $(2+ε)$- approximation\n  algorithms for the $\\ell$-center clustering and minimum-diameter\n  $\\ell$-clustering problems in Euclidean and Hamming spaces that are\n  substantially faster than the known $2$-approximation ones when both\n  $\\ell$ and the dimension are super-logarithmic. Next, we apply the\n  general method to the recent fast approximation algorithms with\n  higher approximation guarantees for the $\\ell$-center clustering\n  problem in a high dimensional Euclidean space. Finally, we provide a\n  speed-up of the known $O(1)$-approximation method for the\n  generalization of the $\\ell$-center clustering problem to include\n  $z$ outliers (i.e., $z$ input points can be ignored while computing\n  the maximum distance of an input point to a center) in high\n  dimensional Euclidean and Hamming spaces."}
{"id": "2512.03311", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.03311", "abs": "https://arxiv.org/abs/2512.03311", "authors": ["Sandy Irani", "Michael Luby"], "title": "Singing a MIS", "comment": "34 pages, 4 figures", "summary": "We introduce a broadcast model called the singing model, where agents are oblivious of the size and structure of the communication network, even their immediate neighborhood. Agents can sing multiple notes which are heard by their neighbors. The model is a generalization of the beeping model, where agents can only emit sound at a single frequency. We give a simple and natural protocol where agents compete with their neighbors and their strength is reflected in the number of notes they sing. It converges in $O(log(n))$ time with high probability, where $n$ is the number of agents in the network. The protocol works in an asynchronous model where rounds vary in length and have different start times. It works with completely dynamic networks where agents can be faulty. The protocol is the first to converge to an MIS in logarithmic time for dynamic networks in a network oblivious model."}
{"id": "2512.03975", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03975", "abs": "https://arxiv.org/abs/2512.03975", "authors": ["Kshipra Bhawalkar", "Alexandros Psomas", "Di Wang"], "title": "Sponsored Questions and How to Auction Them", "comment": null, "summary": "Online platforms connect users with relevant products and services using ads. A key challenge is that a user's search query often leaves their true intent ambiguous. Typically, platforms passively predict relevance based on available signals and in some cases offer query refinements. The shift from traditional search to conversational AI provides a new approach. When a user's query is ambiguous, a Large Language Model (LLM) can proactively offer several clarifying follow-up prompts. In this paper we consider the following: what if some of these follow-up prompts can be ``sponsored,'' i.e., selected for their advertising potential. How should these ``suggestion slots'' be allocated? And, how does this new mechanism interact with the traditional ad auction that might follow?\n  This paper introduces a formal model for designing and analyzing these interactive platforms. We use this model to investigate a critical engineering choice: whether it is better to build an end-to-end pipeline that jointly optimizes the user interaction and the final ad auction, or to decouple them into separate mechanisms for the suggestion slots and another for the subsequent ad slot. We show that the VCG mechanism can be adopted to jointly optimize the sponsored suggestion and the ads that follow; while this mechanism is more complex, it achieves outcomes that are efficient and truthful. On the other hand, we prove that the simple-to-implement modular approach suffers from strategic inefficiency: its Price of Anarchy is unbounded."}
{"id": "2512.03087", "categories": ["cs.MM", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03087", "abs": "https://arxiv.org/abs/2512.03087", "authors": ["Yanhui Li", "Qi Zhou", "Zhihong Xu", "Huizhong Guo", "Wenhai Wang", "Dongxia Wang"], "title": "When Harmful Content Gets Camouflaged: Unveiling Perception Failure of LVLMs with CamHarmTI", "comment": null, "summary": "Large vision-language models (LVLMs) are increasingly used for tasks where detecting multimodal harmful content is crucial, such as online content moderation. However, real-world harmful content is often camouflaged, relying on nuanced text-image interplay, such as memes or images with embedded malicious text, to evade detection. This raises a key question: \\textbf{can LVLMs perceive such camouflaged harmful content as sensitively as humans do?} In this paper, we introduce CamHarmTI, a benchmark for evaluating LVLM ability to perceive and interpret camouflaged harmful content within text-image compositions. CamHarmTI consists of over 4,500 samples across three types of image-text posts. Experiments on 100 human users and 12 mainstream LVLMs reveal a clear perceptual gap: humans easily recognize such content (e.g., over 95.75\\% accuracy), whereas current LVLMs often fail (e.g., ChatGPT-4o achieves only 2.10\\% accuracy). Moreover, fine-tuning experiments demonstrate that \\bench serves as an effective resource for improving model perception, increasing accuracy by 55.94\\% for Qwen2.5VL-7B. Attention analysis and layer-wise probing further reveal that fine-tuning enhances sensitivity primarily in the early layers of the vision encoder, promoting a more integrated scene understanding. These findings highlight the inherent perceptual limitations in LVLMs and offer insight into more human-aligned visual reasoning systems."}
{"id": "2512.03413", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03413", "abs": "https://arxiv.org/abs/2512.03413", "authors": ["Shu Wang", "Yingli Zhou", "Yixiang Fang"], "title": "BookRAG: A Hierarchical Structure-aware Index-based Approach for Retrieval-Augmented Generation on Complex Documents", "comment": null, "summary": "As an effective method to boost the performance of Large Language Models (LLMs) on the question answering (QA) task, Retrieval-Augmented Generation (RAG), which queries highly relevant information from external complex documents, has attracted tremendous attention from both industry and academia. Existing RAG approaches often focus on general documents, and they overlook the fact that many real-world documents (such as books, booklets, handbooks, etc.) have a hierarchical structure, which organizes their content from different granularity levels, leading to poor performance for the QA task. To address these limitations, we introduce BookRAG, a novel RAG approach targeted for documents with a hierarchical structure, which exploits logical hierarchies and traces entity relations to query the highly relevant information. Specifically, we build a novel index structure, called BookIndex, by extracting a hierarchical tree from the document, which serves as the role of its table of contents, using a graph to capture the intricate relationships between entities, and mapping entities to tree nodes. Leveraging the BookIndex, we then propose an agent-based query method inspired by the Information Foraging Theory, which dynamically classifies queries and employs a tailored retrieval workflow. Extensive experiments on three widely adopted benchmarks demonstrate that BookRAG achieves state-of-the-art performance, significantly outperforming baselines in both retrieval recall and QA accuracy while maintaining competitive efficiency."}
{"id": "2512.03278", "categories": ["cs.DB", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03278", "abs": "https://arxiv.org/abs/2512.03278", "authors": ["Michael Theologitis", "Dan Suciu"], "title": "Thucy: An LLM-based Multi-Agent System for Claim Verification across Relational Databases", "comment": "Accepted at AAAI 2026 Workshop on LLM-based Multi-Agent Systems (LaMAS)", "summary": "In today's age, it is becoming increasingly difficult to decipher truth from lies. Every day, politicians, media outlets, and public figures make conflicting claims$\\unicode{x2014}$often about topics that can, in principle, be verified against structured data. For instance, statements about crime rates, economic growth or healthcare can all be verified against official public records and structured datasets. Building a system that can automatically do that would have sounded like science fiction just a few years ago. Yet, with the extraordinary progress in LLMs and agentic AI, this is now within reach. Still, there remains a striking gap between what is technically possible and what is being demonstrated by recent work. Most existing verification systems operate only on small, single-table databases$\\unicode{x2014}$typically a few hundred rows$\\unicode{x2014}$that conveniently fit within an LLM's context window.\n  In this paper we report our progress on Thucy, the first cross-database, cross-table multi-agent claim verification system that also provides concrete evidence for each verification verdict. Thucy remains completely agnostic to the underlying data sources before deployment and must therefore autonomously discover, inspect, and reason over all available relational databases to verify claims. Importantly, Thucy also reports the exact SQL queries that support its verdict (whether the claim is accurate or not) offering full transparency to expert users familiar with SQL. When evaluated on the TabFact dataset$\\unicode{x2014}$the standard benchmark for fact verification over structured data$\\unicode{x2014}$Thucy surpasses the previous state of the art by 5.6 percentage points in accuracy (94.3% vs. 88.7%)."}
{"id": "2512.03096", "categories": ["cs.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.03096", "abs": "https://arxiv.org/abs/2512.03096", "authors": ["Daniel Alarcón-Martín", "Mari Carmen Aguayo-Torres", "Francisco J. Martín-Vega", "Gerardo Gómez"], "title": "CFO-Robust Detection for 5G PRACH under Fading Channels: Analytical Modeling and Performance Evaluation", "comment": "13 pages, 11 figures, journal", "summary": "The Physical Random Access Channel (PRACH) is essential for initial access and synchronization in both 5G and future 6G networks; however, its detection is highly sensitive to impairments such as high user density, large carrier frequency offset (CFO), and fast fading. Although prior studies have examined PRACH detection, they are often restricted to specific scenarios or lack a comprehensive analytical characterization of performance. We introduce a unified analytical framework that characterizes the statistical distribution of the received power delay profile (PDP) under flat Rayleigh fading and supports both coherent combining (CC) and power combining (PC) repetition strategies. For each strategy, we derive optimal threshold expressions and closed-form detection probabilities. Furthermore, we analyze two key cases depending on the coherence time: identical and independent channel realizations per repetition. Secondly, we exploit the correlation induced by CFO across cyclic shifts to design a novel low-complexity detector that exploits PDP dependencies. Numerical results indicate that PC outperforms CC when repetitions experience independent channels, while CC can be preferable under identical realizations in limited settings. On the other hand, the proposed CFO-aware detector delivers improved robustness under severe CFO conditions."}
{"id": "2512.03419", "categories": ["cs.DS", "cs.DM", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.03419", "abs": "https://arxiv.org/abs/2512.03419", "authors": ["Bharat Sharman", "Elkafi Hassini"], "title": "Comparative algorithm performance evaluation and prediction for the maximum clique problem using instance space analysis", "comment": null, "summary": "The maximum clique problem, a well-known graph-based combinatorial optimization problem, has been addressed through various algorithmic approaches, though systematic analyses of the problem instances remain sparse. This study employs the instance space analysis (ISA) methodology to systematically analyze the instance space of this problem and assess & predict the performance of state-of-the-art (SOTA) algorithms, including exact, heuristic, and graph neural network (GNN)-based methods. A dataset was compiled using graph instances from TWITTER, COLLAB and IMDB-BINARY benchmarks commonly used in graph machine learning research. A set of 33 generic and 2 problem-specific polynomial-time-computable graph-based features, including several spectral properties, was employed for the ISA. A composite performance mea- sure incorporating both solution quality and algorithm runtime was utilized. The comparative analysis demonstrated that the exact algorithm Mixed Order Maximum Clique (MOMC) exhib- ited superior performance across approximately 74.7% of the instance space constituted by the compiled dataset. Gurobi & CliSAT accounted for superior performance in 13.8% and 11% of the instance space, respectively. The ISA-based algorithm performance prediction model run on 34 challenging test instances compiled from the BHOSLIB and DIMACS datasets yielded top-1 and top-2 best performing algorithm prediction accuracies of 88% and 97%, respectively."}
{"id": "2512.03521", "categories": ["cs.MM", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.03521", "abs": "https://arxiv.org/abs/2512.03521", "authors": ["Xiaosen Lyu", "Jiayu Xiong", "Yuren Chen", "Wanlong Wang", "Xiaoqing Dai", "Jing Wang"], "title": "Cross-Space Synergy: A Unified Framework for Multimodal Emotion Recognition in Conversation", "comment": "Accepted to AAAI 2026", "summary": "Multimodal Emotion Recognition in Conversation (MERC) aims to predict speakers' emotions by integrating textual, acoustic, and visual cues. Existing approaches either struggle to capture complex cross-modal interactions or experience gradient conflicts and unstable training when using deeper architectures. To address these issues, we propose Cross-Space Synergy (CSS), which couples a representation component with an optimization component. Synergistic Polynomial Fusion (SPF) serves the representation role, leveraging low-rank tensor factorization to efficiently capture high-order cross-modal interactions. Pareto Gradient Modulator (PGM) serves the optimization role, steering updates along Pareto-optimal directions across competing objectives to alleviate gradient conflicts and improve stability. Experiments show that CSS outperforms existing representative methods on IEMOCAP and MELD in both accuracy and training stability, demonstrating its effectiveness in complex multimodal scenarios."}
{"id": "2512.03439", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.03439", "abs": "https://arxiv.org/abs/2512.03439", "authors": ["Yaqi Wang", "Haojia Sun", "Shuting Zhang"], "title": "LLM as Explainable Re-Ranker for Recommendation System", "comment": null, "summary": "The application of large language models (LLMs) in recommendation systems has recently gained traction. Traditional recommendation systems often lack explainability and suffer from issues such as popularity bias. Previous research has also indicated that LLMs, when used as standalone predictors, fail to achieve accuracy comparable to traditional models. To address these challenges, we propose to use LLM as an explainable re-ranker, a hybrid approach that combines traditional recommendation models with LLMs to enhance both accuracy and interpretability. We constructed a dataset to train the re-ranker LLM and evaluated the alignment between the generated dataset and human expectations. Leveraging a two-stage training process, our model significantly improved NDCG, a key ranking metric. Moreover, the re-ranker outperformed a zero-shot baseline in ranking accuracy and interpretability. These results highlight the potential of integrating traditional recommendation models with LLMs to address limitations in existing systems and pave the way for more explainable and fair recommendation frameworks."}
{"id": "2512.03389", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.03389", "abs": "https://arxiv.org/abs/2512.03389", "authors": ["Shu Chen", "Deepti Raghavan", "Uğur Çetintemel"], "title": "Continuous Prompts: LLM-Augmented Pipeline Processing over Unstructured Streams", "comment": null, "summary": "Monitoring unstructured streams increasingly requires persistent, semantics-aware computation, yet today's LLM frameworks remain stateless and one-shot, limiting their usefulness for long-running analytics. We introduce Continuous Prompts (CPs), the first framework that brings LLM reasoning into continuous stream processing. CPs extend RAG to streaming settings, define continuous semantic operators, and provide multiple implementations, primarily focusing on LLM-based approaches but also reporting one embedding-based variants. Furthermore, we study two LLM-centric optimizations, tuple batching and operator fusion, to significantly improve efficiency while managing accuracy loss.\n  Because these optimizations inherently trade accuracy for speed, we present a dynamic optimization framework that uses lightweight shadow executions and cost-aware multi-objective Bayesian optimization (MOBO) to learn throughput-accuracy frontiers and adapt plans under probing budgets.\n  We implement CPs in the VectraFlow stream processing system. Using operator-level microbenchmarks and streaming pipelines on real datasets, we show that VectraFlow can adapt to workload dynamics, navigate accuracy-efficiency trade-offs, and sustain persistent semantic queries over evolving unstructured streams."}
{"id": "2512.03117", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.03117", "abs": "https://arxiv.org/abs/2512.03117", "authors": ["Peijie Li", "Guangyue Han"], "title": "Strengthening Han's Fourier Entropy-Influence Inequality via an Information-Theoretic Proof", "comment": "4 pages", "summary": "We strengthen Han's Fourier entropy-influence inequality $$ H[\\widehat{f}] \\leq C_{1}I(f) + C_{2}\\sum_{i\\in [n]}I_{i}(f)\\ln\\frac{1}{I_{i}(f)} $$ originally proved for $\\{-1,1\\}$-valued Boolean functions with $C_{1}=3+2\\ln 2$ and $C_{2}=1$. We show, by a short information-theoretic proof, that it in fact holds with sharp constants $C_{1}=C_{2}=1$ for all real-valued Boolean functions of unit $L^{2}$-norm, thereby establishing the inequality as an elementary structural property of Shannon entropy and influence."}
{"id": "2512.03718", "categories": ["cs.DS", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03718", "abs": "https://arxiv.org/abs/2512.03718", "authors": ["Robert Ganian", "Hung P. Hoang", "Simon Wietheger"], "title": "Matrix Editing Meets Fair Clustering: Parameterized Algorithms and Complexity", "comment": null, "summary": "We study the computational problem of computing a fair means clustering of discrete vectors, which admits an equivalent formulation as editing a colored matrix into one with few distinct color-balanced rows by changing at most $k$ values. While NP-hard in both the fairness-oblivious and the fair settings, the problem is well-known to admit a fixed-parameter algorithm in the former ``vanilla'' setting. As our first contribution, we exclude an analogous algorithm even for highly restricted fair means clustering instances. We then proceed to obtain a full complexity landscape of the problem, and establish tractability results which capture three means of circumventing our obtained lower bound: placing additional constraints on the problem instances, fixed-parameter approximation, or using an alternative parameterization targeting tree-like matrices."}
{"id": "2512.03514", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.03514", "abs": "https://arxiv.org/abs/2512.03514", "authors": ["Adithya S Kolavi", "Vyoman Jain"], "title": "M3DR: Towards Universal Multilingual Multimodal Document Retrieval", "comment": null, "summary": "Multimodal document retrieval systems have shown strong progress in aligning visual and textual content for semantic search. However, most existing approaches remain heavily English-centric, limiting their effectiveness in multilingual contexts. In this work, we present M3DR (Multilingual Multimodal Document Retrieval), a framework designed to bridge this gap across languages, enabling applicability across diverse linguistic and cultural contexts. M3DR leverages synthetic multilingual document data and generalizes across different vision-language architectures and model sizes, enabling robust cross-lingual and cross-modal alignment. Using contrastive training, our models learn unified representations for text and document images that transfer effectively across languages. We validate this capability on 22 typologically diverse languages, demonstrating consistent performance and adaptability across linguistic and script variations. We further introduce a comprehensive benchmark that captures real-world multilingual scenarios, evaluating models under monolingual, multilingual, and mixed-language settings. M3DR generalizes across both single dense vector and ColBERT-style token-level multi-vector retrieval paradigms. Our models, NetraEmbed and ColNetraEmbed achieve state-of-the-art performance with ~150% relative improvements on cross-lingual retrieval."}
{"id": "2512.03401", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.03401", "abs": "https://arxiv.org/abs/2512.03401", "authors": ["Ryoto Miyamoto", "Akira Kasuga"], "title": "Enterprise Data Science Platform: A Unified Architecture for Federated Data Access", "comment": "10 pages, 2 figures, 3 tables, WS-D2ET @ IEEE BigData 2025", "summary": "Organizations struggle to share data across departments that have adopted different data analytics platforms. If n datasets must serve m environments, up to n*m replicas can emerge, increasing inconsistency and cost. Traditional warehouses copy data into vendor-specific stores; cross-platform access is hard. This study proposes the Enterprise Data Science Platform (EDSP), which builds on data lakehouse architecture and follows a Write-Once, Read-Anywhere principle. EDSP enables federated data access for multi-query engine environments, targeting data science workloads with periodic data updates and query response times ranging from seconds to minutes. By providing centralized data management with federated access from multiple query engines to the same data sources, EDSP eliminates data duplication and vendor lock-in inherent in traditional data warehouses. The platform employs a four-layer architecture: Data Preparation, Data Store, Access Interface, and Query Engines. This design enforces separation of concerns and reduces the need for data migration when integrating additional analytical environments. Experimental results demonstrate that major cloud data warehouses and programming environments can directly query EDSP-managed datasets. We implemented and deployed EDSP in production, confirming interoperability across multiple query engines. For data sharing across different analytical environments, EDSP achieves a 33-44% reduction in operational steps compared with conventional approaches requiring data migration. Although query latency may increase by up to a factor of 2.6 compared with native tables, end-to-end completion times remain on the order of seconds, maintaining practical performance for analytical use cases. Based on our production experience, EDSP provides practical design guidelines for addressing the data-silo problem in multi-query engine environments."}
{"id": "2512.03241", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.03241", "abs": "https://arxiv.org/abs/2512.03241", "authors": ["Mohammad Moltafet", "Hamid R. Sadjadpour", "Zouheir Rezki", "Marian Codreanu", "Roy D. Yates"], "title": "Multi-Source M/G/1/1 Queues with Probabilistic Preemption", "comment": null, "summary": "We consider a multi-source status update system consisting of multiple independent sources, a single server, and a single sink. Each source generates packets according to a Poisson process, and packets are served according to a general service time distribution. The system has a capacity of one packet, i.e., no waiting buffer, and is modeled as a multi-source M/G/1/1 queueing system. We introduce a probabilistically preemptive packet management policy, under which an existing packet from the same source in the system is replaced by an arriving packet with a fixed probability. We derive the moment generating functions (MGFs) of the age of information (AoI) and peak AoI (PAoI) for each source under this policy. Numerical results demonstrate the effectiveness of the proposed packet management policy."}
{"id": "2512.03843", "categories": ["cs.DS", "cs.CG"], "pdf": "https://arxiv.org/pdf/2512.03843", "abs": "https://arxiv.org/abs/2512.03843", "authors": ["Malory Marin", "Jean-Florent Raymond", "Rémi Watrigant"], "title": "Robust Algorithms for Path and Cycle Problems in Geometric Intersection Graphs", "comment": null, "summary": "We study the design of robust subexponential algorithms for classical connectivity problems on intersection graphs of similarly sized fat objects in $\\mathbb{R}^d$. In this setting, each vertex corresponds to a geometric object, and two vertices are adjacent if and only if their objects intersect. We introduce a new tool for designing such algorithms, which we call a $λ$-linked partition. This is a partition of the vertex set into groups of highly connected vertices. Crucially, such a partition can be computed in polynomial time and does not require access to the geometric representation of the graph. We apply this framework to problems related to paths and cycles in graphs. First, we obtain the first robust ETH-tight algorithms for Hamiltonian Path and Hamiltonian Cycle, running in time $2^{O(n^{1-1/d})}$ on intersection graphs of similarly sized fat objects in $\\mathbb{R}^d$. This resolves an open problem of de Berg et al. [STOC 2018] and completes the study of these problems on geometric intersection graphs from the viewpoint of ETH-tight exact algorithms. We further extend our approach to the parameterized setting and design the first robust subexponential parameterized algorithm for Long Path in any fixed dimension $d$. More precisely, we obtain a randomized robust algorithm running in time $2^{O(k^{1-1/d}\\log^2 k)}\\, n^{O(1)}$ on intersection graphs of similarly sized fat objects in $\\mathbb{R}^d$, where $k$ is the natural parameter. Besides $λ$-linked partitions, our algorithm also relies on a low-treewidth pattern covering theorem that we establish for geometric intersection graphs, which may be viewed as a refinement of a result of Marx-Pilipczuk [ESA 2017]. This structural result may be of independent interest."}
{"id": "2512.03807", "categories": ["cs.IR", "eess.SP", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.03807", "abs": "https://arxiv.org/abs/2512.03807", "authors": ["Christos Kolomvakis", "Thomas Bobille", "Arnaud Vandaele", "Nicolas Gillis"], "title": "Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics", "comment": "24 pages, 12 tables, 3 figures, code and data available from https://gitlab.com/ckolomvakis/boolean-matrix-factorization-ip-and-heuristics", "summary": "Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging."}
{"id": "2512.03790", "categories": ["cs.DB", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.03790", "abs": "https://arxiv.org/abs/2512.03790", "authors": ["Iris Beerepoot", "Vinicius Stein Dani", "Xixi Lu"], "title": "ExOAR: Expert-Guided Object and Activity Recognition from Textual Data", "comment": "Accepted manuscript (on August 22, 2025) to the 2nd International Workshop on Generative AI for Process Mining (GenAI4PM 2025), held in conjunction with the 7th International Conference on Process Mining (ICPM 2025)", "summary": "Object-centric process mining requires structured data, but extracting it from unstructured text remains a challenge. We introduce ExOAR (Expert-Guided Object and Activity Recognition), an interactive method that combines large language models (LLMs) with human verification to identify objects and activities from textual data. ExOAR guides users through consecutive stages in which an LLM generates candidate object types, activities, and object instances based on contextual input, such as a user's profession, and textual data. Users review and refine these suggestions before proceeding to the next stage. Implemented as a practical tool, ExOAR is initially validated through a demonstration and then evaluated with real-world Active Window Tracking data from five users. Our results show that ExOAR can effectively bridge the gap between unstructured textual data and the structured log with clear semantics needed for object-centric process analysis, while it maintains flexibility and human oversight."}
{"id": "2512.03326", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.03326", "abs": "https://arxiv.org/abs/2512.03326", "authors": ["Keigo Takeuchi"], "title": "Generalized Orthogonal Approximate Message-Passing for Sublinear Sparsity", "comment": "Long version of a manuscript submitted to IEEE Trans. Inf. Theory", "summary": "This paper addresses the reconstruction of sparse signals from generalized linear measurements. Signal sparsity is assumed to be sublinear in the signal dimension while it was proportional to the signal dimension in conventional research. Approximate message-passing (AMP) has poor convergence properties for sensing matrices beyond standard Gaussian matrices. To solve this convergence issue, generalized orthogonal AMP (GOAMP) is proposed for signals with sublinear sparsity. The main feature of GOAMP is the so-called Onsager correction to realize asymptotic Gaussianity of estimation errors. The Onsager correction in GOAMP is designed via state evolution for orthogonally invariant sensing matrices in the sublinear sparsity limit, where the signal sparsity and measurement dimension tend to infinity at sublinear speed in the signal dimension. When the support of non-zero signals does not contain a neighborhood of the origin, GOAMP using Bayesian denoisers is proved to achieve error-free signal reconstruction for linear measurements if and only if the measurement dimension is larger than a threshold, which is equal to that of AMP for standard Gaussian sensing matrices. Numerical simulations are also presented for linear measurements and 1-bit compressed sensing. When ill-conditioned sensing matrices are used, GOAMP for sublinear sparsity is shown to outperform existing reconstruction algorithms, including generalized AMP for sublinear sparsity."}
{"id": "2512.03960", "categories": ["cs.DS", "cs.DM", "cs.SI"], "pdf": "https://arxiv.org/pdf/2512.03960", "abs": "https://arxiv.org/abs/2512.03960", "authors": ["Noga Alon", "Sabyasachi Basu", "Shweta Jain", "Haim Kaplan", "Jakub Łącki", "Blair D. Sullivan"], "title": "Aggregating maximal cliques in real-world graphs", "comment": null, "summary": "Maximal clique enumeration is a fundamental graph mining task, but its utility is often limited by computational intractability and highly redundant output. To address these challenges, we introduce \\emph{$ρ$-dense aggregators}, a novel approach that succinctly captures maximal clique structure. Instead of listing all cliques, we identify a small collection of clusters with edge density at least $ρ$ that collectively contain every maximal clique.\n  In contrast to maximal clique enumeration, we prove that for all $ρ< 1$, every graph admits a $ρ$-dense aggregator of \\emph{sub-exponential} size, $n^{O(\\log_{1/ρ}n)}$, and provide an algorithm achieving this bound. For graphs with bounded degeneracy, a typical characteristic of real-world networks, our algorithm runs in near-linear time and produces near-linear size aggregators. We also establish a matching lower bound on aggregator size, proving our results are essentially tight. In an empirical evaluation on real-world networks, we demonstrate significant practical benefits for the use of aggregators: our algorithm is consistently faster than the state-of-the-art clique enumeration algorithm, with median speedups over $6\\times$ for $ρ=0.1$ (and over $300\\times$ in an extreme case), while delivering a much more concise structural summary."}
{"id": "2512.04009", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.04009", "abs": "https://arxiv.org/abs/2512.04009", "authors": ["Jie Tang", "Daochen Zha", "Xin Liu", "Huiji Gao", "Liwei He", "Stephanie Moyerman", "Sanjeev Katariya"], "title": "Learning to Comparison-Shop", "comment": null, "summary": "In online marketplaces like Airbnb, users frequently engage in comparison shopping before making purchase decisions. Despite the prevalence of this behavior, a significant disconnect persists between mainstream e-commerce search engines and users' comparison needs. Traditional ranking models often evaluate items in isolation, disregarding the context in which users compare multiple items on a search results page. While recent advances in deep learning have sought to improve ranking accuracy, diversity, and fairness by encoding listwise context, the challenge of aligning search rankings with user comparison shopping behavior remains inadequately addressed. In this paper, we propose a novel ranking architecture - Learning-to-Comparison-Shop (LTCS) System - that explicitly models and learns users' comparison shopping behaviors. Through extensive offline and online experiments, we demonstrate that our approach yields statistically significant gains in key business metrics - improving NDCG by 1.7% and boosting booking conversion rate by 0.6% in A/B testing - while also enhancing user experience. We also compare our model against state-of-the-art approaches and demonstrate that LTCS significantly outperforms them."}
{"id": "2512.03906", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.03906", "abs": "https://arxiv.org/abs/2512.03906", "authors": ["Alberto Ronzoni", "Anina Antony", "Anjana M R", "Francesca De Leo", "Jesna Jose", "Mattia Freda", "Nandini Narayanankutty", "Rafflesia Khan", "Raji RV", "Thomas Diacci"], "title": "IBM Multilevel Process Mining vs de facto Object-Centric Process Mining approaches", "comment": null, "summary": "The academic evolution of process mining is moving toward object centric process mining, marking a significant shift in how processes are modeled and analyzed. IBM has developed its own distinctive approach called Multilevel Process Mining. This paper provides a description of the two approaches and presents a comparative analysis of their respective advantages and limitations. IBM leveraged this comparison to drive the evolution of IBM Process Mining product, creating the new Organizational Mining feature, an innovation that combines the best of the two approaches. Demonstrate the potential of this novel, innovative and distinct methodology with an example."}
{"id": "2512.03518", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.03518", "abs": "https://arxiv.org/abs/2512.03518", "authors": ["Chaorong Zhang", "Benjamin K. Ng", "Ke Wang", "Hui Xu", "Chan-Tong Lam"], "title": "From Reliability to Security: How RIS-Assisted Adaptive SM and SSK Enhances Wireless Systems", "comment": "Submitted in IEEE journals", "summary": "This paper proposes two novel wireless transmission schemes, namely reconfigurable intelligent surface (RIS)-assisted received adaptive spatial modulation (RASM) scheme and RIS-assisted received adaptive space shift keying (RASSK) scheme, designed to enhance spectral efficiency (SE) and physical layer security (PLS).In both proposed schemes, transmitting bits are dynamically mapped at receive antennas by leveraging the characteristics of the RIS in each time slot, which enables the enhancement of signal-to-noise ratio (SNR) at specific selected antennas with near few power, thus leading a reliable and green wireless communication. This adaptive approach facilitates the conveyance of extra bits to the receiver, which means it needs less cost of radio-frequency chains at transmitter while improving SE. Besides, the proposed schemes offer an inherent PLS security advantage, as the eavesdropper is unable to completely detect signals reflected from the RIS. To comprehensively evaluate the performance of the proposed RASM and RASSK schemes, this paper presents a detailed analytical performance of their spectral efficiency, detection complexity, bit error rate, and secrecy rate, which are accompanied by insightful findings and conclusions. Simulation and analytical results demonstrate the superiority of the proposed schemes, showcasing their improved error performance and robustness against wiretapping, while also highlighting the potential of the RASM and RASSK schemes for future wireless applications."}
{"id": "2512.03612", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.03612", "abs": "https://arxiv.org/abs/2512.03612", "authors": ["Saeed Rasouli", "Hamid Karamikabir"], "title": "Expected Confidence Dependency: A Novel Rough Set-Based Approach to Feature Selection", "comment": "33 pages, 5 figures", "summary": "This paper proposes Expected Confidence Dependency (ECD), a novel, soft computing-oriented, accuracy driven dependency measure for feature selection within the rough set theory framework. Unlike traditional rough set dependency measures that rely on binary characterizations of conditional blocks, ECD assigns confidence-based contributions to individual equivalence blocks and aggregates them through a normalized expectation operator. We formally establish several desirable properties of ECD, including normalization, compatibility with classical dependency, monotonicity, and invariance under structural and label-preserving transformations."}
{"id": "2512.03719", "categories": ["cs.IT", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.03719", "abs": "https://arxiv.org/abs/2512.03719", "authors": ["Seyed Mohammad Azimi-Abarghouyi", "Carlo Fischione", "Kaibin Huang"], "title": "Over-the-Air Federated Learning: Rethinking Edge AI Through Signal Processing", "comment": null, "summary": "Over-the-Air Federated Learning (AirFL) is an emerging paradigm that tightly integrates wireless signal processing and distributed machine learning to enable scalable AI at the network edge. By leveraging the superposition property of wireless signals, AirFL performs communication and model aggregation of the learning process simultaneously, significantly reducing latency, bandwidth, and energy consumption. This article offers a tutorial treatment of AirFL, presenting a novel classification into three design approaches: CSIT-aware, blind, and weighted AirFL. We provide a comprehensive guide to theoretical foundations, performance analysis, complexity considerations, practical limitations, and prospective research directions."}
{"id": "2512.03872", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.03872", "abs": "https://arxiv.org/abs/2512.03872", "authors": ["Matteo Nerini", "Bruno Clerckx"], "title": "Movable Signals with Dual-Polarized Fixed Intelligent Surfaces: Beyond Diagonal Reflection Matrices", "comment": "Submitted to IEEE for publication", "summary": "This paper investigates wireless systems aided by dual-polarized intelligent surfaces. We compare reconfigurable intelligent surface (RIS), which adjust their reflection matrices, with movable signals operating with fixed intelligent surface (FIS), which adjust the signal frequency while the surface properties remain fixed. For both RIS and FIS, we consider surfaces with a diagonal reflection matrix, named diagonal RIS/FIS, and surfaces with a reflection matrix not limited to being diagonal, named beyond-diagonal RIS/FIS. Movable signals with FIS always outperform RIS, achieving at least a fourfold gain. When transmitter and receiver polarizations differ, beyond-diagonal FIS further enhances performance."}
{"id": "2512.04020", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.04020", "abs": "https://arxiv.org/abs/2512.04020", "authors": ["Inocencio Ortiz", "Santiago Gómez-Guerrero", "Christian E. Schaerer"], "title": "On topological and algebraic structures of categorical random variables", "comment": "18 pages", "summary": "Based on entropy and symmetrical uncertainty (SU), we define a metric for categorical random variables and show that this metric can be promoted into an appropriate quotient space of categorical random variables. Moreover, we also show that there is a natural commutative monoid structure in the same quotient space, which is compatible with the topology induced by the metric, in the sense that the monoid operation is continuous."}
{"id": "2512.04077", "categories": ["cs.IT", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.04077", "abs": "https://arxiv.org/abs/2512.04077", "authors": ["Ismail Cosandal", "Sennur Ulukus", "Nail Akar"], "title": "Semi-Markov Decision Process Framework for Age of Incorrect Information Minimization", "comment": null, "summary": "For a remote estimation system, we study age of incorrect information (AoII), which is a recently proposed semantic-aware freshness metric. In particular, we assume an information source observing a discrete-time finite-state Markov chain (DTMC) and employing push-based transmissions of status update packets towards the monitor which is tasked with remote estimation of the source. The source-to-monitor channel delay is assumed to have a general discrete-time phase-type (DPH) distribution, whereas the zero-delay reverse channel ensures that the source has perfect information on AoII and the remote estimate. A multi-threshold transmission policy is employed where packet transmissions are initiated when the AoII process exceeds a threshold which may be different for each estimation value. In this general setting, our goal is to minimize the weighted sum of time average of an arbitrary function of AoII and estimation, and transmission costs, by suitable choice of the thresholds. We formulate the problem as a semi-Markov decision process (SMDP) with the same state-space as the original DTMC to obtain the optimum multi-threshold policy whereas the parameters of the SMDP are obtained by using a novel stochastic tool called dual-regime absorbing Markov chain (DR-AMC), and its corresponding absorption time distribution named as dual-regime DPH (DR-DPH)."}
