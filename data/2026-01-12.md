<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 12]
- [cs.DS](#cs.DS) [Total: 2]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.DB](#cs.DB) [Total: 6]
- [cs.GT](#cs.GT) [Total: 4]
- [cs.IR](#cs.IR) [Total: 23]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [On the Limits of Self-Improving in LLMs and Why AGI, ASI and the Singularity Are Not Near Without Symbolic Model Synthesis](https://arxiv.org/abs/2601.05280)
*Hector Zenil*

Main category: cs.IT

TL;DR: 论文将LLM递归自训练形式化为离散动力系统，证明随着训练数据越来越自生成，系统必然退化，出现熵衰减和方差放大两种失败模式，并提出神经符号混合方法作为解决方案。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型和生成式AI中递归自训练的退化动态，揭示纯粹基于分布学习的方法在数据自生成情况下的根本性局限。

Method: 将递归自训练形式化为离散时间动力系统，分析训练数据自生成比例趋近于零时的动态特性，推导出熵衰减和方差放大两种失败模式，并提出基于算法概率的符号回归和程序合成作为解决方案。

Result: 证明随着训练数据越来越自生成，系统必然经历退化动态：熵衰减导致分布多样性单调损失（模式崩溃），方差放大导致模型对真理的表征随机漂移。这些行为不是架构依赖的，而是有限样本分布学习的必然结果。

Conclusion: 纯粹分布学习必然导致模型崩溃，而结合算法概率的神经符号混合方法能够识别生成机制而非仅仅相关性，突破了标准统计学习的数据处理不等式限制，为持续自我改进提供了连贯框架。

Abstract: We formalise recursive self-training in Large Language Models (LLMs) and Generative AI as a discrete-time dynamical system and prove that, as training data become increasingly self-generated ($α_t \to 0$), the system undergoes inevitably degenerative dynamics. We derive two fundamental failure modes: (1) Entropy Decay, where finite sampling effects cause a monotonic loss of distributional diversity (mode collapse), and (2) Variance Amplification, where the loss of external grounding causes the model's representation of truth to drift as a random walk, bounded only by the support diameter. We show these behaviours are not contingent on architecture but are consequences of distributional learning on finite samples. We further argue that Reinforcement Learning with imperfect verifiers suffers similar semantic collapse. To overcome these limits, we propose a path involving symbolic regression and program synthesis guided by Algorithmic Probability. The Coding Theorem Method (CTM) allows for identifying generative mechanisms rather than mere correlations, escaping the data-processing inequality that binds standard statistical learning. We conclude that while purely distributional learning leads to model collapse, hybrid neurosymbolic approaches offer a coherent framework for sustained self-improvement.

</details>


### [2] [Multi-User Covert Communications via Intelligent Spectrum Control](https://arxiv.org/abs/2601.05281)
*Yujie Ling,Zan Li,Lei Guan,Zheng Zhang,Dusit Niyato*

Main category: cs.IT

TL;DR: 该论文提出了一种智能频谱控制方案，用于多小区场景下的多用户隐蔽通信，通过AI辅助实时决策生成动态频谱占用模式，提高隐蔽性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在多小区环境中，同时存在窃听者和恶意干扰者的情况下，如何实现多用户隐蔽通信是一个挑战。传统方法难以在固定带宽下同时避免外部干扰和系统内同频碰撞。

Method: 提出智能频谱控制方案，结合高精度频谱感知和AI辅助实时决策，为多个合法用户生成时频动态占用模式。推导了窃听者检测错误概率和合法用户可靠传输概率的闭式表达式，并优化了传输功率和最大用户数。

Result: 仿真结果显示分析结果与蒙特卡洛曲线高度匹配，所提方案相比基准方案能实现更高的检测错误概率、更大的可靠传输概率和更大的多用户容量。

Conclusion: 智能频谱控制方案能有效提高多用户隐蔽通信的性能，在给定隐蔽性和可靠性约束下优化系统参数，为实际部署提供了理论依据。

Abstract: This paper investigates the performance of multi-user covert communications over a fixed bandwidth in a multi-cell scenario with both eavesdroppers and malicious jammers. We propose an intelligent spectrum control (ISC) scheme that combines high-accuracy spectrum sensing with AI-assisted real-time decision-making to generate time-frequency dynamic occupation patterns for multiple legitimate users. The scheme can proactively avoid external interference and intra-system co-channel collisions, thereby improving covertness and reliability. Within this framework, we derive closed-form expressions for the detection error probability (DEP) of the eavesdropper and the reliable transmission probability (RTP) of legitimate users under multi-user joint detection. We then analytically optimize the transmission power that can maximize the covert rate (CR), as well as the maximum number of users that can access the system covertly and concurrently under given covertness and reliability constraints. Simulation results confirm the tight match between the analytical and Monte Carlo curves, and show that the proposed scheme can achieve a higher DEP, a larger RTP, and a greater multi-user capacity than the benchmark scheme.

</details>


### [3] [Secure Communication via Modulation Order Confusion](https://arxiv.org/abs/2601.05292)
*Jingyi Wang,Fanggang Wang*

Main category: cs.IT

TL;DR: 提出基于调制阶数混淆的安全通信框架，通过伪装调制阶数误导窃听者，保护无线通信安全。


<details>
  <summary>Details</summary>
Motivation: 调制分类技术对无线安全构成威胁，需要开发能够抵御调制分类攻击的安全通信方案。

Method: 针对单天线系统提出符号随机映射和符号时间分集方案；针对多天线系统提出基于级数展开和星座路径的信号设计，并扩展到RIS辅助系统。

Result: 所提方案能有效击败基于深度学习和专家知识的调制分类器，同时不降低通信性能。

Conclusion: 调制阶数混淆是一种有效的物理层安全技术，能够在不影响合法通信的情况下保护无线传输免受调制分类攻击。

Abstract: With the increasing threat posed by modulation classification to wireless security, this paper proposes a secure communication framework based on modulation order confusion (MOC), which intentionally disguises the original modulation as a higher- or lower-order one to mislead eavesdroppers. For single-antenna systems, two schemes are developed: symbol random mapping and symbol time diversity, enabling modulation order confusion with customized receivers. For multi-antenna systems, receiver-transparent MOC schemes are proposed, including series-expansion-based and constellation-path-based signal designs, and are further extended to RIS-assisted systems with joint beamformer and RIS reflection design. Numerical results show that the proposed schemes effectively defeat both deep-learning-based and expert-knowledge-based modulation classifiers without degrading communication performance.

</details>


### [4] [The Number of Cycles of Bi-regular Tanner Graphs in Terms of the Eigenvalues of the Adjacency Matrix](https://arxiv.org/abs/2601.05340)
*Roxana Smarandache,David G. M. Mitchell*

Main category: cs.IT

TL;DR: 该论文研究了LDPC码图中环与邻接矩阵特征值之间的新联系，推导了双正则图中短环数量的快速递归公式，并给出了前7个环数的显式特征值表达式。


<details>
  <summary>Details</summary>
Motivation: 研究LDPC码图中环与邻接矩阵特征值之间的新联系，旨在为双正则图（特别是QC-LDPC码）提供计算环数量的高效方法。传统计算环数的方法通常计算复杂度高，而利用特征值可以简化计算过程。

Method: 通过分析双正则图中环与邻接矩阵特征值之间的关系，推导出计算环数N_{2k}（k<g）的快速递归公式。特别针对周长g的双正则图，给出了k≤7时环数的显式特征值表达式。研究聚焦于双正则QC-LDPC码，利用其块循环矩阵特性高效计算特征值。

Result: 建立了LDPC码图中环数与邻接矩阵特征值之间的数学联系，推导出计算短环数量的递归公式和显式表达式。对于双正则QC-LDPC码，可以利用块循环矩阵技术高效计算特征值，从而快速确定环数。

Conclusion: 该研究揭示了LDPC码图中环与特征值之间的新联系，为双正则图（特别是QC-LDPC码）提供了计算环数量的高效方法。这些结果对于LDPC码设计和分析具有重要意义，能够帮助设计具有更好性能的编码方案。

Abstract: In this paper, we explore new connections between the cycles in the graph of low-density parity-check (LDPC) codes and the eigenvalues of the corresponding adjacency matrix. The resulting observations are used to derive fast, simple, recursive formulas for the number of cycles $N_{2k}$ of length $2k$, $k<g$, in a bi-regular graph of girth $g$. Moreover, we derive explicit formulas for $N_{2k}$, $k\leq 7$, in terms of the nonzero eigenvalues of the adjacency matrix. Throughout, we focus on the practically interesting class of bi-regular quasi-cyclic LDPC (QC-LDPC) codes, for which the eigenvalues can be obtained efficiently by applying techniques used for block-circulant matrices.

</details>


### [5] [Strong Singleton-Like Bounds, Quasi-Perfect Codes and Distance-Optimal Codes in the Sum-Rank Metric](https://arxiv.org/abs/2601.05581)
*Chao Liu,Hao Chen,Qinqin Ji,Ziyan Xie,Dabin Zheng*

Main category: cs.IT

TL;DR: 该论文通过从汉明度量覆盖码构造和秩度量覆盖码，得到了和秩度量码的新上界，提出了更强的Singleton-like界，并构造了多种距离最优和秩码及准完美和秩码。


<details>
  <summary>Details</summary>
Motivation: 和秩度量码在多镜头网络编码、空时编码和分布式存储中有广泛应用，但现有理论界不够紧致，需要更精确的上界和更好的构造方法。

Method: 通过从汉明度量覆盖码构造和秩度量覆盖码，推导和秩度量码的尺寸、覆盖半径和块长度函数的新上界；利用循环码构造距离最优和秩码；使用Plotkin和构造更多距离最优码。

Result: 得到了比经典Singleton-like界更紧致的强Singleton-like界；构造了矩阵尺寸为s×s和2×2的最小和秩距离为4的距离最优码；给出了无限族准完美q元和秩码；构造了更大块长度的几乎MSRD码。

Conclusion: 通过汉明度量覆盖码构造和秩度量覆盖码的方法有效，获得了更紧致的理论界和多种距离最优码构造，为和秩度量码的理论和应用发展提供了重要贡献。

Abstract: Codes in the sum-rank metric have received many attentions in recent years, since they have wide applications in the multishot network coding, the space-time coding and the distributed storage. In this paper, by constructing covering codes in the sum-rank metric from covering codes in the Hamming metric, we derive new upper bounds on sizes, the covering radii and the block length functions of codes in the sum-rank metric. As applications, we present several strong Singleton-like bounds that are tighter than the classical Singleton-like bound when block lengths are large. In addition, we give the explicit constructions of the distance-optimal sum-rank codes of matrix sizes $s\times s$ and $2\times 2$ with minimum sum-rank distance four respectively by using cyclic codes in the Hamming metric. More importantly, we present an infinite families of quasi-perfect $q$-ary sum-rank codes with matrix sizes $2\times m$. Furthermore, we construct almost MSRD codes with larger block lengths and demonstrate how the Plotkin sum can be used to give more distance-optimal sum-rank codes.

</details>


### [6] [Multiset Deletion-Correcting Codes: Bounds and Constructions](https://arxiv.org/abs/2601.05636)
*Avraham Kreindel,Isaac Barouch Essayag,Aryeh Lev Zabokritskiy*

Main category: cs.IT

TL;DR: 该论文研究多集空间中的纠错码，针对符号删除错误（仅减少符号重数），在极端删除场景下建立了码大小的紧界或近紧界，并给出了具体的构造方法。


<details>
  <summary>Details</summary>
Motivation: 研究多集空间中的纠错码，主要动机是应对排列信道中完全丢失排序信息且仅通过删除符号（减少符号重数）产生错误的情况。

Method: 1. 在极端删除场景下建立码大小的紧界或近紧界；2. 确定t=n-1和t=n-2时的精确最优码大小；3. 对t=n-3进行精细分析；4. 通过从参数(n,k)约简到(n-1,k-1)推导一般递归穿孔上界；5. 提出具体的构造方法，包括二进制多集模型的同余构造、q进制单删除码构造以及基于单同余约束的循环Sidon型线性构造。

Result: 1. 完全解决了二进制多集模型，对所有t≥1确定了S₂(n,t)的精确值并给出了显式最优同余构造；2. 展示了q≥3时自然模构造不一定最优；3. 提出了基于单同余约束的循环Sidon型线性构造，具有冗余度log_q(t(t+1)^{q-2}+1)和线性编码解码复杂度。

Conclusion: 该论文在多集空间的纠错码研究中取得了重要进展，特别是在极端删除场景下建立了紧界并提出了有效的构造方法，为处理排列信道中的符号删除错误提供了理论工具和实用方案。

Abstract: We study error-correcting codes in the space $\mathcal{S}_{n,q}$ of length-$n$ multisets over a $q$-ary alphabet, motivated by permutation channels in which ordering is completely lost and errors act solely by deletions of symbols, i.e., by reducing symbol multiplicities.
  Our focus is on the \emph{extremal deletion regime}, where the channel output contains $k=n-t$ symbols. In this regime, we establish tight or near-tight bounds on the maximum code size. In particular, we determine the exact optimal code sizes for $t=n-1$ and for $t=n-2$, develop a refined analysis for $t=n-3$, and derive a general recursive puncturing upper bound for $t=n-k$ via a reduction from parameters $(n,k)$ to $(n-1,k-1)$.
  On the constructive side, we completely resolve the binary multiset model: for all $t\ge1$ we determine $S_2(n,t)$ exactly and give an explicit optimal congruence-based construction. We then study single-deletion codes beyond the binary case, presenting general $q$-ary constructions and showing, via explicit small-parameter examples, that the natural modular construction need not be optimal for $q\ge3$. Finally, we present an explicit cyclic Sidon-type linear construction for general $(q,t)$ based on a single congruence constraint, with redundancy $\log_q\!\bigl(t(t+1)^{q-2}+1\bigr)$ and encoding and decoding complexity linear in the blocklength $n$.

</details>


### [7] [Coset Shaping for Coded Modulation](https://arxiv.org/abs/2601.05652)
*Irina Bocharova,Maiara F. Bollauf,Boris Kudryashov*

Main category: cs.IT

TL;DR: 提出了一种用于编码QAM和PAM调制的陪集整形技术，该技术可同时应用于信息比特和校验比特，且不增加复杂度，在码长和调制阶数趋于无穷时能达到任意接近容量的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的整形技术通常只应用于信息比特，而校验比特未经过整形，限制了系统性能。需要一种既能应用于信息比特又能应用于校验比特，且不增加复杂度的整形方案。

Method: 提出陪集整形技术，该技术通过特定的陪集结构设计，使得整形不仅适用于信息比特，也能扩展到校验比特。方法基于编码调制框架，将整形与纠错编码相结合。

Result: 理论证明当纠错码长度和调制阶数趋于无穷时，该整形方案与信道容量的差距可以任意小。数值结果显示该方案与非二进制LDPC编码的QAM调制相结合时表现出良好性能。

Conclusion: 陪集整形是一种有效的编码调制整形技术，能够在不增加复杂度的情况下同时整形信息比特和校验比特，理论上可达到接近信道容量的性能，具有实际应用价值。

Abstract: A new shaping technique called coset shaping for coded QAM and PAM signaling is introduced and analyzed. This technique can be applied not only to information bits but also to parity bits without incurring additional complexity costs. It is proven that as the length of the error-correcting code and the modulation order tend to infinity, the gap to capacity for the proposed shaping scheme can be made arbitrarily small. Numerical results and comparisons for the shaping scheme, along with nonbinary LDPC-coded QAM signaling, are presented.

</details>


### [8] [Nonlinearity Mitigation for Coherent Ground-to-Satellite Optical Links](https://arxiv.org/abs/2601.05655)
*Stella Civelli,Marco Secondini,Luca Potì*

Main category: cs.IT

TL;DR: 提出用于卫星通信中高功率光放大器非线性抑制的数字信号处理技术，可将可接受链路损耗提高6dB且复杂度可忽略


<details>
  <summary>Details</summary>
Motivation: 卫星通信系统中高功率光放大器存在非线性失真问题，限制了链路性能和传输距离，需要有效的非线性抑制技术

Method: 采用数字信号处理技术来抑制高功率光放大器的非线性效应，具体方法未详细说明但强调复杂度可忽略

Result: 提出的DSP技术能够将可接受的链路损耗提高6dB，显著改善了系统性能

Conclusion: 数字信号处理技术是卫星通信中高功率光放大器非线性抑制的有效解决方案，能以极低复杂度显著提升系统性能

Abstract: We propose digital signal processing techniques for nonlinearity mitigation in high power optical amplifiers used in satellite communications. The acceptable link loss increases by 6dB with negligible complexity.

</details>


### [9] [On the Complexity of Electromagnetic Far-Field Modeling](https://arxiv.org/abs/2601.05674)
*Torben Kölle,Alexander Stutz-Tirri,Christoph Studer*

Main category: cs.IT

TL;DR: 论文为通用天线架构的电磁远场建模提供了严格的数学框架，证明在物理假设下天线架构具有有限复杂度，可用有限参数建模，并构造了超指数收敛的有限秩算子序列。


<details>
  <summary>Details</summary>
Motivation: 现代无线系统需要能够发射、接收、反射和变换电磁波的天线架构，但缺乏对这些通用天线架构电磁远场建模复杂度的严格数学分析框架。

Method: 基于麦克斯韦方程组建立严格的数学框架，在物理意义假设下分析天线架构的复杂度，证明其可用有限秩算子建模，并构造具有超指数收敛速度的有限秩算子序列。

Result: 证明在物理假设下，通用天线架构具有有限复杂度，可用有限参数通过有限秩算子建模；构造的有限秩算子序列在算子秩超过天线架构有效带宽后，近似误差呈超指数衰减。

Conclusion: 该研究为通用天线架构在数字计算平台上的高效准确建模提供了理论基础，证明了天线架构的有限复杂度特性，为实际工程应用中的建模优化提供了数学保证。

Abstract: Modern wireless systems are envisioned to employ antenna architectures that not only transmit and receive electromagnetic (EM) waves, but also intentionally reflect and possibly transform incident EM waves. In this paper, we propose a mathematically rigorous framework grounded in Maxwell's equations for analyzing the complexity of EM far-field modeling of general antenna architectures. We show that-under physically meaningful assumptions-such antenna architectures exhibit limited complexity, i.e., can be modeled by finite-rank operators using finitely many parameters. Furthermore, we construct a sequence of finite-rank operators whose approximation error decays super-exponentially once the operator rank exceeds an effective bandwidth associated with the antenna architecture and the analysis frequency. These results constitute a fundamental prerequisite for the efficient and accurate modeling of general antenna architectures on digital computing platforms.

</details>


### [10] [Secure Multiuser Beamforming With Movable Antenna Arrays](https://arxiv.org/abs/2601.05686)
*Zhenqiao Cheng,Chongjun Ouyang,Boqun Zhao,Xingqi Zhang*

Main category: cs.IT

TL;DR: 提出了一种基于可移动天线的安全多用户传输框架，通过联合优化数字波束成形和天线位置来最大化系统和保密率，相比传统固定天线阵列能获得更高的保密速率。


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线阵列在物理层安全方面的性能有限，需要新的技术来增强无线通信的安全性。可移动天线技术为提升物理层安全提供了新的可能性。

Method: 开发了基于可移动天线的安全多用户传输框架，推导了系统和保密率的新表达式，提出了基于分数规划和块坐标下降的联合优化算法，在每次迭代中通过闭式更新或低复杂度一维/二分搜索更新变量。

Result: 数值结果表明所提方法有效，可移动天线设计相比传统固定位置天线阵列能获得更高的保密速率。

Conclusion: 可移动天线技术能显著提升物理层安全性能，所提出的联合优化算法实现高效，为未来安全无线通信系统设计提供了新思路。

Abstract: A movable antennas (MAs)-enabled secure multiuser transmission framework is developed to enhance physical-layer security. Novel expressions are derived to characterize the achievable sum secrecy rate based on the secure channel coding theorem. On this basis, a joint optimization algorithm for digital beamforming and MA placement is proposed to maximize the sum secrecy rate via fractional programming and block coordinate descent. In each iteration, every variable admits either a closed-form update or a low-complexity one-dimensional or bisection search, which yields an efficient implementation. Numerical results demonstrate the effectiveness of the proposed method and show that the MA-enabled design achieves higher secrecy rates than conventional fixed-position antenna arrays.

</details>


### [11] [Universal and Asymptotically Optimal Data and Task Allocation in Distributed Computing](https://arxiv.org/abs/2601.05873)
*Javad Maheri,K. K. Krishnan Namboodiri,Petros Elia*

Main category: cs.IT

TL;DR: 本文研究分布式计算中通信与计算成本的联合优化，提出了一种确定性分配方案（IC设计），在广泛参数范围内同时实现通信成本n/N^{1/d}和计算成本的最优缩放，且无需了解具体函数分解结构。


<details>
  <summary>Details</summary>
Motivation: 在分布式计算中，主节点协调多个工作节点评估函数时，需要同时优化通信成本（服务器间传输的文件数）和计算成本（工作节点的子函数负载）。现有方法通常需要针对特定函数分解进行优化，缺乏通用且同时优化两种成本的确定性方案。

Method: 将分布式计算问题转化为d-均匀超图边划分问题，提出Interweaved-Cliques (IC)设计——一种基于信息论启发的交织团结构。该设计通过确定性文件分配策略，将子函数集划分为N个不相交组，同时最小化通信成本π_X（每服务器最大不同文件数）和计算成本δ_X（最大工作节点子函数负载）。

Result: IC设计在广泛参数范围内同时实现了通信成本n/N^{1/d}和计算成本的最优缩放。可达性和逆界分析表明，在合理的X密度假设下，最优通信成本缩放为n/N^{1/d}，IC设计实现了N^{1/d}的分区增益，且计算成本也达到最优缩放。该设计是确定性的，且无需了解具体函数分解结构X。

Conclusion: IC设计提供了一种确定性分配方案，能够同时优化分布式计算中的通信和计算成本，实现最优缩放性能。更重要的是，该方案对函数分解结构X是"盲"的，使得多个不同函数可以在不重新分配文件的情况下进行计算，具有实际应用价值。

Abstract: We study the joint minimization of communication and computation costs in distributed computing, where a master node coordinates $N$ workers to evaluate a function over a library of $n$ files. Assuming that the function is decomposed into an arbitrary subfunction set $\mathbf{X}$, with each subfunction depending on $d$ input files, renders our distributed computing problem into a $d$-uniform hypergraph edge partitioning problem wherein the edge set (subfunction set), defined by $d$-wise dependencies between vertices (files) must be partitioned across $N$ disjoint groups (workers). The aim is to design a file and subfunction allocation, corresponding to a partition of $\mathbf{X}$, that minimizes the communication cost $π_{\mathbf{X}}$, representing the maximum number of distinct files per server, while also minimizing the computation cost $δ_{\mathbf{X}}$ corresponding to a maximal worker subfunction load. For a broad range of parameters, we propose a deterministic allocation solution, the \emph{Interweaved-Cliques (IC) design}, whose information-theoretic-inspired interweaved clique structure simultaneously achieves order-optimal communication and computation costs, for a large class of decompositions $\mathbf{X}$. This optimality is derived from our achievability and converse bounds, which reveal -- under reasonable assumptions on the density of $\mathbf{X}$ -- that the optimal scaling of the communication cost takes the form $n/N^{1/d}$, revealing that our design achieves the order-optimal \textit{partitioning gain} that scales as $N^{1/d}$, while also achieving an order-optimal computation cost. Interestingly, this order optimality is achieved in a deterministic manner, and very importantly, it is achieved blindly from $\mathbf{X}$, therefore enabling multiple desired functions to be computed without reshuffling files.

</details>


### [12] [Age of Gossip With Cellular Drone Mobility](https://arxiv.org/abs/2601.05983)
*Arunabh Srivastava,Sennur Ulukus*

Main category: cs.IT

TL;DR: 研究无人机辅助蜂窝网络中信息新鲜度，分析无人机移动速度、传播速率和小区数量对版本年龄的影响，发现存在无人机移动与传播的双重瓶颈效应。


<details>
  <summary>Details</summary>
Motivation: 研究无人机辅助的蜂窝网络中信息新鲜度问题，无人机从源节点获取更新并在小区间移动传播，需要量化无人机移动速度、传播速率和网络规模对信息新鲜度的影响。

Method: 采用连续时间马尔可夫链（CTMC）建模无人机移动，使用版本年龄度量信息新鲜度，分析无人机移动速度λ_m(n)、传播速率λ_d(n)和小区数量f(n)对版本年龄的影响，特别关注全连接无人机移动模型。

Result: 发现无人机到小区服务时间的期望持续时间取决于底层CTMC的平稳分布和λ_d(n)，但与λ_m(n)无关。在全连接移动模型下，揭示了无人机移动与传播的双重瓶颈：版本年龄受制于两者中较慢的过程。当λ_d(n)远大于λ_m(n)时，版本年龄缩放由λ_m(n)的倒数主导；反之则由λ_d(n)的倒数主导。

Conclusion: 无人机辅助蜂窝网络中存在移动与传播的双重瓶颈效应，信息新鲜度受限于较慢的过程，这为无人机移动网络设计提供了重要指导，需要平衡无人机移动速度和传播速率以优化信息新鲜度。

Abstract: We consider a cellular network containing $n$ nodes where nodes within a cell gossip with each other in a fully-connected fashion and a source shares updates with these nodes via a mobile drone. The mobile drone receives updates directly from the source and shares them with nodes in the cell where it currently resides. The drone moves between cells according to an underlying continuous-time Markov chain (CTMC). In this work, we evaluate the impact of the number of cells $f(n)$, drone speed $λ_m(n)$ and drone dissemination rate $λ_d(n)$ on the freshness of information of nodes in the network. We utilize the version age of information metric to quantify the freshness of information. We observe that the expected duration between two drone-to-cell service times depends on the stationary distribution of the underlying CTMC and $λ_d(n)$, but not on $λ_m(n)$. However, the version age instability in slow moving CTMCs makes high probability analysis for a general underlying CTMC difficult. Therefore, next we focus on the fully-connected drone mobility model. Under this model, we uncover a dual-bottleneck between drone mobility and drone dissemination speed: the version age is constrained by the slower of these two processes. If $λ_d(n) \gg λ_m(n)$, then the version age scaling of nodes is dominated by the inverse of $λ_m(n)$ and is independent of $λ_d(n)$. If $λ_m(n) \gg λ_d(n)$, then the version age scaling of nodes is dominated by the inverse of $λ_d(n)$ and is independent of $λ_m(n)$.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [13] [On the closest pair of points problem](https://arxiv.org/abs/2601.05681)
*Martin Hitz,Michaela Hitz*

Main category: cs.DS

TL;DR: 提出了两种基于最优填充理论的新算法cppMM和cppAPs来解决最近点对问题，其中cppMM在均匀分布点情况下具有O(n)时间复杂度，cppAPs虽然最坏情况O(n²)但实际运行极快。


<details>
  <summary>Details</summary>
Motivation: 解决大规模点云中最近点对查找问题，现有算法在效率或实现复杂度上存在不足，需要开发更高效、易于实现的确定性算法。

Method: 基于数学最优填充理论开发两种算法：cppMM（主要算法）和cppAPs（简化算法）。cppMM利用均匀分布特性实现线性时间复杂度，cppAPs采用类似暴力搜索但更高效的策略。

Result: 在C++测试环境中对多达33,554,432个点进行测试，cppMM在大规模问题上表现最优，cppAPs虽然理论复杂度较高但实际运行速度极快。

Conclusion: 提出的两种新算法在最近点对问题上表现出色，特别是cppMM在大规模均匀分布点云中具有线性时间复杂度和优越的实际性能。

Abstract: We introduce two novel algorithms for the problem of finding the closest pair in a cloud of $n$ points based on findings from mathematical optimal packing theory. Both algorithms are deterministic, show fast effective runtimes, and are very easy to implement. For our main algorithm, cppMM, we prove $O(n)$ time complexity for the case of uniformly distributed points. Our second algorithm, cppAPs, is almost as simple as the brute-force approach, but exhibits an extremely fast empirical running time, although its worst-case time complexity is also $O(n^2)$. We embed the new algorithms in a review of the most prominent contenders and empirically demonstrate their runtime behavior for problem sizes up to $n =$ 33,554,432 points observed in our C++ test environment. For large $n$, cppMM dominates the other algorithms under study.

</details>


### [14] [Spectral Clustering in Birthday Paradox Time](https://arxiv.org/abs/2601.05883)
*Michael Kapralov,Ekaterina Kochetkova,Weronika Wrzos-Kaminska*

Main category: cs.DS

TL;DR: 本文针对(k, φ, ε)-可聚类图，提出了一种基于随机游走混合表示的新方法，将每个顶点的查询复杂度从之前的poly(k)·n^{1/2+O(ε/φ^2)}优化到(n/k)^{1/2+O(ε/φ^2)}，实现了与生日悖论一致的理论界限。


<details>
  <summary>Details</summary>
Motivation: 现有方法在k>2时需要的随机游走样本数为poly(k)·n^{1/2+O(ε/φ^2)}，这与k=2时的结果在k的多项式因子内匹配，但与生日悖论的直觉相矛盾：随着聚类数k增加，每个聚类的大小减小，理论上应该需要更少的样本。这种不一致性促使研究者寻找更优的表示方法。

Method: 设计了一种新颖的顶点表示方法：使用对数长度的随机游走混合来表示(k, φ, ε)-可聚类图中的顶点。每个顶点只需要约(n/k)^{1/2+O(ε/φ^2)}个随机游走样本。通过快速最近邻搜索算法，给定k个代表聚类的顶点，可以在接近线性的时间内确定查询顶点x所属的聚类。

Result: 提出的聚类预言机具有查询时间≈(n/k)^{1/2+O(ε/φ^2)}和空间复杂度k·(n/k)^{1/2+O(ε/φ^2)}，这与生日悖论的理论界限完全匹配，相比之前的方法在k较大时有显著改进。

Conclusion: 本文解决了(k, φ, ε)-可聚类图中顶点聚类归属的快速判定问题，通过创新的随机游走混合表示方法，实现了与生日悖论直觉一致的最优查询复杂度，为图聚类算法提供了理论上的重要突破。

Abstract: Given a vertex in a $(k, \varphi, ε)$-clusterable graph, i.e. a graph whose vertex set can be partitioned into a disjoint union of $\varphi$-expanders of size $\approx n/k$ with outer conductance bounded by $ε$, can one quickly tell which cluster it belongs to? This question goes back to the expansion testing problem of Goldreich and Ron'11. For $k=2$ a sample of $\approx n^{1/2+O(ε/\varphi^2)}$ logarithmic length walks from a given vertex approximately determines its cluster membership by the birthday paradox: two vertices whose random walk samples are `close' are likely in the same cluster.
  The study of the general case $k>2$ was initiated by Czumaj, Peng and Sohler [STOC'15], and the works of Chiplunkar et al. [FOCS'18], Gluch et al. [SODA'21] showed that $\approx \text{poly}(k)\cdot n^{1/2+O(ε/\varphi^2)}$ random walk samples suffice for general $k$. This matches the $k=2$ result up to polynomial factors in $k$, but creates a conceptual inconsistency: if the birthday paradox is the guiding phenomenon, then the query complexity should decrease with the number of clusters $k$! Since clusters have size $\approx n/k$, we expect to need $\approx (n/k)^{1/2+O(ε/\varphi^2)}$ random walk samples, which decreases with $k$.
  We design a novel representation of vertices in a $(k, \varphi, ε)$-clusterable graph by a mixture of logarithmic length walks. This representation uses the optimal $\approx (n/k)^{1/2+O(ε/\varphi^2)}$ walks per vertex, and allows for a fast nearest neighbor search: given $k$ vertices representing the clusters, we can find the cluster of a given query vertex $x$ using nearly linear time in the representation size of $x$. This gives a clustering oracle with query time $\approx (n/k)^{1/2+O(ε/\varphi^2)}$ and space complexity $k\cdot (n/k)^{1/2+O(ε/\varphi^2)}$, matching the birthday paradox bound.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [15] [Meaning over Motion: A Semantic-First Approach to 360° Viewport Prediction](https://arxiv.org/abs/2601.05416)
*Arman Nik Khah,Arvin Bahreini,Ravi Prakash*

Main category: cs.MM

TL;DR: 提出语义自适应保形分块与关联预取框架，通过认知意图预测解决360度视频流中的"扫视陷阱"问题，减少卡顿20%以上并降低带宽消耗18%以上。


<details>
  <summary>Details</summary>
Motivation: 当前360度视频流媒体技术主要依赖运动学或低级视觉显著性预测，将用户视为受惯性支配的被动物理对象，导致"扫视陷阱"问题——当用户注意力因语义内容快速转移时，预测失败造成卡顿。

Method: 提出语义自适应保形分块与关联预取框架：1) 服务器端进行语义推理生成轻量级关联图；2) 客户端控制器使用个性化多模态预测集，在稳定注视时收紧安全边界提高效率；3) 关联预取机制预先获取语义相关但非相邻的分块内容。

Result: 在360-AV-HM数据集上的跟踪驱动评估显示，该方法成功缓解了扫视陷阱问题，相比最先进的基于轨迹的基线方法，卡顿持续时间减少≥20%，有效带宽消耗降低≥18%。

Conclusion: 通过将认知意图整合到网络控制中，提出的框架能够有效预测用户基于语义的注意力转移，将注视的"平静期"转化为下一次交互的准备阶段，显著提升360度视频流媒体性能。

Abstract: Ultra-high-resolution 360-degree video streaming is severely constrained by the massive bandwidth required to deliver immersive experiences. Current viewport prediction techniques predominately rely on kinematics or low-level visual saliency, treating users as passive physical objects governed by inertia. This theoretical limitation leads to the "Saccade Trap" -- a critical failure mode where predictors fail to anticipate rapid, meaning-driven shifts in attention, causing rebuffering stalls exactly when user engagement is highest. To resolve this, we propose Semantically-Adaptive Conformal Tiling with Associative Lookahead, a novel framework that integrates cognitive intent into network control. Unlike "one-size-fits-all" approaches, our method utilizes an architectural inversion strategy: heavy semantic reasoning is offloaded to the server to generate lightweight association graphs, which guide a low-latency client-side controller. We construct a personalized Multi-Modal Prediction Set that dynamically tightens safety margins during stable fixation to maximize efficiency, while simultaneously pre-fetching non-adjacent tiles containing semantically linked objects (Associative Lookahead). This mechanism effectively converts the "calm" of fixation into a preparation phase for the next interaction. Trace-driven evaluation on the 360-AV-HM dataset demonstrates that this approach successfully mitigates the Saccade Trap, reducing stall duration by $\ge$ 20% and lowering effective bandwidth consumption by $\ge$ 18% compared to state-of-the-art trajectory-based baselines.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [16] [Parallel Dynamic Spatial Indexes](https://arxiv.org/abs/2601.05347)
*Ziyang Men,Bo Huang,Yan Gu,Yihan Sun*

Main category: cs.DB

TL;DR: 提出两种并行空间索引结构P-Orth树和SPaC树家族，用于高效处理动态空间数据的批量更新，相比现有并行索引在更新性能上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现实应用中空间数据高度动态，需要低延迟的批量更新，但现有并行空间索引在高效更新方面研究不足。

Method: 系统研究并行空间索引，重点关注高动态工作负载的更新性能。选择两种适合低延迟更新的索引类型：Orth树和R树/BVH，分别提出P-Orth树（并行Orth树）和SPaC树家族（并行R树/BVH）。

Result: P-Orth树和SPaC树在批量更新性能上优于现有并行kd树和Orth树，同时在查询性能上保持与对应Orth树和R树相当或更好的竞争力。

Conclusion: 提出的两种并行空间索引结构能有效处理高度动态的空间数据工作负载，为并行空间索引的高性能更新提供了系统解决方案，并通过全面实验验证了性能优势。

Abstract: Maintaining spatial data (points in two or three dimensions) is crucial and has a wide range of applications, such as graphics, GIS, and robotics. To handle spatial data, many data structures, called spatial indexes, have been proposed, e.g. kd-trees, oct/quadtrees (also called Orth-trees), R-trees, and bounding volume hierarchies (BVHs). In real-world applications, spatial datasets tend to be highly dynamic, requiring batch updates of points with low latency. This calls for efficient parallel batch updates on spatial indexes. Unfortunately, there is very little work that achieves this.
  In this paper, we systematically study parallel spatial indexes, with a special focus on achieving high-performance update performance for highly dynamic workloads. We select two types of spatial indexes that are considered optimized for low-latency updates: Orth-tree and R-tree/BVH. We propose two data structures: the P-Orth tree, a parallel Orth-tree, and the SPaC-tree family, a parallel R-tree/BVH. Both the P-Orth tree and the SPaC-tree deliver superior performance in batch updates compared to existing parallel kd-trees and Orth-trees, while preserving better or competitive query performance relative to their corresponding Orth-tree and R-tree counterparts. We also present comprehensive experiments comparing the performance of various parallel spatial indexes and share our findings at the end of the paper.

</details>


### [17] [The Importance of Parameters in Ranking Functions](https://arxiv.org/abs/2601.06001)
*Christoph Standke,Nikolaos Tziavelis,Wolfgang Gatterbauer,Benny Kimelfeld*

Main category: cs.DB

TL;DR: 该论文研究了如何计算SHAP分数来解释列权重对表排序的影响，分析了不同排序函数和效应函数组合下的计算复杂度，发现所有情况都有FPRAS近似算法，但精确计算在多项式时间和#P-hard之间变化。


<details>
  <summary>Details</summary>
Motivation: 为了解决"列权重在决定表元组排序中的重要性"这一解释性问题，需要计算列权重的SHAP分数，为排序函数提供可解释性分析。

Method: 采用Grohe等人的框架，分析三个关键组件：排序函数（字典序、基于求和/最小/最大函数的评分排序）、效应函数（全局、top-k、局部）和权重分布（概率独立的有限分布）。研究不同组合下的计算复杂度。

Result: 所有情况都允许加法完全多项式时间随机近似方案（FPRAS），但精确计算复杂度不同：某些情况可在多项式时间内解决，而其他情况是#P-hard的。这些复杂度结果也适用于计算整个列的Shapley值。

Conclusion: 该研究为排序函数的可解释性提供了理论框架，明确了不同配置下计算SHAP分数的复杂度边界，为实际应用中的近似算法选择提供了指导。

Abstract: How important is the weight of a given column in determining the ranking of tuples in a table? To address such an explanation question about a ranking function, we investigate the computation of SHAP scores for column weights, adopting a recent framework by Grohe et al.[ICDT'24]. The exact definition of this score depends on three key components: (1) the ranking function in use, (2) an effect function that quantifies the impact of using alternative weights on the ranking, and (3) an underlying weight distribution. We analyze the computational complexity of different instantiations of this framework for a range of fundamental ranking and effect functions, focusing on probabilistically independent finite distributions for individual columns.
  For the ranking functions, we examine lexicographic orders and score-based orders defined by the summation, minimum, and maximum functions. For the effect functions, we consider global, top-k, and local perspectives: global measures quantify the divergence between the perturbed and original rankings, top-k measures inspect the change in the set of top-k answers, and local measures capture the impact on an individual tuple of interest. Although all cases admit an additive fully polynomial-time randomized approximation scheme (FPRAS), we establish the complexity of exact computation, identifying which cases are solvable in polynomial time and which are #P-hard. We further show that all complexity results, lower bounds and upper bounds, extend to a related task of computing the Shapley value of whole columns (regardless of their weight).

</details>


### [18] [Task Cascades for Efficient Unstructured Data Processing](https://arxiv.org/abs/2601.05536)
*Shreya Shankar,Sepanta Zeighami,Aditya Parameswaran*

Main category: cs.DB

TL;DR: 论文提出任务级联框架，通过变化模型、文档部分和操作来优化LLM文档处理，相比模型级联平均降低36%成本


<details>
  <summary>Details</summary>
Motivation: 现有模型级联框架仅通过廉价代理模型处理不确定案例，但忽略了文档部分选择和操作简化的优化机会，导致成本仍有降低空间

Method: 提出任务级联框架，使用LLM代理生成简化、分解或相关操作，选择最相关文档部分，构建数百个候选任务并组装任务级联，采用迭代方法构建有效级联

Result: 在8个真实世界文档处理任务中，以90%目标准确率，任务级联相比模型级联平均降低36%端到端成本，并提供统计准确性保证

Conclusion: 任务级联框架通过同时优化模型、文档部分和操作，显著降低LLM文档处理成本，同时提供准确性保证，适用于生产规模应用

Abstract: Modern database systems allow users to query or process unstructured text or document columns using LLM-powered functions. Users can express an operation in natural language (e.g., "identify if this review mentions billing issues"), with the system executing the operation on each document, in a row-by-row fashion. One way to reduce cost on a batch of documents is to employ the model cascade framework: a cheap proxy model processes each document, and only uncertain cases are escalated to a more accurate, expensive oracle. However, model cascades miss important optimization opportunities; for example, often only part of a document is needed to answer a query, or other related, but simpler operations (e.g., "is the review sentiment negative?", "does the review mention money?") can be handled by cheap models more effectively than the original operation, while still being correlated with it.
  We introduce the task cascades framework, which generalizes model cascades by varying not just the model, but also the document portion and operation at each stage. Our framework uses an LLM agent to generate simplified, decomposed, or otherwise related operations and selects the most relevant document portions, constructing hundreds of candidate tasks from which it assembles a task cascade. We show that optimal cascade selection is intractable via reduction from Minimum Sum Set Cover, but our iterative approach constructs effective cascades. We also provide an extension that offers statistical accuracy guarantees: the resulting cascade meets a user-defined accuracy target (with respect to the oracle) up to a bounded failure probability. Across eight real-world document processing tasks at a 90% target accuracy, task cascades reduce end-to-end cost by an average of 36% compared to model cascades, at a production scale.

</details>


### [19] [RISE: Rule-Driven SQL Dialect Translation via Query Reduction](https://arxiv.org/abs/2601.05579)
*Xudong Xie,Yuwei Zhang,Wensheng Dou,Yu Gao,Ziyu Cui,Jiansen Song,Rui Yang,Jun Wei*

Main category: cs.DB

TL;DR: RISE：一种基于LLM的SQL方言翻译方法，通过方言感知查询简化和规则提取，能准确处理复杂SQL查询，在TPC-DS和SQLProcBench基准测试中分别达到97.98%和100%的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统SQL方言翻译工具依赖手动编写规则，支持新RDBMS和方言需要大量人工工作。虽然LLM可以辅助翻译，但处理复杂长SQL查询时效果不佳。

Method: RISE采用方言感知查询简化技术：1) 从复杂查询中移除方言无关的SQL元素得到简化查询；2) 用LLM翻译简化查询；3) 自动提取方言翻译规则；4) 将规则应用到原始复杂查询中。

Result: 在TPC-DS和SQLProcBench两个真实基准测试中，RISE分别达到97.98%和100%的准确率，相比基线方法平均提升24.62%和238.41%。

Conclusion: RISE通过简化-翻译-规则提取的方法，有效解决了LLM处理复杂SQL查询的局限性，显著提升了SQL方言翻译的准确性和效率。

Abstract: Translating SQL dialects across different relational database management systems (RDBMSs) is crucial for migrating RDBMS-based applications to the cloud. Traditional SQL dialect translation tools rely on manually-crafted rules, necessitating significant manual effort to support new RDBMSs and dialects. Although large language models (LLMs) can assist in translating SQL dialects, they often struggle with lengthy and complex SQL queries.
  In this paper, we propose RISE, a novel LLM-based SQL dialect translation approach that can accurately handle lengthy and complex SQL queries. Given a complex source query $Q_c$ that contains a SQL dialect $d$, we first employ a dialect-aware query reduction technique to derive a simplified query $Q_{s}$ by removing $d$-irrelevant SQL elements from $Q_c$. Subsequently, we utilize LLMs to translate $Q_{s}$ into $Q_{s^{'}}$, and automatically extract the translation rule $r_d$ for dialect $d$ based on the relationship between $Q_{s}$ and $Q_{s^{'}}$. By applying $r_d$ to $Q_c$, we can effectively translate the dialect $d$ within $Q_c$, thereby bypassing the complexity of the source query $Q_c$. We evaluate RISE on two real-world benchmarks, i.e., TPC-DS and SQLProcBench, comparing its performance against both the traditional rule-based tools and the LLM-based approaches with respect to translation accuracy. RISE achieves accuracies of 97.98% on TPC-DS and 100% on SQLProcBench, outperforming the baselines by an average improvement of 24.62% and 238.41%, respectively.

</details>


### [20] [Descriptor: Multi-Regional Cloud Honeypot Dataset (MURHCAD)](https://arxiv.org/abs/2601.05813)
*Enrique Feito-Casares,Ismael Gómez-Talal,José-Luis Rojo-Álvarez*

Main category: cs.DB

TL;DR: 该数据文章介绍了一个高分辨率蜜网数据集，包含72小时内捕获的132,425个攻击事件，涵盖SIP、Telnet和SMB三种主要协议，支持网络攻击行为的独立分析。


<details>
  <summary>Details</summary>
Motivation: 为支持全球网络攻击行为的独立分析，提供高分辨率、包含丰富元数据的蜜网数据集，以促进异常检测、威胁情报和防御策略研究。

Method: 在Microsoft Azure上部署三个蜜罐（Cowrie、Dionaea、SentryPeer）到四个地理分散的虚拟机，连续72小时收集攻击数据，并添加时间戳、IP地址、地理位置、协议分类等元数据。

Result: 数据集包含132,425个攻击事件，来自2,438个唯一源IP，覆盖95个国家。SIP、Telnet、SMB三种协议占主导，攻击活动在07:00和23:00 UTC呈现明显高峰，不同蜜罐捕获的攻击具有地理分布特征。

Conclusion: 该数据集结合了高时间分辨率和丰富的地理位置、协议元数据，为可重复的云规模网络威胁研究提供了支持，有助于揭示攻击模式和防御盲点。

Abstract: This data article introduces a comprehensive, high-resolution honeynet dataset designed to support standalone analyses of global cyberattack behaviors. Collected over a continuous 72-hour window (June 9 to 11, 2025) on Microsoft Azure, the dataset comprises 132,425 individual attack events captured by three honeypots (Cowrie, Dionaea, and SentryPeer) deployed across four geographically dispersed virtual machines. Each event record includes enriched metadata (UTC timestamps, source/destination IPs, autonomous system and organizational mappings, geolocation coordinates, targeted ports, and honeypot identifiers alongside derived temporal features and standardized protocol classifications). We provide actionable guidance for researchers seeking to leverage this dataset in anomaly detection, protocol-misuse studies, threat intelligence, and defensive policy design. Descriptive statistics highlight significant skew: 2,438 unique source IPs span 95 countries, yet the top 1% of IPs account for 1% of all events, and three protocols dominate: Session Initiation Protocol (SIP), Telnet, Server Message Block (SMB). Temporal analysis uncovers pronounced rush-hour peaks at 07:00 and 23:00 UTC, interspersed with maintenance-induced gaps that reveal operational blind spots. Geospatial mapping further underscores platform-specific biases: SentryPeer captures concentrated SIP floods in North America and Southeast Asia, Cowrie logs Telnet/SSH scans predominantly from Western Europe and the U.S., and Dionaea records SMB exploits around European nodes. By combining fine-grained temporal resolution with rich, contextual geolocation and protocol metadata, this standalone dataset aims to empower reproducible, cloud-scale investigations into evolving cyber threats. Accompanying analysis code and data access details are provided.

</details>


### [21] [Database Theory in Action: Direct Access to Query Answers](https://arxiv.org/abs/2601.06013)
*Jiayin Hu,Nikolaos Tziavelis*

Main category: cs.DB

TL;DR: 论文实现了一个支持多种查询和排序的直接访问系统，并研究了其实际性能表现


<details>
  <summary>Details</summary>
Motivation: 直接访问（按排名位置检索查询答案）的时间复杂度已有深入研究，但其实际性能表现却很少被关注

Method: 实现了一个覆盖广泛查询和排序的直接访问系统，用于研究实际性能表现

Result: 能够研究数据库系统的比较性能，以及直接访问与其单次访问对应物之间的关系

Conclusion: 通过实现直接访问系统，填补了理论研究和实际性能分析之间的空白

Abstract: Direct access asks for the retrieval of query answers by their ranked position, given a query and a desired order. While the time complexity of data structures supporting such accesses has been studied in depth, and efficient algorithms for many queries and common orders are known, their practical performance has received little attention. We provide an implementation covering a wide range of queries and orders; it allows us to investigate intriguing practical aspects, including the comparative performance of database systems and the relationship between direct access and its single-access counterpart.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [22] [Bayesian Recovery for Probabilistic Coalition Structures](https://arxiv.org/abs/2601.05273)
*Angshul Majumdar*

Main category: cs.GT

TL;DR: 论文证明在PCSG问题中，传统稀疏方法（如l1松弛和贪婪追踪）无法可靠恢复最优联盟结构，而稀疏贝叶斯学习(SBL)方法具有支持一致性，能有效抑制伪近重复项。


<details>
  <summary>Details</summary>
Motivation: 研究概率联盟结构生成(PCSG)问题中，标准稀疏方法（如l1松弛和贪婪追踪）是否能够可靠恢复最优联盟结构，特别是在联盟重叠导致高度相干、近重复列的情况下。

Method: 将PCSG重新表述为l0型稀疏恢复问题，通过联盟-关联设计将联盟结构表示为稀疏系数向量。分析l1松弛、k步正交匹配追踪(OMP)和稀疏贝叶斯学习(SBL)在高度相干设计下的性能。

Result: 在PCSG启发的机制下，传统稀疏方法失败：设计的不可表示条件不满足，OMP存在不可逆错误选择的非消失概率。相反，SBL在高斯-伽马层次结构下具有支持一致性，能以概率趋于1恢复真实联盟支持。

Conclusion: 该研究在PCSG问题上建立了凸优化、贪婪算法和贝叶斯稀疏方法之间的严格分离，证明SBL在抑制伪近重复项方面优于传统稀疏方法。

Abstract: Probabilistic Coalition Structure Generation (PCSG) is NP-hard and can be recast as an $l_0$-type sparse recovery problem by representing coalition structures as sparse coefficient vectors over a coalition-incidence design. A natural question is whether standard sparse methods, such as $l_1$ relaxations and greedy pursuits, can reliably recover the optimal coalition structure in this setting. We show that the answer is negative in a PCSG-inspired regime where overlapping coalitions generate highly coherent, near-duplicate columns: the irrepresentable condition fails for the design, and $k$-step Orthogonal Matching Pursuit (OMP) exhibits a nonvanishing probability of irreversible mis-selection. In contrast, we prove that Sparse Bayesian Learning (SBL) with a Gaussian-Gamma hierarchy is support consistent under the same structural assumptions. The concave sparsity penalty induced by SBL suppresses spurious near-duplicates and recovers the true coalition support with probability tending to one. This establishes a rigorous separation between convex, greedy, and Bayesian sparse approaches for PCSG.

</details>


### [23] [Congestion Mitigation in Vehicular Traffic Networks with Multiple Operational Modalities](https://arxiv.org/abs/2601.05375)
*Doris E. M. Brown,Sajal K. Das*

Main category: cs.GT

TL;DR: 提出TACTS算法，通过重复Stackelberg博弈解决多模态车辆动态切换操作模式时的自私路由问题，减少网络拥堵。


<details>
  <summary>Details</summary>
Motivation: 现代商用地面车辆具有多种操作模式（人工驾驶、辅助驾驶、远程遥控、全自动驾驶），这些模式依赖不同的传感基础设施和路由算法，导致交通环境感知不一致和路由偏好差异。现有技术未能解决自私路由行为问题，且现有交通流管理策略无法处理车辆动态切换操作模式的情况。

Method: 将车辆控制仲裁系统与多模态车辆的交互建模为重复的单领导者-多跟随者Stackelberg博弈，考虑信息不对称。提出基于遗憾匹配的TACTS算法，自适应更新仲裁系统在连续动态路由决策中的混合策略。

Result: 理论分析为TACTS算法相对于系统最优总网络行程时间的实际总网络行程时间提供了界限。在多个真实交通网络的不同拥堵水平下的仿真实验表明，TACTS能持续减少网络范围拥堵，在高拥堵和重诱导车辆流条件下表现优于替代路由和控制分配策略。

Conclusion: TACTS算法能有效解决多模态车辆动态切换操作模式时的自私路由问题，减少网络拥堵，特别是在高拥堵条件下表现优异，为智能交通网络中的多模态车辆管理提供了有效解决方案。

Abstract: Modern commercial ground vehicles are increasingly equipped with multiple operational modalities (e.g., human driving, advanced driver assistance, remote tele-operation, full autonomy). These often rely on heterogeneous sensing infrastructures and distinct routing algorithms, which can yield misaligned perceptions of the traffic environment and route preferences. While such technologies accelerate the transition toward increasingly intelligent transportation networks, their current deployment fails to avoid challenges associated with selfish routing behavior, in which drivers or automated agents prioritize individually optimal routes instead of network-wide congestion mitigation. Existing traffic flow management strategies can address leader-follower dynamics in traffic routing problems but are not designed to account for vehicles capable of dynamically switching between multiple operational modes. This paper models the interaction between a vehicle control arbitration system and a multi-modal vehicle as a repeated single-leader, multiple follower Stackelberg game with asymmetric information. To address the intractability of computing an exact solution in this setting, we propose a Trust-Aware Control Trading Strategy (TACTS) utilizing a regret matching-based algorithm to adaptively update the arbitration system's mixed strategy over sequential, dynamic routing decisions. Theoretical results provide bounds on the realized total network travel time under TACTS algorithm relative to the system-optimal total network travel time. Experimental results of simulations between the system and a vehicle in several real-world traffic networks under various different congestion levels demonstrate that TACTS consistently reduces network-wide congestion and generally outperforms alternative routing and control-allocation strategies, particularly under high congestion and heavy induced vehicle flows.

</details>


### [24] [Mean Field Analysis of Blockchain Systems](https://arxiv.org/abs/2601.05417)
*Yanni Georghiades,Takashi Tanaka,Sriram Vishwanath*

Main category: cs.GT

TL;DR: 提出基于部分可观测随机博弈和平均场近似的区块链共识分析框架，形式化矿工决策过程，分析最长链规则的最优性


<details>
  <summary>Details</summary>
Motivation: 为区块链共识机制提供形式化分析框架，解决现有研究中缺乏对矿工决策过程系统建模的问题，为最长链规则提供理论验证

Method: 将区块链增长建模为部分可观测随机博弈，通过平均场近似简化为部分可观测马尔可夫决策过程，分析网络延迟与PoW效率的权衡关系

Result: 1) 精确刻画网络延迟与PoW效率的权衡关系；2) 证明最长链规则是平均场均衡且在特定条件下唯一最优；3) 提供灵活的实验框架替代昂贵的测试网部署

Conclusion: 该框架为区块链共识机制提供系统化分析工具，首次为最长链规则提供形式化理论验证，支持灵活的策略实验和系统动态分析

Abstract: We present a novel framework for analyzing blockchain consensus mechanisms by modeling blockchain growth as a Partially Observable Stochastic Game (POSG) which we reduce to a set of Partially Observable Markov Decision Processes (POMDPs) through the use of the mean field approximation. This approach formalizes the decision-making process of miners in Proof-of-Work (PoW) systems and enables a principled examination of block selection strategies as well as steady state analysis of the induced Markov chain. By leveraging a mean field game formulation, we efficiently characterize the information asymmetries that arise in asynchronous blockchain networks.
  Our first main result is an exact characterization of the tradeoff between network delay and PoW efficiency--the fraction of blocks which end up in the longest chain. We demonstrate that the tradeoff observed in our model at steady state aligns closely with theoretical findings, validating our use of the mean field approximation.
  Our second main result is a rigorous equilibrium analysis of the Longest Chain Rule (LCR). We show that the LCR is a mean field equilibrium and that it is uniquely optimal in maximizing PoW efficiency under certain mild assumptions. This result provides the first formal justification for continued use of the LCR in decentralized consensus protocols, offering both theoretical validation and practical insights.
  Beyond these core results, our framework supports flexible experimentation with alternative block selection strategies, system dynamics, and reward structures. It offers a systematic and scalable substitute for expensive test-net deployments or ad hoc analysis. While our primary focus is on Nakamoto-style blockchains, the model is general enough to accommodate other architectures through modifications to the underlying MDP.

</details>


### [25] [Betting on Equilibrium: Monitoring Strategic Behavior in Multi-Agent Systems](https://arxiv.org/abs/2601.05427)
*Etienne Gauthier,Francis Bach,Michael I. Jordan*

Main category: cs.GT

TL;DR: 提出一种用于实时监测重复博弈中行为是否偏离均衡的序列测试框架，基于e值构建检验超鞅，可在线监控并提供统计保证。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，智能体反复交互并期望随时间收敛到均衡行为，但实践中行为经常漂移，实时检测这种偏离仍是一个开放挑战。

Method: 基于e值框架构建安全随时有效推断：通过"押注"反对均衡，构造检验超鞅，当观测到的收益系统性违反均衡条件时积累证据。利用Benjamini-Hochberg型程序提高大型博弈中的检测能力，同时严格控制错误发现率。

Result: 该方法提供了统计可靠、可解释的均衡偏离度量，可在线监控，统一处理纳什均衡、相关均衡和粗相关均衡，提供有限时间保证和检测时间详细分析。

Conclusion: 该框架扩展了均衡监测方法，可应用于随机博弈，超越了重复博弈设置，为解决多智能体系统中实时行为漂移检测问题提供了有效工具。

Abstract: In many multi-agent systems, agents interact repeatedly and are expected to settle into equilibrium behavior over time. Yet in practice, behavior often drifts, and detecting such deviations in real time remains an open challenge. We introduce a sequential testing framework that monitors whether observed play in repeated games is consistent with equilibrium, without assuming a fixed sample size. Our approach builds on the e-value framework for safe anytime-valid inference: by "betting" against equilibrium, we construct a test supermartingale that accumulates evidence whenever observed payoffs systematically violate equilibrium conditions. This yields a statistically sound, interpretable measure of departure from equilibrium that can be monitored online. We also leverage Benjamini-Hochberg-type procedures to increase detection power in large games while rigorously controlling the false discovery rate. Our framework unifies the treatment of Nash, correlated, and coarse correlated equilibria, offering finite-time guarantees and a detailed analysis of detection times. Moreover, we extend our method to stochastic games, broadening its applicability beyond repeated-play settings.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [26] [A General Metric-Space Formulation of the Time Warp Edit Distance (TWED)](https://arxiv.org/abs/2601.05263)
*Zhen Yi Lau*

Main category: cs.IR

TL;DR: 本文提出了时间弯曲编辑距离(TWED)在任意度量空间上的形式化推广，称为广义TWED(GTWED)，证明了其在温和假设下仍保持度量性质。


<details>
  <summary>Details</summary>
Motivation: 将TWED从传统的欧几里得空间时间序列扩展到更一般的度量空间，使其能够应用于符号数据、流形或嵌入等任意域上的序列分析。

Method: 将观测域和时间域都视为度量空间$(X, d)$和$(T, Δ)$，通过形式化推广定义广义TWED(GTWED)，并提供其度量性质的自包含证明。

Result: GTWED在温和假设下保持度量性质，当$X = \mathbb{R}^d$、$T \subset \mathbb{R}$且$g(x) = x$时，经典TWED作为特例被恢复。

Conclusion: GTWED为弹性距离提供了理论框架，使TWED类度量能够应用于任意域上的序列，扩展了时间序列分析的应用范围。

Abstract: This short technical note presents a formal generalization of the Time Warp Edit Distance (TWED) proposed by Marteau (2009) to arbitrary metric spaces. By viewing both the observation and temporal domains as metric spaces $(X, d)$ and $(T, Δ)$, we define a Generalized TWED (GTWED) that remains a true metric under mild assumptions. We provide self-contained proofs of its metric properties and show that the classical TWED is recovered as a special case when $X = \mathbb{R}^d$, $T \subset \mathbb{R}$, and $g(x) = x$. This note focuses on the theoretical structure of GTWED and its implications for extending elastic distances beyond time series, which enables the use of TWED-like metrics on sequences over arbitrary domains such as symbolic data, manifolds, or embeddings.

</details>


### [27] [SP-Rank: A Dataset for Ranked Preferences with Secondary Information](https://arxiv.org/abs/2601.05253)
*Hadi Hosseini,Debmalya Mandal,Amrit Puhan*

Main category: cs.IR

TL;DR: SP-Rank是首个大规模公开数据集，用于评估结合一阶偏好和二阶预测的排序算法，包含12,000+人类生成数据点，涵盖地理、电影、绘画三个领域。


<details>
  <summary>Details</summary>
Motivation: 传统数据集仅捕获个体偏好，缺乏对二阶预测（即个体对他人偏好的预测）的建模。SP-Rank旨在支持更丰富的偏好建模，特别是在专家身份未知但存在的情况下，个体投票被视为共享真实排序的噪声估计。

Method: 构建包含一阶个人投票和二阶元预测（预测他人如何投票）的数据集，涵盖9种不同子集大小的启发格式。提出SP-Voting方法，联合推理两个信号来推断真实排序，并与仅使用一阶投票的传统聚合方法进行基准比较。

Result: 结合二阶信号显著提高了排序准确性，优于仅使用投票的方法。在三个核心任务上表现优异：(1)完整真实排序恢复，(2)子集级排序恢复，(3)投票者行为的概率建模。

Conclusion: SP-Rank数据集支持二阶信号在偏好建模中的重要性，为学习排序、从噪声众包中提取专家知识、偏好微调管道中的奖励模型训练等下游应用提供支持，促进人类偏好建模、聚合理论和人机对齐研究。

Abstract: We introduce $\mathbf{SP-Rank}$, the first large-scale, publicly available dataset for benchmarking algorithms that leverage both first-order preferences and second-order predictions in ranking tasks. Each datapoint includes a personal vote (first-order signal) and a meta-prediction of how others will vote (second-order signal), allowing richer modeling than traditional datasets that capture only individual preferences. SP-Rank contains over 12,000 human-generated datapoints across three domains -- geography, movies, and paintings, and spans nine elicitation formats with varying subset sizes. This structure enables empirical analysis of preference aggregation when expert identities are unknown but presumed to exist, and individual votes represent noisy estimates of a shared ground-truth ranking. We benchmark SP-Rank by comparing traditional aggregation methods that use only first-order votes against SP-Voting, a second-order method that jointly reasons over both signals to infer ground-truth rankings. While SP-Rank also supports models that rely solely on second-order predictions, our benchmarks emphasize the gains from combining both signals. We evaluate performance across three core tasks: (1) full ground-truth rank recovery, (2) subset-level rank recovery, and (3) probabilistic modeling of voter behavior. Results show that incorporating second-order signals substantially improves accuracy over vote-only methods. Beyond social choice, SP-Rank supports downstream applications in learning-to-rank, extracting expert knowledge from noisy crowds, and training reward models in preference-based fine-tuning pipelines. We release the dataset, code, and baseline evaluations (available at https://github.com/amrit19/SP-Rank-Dataset ) to foster research in human preference modeling, aggregation theory, and human-AI alignment.

</details>


### [28] [TagRAG: Tag-guided Hierarchical Knowledge Graph Retrieval-Augmented Generation](https://arxiv.org/abs/2601.05254)
*Wenbiao Tao,Yunshi Lan,Weining Qian*

Main category: cs.IR

TL;DR: TagRAG：基于标签引导的层次知识图谱RAG框架，通过标签知识图谱构建和标签引导检索增强生成，实现高效全局推理和可扩展的图维护，相比传统RAG和GraphRAG在性能和效率上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法依赖片段级检索，难以处理查询聚焦的摘要查询；GraphRAG虽然引入基于图的全局知识推理，但存在信息提取效率低、资源消耗大、增量更新适应性差等问题。需要一种更高效、可扩展的RAG框架。

Method: 提出TagRAG框架，包含两个核心组件：1) 标签知识图谱构建：从文档中提取对象标签及其关系，组织成层次化的领域标签链，实现结构化知识表示；2) 标签引导检索增强生成：检索领域中心的标签链，在推理过程中定位和合成相关知识。

Result: 在涵盖农业、计算机科学、法律和跨领域设置的UltraDomain数据集上，TagRAG相对于基线方法平均胜率达到95.41%，同时在构建效率上比GraphRAG提升约14.6倍，检索效率提升约1.9倍。

Conclusion: TagRAG通过标签引导的层次知识图谱方法，显著提升了RAG系统的全局推理能力、检索粒度、对小语言模型的适应性以及知识增量效率，为高效可扩展的知识增强生成提供了有效解决方案。

Abstract: Retrieval-Augmented Generation enhances language models by retrieving external knowledge to support informed and grounded responses. However, traditional RAG methods rely on fragment-level retrieval, limiting their ability to address query-focused summarization queries. GraphRAG introduces a graph-based paradigm for global knowledge reasoning, yet suffers from inefficiencies in information extraction, costly resource consumption, and poor adaptability to incremental updates. To overcome these limitations, we propose TagRAG, a tag-guided hierarchical knowledge graph RAG framework designed for efficient global reasoning and scalable graph maintenance. TagRAG introduces two key components: (1) Tag Knowledge Graph Construction, which extracts object tags and their relationships from documents and organizes them into hierarchical domain tag chains for structured knowledge representation, and (2) Tag-Guided Retrieval-Augmented Generation, which retrieves domain-centric tag chains to localize and synthesize relevant knowledge during inference. This design significantly adapts to smaller language models, improves retrieval granularity, and supports efficient knowledge increment. Extensive experiments on UltraDomain datasets spanning Agriculture, Computer Science, Law, and cross-domain settings demonstrate that TagRAG achieves an average win rate of 95.41\% against baselines while maintaining about 14.6x construction and 1.9x retrieval efficiency compared with GraphRAG.

</details>


### [29] [CourtNav: Voice-Guided, Anchor-Accurate Navigation of Long Legal Documents in Courtrooms](https://arxiv.org/abs/2601.05255)
*Sai Khadloya,Kush Juvekar,Arghya Bhattacharya,Utkarsh Saxena*

Main category: cs.IR

TL;DR: CourtNav是一个语音引导的法律PDF导航系统，通过语音命令快速定位法律文档中的特定段落，将查找时间从3-5分钟缩短到10-15秒。


<details>
  <summary>Details</summary>
Motivation: 法官需要阅读冗长的法律文件（数百页），但人员支持有限，听证会上无法详尽阅读。特别是在印度，判决书和交叉询问记录特别冗长，需要高效导航工具。

Method: 语音引导、锚点优先的导航系统：转录语音命令，使用语法优先（精确正则匹配）和LLM支持的路由器（基于少样本示例）分类查询意图，通过布局感知的混合索引检索，自动滚动到引用段落并高亮显示。界面只显示有依据的段落，不显示自由文本。

Result: 在代表性起诉书、诉状和命令的试点中，中位相关时间从3-5分钟（手动导航）降至10-15秒；包含快速视觉验证后为30-45秒。在固定时间预算下，这种导航优先设计增加了实际查阅记录的广度，同时保持了控制和透明度。

Conclusion: CourtNav通过语音命令快速导航法律PDF，显著提高了法官查阅冗长法律文件的效率，同时保持了证据的可验证性和可审计性，解决了印度等地区法律文件冗长的实际问题。

Abstract: Judicial work depends on close reading of long records, charge sheets, pleadings, annexures, orders, often spanning hundreds of pages. With limited staff support, exhaustive reading during hearings is impractical. We present CourtNav, a voice-guided, anchor-first navigator for legal PDFs that maps a judge's spoken command (e.g., "go to paragraph 23", "highlight the contradiction in the cross-examination") directly to a highlighted paragraph in seconds. CourtNav transcribes the command, classifies intent with a grammar-first(Exact regex matching), LLM-backed router classifying the queries using few shot examples, retrieves over a layout-aware hybrid index, and auto-scrolls the viewer to the cited span while highlighting it and close alternates. By design, the interface shows only grounded passages, never free text, keeping evidence verifiable and auditable. This need is acute in India, where judgments and cross-examinations are notoriously long.In a pilot on representative charge sheets, pleadings, and orders, median time-to-relevance drops from 3-5 minutes (manual navigation) to 10-15 seconds; with quick visual verification included, 30-45 seconds. Under fixed time budgets, this navigation-first design increases the breadth of the record actually consulted while preserving control and transparency.

</details>


### [30] [KP-Agent: Keyword Pruning in Sponsored Search Advertising via LLM-Powered Contextual Bandits](https://arxiv.org/abs/2601.05257)
*Hou-Wan Long,Yicheng Song,Zidong Wang,Tianshu Sun*

Main category: cs.IR

TL;DR: 本文提出KP-Agent，一个基于LLM的智能代理系统，用于赞助搜索广告中的关键词修剪，通过强化学习优化关键词集，实验显示可将累计利润提升高达49.28%。


<details>
  <summary>Details</summary>
Motivation: 赞助搜索广告中，广告主需要不断调整关键词策略。虽然出价调整和关键词生成已有较多研究，但关键词修剪（优化关键词集以提升广告活动性能）仍未被充分探索。当前实践中存在效率低下的问题，这在美团平台上的50万条SSA记录数据集中得到了证实。

Method: 提出KP-Agent，一个基于大语言模型的智能代理系统，包含领域工具集和记忆模块。通过将关键词修剪建模为上下文赌博机问题，KP-Agent生成代码片段，通过强化学习来优化关键词集。

Result: 实验表明，KP-Agent相比基线方法，能将累计利润提升高达49.28%。

Conclusion: KP-Agent系统有效地解决了赞助搜索广告中关键词修剪的挑战，通过LLM代理和强化学习的结合，显著提升了广告活动的盈利能力。

Abstract: Sponsored search advertising (SSA) requires advertisers to constantly adjust keyword strategies. While bid adjustment and keyword generation are well-studied, keyword pruning-refining keyword sets to enhance campaign performance-remains under-explored. This paper addresses critical inefficiencies in current practices as evidenced by a dataset containing 0.5 million SSA records from a pharmaceutical advertiser on search engine Meituan, China's largest delivery platform. We propose KP-Agent, an LLM agentic system with domain tool set and a memory module. By modeling keyword pruning within a contextual bandit framework, KP-Agent generates code snippets to refine keyword sets through reinforcement learning. Experiments show KP-Agent improves cumulative profit by up to 49.28% over baselines.

</details>


### [31] [From Events to Trending: A Multi-Stage Hotspots Detection Method Based on Generative Query Indexing](https://arxiv.org/abs/2601.05258)
*Kaichun Wang,Yanguang Chen,Ting Zhang,Mengyao Bao,Keyu Chen,Xu Hu,Yongliang Wang,Jingsheng Yang,Jinsong Zhang,Fei Lu*

Main category: cs.IR

TL;DR: 提出多阶段框架检测对话系统中的趋势查询，通过离线生成和在线识别优化，显著提升用户满意度


<details>
  <summary>Details</summary>
Motivation: 现有聊天机器人难以有效处理新闻相关趋势查询，而传统搜索引擎的检测方法在对话场景中表现不佳，需要专门针对对话系统的趋势检测方法

Method: 多阶段框架：1) 利用热点事件生成索引查询；2) 采用检索匹配机制实时检测，引入级联召回和排序架构平衡效率与准确性；3) 使用单召回模块作为冷启动策略收集在线数据微调排序器

Result: 框架在离线评估和在线A/B测试中显著优于基线方法，用户满意度（正负反馈比）相对提升27%

Conclusion: 提出的多阶段趋势检测框架有效解决了对话系统中趋势查询检测问题，通过系统化优化显著改善了用户体验

Abstract: LLM-based conversational systems have become a popular gateway for information access, yet most existing chatbots struggle to handle news-related trending queries effectively. To improve user experience, an effective trending query detection method is urgently needed to enable differentiated processing of such target traffic. However, current research on trending detection tailored to the dialogue system scenario remains largely unexplored, and methods designed for traditional search engines often underperform in conversational contexts due to radically distinct query distributions and expression patterns. To fill this gap, we propose a multi-stage framework for trending detection, which achieves systematic optimization from both offline generation and online identification perspectives. Specifically, our framework first exploits selected hot events to generate index queries, establishing a key bridge between static events and dynamic user queries. It then employs a retrieval matching mechanism for real-time online detection of trending queries, where we introduce a cascaded recall and ranking architecture to balance detection efficiency and accuracy. Furthermore, to better adapt to the practical application scenario, our framework adopts a single-recall module as a cold-start strategy to collect online data for fine-tuning the reranker. Extensive experiments demonstrate that our framework significantly outperforms baseline methods in both offline evaluations and online A/B tests, and user satisfaction is relatively improved by 27\% in terms of positive-negative feedback ratio.

</details>


### [32] [A Technical Report on the Second Place Solution for the CIKM 2025 AnalytiCup Competition](https://arxiv.org/abs/2601.05259)
*Haotao Xie,Ruilin Chen,Yicheng Wu,Zhan Zhao,Yuanyuan Liu*

Main category: cs.IR

TL;DR: 提出基于提示工程和思维链任务分解的单模型框架，用于多语言电商搜索分类相关性判断，在保持高准确率的同时显著降低计算和维护复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统集成系统虽然能提高准确性，但存在训练、推理和维护复杂度高的问题，需要一种更简化有效的解决方案来处理多语言电商搜索中的分类相关性判断任务。

Method: 使用思维链任务分解将相关性判断过程分为四个可解释子任务（翻译、意图理解、分类匹配、相关性判断），并基于Qwen2.5-14B模型通过LoRA进行轻量级微调。

Result: 在CIKM 2025 AnalytiCup竞赛中，公开榜得分0.8902，私有榜得分0.8889；单A100 GPU上达到每秒20个样本的高推理效率，性能与复杂集成系统相当但更高效。

Conclusion: 结构化提示与轻量级微调相结合的方法能够超越复杂集成系统，为可扩展的工业AI应用提供了新范式，在保持高准确率的同时显著降低了计算和维护成本。

Abstract: In this work, we address the challenge of multilingual category relevance judgment in e-commerce search, where traditional ensemble-based systems improve accuracy but at the cost of heavy training, inference, and maintenance complexity. To overcome this limitation, we propose a simplified yet effective framework that leverages prompt engineering with Chain-of-Thought task decomposition to guide reasoning within a single large language model. Specifically, our approach decomposes the relevance judgment process into four interpretable subtasks: translation, intent understanding, category matching, and relevance judgment -- and fine-tunes a base model (Qwen2.5-14B) using Low-Rank Adaptation (LoRA) for efficient adaptation. This design not only reduces computational and storage overhead but also enhances interpretability by explicitly structuring the model's reasoning path. Experimental results show that our single-model framework achieves competitive accuracy and high inference efficiency, processing 20 samples per second on a single A100 GPU. In the CIKM 2025 AnalytiCup Competition Proposals, our method achieved 0.8902 on the public leaderboard and 0.8889 on the private leaderboard, validating the effectiveness and robustness of the proposed approach. These results highlight that structured prompting combined with lightweight fine-tuning can outperform complex ensemble systems, offering a new paradigm for scalable industrial AI applications.

</details>


### [33] [Quantifying Document Impact in RAG-LLMs](https://arxiv.org/abs/2601.05260)
*Armin Gerami,Kazem Faghih,Ramani Duraiswami*

Main category: cs.IR

TL;DR: 本文提出了一种新的度量标准——影响力分数（IS），用于量化RAG系统中单个检索文档对最终输出的贡献，解决了当前RAG评估中缺乏文档级影响力量化的问题。


<details>
  <summary>Details</summary>
Motivation: RAG系统虽然能增强LLM的准确性和时效性，但带来了事实不一致、来源冲突、偏见传播和安全漏洞等问题，这些影响了RAG系统的可信度。当前RAG评估的一个关键缺陷是缺乏量化单个检索文档对最终输出贡献的指标。

Method: 基于部分信息分解（Partial Information Decomposition）提出了影响力分数（IS）这一新度量标准，用于衡量每个检索文档对生成响应的具体影响。通过两个实验验证：1）在三个数据集上进行毒化攻击模拟；2）消融研究，比较仅使用IS排名靠前文档生成的响应与使用剩余文档生成的响应。

Result: 毒化攻击实验中，IS在86%的情况下正确识别出恶意文档为最具影响力的文档。消融研究表明，仅使用IS排名靠前文档生成的响应比使用剩余文档生成的响应更接近原始响应，验证了IS在隔离和量化文档影响力方面的有效性。

Conclusion: 影响力分数（IS）能够有效隔离和量化RAG系统中单个文档的影响力，为提高RAG系统的透明度和可靠性提供了有价值的工具，有助于解决当前RAG评估中的关键缺陷。

Abstract: Retrieval Augmented Generation (RAG) enhances Large Language Models (LLMs) by connecting them to external knowledge, improving accuracy and reducing outdated information. However, this introduces challenges such as factual inconsistencies, source conflicts, bias propagation, and security vulnerabilities, which undermine the trustworthiness of RAG systems. A key gap in current RAG evaluation is the lack of a metric to quantify the contribution of individual retrieved documents to the final output. To address this, we introduce the Influence Score (IS), a novel metric based on Partial Information Decomposition that measures the impact of each retrieved document on the generated response. We validate IS through two experiments. First, a poison attack simulation across three datasets demonstrates that IS correctly identifies the malicious document as the most influential in $86\%$ of cases. Second, an ablation study shows that a response generated using only the top-ranked documents by IS is consistently judged more similar to the original response than one generated from the remaining documents. These results confirm the efficacy of IS in isolating and quantifying document influence, offering a valuable tool for improving the transparency and reliability of RAG systems.

</details>


### [34] [LiveVectorLake: A Real-Time Versioned Knowledge Base Architecture for Streaming Vector Updates and Temporal Retrieval](https://arxiv.org/abs/2601.05270)
*Tarun Prajapati*

Main category: cs.IR

TL;DR: LiveVectorLake提出双层级时间知识库架构，解决RAG系统中向量索引更新效率与数据湖查询延迟的矛盾，实现实时语义搜索与完整版本历史管理。


<details>
  <summary>Details</summary>
Motivation: 现代RAG系统面临架构矛盾：向量索引优化查询延迟但处理连续知识更新困难，数据湖擅长版本控制但引入查询延迟惩罚。需要同时优化查询性能、更新效率和合规性。

Method: 1) 基于SHA-256哈希的内容可寻址块级同步，无需外部状态跟踪；2) 热层向量索引（Milvus+HNSW）与冷层列式版本控制（Delta Lake+Parquet）分离的双层级存储；3) 通过delta版本控制实现时间点知识检索的时间查询路由。

Result: 在100文档5个时间点版本化评估中：1) 更新时仅需重新处理10-15%内容（相比全量重索引的100%）；2) 当前知识检索延迟低于100ms；3) 跨版本历史的时间查询延迟低于2秒；4) 通过热冷层分离优化存储成本。

Conclusion: LiveVectorLake架构使生产RAG部署能够同时优化查询性能、更新效率和监管合规性，解决了向量索引与数据湖之间的基本架构矛盾。

Abstract: Modern Retrieval-Augmented Generation (RAG) systems struggle with a fundamental architectural tension: vector indices are optimized for query latency but poorly handle continuous knowledge updates, while data lakes excel at versioning but introduce query latency penalties. We introduce LiveVectorLake, a dual-tier temporal knowledge base architecture that enables real-time semantic search on current knowledge while maintaining complete version history for compliance, auditability, and point-in-time retrieval. The system introduces three core architectural contributions: (1) Content-addressable chunk-level synchronization using SHA-256 hashing for deterministic change detection without external state tracking; (2) Dual-tier storage separating hot-tier vector indices (Milvus with HNSW) from cold-tier columnar versioning (Delta Lake with Parquet), optimizing query latency and storage cost independently; (3) Temporal query routing enabling point-in-time knowledge retrieval via delta-versioning with ACID consistency across tiers. Evaluation on a 100-document corpus versioned across five time points demonstrates: (i) 10-15% re-processing of content during updates compared to 100% for full re-indexing; (ii) sub-100ms retrieval latency on current knowledge; (iii) sub-2s latency for temporal queries across version history; and (iv) storage cost optimization through hot/cold tier separation (only current chunks in expensive vector indices). The approach enables production RAG deployments requiring simultaneous optimization for query performance, update efficiency, and regulatory compliance. Code and resources: [https://github.com/praj-tarun/LiveVectorLake]

</details>


### [35] [Improving User Experience with Personalized Review Ranking and Summarization](https://arxiv.org/abs/2601.05261)
*Muhammad Mufti,Omar Hammad,Mahfuzur Rahman*

Main category: cs.IR

TL;DR: 提出一个个性化评论排序与摘要框架，通过整合用户情感分析和偏好建模，为消费者提供定制化的产品评论内容，缓解信息过载问题。


<details>
  <summary>Details</summary>
Motivation: 现有评论排序系统主要依赖有用性投票、星级评分和时效性等通用指标，无法捕捉个体用户兴趣，且将文本情感和评分信号分开处理，导致信息过载问题严重，消费者难以找到符合个人偏好的内容。

Method: 提出个性化框架整合评论排序和抽象摘要：1) 通过星级评分和评论内容的混合分析建模用户情感；2) 使用句子嵌入和聚类从历史评论中提取用户偏好，形成语义配置文件；3) 基于情感和方面相似性的相关性评分算法匹配用户配置文件与未读评论；4) 对匹配度最高的评论进行摘要生成以反映个体兴趣。

Result: 70名参与者的用户研究表明，个性化方法提高了满意度、感知相关性和决策信心，同时减少了阅读时间。结果证明了该方法在缓解信息过载和提供定制内容方面的有效性。

Conclusion: 该个性化框架能有效提升评论丰富决策环境中的用户体验，通过整合情感分析和偏好建模，为消费者提供更相关、高效的决策支持，强调了定制化内容在信息过载环境中的价值。

Abstract: Online consumer reviews play a crucial role in guiding purchase decisions by offering insights into product quality, usability, and performance. However, the increasing volume of user-generated reviews has led to information overload, making it difficult for consumers to identify content that aligns with their specific preferences. Existing review ranking systems typically rely on metrics such as helpfulness votes, star ratings, and recency, but these fail to capture individual user interests and often treat textual sentiment and rating signals separately. This research addresses these limitations by proposing a personalized framework that integrates review ranking and abstractive summarization to enhance decision-making efficiency. The proposed system begins by modeling each user's sentiment through a hybrid analysis of star ratings and review content. Simultaneously, user preferences were derived from historical reviews using sentence embeddings and clustering, forming semantic profiles aligned with thematic and sentiment dimensions. A relevance scoring algorithm matched these profiles with unseen reviews based on sentiment and aspect similarity. Top-matched reviews were then summarized to reflect individual interests. A user study with 70 participants demonstrated that the personalized approach improved satisfaction, perceived relevance, and decision-making confidence, while reducing time spent reading. The results highlight the method's effectiveness in alleviating information overload and delivering content tailored to user-specific preferences, emphasizing its value in enhancing user experience in review-rich decision-making environments.

</details>


### [36] [LLM2IR: simple unsupervised contrastive learning makes long-context LLM great retriever](https://arxiv.org/abs/2601.05262)
*Xiaocong Yang*

Main category: cs.IR

TL;DR: LLM2IR：一种将解码器专用大语言模型转换为信息检索模型的无监督对比学习框架，无需大规模预训练，且发现模型上下文长度与IR能力正相关


<details>
  <summary>Details</summary>
Motivation: 现代密集信息检索模型通常依赖昂贵的大规模预训练，需要一种更高效的方法来构建IR模型，并探索模型上下文长度与IR能力的关系

Method: 提出LLM2IR框架，通过无监督对比学习将任何解码器专用大语言模型转换为信息检索模型，无需大规模预训练

Result: 在不同LLM和多个IR基准测试（LoCo、LongEmbed和BEIR）上证明有效性，发现同一模型家族中上下文长度更长的模型具有更强的IR能力

Conclusion: LLM2IR为在最新LLMs上构建IR模型提供了有效方法，揭示了信息检索能力与模型上下文长度的关系，有助于设计更好的信息检索器

Abstract: Modern dense information retrieval (IR) models usually rely on costly large-scale pretraining. In this paper, we introduce LLM2IR, an efficient unsupervised contrastive learning framework to convert any decoder-only large language model (LLM) to an information retrieval model. Despite its simplicity, the effectiveness is proven among different LLMs on multiple IR benchmarks including LoCo, LongEmbed and BEIR. We also find that models with a longer context length tend to have a stronger IR capacity by comparing task performances of models in the same model family. Our work not only provides an effective way to build IR models on the state-of-the-art LLMs, but also shed light on the relationship between information retrieval ability and model context length, which helps the design of better information retrievers.

</details>


### [37] [Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2601.05264)
*Dean Wampler,Dave Nielson,Alireza Seddighi*

Main category: cs.IR

TL;DR: 对2018-2025年检索增强生成(RAG)架构的系统性文献综述，提供实用指南和统一分类法


<details>
  <summary>Details</summary>
Motivation: 随着LLM系统扩展，RAG提供了一种模块化方法集成外部知识而无需增加模型容量。然而，由于RAG方法的多样性（融合机制、检索策略、编排方法等），研究和工程实践变得碎片化，需要系统整合。

Method: 对学术研究、工业应用和实际部署进行系统性文献综述，将现有RAG技术整合为统一分类法，提供定量评估框架，并分析信任和对齐的影响。

Result: 提供了现代RAG架构的详细概述和实用指南，建立了统一的RAG技术分类体系，开发了部署弹性、安全和领域适应性RAG系统的实用框架。

Conclusion: 本文为RAG系统部署提供了技术参考和实用框架，综合了学术文献、行业报告和技术实施指南的见解，有助于推动RAG技术的标准化和应用。

Abstract: This article provides a comprehensive systematic literature review of academic studies, industrial applications, and real-world deployments from 2018 to 2025, providing a practical guide and detailed overview of modern Retrieval-Augmented Generation (RAG) architectures. RAG offers a modular approach for integrating external knowledge without increasing the capacity of the model as LLM systems expand. Research and engineering practices have been fragmented as a result of the increasing diversity of RAG methodologies, which encompasses a variety of fusion mechanisms, retrieval strategies, and orchestration approaches. We provide quantitative assessment frameworks, analyze the implications for trust and alignment, and systematically consolidate existing RAG techniques into a unified taxonomy. This document is a practical framework for the deployment of resilient, secure, and domain-adaptable RAG systems, synthesizing insights from academic literature, industry reports, and technical implementation guides. It also functions as a technical reference.

</details>


### [38] [Cross-Document Topic-Aligned Chunking for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.05265)
*Mile Stankovic*

Main category: cs.IR

TL;DR: CDTA chunking通过跨文档主题对齐重构知识，解决知识碎片化问题，在复杂查询中显著提升RAG系统性能


<details>
  <summary>Details</summary>
Motivation: 现有文档分块方法单独处理每个文档，但复杂查询需要跨多个来源的信息，存在知识碎片化问题

Method: 跨文档主题对齐分块：首先识别跨文档主题，将文档片段映射到相应主题，然后合成统一的知识块

Result: 在HotpotQA多跳推理中达到0.93忠实度（比现有最佳方法提升12%），在UAE法律文本中达到0.94忠实度和0.93引用准确率，在k=3时仍保持0.91忠实度

Conclusion: 虽然索引成本较高，但合成信息密集的知识块减少了查询时检索需求，对于高查询量且知识分散的应用，跨文档合成优于文档内优化

Abstract: Chunking quality determines RAG system performance. Current methods partition documents individually, but complex queries need information scattered across multiple sources: the knowledge fragmentation problem. We introduce Cross-Document Topic-Aligned (CDTA) chunking, which reconstructs knowledge at the corpus level. It first identifies topics across documents, maps segments to each topic, and synthesizes them into unified chunks.
  On HotpotQA multi-hop reasoning, our method reached 0.93 faithfulness versus 0.83 for contextual retrieval and 0.78 for semantic chunking, a 12% improvement over current industry best practice (p < 0.05). On UAE Legal texts, it reached 0.94 faithfulness with 0.93 citation accuracy. At k = 3, it maintains 0.91 faithfulness while semantic methods drop to 0.68, with a single CDTA chunk containing information requiring multiple traditional fragments.
  Indexing costs are higher, but synthesis produces information-dense chunks that reduce query-time retrieval needs. For high-query-volume applications with distributed knowledge, cross-document synthesis improves measurably over within-document optimization.

</details>


### [39] [Retrieval-Augmented Multi-LLM Ensemble for Industrial Part Specification Extraction](https://arxiv.org/abs/2601.05266)
*Muzakkiruddin Ahmed Mohammed,John R. Talburt,Leon Claasssens,Adriaan Marais*

Main category: cs.IR

TL;DR: 提出RAGsemble框架，通过检索增强的多LLM集成方法，从非结构化文本中提取工业零件规格，显著提升准确性和完整性


<details>
  <summary>Details</summary>
Motivation: 工业零件规格从非结构化文本中提取存在挑战，传统手动处理耗时且易错，单一模型系统存在局限性

Method: 采用检索增强的多LLM集成框架，整合9个先进LLM，构建三阶段流水线：并行提取、针对性研究增强、智能合成与冲突解决，结合FAISS语义检索

Result: 在真实工业数据集上实验显示，相比领先的单LLM基线，在提取准确性、技术完整性和结构化输出质量方面有显著提升

Conclusion: RAGsemble为工业领域提供了可扩展的集成架构，实现了全流程RAG集成，建立了全面的质量评估机制，是适合知识密集型制造环境的生产就绪解决方案

Abstract: Industrial part specification extraction from unstructured text remains a persistent challenge in manufacturing, procurement, and maintenance, where manual processing is both time-consuming and error-prone. This paper introduces a retrieval-augmented multi-LLM ensemble framework that orchestrates nine state-of-the-art Large Language Models (LLMs) within a structured three-phase pipeline. RAGsemble addresses key limitations of single-model systems by combining the complementary strengths of model families including Gemini (2.0, 2.5, 1.5), OpenAI (GPT-4o, o4-mini), Mistral Large, and Gemma (1B, 4B, 3n-e4b), while grounding outputs in factual data using FAISS-based semantic retrieval. The system architecture consists of three stages: (1) parallel extraction by diverse LLMs, (2) targeted research augmentation leveraging high-performing models, and (3) intelligent synthesis with conflict resolution and confidence-aware scoring. RAG integration provides real-time access to structured part databases, enabling the system to validate, refine, and enrich outputs through similarity-based reference retrieval. Experimental results using real industrial datasets demonstrate significant gains in extraction accuracy, technical completeness, and structured output quality compared to leading single-LLM baselines. Key contributions include a scalable ensemble architecture for industrial domains, seamless RAG integration throughout the pipeline, comprehensive quality assessment mechanisms, and a production-ready solution suitable for deployment in knowledge-intensive manufacturing environments.

</details>


### [40] [Transforming User Defined Criteria into Explainable Indicators with an Integrated LLM AHP System](https://arxiv.org/abs/2601.05267)
*Geonwoo Bang,Dongho Kim,Moohong Min*

Main category: cs.IR

TL;DR: 提出一个结合LLM评分与层次分析法(AHP)的可解释聚合框架，用于跨领域复杂文本评估，在保持预测能力的同时提高可解释性和操作效率。


<details>
  <summary>Details</summary>
Motivation: 评估跨领域复杂文本需要将用户定义的标准转化为可量化、可解释的指标，这是搜索和推荐系统中的持续挑战。单一提示的LLM评估存在复杂性和延迟问题，而特定标准分解方法依赖简单平均或不透明的黑盒聚合方法。

Method: 提出可解释聚合框架，结合LLM评分与层次分析法(AHP)：1) 通过LLM作为评判者生成特定标准分数；2) 使用Jensen-Shannon距离测量判别能力；3) 通过AHP成对比较矩阵推导统计基础权重。

Result: 在亚马逊评论质量评估和抑郁相关文本评分实验中，该方法实现了高可解释性和操作效率，同时保持可比较的预测能力，适合实时延迟敏感的Web服务。

Conclusion: 该方法为复杂文本评估提供了一个可解释、高效的解决方案，特别适用于需要实时响应和透明决策过程的Web服务应用。

Abstract: Evaluating complex texts across domains requires converting user defined criteria into quantitative, explainable indicators, which is a persistent challenge in search and recommendation systems. Single prompt LLM evaluations suffer from complexity and latency issues, while criterion specific decomposition approaches rely on naive averaging or opaque black-box aggregation methods. We present an interpretable aggregation framework combining LLM scoring with the Analytic Hierarchy Process. Our method generates criterion specific scores via LLM as judge, measures discriminative power using Jensen Shannon distance, and derives statistically grounded weights through AHP pairwise comparison matrices. Experiments on Amazon review quality assessment and depression related text scoring demonstrate that our approach achieves high explainability and operational efficiency while maintaining comparable predictive power, making it suitable for real time latency sensitive web services.

</details>


### [41] [Separating Semantic Expansion from Linear Geometry for PubMed-Scale Vector Search](https://arxiv.org/abs/2601.05268)
*Rob Koopman*

Main category: cs.IR

TL;DR: 提出一个PubMed规模检索框架，将语义解释与度量几何分离，使用LLM扩展查询为生物医学短语，在固定、均值自由、近似各向同性的嵌入空间中进行检索，无需训练参数。


<details>
  <summary>Details</summary>
Motivation: 解决大规模生物医学文献检索中语义理解与几何检索分离的问题，避免传统方法需要训练参数和复杂优化的限制，实现高效、可扩展的检索系统。

Method: 1) LLM将自然语言查询扩展为简洁生物医学短语；2) 文档和查询向量作为标记嵌入的加权均值；3) 投影到冗余轴补空间；4) 通过Johnson-Lindenstrauss变换压缩；5) 在256维int8向量上进行精确余弦搜索。

Result: 系统能在整个MEDLINE语料库（约4000万条记录）中检索到连贯的生物医学聚类，使用纯几何评估指标（头部余弦、紧密度、质心闭合度、各向同性）优于随机向量基线。

Conclusion: 该框架展示了无需训练参数即可实现大规模生物医学文献检索的可行性，通过分离语义解释和度量几何，为高效检索系统提供了新思路。

Abstract: We describe a PubMed scale retrieval framework that separates semantic interpretation from metric geometry. A large language model expands a natural language query into concise biomedical phrases; retrieval then operates in a fixed, mean free, approximately isotropic embedding space. Each document and query vector is formed as a weighted mean of token embeddings, projected onto the complement of nuisance axes and compressed by a Johnson Lindenstrauss transform. No parameters are trained. The system retrieves coherent biomedical clusters across the full MEDLINE corpus (about 40 million records) using exact cosine search on 256 dimensional int8 vectors. Evaluation is purely geometric: head cosine, compactness, centroid closure, and isotropy are compared with random vector baselines. Recall is not defined, since the language-model expansion specifies the effective target set.

</details>


### [42] [Studying Illustrations in Manuscripts: An Efficient Deep-Learning Approach](https://arxiv.org/abs/2601.05269)
*Yoav Evron,Michal Bar-Asher Siegal,Michael Fire*

Main category: cs.IR

TL;DR: 提出一个快速可扩展的AI流水线，用于检测、提取和描述数字化手稿中的插图，应用于梵蒂冈图书馆等收藏，处理了300多万页，提取了20多万张插图。


<details>
  <summary>Details</summary>
Motivation: AI革命为人文学科带来了变革可能，特别是解锁历史手稿中的视觉内容。虽然数字档案提供了前所未有的访问，但大规模系统研究插图仍然具有挑战性。

Method: 三阶段流水线：1) 微调图像分类模型过滤纯文本页面；2) 高效目标检测模型识别和裁剪插图；3) 多模态图像描述模型生成简洁可读的描述。结果存储在可搜索数据库中。

Result: 应用于300多万数字化手稿页面，自动识别和提取了20多万张独特插图，处理速度达到每页不到0.06秒，在效率和可访问性上显著优于传统分割技术。

Conclusion: 前沿AI工具能够深刻重塑学术工作流程，为数字手稿时代的多学科研究开辟新途径，使历史研究、艺术史和文化遗产领域的学者能够以新的精度和速度探索视觉主题、艺术风格和跨文化影响。

Abstract: The recent Artificial Intelligence (AI) revolution has opened transformative possibilities for the humanities, particularly in unlocking the visual content embedded in historical manuscripts. While digital archives now offer unprecedented access to these materials, the ability to systematically study illustrations at a large scale remains challenging. Our study presents a fast and scalable AI approach for detecting, extracting, and describing illustrations in digitized manuscripts. Focusing on collections like the Vatican Library, our system enables efficient visual analysis across millions of pages. Our pipeline consists of three stages: (1) a fine-tuned image classification model filters out text-only pages; (2) an efficient object detection model identifies and crops illustrations; and (3) a multimodal image captioning model generates concise, human-readable descriptions. These are stored in a searchable database, allowing scholars to retrieve relevant visual materials through keyword queries. By harnessing the power of recent AI advancements, we enable large-scale visual research that was previously impractical, empowering scholars in historical studies, art history, and cultural heritage to explore visual motifs, artistic styles, and cross-cultural influences with new precision and speed. Applying our pipeline to over three million digitized manuscript pages, we automatically identified and extracted more than 200,000 unique illustrations. This scale of processing in under 0.06 seconds per page, dramatically outperforms traditional segmentation techniques in both efficiency and accessibility for visual scholarship. Our work demonstrates how cutting-edge AI tools can profoundly reshape scholarly workflows and open new avenues for multidisciplinary research in the age of digital manuscripts.

</details>


### [43] [RECOR: Reasoning-focused Multi-turn Conversational Retrieval Benchmark](https://arxiv.org/abs/2601.05461)
*Mohammed Ali,Abdelrahman Abdallah,Amit Agarwal,Hitesh Laxmichand Patel,Adam Jatowt*

Main category: cs.IR

TL;DR: 提出了一个结合多轮对话和推理密集型检索的基准测试，包含707个对话和11个领域，通过分解验证框架确保质量，结果显示结合对话历史和推理能显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试将多轮对话和推理密集型检索分开处理，但现实世界的信息寻求需要两者结合。为了填补这一空白，需要创建一个能够评估推理型对话信息检索的基准。

Method: 提出了分解与验证框架，将复杂查询转化为基于事实的多轮对话，通过多层次验证确保质量：原子事实与来源验证，并为每个对话轮次生成明确的检索推理。

Result: 结合对话历史和推理使检索性能翻倍（基线0.236 → 历史+推理0.479 nDCG@10），推理专用模型显著优于密集编码器。但隐式推理仍然具有挑战性，特别是当逻辑连接未在文本中明确表述时。

Conclusion: 该研究填补了对话式信息检索与推理密集型检索之间的空白，展示了结合对话历史和推理的重要性，同时指出了隐式推理仍是未来研究的重要挑战。

Abstract: Existing benchmarks treat multi-turn conversation and reasoning-intensive retrieval separately, yet real-world information seeking requires both. To bridge this gap, we present a benchmark for reasoning-based conversational information retrieval comprising 707 conversations (2,971 turns) across eleven domains. To ensure quality, our Decomposition-and-Verification framework transforms complex queries into fact-grounded multi-turn dialogues through multi-level validation, where atomic facts are verified against sources and explicit retrieval reasoning is generated for each turn. Comprehensive evaluation reveals that combining conversation history with reasoning doubles retrieval performance (Baseline .236 $\rightarrow$ History+Reasoning .479 nDCG@10), while reasoning-specialized models substantially outperform dense encoders. Despite these gains, further analysis highlights that implicit reasoning remains challenging, particularly when logical connections are not explicitly stated in the text.

</details>


### [44] [LEAPS: An LLM-Empowered Adaptive Plugin for Taobao AI Search](https://arxiv.org/abs/2601.05513)
*Lei Wang,Jinhang Wu,Zhibin Wang,Biye Li,Haiping Hou*

Main category: cs.IR

TL;DR: LEAPS是一个LLM赋能的淘宝AI搜索自适应插件，采用"扩展-精炼"范式，通过上游查询扩展器和下游相关性验证器提升对话式搜索体验，同时保持传统短文本查询的检索性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型重塑了用户搜索认知，从离散关键词搜索转向高维对话交互。现有电商搜索架构难以适应这一变化：精确的自然语言描述常导致零结果，而简化查询又会产生噪声过多的通用结果。

Method: LEAPS采用非侵入式架构，在搜索管道两端附加插件：上游查询扩展器通过逆数据增强、后验知识监督微调和多样性感知强化学习的三阶段训练策略生成自适应查询组合；下游相关性验证器通过整合多源数据（OCR文本、评论等）和思维链推理精确过滤噪声。

Result: 离线实验和在线A/B测试表明，LEAPS显著提升了对话式搜索体验。自2025年8月在淘宝AI搜索全面部署以来，每月服务数亿用户，同时保持了传统短文本查询的检索性能。

Conclusion: LEAPS成功解决了电商搜索中的查询-结果不匹配问题，通过"扩展-精炼"范式实现了传统搜索系统向对话式搜索的无缝升级，且具有低成本集成到不同后端的优势。

Abstract: The rapid advancement of large language models has reshaped user search cognition, driving a paradigm shift from discrete keyword-based search to high-dimensional conversational interaction. However, existing e-commerce search architectures face a critical capability deficit in adapting to this change. Users are often caught in a dilemma: precise natural language descriptions frequently trigger zero-result scenarios, while the forced simplification of queries leads to decision overload from noisy, generic results. To tackle this challenge, we propose LEAPS (LLM-Empowered Adaptive Plugin for Taobao AI Search), which seamlessly upgrades traditional search systems via a "Broaden-and-Refine" paradigm. Specifically, it attaches plugins to both ends of the search pipeline: (1) Upstream, a Query Expander acts as an intent translator. It employs a novel three-stage training strategy--inverse data augmentation, posterior-knowledge supervised fine-tuning, and diversity-aware reinforcement learning--to generate adaptive and complementary query combinations that maximize the candidate product set. (2) Downstream, a Relevance Verifier serves as a semantic gatekeeper. By synthesizing multi-source data (e.g., OCR text, reviews) and leveraging chain-of-thought reasoning, it precisely filters noise to resolve selection overload. Extensive offline experiments and online A/B testing demonstrate that LEAPS significantly enhances conversational search experiences. Crucially, its non-invasive architecture preserves established retrieval performance optimized for short-text queries, while simultaneously allowing for low-cost integration into diverse back-ends. Fully deployed on Taobao AI Search since August 2025, LEAPS currently serves hundreds of millions of users monthly.

</details>


### [45] [Efficient Temporal-aware Matryoshka Adaptation for Temporal Information Retrieval](https://arxiv.org/abs/2601.05549)
*Tuan-Luc Huynh,Weiqing Wang,Trung Le,Thuy-Trang Vu,Dragan Gašević,Yuan-Fang Li,Thanh-Toan Do*

Main category: cs.IR

TL;DR: TMRL通过引入时间感知的Matryoshka嵌入，提升检索器在时序RAG系统中的时间相关性检索能力，同时保持语义表示并支持精度-效率权衡。


<details>
  <summary>Details</summary>
Motivation: 时序检索增强生成系统中，检索器是关键瓶颈：如果无法检索到时间相关的上下文，无论LLM推理能力如何，都会降低下游生成质量。现有方法在时间感知检索方面存在不足。

Method: 提出时间感知的Matryoshka表示学习（TMRL），利用Matryoshka嵌入的嵌套结构引入时间子空间，增强时间编码同时保持通用语义表示，可高效适配多种文本嵌入模型。

Result: 实验表明TMRL能高效适配多样文本嵌入模型，在时间检索和时序RAG性能上优于先前的Matryoshka非时序方法和时序方法，同时支持灵活的精度-效率权衡。

Conclusion: TMRL为时序RAG系统提供了一种高效的时间感知检索解决方案，通过Matryoshka嵌入的时间子空间设计，在保持语义表示的同时显著提升时间相关性检索能力。

Abstract: Retrievers are a key bottleneck in Temporal Retrieval-Augmented Generation (RAG) systems: failing to retrieve temporally relevant context can degrade downstream generation, regardless of LLM reasoning. We propose Temporal-aware Matryoshka Representation Learning (TMRL), an efficient method that equips retrievers with temporal-aware Matryoshka embeddings. TMRL leverages the nested structure of Matryoshka embeddings to introduce a temporal subspace, enhancing temporal encoding while preserving general semantic representations. Experiments show that TMRL efficiently adapts diverse text embedding models, achieving competitive temporal retrieval and temporal RAG performance compared to prior Matryoshka-based non-temporal methods and prior temporal methods, while enabling flexible accuracy-efficiency trade-offs.

</details>


### [46] [Autoregressive Ranking: Bridging the Gap Between Dual and Cross Encoders](https://arxiv.org/abs/2601.05588)
*Benjamin Rozonoyer,Chong You,Michael Boratko,Himanshu Jain,Nilesh Gupta,Srinadh Bhojanapalli,Andrew McCallum,Felix Yu*

Main category: cs.IR

TL;DR: 提出SToICaL损失函数，在点式生成排序中结合项目级和令牌级排序监督，提升LLM排序性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM排序方法大多依赖下一个令牌预测，这种损失函数本质上是与排序无关的（特别是在点式监督下）。需要一种能结合排序感知监督的方法来提升LLM在信息检索任务中的表现。

Method: 提出SToICaL（Simple Token-Item Calibrated Loss）损失函数，在点式生成排序框架中同时融入项目级和令牌级的排序监督。首先证明多令牌文档ID的点式生成排序表达能力优于双编码器，然后设计新的损失函数来抑制无效文档ID生成并改进排序指标。

Result: 在WordNet和ESCI数据集上的实验表明，SToICaL的两个变体成功抑制了无效文档ID生成，并在除top-1检索之外的常见排序指标上取得了改进。

Conclusion: SToICaL损失函数有效解决了LLM排序中点式监督的局限性，通过结合项目级和令牌级排序监督，提升了生成排序模型的性能，特别是在多令牌文档ID场景下。

Abstract: Dual and cross encoders have long been mainstays of information retrieval (IR), but are being challenged by the emergent capabilities of LLMs. An LLM-based approach we term pointwise generative ranking - generating tokens the length of a single docID as opposed to a list in order to enable ranking via beam search - combines efficiency and expressivity benefits while leveraging the in-context capabilities of Causal Transformers. Although there is ample evidence to suggest that pretrained LLMs are well-suited for ranking, we find that the vast majority of LLM-based approaches rely on next-token prediction, a loss function which is fundamentally rank-agnostic (and especially so with pointwise supervision). In this paper, we first prove that the expressivity of pointwise generative ranking with multi-token docIDs is superior to that of dual encoders. We then propose SToICaL - a Simple Token-Item Calibrated Loss - which can incorporate rank-aware supervision at both the item and token levels within the pointwise setup. We run a suite of experiments on ranking tasks derived from WordNet (Fellbaum, 1998) and ESCI (Reddy et al., arXiv:2206.06588). Two variants of SToICaL successfully suppress the probability of invalid docID generations and improve on common ranking metrics beyond top-1 retrieval.

</details>


### [47] [Revisiting Human-vs-LLM judgments using the TREC Podcast Track](https://arxiv.org/abs/2601.05603)
*Watheq Mansour,J. Shane Culpepper,Joel Mackenzie,Andrew Yates*

Main category: cs.IR

TL;DR: LLM标注相关性在信息检索中日益重要，但现有研究主要关注文本搜索。本研究分析LLM与人类专家在播客音频转录片段上的标注一致性，发现高分歧案例中专家更倾向于同意LLM而非TREC标注者，验证了单一标注者导致低一致性的观点。


<details>
  <summary>Details</summary>
Motivation: 现有关于LLM标注相关性的研究主要集中于传统文本搜索场景，且结论存在矛盾（一些研究显示LLM与人类标注高度一致，另一些则相反）。本研究旨在探索LLM在播客音频转录片段这种非传统场景下的标注表现，分析LLM与人类专家的一致性，并考察分歧对系统排名的影响。

Method: 使用TREC 2020和2021播客赛道的数据集，包含音频文件转录的2分钟片段。采用5种不同的LLM模型重新评估所有查询-片段对（这些对原本由TREC标注者标注）。特别地，对LLM与TREC标注者分歧最高的子集进行重新评估，由人类专家进行判断。

Result: 在LLM与TREC标注者分歧最高的案例中，人类专家更倾向于同意LLM的标注，而非TREC标注者的原始标注。这一结果强化了Sormunen（2002）的见解：依赖单一标注者会导致较低的用户一致性。

Conclusion: LLM在播客音频转录片段的标注任务中表现出与人类专家良好的一致性，特别是在高分歧案例中专家更信任LLM。研究证实了多标注者评估的重要性，并支持LLM作为有效标注工具的潜力，尤其是在非传统文本搜索场景中。

Abstract: Using large language models (LLMs) to annotate relevance is an increasingly important technique in the information retrieval community. While some studies demonstrate that LLMs can achieve high user agreement with ground truth (human) judgments, other studies have argued for the opposite conclusion. To the best of our knowledge, these studies have primarily focused on classic ad-hoc text search scenarios. In this paper, we conduct an analysis on user agreement between LLM and human experts, and explore the impact disagreement has on system rankings. In contrast to prior studies, we focus on a collection composed of audio files that are transcribed into two-minute segments -- the TREC 2020 and 2021 podcast track. We employ five different LLM models to re-assess all of the query-segment pairs, which were originally annotated by TREC assessors. Furthermore, we re-assess a small subset of pairs where LLM and TREC assessors have the highest disagreement, and found that the human experts tend to agree with LLMs more than with the TREC assessors. Our results reinforce the previous insights of Sormunen in 2002 -- that relying on a single assessor leads to lower user agreement.

</details>


### [48] [Statistical Foundations of DIME: Risk Estimation for Practical Index Selection](https://arxiv.org/abs/2601.05649)
*Giulio D'Erasmo,Cesare Campagnano,Antonio Mallia,Pierpaolo Brutti,Nicola Tonellotto,Fabrizio Silvestri*

Main category: cs.IR

TL;DR: 提出一种统计准则，在推理时直接为每个查询识别最优维度集合，无需预先网格搜索，平均减少约50%嵌入大小


<details>
  <summary>Details</summary>
Motivation: 高维密集嵌入存在噪声和冗余维度，现有DIME方法需要昂贵的网格搜索预先选择所有查询的维度，缺乏查询自适应的维度选择

Method: 提出基于统计准则的方法，在推理时直接为每个查询识别最优维度集合，无需预先网格搜索选择固定维度

Result: 在不同模型和数据集上实现检索效果相当，推理时平均减少约50%嵌入大小

Conclusion: 提出的统计准则方法能有效识别查询相关的重要维度，显著减少嵌入大小同时保持检索效果

Abstract: High-dimensional dense embeddings have become central to modern Information Retrieval, but many dimensions are noisy or redundant. Recently proposed DIME (Dimension IMportance Estimation), provides query-dependent scores to identify informative components of embeddings. DIME relies on a costly grid search to select a priori a dimensionality for all the query corpus's embeddings. Our work provides a statistically grounded criterion that directly identifies the optimal set of dimensions for each query at inference time. Experiments confirm achieving parity of effectiveness and reduces embedding size by an average of $\sim50\%$ across different models and datasets at inference time.

</details>
