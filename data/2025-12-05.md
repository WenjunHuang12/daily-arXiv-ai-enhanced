<div id=toc></div>

# Table of Contents

- [cs.GT](#cs.GT) [Total: 2]
- [cs.DS](#cs.DS) [Total: 3]
- [cs.DB](#cs.DB) [Total: 3]
- [cs.IT](#cs.IT) [Total: 10]
- [cs.IR](#cs.IR) [Total: 4]
- [cs.MM](#cs.MM) [Total: 1]


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [1] [Omniscient Attacker in Stochastic Security Games with Interdependent Nodes](https://arxiv.org/abs/2512.04561)
*Yuksel Arslantas,Ahmed Said Donmez,Ege Yuceel,Muhammed O. Sayin*

Main category: cs.GT

TL;DR: 论文研究RL防御者在关键基础设施中的脆弱性，提出利用神经动态规划对抗全知攻击者的方法


<details>
  <summary>Details</summary>
Motivation: 强化学习在关键基础设施防御中的应用存在脆弱性，攻击者可以利用防御算法的学习动态进行战略攻击。现有研究主要关注重复正规形式博弈，但扩展到随机博弈仍是一个开放的研究空白。

Method: 使用可处理的线性影响网络模型研究RL防御者与全知攻击者之间的随机安全博弈。为克服先前方法的结构限制，提出并应用神经动态规划方法。

Result: 实验结果表明，全知攻击者能够显著优于天真的防御者，突显了学习动态引入的关键脆弱性以及所提出策略的有效性。

Conclusion: 该研究填补了随机安全博弈中RL防御脆弱性的研究空白，证明了神经动态规划在对抗全知攻击者方面的有效性，强调了在关键基础设施防御中考虑学习动态安全性的重要性。

Abstract: The adoption of reinforcement learning for critical infrastructure defense introduces a vulnerability where sophisticated attackers can strategically exploit the defense algorithm's learning dynamics. While prior work addresses this vulnerability in the context of repeated normal-form games, its extension to the stochastic games remains an open research gap. We close this gap by examining stochastic security games between an RL defender and an omniscient attacker, utilizing a tractable linear influence network model. To overcome the structural limitations of prior methods, we propose and apply neuro-dynamic programming. Our experimental results demonstrate that the omniscient attacker can significantly outperform a naive defender, highlighting the critical vulnerability introduced by the learning dynamics and the effectiveness of the proposed strategy.

</details>


### [2] [Side-by-side first-price auctions with imperfect bidders](https://arxiv.org/abs/2512.04850)
*Benjamin Heymann*

Main category: cs.GT

TL;DR: 研究并行竞价采购场景，证明迭代最佳响应算法收敛到均衡，并提供唯一性条件


<details>
  <summary>Details</summary>
Motivation: 在展示广告等场景中，两个不完美的投标人代表单个买家同时行动（并行竞价），这种配置在理论上尚未充分探索

Method: 建立并行竞价采购模型，证明迭代最佳响应算法在标准分布假设下收敛到均衡，并提供均衡唯一性的充分条件

Result: 证明了均衡存在性和算法收敛性，为并行竞价采购的定量研究提供了可处理的数值方法

Conclusion: 该研究填补了并行竞价理论空白，为实际应用提供了理论支持和计算工具

Abstract: We model a procurement scenario in which two \textit{imperfect} bidders act simultaneously on behalf of a single buyer, a configuration common in display advertising and referred to as \textit{side-by-side bidding} but largely unexplored in theory. We prove that the iterated best response algorithm converges to an equilibrium under standard distributional assumptions and provide sufficient condition for uniqueness. Beyond establishing existence and convergence, our analysis provides a tractable numerical method for quantitative studies of side-by-side procurement.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [3] [Improved Time-Space Tradeoffs for 3SUM-Indexing](https://arxiv.org/abs/2512.04258)
*Itai Dinur,Alexander Golovnev*

Main category: cs.DS

TL;DR: 本文改进了3SUM-Indexing问题的时间-空间权衡，从TS³=n⁶提升到TS=n².⁵，并在n³/²≪S≪n⁷/⁴范围内优于已知最佳结果


<details>
  <summary>Details</summary>
Motivation: 3SUM-Indexing是3SUM问题的预处理变体，现有最佳时间-空间权衡TS³=n⁶基于Fiat-Naor通用函数求逆算法。作者希望利用3SUM-Indexing的特殊结构来改进这一结果

Method: 通过将待求逆函数分解为具有特定性质的"子函数"，以替代方式应用Fiat-Naor算法。这利用了[GGPS23]中获得的改进，该改进原本不能直接应用于3SUM-Indexing

Result: 获得了TS=n².⁵的时间-空间权衡，在n³/²≪S≪n⁷/⁴范围内优于已知最佳结果。该改进还扩展到kSUM-Indexing、kXOR-Indexing问题，并改进了Gapped String Indexing和Jumbled Indexing问题的最佳时间-空间权衡

Conclusion: 通过利用3SUM-Indexing的结构特性，本文显著改进了该问题的时间-空间权衡。所提出的技术可能对Fiat-Naor算法的其他应用相关优化也有帮助

Abstract: 3SUM-Indexing is a preprocessing variant of the 3SUM problem that has recently received a lot of attention. The best known time-space tradeoff for the problem is $T S^3 = n^{6}$ (up to logarithmic factors), where $n$ is the number of input integers, $S$ is the length of the preprocessed data structure, and $T$ is the running time of the query algorithm. This tradeoff was achieved in [KP19, GGHPV20] using the Fiat-Naor generic algorithm for Function Inversion. Consequently, [GGHPV20] asked whether this algorithm can be improved by leveraging the structure of 3SUM-Indexing.
  In this paper, we exploit the structure of 3SUM-Indexing to give a time-space tradeoff of $T S = n^{2.5}$, which is better than the best known one in the range $n^{3/2} \ll S \ll n^{7/4}$. We further extend this improvement to the $k$SUM-Indexing problem-a generalization of 3SUM-Indexing-and to the related $k$XOR-Indexing problem, where addition is replaced with XOR. Additionally, we improve the best known time-space tradeoffs for the Gapped String Indexing and Jumbled Indexing problems, which are well-known data structure problems related to 3SUM-Indexing.
  Our improvement comes from an alternative way to apply the Fiat-Naor algorithm to 3SUM-Indexing. Specifically, we exploit the structure of the function to be inverted by decomposing it into "sub-functions" with certain properties. This allows us to apply an improvement to the Fiat-Naor algorithm (which is not directly applicable to 3SUM-Indexing), obtained in [GGPS23] in a much larger range of parameters. We believe that our techniques may be useful in additional application-dependent optimizations of the Fiat-Naor algorithm.

</details>


### [4] [A customizable inexact subgraph matching algorithm for attributed graphs](https://arxiv.org/abs/2512.04280)
*Tatyana Benko,Rebecca Jones,Lucas Tate*

Main category: cs.DS

TL;DR: 提出一种新的可定制化非精确子图匹配算法，利用节点和边属性缩小搜索空间，通过可修改的图编辑距离成本函数实现灵活匹配


<details>
  <summary>Details</summary>
Motivation: 现实世界数据常包含噪声和错误，精确子图匹配算法不适用，需要能够处理噪声的非精确匹配方法

Method: 利用节点和边属性缩小搜索空间，采用可修改的图编辑距离成本函数进行节点配对，实现灵活的非精确子图匹配

Result: 在家族树图和程序控制流图上展示了算法的有效性

Conclusion: 提出的可定制化非精确子图匹配算法能够有效处理现实世界中的噪声数据，具有灵活性和实用性

Abstract: Graphs provide a natural way to represent data by encoding information about objects and the relationships between them. With the ever-increasing amount of data collected and generated, locating specific patterns of relationships between objects in a graph is often required. Given a larger graph and a smaller graph, one may wish to identify instances of the smaller query graph in the larger target graph. This task is called subgraph identification or matching. Subgraph matching is helpful in areas such as bioinformatics, binary analysis, pattern recognition, and computer vision. In these applications, datasets frequently contain noise and errors, thus exact subgraph matching algorithms do not apply. In this paper we introduce a new customizable algorithm for inexact subgraph matching. Our algorithm utilizes node and edge attributes which are often present in real-world datasets to narrow down the search space. The algorithm is flexible in the type of subgraph matching it can perform and the types of datasets it can process by its use of a modifiable graph edit distance cost function for pairing nodes. We show its effectiveness on family trees graphs and control-flow graphs.

</details>


### [5] [On Tight FPT Time Approximation Algorithms for k-Clustering Problems](https://arxiv.org/abs/2512.04614)
*Han Dai,Shi Li,Sijin Peng*

Main category: cs.DS

TL;DR: 本文研究了最小范数k聚类问题的FPT时间近似算法，针对容量限制和无容量限制两种情况提出了紧致的近似比，并建立了一个统一的算法框架。


<details>
  <summary>Details</summary>
Motivation: 结合近似算法与固定参数可解性(FPT)的最新进展，研究最小范数k聚类问题的FPT时间近似算法，参数化为开放设施数量k。现有研究主要集中在多项式时间近似算法，FPT时间下的结果较少。

Method: 建立统一框架：通过LP舍入计算使用O(k log n/ε)个设施的(1+ε)近似解，基于解S采样少量客户代表R，从S∪R中猜测少量枢轴及其半径信息，然后利用猜测解决问题。

Result: 容量限制：得到紧致的(3+ε)近似算法；无容量限制：对top-cn范数k聚类问题，当c∈(1/e,1]时得到紧致的(1+2/(ec)+ε)近似比；还改进了(k-center,k-median)问题的双准则近似比。

Conclusion: 本文为最小范数k聚类问题提供了FPT时间下的紧致近似算法，建立了一个可扩展的统一框架，有望应用于更多k聚类问题的研究。

Abstract: Following recent advances in combining approximation algorithms with fixed-parameter tractability (FPT), we study FPT-time approximation algorithms for minimum-norm $k$-clustering problems, parameterized by the number $k$ of open facilities.
  For the capacitated setting, we give a tight $(3+ε)$-approximation for the general-norm capacitated $k$-clustering problem in FPT-time parameterized by $k$ and $ε$. Prior to our work, such a result was only known for the capacitated $k$-median problem [CL, ICALP, 2019]. As a special case, our result yields an FPT-time $3$-approximation for capacitated $k$-center. The problem has not been studied in the FPT-time setting, with the previous best known polynomial-time approximation ratio being 9 [ABCG, MP, 2015].
  In the uncapacitated setting, we consider the $top$-$cn$ norm $k$-clustering problem, where the goal of the problem is to minimize the $top$-$cn$ norm of the connection distance vector. Our main result is a tight $\big(1 + \frac 2{ec} + ε\big)$-approximation algorithm for the problem with $c \in \big(\frac1e, 1\big]$. (For the case $c \leq \frac1e$, there is a simple tight $(3+ε)$-approximation.) Our framework can be easily extended to give a tight $\left(3, 1+\frac2e + ε\right)$-bicriteria approximation for the ($k$-center, $k$-median) problem in FPT time, improving the previous best polynomial-time $(4, 8)$ guarantee [AB, WAOA, 2017].
  All results are based on a unified framework: computing a $(1+ε)$-approximate solution using $O\left(\frac{k\log n}ε\right)$ facilities $S$ via LP rounding, sampling a few client representatives $R$ based on the solution $S$, guessing a few pivots from $S \cup R$ and some radius information on the pivots, and solving the problem using the guesses. We believe this framework can lead to further results on $k$-clustering problems.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [6] [Energy Profiling of Data-Sharing Pipelines: Modeling, Estimation, and Reuse Strategies](https://arxiv.org/abs/2512.04086)
*Sepideh Masoudi,Sebastian Werner,Pierluigi Plebani,Stefan Tai*

Main category: cs.DB

TL;DR: 提出一种建模和估算数据共享管道能耗的新方法，识别跨管道共享阶段的复用潜力以降低能耗


<details>
  <summary>Details</summary>
Motivation: 数据共享管道涉及多个阶段的数据转换，现有工具主要关注治理和执行，但能源效率研究有限。随着数据共享联盟规模扩大，能耗优化变得重要。

Method: 开发了一种建模和估算数据共享管道不同执行配置能耗的方法，识别跨管道共享阶段的复用潜力，通过模拟实验验证。

Result: 模拟实验验证了方法的有效性，揭示了跨组织管道优化的潜力，为能源感知执行策略奠定了基础。

Conclusion: 该方法为大规模数据共享联盟的能源效率优化提供了新途径，通过识别共享阶段复用潜力实现能耗降低。

Abstract: Data-sharing pipelines involve a series of stages that apply policy-based data transformations to enable secure and effective data exchange among organizations. Although numerous tools and platforms exist to manage governance and enforcement in these pipelines, energy efficiency in data exchange has received limited attention. This paper introduces a novel method to model and estimate the energy consumption of different execution configurations in data-sharing pipelines. Additionally, this method identifies reuse potential in shared stages across pipelines that hold the key to reducing energy in large data-sharing federations. We validate this method through simulation experiments, revealing promising potential for cross-organizational pipeline optimization and laying a foundation for energy-conscious execution strategies.

</details>


### [7] [A Fast Ethereum-Compatible Forkless Database](https://arxiv.org/abs/2512.04735)
*Herbert Jordan,Kamil Jezek,Pavle Subotic,Bernhard Scholz*

Main category: cs.DB

TL;DR: 提出专为非分叉区块链设计的新型原生状态数据库，保持以太坊兼容性，性能提升10倍，存储减少99%


<details>
  <summary>Details</summary>
Motivation: 现代区块链采用快速共识协议避免分叉，但以太坊StateDB为分叉链设计，维护多个状态版本。新链为兼容DApp采用以太坊标准，但不需要多版本状态，导致现有数据库效率低下。现有实现基于键值存储（如LevelDB）效率不高。

Method: 设计原生数据库实现，专门针对非分叉区块链优化，同时保持以太坊兼容性。采用新的存储架构，避免维护多个状态版本的开销。

Result: 验证器性能提升10倍，存储空间减少99%；归档节点存储需求降低3倍。在保持以太坊兼容性的同时显著提升效率。

Conclusion: 针对非分叉区块链设计的原生状态数据库能显著提升性能和存储效率，同时保持与以太坊生态的兼容性，为现代区块链提供更优的数据库解决方案。

Abstract: The State Database of a blockchain stores account data and enables authentication. Modern blockchains use fast consensus protocols to avoid forking, improving throughput and finality. However, Ethereum's StateDB was designed for a forking chain that maintains multiple state versions. While newer blockchains adopt Ethereum's standard for DApp compatibility, they do not require multiple state versions, making legacy Ethereum databases inefficient for fast, non-forking blockchains. Moreover, existing StateDB implementations have been built on key-value stores (e.g., LevelDB), which make them less efficient.
  This paper introduces a novel state database that is a native database implementation and maintains Ethereum compatibility while being specialized for non-forking blockchains. Our database delivers ten times speedups and 99% space reductions for validators, and a threefold decrease in storage requirements for archive nodes.

</details>


### [8] [High-Performance DBMSs with io_uring: When and How to use it](https://arxiv.org/abs/2512.04859)
*Matthias Jasny,Muhammad El-Hindi,Tobias Ziegler,Viktor Leis,Carsten Binnig*

Main category: cs.DB

TL;DR: 论文研究现代数据库系统如何利用Linux io_uring接口实现高效、低开销的I/O操作，通过两个用例评估其性能优势，并推导出实用设计指南。


<details>
  <summary>Details</summary>
Motivation: io_uring是Linux的异步系统调用批处理接口，能统一存储和网络操作，但简单地替换传统I/O接口不一定带来性能提升。需要研究何时以及如何有效使用io_uring来提升数据库系统性能。

Method: 通过两个用例评估io_uring：1) 在存储受限的缓冲区管理器中集成io_uring；2) 在网络受限的分析工作负载中使用io_uring进行高吞吐量数据洗牌。进一步分析高级功能如注册缓冲区和直通I/O对端到端性能的影响。

Result: 研究表明低层优化何时能转化为实际的系统级性能提升，以及架构选择如何影响这些收益。基于这些洞察，推导出使用io_uring设计I/O密集型系统的实用指南。

Conclusion: 在PostgreSQL最近的io_uring集成案例研究中，应用这些指南实现了14%的性能提升，验证了指南的有效性。研究为数据库系统有效利用io_uring提供了实践指导。

Abstract: We study how modern database systems can leverage the Linux io_uring interface for efficient, low-overhead I/O. io_uring is an asynchronous system call batching interface that unifies storage and network operations, addressing limitations of existing Linux I/O interfaces. However, naively replacing traditional I/O interfaces with io_uring does not necessarily yield performance benefits. To demonstrate when io_uring delivers the greatest benefits and how to use it effectively in modern database systems, we evaluate it in two use cases: Integrating io_uring into a storage-bound buffer manager and using it for high-throughput data shuffling in network-bound analytical workloads. We further analyze how advanced io_uring features, such as registered buffers and passthrough I/O, affect end-to-end performance. Our study shows when low-level optimizations translate into tangible system-wide gains and how architectural choices influence these benefits. Building on these insights, we derive practical guidelines for designing I/O-intensive systems using io_uring and validate their effectiveness in a case study of PostgreSQL's recent io_uring integration, where applying our guidelines yields a performance improvement of 14%.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [9] [Constructing Low-Redundancy Codes via Distributed Graph Coloring](https://arxiv.org/abs/2512.04197)
*Yuting Li,Ryan Gabrys,Farzad Farnoud*

Main category: cs.IT

TL;DR: 提出基于分布式图着色的纠错码通用框架，利用混淆图的独立集与有效编码的对应关系，通过改进的Linial着色算法实现多项式时间编码解码，获得多种纠错码构造和同步方案。


<details>
  <summary>Details</summary>
Motivation: 传统纠错码构造方法如综合征压缩存在局限性：依赖好的基码、灵活性不足、参数范围受限。需要更通用、灵活且不依赖特定基码的纠错码构造框架。

Method: 基于分布式计算LOCAL模型，利用混淆图中独立集与有效编码的对应关系，改进Linial着色算法实现多项式时间的全局一致着色，从而构建编码方案。扩展至超图标记实现列表可解码码。

Result: 1) 常数错误数的唯一可解码码，冗余度为Gilbert-Varshamov界的2倍；2) 通过超图标记实现列表可解码码；3) 编辑距离未知时的增量同步方案；4) 无界长度编辑突发纠正的渐近最优码（因子8内）。

Conclusion: 该框架比综合征压缩更灵活通用，不依赖好的基码，在多种参数下实现改进的冗余度，为纠错码构造提供了新的分布式计算方法。

Abstract: We present a general framework for constructing error-correcting codes using distributed graph coloring under the LOCAL model. Building on the correspondence between independent sets in the confusion graph and valid codes, we show that the color of a single vertex - consistent with a global proper coloring - can be computed in polynomial time using a modified version of Linial's coloring algorithm, leading to efficient encoding and decoding. Our results include: i) uniquely decodable code constructions for a constant number of errors of any type with redundancy twice the Gilbert-Varshamov bound; ii) list-decodable codes via a proposed extension of graph coloring, namely, hypergraph labeling; iii) an incremental synchronization scheme with reduced average-case communication when the edit distance is not precisely known; and iv) the first asymptotically optimal codes (up to a factor of 8) for correcting bursts of unbounded-length edits. Compared to syndrome compression, our approach is more flexible and generalizable, does not rely on a good base code, and achieves improved redundancy across a range of parameters.

</details>


### [10] [Joint Low-Rank and Sparse Bayesian Channel Estimation for Ultra-Massive MIMO Communications](https://arxiv.org/abs/2512.04470)
*Jianghan Ji,Cheng-Xiang Wang,Shuaifei Chen,Chen Huang,Xiping Wu,Emil Björnson*

Main category: cs.IT

TL;DR: 提出一种联合低秩稀疏贝叶斯估计算法（LRSBE），用于超大规模MIMO通信中的空间非平稳信道估计，通过利用波束域中的低秩性和稀疏性来提升估计精度并降低复杂度。


<details>
  <summary>Details</summary>
Motivation: 超大规模MIMO通信中的信道估计面临空间非平稳性挑战，传统方法难以有效利用信道在波束域中的低秩和稀疏特性，需要开发更高效准确的估计算法。

Method: 提出联合低秩稀疏贝叶斯估计算法（LRSBE），在期望最大化框架内集成稀疏贝叶斯学习和软阈值梯度下降，充分利用信道在波束域的低秩性和稀疏性。

Result: 仿真结果表明，在不同信噪比条件下，所提算法在估计精度和总体复杂度方面显著优于现有最先进方法。

Conclusion: LRSBE算法通过联合利用信道低秩性和稀疏性，为超大规模MIMO空间非平稳信道提供了一种高效准确的估计方案，在性能和复杂度方面均优于现有方法。

Abstract: This letter investigates channel estimation for ultra-massive multiple-input multiple-output (MIMO) communications. We propose a joint low-rank and sparse Bayesian estimation (LRSBE) algorithm for spatial non-stationary ultra-massive channels by exploiting the low-rankness and sparsity in the beam domain. Specifically, the channel estimation integrates sparse Bayesian learning and soft-threshold gradient descent within the expectation-maximization framework. Simulation results show that the proposed algorithm significantly outperforms the state-of-the-art alternatives under different signal-to-noise ratio conditions in terms of estimation accuracy and overall complexity.

</details>


### [11] [One-Step Generative Channel Estimation via Average Velocity Field](https://arxiv.org/abs/2512.04501)
*Zehua Jiang,Fenghao Zhu,Siming Jiang,Chongwen Huang,Zhaohui Yang,Richeng Jin,Zhaoyang Zhang,Merouane Debbah*

Main category: cs.IT

TL;DR: 提出一种用于无线通信信道估计的一步生成方法，通过直接学习平均速度场来绕过传统扩散模型的迭代去噪过程，显著降低延迟并提升性能。


<details>
  <summary>Details</summary>
Motivation: 生成模型在无线通信中通过学习复杂信道数据分布展现出巨大潜力，但其迭代去噪过程在延迟敏感的信道估计场景中带来显著挑战，需要解决延迟问题。

Method: 提出一种新颖的一步生成信道估计解决方案，通过直接学习平均速度场来绕过传统模型的耗时迭代步骤，实现快速信道估计。

Result: 通过大量仿真验证，该方法相比现有最先进的基于扩散的方法，归一化均方误差降低达2.65 dB，延迟减少约90%，显著提升信道估计性能。

Conclusion: 该方法通过一步生成的方式有效解决了生成模型在无线信道估计中的延迟问题，展示了在增强信道估计性能方面的潜力。

Abstract: Generative models have shown immense potential for wireless communication by learning complex channel data distributions. However, the iterative denoising process associated with these models imposes a significant challenge in latency-sensitive wireless communication scenarios, particularly in channel estimation. To address this challenge, we propose a novel solution for one-step generative channel estimation. Our approach bypasses the time-consuming iterative steps of conventional models by directly learning the average velocity field. Through extensive simulations, we validate the effectiveness of our proposed method over existing state-of-the-art diffusion-based approach. Specifically, our scheme achieves a normalized mean squared error up to 2.65 dB lower than the diffusion method and reduces latency by around 90%, demonstrating the potential of our method to enhance channel estimation performance.

</details>


### [12] [Timely Information for Strategic Persuasion](https://arxiv.org/abs/2512.04679)
*Ahmet Bugra Gundogan,Melih Bastopcu*

Main category: cs.IT

TL;DR: 研究动态贝叶斯说服问题，发送者通过控制信息揭示时机在资源约束下影响接收者信念，采用Stackelberg博弈框架，最优策略是给不期望状态分配最小采样率，剩余资源分配给期望状态。


<details>
  <summary>Details</summary>
Motivation: 研究动态环境下的信息说服问题，发送者希望影响接收者对二进制信息源状态的估计，但双方目标不一致（发送者希望接收者估计为1，接收者希望准确估计），需要在资源约束下设计最优信息揭示策略。

Method: 采用Stackelberg博弈框架，发送者为领导者选择信息揭示策略，接收者为跟随者决定是否跟随消息。考虑连续时间马尔可夫链演化的二进制信息源，发送者目标是在满足总采样约束和激励相容约束下最大化接收者估计为1的长期平均时间。

Result: 单源问题中，发送者最优策略是给不期望状态0分配最小采样率（刚好满足激励相容约束），剩余采样率分配给期望状态1。多源扩展中，每个源有不同的最小采样率，发送者可以利用信息及时性影响接收者获得更高效用。

Conclusion: 动态贝叶斯说服中，发送者可以通过控制信息揭示时机在资源约束下有效影响接收者信念，最优策略涉及资源在不同状态间的战略分配，信息及时性成为影响效用的重要因素。

Abstract: This work investigates a dynamic variant of Bayesian persuasion, in which a strategic sender seeks to influence a receiver's belief over time through controlling the timing of the information disclosure, under resource constraints. We consider a binary information source (i.e., taking values 0 or 1), where the source's state evolve according to a continuous-time Markov chain (CTMC). In this setting, the receiver aims to estimate the source's state as accurately as possible. In contrast, the sender seeks to persuade the receiver to estimate the state to be 1, regardless of whether this estimate reflects the true state. This misalignment between their objectives naturally leads to a Stackelberg game formulation where the sender, acting as the leader, chooses an information-revelation policy, and the receiver, as the follower, decides whether to follow the sender's messages. As a result, the sender's objective is to maximize the long-term average time that the receiver's estimate equals 1, subject to a total sampling constraint and a constraint for the receiver to follow the sender's messages called incentive compatibility (IC) constraint. We first consider the single-source problem and show that the sender's optimal policy is to allocate a minimal sampling rate to the undesired state 0 (just enough to satisfy the IC constraint) and assign the remaining sampling rate to the desired state 1. Next, we extend the analysis to the multi-source case, where each source has a different minimal sampling rate. Our results show that the sender can leverage the timeliness of the revealed information to influence the receiver, thereby achieving a higher utility.

</details>


### [13] [Rotatable Antenna-Enhanced Cell-Free Communication](https://arxiv.org/abs/2512.04742)
*Kecheng Pan,Beixiong Zheng,Yanhua Tan,Emil Björnson,Robert Schober,Rui Zhang*

Main category: cs.IT

TL;DR: 提出一种可旋转天线增强的无蜂窝系统，通过联合优化AP-用户关联和天线波束方向来最大化下行链路总速率。


<details>
  <summary>Details</summary>
Motivation: 可旋转天线技术能够通过灵活调整天线的三维波束方向来开发新的空间自由度，这为提升无线通信系统性能提供了新的可能性。

Method: 采用两阶段策略：首先解决AP-用户关联问题，然后使用分数规划和连续凸逼近技术优化可旋转天线的波束方向。

Result: 数值结果表明，所提出的可旋转天线增强的无蜂窝系统在各种基准方案中表现出显著优越的性能。

Conclusion: 可旋转天线技术能够有效提升无蜂窝系统的性能，通过联合优化天线波束方向和AP-用户关联可以显著提高系统总速率。

Abstract: Rotatable antenna (RA) is a promising technology that can exploit new spatial degrees-of-freedom (DoFs) by flexibly adjusting the three-dimensional (3D) boresight direction of antennas. In this letter, we investigate an RA-enhanced cell-free system for downlink transmission, where multiple RA-equipped access points (APs) cooperatively serve multiple single-antenna users over the same time-frequency resource. Specifically, we aim to maximize the sum rate of all users by jointly optimizing the AP-user associations and the RA boresight directions. Accordingly, we propose a two-stage strategy to solve the AP-user association problem, and then employ fractional programming (FP) and successive convex approximation (SCA) techniques to optimize the RA boresight directions. Numerical results demonstrate that the proposed RA-enhanced cell-free system significantly outperforms various benchmark schemes.

</details>


### [14] [Robust Precoding Designs of RSMA for Multiuser MIMO Systems](https://arxiv.org/abs/2512.04750)
*Wentao Zhou,Yijie Mao,Di Zhang,Mérouane Debbah,Inkyu Lee*

Main category: cs.IT

TL;DR: 提出一种低复杂度的鲁棒预编码设计用于RSMA多用户MIMO系统，在信道状态信息不完美情况下实现接近传统方法的性能但显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有的RSMA多用户MIMO系统预编码设计在最大化和速率时通常具有很高的计算复杂度，特别是在不完美信道状态信息情况下。需要一种高效且鲁棒的实现方案。

Method: 首先采用广义互信息构建和速率最大化问题中目标函数的下界，然后应用非光滑和速率目标函数的平滑下界构建新优化问题。通过揭示广义信干噪比与最小均方误差矩阵之间的关系，将问题转化为可处理形式，并分解为三个子问题进行交替预编码设计。

Result: 仿真结果表明，所提出的预编码方案在性能上与常规方法相当，同时显著降低了计算复杂度。

Conclusion: 该研究为RSMA多用户MIMO系统提供了一种高效且鲁棒的预编码设计方案，在不完美信道状态信息下实现了性能与复杂度的良好平衡。

Abstract: Rate-splitting multiple access (RSMA) has been studied for multiuser multiple-input multiple-output (MUMIMO) systems especially in the presence of imperfect channel state information (CSI) at the transmitter. However, its precoding designs that maximize the sum rate normally have high computational complexity. To implement an efficient RSMA scheme for the MU-MIMO system, in this work, we propose a novel robust precoding design, which can handle imperfect CSI. Specifically, we first adopt the generalized mutual information to construct a lower bound of the objective function in the sum rate maximization problem. Then, we apply a smooth lower bound of the non-smooth sum rate objective function to construct a new optimization problem. By revealing the relationship between the generalized signal-to-interference-plus-noise ratio and the minimum mean square error matrices, we transform the constructed problem into a tractable one. After decomposing the transformed problem into three subproblems, we investigate a new alternating precoding design based on sequential solutions. Simulation results demonstrate that the proposed precoding scheme achieves comparable performance to conventional methods, while significantly reducing the computational complexity.

</details>


### [15] [Exact 3-D Channel Impulse Response for Spherical Receivers with Arbitrary Drift Directions](https://arxiv.org/abs/2512.04858)
*Yen-Chi Lee,Ping-Cheng Yeh,Chia-Han Lee*

Main category: cs.IT

TL;DR: 本文首次推导出任意方向均匀漂移下球形吸收接收器的精确解析信道冲激响应，解决了分子MIMO系统中三维信道建模的关键难题。


<details>
  <summary>Details</summary>
Motivation: 现有分子通信系统的信道建模存在局限性：精确解仅限于一维/无漂移场景或平面接收器几何结构，无法处理任意流动方向下的球形接收器信道冲激响应计算问题。

Method: 采用Girsanov定理，将平稳介质中的命中时间分布解析地转换到漂移介质中，从而推导出任意方向均匀漂移下球形接收器的闭合形式信道冲激响应表达式。

Result: 获得了首个三维分子通信系统中球形接收器在任意方向均匀漂移下的精确解析CIR，消除了先前近似方法对接收器离轴角度的忽略误差，并能高效探索关键系统参数。

Conclusion: 提出的闭合形式表达式不仅提高了分子MIMO系统信道建模的准确性，还为系统参数优化提供了高效分析工具，相比纯仿真方法显著降低了计算成本。

Abstract: Accurate channel modeling for spherical absorbing receivers is fundamental to the design of realistic molecular multiple-input multiple-output (MIMO) systems. While advanced modulation schemes have been proposed to mitigate interference, determining the channel impulse response (CIR) under arbitrary flow directions remains a challenge; existing exact solutions are restricted to either 1-D/no-drift scenarios or planar receiver geometries. Addressing this gap, we derive the first exact analytical CIR for a spherical receiver in a 3-D molecular communication system with uniform drift in an arbitrary direction. Unlike prior approximations that ignore the angle between the drift and the transmission axis, our approach utilizes the Girsanov theorem to analytically transform the hitting-time distribution from a stationary medium to a drifted one. The proposed closed-form expression not only eliminates modeling errors inherent in previous approximations for off-axis receivers but also enables efficient parameter-space exploration of critical system metrics (e.g., peak time and amplitude), a task that would be computationally costly with pure simulation-based approaches.

</details>


### [16] [Bounds on Maximal Leakage over Bayesian Networks](https://arxiv.org/abs/2512.04955)
*Anuran Makur,Japneet Singh*

Main category: cs.IT

TL;DR: 本文研究贝叶斯网络中最大泄漏的行为，针对有限字母表建立了新的边界，并提供了耦合表征的推广条件。


<details>
  <summary>Details</summary>
Motivation: 虽然最大泄漏的基本性质（如数据处理、次可加性及其与互信息的联系）已确立，但其在贝叶斯网络中的行为尚不清楚，现有边界主要限于二元字母表。

Method: 利用满足特定条件的信道存在的耦合表征来建立最大泄漏边界，并为|X|=4的情况提供更一般的耦合表征条件，同时提出新的最大泄漏指数同时耦合结果。

Result: 建立了有限字母表贝叶斯网络中最大泄漏的边界，推广了耦合表征的条件，并通过示例展示了所提边界的有效性。

Conclusion: 本文填补了最大泄漏在贝叶斯网络中行为研究的空白，为有限字母表情况提供了理论边界和耦合表征的推广，对信息泄漏分析有重要意义。

Abstract: Maximal leakage quantifies the leakage of information from data $X \in \mathcal{X}$ due to an observation $Y$. While fundamental properties of maximal leakage, such as data processing, sub-additivity, and its connection to mutual information, are well-established, its behavior over Bayesian networks is not well-understood and existing bounds are primarily limited to binary $\mathcal{X}$. In this paper, we investigate the behavior of maximal leakage over Bayesian networks with finite alphabets. Our bounds on maximal leakage are established by utilizing coupling-based characterizations which exist for channels satisfying certain conditions. Furthermore, we provide more general conditions under which such coupling characterizations hold for $|\mathcal{X}| = 4$. In the course of our analysis, we also present a new simultaneous coupling result on maximal leakage exponents. Finally, we illustrate the effectiveness of the proposed bounds with some examples.

</details>


### [17] [Environment-Aware Channel Inference via Cross-Modal Flow: From Multimodal Sensing to Wireless Channels](https://arxiv.org/abs/2512.04966)
*Guangming Liang,Mingjie Yang,Dongzhu Liu,Paul Henderson,Lajos Hanzo*

Main category: cs.IT

TL;DR: 提出一种基于多模态感知数据（图像、激光雷达、GPS）的无导频信道推断方法，通过跨模态流匹配学习从感知到信道的映射，显著提升大规模MIMO系统中的信道估计精度和频谱效率。


<details>
  <summary>Details</summary>
Motivation: 在大规模MIMO系统和高多普勒环境中，通过导频估计获取信道状态信息（CSI）会产生巨大开销。随着环境感知数据的可用性增加，研究者希望利用多模态观测数据直接推断完整CSI，避免传统导频估计的局限性。

Method: 开发数据驱动框架，将感知到信道的映射建模为跨模态流匹配问题。框架将多模态特征融合到信道域的潜在分布中，学习一个速度场，将潜在分布连续变换到信道分布。采用条件流匹配目标和模态对齐损失，结合低延迟推理机制实现实时CSI估计。

Result: 基于Sionna和Blender构建程序化数据生成器，支持真实感知场景和无线传播建模。系统级评估显示，该方法在信道估计精度和下游波束成形任务的频谱效率方面，显著优于基于导频和感知的基准方法。

Conclusion: 通过多模态感知数据实现无导频信道推断是可行的，跨模态流匹配框架能够有效学习感知到信道的复杂映射，为大规模MIMO系统提供高效、准确的CSI获取方案。

Abstract: Accurate channel state information (CSI) underpins reliable and efficient wireless communication. However, acquiring CSI via pilot estimation incurs substantial overhead, especially in massive multiple-input multiple-output (MIMO) systems operating in high-Doppler environments. By leveraging the growing availability of environmental sensing data, this treatise investigates pilot-free channel inference that estimates complete CSI directly from multimodal observations, including camera images, LiDAR point clouds, and GPS coordinates. In contrast to prior studies that rely on predefined channel models, we develop a data-driven framework that formulates the sensing-to-channel mapping as a cross-modal flow matching problem. The framework fuses multimodal features into a latent distribution within the channel domain, and learns a velocity field that continuously transforms the latent distribution toward the channel distribution. To make this formulation tractable and efficient, we reformulate the problem as an equivalent conditional flow matching objective and incorporate a modality alignment loss, while adopting low-latency inference mechanisms to enable real-time CSI estimation. In experiments, we build a procedural data generator based on Sionna and Blender to support realistic modeling of sensing scenes and wireless propagation. System-level evaluations demonstrate significant improvements over pilot- and sensing-based benchmarks in both channel estimation accuracy and spectral efficiency for the downstream beamforming task.

</details>


### [18] [Performance Analysis of Fluid Reconfigurable Intelligent Surface over Covert Communications](https://arxiv.org/abs/2512.05085)
*Farshad Rostami Ghadi,Masoud Kaveh,Hanjiang Hong,Kai-Kit Wong,Riku Jantti,F. Javier Lopez-Martinez*

Main category: cs.IT

TL;DR: FRIS在隐蔽通信中优于固定位置RIS，在低到中等功率下提升可靠性和隐蔽性，但在高功率下固定位置RIS可能因减少向对手的泄漏而略胜一筹。


<details>
  <summary>Details</summary>
Motivation: 研究流体可重构智能表面（FRIS）在隐蔽通信中的影响，探索如何利用FRIS提高合法通信的隐蔽性，同时对抗对手的检测企图。

Method: 分析虚假警报和漏检概率，推导隐蔽中断概率的闭式表达式，在最优检测阈值下表征成功概率，研究隐蔽性与可靠传输之间的权衡。

Result: 数值结果表明，在低到中等发射功率下，FRIS相比固定位置RIS具有明显优势，能同时提高可靠性和隐蔽性；但在极高功率水平下，固定位置RIS可能因减少向对手的泄漏而维持略高的成功概率。

Conclusion: FRIS为隐蔽通信提供了有前景的解决方案，特别是在实际功率范围内能同时优化隐蔽性和可靠性，但在极端高功率场景下需要权衡考虑。

Abstract: This paper investigates the impact of the recently proposed concept of fluid reconfigurable intelligent surfaces (FRIS) on covert communications. Specifically, we consider a communication scenario where a legitimate transmitter aims to covertly deliver information to its intended receiver through a planar FRIS, while an adversary attempts to detect whether any transmission is occurring. In this context, we analyze the false alarm (FA) and missed detection (MD) probabilities, and derive a closed-form expression for the covertness outage probability (COP). Furthermore, the success probability is characterized under the optimal detection threshold, providing new insights into the trade-off between covertness and reliable transmission. Numerical results reveal that FRIS provides a clear advantage over fixed-position RIS at low-to-moderate transmit powers by improving reliability and enhancing covertness, while at very high power levels, fixed-position RIS may sustain slightly higher success probability due to reduced leakage toward the adversary.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [19] [The Personalization Paradox: Semantic Loss vs. Reasoning Gains in Agentic AI Q&A](https://arxiv.org/abs/2512.04343)
*Satyajit Movidi,Stephen Russell*

Main category: cs.IR

TL;DR: 个性化AI顾问系统AIVisor在多个评估维度上表现出权衡：个性化提高了推理质量和事实依据，但降低了语义相似度得分，这揭示了当前LLM评估方法的结构性缺陷。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探究个性化如何影响AI学生顾问系统的性能，特别是在多个评估维度上的表现，并检验当前LLM评估方法是否适合评估用户特定的个性化响应。

Method: 使用AIVisor（基于检索增强LLM的代理系统），设计了12个真实的咨询问题来测试词汇精确性。比较了10种个性化和非个性化配置，使用线性混合效应模型分析词汇（BLEU、ROUGE-L）、语义（METEOR、BERTScore）和事实依据（RAGAS）指标。

Result: 结果显示一致的权衡：个性化可靠地提高了推理质量和事实依据，但在语义相似度上产生了显著的负面交互效应。这种负面效应并非源于回答质量差，而是由于当前评估指标会惩罚有意义的个性化偏离通用参考文本。

Conclusion: 研究揭示了当前LLM评估方法的结构性缺陷，这些方法不适合评估用户特定的响应。完全集成的个性化配置产生了最高的整体收益，表明当使用适当的多维指标评估时，个性化可以增强系统有效性。个性化产生的是指标依赖的转变而非统一改进。

Abstract: AIVisor, an agentic retrieval-augmented LLM for student advising, was used to examine how personalization affects system performance across multiple evaluation dimensions. Using twelve authentic advising questions intentionally designed to stress lexical precision, we compared ten personalized and non-personalized system configurations and analyzed outcomes with a Linear Mixed-Effects Model across lexical (BLEU, ROUGE-L), semantic (METEOR, BERTScore), and grounding (RAGAS) metrics. Results showed a consistent trade-off: personalization reliably improved reasoning quality and grounding, yet introduced a significant negative interaction on semantic similarity, driven not by poorer answers but by the limits of current metrics, which penalize meaningful personalized deviations from generic reference texts. This reveals a structural flaw in prevailing LLM evaluation methods, which are ill-suited for assessing user-specific responses. The fully integrated personalized configuration produced the highest overall gains, suggesting that personalization can enhance system effectiveness when evaluated with appropriate multidimensional metrics. Overall, the study demonstrates that personalization produces metric-dependent shifts rather than uniform improvements and provides a methodological foundation for more transparent and robust personalization in agentic AI.

</details>


### [20] [UserSimCRS v2: Simulation-Based Evaluation for Conversational Recommender Systems](https://arxiv.org/abs/2512.04588)
*Nolwenn Bernard,Krisztian Balog*

Main category: cs.IR

TL;DR: UserSimCRS v2 是对话推荐系统评估工具包的重大升级，增加了增强的用户模拟器、LLM模拟器、更多CRS和数据集支持，以及LLM作为评判者的评估工具。


<details>
  <summary>Details</summary>
Motivation: 对话推荐系统（CRS）的基于模拟的评估资源稀缺，需要更新工具包以跟上最新研究进展。

Method: 开发 UserSimCRS v2，包含：1）增强的议程式用户模拟器；2）引入基于大语言模型的模拟器；3）支持更广泛的CRS和数据集集成；4）新增LLM作为评判者的评估工具。

Result: 通过案例研究展示了这些扩展功能，提供了更先进的对话推荐系统评估工具包。

Conclusion: UserSimCRS v2 显著提升了对话推荐系统评估工具包的能力，使其与最先进研究保持一致，为CRS研究社区提供了更强大的评估资源。

Abstract: Resources for simulation-based evaluation of conversational recommender systems (CRSs) are scarce. The UserSimCRS toolkit was introduced to address this gap. In this work, we present UserSimCRS v2, a significant upgrade aligning the toolkit with state-of-the-art research. Key extensions include an enhanced agenda-based user simulator, introduction of large language model-based simulators, integration for a wider range of CRSs and datasets, and new LLM-as-a-judge evaluation utilities. We demonstrate these extensions in a case study.

</details>


### [21] [Spatially-Enhanced Retrieval-Augmented Generation for Walkability and Urban Discovery](https://arxiv.org/abs/2512.04790)
*Maddalena Amendola,Chiara Pugliese,Raffaele Perego,Chiara Renso*

Main category: cs.IR

TL;DR: WalkRAG：基于空间RAG的对话式步行路线推荐框架，结合信息检索、空间推理和LLM支持城市探索


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在空间检索和推理方面存在局限性，容易产生幻觉，需要新的解决方案来支持城市系统和旅游推荐等应用

Method: 提出WalkRAG框架，基于空间检索增强生成技术，结合对话界面，支持用户根据空间约束和偏好推荐步行路线，并沿途检索路径和兴趣点信息

Result: 初步结果显示，结合信息检索、空间推理和LLM的方法能有效支持城市探索

Conclusion: WalkRAG展示了空间RAG在增强LLM空间能力方面的潜力，为城市步行路线推荐提供了有效解决方案

Abstract: Large Language Models (LLMs) have become foundational tools in artificial intelligence, supporting a wide range of applications beyond traditional natural language processing, including urban systems and tourist recommendations. However, their tendency to hallucinate and their limitations in spatial retrieval and reasoning are well known, pointing to the need for novel solutions. Retrieval-augmented generation (RAG) has recently emerged as a promising way to enhance LLMs with accurate, domain-specific, and timely information. Spatial RAG extends this approach to tasks involving geographic understanding. In this work, we introduce WalkRAG, a spatial RAG-based framework with a conversational interface for recommending walkable urban itineraries. Users can request routes that meet specific spatial constraints and preferences while interactively retrieving information about the path and points of interest (POIs) along the way. Preliminary results show the effectiveness of combining information retrieval, spatial reasoning, and LLMs to support urban discovery.

</details>


### [22] [Ask Safely: Privacy-Aware LLM Query Generation for Knowledge Graphs](https://arxiv.org/abs/2512.04852)
*Mauro Dalle Lucca Tosi,Jordi Cabot*

Main category: cs.IR

TL;DR: 提出一种隐私感知的KG查询生成方法，在向第三方LLM发送请求前识别并省略KG中的敏感信息，以保护隐私数据


<details>
  <summary>Details</summary>
Motivation: 当KG包含敏感数据且用户缺乏部署本地生成式LLM资源时，现有基于LLM的KG查询方法存在隐私泄露风险

Method: 基于KG结构识别敏感信息，在请求LLM将自然语言问题转换为Cypher查询前省略敏感值

Result: 实验结果表明，该方法在保持生成查询质量的同时，有效防止敏感数据传输到第三方服务

Conclusion: 提出的隐私感知查询生成方法解决了敏感KG数据查询时的隐私保护问题，平衡了查询质量和数据安全

Abstract: Large Language Models (LLMs) are increasingly used to query knowledge graphs (KGs) due to their strong semantic understanding and extrapolation capabilities compared to traditional approaches. However, these methods cannot be applied when the KG contains sensitive data and the user lacks the resources to deploy a local generative LLM. To address this issue, we propose a privacy-aware query generation approach for KGs. Our method identifies sensitive information in the graph based on its structure and omits such values before requesting the LLM to translate natural language questions into Cypher queries. Experimental results show that our approach preserves the quality of the generated queries while preventing sensitive data from being transmitted to third-party services.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [23] [MindFuse: Towards GenAI Explainability in Marketing Strategy Co-Creation](https://arxiv.org/abs/2512.04112)
*Aleksandr Farseev,Marlo Ongpin,Qi Yang,Ilia Gossoudarev,Yu-Yi Chu-Farseeva,Sergey Nikolenko*

Main category: cs.MM

TL;DR: MindFuse是一个可解释的生成式AI框架，作为营销战略合作伙伴，将CTR内容AI与LLM结合，实现从竞品分析到实时优化的全流程营销自动化，效率提升高达12倍。


<details>
  <summary>Details</summary>
Motivation: 数字营销的未来在于人类创造力与生成式AI的融合，但现有LLM应用仅停留在内容生成层面，缺乏战略推理、实时优化和基于真实广告数据的解释能力。

Method: 融合CTR内容AI与大型语言模型，使用基于注意力的可解释性机制诊断广告效果，通过动态叙事构建对齐战略目标，实现从竞品分析、用户画像提取到实时优化的全生命周期营销自动化。

Result: 在代理部署中验证，效率提升高达12倍，为未来整合实证受众数据（如GWI、Nielsen）和全漏斗归因建模奠定了基础。

Conclusion: MindFuse重新定义了AI在营销中的角色，不仅是工具，更是现代营销创意和战略结构中的协作代理，开创了营销领域生成式AI的新范式。

Abstract: The future of digital marketing lies in the convergence of human creativity and generative AI, where insight, strategy, and storytelling are co-authored by intelligent systems. We present MindFuse, a brave new explainable generative AI framework designed to act as a strategic partner in the marketing process. Unlike conventional LLM applications that stop at content generation, MindFuse fuses CTR-based content AI-guided co-creation with large language models to extract, interpret, and iterate on communication narratives grounded in real advertising data. MindFuse operates across the full marketing lifecycle: from distilling content pillars and customer personas from competitor campaigns to recommending in-flight optimizations based on live performance telemetry. It uses attention-based explainability to diagnose ad effectiveness and guide content iteration, while aligning messaging with strategic goals through dynamic narrative construction and storytelling. We introduce a new paradigm in GenAI for marketing, where LLMs not only generate content but reason through it, adapt campaigns in real time, and learn from audience engagement patterns. Our results, validated in agency deployments, demonstrate up to 12 times efficiency gains, setting the stage for future integration with empirical audience data (e.g., GWI, Nielsen) and full-funnel attribution modeling. MindFuse redefines AI not just as a tool, but as a collaborative agent in the creative and strategic fabric of modern marketing.

</details>
