{"id": "2510.19986", "categories": ["cs.IR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.19986", "abs": "https://arxiv.org/abs/2510.19986", "authors": ["Drew B. Thomas"], "title": "Automating Iconclass: LLMs and RAG for Large-Scale Classification of Religious Woodcuts", "comment": "29 pages, 7 figures. First presented at the \"Digital Humanities and\n  Artificial Intelligence\" conference at the University of Reading on 17 June\n  2024", "summary": "This paper presents a novel methodology for classifying early modern\nreligious images by using Large Language Models (LLMs) and vector databases in\ncombination with Retrieval-Augmented Generation (RAG). The approach leverages\nthe full-page context of book illustrations from the Holy Roman Empire,\nallowing the LLM to generate detailed descriptions that incorporate both visual\nand textual elements. These descriptions are then matched to relevant Iconclass\ncodes through a hybrid vector search. This method achieves 87% and 92%\nprecision at five and four levels of classification, significantly\noutperforming traditional image and keyword-based searches. By employing\nfull-page descriptions and RAG, the system enhances classification accuracy,\noffering a powerful tool for large-scale analysis of early modern visual\narchives. This interdisciplinary approach demonstrates the growing potential of\nLLMs and RAG in advancing research within art history and digital humanities."}
{"id": "2510.20179", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20179", "abs": "https://arxiv.org/abs/2510.20179", "authors": ["Tadashi Wadayama"], "title": "Information Gradient for Nonlinear Gaussian Channel with Applications to Task-Oriented Communication", "comment": null, "summary": "We propose a gradient-based framework for optimizing parametric nonlinear\nGaussian channels via mutual information maximization. Leveraging the\nscore-to-Fisher bridge (SFB) methodology, we derive a computationally tractable\nformula for the information gradient that is the gradient of mutual information\nwith respect to the parameters of the nonlinear front-end. Our formula\nexpresses this gradient in terms of two key components: the score function of\nthe marginal output distribution, which can be learned via denoising score\nmatching (DSM), and the Jacobian of the front-end function, which is handled\nefficiently using the vector-Jacobian product (VJP) within automatic\ndifferentiation frameworks. This enables practical parameter optimization\nthrough gradient ascent. Furthermore, we extend this framework to task-oriented\nscenarios, deriving gradients for both task-specific mutual information, where\na task variable depends on the channel input, and the information bottleneck\n(IB) objective. A key advantage of our approach is that it facilitates\nend-to-end optimization of the nonlinear front-end without requiring explicit\ncomputation on the output distribution. Extensive experimental validation\nconfirms the correctness of our information gradient formula against analytical\nsolutions and demonstrates its effectiveness in optimizing both linear and\nnonlinear channels toward their objectives."}
{"id": "2510.20150", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.20150", "abs": "https://arxiv.org/abs/2510.20150", "authors": ["Yaochen Zhu", "Harald Steck", "Dawen Liang", "Yinhan He", "Jundong Li", "Nathan Kallus"], "title": "Rank-GRPO: Training LLM-based Conversational Recommender Systems with Reinforcement Learning", "comment": null, "summary": "Large language models (LLMs) are reshaping the recommender system paradigm by\nenabling users to express preferences and receive recommendations through\nconversations. Yet, aligning LLMs to the recommendation task remains\nchallenging: pretrained LLMs often generate out-of-catalog items, violate\nrequired output formats, and their ranking quality degrades sharply toward the\nend of the generated list. To this end, we propose ConvRec-R1, a two-stage\nframework for end-to-end training of LLM-based conversational recommender\nsystems. In Stage 1, we construct a behavioral-cloning dataset with a\nRemap-Reflect-Adjust pipeline, which produces high-quality, catalog-grounded\ndemonstrations from powerful blackbox LLMs to warm-start the RL training. In\nStage 2, we propose Rank-GRPO, a principled extension of group relative policy\noptimization (GRPO) tailored to tasks with rank-style outputs. Rank-GRPO treats\neach rank in the recommendation list as the unit instead of token (too\nfine-grained) or sequence (too coarse), redefining rewards to remove non-causal\ncredit assignment and introducing a rank-level importance ratio based on the\ngeometric mean of rank-wise token probabilities to stabilize policy updates.\nExperiments on the public Reddit-v2 dataset show that ConvRec-R1 converges\nfaster and achieves higher Recall and NDCG than GRPO-style baselines. Code and\ndatasets are released at https://github.com/yaochenzhu/Rank-GRPO."}
{"id": "2510.20241", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20241", "abs": "https://arxiv.org/abs/2510.20241", "authors": ["Xiang Li", "Cheuk Ting Li"], "title": "New Second-Order Achievability Bounds for Coding with Side Information via Type Deviation Convergence", "comment": "31 pages, 3 figures", "summary": "We propose a framework for second-order achievability, called type deviation\nconvergence, that is generally applicable to settings in network information\ntheory, and is especially suitable for lossy source coding and channel coding\nwith cost. We give a second-order achievability bound for lossy source coding\nwith side information at the decoder (Wyner-Ziv problem) that improves upon all\nknown bounds (e.g., Watanabe-Kuzuoka-Tan, Yassaee-Aref-Gohari and\nLi-Anantharam). We also give second-order achievability bounds for lossy\ncompression where side information may be absent (Heegard-Berger problem) and\nchannels with noncausal state information at the encoder and cost constraint\n(Gelfand-Pinsker problem with cost) that improve upon previous bounds."}
{"id": "2510.20193", "categories": ["cs.IR", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20193", "abs": "https://arxiv.org/abs/2510.20193", "authors": ["Rahul Raja", "Arpita Vats"], "title": "Multimedia-Aware Question Answering: A Review of Retrieval and Cross-Modal Reasoning Architectures", "comment": "In Proceedings of the 2nd ACM Workshop in AI-powered Question and\n  Answering Systems (AIQAM '25), October 27-28, 2025, Dublin, Ireland. ACM, New\n  York, NY, USA, 8 pages. https://doi.org/10.1145/3746274.3760393", "summary": "Question Answering (QA) systems have traditionally relied on structured text\ndata, but the rapid growth of multimedia content (images, audio, video, and\nstructured metadata) has introduced new challenges and opportunities for\nretrieval-augmented QA. In this survey, we review recent advancements in QA\nsystems that integrate multimedia retrieval pipelines, focusing on\narchitectures that align vision, language, and audio modalities with user\nqueries. We categorize approaches based on retrieval methods, fusion\ntechniques, and answer generation strategies, and analyze benchmark datasets,\nevaluation protocols, and performance tradeoffs. Furthermore, we highlight key\nchallenges such as cross-modal alignment, latency-accuracy tradeoffs, and\nsemantic grounding, and outline open problems and future research directions\nfor building more robust and context-aware QA systems leveraging multimedia\ndata."}
{"id": "2510.20277", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20277", "abs": "https://arxiv.org/abs/2510.20277", "authors": ["Wenli Yuan", "Kan Yu", "Xiaowu Liu", "Kaixuan Li", "Qixun Zhang", "Zhiyong Feng"], "title": "A Location-Aware Hybrid Deep Learning Framework for Dynamic Near-Far Field Channel Estimation in Low-Altitude UAV Communications", "comment": null, "summary": "In low altitude UAV communications, accurate channel estimation remains\nchallenging due to the dynamic nature of air to ground links, exacerbated by\nhigh node mobility and the use of large scale antenna arrays, which introduce\nhybrid near and far field propagation conditions. While conventional estimation\nmethods rely on far field assumptions, they fail to capture the intricate\nchannel variations in near-field scenarios and overlook valuable geometric\npriors such as real-time transceiver positions. To overcome these limitations,\nthis paper introduces a unified channel estimation framework based on a\nlocation aware hybrid deep learning architecture. The proposed model\nsynergistically combines convolutional neural networks (CNNs) for spatial\nfeature extraction, bidirectional long short term memory (BiLSTM) networks for\nmodeling temporal evolution, and a multihead self attention mechanism to\nenhance focus on discriminative channel components. Furthermore, real-time\ntransmitter and receiver locations are embedded as geometric priors, improving\nsensitivity to distance under near field spherical wavefronts and boosting\nmodel generalization. Extensive simulations validate the effectiveness of the\nproposed approach, showing that it outperforms existing benchmarks by a\nsignificant margin, achieving at least a 30.25% reduction in normalized mean\nsquare error (NMSE) on average."}
{"id": "2510.20260", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.20260", "abs": "https://arxiv.org/abs/2510.20260", "authors": ["Changping Meng", "Hongyi Ling", "Jianling Wang", "Yifan Liu", "Shuzhou Zhang", "Dapeng Hong", "Mingyan Gao", "Onkar Dalal", "Ed Chi", "Lichan Hong", "Haokai Lu", "Ningren Han"], "title": "Balancing Fine-tuning and RAG: A Hybrid Strategy for Dynamic LLM Recommendation Updates", "comment": "RecSys 2025 Industry Track", "summary": "Large Language Models (LLMs) empower recommendation systems through their\nadvanced reasoning and planning capabilities. However, the dynamic nature of\nuser interests and content poses a significant challenge: While initial\nfine-tuning aligns LLMs with domain knowledge and user preferences, it fails to\ncapture such real-time changes, necessitating robust update mechanisms. This\npaper investigates strategies for updating LLM-powered recommenders, focusing\non the trade-offs between ongoing fine-tuning and Retrieval-Augmented\nGeneration (RAG). Using an LLM-powered user interest exploration system as a\ncase study, we perform a comparative analysis of these methods across\ndimensions like cost, agility, and knowledge incorporation. We propose a hybrid\nupdate strategy that leverages the long-term knowledge adaptation of periodic\nfine-tuning with the agility of low-cost RAG. We demonstrate through live A/B\nexperiments on a billion-user platform that this hybrid approach yields\nstatistically significant improvements in user satisfaction, offering a\npractical and cost-effective framework for maintaining high-quality LLM-powered\nrecommender systems."}
{"id": "2510.20293", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20293", "abs": "https://arxiv.org/abs/2510.20293", "authors": ["Wenxu Wang", "Xiaowu Liu", "Wei Gong", "Yujia Zhao", "Kaixuan Li", "Qixun Zhang", "Zhiyong Feng", "Kan Yu"], "title": "Moving or Predicting? RoleAware-MAPP: A Role-Aware Transformer Framework for Movable Antenna Position Prediction to Secure Wireless Communications", "comment": null, "summary": "Movable antenna (MA) technology provides a promising avenue for actively\nshaping wireless channels through dynamic antenna positioning, thereby enabling\nelectromagnetic radiation reconstruction to enhance physical layer security\n(PLS). However, its practical deployment is hindered by two major challenges:\nthe high computational complexity of real time optimization and a critical\ntemporal mismatch between slow mechanical movement and rapid channel\nvariations. Although data driven methods have been introduced to alleviate\nonline optimization burdens, they are still constrained by suboptimal training\nlabels derived from conventional solvers or high sample complexity in\nreinforcement learning. More importantly, existing learning based approaches\noften overlook communication-specific domain knowledge, particularly the\nasymmetric roles and adversarial interactions between legitimate users and\neavesdroppers, which are fundamental to PLS. To address these issues, this\npaper reformulates the MA positioning problem as a predictive task and\nintroduces RoleAware-MAPP, a novel Transformer based framework that\nincorporates domain knowledge through three key components: role-aware\nembeddings that model user specific intentions, physics-informed semantic\nfeatures that encapsulate channel propagation characteristics, and a composite\nloss function that strategically prioritizes secrecy performance over mere\ngeometric accuracy. Extensive simulations under 3GPP-compliant scenarios show\nthat RoleAware-MAPP achieves an average secrecy rate of 0.3569 bps/Hz and a\nstrictly positive secrecy capacity of 81.52%, outperforming the strongest\nbaseline by 48.4% and 5.39 percentage points, respectively, while maintaining\nrobust performance across diverse user velocities and noise conditions."}
{"id": "2510.20276", "categories": ["cs.IR", "cs.HC", "cs.MA", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.20276", "abs": "https://arxiv.org/abs/2510.20276", "authors": ["Wonil Kim", "Hyeongseok Wi", "Seungsoon Park", "Taejun Kim", "Sangeun Keum", "Keunhyoung Kim", "Taewan Kim", "Jongmin Jung", "Taehyoung Kim", "Gaetan Guerrero", "Mael Le Goff", "Julie Po", "Dongjoo Moon", "Juhan Nam", "Jongpil Lee"], "title": "From Generation to Attribution: Music AI Agent Architectures for the Post-Streaming Era", "comment": "Accepted to the NeurIPS 2025 AI4Music Workshop", "summary": "Generative AI is reshaping music creation, but its rapid growth exposes\nstructural gaps in attribution, rights management, and economic models. Unlike\npast media shifts, from live performance to recordings, downloads, and\nstreaming, AI transforms the entire lifecycle of music, collapsing boundaries\nbetween creation, distribution, and monetization. However, existing streaming\nsystems, with opaque and concentrated royalty flows, are ill-equipped to handle\nthe scale and complexity of AI-driven production. We propose a content-based\nMusic AI Agent architecture that embeds attribution directly into the creative\nworkflow through block-level retrieval and agentic orchestration. Designed for\niterative, session-based interaction, the system organizes music into granular\ncomponents (Blocks) stored in BlockDB; each use triggers an Attribution Layer\nevent for transparent provenance and real-time settlement. This framework\nreframes AI from a generative tool into infrastructure for a Fair AI Media\nPlatform. By enabling fine-grained attribution, equitable compensation, and\nparticipatory engagement, it points toward a post-streaming paradigm where\nmusic functions not as a static catalog but as a collaborative and adaptive\necosystem."}
{"id": "2510.20307", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20307", "abs": "https://arxiv.org/abs/2510.20307", "authors": ["Anastasios Papazafeiropoulos", "Pandelis Kourtessis", "Dimitra I. Kaklamani", "Iakovos S. Venieris"], "title": "Ergodic Mutual Information and Outage Probability for SIM-Assisted Holographic MIMO Communications", "comment": "accepted in IEEE TVT, 13 pages, 9 figures", "summary": "Stacked intelligent metasurface (SIM) is a promising enabler for\nnext-generation high-capacity networks that exhibit better performance compared\nto its single-layer counterpart by means of just wave propagation. However, the\nstudy of ergodic mutual information (EMI) and outage probability for\nSIM-assisted multiple-input-multiple-output (MIMO) systems is not available in\nthe literature. To this end, we obtain the distribution of the MI by using\nlarge random matrix theory (RMT) tools. Next, we derive a tight closed-form\nexpression for the outage probability based on statistical channel state\ninformation (CSI). Moreover, we apply the gradient descent method for the\nminimization of the outage probability. Simulation results verify the\nanalytical results and provide fundamental insights such as the performance\nenhancements compared to conventional MIMO systems and the single-layer\ncounterpart. Notably the proposed optimization algorithm is faster than the\nalternating optimization (AO) benchmark by saving significant overhead."}
{"id": "2510.20020", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20020", "abs": "https://arxiv.org/abs/2510.20020", "authors": ["Luise Ge", "Gregory Kehne", "Yevgeniy Vorobeychik"], "title": "Optimized Distortion in Linear Social Choice", "comment": null, "summary": "Social choice theory offers a wealth of approaches for selecting a candidate\non behalf of voters based on their reported preference rankings over options.\nWhen voters have underlying utilities for these options, however, using\npreference rankings may lead to suboptimal outcomes vis-\\`a-vis utilitarian\nsocial welfare. Distortion is a measure of this suboptimality, and provides a\nworst-case approach for developing and analyzing voting rules when utilities\nhave minimal structure. However in many settings, such as common paradigms for\nvalue alignment, alternatives admit a vector representation, and it is natural\nto suppose that utilities are parametric functions thereof. We undertake the\nfirst study of distortion for linear utility functions. Specifically, we\ninvestigate the distortion of linear social choice for deterministic and\nrandomized voting rules. We obtain bounds that depend only on the dimension of\nthe candidate embedding, and are independent of the numbers of candidates or\nvoters. Additionally, we introduce poly-time instance-optimal algorithms for\nminimizing distortion given a collection of candidates and votes. We\nempirically evaluate these in two real-world domains: recommendation systems\nusing collaborative filtering embeddings, and opinion surveys utilizing\nlanguage model embeddings, benchmarking several standard rules against our\ninstance-optimal algorithms."}
{"id": "2510.20082", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2510.20082", "abs": "https://arxiv.org/abs/2510.20082", "authors": ["Yuanyuan Tian"], "title": "Query Optimization in the Wild: Realities and Trends", "comment": "6 pages, 3 figures. This paper is based on an invited talk given by\n  Yuanyuan Tian at the Special EDBT/ICDT Joint Event on Theory & Practice of\n  Query Processing in EDBT 2026\n  (https://edbticdt2025.upc.edu/?contents=special_event.html)", "summary": "For nearly half a century, the core design of query optimizers in industrial\ndatabase systems has remained remarkably stable, relying on foundational\nprinciples from System R and the Volcano/Cascades framework. However, the rise\nof cloud computing, massive data volumes, and unified data platforms has\nexposed the limitations of this traditional, monolithic architecture. Taking an\nindustrial perspective, this paper reviews the past and present of query\noptimization in production systems and identifies the challenges they face\ntoday. Then this paper highlights three key trends gaining momentum in the\nindustry that promise to address these challenges. First, a tighter feedback\nloop between query optimization and query execution is being used to improve\nthe robustness of query performance. Second, the scope of optimization is\nexpanding from a single query to entire workloads through the convergence of\nquery optimization and workload optimization. Third, and perhaps most\ntransformatively, the industry is moving from monolithic designs to composable\narchitectures that foster agility and cross-engine collaboration. Together,\nthese trends chart a clear path toward a more dynamic, holistic, and adaptable\nfuture for query optimization in practice."}
{"id": "2510.20026", "categories": ["cs.DS", "F.2.2"], "pdf": "https://arxiv.org/pdf/2510.20026", "abs": "https://arxiv.org/abs/2510.20026", "authors": ["Jeffrey Bringolf", "Hovhannes A. Harutyunyan", "Shahin Kamali", "Seyed-Mohammad Seyed-Javadi"], "title": "On Hardness and Approximation of Broadcasting in Sparse Graphs", "comment": null, "summary": "We study the Telephone Broadcasting problem in sparse graphs. Given a\ndesignated source in an undirected graph, the task is to disseminate a message\nto all vertices in the minimum number of rounds, where in each round every\ninformed vertex may inform at most one uninformed neighbor. For general graphs\nwith $n$ vertices, the problem is NP-hard. Recent work shows that the problem\nremains NP-hard even on restricted graph classes such as cactus graphs of\npathwidth $2$ [Aminian et al., ICALP 2025] and graphs at distance-1 to a path\nforest [Egami et al., MFCS 2025].\n  In this work, we investigate the problem in several sparse graph families. We\nfirst prove NP-hardness for $k$-cycle graphs, namely graphs formed by $k$\ncycles sharing a single vertex, as well as $k$-path graphs, namely graphs\nformed by $k$ paths with shared endpoints. Despite multiple efforts to\nunderstand the problem in these simple graph families, the computational\ncomplexity of the problem had remained unsettled, and our hardness results\nanswer open questions by Bhabak and Harutyunyan [CALDAM 2015] and Harutyunyan\nand Hovhannisyan [COCAO 2023] concerning the problem's complexity in $k$-cycle\nand $k$-path graphs, respectively.\n  On the positive side, we present Polynomial-Time Approximation Schemes\n(PTASs) for $k$-cycle and $k$-path graphs, improving over the best existing\napproximation factors of $2$ for $k$-cycle graphs and an approximation factor\nof $4$ for $k$-path graphs. Moreover, we identify a structural frontier for\ntractability by showing that the problem is solvable in polynomial time on\ngraphs of bounded bandwidth. This result generalizes existing tractability\nresults for special sparse families such as necklace graphs."}
{"id": "2510.20455", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.20455", "abs": "https://arxiv.org/abs/2510.20455", "authors": ["Xiaokai Wei", "Jiajun Wu", "Daiyao Yi", "Reza Shirkavand", "Michelle Gong"], "title": "Rotate Both Ways: Time-and-Order RoPE for Generative Recommendation", "comment": null, "summary": "Generative recommenders, typically transformer-based autoregressive models,\npredict the next item or action from a user's interaction history. Their\neffectiveness depends on how the model represents where an interaction event\noccurs in the sequence (discrete index) and when it occurred in wall-clock\ntime. Prevailing approaches inject time via learned embeddings or relative\nattention biases. In this paper, we argue that RoPE-based approaches, if\ndesigned properly, can be a stronger alternative for jointly modeling temporal\nand sequential information in user behavior sequences. While vanilla RoPE in\nLLMs considers only token order, generative recommendation requires\nincorporating both event time and token index. To address this, we propose\nTime-and-Order RoPE (TO-RoPE), a family of rotary position embedding designs\nthat treat index and time as angle sources shaping the query-key geometry\ndirectly. We present three instantiations: early fusion, split-by-dim, and\nsplit-by-head. Extensive experiments on both publicly available datasets and a\nproprietary industrial dataset show that TO-RoPE variants consistently improve\naccuracy over existing methods for encoding time and index. These results\nposition rotary embeddings as a simple, principled, and deployment-friendly\nfoundation for generative recommendation."}
{"id": "2510.20379", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20379", "abs": "https://arxiv.org/abs/2510.20379", "authors": ["Rimpi Borah", "J. Harshan"], "title": "Robust Analog Lagrange Coded Computing: Theory and Algorithms via Discrete Fourier Transforms", "comment": "37 pages. This is an extended version of a short paper presented at\n  IEEE International Symposium on Information Theory (ISIT) 2024", "summary": "Analog Lagrange Coded Computing (ALCC) is a recently proposed computational\nparadigm wherein certain computations over analog datasets are efficiently\nperformed using distributed worker nodes through floating point representation.\nWhile the vanilla version of ALCC is known to preserve the privacy of the\ndatasets from the workers and also achieve resilience against stragglers, it is\nnot robust against Byzantine workers that return erroneous results.\nHighlighting this vulnerability, we propose a secure ALCC framework that is\nresilient against a wide range of integrity threats from the Byzantine workers.\nAs a foundational step, we use error-correction algorithms for Discrete Fourier\nTransform (DFT) codes to build novel reconstruction strategies for ALCC thereby\nimproving its computational accuracy in the presence of a bounded number of\nByzantine workers. Furthermore, capitalizing on some theoretical results on the\nperformance of the DFT decoders, we propose novel strategies for distributing\nthe ALCC computational tasks to the workers, and show that such methods\nsignificantly improve the accuracy when the workers' trust profiles are\navailable at the master server. Finally, we study the robustness of the\nproposed framework against colluding attacks, and show that interesting attack\nstrategies can be executed by exploiting the inherent precision noise owing to\nfloating point implementation."}
{"id": "2510.20606", "categories": ["cs.GT", "cs.CY", "cs.LG", "econ.TH"], "pdf": "https://arxiv.org/pdf/2510.20606", "abs": "https://arxiv.org/abs/2510.20606", "authors": ["L. Elisa Celis", "Lingxiao Huang", "Milind Sohoni", "Nisheeth K. Vishnoi"], "title": "Strategic Costs of Perceived Bias in Fair Selection", "comment": "The paper has been accepted by NeurIPS 2025", "summary": "Meritocratic systems, from admissions to hiring, aim to impartially reward\nskill and effort. Yet persistent disparities across race, gender, and class\nchallenge this ideal. Some attribute these gaps to structural inequality;\nothers to individual choice. We develop a game-theoretic model in which\ncandidates from different socioeconomic groups differ in their perceived\npost-selection value--shaped by social context and, increasingly, by AI-powered\ntools offering personalized career or salary guidance. Each candidate\nstrategically chooses effort, balancing its cost against expected reward;\neffort translates into observable merit, and selection is based solely on\nmerit. We characterize the unique Nash equilibrium in the large-agent limit and\nderive explicit formulas showing how valuation disparities and institutional\nselectivity jointly determine effort, representation, social welfare, and\nutility. We further propose a cost-sensitive optimization framework that\nquantifies how modifying selectivity or perceived value can reduce disparities\nwithout compromising institutional goals. Our analysis reveals a\nperception-driven bias: when perceptions of post-selection value differ across\ngroups, these differences translate into rational differences in effort,\npropagating disparities backward through otherwise \"fair\" selection processes.\nWhile the model is static, it captures one stage of a broader feedback cycle\nlinking perceptions, incentives, and outcome--bridging rational-choice and\nstructural explanations of inequality by showing how techno-social environments\nshape individual incentives in meritocratic systems."}
{"id": "2510.20110", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2510.20110", "abs": "https://arxiv.org/abs/2510.20110", "authors": ["Ming Sheng", "Shuliang Wang", "Yong Zhang", "Yi Luo", "Xianbo Liu", "Zeming Li"], "title": "UREM: A High-performance Unified and Resilient Enhancement Method for Multi- and High-Dimensional Indexes", "comment": "12 pages,12 Figures", "summary": "Numerous multi- or high-dimensional indexes with distinct advantages have\nbeen proposed on various platforms to meet application requirements. To achieve\nhigher-performance queries, most indexes employ enhancement methods, including\nstructure-oriented and layout-oriented enhancement methods. Existing\nstructure-oriented methods tailored to specific indexes work well under static\nworkloads but lack generality and degrade under dynamic workloads. The\nlayout-oriented methods exhibit good generality and perform well under dynamic\nworkloads, but exhibit suboptimal performance under static workloads.\nTherefore, it is an open challenge to develop a unified and resilient\nenhancement method that can improve query performance for different indexes\nadaptively under different scenarios. In this paper, we propose UREM, which is\nthe first high-performance Unified and Resilient Enhancement Method designed\nfor both multi- and high-dimensional indexes, capable of adapting to different\nscenarios. Specifically, UREM (1) can be uniformly applied with different\nindexes on various platforms; (2) enhances the query performance of indexes by\nlayout optimization under static workloads; (3) enables indexes to stabilize\nperformance when queries shift through partial layout reorganization. We\nevaluate UREM on 20 widely used indexes. Experimental results demonstrate that\nUREM improves the query performance of multi- and high-dimensional indexes by\nup to 5.73x and 9.18x under static workloads, and by an average of 5.72x and\n9.47x under dynamic workloads. Moreover, some traditional indexes enhanced by\nUREM even achieve performance comparable to or even surpassing that of recent\nadvanced indexes."}
{"id": "2510.20053", "categories": ["cs.DS", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.20053", "abs": "https://arxiv.org/abs/2510.20053", "authors": ["Michael Goodrich", "Yan Gu", "Ryuto Kitagawa", "Yihan Sun"], "title": "Parallel Joinable B-Trees in the Fork-Join I/O Model", "comment": null, "summary": "Balanced search trees are widely used in computer science to efficiently\nmaintain dynamic ordered data. To support efficient set operations (e.g.,\nunion, intersection, difference) using trees, the join-based framework is\nwidely studied. This framework has received particular attention in the\nparallel setting, and has been shown to be effective in enabling simple and\ntheoretically efficient set operations on trees. Despite the widespread\nadoption of parallel join-based trees, a major drawback of previous work on\nsuch data structures is the inefficiency of their input/output (I/O) access\npatterns. Some recent work (e.g., C-trees and PaC-trees) focused on more\nI/O-friendly implementations of these algorithms. Surprisingly, however, there\nhave been no results on bounding the I/O-costs for these algorithms. It remains\nopen whether these algorithms can provide tight, provable guarantees in\nI/O-costs on trees.\n  This paper studies efficient parallel algorithms for set operations based on\nsearch tree algorithms using a join-based framework, with a special focus on\nachieving I/O efficiency in these algorithms. To better capture the\nI/O-efficiency in these algorithms in parallel, we introduce a new\ncomputational model, Fork-Join I/O Model, to measure the I/O costs in fork-join\nparallelism. This model measures the total block transfers (I/O work) and their\ncritical path (I/O span). Under this model, we propose our new solution based\non B-trees. Our parallel algorithm computes the union, intersection, and\ndifference of two B-trees with $O(m \\log_B(n/m))$ I/O work and $O(\\log_B m\n\\cdot \\log_2 \\log_B n + \\log_B n)$ I/O span, where $n$ and $m \\leq n$ are the\nsizes of the two trees, and $B$ is the block size."}
{"id": "2510.20674", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20674", "abs": "https://arxiv.org/abs/2510.20674", "authors": ["Rakshith R", "Shubham Sharma", "Mohammed Sameer Khan", "Ankush Chopra"], "title": "Analyticup E-commerce Product Search Competition Technical Report from Team Tredence_AICOE", "comment": null, "summary": "This study presents the multilingual e-commerce search system developed by\nthe Tredence_AICOE team. The competition features two multilingual relevance\ntasks: Query-Category (QC) Relevance, which evaluates how well a user's search\nquery aligns with a product category, and Query-Item (QI) Relevance, which\nmeasures the match between a multilingual search query and an individual\nproduct listing. To ensure full language coverage, we performed data\naugmentation by translating existing datasets into languages missing from the\ndevelopment set, enabling training across all target languages. We fine-tuned\nGemma-3 12B and Qwen-2.5 14B model for both tasks using multiple strategies.\nThe Gemma-3 12B (4-bit) model achieved the best QC performance using original\nand translated data, and the best QI performance using original, translated,\nand minority class data creation. These approaches secured 4th place on the\nfinal leaderboard, with an average F1-score of 0.8857 on the private test set."}
{"id": "2510.20518", "categories": ["cs.IT", "cs.CR", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20518", "abs": "https://arxiv.org/abs/2510.20518", "authors": ["Mohamed Seif", "Malcolm Egan", "Andrea J. Goldsmith", "H. Vincent Poor"], "title": "Adversary-Aware Private Inference over Wireless Channels", "comment": null, "summary": "AI-based sensing at wireless edge devices has the potential to significantly\nenhance Artificial Intelligence (AI) applications, particularly for vision and\nperception tasks such as in autonomous driving and environmental monitoring. AI\nsystems rely both on efficient model learning and inference. In the inference\nphase, features extracted from sensing data are utilized for prediction tasks\n(e.g., classification or regression). In edge networks, sensors and model\nservers are often not co-located, which requires communication of features. As\nsensitive personal data can be reconstructed by an adversary, transformation of\nthe features are required to reduce the risk of privacy violations. While\ndifferential privacy mechanisms provide a means of protecting finite datasets,\nprotection of individual features has not been addressed. In this paper, we\npropose a novel framework for privacy-preserving AI-based sensing, where\ndevices apply transformations of extracted features before transmission to a\nmodel server."}
{"id": "2510.20296", "categories": ["cs.DB", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20296", "abs": "https://arxiv.org/abs/2510.20296", "authors": ["Wenqi Jiang"], "title": "RAG-Stack: Co-Optimizing RAG Quality and Performance From the Vector Database Perspective", "comment": null, "summary": "Retrieval-augmented generation (RAG) has emerged as one of the most prominent\napplications of vector databases. By integrating documents retrieved from a\ndatabase into the prompt of a large language model (LLM), RAG enables more\nreliable and informative content generation. While there has been extensive\nresearch on vector databases, many open research problems remain once they are\nconsidered in the wider context of end-to-end RAG pipelines. One practical yet\nchallenging problem is how to jointly optimize both system performance and\ngeneration quality in RAG, which is significantly more complex than it appears\ndue to the numerous knobs on both the algorithmic side (spanning models and\ndatabases) and the systems side (from software to hardware). In this paper, we\npresent RAG-Stack, a three-pillar blueprint for quality-performance\nco-optimization in RAG systems. RAG-Stack comprises: (1) RAG-IR, an\nintermediate representation that serves as an abstraction layer to decouple\nquality and performance aspects; (2) RAG-CM, a cost model for estimating system\nperformance given an RAG-IR; and (3) RAG-PE, a plan exploration algorithm that\nsearches for high-quality, high-performance RAG configurations. We believe this\nthree-pillar blueprint will become the de facto paradigm for RAG\nquality-performance co-optimization in the years to come."}
{"id": "2510.20153", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2510.20153", "abs": "https://arxiv.org/abs/2510.20153", "authors": ["Tristan Pollner", "Amin Saberi", "Anders Wikum"], "title": "Optimal Rounding for Two-Stage Bipartite Matching", "comment": null, "summary": "We study two-stage bipartite matching, in which the edges of a bipartite\ngraph on vertices $(B_1 \\cup B_2, I)$ are revealed in two batches. In stage\none, a matching must be selected from among revealed edges $E \\subseteq B_1\n\\times I$. In stage two, edges $E^\\theta \\subseteq B_2 \\times I$ are sampled\nfrom a known distribution, and a second matching must be selected between $B_2$\nand unmatched vertices in $I$. The objective is to maximize the total weight of\nthe combined matching. We design polynomial-time approximations to the optimum\nonline algorithm, achieving guarantees of $7/8$ for vertex-weighted graphs and\n$2\\sqrt{2}-2 \\approx 0.828$ for edge-weighted graphs under arbitrary\ndistributions. Both approximation ratios match known upper bounds on the\nintegrality gap of the natural fractional relaxation, improving upon the\nbest-known approximation of 0.767 by Feng, Niazadeh, and Saberi for unweighted\ngraphs whose second batch consists of independently arriving nodes.\n  Our results are obtained via an algorithm that rounds a fractional matching\nrevealed in two stages, aiming to match offline nodes (respectively, edges)\nwith probability proportional to their fractional weights, up to a\nconstant-factor loss. We leverage negative association (NA) among offline node\navailabilities -- a property induced by dependent rounding -- to derive new\nlower bounds on the expected size of the maximum weight matching in random\ngraphs where one side is realized via NA binary random variables. Moreover, we\nextend these results to settings where we have only sample access to the\ndistribution. In particular, $\\text{poly}(n,\\epsilon^{-1})$ samples suffice to\nobtain an additive loss of $\\epsilon$ in the approximation ratio for the\nvertex-weighted problem; a similar bound holds for the edge-weighted problem\nwith an additional (unavoidable) dependence on the scale of edge weights."}
{"id": "2510.20815", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.20815", "abs": "https://arxiv.org/abs/2510.20815", "authors": ["Minjie Hong", "Zetong Zhou", "Zirun Guo", "Ziang Zhang", "Ruofan Hu", "Weinan Gan", "Jieming Zhu", "Zhou Zhao"], "title": "Generative Reasoning Recommendation via LLMs", "comment": null, "summary": "Despite their remarkable reasoning capabilities across diverse domains, large\nlanguage models (LLMs) face fundamental challenges in natively functioning as\ngenerative reasoning recommendation models (GRRMs), where the intrinsic\nmodeling gap between textual semantics and collaborative filtering signals,\ncombined with the sparsity and stochasticity of user feedback, presents\nsignificant obstacles. This work explores how to build GRRMs by adapting\npre-trained LLMs, which achieves a unified understanding-reasoning-prediction\nmanner for recommendation tasks. We propose GREAM, an end-to-end framework that\nintegrates three components: (i) Collaborative-Semantic Alignment, which fuses\nheterogeneous textual evidence to construct semantically consistent, discrete\nitem indices and auxiliary alignment tasks that ground linguistic\nrepresentations in interaction semantics; (ii) Reasoning Curriculum Activation,\nwhich builds a synthetic dataset with explicit Chain-of-Thought supervision and\na curriculum that progresses through behavioral evidence extraction, latent\npreference modeling, intent inference, recommendation formulation, and denoised\nsequence rewriting; and (iii) Sparse-Regularized Group Policy Optimization\n(SRPO), which stabilizes post-training via Residual-Sensitive Verifiable Reward\nand Bonus-Calibrated Group Advantage Estimation, enabling end-to-end\noptimization under verifiable signals despite sparse successes. GREAM natively\nsupports two complementary inference modes: Direct Sequence Recommendation for\nhigh-throughput, low-latency deployment, and Sequential Reasoning\nRecommendation that first emits an interpretable reasoning chain for causal\ntransparency. Experiments on three datasets demonstrate consistent gains over\nstrong baselines, providing a practical path toward verifiable-RL-driven LLM\nrecommenders."}
{"id": "2510.20569", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20569", "abs": "https://arxiv.org/abs/2510.20569", "authors": ["Feilong Zhang", "Jianxin Dai", "Zhaohui Yang", "Kai-Kit Wong", "Lingyuxiu Li", "Jianglin Ye"], "title": "Simultaneous Wireless Information and Power Transfer for Fluid Antenna Systems", "comment": null, "summary": "Fluid antenna is a promising wireless communication technology that enhances\ncommunication rate by changing the antenna positions. This article proposes a\nnew communication system that combines multiple-input single-output (MISO)\nfluid antennas with traditional fixed-position antennas, utilizing antenna\nposition optimization to improve energy harvesting efficiency. In this model,\nwe consider simultaneous wireless information and power transfer (SWIPT) which\ntransmits identical signals from the base station to both information receiver\n(IR) and energy receiver (ER). We strive to enhance the power delivered to the\nER by fine-tuning the positions of transmit and receive fluid antennas, along\nwith optimizing the transmit covariance matrix, subject to a given minimum\nsignal-to-interference-plus-noise ratio (SINR) constraint at the IR. Simulation\nresults indicate that fluid antenna systems significantly enhance the energy\nharvesting efficiency of the ER compared to traditional fixed-position\nantennas."}
{"id": "2510.20308", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2510.20308", "abs": "https://arxiv.org/abs/2510.20308", "authors": ["Manuel Schönberger", "Immanuel Trummer", "Wolfgang Mauerer"], "title": "Hybrid Mixed Integer Linear Programming for Large-Scale Join Order Optimisation", "comment": null, "summary": "Finding optimal join orders is among the most crucial steps to be performed\nby query optimisers. Though extensively studied in data management research,\nthe problem remains far from solved: While query optimisers rely on exhaustive\nsearch methods to determine ideal solutions for small problems, such methods\nreach their limits once queries grow in size. Yet, large queries become\nincreasingly common in real-world scenarios, and require suitable methods to\ngenerate efficient execution plans. While a variety of heuristics have been\nproposed for large-scale query optimisation, they suffer from degrading\nsolution quality as queries grow in size, or feature highly sub-optimal\nworst-case behavior, as we will show.\n  We propose a novel method based on the paradigm of mixed integer linear\nprogramming (MILP): By deriving a novel MILP model capable of optimising\narbitrary bushy tree structures, we address the limitations of existing MILP\nmethods for join ordering, and can rely on highly optimised MILP solvers to\nderive efficient tree structures that elude competing methods. To ensure\noptimisation efficiency, we embed our MILP method into a hybrid framework,\nwhich applies MILP solvers precisely where they provide the greatest advantage\nover competitors, while relying on more efficient methods for less complex\noptimisation steps. Thereby, our approach gracefully scales to extremely large\nquery sizes joining up to 100 relations, and consistently achieves the most\nrobust plan quality among a large variety of competing join ordering methods."}
{"id": "2510.20288", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2510.20288", "abs": "https://arxiv.org/abs/2510.20288", "authors": ["Yingxi Li", "Ellen Vitercik", "Mingwei Yang"], "title": "Smoothed Analysis of Online Metric Matching with a Single Sample: Beyond Metric Distortion", "comment": null, "summary": "In the online metric matching problem, $n$ servers and $n$ requests lie in a\nmetric space. Servers are available upfront, and requests arrive sequentially.\nAn arriving request must be matched immediately and irrevocably to an available\nserver, incurring a cost equal to their distance. The goal is to minimize the\ntotal matching cost.\n  We study this problem in the Euclidean metric $[0, 1]^d$, when servers are\nadversarial and requests are independently drawn from distinct distributions\nthat satisfy a mild smoothness condition. Our main result is an\n$O(1)$-competitive algorithm for $d \\neq 2$ that requires no distributional\nknowledge, relying only on a single sample from each request distribution. To\nour knowledge, this is the first algorithm to achieve an $o(\\log n)$\ncompetitive ratio for non-trivial metrics beyond the i.i.d. setting. Our\napproach bypasses the $\\Omega(\\log n)$ barrier introduced by probabilistic\nmetric embeddings: instead of analyzing the embedding distortion and the\nalgorithm separately, we directly bound the cost of the algorithm on the target\nmetric of a simple deterministic embedding. We then combine this analysis with\nlower bounds on the offline optimum for Euclidean metrics, derived via\nmajorization arguments, to obtain our guarantees."}
{"id": "2510.20572", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20572", "abs": "https://arxiv.org/abs/2510.20572", "authors": ["Enyu Shi", "Jiayi Zhang", "Zhilong Liu", "Ziheng Liu", "Arumugam Nallanathan", "Merouane Debbah", "Shi Jin", "Bo Ai"], "title": "Stacked Intelligent Metasurfaces for 6G Wireless Networks: Principles, Applications, and Research Directions", "comment": null, "summary": "The sixth-generation (6G) wireless networks are expected to deliver\nubiquitous connectivity, resilient coverage, and intelligence-driven services\nin highly dynamic environments. To achieve these goals, distributed wireless\narchitectures such as cell-free massive multiple-input multiple-output (MIMO)\nhave attracted significant attention due to their scalability and fairness.\nRecently, stacked intelligent metasurfaces (SIMs) have emerged as a promising\nevolution of reconfigurable intelligent surfaces, offering multi-layer\nelectromagnetic domain processing with enhanced controllability and spatial\ndegrees of freedom. By integrating SIMs into distributed wireless networks,\nadvanced wave-domain operations can be realized, enabling efficient\ninterference management, improved energy and spectral efficiency, and robust\nphysical-layer security. This article provides a comprehensive overview of\nSIM-aided distributed wireless networks, including their application scenarios,\nclassification, and system architectures. Key signal processing challenges,\nsuch as hierarchical frameworks, user association, and joint precoding, are\ndiscussed, followed by case studies demonstrating significant performance\ngains. Finally, future research directions in hardware design, energy\nconsumption modeling, algorithm development, and artificial intelligence\nintegration are highlighted, aiming to pave the way for scalable and\nintelligent 6G distributed wireless networks."}
{"id": "2510.20582", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2510.20582", "abs": "https://arxiv.org/abs/2510.20582", "authors": ["Maxime André", "Marco Raglianti", "Souhaila Serbout", "Anthony Cleve", "Michele Lanza"], "title": "An Empirical Study on Database Usage in Microservices", "comment": "Submitted to Journal Systems and Software, 17 pages", "summary": "Microservices architectures are an integral part of modern software\ndevelopment. Their adoption brings significant changes to database management.\nInstead of relying on a single database, a microservices architecture is\ntypically composed of multiple, smaller, heterogeneous, and distributed DBs. In\nthese data-intensive systems, the variety and combination of database\ncategories and technologies play a crucial role in storing and managing data.\nWhile data management in microservices is a major challenge, research\nliterature is scarce.\n  We present an empirical study on how databases are used in microservices. On\nthe dataset we collected (and released as open data for future research),\nconsidering 15 years of microservices, we examine ca. 1,000 GitHub projects\nthat use databases selected among 180 technologies from 14 categories. We\nperform a comprehensive analysis of current practices, providing researchers\nand practitioners with empirical evidence to better understand database usage\nin microservices. We report 18 findings and 9 recommendations. We show that\nmicroservices predominantly use Relational, Key-Value, Document, and Search\ndatabases. Notably, 52% of microservices combine multiple database categories.\nComplexity correlates with database count, with older systems favoring\nRelational databases and newer ones increasingly adopting Key-Value and\nDocument technologies. Niche databases (e.g., EventStoreDB, PostGIS), while not\nwidespread, are often combined with a mainstream one."}
{"id": "2510.20341", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2510.20341", "abs": "https://arxiv.org/abs/2510.20341", "authors": ["Aaron Bernstein", "Sayan Bhattacharya", "Nick Fischer", "Peter Kiss", "Thatchaphol Saranurak"], "title": "Separations between Oblivious and Adaptive Adversaries for Natural Dynamic Graph Problems", "comment": "Appears at SODA '26", "summary": "We establish the first update-time separation between dynamic algorithms\nagainst oblivious adversaries and those against adaptive adversaries in natural\ndynamic graph problems, based on popular fine-grained complexity hypotheses.\nSpecifically, under the combinatorial BMM hypothesis, we show that every\ncombinatorial algorithm against an adaptive adversary for the incremental\nmaximal independent set problem requires $n^{1-o(1)}$ amortized update time.\nFurthermore, assuming either the 3SUM or APSP hypotheses, every algorithm for\nthe decremental maximal clique problem needs $\\Delta/n^{o(1)}$ amortized update\ntime when the initial maximum degree is $\\Delta \\le \\sqrt{n}$. These lower\nbounds are matched by existing algorithms against adaptive adversaries. In\ncontrast, both problems admit algorithms against oblivious adversaries that\nachieve $\\operatorname{polylog}(n)$ amortized update time [Behnezhad,\nDerakhshan, Hajiaghayi, Stein, Sudan; FOCS '19] [Chechik, Zhang; FOCS '19].\nTherefore, our separations are exponential. Previously known separations for\ndynamic algorithms were either engineered for contrived problems and relied on\nstrong cryptographic assumptions [Beimel, Kaplan, Mansour, Nissim, Saranurak,\nStemmer; STOC '22], or worked for problems whose inputs are not explicitly\ngiven but are accessed through oracle calls [Bateni, Esfandiari, Fichtenberger,\nHenzinger, Jayaram, Mirrokni, Wiese; SODA '23].\n  As a byproduct, we also provide a separation between incremental and\ndecremental algorithms for the triangle detection problem: we show a\ndecremental algorithm with $\\tilde{O}(n^{\\omega})$ total update time, while\nevery incremental algorithm requires $n^{3-o(1)}$ total update time, assuming\nthe OMv hypothesis. To our knowledge this is the first separation of this kind."}
{"id": "2510.20723", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20723", "abs": "https://arxiv.org/abs/2510.20723", "authors": ["Haiyang Wang"], "title": "Super-Linear Growth of the Capacity-Achieving Input Support for the Amplitude-Constrained AWGN Channel", "comment": "3 pages", "summary": "We study the growth of the support size of the capacity-achieving input\ndistribution for the amplitude-constrained additive white Gaussian noise (AWGN)\nchannel. While it is known since Smith (1971) that the optimal input is\ndiscrete with finitely many mass points, tight bounds on the number of support\npoints $K(A)$ as the amplitude constraint $A$ increases remain open. Building\non recent work by Dytso \\emph{et al.} (2019) and Mattingly \\emph{et al.}\n(2018), we derive a new analytical lower bound showing that $K(A)$ grows\nsuper-linearly in $A$. Our approach combines total-variation convergence of the\noutput distribution to the uniform law with quantitative limits on Gaussian\nmixture approximation."}
{"id": "2510.20600", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2510.20600", "abs": "https://arxiv.org/abs/2510.20600", "authors": ["Dildar Ali", "Suman Banerjee", "Yamuna Prasad"], "title": "Balanced Popularity in Multi-Product Billboard Advertisement", "comment": "13 Pages", "summary": "The billboard advertisement has emerged as an effective out-of-home\nadvertisement technique where the objective is to choose a limited number of\nslots to play some advertisement content (e.g., animation, video, etc.) with\nthe hope that the content will be visible to a large number of travelers, and\nthis will be helpful to earn more revenue. In this paper, we study a variant of\nthe influential slot selection problem where the advertiser wants to promote\nmultiple products. Formally, we call this problem the \\textsc{Multi-Product\nInfluence Maximization Problem for the Balanced Popularity} Problem. The input\nto our problem is a trajectory and a billboard database, as well as a budget\nfor each product. The goal here is to choose a subset of slots for each product\nsuch that the aggregated influence of all the products gets maximized subject\nto the following two constraints: total selection cost for each product is less\nthan or equal to the allocated budget for that product, and the difference\nbetween the influence for any two products is less than or equal to a given\nthreshold. We show that the problem is NP-hard to solve optimally. We formulate\nthis problem as a linear programming problem and use linear programming\nrelaxation with randomized rounding. Further, we propose a greedy-based\nheuristic with balance correction to solve this problem. We conduct a number of\nexperiments with real-world trajectory and billboard datasets, and the results\nare reported. From the reported results, we observe that the proposed solution\napproaches lead to more influence compared to many baseline methods."}
{"id": "2510.20361", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2510.20361", "abs": "https://arxiv.org/abs/2510.20361", "authors": ["Nick Fischer", "Vasileios Nakos"], "title": "$\\ell_2/\\ell_2$ Sparse Recovery via Weighted Hypergraph Peeling", "comment": "Appears at FOCS '25", "summary": "We demonstrate that the best $k$-sparse approximation of a length-$n$ vector\ncan be recovered within a $(1+\\epsilon)$-factor approximation in\n$O((k/\\epsilon) \\log n)$ time using a non-adaptive linear sketch with\n$O((k/\\epsilon) \\log n)$ rows and $O(\\log n)$ column sparsity. This improves\nthe running time of the fastest-known sketch [Nakos, Song; STOC '19] by a\nfactor of $\\log n$, and is optimal for a wide range of parameters.\n  Our algorithm is simple and likely to be practical, with the analysis built\non a new technique we call weighted hypergraph peeling. Our method naturally\nextends known hypergraph peeling processes (as in the analysis of Invertible\nBloom Filters) to a setting where edges and nodes have (possibly correlated)\nweights."}
{"id": "2510.20734", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20734", "abs": "https://arxiv.org/abs/2510.20734", "authors": ["Abhishek Bairwa", "Ananthanarayanan Chockalingam"], "title": "MIMO-Zak-OTFS with Superimposed Spread Pilots", "comment": "Submitted to IEEE conference for possible publication", "summary": "In this paper, we consider the problem of spread pilot design and effective\nchannel estimation in multiple-input multiple-output Zak-OTFS (MIMO-Zak-OTFS)\nwith superimposed spread pilots, where data and spread pilot signals are\nsuperimposed in the same frame. To achieve good estimation performance in a\nMIMO setting, the spread pilots at different transmit antennas need to be\neffectively separated at the receiver. Towards this, we propose a spread pilot\ndesign that separates the pilot sequences in the cross-ambiguity domain and\nenables the estimation of the effective channel taps by a simple read-off\noperation. To further alleviate the effect of pilot-data interference on\nperformance, we carry out turbo iterations between channel estimation and\ndetection. Simulation results for $2\\times 2$ and $3\\times 3$ MIMO-Zak-OTFS\nwith Gaussian-sinc pulse shaping filter for vehicular-A channel model show that\nthe proposed pilot design and estimation scheme with three turbo iterations can\nachieve very good estimation/detection performance."}
{"id": "2510.20681", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2510.20681", "abs": "https://arxiv.org/abs/2510.20681", "authors": ["Xinhe Mu", "Zhaoqi Zhou", "Zaijiu Shang", "Chuan Zhou", "Gang Fu", "Guiying Yan", "Guoliang Li", "Zhiming Ma"], "title": "Downsizing Diffusion Models for Cardinality Estimation", "comment": null, "summary": "Inspired by the performance of score-based diffusion models in estimating\ncomplex text, video, and image distributions with thousands of dimensions, we\nintroduce Accelerated Diffusion Cardest (ADC), the first joint distribution\ncardinality estimator based on a downsized diffusion model.\n  To calculate the pointwise density value of data distributions, ADC's density\nestimator uses a formula that evaluates log-likelihood by integrating the score\nfunction, a gradient mapping which ADC has learned to efficiently approximate\nusing its lightweight score estimator. To answer ranged queries, ADC's\nselectivity estimator first predicts their selectivity using a Gaussian Mixture\nModel (GMM), then uses importance sampling Monte Carlo to correct its\npredictions with more accurate pointwise density values calculated by the\ndensity estimator. ADC+ further trains a decision tree to identify the\nhigh-volume, high-selectivity queries that the GMM alone can predict very\naccurately, in which case it skips the correction phase to prevent Monte Carlo\nfrom adding more variance. Doing so lowers median Q-error and cuts per-query\nlatency by 25 percent, making ADC+ usually twice as fast as Naru, arguably the\nstate-of-the-art joint distribution cardinality estimator.\n  Numerical experiments using well-established benchmarks show that on all\nreal-world datasets tested, ADC+ is capable of rivaling Naru and outperforming\nMSCN, DeepDB, LW-Tree, and LW-NN using around 66 percent their storage space,\nbeing at least 3 times as accurate as MSCN on 95th and 99th percentile error.\nFurthermore, on a synthetic dataset where attributes exhibit complex,\nmultilateral correlations, ADC and ADC+ are considerably robust while almost\nevery other learned model suffered significant accuracy declines. In this case,\nADC+ performs better than any other tested model, being 10 times as accurate as\nNaru on 95th and 99th percentile error."}
{"id": "2510.20368", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2510.20368", "abs": "https://arxiv.org/abs/2510.20368", "authors": ["Daniel Dadush", "James B. Orlin", "Aaron Sidford", "László A. Végh"], "title": "From Incremental Transitive Cover to Strongly Polynomial Maximum Flow", "comment": null, "summary": "We provide faster strongly polynomial time algorithms solving maximum flow in\nstructured $n$-node $m$-arc networks. Our results imply an $n^{\\omega +\no(1)}$-time strongly polynomial time algorithms for computing a maximum\nbipartite $b$-matching where $\\omega$ is the matrix multiplication constant.\nAdditionally, they imply an $m^{1 + o(1)} W$-time algorithm for solving the\nproblem on graphs with a given tree decomposition of width $W$.\n  We obtain these results by strengthening and efficiently implementing an\napproach in Orlin's (STOC 2013) state-of-the-art $O(mn)$ time maximum flow\nalgorithm. We develop a general framework that reduces solving maximum flow\nwith arbitrary capacities to (1) solving a sequence of maximum flow problems\nwith polynomial bounded capacities and (2) dynamically maintaining a\nsize-bounded supersets of the transitive closure under arc additions; we call\nthis problem \\emph{incremental transitive cover}. Our applications follow by\nleveraging recent weakly polynomial, almost linear time algorithms for maximum\nflow due to Chen, Kyng, Liu, Peng, Gutenberg, Sachdeva (FOCS 2022) and Brand,\nChen, Kyng, Liu, Peng, Gutenberg, Sachdeva, Sidford (FOCS 2023), and by\ndeveloping incremental transitive cover data structures."}
{"id": "2510.20382", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2510.20382", "abs": "https://arxiv.org/abs/2510.20382", "authors": ["László Kozma", "Michal Opler"], "title": "Compact representations of pattern-avoiding permutations", "comment": null, "summary": "Pattern-avoiding permutations are a central object of study in both\ncombinatorics and theoretical computer science. In this paper we design a data\nstructure that can store any size-$n$ permutation $\\tau$ that avoids an\narbitrary (and unknown) fixed pattern $\\pi$ in the asymptotically optimal $O(n\n\\lg{s_\\pi})$ bits, where $s_\\pi$ is the Stanley-Wilf limit of $\\pi$. Our data\nstructure supports $\\tau(i)$ and $\\tau^{-1}(i)$ queries in $O(1)$ time,\nsidestepping the lower bound of Golynski (SODA 2009) that holds for general\npermutations. Comparable results were previously known only in more restricted\ncases, e.g., when $\\tau$ is separable, which means avoiding the patterns 2413\nand 3142.\n  We also extend our data structure to support more complex geometric queries\non pattern-avoiding permutations (or planar point sets) such as rectangle range\ncounting in $O(\\lg\\lg{n})$ time. This result circumvents the lower bound of\n$\\Omega{(\\lg{n}/\\lg\\lg{n})}$ by P\\u{a}tra\\c{s}cu (STOC 2007) that holds in the\ngeneral case. For bounded treewidth permutation classes (which include the\nabove-mentioned separable class), we further reduce the space overhead to a\nlower order additive term, making our data structure succinct. This extends and\nimproves results of Chakraborty et al. (ISAAC 2024) that were obtained for\nseparable permutations via different techniques. All our data structures can be\nconstructed in linear time."}
{"id": "2510.20456", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2510.20456", "abs": "https://arxiv.org/abs/2510.20456", "authors": ["Bernhard Haeupler", "Yonggang Jiang", "Yaowei Long", "Thatchaphol Saranurak", "Shengzhe Wang"], "title": "Parallel $(1+ε)$-Approximate Multi-Commodity Mincost Flow in Almost Optimal Depth and Work", "comment": "To appear in FOCS 2025, 104 pages, 3 figures", "summary": "We present a parallel algorithm for computing $(1+\\epsilon)$-approximate\nmincost flow on an undirected graph with $m$ edges, where capacities and costs\nare assigned to both edges and vertices. Our algorithm achieves $\\hat{O}(m)$\nwork and $\\hat{O}(1)$ depth when $\\epsilon > 1/\\mathrm{polylog}(m)$, making\nboth the work and depth almost optimal, up to a subpolynomial factor.\n  Previous algorithms with $\\hat{O}(m)$ work required $\\Omega(m)$ depth, even\nfor special cases of mincost flow with only edge capacities or max flow with\nvertex capacities. Our result generalizes prior almost-optimal parallel\n$(1+\\epsilon)$-approximation algorithms for these special cases, including\nshortest paths [Li, STOC'20] [Andoni, Stein, Zhong, STOC'20] [Rozhen, Haeupler,\nMarinsson, Grunau, Zuzic, STOC'23] and max flow with only edge capacities\n[Agarwal, Khanna, Li, Patil, Wang, White, Zhong, SODA'24].\n  Our key technical contribution is the first construction of\nlength-constrained flow shortcuts with $(1+\\epsilon)$ length slack,\n$\\hat{O}(1)$ congestion slack, and $\\hat{O}(1)$ step bound. This provides a\nstrict generalization of the influential concept of\n$(\\hat{O}(1),\\epsilon)$-hopsets [Cohen, JACM'00], allowing for additional\ncontrol over congestion. Previous length-constrained flow shortcuts [Haeupler,\nHershkowitz, Li, Roeyskoe, Saranurak, STOC'24] incur a large constant in the\nlength slack, which would lead to a large approximation factor. To enable our\nflow algorithms to work under vertex capacities, we also develop a\nclose-to-linear time algorithm for computing length-constrained vertex expander\ndecomposition.\n  Building on Cohen's idea of path-count flows [Cohen, SICOMP'95], we further\nextend our algorithm to solve $(1+\\epsilon)$-approximate $k$-commodity mincost\nflow problems with almost-optimal $\\hat{O}(mk)$ work and $\\hat{O}(1)$ depth,\nindependent of the number of commodities $k$."}
{"id": "2510.20555", "categories": ["cs.DS", "68W25", "F.2.0"], "pdf": "https://arxiv.org/pdf/2510.20555", "abs": "https://arxiv.org/abs/2510.20555", "authors": ["Swati Gupta", "Jai Moondra", "Mohit Singh"], "title": "Provably Small Portfolios for Multiobjective Optimization with Application to Subsidized Facility Location", "comment": null, "summary": "Many multiobjective real-world problems, such as facility location and bus\nrouting, become more complex when optimizing the priorities of multiple\nstakeholders. These are often modeled using infinite classes of objectives,\ne.g., $L_p$ norms over group distances induced by feasible solutions in a fixed\ndomain. Traditionally, the literature has considered explicitly balancing\n`equity' (or min-max) and `efficiency' (or min-sum) objectives to capture this\ntrade-off. However, the structure of solutions obtained by such modeling\nchoices can be very different. Taking a solution-centric approach, we introduce\nthe concept of provably small set of solutions $P$, called a {\\it portfolio},\nsuch that for every objective function $h(\\cdot)$ in the given class\n$\\mathbf{C}$, there exists some solution in $P$ which is an\n$\\alpha$-approximation for $h(\\cdot)$. Constructing such portfolios can help\ndecision-makers understand the impact of balancing across multiple objectives.\n  Given a finite set of base objectives $h_1, \\ldots, h_N$, we give provable\nalgorithms for constructing portfolios for (1) the class of conic combinations\n$\\mathbf{C} = \\{\\sum_{j \\in [N]}\\lambda_j h_j: \\lambda \\ge 0\\}$ and for (2) any\nclass $\\mathbf{C}$ of functions that interpolates monotonically between the\nmin-sum efficiency objective (i.e., $h_1 + \\ldots + h_N$) and the min-max\nequity objective (i.e., $\\max_{j \\in [N]} h_j$). Examples of the latter are\n$L_p$ norms and top-$\\ell$ norms. As an application, we study the Fair\nSubsidized Facility Location (FSFL) problem, motivated by the crisis of medical\ndeserts caused due to pharmacy closures. FSFL allows subsidizing facilities in\nunderserved areas using revenue from profitable locations. We develop a novel\nbicriteria approximation algorithm and show a significant reduction of medical\ndeserts across states in the U.S."}
{"id": "2510.20588", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2510.20588", "abs": "https://arxiv.org/abs/2510.20588", "authors": ["Marc Dufay", "Roger Wattenhofer"], "title": "A Deterministic Polylogarithmic Competitive Algorithm for Matching with Delays", "comment": null, "summary": "In the online Min-cost Perfect Matching with Delays (MPMD) problem, $m$\nrequests in a metric space are submitted at different times by an adversary.\nThe goal is to match all requests while (i) minimizing the sum of the distances\nbetween matched pairs as well as (ii) how long each request remained unmatched\nafter it appeared.\n  While there exist almost optimal algorithms when the metric space is finite\nand known a priori, this is not the case when the metric space is infinite or\nunknown. In this latter case, the best known algorithm, due to Azar and\nJacob-Fanani, has competitiveness $\\mathcal{O}(m^{0.59})$ which is\nexponentially worse than the best known lower bound of $\\Omega(\\log m / \\log\n\\log m)$ by Ashlagi et al.\n  We present a $\\mathcal{O}(\\log^5 m)$-competitive algorithm for the MPMD\nproblem. This algorithm is deterministic and does not need to know the metric\nspace or $m$ in advance. This is an exponential improvement over previous\nresults and only a polylogarithmic factor away from the lower bound."}
