<div id=toc></div>

# Table of Contents

- [cs.DS](#cs.DS) [Total: 3]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.IR](#cs.IR) [Total: 5]
- [cs.IT](#cs.IT) [Total: 5]


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [1] [Expander Decomposition for Non-Uniform Vertex Measures](https://arxiv.org/abs/2510.23913)
*Daniel Agassy,Dani Dorfman,Haim Kaplan*

Main category: cs.DS

TL;DR: 本文提出了一种针对广义扩展概念（μ-扩展）的随机算法，可在近线性时间内计算扩展分解，推广了ADK23的结果。


<details>
  <summary>Details</summary>
Motivation: 扩展分解在图算法中至关重要，但现有算法主要针对标准扩展概念。本文旨在将ADK23的随机算法推广到更广义的μ-扩展概念，以适应更广泛的应用场景。

Method: 使用随机算法框架，在近线性时间Õ(m)内计算基于μ-扩展的扩展分解，其中μ是顶点度量，μ-扩展定义为边割大小与分割部分μ度量的最小值的比值。

Result: 成功开发了一个随机算法，能够计算(φ, φ log²n (μ(V)/m))-扩展分解，其中φ是扩展参数，μ(V)/m是归一化因子。

Conclusion: 本文推广了ADK23的扩展分解算法，使其适用于广义的μ-扩展概念，保持了近线性时间复杂度，为更广泛的图算法应用提供了基础。

Abstract: A $(\phi,\epsilon)$-expander-decomposition of a graph $G$ (with $n$ vertices
and $m$ edges) is a partition of $V$ into clusters $V_1,\ldots,V_k$ with
conductance $\Phi(G[V_i]) \ge \phi$, such that there are at most $\epsilon m$
inter-cluster edges. Such a decomposition plays a crucial role in many graph
algorithms. [ADK23] gave a randomized $\tilde{O}(m)$ time algorithm for
computing a $(\phi, \phi\log^2 {n})$-expander decomposition.
  In this paper we generalize this result for a broader notion of expansion.
Let $\mu \in {\mathbb{R}}_{\ge 0 }^n$ be a vertex measure. A standard
generalization of conductance of a cut $(S,\bar{S})$ is its $\mu$-expansion
$\Phi^{\mu}_G(S,\bar{S}) = |E(S,\bar{S})|/\min \mu(S)),\mu(\bar{S})\}$, where
$\mu(S) = \sum_{v\in S} \mu(v)$. We present a randomized $\tilde{O}(m)$ time
algorithm for computing a $(\phi, \phi \log^2
{n}\left(\frac{\mu(V)}{m}\right))$-expander decomposition with respect to
$\mu$-expansion.

</details>


### [2] [On Competitiveness of Dynamic Replication for Distributed Data Access](https://arxiv.org/abs/2510.24098)
*Tianyu Zuo,Xueyan Tang,Bu Sung Lee,Jianfei Cai*

Main category: cs.DS

TL;DR: 本文研究了分布式存储和访问的在线成本优化问题，通过构建反例证明现有算法的竞争比并非如声称的2，并证明确定性在线算法无法达到2的竞争比。提出新算法获得max{2, min{γ, 3}}的竞争比，其中γ是服务器间存储成本的最大/最小比值。


<details>
  <summary>Details</summary>
Motivation: 重新审视分布式存储系统中数据对象动态复制和删除的在线成本优化问题，发现现有算法竞争比分析存在错误，需要开发更准确的分析方法和改进算法。

Method: 构建反例证明现有算法竞争比分析错误，证明无确定性在线算法能达到2的竞争比，开发新的在线算法并进行竞争比分析，使用真实对象访问轨迹进行实证评估。

Result: 证明现有算法竞争比不是2，无确定性算法能达到2的竞争比，新算法获得max{2, min{γ, 3}}的竞争比，且该分析是紧的。

Conclusion: 本文纠正了现有算法竞争比分析的错误，建立了更准确的理论界限，提出的新算法在理论和实证上都表现出良好的性能。

Abstract: This paper studies an online cost optimization problem for distributed
storage and access. The goal is to dynamically create and delete copies of data
objects over time at geo-distributed servers to serve access requests and
minimize the total storage and network cost. We revisit a recent algorithm in
the literature and show that it does not have a competitive ratio of $2$ as
claimed by constructing a counterexample. We further prove that no
deterministic online algorithm can achieve a competitive ratio bounded by $2$
for the general cost optimization problem. We develop an online algorithm and
prove that it achieves a competitive ratio of $\max\{2, \min\{\gamma, 3\}\}$,
where $\gamma$ is the max/min storage cost ratio among all servers. Examples
are given to confirm the tightness of competitive analysis. We also empirically
evaluate algorithms using real object access traces.

</details>


### [3] [Coreset for Robust Geometric Median: Eliminating Size Dependency on Outliers](https://arxiv.org/abs/2510.24621)
*Ziyi Fang,Lingxiao Huang,Runkai Yang*

Main category: cs.DS

TL;DR: 本文研究了欧几里得空间中的鲁棒几何中位数问题，重点关注核心集构建。通过新颖的非分量误差分析，消除了先前工作中对异常值数量m的依赖，在n≥4m时实现了大小为Õ(ε⁻²·min{ε⁻²,d})的核心集。对于一维情况，获得了最优核心集大小Õ(ε⁻¹/² + (m/n)ε⁻¹)。


<details>
  <summary>Details</summary>
Motivation: 先前关于鲁棒几何中位数问题的核心集构建工作存在对异常值数量m的依赖，这限制了核心集的紧凑性。本文旨在消除这种依赖，构建更紧凑的核心集。

Method: 采用新颖的非分量误差分析方法，显著减少异常值的影响。与先前保留异常值的方法不同，该方法通过不同的技术手段处理异常值。

Result: 在n≥4m时，构建了大小为Õ(ε⁻²·min{ε⁻²,d})的核心集，消除了O(m)依赖。对于d=1的情况，获得了最优核心集大小Õ(ε⁻¹/² + (m/n)ε⁻¹)。结果还扩展到各种度量空间中的鲁棒(k,z)-聚类问题。

Conclusion: 本文提出的方法在理论和实验上都优于现有基线，即使在数据假设被违反的情况下，在尺寸-精度权衡和运行时间方面都表现出色。关键的技术贡献是新颖的非分量误差分析，能够显著减少异常值的影响。

Abstract: We study the robust geometric median problem in Euclidean space
$\mathbb{R}^d$, with a focus on coreset construction.A coreset is a compact
summary of a dataset $P$ of size $n$ that approximates the robust cost for all
centers $c$ within a multiplicative error $\varepsilon$. Given an outlier count
$m$, we construct a coreset of size $\tilde{O}(\varepsilon^{-2} \cdot
\min\{\varepsilon^{-2}, d\})$ when $n \geq 4m$, eliminating the $O(m)$
dependency present in prior work [Huang et al., 2022 & 2023]. For the special
case of $d = 1$, we achieve an optimal coreset size of
$\tilde{\Theta}(\varepsilon^{-1/2} + \frac{m}{n} \varepsilon^{-1})$, revealing
a clear separation from the vanilla case studied in [Huang et al., 2023;
Afshani and Chris, 2024]. Our results further extend to robust
$(k,z)$-clustering in various metric spaces, eliminating the $m$-dependence
under mild data assumptions. The key technical contribution is a novel
non-component-wise error analysis, enabling substantial reduction of outlier
influence, unlike prior methods that retain them.Empirically, our algorithms
consistently outperform existing baselines in terms of size-accuracy tradeoffs
and runtime, even when data assumptions are violated across a wide range of
datasets.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [4] [Odyssey: An End-to-End System for Pareto-Optimal Serverless Query Processing](https://arxiv.org/abs/2510.24307)
*Shyam Jesalpura,Shengda Zhu,Amir Shaikhha,Antonio Barbalace,Boris Grot*

Main category: cs.DB

TL;DR: Odyssey是一个端到端的无服务器原生数据分析管道，集成了查询规划器、成本模型和执行引擎，能够自动生成和评估无服务器查询计划，在成本和性能之间找到帕累托最优解。


<details>
  <summary>Details</summary>
Motivation: 现有无服务器数据分析工作主要关注执行引擎，假设存在'好'的查询执行计划或依赖用户指导来构建这样的计划，而实际上无服务器环境中的简单分析查询也存在巨大的计划空间，不同计划在性能和成本上差异巨大。

Method: 利用状态空间剪枝启发式和新型搜索算法，自动生成和评估无服务器查询计划，识别平衡成本和性能的帕累托最优计划。

Result: 评估表明Odyssey能够准确预测货币成本和延迟，在成本和/或延迟方面持续优于AWS Athena。

Conclusion: Odyssey提供了一个完整的无服务器数据分析解决方案，能够自动优化查询计划，在无服务器环境中实现更好的成本效益和性能表现。

Abstract: Running data analytics queries on serverless (FaaS) workers has been shown to
be cost- and performance-efficient for a variety of real-world scenarios,
including intermittent query arrival patterns, sudden load spikes and
management challenges that afflict managed VM clusters. Alas, existing
serverless data analytics works focus primarily on the serverless execution
engine and assume the existence of a "good" query execution plan or rely on
user guidance to construct such a plan. Meanwhile, even simple analytics
queries on serverless have a huge space of possible plans, with vast
differences in both performance and cost among plans.
  This paper introduces Odyssey, an end-to-end serverless-native data analytics
pipeline that integrates a query planner, cost model and execution engine.
Odyssey automatically generates and evaluates serverless query plans, utilizing
state space pruning heuristics and a novel search algorithm to identify
Pareto-optimal plans that balance cost and performance with low latency even
for complex queries. Our evaluations demonstrate that Odyssey accurately
predicts both monetary cost and latency, and consistently outperforms AWS
Athena on cost and/or latency.

</details>


### [5] [Evaluating Joinable Column Discovery Approaches for Context-Aware Search](https://arxiv.org/abs/2510.24599)
*Harsha Kokel,Aamod Khatiwada,Tejaswini Pedapati,Haritha Ananthakrishnan,Oktie Hassanzadeh,Horst Samulowitz,Kavitha Srinivas*

Main category: cs.DB

TL;DR: 本文对可连接列发现方法进行了全面的实验评估，比较了语法和语义技术在七个基准测试上的表现，分析了六个关键标准的影响，并展示了集成方法在连接发现中的优势。


<details>
  <summary>Details</summary>
Motivation: 自动化企业数据分析中，可连接列发现是一个关键挑战。现有方法主要关注语法重叠和语义相似性，但对于不同数据特征下哪种方法表现最佳，以及多个标准如何影响发现效果的理解仍然有限。

Method: 在七个涵盖关系数据库和数据湖的基准测试上，比较语法和语义技术。分析六个关键标准——唯一值、交集大小、连接大小、反向连接大小、值语义和元数据语义，并研究通过集成排名组合这些标准对性能的影响。

Result: 分析揭示了方法在不同数据上下文中的行为差异，并突出了整合多个标准对稳健连接发现的好处。提供了关于每个标准何时重要的经验证据，比较了用于语义连接的预训练嵌入模型，并基于数据集特征提供了选择合适方法的实用指南。

Conclusion: 元数据和值语义对数据湖至关重要，基于大小的标准在关系数据库中发挥更强作用，集成方法始终优于单一标准方法。

Abstract: Joinable Column Discovery is a critical challenge in automating enterprise
data analysis. While existing approaches focus on syntactic overlap and
semantic similarity, there remains limited understanding of which methods
perform best for different data characteristics and how multiple criteria
influence discovery effectiveness. We present a comprehensive experimental
evaluation of joinable column discovery methods across diverse scenarios. Our
study compares syntactic and semantic techniques on seven benchmarks covering
relational databases and data lakes. We analyze six key criteria -- unique
values, intersection size, join size, reverse join size, value semantics, and
metadata semantics -- and examine how combining them through ensemble ranking
affects performance. Our analysis reveals differences in method behavior across
data contexts and highlights the benefits of integrating multiple criteria for
robust join discovery. We provide empirical evidence on when each criterion
matters, compare pre-trained embedding models for semantic joins, and offer
practical guidelines for selecting suitable methods based on dataset
characteristics. Our findings show that metadata and value semantics are
crucial for data lakes, size-based criteria play a stronger role in relational
databases, and ensemble approaches consistently outperform single-criterion
methods.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [6] [Resource-Efficient LLM Application for Structured Transformation of Unstructured Financial Contracts](https://arxiv.org/abs/2510.23990)
*Maruf Ahmed Mridul,Oshani Seneviratne*

Main category: cs.IR

TL;DR: 扩展CDMizer框架，使用模板驱动方法将法律合同转换为标准化的CDM格式，在较小开源LLM支持下实现与大型专有模型相竞争的性能。


<details>
  <summary>Details</summary>
Motivation: 将非结构化法律合同转换为机器可读格式对金融工作流自动化至关重要，但复杂文档如信用支持附件(CSA)的CDM转换仍具挑战性。

Method: 扩展CDMizer框架，采用模板驱动解决方案，确保在合同到CDM转换过程中的语法正确性和CDM模式遵循。

Result: 与ISDA基准比较显示，集成较小开源LLM的CDMizer在准确性和效率方面达到与大型专有模型相竞争的性能。

Conclusion: 资源高效解决方案在自动化法律合同转换方面具有潜力，为资源受限或数据隐私要求严格的金融机构提供成本效益高且可扩展的方法。

Abstract: The transformation of unstructured legal contracts into standardized,
machine-readable formats is essential for automating financial workflows. The
Common Domain Model (CDM) provides a standardized framework for this purpose,
but converting complex legal documents like Credit Support Annexes (CSAs) into
CDM representations remains a significant challenge. In this paper, we present
an extension of the CDMizer framework, a template-driven solution that ensures
syntactic correctness and adherence to the CDM schema during contract-to-CDM
conversion. We apply this extended framework to a real-world task, comparing
its performance with a benchmark developed by the International Swaps and
Derivatives Association (ISDA) for CSA clause extraction. Our results show that
CDMizer, when integrated with a significantly smaller, open-source Large
Language Model (LLM), achieves competitive performance in terms of accuracy and
efficiency against larger, proprietary models. This work underscores the
potential of resource-efficient solutions to automate legal contract
transformation, offering a cost-effective and scalable approach that can meet
the needs of financial institutions with constrained resources or strict data
privacy requirements.

</details>


### [7] [DUET: Dual Model Co-Training for Entire Space CTR Prediction](https://arxiv.org/abs/2510.24369)
*Yutian Xiao,Meng Yuan,Fuzhen Zhuang,Wei Chen,Shukuan Wang,Shanqi Liu,Chao Feng,Wenhui Yu,Xiang Li,Lantao Hu,Han Li,Zhao Zhang*

Main category: cs.IR

TL;DR: DUET是一个双模型协同训练框架，通过集合级预测和伪标签优化解决推荐系统中预排序阶段的表达能力和计算效率之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统预排序系统使用轻量级双塔架构，虽然计算高效但表达能力有限，难以捕捉候选项目间的复杂协同和抑制关系，且加剧了样本选择偏差问题。

Method: 提出集合级预测方法，在单次前向传播中对整个候选子集进行预测；采用双模型协同训练机制，通过相互伪标签优化将监督扩展到未曝光项目。

Result: 经过离线和在线A/B测试验证，DUET在多个核心业务指标上持续优于现有最先进基线方法。

Conclusion: DUET已在快手和快手极速版全面部署，为数亿用户提供服务，成功实现了在严格计算预算下的表达性建模。

Abstract: The pre-ranking stage plays a pivotal role in large-scale recommender systems
but faces an intrinsic trade-off between model expressiveness and computational
efficiency. Owing to the massive candidate pool and strict latency constraints,
industry systems often rely on lightweight two-tower architectures, which are
computationally efficient yet limited in estimation capability. As a result,
they struggle to capture the complex synergistic and suppressive relationships
among candidate items, which are essential for producing contextually coherent
and diverse recommendation lists. Moreover, this simplicity further amplifies
the Sample Selection Bias (SSB) problem, as coarse-grained models trained on
biased exposure data must generalize to a much larger candidate space with
distinct distributions.
  To address these issues, we propose \textbf{DUET} (\textbf{DU}al Model
Co-Training for \textbf{E}ntire Space C\textbf{T}R Prediction), a set-wise
pre-ranking framework that achieves expressive modeling under tight
computational budgets. Instead of scoring items independently, DUET performs
set-level prediction over the entire candidate subset in a single forward pass,
enabling information-aware interactions among candidates while amortizing the
computational cost across the set. Moreover, a dual model co-training mechanism
extends supervision to unexposed items via mutual pseudo-label refinement,
effectively mitigating SSB. Validated through extensive offline experiments and
online A/B testing, DUET consistently outperforms state-of-the-art baselines
and achieves improvements across multiple core business metrics. At present,
DUET has been fully deployed in Kuaishou and Kuaishou Lite Apps, serving the
main traffic for hundreds of millions of users.

</details>


### [8] [Metadata-Driven Retrieval-Augmented Generation for Financial Question Answering](https://arxiv.org/abs/2510.24402)
*Michail Dadopoulos,Anestis Ladas,Stratos Moschidis,Ioannis Negkakis*

Main category: cs.IR

TL;DR: 本文提出了一种用于金融文档分析的多阶段元数据驱动RAG架构，通过LLM生成的元数据、上下文丰富的文档块和多种增强技术，在FinanceBench数据集上实现了优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统RAG在处理结构复杂、证据稀疏且相互引用的长金融文件时表现不佳，需要更有效的检索增强方法。

Method: 提出多阶段RAG架构，包括LLM生成的元数据、预检索过滤、后检索重排序和丰富嵌入等技术，特别强调将块元数据直接与文本嵌入的"上下文块"方法。

Result: 结果显示强大的重排序器对精度至关重要，但最大性能提升来自上下文块嵌入。提出的最优架构结合LLM驱动的预检索优化和上下文嵌入，实现了优越性能。

Conclusion: 本研究为构建稳健的元数据感知RAG系统提供了蓝图，特别适用于金融文档分析，并在性能与运营效率之间提供了实用的权衡方案。

Abstract: Retrieval-Augmented Generation (RAG) struggles on long, structured financial
filings where relevant evidence is sparse and cross-referenced. This paper
presents a systematic investigation of advanced metadata-driven
Retrieval-Augmented Generation (RAG) techniques, proposing and evaluating a
novel, multi-stage RAG architecture that leverages LLM-generated metadata. We
introduce a sophisticated indexing pipeline to create contextually rich
document chunks and benchmark a spectrum of enhancements, including
pre-retrieval filtering, post-retrieval reranking, and enriched embeddings,
benchmarked on the FinanceBench dataset. Our results reveal that while a
powerful reranker is essential for precision, the most significant performance
gains come from embedding chunk metadata directly with text ("contextual
chunks"). Our proposed optimal architecture combines LLM-driven pre-retrieval
optimizations with these contextual embeddings to achieve superior performance.
Additionally, we present a custom metadata reranker that offers a compelling,
cost-effective alternative to commercial solutions, highlighting a practical
trade-off between peak performance and operational efficiency. This study
provides a blueprint for building robust, metadata-aware RAG systems for
financial document analysis.

</details>


### [9] [From Time and Place to Preference: LLM-Driven Geo-Temporal Context in Recommendations](https://arxiv.org/abs/2510.24430)
*Yejin Kim,Shaghayegh Agah,Mayur Nankani,Neeraj Sharma,Feifei Peng,Maria Peifer,Sardar Hamidian,H Howie Huang*

Main category: cs.IR

TL;DR: 提出了一个使用LLM生成地理时间嵌入的框架，能够捕捉节假日、季节趋势和本地/全球事件，并通过特征融合或辅助损失整合到序列推荐模型中。


<details>
  <summary>Details</summary>
Motivation: 大多数推荐系统将时间戳视为数值或周期性值，忽略了现实世界中的节假日、事件和季节模式等上下文信息。

Method: 使用LLM从时间戳和粗略位置生成地理时间嵌入，通过直接特征融合与元数据嵌入或使用辅助损失强制语义和地理时间对齐的方式整合到序列模型中。

Result: 在MovieLens、LastFM和生产数据集上的实验表明，这些嵌入提供了与完整模型集成结果一致的预测信号。

Conclusion: 研究强调了自适应或混合推荐策略的必要性，并发布了上下文丰富的MovieLens数据集以支持未来研究。

Abstract: Most recommender systems treat timestamps as numeric or cyclical values,
overlooking real-world context such as holidays, events, and seasonal patterns.
We propose a scalable framework that uses large language models (LLMs) to
generate geo-temporal embeddings from only a timestamp and coarse location,
capturing holidays, seasonal trends, and local/global events. We then introduce
a geo-temporal embedding informativeness test as a lightweight diagnostic,
demonstrating on MovieLens, LastFM, and a production dataset that these
embeddings provide predictive signal consistent with the outcomes of full model
integrations. Geo-temporal embeddings are incorporated into sequential models
through (1) direct feature fusion with metadata embeddings or (2) an auxiliary
loss that enforces semantic and geo-temporal alignment. Our findings highlight
the need for adaptive or hybrid recommendation strategies, and we release a
context-enriched MovieLens dataset to support future research.

</details>


### [10] [MiniOneRec: An Open-Source Framework for Scaling Generative Recommendation](https://arxiv.org/abs/2510.24431)
*Xiaoyu Kong,Leheng Sheng,Junfei Tan,Yuxin Chen,Jiancan Wu,An Zhang,Xiang Wang,Xiangnan He*

Main category: cs.IR

TL;DR: MiniOneRec是首个完全开源的生成式推荐框架，通过语义ID序列和Transformer模型验证了推荐系统的扩展定律，并提出轻量级后训练方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 验证生成式推荐系统是否遵循扩展定律，以及找到实现竞争性性能的最小后训练方案，解决工业部署中存在的封闭性问题。

Method: 使用残差量化VAE生成语义ID序列，在Amazon Review数据集上对0.5B到7B参数的Qwen模型进行后训练，包括监督微调和推荐导向的强化学习。

Result: 实验显示随着模型规模增大，训练和评估损失持续下降，验证了生成式方法的参数效率。提出的后训练方法显著提升了排序准确性和候选多样性。

Conclusion: 生成式推荐系统确实遵循扩展定律，提出的轻量级后训练方法能有效提升性能，为开源推荐系统提供了可行方案。

Abstract: The recent success of large language models (LLMs) has renewed interest in
whether recommender systems can achieve similar scaling benefits. Conventional
recommenders, dominated by massive embedding tables, tend to plateau as
embedding dimensions grow. In contrast, the emerging generative paradigm
replaces embeddings with compact Semantic ID (SID) sequences produced by
autoregressive Transformers. Yet most industrial deployments remain
proprietary, leaving two fundamental questions open: (1) Do the expected
scaling laws hold on public benchmarks? (2) What is the minimal post-training
recipe that enables competitive performance?
  We present MiniOneRec, to the best of our knowledge, the first fully
open-source generative recommendation framework, which provides an end-to-end
workflow spanning SID construction, supervised fine-tuning, and
recommendation-oriented reinforcement learning. We generate SIDs via a Residual
Quantized VAE and post-train Qwen backbones ranging from 0.5B to 7B parameters
on the Amazon Review dataset. Our experiments reveal a consistent downward
trend in both training and evaluation losses with increasing model size,
validating the parameter efficiency of the generative approach. To further
enhance performance, we propose a lightweight yet effective post-training
pipeline that (1) enforces full-process SID alignment and (2) applies
reinforcement learning with constrained decoding and hybrid rewards. Together,
these techniques yield significant improvements in both ranking accuracy and
candidate diversity.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [11] [Flexible Intelligent Layered Metasurfaces for Downlink Multi-user MISO Communications](https://arxiv.org/abs/2510.24190)
*Hong Niu,Jiancheng An,Chau Yuen*

Main category: cs.IT

TL;DR: 提出了一种灵活智能分层超表面（FILM）架构，用两个形状可控的柔性超表面层替代传统刚性超表面，通过动态调整传输系数矩阵，在保持信号处理性能的同时显著减少所需层数。


<details>
  <summary>Details</summary>
Motivation: 传统堆叠智能超表面（SIMs）依赖均匀层间距且需要深度堆叠来确保处理能力，导致严重的功率衰减。为了解决这个问题，需要开发更高效的架构。

Method: 开发了一个双层FILM辅助的多用户多输入单输出系统，通过交替优化方法解决信道拟合问题，包括闭式相位偏移更新和基于梯度下降的形状优化。

Result: 仿真结果表明，所提出的透射式FILM架构相比传统的七层SIMs，在总速率上实现了超过200%的提升，在误码率上获得了超过7dB的增益。

Conclusion: FILM架构通过使用柔性超表面和形状控制，在减少层数的同时保持了优异的信号处理性能，为解决传统SIMs的功率衰减问题提供了有效方案。

Abstract: Stacked intelligent metasurfaces (SIMs) have recently gained attention as a
paradigm for wave-domain signal processing with reduced reliance on costly
radio-frequency (RF) chains. However, conventional SIMs rely on uniform
inter-layer spacing and require deep stacking to ensure processing capability,
resulting in severe power attenuation in practice. To address this issue, we
propose a flexible intelligent layered metasurface (FILM) architecture
consisting of two shape-controllable flexible metasurface layers. By replacing
rigid metasurfaces with flexible ones in both layers, the transmission
coefficient matrix can be dynamically adjusted, significantly decreasing the
number of required layers while maintaining signal processing performance.
Firstly, we develop a two-layer FILM-assisted multi-user multiple-input
single-output (MU-MISO) system, wherein we formulate a channel fitting problem
aimed at reducing the difference between the FILM-induced and target channels.
Then, we solve this non-convex problem by employing an alternating optimization
(AO) method, featuring closed-form phase shift updates and a gradient
descent-based shape optimization. Furthermore, we analyze the upper bound on
sum-rate and the complexity of computation to provide insights into design
trade-offs. Finally, simulation results demonstrated that the proposed
transmissive FILM architecture achieves over 200\% improvement in sum-rate and
more than 7 dB bit-error rate (BER) gain compared to the conventional
seven-layer SIMs.

</details>


### [12] [What Can Be Recovered Under Sparse Adversarial Corruption? Assumption-Free Theory for Linear Measurements](https://arxiv.org/abs/2510.24215)
*Vishal Halder,Alexandre Reiffers-Masson,Abdeldjalil Aïssa-El-Bey,Gugan Thoppe*

Main category: cs.IT

TL;DR: 该论文研究了在存在稀疏对抗性噪声的情况下，从观测数据中恢复信号的最大可恢复信息集，证明了最优恢复集是原始信号加上特定核空间的元素。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常基于对矩阵或信号的强结构假设（如受限等距性、稀疏性）来实现精确恢复，但对于任意矩阵和信号的可恢复性问题仍然开放。本文旨在解决这一开放性问题。

Method: 通过分析所有可能删除2q行后得到的子矩阵的行空间交集，定义投影矩阵U，证明最小化残差ℓ0范数的解位于x* + ker(U)中。

Result: 证明了最优可恢复集是x* + ker(U)，其中U是所有删除2q行后子矩阵行空间交集的投影矩阵，并给出了构造性恢复方法。

Conclusion: 对于任意矩阵和信号，在q-稀疏对抗性噪声下，最大可恢复信息集是x* + ker(U)，这为稀疏对抗性场景下的信号恢复提供了理论保证和实用方法。

Abstract: Let $\mathbf{A} \in \mathbb{R}^{m \times n}$ be an arbitrary, known matrix
and $\mathbf{e}$ a $q$-sparse adversarial vector. Given $\mathbf{y} =
\mathbf{A} x^* + \mathbf{e}$ and $q$, we seek the smallest set containing
$x^*$-hence the one conveying maximal information about $x^*$-that is uniformly
recoverable from $\mathbf{y}$ without knowing $\mathbf{e}$. While exact
recovery of $x^*$ via strong (and often impractical) structural assumptions on
$\mathbf{A}$ or $x^*$ (for example, restricted isometry, sparsity) is well
studied, recoverability for arbitrary $\mathbf{A}$ and $x^*$ remains open. Our
main result shows that the best that one can hope to recover is $x^* +
\ker(\mathbf{U})$, where $\mathbf{U}$ is the unique projection matrix onto the
intersection of rowspaces of all possible submatrices of $\mathbf{A}$ obtained
by deleting $2q$ rows. Moreover, we prove that every $x$ that minimizes the
$\ell_0$-norm of $\mathbf{y} - \mathbf{A} x$ lies in $x^* + \ker(\mathbf{U})$,
which then gives a constructive approach to recover this set.

</details>


### [13] [Precoding-free Hierarchical Rate-Splitting Multiple Access via Stacked Intelligent Metasurface](https://arxiv.org/abs/2510.24246)
*Hiroaki Hashida,Boya Di*

Main category: cs.IT

TL;DR: 提出了一种基于堆叠智能超表面(SIM)的无数字预编码分层速率分割多址接入(HRSMA)架构，通过波域处理实现干扰管理和用户分离，显著降低硬件复杂度。


<details>
  <summary>Details</summary>
Motivation: 密集多天线无线网络中的干扰管理是主要瓶颈，需要高谱效和用户公平性，同时降低硬件复杂度。

Method: 基站仅进行标量功率分配，多层SIM作为波域处理器通过非线性波前重构实现用户空间分离和干扰抑制，无需数字或混合预编码。采用交替优化算法联合优化SIM相位、功率分配和用户分组。

Result: 相比混合波束成形和无预编码基线，SIM辅助HRSMA在谱效和公平性方面取得显著提升，使用更少天线即可达到相当或更优的最小速率。

Conclusion: SIM辅助HRSMA是面向6G后网络的一种低成本、高能效和可扩展的解决方案，充分利用了多层SIM提供的波域自由度。

Abstract: Interference management is a central bottleneck in dense multi-antenna
wireless networks. Therefore, in this study, we present a digital
precoding-free hierarchical rate-splitting multiple access (HRSMA) architecture
assisted by a stacked intelligent metasurface (SIM) to achieve high spectral
efficiency and user fairness with reduced hardware complexity. In the proposed
system, the base station performs only scalar power allocation, while a
multi-layer SIM acts as a wave-domain processor that spatially separates users
and mitigates interference via nonlinear wavefront reconfiguration. This design
eliminates the need for digital or hybrid precoding, drastically reducing the
baseband computations. A joint optimization problem is formulated to maximize
the minimum user rate by jointly optimizing SIM phase shifts, power allocation,
and user grouping. To efficiently solve the resulting non-convex problem, an
alternating optimization algorithm is developed, combining simultaneous
perturbation stochastic approximation (SPSA) for SIM configuration and power
control with clustering-based grouping refinement. Simulation results
demonstrate that the proposed SIM-aided HRSMA achieves substantial gains in
both spectral efficiency and fairness compared to hybrid beamforming and
non-precoding baselines. Specifically, SIM-aided HRSMA attains comparable or
superior minimum rates with significantly fewer active antennas by exploiting
the additional wave-domain degrees of freedom provided by multi-layer SIMs.
These findings highlight the potential of SIM-aided HRSMA as a low-cost,
energy-efficient, and scalable solution for beyond-6G networks.

</details>


### [14] [Joint Active and Passive Beamforming with Sensing-Assisted Discrete Phase Shifts for Dual-RIS ISAC Systems](https://arxiv.org/abs/2510.24480)
*Qing Xue,Yun Lan,Jiajia Guo,Qianbin Chen,Shaodan Ma*

Main category: cs.IT

TL;DR: 本文研究了一种半被动双可重构智能表面辅助的集成感知与通信系统，通过联合主动和被动波束成形解决最大-最小用户信干噪比问题，以提升系统性能并确保用户公平性。


<details>
  <summary>Details</summary>
Motivation: 针对6G需求，研究双RIS辅助的ISAC系统，旨在通过优化波束成形来增强系统性能并保证用户公平性。

Method: 首先利用双RIS进行用户角度估计以简化问题求解过程，然后开发高效的交替优化算法，包括使用半定松弛和二分法解决发射波束成形优化子问题，以及针对RIS离散相位采用感知辅助方法约束优化搜索空间。

Result: 数值仿真结果表明，所提算法性能接近理想连续相位基准，优于传统离散相位优化算法，且相比单RIS系统有显著改进。

Conclusion: 所提出的双RIS辅助ISAC系统及其优化算法在性能上表现优异，能够有效提升系统性能并确保用户公平性。

Abstract: Targeting the requirements of 6G, this paper investigates a semi-passive
dual-reconfigurable intelligent surface (RIS)-assisted integrated sensing and
communication (ISAC) system, tackling the max-min user
signal-to-interference-plus-noise ratio (SINR) problem via joint active and
passive beamforming to enhance system performance and ensure user fairness.
Addressing this challenge, we first utilize dual RISs for user angle estimation
to simplify the solution process of the formulated problem, an efficient
alternating optimization algorithm is then developed. Specifically,
semi-definite relaxation and the bisection method are employed to solve the
transmit beamforming optimization subproblem. For the RIS discrete phase
shifts, a sensing-assisted approach is adopted to constrain the optimization
search space, with two distinct low-complexity search strategies introduced for
different RIS sizes. Numerical simulation results demonstrate that the proposed
algorithm achieves performance close to the ideal continuous phase shift
benchmark, outperforms conventional discrete phase shift optimization
algorithms, and exhibits a significant improvement over single-RIS systems.

</details>


### [15] [Dual-Mind World Models: A General Framework for Learning in Dynamic Wireless Networks](https://arxiv.org/abs/2510.24546)
*Lingyi Wang,Rashed Shelim,Walid Saad,Naren Ramakrishnan*

Main category: cs.IT

TL;DR: 提出了一种基于双心智世界模型的强化学习框架，用于优化毫米波V2X场景中的完整性加权信息年龄(CAoI)，通过结合模式驱动的系统1和逻辑驱动的系统2组件，提高数据效率和长期规划能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于模型无关RL和基于模型RL的方法在无线网络中数据效率低、视野短浅，无法泛化到新的网络状态，因为它们只捕捉统计模式而非底层物理逻辑。在复杂无线网络的高动态性和长期规划需求下，这些限制尤为突出。

Method: 提出双心智世界模型框架，包含模式驱动的系统1组件和逻辑驱动的系统2组件，学习无线网络动态和逻辑。通过端到端可微分想象轨迹进行链路调度学习，确保长期逻辑一致性，无需依赖环境交互获取的无线数据。

Result: 在基于Sionna的真实模拟器上进行广泛实验，结果显示该方法在数据效率上显著提升，对未见环境具有强大的泛化和适应能力，优于最先进的RL基线和仅使用系统1的世界模型方法。

Conclusion: 双心智世界模型框架通过结合模式识别和逻辑推理，有效解决了无线网络中RL方法的局限性，实现了高效的数据利用、长期规划和环境泛化能力。

Abstract: Despite the popularity of reinforcement learning (RL) in wireless networks,
existing approaches that rely on model-free RL (MFRL) and model-based RL (MBRL)
are data inefficient and short-sighted. Such RL-based solutions cannot
generalize to novel network states since they capture only statistical patterns
rather than the underlying physics and logic from wireless data. These
limitations become particularly challenging in complex wireless networks with
high dynamics and long-term planning requirements. To address these
limitations, in this paper, a novel dual-mind world model-based learning
framework is proposed with the goal of optimizing completeness-weighted age of
information (CAoI) in a challenging mmWave V2X scenario. Inspired by cognitive
psychology, the proposed dual-mind world model encompasses a pattern-driven
System 1 component and a logic-driven System 2 component to learn dynamics and
logic of the wireless network, and to provide long-term link scheduling over
reliable imagined trajectories. Link scheduling is learned through end-to-end
differentiable imagined trajectories with logical consistency over an extended
horizon rather than relying on wireless data obtained from environment
interactions. Moreover, through imagination rollouts, the proposed world model
can jointly reason network states and plan link scheduling. During intervals
without observations, the proposed method remains capable of making efficient
decisions. Extensive experiments are conducted on a realistic simulator based
on Sionna with real-world physical channel, ray-tracing, and scene objects with
material properties. Simulation results show that the proposed world model
achieves a significant improvement in data efficiency and achieves strong
generalization and adaptation to unseen environments, compared to the
state-of-the-art RL baselines, and the world model approach with only System 1.

</details>
