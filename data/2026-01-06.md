<div id=toc></div>

# Table of Contents

- [cs.GT](#cs.GT) [Total: 5]
- [cs.DB](#cs.DB) [Total: 10]
- [cs.IR](#cs.IR) [Total: 19]
- [cs.DS](#cs.DS) [Total: 6]
- [cs.IT](#cs.IT) [Total: 12]


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [1] [Bad News for Couples: Tight Lower Bounds for Fair Division of Indivisible Items](https://arxiv.org/abs/2601.01012)
*Max Dupré la Tour*

Main category: cs.GT

TL;DR: 本文证明了在将不可分割物品分配给n对夫妇时，存在需要Ω(√n)物品才能消除嫉妒的实例，匹配了已知上界，解决了该问题的紧性


<details>
  <summary>Details</summary>
Motivation: 研究不可分割物品在夫妇间的公平分配问题，每对夫妇中的两个代理具有不同的加性估值。之前Manurangsi和Suksompong给出了n个代理的任意实例的上界，但人们推测对于仅由小群体（如夫妇）组成的实例，该上界可能不是紧的

Method: 通过构造具体的分配实例，证明存在需要Ω(√n)物品才能实现无嫉妒分配的夫妇分配问题实例

Result: 证明了存在这样的分配实例：对于n对夫妇，需要Ω(√n)物品才能消除嫉妒，这匹配了已知的上界，表明该上界是紧的

Conclusion: 该结果令人惊讶，因为它表明即使仅由小群体（夫妇）组成的实例，之前猜想不是紧的上界实际上是紧的，解决了公平分配理论中的一个开放性问题

Abstract: We consider the problem of fairly allocating indivisible goods to couples, where each couple consists of two agents with distinct additive valuations. We show that there exist instances of allocating indivisible items to $n$ couples for which envy-freeness up to $Ω(\sqrt{n})$ items cannot be guaranteed. This closes the gap by matching the upper bound of Manurangsi and Suksompong, which applies to arbitrary instances with $n$ agents in total. This result is somewhat surprising, as that upper bound was conjectured not to be tight for instances consisting only of small groups.

</details>


### [2] [Carroll Mechanisms: Opportunities, Challenges, and Agenda](https://arxiv.org/abs/2601.01013)
*Philip N. Brown,Connor McCormick*

Main category: cs.GT

TL;DR: Carroll Mechanisms旨在通过激励参与者透明展示推理过程，赋能那些已知能够改变想法的人，促进自主群体意义建构和理性决策。该机制基于网络化组合LMSR构建，继承市场评分规则和自动做市商的优良特性。


<details>
  <summary>Details</summary>
Motivation: 当前需要促进群体意义建构和理性决策，但现有机制缺乏对推理过程透明度的激励，也未能充分赋能那些愿意改变想法的人。需要一种新机制来克服这些限制。

Method: 基于网络化组合LMSR（对数市场评分规则）构建Carroll Mechanisms，继承市场评分规则和自动做市商的优良特性。通过经济激励促使参与者透明展示推理过程，并特别关注那些能够改变想法的人。

Result: 在2025年秋季已取得重要进展，建立了基础框架，但也发现了若干重要问题并引发了新的研究问题。目前处于理论框架建立和问题识别阶段。

Conclusion: 本文旨在记录理论基础，清晰界定研究问题，并提出解决这些问题的研究计划。Carroll Mechanisms有潜力改进群体决策过程，但需要进一步研究来解决开放性问题。

Abstract: The purpose of Carroll Mechanisms is to facilitate autonomous group sensemaking and reasoned decisionmaking by incentivizing participants to be transparent about their reasoning process, and to empower participants who are known to be capable of changing their minds. We envision Carroll Mechanisms to be built on top of a networked combinatorial LMSR foundation and thus to inherit the desriable properties of market scoring rules and automated market-makers. While we have made great strides during Fall 2025 in building out this foundation, several significant questions remain and several major new questions have arisen as a result of this work. The purpose of this document is to document the theoretical foundation, frame these questions clearly, and propose a research plan to address the questions.

</details>


### [3] [The Optimal Sample Complexity of Linear Contracts](https://arxiv.org/abs/2601.01496)
*Mikael Møller Høgsgaard*

Main category: cs.GT

TL;DR: 该论文解决了离线设置下从数据中学习最优线性合约的问题，证明了经验效用最大化算法能以最优样本复杂度获得ε近似最优解。


<details>
  <summary>Details</summary>
Motivation: 在委托代理模型中，委托人需要设计合约来最大化自身效用，但代理人的类型分布未知。现有方法样本复杂度较高，需要开发更高效的算法来学习最优线性合约。

Method: 采用经验效用最大化算法，利用线性合约的期望奖励非递减这一结构特性，通过链式论证构建精细的网络，实现最优样本复杂度。

Result: EUM算法仅需O(ln(1/δ)/ε²)个样本就能以至少1-δ的概率获得ε近似最优线性合约，达到了已知下界，证明了最优性。同时建立了更强的均匀收敛保证。

Conclusion: 该工作解决了离线线性合约学习问题，证明了简单EUM算法的最优样本复杂度，为合约设计提供了理论保证。

Abstract: In this paper, we settle the problem of learning optimal linear contracts from data in the offline setting, where agent types are drawn from an unknown distribution and the principal's goal is to design a contract that maximizes her expected utility. Specifically, our analysis shows that the simple Empirical Utility Maximization (EUM) algorithm yields an $\varepsilon$-approximation of the optimal linear contract with probability at least $1-δ$, using just $O(\ln(1/δ) / \varepsilon^2)$ samples. This result improves upon previously known bounds and matches a lower bound from Duetting et al. [2025] up to constant factors, thereby proving its optimality. Our analysis uses a chaining argument, where the key insight is to leverage a simple structural property of linear contracts: their expected reward is non-decreasing. This property, which holds even though the utility function itself is non-monotone and discontinuous, enables the construction of fine-grained nets required for the chaining argument, which in turn yields the optimal sample complexity. Furthermore, our proof establishes the stronger guarantee of uniform convergence: the empirical utility of every linear contract is a $\varepsilon$-approximation of its true expectation with probability at least $1-δ$, using the same optimal $O(\ln(1/δ) / \varepsilon^2)$ sample complexity.

</details>


### [4] [Existence of Optimal Mechanisms for Selling Multiple Goods: An Elementary Proof](https://arxiv.org/abs/2601.01607)
*Sergiu Hart,Noam Nisan*

Main category: cs.GT

TL;DR: 证明了在多参数拍卖中，只要估值分布具有有限期望，收益最大化机制就存在


<details>
  <summary>Details</summary>
Motivation: 在多参数拍卖机制设计中，收益最大化机制的存在性是一个基本理论问题。先前的研究通常需要较强的假设条件，本文旨在证明在更弱的条件下（仅需估值分布具有有限期望）收益最大化机制仍然存在。

Method: 采用初等证明方法，不依赖复杂的数学工具，基于估值分布有限期望的基本假设，构建理论框架证明收益最大化机制的存在性。

Result: 成功证明了在多参数拍卖设置中，只要估值分布具有有限期望，就存在收益最大化的机制设计。

Conclusion: 该结果为多参数拍卖机制设计提供了更一般的存在性保证，放宽了先前研究中的假设条件，具有重要的理论意义。

Abstract: We provide an elementary proof that revenue-maximizing mechanisms exist in multi-parameter settings whenever the distribution of valuations has finite expectation.

</details>


### [5] [Metric Distortion with Preference Intensities](https://arxiv.org/abs/2601.02095)
*Mehrad Abbaszadeh,Ali Ansarifar,Mohamad Latifian,Masoud Seddighin*

Main category: cs.GT

TL;DR: 论文提出在排序投票中加入强度表达，设计Positional Scoring Matching规则，在度量失真框架下实现低于3的失真率，证明忽略强度表达会导致显著失真损失。


<details>
  <summary>Details</summary>
Motivation: 传统排序投票（a≻b≻c≻d）虽然具有良好特性，但表达能力有限。Kahng等人通过添加强度表达（≻≻和≻）来增强表达性，但主要关注功利主义失真框架。本研究从度量失真角度探索这种强度表达投票格式的潜力。

Method: 设计了一类称为Positional Scoring Matching的投票规则，适用于度量设置下的不同问题。通过求解零和博弈，找到该类别中最优的规则成员。该规则考虑了强度表达，并能在度量失真框架下工作。

Result: 提出的规则实现了低于3的失真率。通过证明忽略强度的代价界限，表明如果不考虑强度表达，会在失真方面造成显著损失。

Conclusion: 在排序投票中加入强度表达是有价值的，从度量失真角度看，Positional Scoring Matching规则能够利用强度信息实现更好的性能，忽略强度信息会导致显著的失真代价。

Abstract: In voting with ranked ballots, each agent submits a strict ranking of the form $a \succ b \succ c \succ d$ over the alternatives, and the voting rule decides on the winner based on these rankings. Although this ballot format has desirable characteristics, there is a question of whether it is expressive enough for the agents. Kahng, Latifian, and Shah address this issue by adding intensities to the rankings. They introduce the ranking with intensities ballot format, where agents can use both $\succ\!\!\succ$ and $\succ$ in their rankings to express intensive and normal preferences between consecutive alternatives in their rankings. While they focus on analyzing this ballot format in the utilitarian distortion framework, in this work, we look at the potential of using this ballot format from the metric distortion viewpoint. We design a class of voting rules coined Positional Scoring Matching rules, which can be used for different problems in the metric setting, and show that by solving a zero-sum game, we can find the optimal member of this class for our problem. This rule takes intensities into account and achieves a distortion lower than $3$. In addition, by proving a bound on the price of ignoring intensities, we show that we might lose a great deal in terms of distortion by not taking the intensities into account.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [6] [A formal query language and automata model for aggregation in complex event recognition](https://arxiv.org/abs/2601.00967)
*Pierre Bourhis,Cristian Riveros,Amaranta Salas*

Main category: cs.DB

TL;DR: 提出ACEL（聚合复杂事件逻辑）扩展CEL，支持任意交换幺半群聚合操作，并引入ACEA（聚合复杂事件自动机）作为计算模型，证明ACEA比ACEL更具表达力。


<details>
  <summary>Details</summary>
Motivation: 现有复杂事件识别系统的查询语言对聚合操作支持有限且语义未定义，需要形式化支持聚合的查询语言来处理如最大值、求和、平均值等代数函数。

Method: 1. 基于元组袋（bags of tuples）而非位置集重新定义CEL语义；2. 提出ACEL扩展，引入任意交换幺半群操作的聚合算子；3. 设计ACEA自动机模型，扩展CEA并加入聚合和过滤功能；4. 证明ACEL查询可在ACEA中表达，并分析表达力关系。

Result: 1. 成功形式化了支持聚合的查询语言ACEL；2. 展示了ACEL在实际查询中的自然表达能力；3. 证明了每个ACEL查询都可在ACEA中表达；4. 发现ACEA比ACEL更具表达力。

Conclusion: 本文为复杂事件识别中的聚合操作提供了形式化基础，提出的ACEL语言和ACEA自动机模型为复杂事件模式识别中的聚合查询提供了完整的理论和计算框架。

Abstract: Complex Event Recognition (CER) systems are used to identify complex patterns in event streams, such as those found in stock markets, sensor networks, and other similar applications. An important task in such patterns is aggregation, which involves summarizing a set of values into a single value using an algebraic function, such as the maximum, sum, or average, among others. Despite the relevance of this task, query languages in CER typically support aggregation in a restricted syntactic form, and their semantics are generally undefined.
  In this work, we present a first step toward formalizing a query language with aggregation for CER. We propose to extend Complex Event Logic (CEL), a formal query language for CER, with aggregation operations. This task requires revisiting the semantics of CEL, using a new semantics based on bags of tuples instead of sets of positions. Then, we present an extension of CEL, called Aggregation CEL (ACEL), which introduces an aggregation operator for any commutative monoid operation. The operator can be freely composed with previous CEL operators, allowing users to define complex queries and patterns. We showcase several queries in practice where ACEL proves to be natural for specifying them. From the computational side, we present a novel automata model, called Aggregation Complex Event Automata (ACEA), that extends the previous proposal of Complex Event Automata (CEA) with aggregation and filtering features. Moreover, we demonstrate that every query in ACEL can be expressed in ACEA, illustrating the effectiveness of our computational model. Finally, we study the expressiveness of ACEA through the lens of ACEL, showing that the automata model is more expressive than ACEL.

</details>


### [7] [Grain-Aware Data Transformations: Type-Level Formal Verification at Zero Computational Cost](https://arxiv.org/abs/2601.00995)
*Nikos Karayannidis*

Main category: cs.DB

TL;DR: 论文提出首个数据粒度（grain）的正式数学定义，通过类型系统实现编译时验证，可自动检测数据转换中的错误（如fan trap、chasm trap），将验证成本降低98-99%


<details>
  <summary>Details</summary>
Motivation: 数据工程中缺乏验证转换正确性的正式方法，传统方法依赖昂贵的迭代测试和数据物化，无法在部署前检测粒度变化导致的错误（如数据重复或丢失）

Method: 建立粒度的类型论框架，定义三种粒度关系（相等、有序、不可比），提出通用粒度推断定理，通过类型级操作计算等值连接的输出粒度，结合关系操作推理规则实现仅通过模式分析的零成本验证

Result: 可在编译时验证整个管道DAG的正确性，自动检测粒度相关错误；在Lean 4中提供机器检查的形式化证明；LLM可自动生成正确性证明，将人工工作从证明编写转向证明验证

Conclusion: 该方法将数据工程中的验证成本降低98-99%，使形式化方法民主化，支持AI生成管道的可靠部署，强调关注关键特征而非所有数据细节的重要性

Abstract: Data transformation correctness is a major challenge in data engineering: how to verify pipeline accuracy before deployment. Traditional methods involve costly iterative testing, data materialization, and manual error detection, due to the lack of formal approaches to reasoning about data granularity (grain), which can shift during transformations, causing issues like fan traps (metrics duplication) and chasm traps (data loss). We introduce the first formal, mathematical definition of grain, extending it from an informal concept in dimensional modeling to a universal, type-theoretic framework applicable to any data type. Encoding grain into the type system allows compile-time verification of transformation correctness, shifting validation from runtime. We define three core grain relations-equality, ordering, and incomparability-and prove a general grain inference theorem that computes the output grain of equi-joins from input grains using type-level operations. This covers all join scenarios, including comparable and incomparable keys. Together with inference rules for relational operations, this enables verification through schema analysis alone, at zero cost. Our approach allows engineers to verify that entire pipeline DAGs maintain correctness properties, detecting grain-related errors such as fan traps, chasm traps, and aggregation issues before data processing. It emphasizes the importance of grain, focusing on critical characteristics rather than all data details. We provide machine-checked formal proofs in Lean 4, reducing verification costs by 98-99%. Additionally, large language models can automatically generate correctness proofs, shifting human effort from proof writing to proof verification, thus democratizing formal methods in data engineering and supporting confident deployment of AI-generated pipelines with machine-checkable guarantees.

</details>


### [8] [Entity-Aware and Secure Query Optimization in Database Using Named Entity Recognition](https://arxiv.org/abs/2601.01254)
*Azrin Sultana,Hasibur Rashid Chayon*

Main category: cs.DB

TL;DR: 提出智能隐私保护查询优化框架，结合NER识别敏感信息，对敏感数据使用AES加密和盲索引，非敏感数据使用K-means聚类和排名搜索，实现高效数据库优化。


<details>
  <summary>Details</summary>
Motivation: 云存储已成为现代数据基础设施的支柱，但隐私和高效数据检索仍是重大挑战。传统隐私保护方法主要关注增强数据库安全性，但未能解决加密前自动识别敏感信息的问题，这会影响查询处理时间并增加人工识别错误带来的隐私风险。

Method: 提出智能隐私保护查询优化框架：1) 使用NER（特别是DBN-LSTM模型）高精度检测和分类查询中的敏感实体；2) 对敏感数据使用AES算法加密，结合盲索引实现安全搜索功能；3) 对非敏感数据使用K-means算法分组，结合排名搜索进行优化。

Result: DBN-LSTM模型在NER任务中表现最佳，准确率93%，精确率94%，召回率和F1分数均为93%。加密搜索借助盲索引获得显著更快的查询结果，非敏感数据获取也优于传统的基于聚类的搜索方法。

Conclusion: 通过集成敏感数据检测、加密和查询优化，该工作推动了现代云基础设施中隐私保护计算的发展，为云存储环境提供了更高效、更安全的隐私保护解决方案。

Abstract: Cloud storage has become the backbone of modern data infrastructure, yet privacy and efficient data retrieval remain significant challenges. Traditional privacy-preserving approaches primarily focus on enhancing database security but fail to address the automatic identification of sensitive information before encryption. This can dramatically reduce query processing time and mitigate errors during manual identification of sensitive information, thereby reducing potential privacy risks. To address this limitation, this research proposes an intelligent privacy-preserving query optimization framework that integrates Named Entity Recognition (NER) to detect sensitive information in queries, utilizing secure data encryption and query optimization techniques for both sensitive and non-sensitive data in parallel, thereby enabling efficient database optimization. Combined deep learning algorithms and transformer-based models to detect and classify sensitive entities with high precision, and the Advanced Encryption Standard (AES) algorithm to encrypt, with blind indexing to secure search functionality of the sensitive data, whereas non-sensitive data was divided into groups using the K-means algorithm, along with a rank search for optimization. Among all NER models, the Deep Belief Network combined with Long Short-Term Memory (DBN-LSTM) delivers the best performance, with an accuracy of 93% and precision (94%), recall, and F1 score of 93%, and 93%, respectively. Besides, encrypted search achieved considerably faster results with the help of blind indexing, and non-sensitive data fetching also outperformed traditional clustering-based searches. By integrating sensitive data detection, encryption, and query optimization, this work advances the state of privacy-preserving computation in modern cloud infrastructures.

</details>


### [9] [Curator: Efficient Vector Search with Low-Selectivity Filters](https://arxiv.org/abs/2601.01291)
*Yicheng Jin,Yongji Wu,Wenjun Hu,Bruce M. Maggs,Jun Yang,Xiao Zhang,Danyang Zhuo*

Main category: cs.DB

TL;DR: Curator是一个双索引架构，通过分区索引补充现有图索引，解决低选择性过滤近似最近邻搜索中图结构碎片化问题


<details>
  <summary>Details</summary>
Motivation: 基于嵌入的稠密检索在关键应用中广泛使用，但图索引在低选择性过滤查询中面临连接性断裂问题。现有解决方案通过扩展图度来缓解，但构建成本过高。需要一种能补充图索引、高效处理低选择性过滤查询的方法。

Method: 提出Curator双索引架构：1) 在共享聚类树中为不同标签构建专门索引；2) 每个索引适应其合格向量的分布以确保高效搜索；3) 共享结构以最小化内存开销；4) 支持增量更新；5) 通过动态构建临时索引处理任意复杂谓词。

Result: 与预过滤回退方法相比，Curator与最先进图索引集成可将低选择性查询延迟降低高达20.9倍，同时构建时间和内存占用仅增加5.5%和4.3%。

Conclusion: Curator证明了双索引架构的有效性，通过分区索引补充图索引，在低选择性过滤近似最近邻搜索中实现了显著性能提升，同时保持了可接受的构建和内存开销。

Abstract: Embedding-based dense retrieval has become the cornerstone of many critical applications, where approximate nearest neighbor search (ANNS) queries are often combined with filters on labels such as dates and price ranges. Graph-based indexes achieve state-of-the-art performance on unfiltered ANNS but encounter connectivity breakdown on low-selectivity filtered queries, where qualifying vectors become sparse and the graph structure among them fragments. Recent research proposes specialized graph indexes that address this issue by expanding graph degree, which incurs prohibitively high construction costs. Given these inherent limitations of graph-based methods, we argue for a dual-index architecture and present Curator, a partition-based index that complements existing graph-based approaches for low-selectivity filtered ANNS. Curator builds specialized indexes for different labels within a shared clustering tree, where each index adapts to the distribution of its qualifying vectors to ensure efficient search while sharing structure to minimize memory overhead. The system also supports incremental updates and handles arbitrary complex predicates beyond single-label filters by efficiently constructing temporary indexes on the fly. Our evaluation demonstrates that integrating Curator with state-of-the-art graph indexes reduces low-selectivity query latency by up to 20.9x compared to pre-filtering fallback, while increasing construction time and memory footprint by only 5.5% and 4.3%, respectively.

</details>


### [10] [A Tool for Semantic-Aware Spatial Corpus Construction](https://arxiv.org/abs/2601.01415)
*Wei Huang,Xieyang Wang,Jianqiu Xu,Guidong Zhang*

Main category: cs.DB

TL;DR: SSCC工具通过语义感知的空间语料库构建方法，显著提升空间自然语言查询对语料库的构建效率和质量


<details>
  <summary>Details</summary>
Motivation: 现有空间自然语言查询语料库稀缺且质量不高，传统方法依赖人工知识库构建和模板生成，效率低下且质量不稳定，限制了空间自然语言接口系统的性能

Method: 提出语义感知空间语料库构建工具SSCC，包含两个核心模块：基于空间关系的知识库构建模块（提取和确定数据集中的空间关系），以及模板增强的查询对语料生成模块（通过模板匹配和参数替换生成查询对）

Result: 实验结果显示SSCC实现了：1) 知识库构建效率提升53倍；2) 查询对语料库有效性提升2.5倍；工具为空间自然语言接口训练提供高质量语料支持，大幅降低构建时间和人力成本

Conclusion: SSCC工具通过语义感知的方法有效解决了空间自然语言查询语料库构建的效率和质量问题，为空间自然语言接口系统的发展提供了重要支持

Abstract: Spatial natural language interface to database systems provide non-expert users with convenient access to spatial data through natural language queries. However, the scarcity of high-quality spatial natural language query corpora limits the performance of such systems. Existing methods rely on manual knowledge base construction and template-based dynamic generation, which suffer from low construction efficiency and unstable corpus quality. This paper presents semantic-aware spatial corpus construction (SSCC), a tool designed for constructing high-quality spatial natural language query and executable language query pair corpora. SSCC consists of two core modules: (i) a knowledge base construction module based on spatial relations, which extracts and determines spatial relations from datasets, and (ii) a template-augmented query pair corpus generation module, which produces query pairs via template matching and parameter substitution. The tool ensures geometric consistency and adherence to spatial logic in the generated spatial relations. Experimental results demonstrate that SSCC achieves (i) a 53x efficiency improvement for knowledge base construction and (ii) a 2.5x effectiveness improvement for query pair corpus. SSCC provides high-quality corpus support for spatial natural language interface training, substantially reducing both time and labor costs in corpus construction.

</details>


### [11] [RadixGraph: A Fast, Space-Optimized Data Structure for Dynamic Graph Storage (Extended Version)](https://arxiv.org/abs/2601.01444)
*Haoxuan Xie,Junfeng Liu,Siqiang Luo,Kai Wang*

Main category: cs.DB

TL;DR: RadixGraph 是一个用于动态图存储的快速内存高效数据结构，采用基数树顶点索引和混合快照-日志架构，支持每秒数百万并发更新，性能比基线提升16.27倍，内存使用减少40.1%。


<details>
  <summary>Details</summary>
Motivation: 动态图在许多实际应用中广泛使用，随着图规模的增长，如何高效存储和更新动态图变得至关重要。需要一种既能支持高并发更新，又能保持内存效率的数据结构。

Method: 1. 精心设计的基于基数树的顶点索引，在指针数组基数树中实现查询效率和空间的最优权衡；2. 采用混合快照-日志架构进行边存储，实现摊销O(1)的更新时间。

Result: 实验结果显示：1. 在图更新吞吐方面，比性能最佳的基线提升高达16.27倍；2. 平均减少40.1%的内存使用；3. 支持每秒数百万并发更新；4. 在图分析任务中保持有竞争力的性能。

Conclusion: RadixGraph 是一个高效、内存优化的动态图存储数据结构，通过创新的基数树索引和混合存储架构，在更新吞吐量和内存效率方面显著优于现有方法，已开源供社区使用。

Abstract: Dynamic graphs model many real-world applications, and as their sizes grow, efficiently storing and updating them becomes critical. We present RadixGraph, a fast and memory-efficient data structure for dynamic graph storage. RadixGraph features a carefully designed radix-tree-based vertex index that strikes an optimal trade-off between query efficiency and space among all pointer-array-based radix trees. For edge storage, it employs a hybrid snapshot-log architecture that enables amortized $O(1)$ update time. RadixGraph supports millions of concurrent updates per second while maintaining competitive performance for graph analytics. Experimental results show that RadixGraph outperforms the most performant baseline by up to $16.27\times$ across various datasets in ingesting graph updates, and reduces memory usage by an average of $40.1\%$. RadixGraph is open-source at https://github.com/ForwardStar/RadixGraph.

</details>


### [12] [SafeLoad: Efficient Admission Control Framework for Identifying Memory-Overloading Queries in Cloud Data Warehouses](https://arxiv.org/abs/2601.01888)
*Yifan Wu,Yuhan Li,Zhenhua Wang,Zhongle Xie,Dingyu Yang,Ke Chen,Lidan Shou,Bo Tang,Liang Lin,Huan Li,Gang Chen*

Main category: cs.DB

TL;DR: SafeLoad是首个专门识别内存过载查询的准入控制框架，配合开源基准SafeBench，通过混合架构和自调优机制显著提升预测精度，减少资源浪费。


<details>
  <summary>Details</summary>
Motivation: 云数据仓库中内存过载查询会导致资源浪费和业务流程中断，现有准入控制框架主要关注SLA满足和资源隔离，对内存过载查询识别精度有限，且缺乏公开的标注数据集。

Method: 1) 使用可解释判别规则过滤内存安全查询；2) 采用全局模型和集群级模型的混合架构；3) 添加误预测校正模块；4) 自调优配额管理机制动态调整集群预测配额。

Result: SafeLoad在预测性能上达到最先进水平，相比最佳基线提升精度达66%，相比无SafeLoad场景减少CPU时间浪费达8.09倍，同时保持较低的在线和离线时间开销。

Conclusion: SafeLoad是首个专门针对内存过载查询识别的准入控制框架，配合开源基准SafeBench，能有效防止资源浪费和查询执行失败，具有高精度、可解释性、高效性和适应性。

Abstract: Memory overload is a common form of resource exhaustion in cloud data warehouses. When database queries fail due to memory overload, it not only wastes critical resources such as CPU time but also disrupts the execution of core business processes, as memory-overloading (MO) queries are typically part of complex workflows. If such queries are identified in advance and scheduled to memory-rich serverless clusters, it can prevent resource wastage and query execution failure. Therefore, cloud data warehouses desire an admission control framework with high prediction precision, interpretability, efficiency, and adaptability to effectively identify MO queries. However, existing admission control frameworks primarily focus on scenarios like SLA satisfaction and resource isolation, with limited precision in identifying MO queries. Moreover, there is a lack of publicly available MO-labeled datasets with workloads for training and benchmarking. To tackle these challenges, we propose SafeLoad, the first query admission control framework specifically designed to identify MO queries. Alongside, we release SafeBench, an open-source, industrial-scale benchmark for this task, which includes 150 million real queries. SafeLoad first filters out memory-safe queries using the interpretable discriminative rule. It then applies a hybrid architecture that integrates both a global model and cluster-level models, supplemented by a misprediction correction module to identify MO queries. Additionally, a self-tuning quota management mechanism dynamically adjusts prediction quotas per cluster to improve precision. Experimental results show that SafeLoad achieves state-of-the-art prediction performance with low online and offline time overhead. Specifically, SafeLoad improves precision by up to 66% over the best baseline and reduces wasted CPU time by up to 8.09x compared to scenarios without SafeLoad.

</details>


### [13] [Vector Search for the Future: From Memory-Resident, Static Heterogeneous Storage, to Cloud-Native Architectures](https://arxiv.org/abs/2601.01937)
*Yitong Song,Xuanhe Zhou,Christian S. Jensen,Jianliang Xu*

Main category: cs.DB

TL;DR: 该教程从存储架构视角回顾向量搜索技术的演进，涵盖内存驻留方法、异构存储技术及云原生系统，分析大规模向量检索的挑战与机遇。


<details>
  <summary>Details</summary>
Motivation: 随着向量数据规模快速增长，向量搜索面临搜索质量、延迟、可扩展性和成本之间的平衡挑战。存储架构的变化驱动着向量搜索技术的演进，从早期全内存设计到异构存储架构，再到面向万亿级检索和云原生弹性的新架构需求。

Method: 1. 回顾内存驻留方法：包括经典IVF、哈希、量化和基于图的设计
2. 系统概述异构存储向量搜索技术：涵盖索引设计、块级布局、查询策略和更新机制
3. 分析新兴云原生系统：探讨内存-SSD-对象存储架构及其在成本效益数据分层和无缝扩展方面的优势

Result: 教程提供了向量搜索技术演进的全面回顾，展示了从内存驻留到异构存储再到云原生架构的技术发展路径，为理解大规模向量检索系统的设计原则和未来方向提供了系统框架。

Conclusion: 向量搜索技术的演进与存储架构变革紧密相关。未来万亿级向量检索和云原生弹性需求将推动向量搜索系统向内存-SSD-对象存储架构发展，实现成本效益数据分层和无缝扩展，同时为大规模向量检索系统开辟了新的研究机会。

Abstract: Vector search (VS) has become a fundamental component in multimodal data management, enabling core functionalities such as image, video, and code retrieval. As vector data scales rapidly, VS faces growing challenges in balancing search, latency, scalability, and cost. The evolution of VS has been closely driven by changes in storage architecture. Early VS methods rely on all-in-memory designs for low latency, but scalability is constrained by memory capacity and cost. To address this, recent research has adopted heterogeneous architectures that offload space-intensive vectors and index structures to SSDs, while exploiting block locality and I/O-efficient strategies to maintain high search performance at billion scale. Looking ahead, the increasing demand for trillion-scale vector retrieval and cloud-native elasticity is driving a further shift toward memory-SSD-object storage architectures, which enable cost-efficient data tiering and seamless scalability.
  In this tutorial, we review the evolution of VS techniques from a storage-architecture perspective. We first review memory-resident methods, covering classical IVF, hash, quantization, and graph-based designs. We then present a systematic overview of heterogeneous storage VS techniques, including their index designs, block-level layouts, query strategies, and update mechanisms. Finally, we examine emerging cloud-native systems and highlight open research opportunities for future large-scale vector retrieval systems.

</details>


### [14] [AeroSketch: Near-Optimal Time Matrix Sketch Framework for Persistent, Sliding Window, and Distributed Streams](https://arxiv.org/abs/2601.02019)
*Hanyan Yin,Dongxie Wen,Jiajun Li,Zhewei Wei,Xiao Zhang,Peng Zhao,Zhi-Hua Zhou*

Main category: cs.DB

TL;DR: AeroSketch：基于RandNLA的新型矩阵素描框架，在保持最优通信和空间成本的同时，将更新时间复杂度从立方级降至平方级，显著提升流式数据处理效率


<details>
  <summary>Details</summary>
Motivation: 现实世界中的矩阵数据常以高吞吐向量流形式到达，难以完整存储或处理。现有矩阵素描技术虽然实现了最优空间和通信复杂度，但需要频繁的耗时矩阵分解操作，在严格近似误差约束下具有立方时间复杂度，限制了更新效率

Method: AeroSketch利用随机数值线性代数（RandNLA）的最新进展，构建新型矩阵素描框架，支持持久流、滑动窗口和分布式流场景，实现接近最优的更新时间复杂度

Result: 在合成和真实数据集上的大量实验表明，AeroSketch在更新吞吐量方面始终优于最先进方法。在严格近似误差约束下，将立方时间复杂度降至平方级，同时保持可比的近似质量以及最优的通信和空间成本

Conclusion: AeroSketch通过RandNLA技术实现了矩阵素描的突破性改进，在保持最优空间和通信效率的同时，显著提升了流式数据处理的实时性能，为大规模流式矩阵分析提供了高效解决方案

Abstract: Many real-world matrix datasets arrive as high-throughput vector streams, making it impractical to store or process them in their entirety. To enable real-time analytics under limited computational, memory, and communication resources, matrix sketching techniques have been developed over recent decades to provide compact approximations of such streaming data. Some algorithms have achieved optimal space and communication complexity. However, these approaches often require frequent time-consuming matrix factorization operations. In particular, under tight approximation error bounds, each matrix factorization computation incurs cubic time complexity, thereby limiting their update efficiency.
  In this paper, we introduce AeroSketch, a novel matrix sketching framework that leverages recent advances in randomized numerical linear algebra (RandNLA). AeroSketch achieves optimal communication and space costs while delivering near-optimal update time complexity (within logarithmic factors) across persistent, sliding window, and distributed streaming scenarios. Extensive experiments on both synthetic and real-world datasets demonstrate that AeroSketch consistently outperforms state-of-the-art methods in update throughput. In particular, under tight approximation error constraints, AeroSketch reduces the cubic time complexity to the quadratic level. Meanwhile, it maintains comparable approximation quality while retaining optimal communication and space costs.

</details>


### [15] [Octopus: A Lightweight Entity-Aware System for Multi-Table Data Discovery and Cell-Level Retrieval](https://arxiv.org/abs/2601.02304)
*Wen-Zhi Li,Sainyam Galhotra*

Main category: cs.DB

TL;DR: Octopus是一个轻量级、实体感知、无需训练的多表数据发现和单元格级检索系统，通过LLM解析查询中的细粒度实体，使用紧凑嵌入索引匹配表头，直接扫描表内容进行值检索。


<details>
  <summary>Details</summary>
Motivation: 现有数据发现系统假设每个问题可由单表回答，且依赖资源密集的离线预处理（如模型训练或大规模内容索引）。实际上，许多问题需要跨多个表的信息（独立或通过连接），用户通常寻求特定单元格值而非整个表。

Method: 使用LLM解析器从自然语言查询中识别细粒度实体（列提及和值提及），通过紧凑嵌入索引匹配表头，直接扫描表内容进行值检索，无需重型内容索引或昂贵的离线阶段。

Result: 实验结果表明，Octopus在保持显著降低计算和token成本的同时，始终优于现有系统。引入的新基准涵盖多表设置下的表和单元格级发现。

Conclusion: Octopus提供了一种轻量级、高效的多表数据发现和单元格级检索方法，通过细粒度实体对齐不仅提高了表检索准确性，还通过减少token使用和冗余LLM调用促进了高效的下游NL2SQL执行。

Abstract: Tabular data constitute a dominant form of information in modern data lakes and repositories, yet discovering the relevant tables to answer user questions remains challenging. Existing data discovery systems assume that each question can be answered by a single table and often rely on resource-intensive offline preprocessing, such as model training or large-scale content indexing. In practice, however, many questions require information spread across multiple tables -- either independently or through joins -- and users often seek specific cell values rather than entire tables. In this paper, we present Octopus, a lightweight, entity-aware, and training-free system for multi-table data discovery and cell-level value retrieval. Instead of embedding entire questions, Octopus identifies fine-grained entities (column mentions and value mentions) from natural-language queries using an LLM parser. It then matches these entities to table headers through a compact embedding index and scans table contents directly for value occurrences, eliminating the need for heavy content indexing or costly offline stages. The resulting fine-grained alignment not only improves table retrieval accuracy but also facilitates efficient downstream NL2SQL execution by reducing token usage and redundant LLM calls. To evaluate Octopus, we introduce a new benchmark covering both table- and cell-level discovery under multi-table settings, including five datasets for independent discovery and two for join-based discovery. Experimental results show that Octopus consistently outperforms existing systems while achieving substantially lower computational and token costs. Code is available at https://github.com/wenzhilics/octopus.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [16] [A Knowledge Graph and Deep Learning-Based Semantic Recommendation Database System for Advertisement Retrieval and Personalization](https://arxiv.org/abs/2601.00833)
*Tangtang Wang,Kaijie Zhang,Kuangcong Liu*

Main category: cs.IR

TL;DR: 提出基于知识图谱和深度学习的语义推荐数据库系统(KGSR-ADS)，用于广告检索和个性化推荐，整合了异构图、语义嵌入、GNN+注意力机制和向量索引优化。


<details>
  <summary>Details</summary>
Motivation: 现代数字营销中广告数据日益复杂，需要智能系统理解产品、受众和广告内容之间的语义关系，以解决广告检索和个性化推荐的挑战。

Method: 构建四层架构：1) 异质广告知识图谱(Ad-KG)捕捉多关系语义；2) 语义嵌入层使用GPT/LLaMA等大语言模型生成上下文感知向量表示；3) GNN+注意力模型推断跨实体依赖关系；4) 基于FAISS/Milvus向量索引的数据库优化与检索层实现高效语义搜索。

Result: 该框架能够实现准确的语义匹配和可扩展的检索，支持大规模异构工作负载下的个性化广告推荐。

Conclusion: 提出的KGSR-ADS系统通过整合知识图谱和深度学习技术，有效解决了现代数字营销中广告语义理解和个性化推荐的复杂问题。

Abstract: In modern digital marketing, the growing complexity of advertisement data demands intelligent systems capable of understanding semantic relationships among products, audiences, and advertising content. To address this challenge, this paper proposes a Knowledge Graph and Deep Learning-Based Semantic Recommendation Database System (KGSR-ADS) for advertisement retrieval and personalization. The proposed framework integrates a heterogeneous Ad-Knowledge Graph (Ad-KG) that captures multi-relational semantics, a Semantic Embedding Layer that leverages large language models (LLMs) such as GPT and LLaMA to generate context-aware vector representations, a GNN + Attention Model that infers cross-entity dependencies, and a Database Optimization & Retrieval Layer based on vector indexing (FAISS/Milvus) for efficient semantic search. This layered architecture enables both accurate semantic matching and scalable retrieval, allowing personalized ad recommendations under large-scale heterogeneous workloads.

</details>


### [17] [Enhancing Retrieval-Augmented Generation with Topic-Enriched Embeddings: A Hybrid Approach Integrating Traditional NLP Techniques](https://arxiv.org/abs/2601.00891)
*Rodrigo Kataishi*

Main category: cs.IR

TL;DR: 该论文提出了一种主题增强嵌入方法，通过结合TF-IDF、主题建模和降维技术来改进RAG系统的文档检索质量，在法务文本语料库上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前检索增强生成（RAG）系统在主题重叠和主题变化高的语料库中，检索质量会下降。需要一种能够同时捕捉术语级和主题级语义的嵌入方法，以提高检索精度和语义聚类效果。

Method: 提出主题增强嵌入方法：结合TF-IDF（术语级信号）与主题建模（LSA和LDA）来编码潜在主题结构，再通过降维技术融合这些表示，最后与紧凑的上下文编码器（all-MiniLM）集成。该方法同时捕捉术语级和主题级语义。

Result: 在法务文本语料库上的实验显示，主题增强嵌入在聚类一致性和检索指标上均有持续提升，相对于纯上下文基线提高了检索精度，同时减少了计算负担。

Conclusion: 主题增强嵌入可以作为知识密集型RAG流水线中更可靠的实用组件，通过整合术语信号和主题结构来改进语义表示，从而提升检索质量和系统可靠性。

Abstract: Retrieval-augmented generation (RAG) systems rely on accurate document retrieval to ground large language models (LLMs) in external knowledge, yet retrieval quality often degrades in corpora where topics overlap and thematic variation is high. This work proposes topic-enriched embeddings that integrate term-based signals and topic structure with contextual sentence embeddings. The approach combines TF-IDF with topic modeling and dimensionality reduction, using Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) to encode latent topical organization, and fuses these representations with a compact contextual encoder (all-MiniLM). By jointly capturing term-level and topic-level semantics, topic-enriched embeddings improve semantic clustering, increase retrieval precision, and reduce computational burden relative to purely contextual baselines. Experiments on a legal-text corpus show consistent gains in clustering coherence and retrieval metrics, suggesting that topic-enriched embeddings can serve as a practical component for more reliable knowledge-intensive RAG pipelines.

</details>


### [18] [The Discovery Gap: How Product Hunt Startups Vanish in LLM Organic Discovery Queries](https://arxiv.org/abs/2601.00912)
*Amit Prakash Sharma*

Main category: cs.IR

TL;DR: 研究显示，当用户直接询问产品名称时，LLMs能准确识别（ChatGPT 99.4%，Perplexity 94.3%），但在发现式查询中成功率骤降（ChatGPT 3.32%，Perplexity 8.29%）。生成式引擎优化(GEO)对AI可见性无显著影响，传统SEO信号和社区存在才是关键预测因素。


<details>
  <summary>Details</summary>
Motivation: 研究旨在了解当用户向ChatGPT等大型语言模型询问项目管理工具推荐时，哪些产品会出现，特别是新创产品能否被LLMs发现。这对于创业创始人评估其产品在AI搜索环境中的可见性至关重要。

Method: 从2025年Product Hunt排行榜前500名产品中随机选取112家初创公司，对每个产品进行2,240次查询测试，分别使用ChatGPT(gpt-4o-mini)和Perplexity(sonar with web search)两个LLMs。分析包括直接产品名称查询和发现式查询两种场景。

Result: 直接产品名称查询识别率极高（ChatGPT 99.4%，Perplexity 94.3%），但发现式查询成功率大幅下降（ChatGPT 3.32%，Perplexity 8.29%）。GEO优化与发现率无相关性，而传统SEO信号如引用域名(r=+0.319)和Product Hunt排名(r=-0.286)对Perplexity可见性有显著预测作用，Reddit社区存在也有积极影响(r=+0.395)。

Conclusion: 不要直接为AI发现进行优化，而应优先建立SEO基础，LLM可见性将随之而来。传统搜索引擎优化信号和社区参与度比专门的生成式引擎优化更有效。

Abstract: When someone asks ChatGPT to recommend a project management tool, which products show up in the response? And more importantly for startup founders: will their newly launched product ever appear? This research set out to answer these questions.
  I randomly selected 112 startups from the top 500 products featured on the 2025 Product Hunt leaderboard and tested each one across 2,240 queries to two different large language models: ChatGPT (gpt-4o-mini) and Perplexity (sonar with web search).
  The results were striking. When users asked about products by name, both LLMs recognized them almost perfectly: 99.4% for ChatGPT and 94.3% for Perplexity. But when users asked discovery-style questions like "What are the best AI tools launched this year?" the success rates collapsed to 3.32% and 8.29% respectively. That's a gap of 30-to-1 for ChatGPT.
  Perhaps the most surprising finding was that Generative Engine Optimization (GEO), the practice of optimizing website content for AI visibility, showed no correlation with actual discovery rates. Products with high GEO scores were no more likely to appear in organic queries than products with low scores.
  What did matter? For Perplexity, traditional SEO signals like referring domains (r = +0.319, p < 0.001) and Product Hunt ranking (r = -0.286, p = 0.002) predicted visibility. After cleaning the Reddit data for false positives, community presence also emerged as significant (r = +0.395, p = 0.002).
  The practical takeaway is counterintuitive: don't optimize for AI discovery directly. Instead, build the SEO foundation first and LLM visibility will follow.

</details>


### [19] [MACA: A Framework for Distilling Trustworthy LLMs into Efficient Retrievers](https://arxiv.org/abs/2601.00926)
*Satya Swaroop Gudipudi,Sahil Girhepuje,Ponnurangam Kumaraguru,Kristine Ma*

Main category: cs.IR

TL;DR: MACA方法通过将经过校准的元数据感知LLM重排器蒸馏到紧凑的学生检索器中，解决企业检索系统中短查询语义模糊问题，避免在线LLM调用成本。


<details>
  <summary>Details</summary>
Motivation: 企业检索系统面临短查询语义模糊问题，需要处理元数据和语义细微差别，但传统的LLM重排和手动标注成本高昂。

Method: 提出元数据感知跨模型对齐(MACA)：1) 使用元数据感知提示验证教师模型的可靠性；2) 提供列表式分数、硬负样本和校准的相关性边界；3) 学生模型通过MetaFusion目标训练，结合元数据条件排序损失和跨模型边界损失。

Result: 在银行FAQ数据集上，MACA教师模型比MAFA基线在Accuracy@1上提升5个点（专有数据集）和3个点（BankFAQs）。学生模型显著优于预训练编码器，如MiniLM的Accuracy@1从0.23提升到0.48。

Conclusion: MACA方法能有效提升企业检索系统性能，同时避免在线LLM调用成本，支持检索增强生成，为实际部署提供了高效解决方案。

Abstract: Modern enterprise retrieval systems must handle short, underspecified queries such as ``foreign transaction fee refund'' and ``recent check status''. In these cases, semantic nuance and metadata matter but per-query large language model (LLM) re-ranking and manual labeling are costly. We present Metadata-Aware Cross-Model Alignment (MACA), which distills a calibrated metadata aware LLM re-ranker into a compact student retriever, avoiding online LLM calls. A metadata-aware prompt verifies the teacher's trustworthiness by checking consistency under permutations and robustness to paraphrases, then supplies listwise scores, hard negatives, and calibrated relevance margins. The student trains with MACA's MetaFusion objective, which combines a metadata conditioned ranking loss with a cross model margin loss so it learns to push the correct answer above semantically similar candidates with mismatched topic, sub-topic, or entity. On a proprietary consumer banking FAQ corpus and BankFAQs, the MACA teacher surpasses a MAFA baseline at Accuracy@1 by five points on the proprietary set and three points on BankFAQs. MACA students substantially outperform pretrained encoders; e.g., on the proprietary corpus MiniLM Accuracy@1 improves from 0.23 to 0.48, while keeping inference free of LLM calls and supporting retrieval-augmented generation.

</details>


### [20] [AlignUSER: Human-Aligned LLM Agents via World Models for Recommender System Evaluation](https://arxiv.org/abs/2601.00930)
*Nicolas Bougie,Gian Maria Marconi,Tony Yip,Narimasa Watanabe*

Main category: cs.IR

TL;DR: AlignUSER框架使用世界模型驱动的LLM代理来模拟真实用户行为，通过从人类交互中学习，解决推荐系统评估中离线指标与真实用户行为之间的差距问题。


<details>
  <summary>Details</summary>
Motivation: 推荐系统评估面临两大挑战：离线指标与真实用户行为之间的差距，以及交互数据的稀缺性。现有的LLM代理方法通常依赖少样本提示，对环境理解较浅，难以忠实再现用户行为。

Method: 1) 将世界建模形式化为下一个状态预测任务，让代理内化环境理解；2) 生成围绕演示的反事实轨迹，提示LLM比较其决策与人类选择，识别次优动作并提取经验教训；3) 使用学习到的策略驱动代理与推荐系统交互。

Result: 在多个数据集上的评估表明，AlignUSER在微观和宏观层面都比先前工作更接近真实人类行为，实现了更好的人类对齐。

Conclusion: AlignUSER框架通过世界模型驱动的代理学习，能够更准确地模拟真实用户行为，为推荐系统评估提供了更可靠的合成用户方法。

Abstract: Evaluating recommender systems remains challenging due to the gap between offline metrics and real user behavior, as well as the scarcity of interaction data. Recent work explores large language model (LLM) agents as synthetic users, yet they typically rely on few-shot prompting, which yields a shallow understanding of the environment and limits their ability to faithfully reproduce user actions. We introduce AlignUSER, a framework that learns world-model-driven agents from human interactions. Given rollout sequences of actions and states, we formalize world modeling as a next state prediction task that helps the agent internalize the environment. To align actions with human personas, we generate counterfactual trajectories around demonstrations and prompt the LLM to compare its decisions with human choices, identify suboptimal actions, and extract lessons. The learned policy is then used to drive agent interactions with the recommender system. We evaluate AlignUSER across multiple datasets and demonstrate closer alignment with genuine humans than prior work, both at the micro and macro levels.

</details>


### [21] [ScienceDB AI: An LLM-Driven Agentic Recommender System for Large-Scale Scientific Data Sharing Services](https://arxiv.org/abs/2601.01118)
*Qingqing Long,Haotian Chen,Chenyang Zhao,Xiaolei Du,Xuezhi Wang,Pengyao Wang,Chengzan Li,Yuanchun Zhou,Hengshu Zhu*

Main category: cs.IR

TL;DR: ScienceDB AI是首个基于大语言模型的对话式科学数据集推荐系统，通过深度语义理解和个性化推荐解决科学数据集共享利用难题。


<details>
  <summary>Details</summary>
Motivation: 科学数据集包含复杂的领域知识和上下文，传统协同过滤推荐方法难以有效处理。随着AI4S快速发展，需要更智能的方式来促进科学数据集的共享和利用。

Method: 开发了ScienceDB AI系统，包含：1) 科学意图感知器提取结构化实验元素；2) 结构化记忆压缩器管理多轮对话；3) 可信检索增强生成框架，采用两阶段检索机制并提供可引用的CSTR标识符。

Result: 在超过1000万个真实世界数据集上进行离线和在线实验，证明了系统的显著有效性。ScienceDB AI是首个专门为大规模科学数据集共享服务定制的LLM驱动对话推荐系统。

Conclusion: ScienceDB AI利用LLM的深度语义理解和推理能力，通过创新的架构解决了科学数据集推荐的挑战，提高了推荐的可信度和可重复性，平台已公开可用。

Abstract: The rapid growth of AI for Science (AI4S) has underscored the significance of scientific datasets, leading to the establishment of numerous national scientific data centers and sharing platforms. Despite this progress, efficiently promoting dataset sharing and utilization for scientific research remains challenging. Scientific datasets contain intricate domain-specific knowledge and contexts, rendering traditional collaborative filtering-based recommenders inadequate. Recent advances in Large Language Models (LLMs) offer unprecedented opportunities to build conversational agents capable of deep semantic understanding and personalized recommendations. In response, we present ScienceDB AI, a novel LLM-driven agentic recommender system developed on Science Data Bank (ScienceDB), one of the largest global scientific data-sharing platforms. ScienceDB AI leverages natural language conversations and deep reasoning to accurately recommend datasets aligned with researchers' scientific intents and evolving requirements. The system introduces several innovations: a Scientific Intention Perceptor to extract structured experimental elements from complicated queries, a Structured Memory Compressor to manage multi-turn dialogues effectively, and a Trustworthy Retrieval-Augmented Generation (Trustworthy RAG) framework. The Trustworthy RAG employs a two-stage retrieval mechanism and provides citable dataset references via Citable Scientific Task Record (CSTR) identifiers, enhancing recommendation trustworthiness and reproducibility. Through extensive offline and online experiments using over 10 million real-world datasets, ScienceDB AI has demonstrated significant effectiveness. To our knowledge, ScienceDB AI is the first LLM-driven conversational recommender tailored explicitly for large-scale scientific dataset sharing services. The platform is publicly accessible at: https://ai.scidb.cn/en.

</details>


### [22] [Adaptive Diffusion-based Augmentation for Recommendation](https://arxiv.org/abs/2601.01448)
*Na Li,Fanghui Sun,Yan Zou,Yangfu Zhu,Xiatian Zhu,Ying Ma*

Main category: cs.IR

TL;DR: 提出ADAR方法，使用扩散模型生成可控的负样本，解决推荐系统中隐式反馈的负采样问题，提升推荐模型性能


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统基于隐式反馈，只能观察到正面的用户-物品交互，负采样至关重要。但现有方法存在两个问题：1) 可能将潜在正面但未观察到的物品误标为负样本；2) 缺乏对负样本选择的精确控制

Method: 提出ADAR（自适应扩散增强推荐）模块，利用扩散模型合成信息丰富的负样本。受扩散过程中渐进式破坏过程的启发，ADAR模拟从正样本到负样本的连续过渡，实现对样本难度的细粒度控制。通过理论识别正样本转变为负样本的过渡点，并推导出感知分数的函数来自适应确定最优采样时间步

Result: 实验证实ADAR具有广泛的兼容性，能够显著提升现有推荐模型的性能，包括协同过滤和序列推荐，且无需修改模型架构

Conclusion: ADAR通过生成可控的负样本，有效解决了推荐系统中负采样的关键问题，能够生成具有挑战性的负样本来细化模型的决策边界，提升推荐性能

Abstract: Recommendation systems often rely on implicit feedback, where only positive user-item interactions can be observed. Negative sampling is therefore crucial to provide proper negative training signals. However, existing methods tend to mislabel potentially positive but unobserved items as negatives and lack precise control over negative sample selection. We aim to address these by generating controllable negative samples, rather than sampling from the existing item pool. In this context, we propose Adaptive Diffusion-based Augmentation for Recommendation (ADAR), a novel and model-agnostic module that leverages diffusion to synthesize informative negatives. Inspired by the progressive corruption process in diffusion, ADAR simulates a continuous transition from positive to negative, allowing for fine-grained control over sample hardness. To mine suitable negative samples, we theoretically identify the transition point at which a positive sample turns negative and derive a score-aware function to adaptively determine the optimal sampling timestep. By identifying this transition point, ADAR generates challenging negative samples that effectively refine the model's decision boundary. Experiments confirm that ADAR is broadly compatible and boosts the performance of existing recommendation models substantially, including collaborative filtering and sequential recommendation, without architectural modifications.

</details>


### [23] [Breadcrumbs in the Digital Forest: Tracing Criminals through Torrent Metadata with OSINT](https://arxiv.org/abs/2601.01492)
*Annelies de Jong,Giuseppe Cascavilla,Jessica De Pascale*

Main category: cs.IR

TL;DR: 利用BitTorrent元数据进行开源情报分析，通过用户画像和行为分析检测高风险行为


<details>
  <summary>Details</summary>
Motivation: 虽然P2P网络在隐私和性能方面已有研究，但其元数据很少用于调查目的。本研究探索如何利用种子元数据进行开源情报分析，特别是检测高风险行为。

Method: 采用五步OSINT流程：源识别、数据收集、数据丰富、行为分析和结果呈现。从The Pirate Bay和UDP跟踪器收集数据，获得超过6万个唯一IP地址和206个热门种子。通过地理位置、匿名状态和儿童剥削材料标记丰富数据。

Result: 网络分析揭示了节点聚类、共同下载模式以及可疑用户使用隐私工具的情况。敏感电子书的案例研究表明，此类数据可帮助检测对非法内容的兴趣。

Conclusion: 公开可用的种子元数据支持可扩展和自动化的OSINT分析，为数字取证提供新方法，在执法、网络安全和威胁分析中具有应用价值。

Abstract: This work investigates the potential of torrent metadata as a source for open-source intelligence (OSINT), with a focus on user profiling and behavioral analysis. While peer-to-peer (P2P) networks such as BitTorrent are well studied with respect to privacy and performance, their metadata is rarely used for investigative purposes. This work presents a proof of concept demonstrating how tracker responses, torrent index data, and enriched IP metadata can reveal patterns associated with high-risk behavior.
  The research follows a five-step OSINT process: source identification, data collection, enrichment, behavioral analysis, and presentation of the results. Data were collected from The Pirate Bay and UDP trackers, yielding a dataset of more than 60,000 unique IP addresses across 206 popular torrents. The data were enriched with geolocation, anonymization status, and flags of involvement in child exploitation material (CEM). A case study on sensitive e-books shows how such data can help detect possible interest in illicit content.
  Network analysis highlights peer clustering, co-download patterns, and the use of privacy tools by suspicious users. The study shows that publicly available torrent metadata can support scalable and automated OSINT profiling.
  This work adds to digital forensics by proposing a new method to extract useful signals from noisy data, with applications in law enforcement, cybersecurity, and threat analysis.

</details>


### [24] [OpenNovelty: An LLM-powered Agentic System for Verifiable Scholarly Novelty Assessment](https://arxiv.org/abs/2601.01576)
*Ming Zhang,Kexin Tan,Yueyuan Huang,Yujiong Shen,Chunchun Ma,Li Ju,Xinran Zhang,Yuhui Wang,Wenqing Jing,Jingyi Deng,Huayu Sha,Binze Hu,Jingqi Tong,Changhao Jiang,Yage Geng,Yuankai Ying,Yue Zhang,Zhangyue Yin,Zhiheng Xi,Shihan Dou,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.IR

TL;DR: OpenNovelty是一个基于LLM的智能系统，通过四阶段流程（提取核心任务、检索相关文献、构建层次分类并进行贡献对比、生成结构化报告）来评估论文新颖性，旨在为同行评审提供透明、可验证的证据支持。


<details>
  <summary>Details</summary>
Motivation: 同行评审中评估新颖性具有挑战性，因为评审者需要在庞大且快速发展的文献中评估提交的论文。当前需要一种透明、基于证据的系统来支持这一过程。

Method: 系统采用四阶段流程：1) 提取核心任务和贡献声明生成检索查询；2) 通过语义搜索引擎检索相关先前工作；3) 构建核心任务相关工作的层次分类，并进行贡献级别的全文对比；4) 将所有分析综合成结构化新颖性报告，包含明确引用和证据片段。

Result: 系统已在500+篇ICLR 2026提交论文上部署，所有报告公开可用。初步分析表明系统能够识别相关先前工作，包括作者可能忽略的密切相关论文。

Conclusion: OpenNovelty旨在为研究社区提供一个可扩展的工具，促进公平、一致和基于证据的同行评审，通过检索真实论文确保所有评估都可验证。

Abstract: Evaluating novelty is critical yet challenging in peer review, as reviewers must assess submissions against a vast, rapidly evolving literature. This report presents OpenNovelty, an LLM-powered agentic system for transparent, evidence-based novelty analysis. The system operates through four phases: (1) extracting the core task and contribution claims to generate retrieval queries; (2) retrieving relevant prior work based on extracted queries via semantic search engine; (3) constructing a hierarchical taxonomy of core-task-related work and performing contribution-level full-text comparisons against each contribution; and (4) synthesizing all analyses into a structured novelty report with explicit citations and evidence snippets. Unlike naive LLM-based approaches, \textsc{OpenNovelty} grounds all assessments in retrieved real papers, ensuring verifiable judgments. We deploy our system on 500+ ICLR 2026 submissions with all reports publicly available on our website, and preliminary analysis suggests it can identify relevant prior work, including closely related papers that authors may overlook. OpenNovelty aims to empower the research community with a scalable tool that promotes fair, consistent, and evidence-backed peer review.

</details>


### [25] [LACONIC: Dense-Level Effectiveness for Scalable Sparse Retrieval via a Two-Phase Training Curriculum](https://arxiv.org/abs/2601.01684)
*Zhichao Xu,Shengyao Zhuang,Crystina Zhang,Xueguang Ma,Yijun Tian,Maitrey Mehta,Jimmy Lin,Vivek Srikumar*

Main category: cs.IR

TL;DR: LACONIC是一个基于Llama-3架构的稀疏检索模型家族，通过两阶段训练实现高效检索，在保持高性能的同时大幅减少内存和计算需求。


<details>
  <summary>Details</summary>
Motivation: 密集检索模型虽然性能优越，但部署时面临高内存需求和GPU依赖的限制。稀疏检索通过倒排索引实现高效搜索，但历史上关注度较低。需要开发既能保持高性能又能在CPU硬件上高效运行的检索模型。

Method: 基于Llama-3架构（1B、3B、8B）构建稀疏检索模型。采用两阶段训练课程：1）弱监督预微调，使因果LLM适应双向上下文化；2）使用精选困难负例进行高质量微调。

Result: LACONIC 8B在MTEB检索基准上达到60.2 nDCG的SOTA性能，在2026年1月1日的排行榜上排名第15位，同时比等效密集模型减少71%的索引内存。能够在商用CPU硬件上高效运行。

Conclusion: LACONIC有效弥合了稀疏检索与密集检索之间的性能差距，为实际搜索应用提供了可扩展且高效的解决方案，大幅降低了计算预算需求。

Abstract: While dense retrieval models have become the standard for state-of-the-art information retrieval, their deployment is often constrained by high memory requirements and reliance on GPU accelerators for vector similarity search. Learned sparse retrieval offers a compelling alternative by enabling efficient search via inverted indices, yet it has historically received less attention than dense approaches. In this report, we introduce LACONIC, a family of learned sparse retrievers based on the Llama-3 architecture (1B, 3B, and 8B). We propose a streamlined two-phase training curriculum consisting of (1) weakly supervised pre-finetuning to adapt causal LLMs for bidirectional contextualization and (2) high-signal finetuning using curated hard negatives. Our results demonstrate that LACONIC effectively bridges the performance gap with dense models: the 8B variant achieves a state-of-the-art 60.2 nDCG on the MTEB Retrieval benchmark, ranking 15th on the leaderboard as of January 1, 2026, while utilizing 71\% less index memory than an equivalent dense model. By delivering high retrieval effectiveness on commodity CPU hardware with a fraction of the compute budget required by competing models, LACONIC provides a scalable and efficient solution for real-world search applications.

</details>


### [26] [When Attention Becomes Exposure in Generative Search](https://arxiv.org/abs/2601.01750)
*Shayan Alipour,Mehdi Kargar,Morteza Zihayat*

Main category: cs.IR

TL;DR: 生成式搜索引擎的引用存在曝光偏见，倾向于已有知名度的声音，这可能导致既有优势固化并缩小观点多样性


<details>
  <summary>Details</summary>
Motivation: 随着生成式搜索引擎取代传统排名列表，以及Web3平台激励创作者生态系统的发展，需要研究生成式搜索引擎引用中的曝光是否受到外部注意力市场的影响

Method: 对44家Web3企业进行审计分析：1) 分析企业创作者社区的持久性；2) 通过企业特定查询研究引用曝光分布；3) 分析粉丝基础和创作者核心集中度与曝光排名的关系

Result: 1) 企业创作者社区具有时间持久性；2) 更受欢迎的声音系统性地获得更多引用曝光；3) 更大的粉丝基础和更集中的创作者核心与更高排名曝光相关

Conclusion: 生成式搜索引擎引用存在向已有知名度声音的曝光偏见，这可能固化既有优势并减少观点多样性

Abstract: Generative search engines are reshaping information access by replacing traditional ranked lists with synthesized answers and references. In parallel, with the growth of Web3 platforms, incentive-driven creator ecosystems have become an essential part of how enterprises build visibility and community by rewarding creators for contributing to shared narratives. However, the extent to which exposure in generative search engine citations is shaped by external attention markets remains uncertain. In this study, we audit the exposure for 44 Web3 enterprises. First, we show that the creator community around each enterprise is persistent over time. Second, enterprise-specific queries reveal that more popular voices systematically receive greater citation exposure than others. Third, we find that larger follower bases and enterprises with more concentrated creator cores are associated with higher-ranked exposure. Together, these results show that generative search engine citations exhibit exposure bias toward already prominent voices, which risks entrenching incumbents and narrowing viewpoint diversity.

</details>


### [27] [Query-Document Dense Vectors for LLM Relevance Judgment Bias Analysis](https://arxiv.org/abs/2601.01751)
*Samaneh Mohtadi,Gianluca Demartini*

Main category: cs.IR

TL;DR: 本文提出了一种基于聚类的框架来分析LLM在信息检索评估中作为相关性评估者的系统性错误，发现LLM与人类评估者的分歧集中在特定语义集群而非随机分布。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM作为相关性评估者比人工评估成本更低、扩展性更强，但现有研究主要关注LLM与人类评估者平均表现的一致性，而忽略了LLM是否会在判断相关性时犯系统性错误。本文旨在深入理解LLM在相关性判断中的系统性偏差模式。

Method: 提出了一种新颖的表示方法，将查询-文档对嵌入到联合语义空间中，将相关性视为关系属性。引入基于聚类的框架来分析相关性标签分布，比较LLM和人类标签以识别分歧模式并定位系统性分歧区域。

Result: 在TREC Deep Learning 2019和2020数据集上的实验表明，人类与LLM之间的系统性分歧集中在特定语义集群中，而非随机分布。查询级分析揭示了重复出现的失败模式，最常见于定义寻求、政策相关或模糊语境中。跨集群一致性差异大的查询成为分歧热点，LLM倾向于低估相关内容或过度包含无关材料。

Conclusion: 该框架通过全局诊断与局部聚类相结合，揭示了LLM判断中的隐藏弱点，为实现偏差感知和更可靠的信息检索评估提供了方法。

Abstract: Large Language Models (LLMs) have been used as relevance assessors for Information Retrieval (IR) evaluation collection creation due to reduced cost and increased scalability as compared to human assessors. While previous research has looked at the reliability of LLMs as compared to human assessors, in this work, we aim to understand if LLMs make systematic mistakes when judging relevance, rather than just understanding how good they are on average. To this aim, we propose a novel representational method for queries and documents that allows us to analyze relevance label distributions and compare LLM and human labels to identify patterns of disagreement and localize systematic areas of disagreement. We introduce a clustering-based framework that embeds query-document (Q-D) pairs into a joint semantic space, treating relevance as a relational property. Experiments on TREC Deep Learning 2019 and 2020 show that systematic disagreement between humans and LLMs is concentrated in specific semantic clusters rather than distributed randomly. Query-level analyses reveal recurring failures, most often in definition-seeking, policy-related, or ambiguous contexts. Queries with large variation in agreement across their clusters emerge as disagreement hotspots, where LLMs tend to under-recall relevant content or over-include irrelevant material. This framework links global diagnostics with localized clustering to uncover hidden weaknesses in LLM judgments, enabling bias-aware and more reliable IR evaluation.

</details>


### [28] [MergeRec: Model Merging for Data-Isolated Cross-Domain Sequential Recommendation](https://arxiv.org/abs/2601.01753)
*Hyunsoo Kim,Jaewan Moon,Seongmin Park,Jongwuk Lee*

Main category: cs.IR

TL;DR: MergeRec：基于模型融合的数据隔离跨域序列推荐新框架，无需共享原始用户数据，通过伪用户数据构造和协同融合优化实现跨域泛化


<details>
  <summary>Details</summary>
Motivation: 现有跨域推荐方法依赖域间重叠用户/物品或忽略隐私约束，无法处理数据隔离的实际场景，需要新的解决方案

Method: 1) 融合初始化：使用免训练融合技术初始化融合模型；2) 伪用户数据构造：将每个物品视为虚拟序列生成训练样本；3) 协同融合优化：通过推荐损失和蒸馏损失的联合目标优化域特定融合权重

Result: MergeRec在保持原始模型优势的同时显著提升未见域的泛化能力，相比传统模型融合方法平均Recall@10提升高达17.21%

Conclusion: 模型融合是构建通用推荐系统的可扩展有效方法，MergeRec为数据隔离跨域序列推荐提供了实用解决方案

Abstract: Modern recommender systems trained on domain-specific data often struggle to generalize across multiple domains. Cross-domain sequential recommendation has emerged as a promising research direction to address this challenge; however, existing approaches face fundamental limitations, such as reliance on overlapping users or items across domains, or unrealistic assumptions that ignore privacy constraints. In this work, we propose a new framework, MergeRec, based on model merging under a new and realistic problem setting termed data-isolated cross-domain sequential recommendation, where raw user interaction data cannot be shared across domains. MergeRec consists of three key components: (1) merging initialization, (2) pseudo-user data construction, and (3) collaborative merging optimization. First, we initialize a merged model using training-free merging techniques. Next, we construct pseudo-user data by treating each item as a virtual sequence in each domain, enabling the synthesis of meaningful training samples without relying on real user interactions. Finally, we optimize domain-specific merging weights through a joint objective that combines a recommendation loss, which encourages the merged model to identify relevant items, and a distillation loss, which transfers collaborative filtering signals from the fine-tuned source models. Extensive experiments demonstrate that MergeRec not only preserves the strengths of the original models but also significantly enhances generalizability to unseen domains. Compared to conventional model merging methods, MergeRec consistently achieves superior performance, with average improvements of up to 17.21% in Recall@10, highlighting the potential of model merging as a scalable and effective approach for building universal recommender systems. The source code is available at https://github.com/DIALLab-SKKU/MergeRec.

</details>


### [29] [SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines](https://arxiv.org/abs/2601.01785)
*Rajiv Chaitanya Muttur*

Main category: cs.IR

TL;DR: SRAS：一种基于强化学习的超轻量级文档选择器，用于边缘设备上的RAG系统，在严格的计算和延迟约束下（<1秒CPU延迟，~0.76MB模型大小）实现高效文档选择。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统使用固定的top-k文档选择机制，忽略了生成质量且计算开销大，不适合边缘设备部署。需要一种轻量级、延迟感知的文档选择方法。

Method: 使用强化学习（PPO算法）训练紧凑的文档选择策略，结合Relaxed F1和BERTScore的混合奖励信号，在严格token和计算约束下运行。

Result: 在合成QA基准测试中优于监督和随机选择器，在SQuAD v2上达到0.8546 BERTScore F1，无需领域特定调优。模型仅~0.76MB，CPU延迟<1秒。

Conclusion: 首次证明基于强化学习的文档选择可以实现超轻量级、延迟感知，并有效用于设备端RAG管道，为边缘部署提供了实用解决方案。

Abstract: Retrieval-Augmented Generation (RAG) systems often rely on fixed top-k document selection mechanisms that ignore downstream generation quality and impose computational overheads. We propose SRAS (Sparse Reward-Aware Selector), a lightweight document selector trained via reinforcement learning (RL) for edge-native RAG deployment. Unlike prior RL-based retrievers that assume large memory and latency budgets, SRAS learns a compact (~0.76MB) policy using Proximal Policy Optimization (PPO), guided by a hybrid reward signal combining Relaxed F1 and BERTScore. Our method operates under tight token and compute constraints, maintaining <1s latency on CPU. SRAS outperforms supervised and random selectors on a synthetic QA benchmark, and generalizes to real-world data, achieving BERTScore F1 of 0.8546 on SQuAD v2 without domain-specific tuning. This work is the first to demonstrate that RL-based document selection can be made ultra-lightweight, latency-aware, and effective for on-device RAG pipelines.

</details>


### [30] [A Hybrid Architecture for Multi-Stage Claim Document Understanding: Combining Vision-Language Models and Machine Learning for Real-Time Processing](https://arxiv.org/abs/2601.01897)
*Lilu Cheng,Jingjun Lu,Yi Xuan Chan,Quoc Khai Nguyen,John Bi,Sean Ho*

Main category: cs.IR

TL;DR: 提出一个结合传统机器学习与视觉语言模型的多阶段流水线，用于从异质医疗理赔文档中高效提取结构化信息，实现95%文档分类准确率和87%字段提取准确率，处理速度比人工快300倍。


<details>
  <summary>Details</summary>
Motivation: 医疗理赔文档通常以扫描PDF或照片形式存在，存在内容异质性（打字发票到手写医疗报告）、语言多样性、图像质量不一致和布局多样等问题，给自动化解析和信息提取带来重大挑战。Fullerton Health每年处理数千万份理赔，跨越九个市场，需要高效解决方案。

Method: 采用多阶段流水线：1) 使用多语言OCR引擎PaddleOCR进行文本识别；2) 传统逻辑回归分类器进行文档类型分类；3) 紧凑型视觉语言模型Qwen 2.5-VL-7B进行字段提取。结合传统机器学习与现代VLM技术。

Result: 文档类型分类准确率超过95%，字段级提取准确率约87%，平均处理延迟低于2秒/文档。相比人工处理每份理赔约10分钟，系统效率提升300倍。已在移动应用中部署，每周处理越南和新加坡数万份理赔。

Conclusion: 结合传统机器学习模型与现代视觉语言模型能够实现生产级的准确性和速度，满足现实世界自动化需求。该系统已成功部署并处理大规模理赔数据，证明了多阶段混合方法的有效性。

Abstract: Claims documents are fundamental to healthcare and insurance operations, serving as the basis for reimbursement, auditing, and compliance. However, these documents are typically not born digital; they often exist as scanned PDFs or photographs captured under uncontrolled conditions. Consequently, they exhibit significant content heterogeneity, ranging from typed invoices to handwritten medical reports, as well as linguistic diversity. This challenge is exemplified by operations at Fullerton Health, which handles tens of millions of claims annually across nine markets, including Singapore, the Philippines, Indonesia, Malaysia, Mainland China, Hong Kong, Vietnam, Papua New Guinea, and Cambodia. Such variability, coupled with inconsistent image quality and diverse layouts, poses a significant obstacle to automated parsing and structured information extraction.
  This paper presents a robust multi-stage pipeline that integrates the multilingual optical character recognition (OCR) engine PaddleOCR, a traditional Logistic Regression classifier, and a compact Vision-Language Model (VLM), Qwen 2.5-VL-7B, to achieve efficient and accurate field extraction from large-scale claims data. The proposed system achieves a document-type classification accuracy of over 95 percent and a field-level extraction accuracy of approximately 87 percent, while maintaining an average processing latency of under 2 seconds per document. Compared to manual processing, which typically requires around 10 minutes per claim, our system delivers a 300x improvement in efficiency. These results demonstrate that combining traditional machine learning models with modern VLMs enables production-grade accuracy and speed for real-world automation. The solution has been successfully deployed in our mobile application and is currently processing tens of thousands of claims weekly from Vietnam and Singapore.

</details>


### [31] [MCGI: Manifold-Consistent Graph Indexing for Billion-Scale Disk-Resident Vector Search](https://arxiv.org/abs/2601.01930)
*Dongfang Zhao*

Main category: cs.IR

TL;DR: MCGI是一种基于流形一致性的图索引方法，通过局部本征维度动态调整搜索策略，解决高维空间中图ANN搜索的性能下降问题，在保持低维数据集性能的同时，显著提升高维和大规模数据集的查询效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于图的近似最近邻搜索在高维空间中存在"欧几里得-测地线不匹配"问题，即贪婪路由偏离底层数据流形，导致性能下降。需要一种能够适应数据内在几何结构的索引方法。

Method: 提出流形一致图索引(MCGI)，这是一种几何感知的磁盘驻留索引方法。利用局部本征维度(LID)进行原位几何分析，动态调整波束搜索预算，消除对静态超参数的依赖，保持流形一致的拓扑连接性。

Result: 在高维GIST1M数据集上，MCGI在95%召回率下实现了5.8倍于DiskANN的吞吐量提升。在十亿规模的SIFT1B数据集上，将高召回查询延迟降低了3倍，同时在标准低维数据集上保持性能相当。

Conclusion: MCGI通过几何感知的索引设计有效解决了高维ANN搜索中的流形不匹配问题，理论分析证实了其改进的近似保证，实证结果表明其在保持低维性能的同时显著提升了高维和大规模数据集的搜索效率。

Abstract: Graph-based Approximate Nearest Neighbor (ANN) search often suffers from performance degradation in high-dimensional spaces due to the ``Euclidean-Geodesic mismatch,'' where greedy routing diverges from the underlying data manifold. To address this, we propose Manifold-Consistent Graph Indexing (MCGI), a geometry-aware and disk-resident indexing method that leverages Local Intrinsic Dimensionality (LID) to dynamically adapt search strategies to the data's intrinsic geometry. Unlike standard algorithms that treat dimensions uniformly, MCGI modulates its beam search budget based on in situ geometric analysis, eliminating dependency on static hyperparameters. Theoretical analysis confirms that MCGI enables improved approximation guarantees by preserving manifold-consistent topological connectivity. Empirically, MCGI achieves 5.8$\times$ higher throughput at 95\% recall on high-dimensional GIST1M compared to state-of-the-art DiskANN. On the billion-scale SIFT1B dataset, MCGI further validates its scalability by reducing high-recall query latency by 3$\times$, while maintaining performance parity on standard lower-dimensional datasets.

</details>


### [32] [Exploring Diversity, Novelty, and Popularity Bias in ChatGPT's Recommendations](https://arxiv.org/abs/2601.01997)
*Dario Di Palma,Giovanni Maria Biancofiore,Vito Walter Anelli,Fedelucio Narducci,Tommaso Di Noia*

Main category: cs.IR

TL;DR: 该研究评估了ChatGPT-3.5和ChatGPT-4在推荐系统中的表现，重点关注多样性、新颖性和流行度偏差，发现ChatGPT-4在平衡推荐质量方面与传统推荐器相当或更优，尤其在冷启动场景下表现突出。


<details>
  <summary>Details</summary>
Motivation: 尽管ChatGPT在推荐系统中的应用受到关注，但现有研究主要关注准确性，对其在多样性、新颖性和流行度偏差等方面的综合性能缺乏全面分析。随着这些模型的广泛应用，理解这些维度对于提升用户满意度和实现长期个性化至关重要。

Method: 研究评估了ChatGPT-3.5和ChatGPT-4在三个不同数据集上的表现，考察了Top-N推荐和冷启动场景下的性能。评估维度包括多样性、新颖性和流行度偏差，并与传统推荐系统进行比较。

Result: ChatGPT-4在匹配或超越传统推荐器的同时，能够平衡推荐的新颖性和多样性。在冷启动场景下，ChatGPT模型在准确性和新颖性方面都表现出色，特别适合新用户场景。

Conclusion: 该研究揭示了ChatGPT推荐系统的优势和局限性，为理解这些模型在超越准确性指标方面的推荐能力提供了新视角，表明ChatGPT-4在平衡推荐质量方面具有潜力，特别是在冷启动场景下。

Abstract: ChatGPT has emerged as a versatile tool, demonstrating capabilities across diverse domains. Given these successes, the Recommender Systems (RSs) community has begun investigating its applications within recommendation scenarios primarily focusing on accuracy. While the integration of ChatGPT into RSs has garnered significant attention, a comprehensive analysis of its performance across various dimensions remains largely unexplored. Specifically, the capabilities of providing diverse and novel recommendations or exploring potential biases such as popularity bias have not been thoroughly examined. As the use of these models continues to expand, understanding these aspects is crucial for enhancing user satisfaction and achieving long-term personalization.
  This study investigates the recommendations provided by ChatGPT-3.5 and ChatGPT-4 by assessing ChatGPT's capabilities in terms of diversity, novelty, and popularity bias. We evaluate these models on three distinct datasets and assess their performance in Top-N recommendation and cold-start scenarios. The findings reveal that ChatGPT-4 matches or surpasses traditional recommenders, demonstrating the ability to balance novelty and diversity in recommendations. Furthermore, in the cold-start scenario, ChatGPT models exhibit superior performance in both accuracy and novelty, suggesting they can be particularly beneficial for new users. This research highlights the strengths and limitations of ChatGPT's recommendations, offering new perspectives on the capacity of these models to provide recommendations beyond accuracy-focused metrics.

</details>


### [33] [Exploring Approaches for Detecting Memorization of Recommender System Data in Large Language Models](https://arxiv.org/abs/2601.02002)
*Antonio Colacicco,Vito Guida,Dario Di Palma,Fedelucio Narducci,Tommaso Di Noia*

Main category: cs.IR

TL;DR: 本文研究LLM在推荐场景中的数据记忆问题，评估了三种方法（越狱提示工程、无监督潜在知识发现、自动提示工程）来检测和提取MovieLens-1M数据集中被记忆的数据。


<details>
  <summary>Details</summary>
Motivation: LLM在推荐系统中应用日益广泛，但其训练数据不公开引发数据泄露担忧。已有研究表明MovieLens-1M数据集被LLaMA和OpenAI模型记忆，但现有提取方法仅依赖手动提示工程，需要探索更有效的检测和提取方法。

Method: 评估三种方法：1) 越狱提示工程；2) 无监督潜在知识发现，通过对比一致搜索(CCS)和聚类范数探测内部激活；3) 自动提示工程(APE)，将提示发现构建为迭代优化候选指令的元学习过程。

Result: 在LLaMA模型上的实验显示：越狱提示无法改进记忆项检索且结果不一致；CCS能可靠区分真实与虚构电影标题但无法处理数值用户和评分数据；APE能中等程度成功检索项目级信息但难以恢复数值交互数据。

Conclusion: 自动优化提示是提取记忆样本最有前景的策略，但现有方法在数值数据提取方面仍有局限，需要进一步研究更有效的自动检测和提取技术。

Abstract: Large Language Models (LLMs) are increasingly applied in recommendation scenarios due to their strong natural language understanding and generation capabilities. However, they are trained on vast corpora whose contents are not publicly disclosed, raising concerns about data leakage. Recent work has shown that the MovieLens-1M dataset is memorized by both the LLaMA and OpenAI model families, but the extraction of such memorized data has so far relied exclusively on manual prompt engineering. In this paper, we pose three main questions: Is it possible to enhance manual prompting? Can LLM memorization be detected through methods beyond manual prompting? And can the detection of data leakage be automated? To address these questions, we evaluate three approaches: (i) jailbreak prompt engineering; (ii) unsupervised latent knowledge discovery, probing internal activations via Contrast-Consistent Search (CCS) and Cluster-Norm; and (iii) Automatic Prompt Engineering (APE), which frames prompt discovery as a meta-learning process that iteratively refines candidate instructions. Experiments on MovieLens-1M using LLaMA models show that jailbreak prompting does not improve the retrieval of memorized items and remains inconsistent; CCS reliably distinguishes genuine from fabricated movie titles but fails on numerical user and rating data; and APE retrieves item-level information with moderate success yet struggles to recover numerical interactions. These findings suggest that automatically optimizing prompts is the most promising strategy for extracting memorized samples.

</details>


### [34] [Cold-Starting Podcast Ads and Promotions with Multi-Task Learning on Spotify](https://arxiv.org/abs/2601.02306)
*Shivam Verma,Hannes Karlbom,Yu Zhao,Nick Topping,Vivian Chen,Kieran Stanley,Bharath Rengarajan*

Main category: cs.IR

TL;DR: Spotify提出统一多目标模型，同时优化播客广告和促销的个性化推荐，通过迁移学习和多任务学习解决冷启动问题，显著降低成本和提升流媒体率。


<details>
  <summary>Details</summary>
Motivation: 解决播客生态系统中的个性化推荐和冷启动初始化挑战，特别是针对新的广告目标和低数据场景，打破历史上孤立的定向管道。

Method: 采用多任务学习框架，利用大规模广告和内容交互数据进行迁移学习，构建共享表示模型，联合优化广告和促销的多个目标（流媒体、点击、关注）。

Result: 在线A/B测试显示有效每流成本降低22%（特别是低流量播客），播客流媒体率提升18-24%；离线实验验证辅助目标和特征组对冷启动性能的贡献。

Conclusion: 统一建模策略提高了可维护性、冷启动性能和覆盖率，打破了孤立的定向管道，但需要权衡实际广告系统中的实际考虑因素。

Abstract: We present a unified multi-objective model for targeting both advertisements and promotions within the Spotify podcast ecosystem. Our approach addresses key challenges in personalization and cold-start initialization, particularly for new advertising objectives. By leveraging transfer learning from large-scale ad and content interactions within a multi-task learning (MTL) framework, a single joint model can be fine-tuned or directly applied to new or low-data targeting tasks, including in-app promotions. This multi-objective design jointly optimizes podcast outcomes such as streams, clicks, and follows for both ads and promotions using a shared representation over user, content, context, and creative features, effectively supporting diverse business goals while improving user experience. Online A/B tests show up to a 22% reduction in effective Cost-Per-Stream (eCPS), particularly for less-streamed podcasts, and an 18-24% increase in podcast stream rates. Offline experiments and ablations highlight the contribution of ancillary objectives and feature groups to cold-start performance. Our experience shows that a unified modeling strategy improves maintainability, cold-start performance, and coverage, while breaking down historically siloed targeting pipelines. We discuss practical trade-offs of such joint models in a real-world advertising system.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [35] [The cost of cyclic permutations and remainder sums in the Euclidean algorithm](https://arxiv.org/abs/2601.00979)
*Valentin Blomer,Kai-Uwe Bux*

Main category: cs.DS

TL;DR: 改进Gries-Mills块交换算法，实现原地旋转，平均每个元素移动1.85次，最坏情况仍为3次


<details>
  <summary>Details</summary>
Motivation: 改进现有的Gries-Mills块交换算法，降低原地旋转操作的平均成本，同时保持最坏情况性能不变

Method: 对Gries-Mills块交换方案进行修改，利用欧几里得算法中余数和的渐近行为来分析平均情况性能

Result: 实现了平均每个元素移动1.85次的性能，最坏情况仍保持每个元素移动3次的性能

Conclusion: 成功改进了Gries-Mills算法，显著降低了原地旋转的平均成本，同时保持了最坏情况的性能保证

Abstract: We discuss a modification to the Gries-Mills block swapping scheme for in-place rotation with average costs of 1.85 moves per element and worst case performance still at 3 moves per element. Analysis of the average case relies on the asymptotic behavior of the sum of remainders in the Euclidean algorithm.

</details>


### [36] [AGIS: Fast Approximate Graph Pattern Mining with Structure-Informed Sampling](https://arxiv.org/abs/2601.01388)
*Seoyong Lee,Jinho Lee*

Main category: cs.DS

TL;DR: AGIS是一种基于结构感知邻居采样的近似图模式挖掘系统，相比传统均匀采样方法，在十亿级边的大图上实现了28.5倍几何平均加速和特定情况下10万倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有基于采样的近似图模式挖掘系统都依赖均匀采样，忽略了底层概率分布，这限制了它们对更广泛模式的可扩展性。

Method: 提出结构感知邻居采样技术，根据模式结构分配特定采样概率；推导AGPM的理想采样分布并提供实用近似方法；开发平衡收敛速度和计算开销的方法来确定何时使用近似分布。

Result: AGIS显著优于最先进的AGPM系统，实现28.5倍几何平均加速，特定情况下超过10万倍加速；是唯一能扩展到数十亿边图的AGPM系统，能在几秒内提供准确估计。

Conclusion: AGIS通过结构感知采样技术解决了传统均匀采样的局限性，实现了对大规模图上任意模式的高效计数，并将开源以促进该领域进一步研究。

Abstract: Approximate Graph Pattern Mining (AGPM) is essential for analyzing large-scale graphs where exact counting is computationally prohibitive. While there exist numerous sampling-based AGPM systems, they all rely on uniform sampling and overlook the underlying probability distribution. This limitation restricts their scalability to a broader range of patterns.
  In this paper, we introduce AGIS, an extremely fast AGPM system capable of counting arbitrary patterns from huge graphs. AGIS employs structure-informed neighbor sampling, a novel sampling technique that deviates from uniformness but allocates specific sampling probabilities based on the pattern structure. We first derive the ideal sampling distribution for AGPM and then present a practical method to approximate it. Furthermore, we develop a method that balances convergence speed and computational overhead, determining when to use the approximated distribution.
  Experimental results demonstrate that AGIS significantly outperforms the state-of-the-art AGPM system, achieving 28.5x geometric mean speedup and more than 100,000x speedup in specific cases. Furthermore, AGIS is the only AGPM system that scales to graphs with tens of billions of edges and robustly handles diverse patterns, successfully providing accurate estimates within seconds. We will open-source AGIS to encourage further research in this field.

</details>


### [37] [Derandomizing Pseudopolynomial Algorithms for Subset Sum](https://arxiv.org/abs/2601.01390)
*Timothy M. Chan*

Main category: cs.DS

TL;DR: 提出了第一个确定性算法，在$\widetilde{O}(t)$时间内解决子集和问题，改进了之前的最佳确定性算法$\widetilde{O}(t\sqrt{n})$和随机算法$\widetilde{O}(t)$。


<details>
  <summary>Details</summary>
Motivation: 子集和问题是经典的NP完全问题，现有最佳确定性算法需要$\widetilde{O}(t\sqrt{n})$时间，随机算法需要$\widetilde{O}(t)$时间。研究目标是开发第一个确定性$\widetilde{O}(t)$时间算法，填补确定性算法与随机算法之间的性能差距。

Method: 开发了新的确定性技术，能够以$\widetilde{O}(t)$时间解决子集和问题。该技术还可用于去随机化其他相关算法，包括输出敏感算法和细粒度归约。

Result: 成功实现了第一个确定性$\widetilde{O}(t)$时间算法，显著改进了确定性算法的性能。该技术还能去随机化多个相关算法，包括$\widetilde{O}(|\mbox{out}|^{4/3})$和$\widetilde{O}(|\mbox{out}|\sqrt{n})$时间的输出敏感算法，以及0-1背包问题到min-plus卷积的细粒度归约。

Conclusion: 本文首次实现了子集和问题的确定性$\widetilde{O}(t)$时间算法，填补了确定性算法与随机算法之间的性能差距。提出的技术具有广泛的应用价值，能够去随机化多个相关算法，为确定性算法设计提供了新工具。

Abstract: We reexamine the classical subset sum problem: given a set $X$ of $n$ positive integers and a number $t$, decide whether there exists a subset of $X$ that sums to $t$; or more generally, compute the set $\mbox{out}$ of all numbers $y\in\{0,\ldots,t\}$ for which there exists a subset of $X$ that sums to $y$. Standard dynamic programming solves the problem in $O(tn)$ time. In SODA'17, two papers appeared giving the current best deterministic and randomized algorithms, ignoring polylogarithmic factors: Koiliaris and Xu's deterministic algorithm runs in $\widetilde{O}(t\sqrt{n})$ time, while Bringmann's randomized algorithm runs in $\widetilde{O}(t)$ time. We present the first deterministic algorithm running in $\widetilde{O}(t)$ time.
  Our technique has a number of other applications: for example, we can also derandomize the more recent output-sensitive algorithms by Bringmann and Nakos [STOC'20] and Bringmann, Fischer, and Nakos [SODA'25] running in $\widetilde{O}(|\mbox{out}|^{4/3})$ and $\widetilde{O}(|\mbox{out}|\sqrt{n})$ time, and we can derandomize a previous fine-grained reduction from 0-1 knapsack to min-plus convolution by Cygan et al. [ICALP'17].

</details>


### [38] [Publishing Below-Threshold Triangle Counts under Local Weight Differential Privacy](https://arxiv.org/abs/2601.01710)
*Kevin Pfisterer,Quentin Hillebrand,Vorapong Suppakitpaisarn*

Main category: cs.DS

TL;DR: 提出在局部权重差分隐私下计算加权图中低于阈值三角形的算法，针对拓扑公开但权重隐私的场景，采用两轮通信机制并引入偏差和无偏变体，通过预计算和光滑敏感度优化提升性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界网络通常包含边权重（如道路网络、电信网络），而现有研究主要关注无权图。需要保护个体对边权重的影响隐私，同时图拓扑是公开已知的。

Method: 采用两轮通信：第一轮每个节点在局部权重差分隐私下发布其关联的权重信息；第二轮节点本地计算低于阈值三角形，引入偏差和无偏两种变体。提出预计算步骤降低协方差，并开发光滑敏感度计算算法减少运行时间。

Result: 通过实验展示了偏差和无偏变体之间的差异，验证了所提改进方法的有效性。预计算降低了预期误差，光滑敏感度算法显著减少了运行时间。

Conclusion: 该算法首次在局部权重差分隐私下处理加权图中的三角形计数问题，通过两轮通信机制和优化技术，在保护权重隐私的同时实现了有效的三角形计数。

Abstract: We propose an algorithm for counting below-threshold triangles in weighted graphs under local weight differential privacy. While prior work focused on unweighted graphs, many real-world networks naturally include edge weights. We study the setting where the graph topology is public known and the privacy of the influence of an individual on the edge weights is protected. This captures realistic scenarios such as road networks and telecommunication networks. Our approach consists of two rounds of communication. In the first round, each node publishes their incident weight information under local weight differential privacy while in the second round, the nodes locally count below-threshold triangles, for which we introduce a biased and unbiased variant. We further propose two different improvements. We present a pre-computation step that reduces the covariance and thereby lowers the expected error. Secondly, we develop an algorithm for computing the smooth-sensitivity, which significantly reduces the running time compared to a straightforward approach. Finally, we provide experimental results that demonstrate the differences between the biased and unbiased variants and the effectiveness of the proposed improvements.

</details>


### [39] [Improved Approximation Algorithms for the Multiple-Depot Split Delivery Vehicle Routing Problem](https://arxiv.org/abs/2601.01841)
*Jingyang Zhao,Yonghang Su,Mingyu Xiao*

Main category: cs.DS

TL;DR: 针对多仓库拆分配送车辆路径问题，提出了改进的近似算法，包括(6-2·10⁻³⁶)近似比算法、超越常数个仓库的常数因子算法、参数化改进算法和双因子近似算法。


<details>
  <summary>Details</summary>
Motivation: MD-SDVRP在物流领域有广泛应用，但现有研究有限。之前只有针对常数个仓库的6-近似算法，且能否改进该比率是开放问题。本文旨在解决这一开放问题并扩展算法适用范围。

Method: 开发了多种近似算法：1) 针对常数个仓库的(6-2·10⁻³⁶)-近似算法；2) 超越常数个仓库的常数因子近似算法；3) 基于车辆容量和仓库数量的参数化改进算法；4) 双因子近似算法。

Result: 成功解决了开放问题，将常数个仓库的近似比从6改进到(6-2·10⁻³⁶)。同时开发了更通用的算法框架，扩展了算法的适用范围。

Conclusion: 本文显著推进了MD-SDVRP的近似算法研究，不仅改进了已知结果，还提供了更广泛适用的算法框架，为物流优化提供了新的理论工具。

Abstract: The Multiple-Depot Split Delivery Vehicle Routing Problem (MD-SDVRP) is a challenging problem with broad applications in logistics. The goal is to serve customers' demand using a fleet of capacitated vehicles located in multiple depots, where each customer's demand can be served by more than one vehicle, while minimizing the total travel cost of all vehicles. We study approximation algorithms for this problem. Previously, the only known result was a $6$-approximation algorithm for a constant number of depots (INFORMS J. Comput. 2023), and whether this ratio could be improved was left as an open question. In this paper, we resolve it by proposing a $(6-2\cdot 10^{-36})$-approximation algorithm for this setting. Moreover, we develop constant-factor approximation algorithms that work beyond a constant number of depots, improved parameterized approximation algorithms related to the vehicle capacity and the number of depots, as well as bi-factor approximation algorithms.

</details>


### [40] [Exact Clique Number Manipulation via Edge Interdiction](https://arxiv.org/abs/2601.01869)
*Yi Zhou,Haoyu Jiang,Chenghao Zhu,André Rossi*

Main category: cs.DS

TL;DR: 本文提出了一种新的混合整数线性规划公式和两阶段精确算法RLCM，用于解决边阻断团问题，显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 边阻断团问题（EICP）旨在通过移除最多k条边来最小化剩余图中最大团的大小，该问题在蛋白质功能维护和图像匹配等实际应用中具有重要意义。现有方法在图形规模和阻断预算k增长时难以扩展。

Method: 提出了新的混合整数线性规划公式，将问题转化为一系列参数化的边阻断团问题（EBCP）。开发了两阶段精确算法RLCM：首先应用问题特定的缩减技术缩小图形，然后使用定制的分支切割框架解决缩减后的问题。

Result: 在最大团基准图、大型真实世界稀疏网络和随机图上的广泛计算实验表明，RLCM算法始终优于现有方法。

Conclusion: 通过新的数学公式和专门设计的算法，成功解决了边阻断团问题的可扩展性挑战，为图操作中的结构关键边识别提供了高效解决方案。

Abstract: The Edge Interdiction Clique Problem (EICP) aims to remove at most $k$ edges from a graph so as to minimize the size of the largest clique in the remaining graph. This problem captures a fundamental question in graph manipulation: which edges are structurally critical for preserving large cliques? Such a problem is also motivated by practical applications including protein function maintenance and image matching. The EICP is computationally challenging and belongs to a complexity class beyond NP. Existing approaches rely on general mixed-integer bilevel programming solvers or reformulate the problem into a single-level mixed integer linear program. However, they are still not scalable when the graph size and interdiction budget $k$ grow. To overcome this, we investigate new mixed integer linear formulations, which recast the problem into a sequence of parameterized Edge Blocker Clique Problems (EBCP). This perspective decomposes the original problem into simpler subproblems and enables tighter modeling of clique-related inequalities. Furthermore, we propose a two-stage exact algorithm, \textsc{RLCM}, which first applies problem-specific reduction techniques to shrink the graph and then solves the reduced problem using a tailored branch-and-cut framework. Extensive computational experiments on maximum clique benchmark graphs, large real-world sparse networks, and random graphs demonstrate that \textsc{RLCM} consistently outperforms existing approaches.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [41] [Improved decoding algorithms for surface codes under independent bit-flip and phase-flip errors](https://arxiv.org/abs/2601.00972)
*Louay Bazzi*

Main category: cs.IT

TL;DR: 本文研究了表面码和环面码在独立X/Z噪声模型下的精确解码问题，提出了改进的解码算法复杂度，从O(n³ log n)提升到O(n³/² log n)，并证明了SMW解码在NC类中。


<details>
  <summary>Details</summary>
Motivation: 研究表面码和环面码的精确解码问题，改进现有解码算法的计算复杂度，探索解码问题的计算复杂性类别，为量子纠错提供更高效的解码方案。

Method: 1. 使用Fisher gadgets将SMW解码局部约简为最小权重完美匹配问题，保持平面性；2. 利用Lipton-Tarjan平面分离器方法；3. 对SMLC解码采用对偶循环公式和Fisher-Kasteleyn-Temperley构造约简为平面Pfaffian计算；4. 基于MacWilliams对偶性和傅里叶分析提供纯代数推导。

Result: 1. SMW解码：表面码和环面码达到O(n³/² log n)时间复杂度，改进标准方法的O(n³ log n)；2. 证明SMW解码在NC类中；3. SMLC解码：平面表面码达到O(n³/²)代数复杂度，在NC类中；4. 环面码SMLC解码达到O(n³)代数复杂度。

Conclusion: 本文提出了表面码和环面码的改进精确解码算法，显著降低了计算复杂度，证明了相关解码问题的计算复杂性类别，为量子纠错提供了更高效的解码方案，并讨论了向去极化噪声模型的扩展。

Abstract: We study exact decoding for the toric code and for planar and rotated surface codes under the standard independent \(X/Z\) noise model, focusing on Separate Minimum Weight (SMW) decoding and Separate Most Likely Coset (SMLC) decoding. For the SMW decoding problem, we show that an \(O(n^{3/2}\log n)\)-time decoder is achievable for surface and toric codes, improving over the \(O(n^{3}\log n)\) worst-case time of the standard approach based on complete decoding graphs. Our approach is based on a local reduction of SMW decoding to the minimum weight perfect matching problem using Fisher gadgets, which preserves planarity for planar and rotated surface codes and genus~\(1\) for the toric code. This reduction enables the use of Lipton--Tarjan planar separator methods and implies that SMW decoding lies in \(\mathrm{NC}\). For SMLC decoding, we show that the planar surface code admits an exact decoder with \(O(n^{3/2})\) algebraic complexity and that the problem lies in \(\mathrm{NC}\), improving over the \(O(n^{2})\) algebraic complexity of Bravyi \emph{et al.} Our approach proceeds via a dual-cycle formulation of coset probabilities and an explicit reduction to planar Pfaffian evaluation using Fisher--Kasteleyn--Temperley constructions. The same complexity measures apply to SMLC decoding of the rotated surface code. For the toric code, we obtain an exact polynomial-time SMLC decoder with \(O(n^{3})\) algebraic complexity. In addition, while the SMLC formulation is motivated by connections to statistical mechanics, we provide a purely algebraic derivation of the underlying duality based on MacWilliams duality and Fourier analysis. Finally, we discuss extensions of the framework to the depolarizing noise model and identify resulting open problems.

</details>


### [42] [A Novel Approach of Solving Polynomial Equations Over Binary Extension Fields](https://arxiv.org/abs/2601.01079)
*Leilei Yu,Yunghsiang S. Han,Pingping Li,Jiasheng Yuan*

Main category: cs.IT

TL;DR: 提出了一种统一的公式化方法，使用纯异或运算求解有限域GF(2^m)上的二次方程x²+x+c=0，适用于所有正整数m，计算成本最多为m²-2m+1次异或运算。


<details>
  <summary>Details</summary>
Motivation: 现有求解有限域二次方程的方法依赖复杂的指数运算或对m的奇偶性/是否为2的幂进行条件判断，缺乏统一性和效率。在代数编码理论和计算三次/四次多项式根时，需要更高效、统一的二次方程求解方法。

Method: 利用Reed-Muller矩阵刻画多项式求值，将问题转化为求解二进制线性系统。该方法仅使用异或运算，不依赖指数运算或条件判断，适用于所有正整数m。

Result: 实现了统一的公式化解决方案，计算成本最多为m²-2m+1次异或运算。在并行化下，延迟仅为⌈log₂m⌉次异或运算，适合低功耗、低延迟应用。

Conclusion: 提出了一种高效、统一的有限域二次方程求解方法，仅使用异或运算，适用于所有m，在计算复杂度和并行性方面具有优势，特别适合硬件实现和低功耗应用。

Abstract: Solving quadratic equations over finite fields is a fundamental task in algebraic coding theory and serves as a key subroutine for computing the roots of cubic and quartic polynomials. For the reduced quadratic polynomial $x^2+x+c\in \mathbb{F}_{2^m}[x]$, existing formula-based methods rely on heavy exponentiation or case distinctions on $m$ (odd/even or powers of two), which limits uniformity and efficiency. This paper presents a unified, formula-based solution for all positive integers $m$ that uses only exclusive-OR operations (XORs). The approach leverages a Reed-Muller matrix characterization of evaluations and reduces the problem to solving a binary linear system. The total cost is at most $m^2-2m+1$ XORs, and under parallelism, the latency is $\lceil \log_2 m\rceil$ XORs, making the method attractive for low-power, low-latency applications.

</details>


### [43] [Single-Shot and Few-Shot Decoding via Stabilizer Redundancy in Bivariate Bicycle Codes](https://arxiv.org/abs/2601.01137)
*Mohammad Rowshan*

Main category: cs.IT

TL;DR: 双变量自行车码（BB码）的容错性能由其最大公约多项式g(z)决定，该多项式控制着稳定子冗余度和单次解码所需的经典校验码结构。研究发现高量子码率会限制校验距离，从而影响单次解码性能。


<details>
  <summary>Details</summary>
Motivation: 虽然已知BB码的逻辑维度和量子距离由最大公约多项式g(z)决定，但其在噪声测量下的容错性能一直不明确。需要理解g(z)如何影响稳定子冗余度和单次解码所需的经典校验码结构，以便为下一代2BGA码提供设计指导。

Method: 通过理论分析证明g(z)多项式决定了码的稳定子冗余度和经典校验码结构。推导量子码率与稳定子冗余密度之间的严格等式关系，提供类似BCH码的界限来界定可实现的单次测量误差容限。基于此框架构造小的互质BB码，并使用BP+OSD算法进行评估。

Result: 发现量子码率与稳定子冗余密度之间存在严格等式关系。在互质BB码框架内，高量子码率会限制校验距离的上界，从而限制单次解码性能。构造的小型互质BB码显示出显著改善的校验距离。

Conclusion: 最大公约多项式g(z)完全决定了BB码的稳定子冗余度和单次解码所需的经典校验码结构。研究揭示了互质BB码设计中的结构性瓶颈：高量子码率会限制校验距离，影响单次解码性能。这些结果为下一代2BGA码在测量受限架构中的设计提供了具体的代数设计规则。

Abstract: Bivariate bicycle (BB) codes are a prominent class of quantum LDPC codes constructed from group algebras. While the logical dimension and quantum distance of \emph{coprime} BB codes are known to be determined by a greatest common divisor polynomial $g(z)$, the properties governing their fault tolerance under noisy measurement have remained implicit. In this work, we prove that this same polynomial $g(z)$ dictates the code's stabilizer redundancy and the structure of the classical \emph{syndrome codes} required for single-shot decoding. We derive a strict equality between the quantum rate and the stabilizer redundancy density, and we provide BCH-like bounds on the achievable single-shot measurement error tolerance. Guided by this framework, we construct small coprime BB codes with significantly improved syndrome distance ($d_S$) and evaluate them using BP+OSD. Our analysis reveals a structural bottleneck: within the coprime BB ansatz, high quantum rate imposes an upper bound on syndrome distance, limiting single-shot performance. These results provide concrete algebraic design rules for next-generation 2BGA codes in measurement-limited architectures.

</details>


### [44] [On the Structure of the Optimal Detector for Sub-THz Multi-Hop Relays with Unknown Prior: Over-the-Air Diffusion](https://arxiv.org/abs/2601.01194)
*Ozgur Ercetin,Mohaned Chraiti*

Main category: cs.IT

TL;DR: 论文提出AF-DDIM解码器，将AF中继链解释为方差保持扩散过程，利用DDIM进行信号恢复，无需逐跳CSI即可实现近最优贝叶斯解码。


<details>
  <summary>Details</summary>
Motivation: AF中继扩展sub-THz覆盖范围时会累积噪声，且非高斯输入分布下最优解码困难，MMSE估计器和互信息无闭式解。需要解决中继是否需要CSI和噪声统计信息的问题。

Method: 将AF中继链解释为方差保持扩散过程，每跳等效于带衰减和噪声注入的扩散步骤。整个多跳链可简化为仅需三个实数标量描述的等效高斯信道。接收端利用这些端到端充分统计量定义匹配的反向调度，指导基于DDIM的去噪器。

Result: 建立了信息论基础，证明解码性能仅取决于最终有效SNR，与中间噪声/信道分配或先验分布无关。仿真显示AF-DDIM解码器在AWGN和莱斯衰落下降低MSE、SER和BER，特别是在中等SNR和高阶调制下。

Conclusion: AF-DDIM框架为AF中继链提供了新的扩散解释，实现了无需逐跳CSI的近最优贝叶斯解码，性能仅取决于端到端有效SNR，简化了系统设计。

Abstract: Amplify and forward (AF) relaying is a viable strategy to extend the coverage of sub-terahertz (sub-THz) links, but inevitably propagates noise, leading to cumulative degradation across multiple hops. At the receiver, optimal decoding is desirable, yet challenging under non-Gaussian input distributions (video, voice, etc), for which neither the Minimum Mean Square Error (MMSE) estimator nor the mutual information admits a closed form. A further open question is whether knowledge of Channel State Information (CSI) and noise statistics at the intermediate relays is necessary for optimal detection. Aiming for an optimal decoder, this paper introduces a new framework that interprets the AF relay chain as a variance-preserving diffusion process and employs denoising diffusion implicit models (DDIMs) for signal recovery. We show that each AF hop is mathematically equivalent to a diffusion step with hop-dependent attenuation and noise injection. Consequently, the entire multi-hop chain collapses to an equivalent Gaussian channel fully described by only three real scalars per block: the cumulative complex gain and the effective noise variance. At the receiver, these end-to-end sufficient statistics define a matched reverse schedule that guides the DDIM-based denoiser, enabling near-optimal Bayesian decoding without per-hop CSI. We establish the information-theoretic foundation of this equivalence, proving that decoding performance depends solely on the final effective Signal-to-Noise-Ratio (SNR), regardless of intermediate noise/channel allocation or prior distribution. Simulations under AWGN and Rician fading confirm that the proposed AF-DDIM decoder reduces mean-squared error, symbol error rate, and bit error rate, particularly at moderate SNRs and for higher-order constellations.

</details>


### [45] [Probabilistic verification algorithm for linear codes](https://arxiv.org/abs/2601.01372)
*Mingchao Li,Jiyou Li*

Main category: cs.IT

TL;DR: 提出一种适用于任意线性码的概率算法，用于判断给定向量是否属于码字集合，具有O(n log n)时间复杂度和O(n²)空间复杂度，错误概率小于1/poly(n)。


<details>
  <summary>Details</summary>
Motivation: 线性码的成员判定问题在编码理论和密码学中具有重要应用，现有算法在效率或通用性上存在限制，需要开发更高效的通用算法。

Method: 采用概率算法设计，适用于任意线性码，通过特定的计算结构实现高效判定，利用概率技术控制错误率。

Result: 算法达到O(n log n)时间复杂度、O(n²)空间复杂度，错误概率小于1/poly(n)，在渐进意义下表现优异。

Conclusion: 该算法为线性码成员判定问题提供了高效的概率解决方案，在编码理论和相关应用中具有重要价值。

Abstract: In this paper, we propose a probabilistic algorithm suitable for any linear code $C$ to determine whether a given vector $\mathbf{x}$ belongs to $ C$. The algorithm achieves $O(n\log n)$ time complexity, $ O(n^2)$ space complexity and with an error probability less than $1/\mathrm{poly}(n)$ in the asymptotic sense.

</details>


### [46] [Edge grouping using methods in Algorithmic Information Theory](https://arxiv.org/abs/2601.01760)
*Gabriel Potestades*

Main category: cs.IT

TL;DR: 该论文探讨了如何利用算法信息理论中的块分解方法来分析图结构中子图与边的关系，通过顶点置换的对称群和自同构子集来识别连接子图的边，并评估算法信息理论作为理解图子结构复杂性的理论基础。


<details>
  <summary>Details</summary>
Motivation: 当前科学界对复杂系统相互作用的研究日益重视，但缺乏既理论严谨又计算实用的复杂性测量框架。算法信息理论在定义复杂性方面取得进展，特别是通过块分解方法分析图的邻接矩阵。本研究旨在探索算法信息理论是否能成为理解图子结构复杂性的可行理论框架。

Method: 采用Zenil等人2018年提出的块分解方法来近似计算图的复杂性。结合边扰动方法，通过顶点置换的完整对称群和特殊的自同构子集，系统性地识别图中连接两个子图的边。分析边是否会在平均算法信息贡献方面更接近其所属的子图。

Result: 研究通过系统分析验证了块分解方法在识别图子结构关系方面的有效性。结果表明，算法信息理论能够为理解图子结构提供理论基础，特别是在识别连接子图的边和评估边的信息贡献方面表现出潜力。

Conclusion: 算法信息理论可以作为理解图子结构复杂性的可行理论框架。块分解方法与边扰动分析相结合，为测量和分析图复杂性提供了有效工具，为未来建立更完善的复杂性测量框架奠定了基础。

Abstract: Understanding natural phenomenon through the interactions of different complex systems has become an increasing focus in scientific inquiry. Defining complexity and actually measuring it is an ongoing debate and no standard framework has been established that is both theoretically sound and computationally practical to use. Currently, one of the fields which attempts to formally define complexity is in the realm of Algorithmic Information Theory. The field has shown advances by studying the outputs of 1-dimensional and 2-dimensional Turing machines to determine the complexity values of binary strings and 2-dimensional binary matrices respectively. Using these complexity values, an algorithm called the Block Decomposition Method developed by Zenil, et al. in 2018, has been created to approximate the complexity of adjacency matrices of graphs which has found relative success in grouping graphs based on their complexity values. We use this method along with another method called edge perturbation to exhaustively determine if an edge can be identified to connect two sub-graphs within a graph using the entire symmetric group of its vertices permutation and via unique permutations we call automorphic subsets, which is a special subset of the symmetric group. We also analyze if edges will be grouped closer to their respective sub-graphs in terms of the average algorithmic information contribution. This analysis has been done in order to ascertain if Algorithmic Information Theory can be a viable theory in understanding substructures within graphs and ultimately as a foundation to create frameworks of measuring and analyzing complexity.

</details>


### [47] [Information Gradient for Directed Acyclic Graphs: A Score-based Framework for End-to-End Mutual Information Maximization](https://arxiv.org/abs/2601.01789)
*Tadashi Wadayama*

Main category: cs.IT

TL;DR: 提出一个基于随机有向无环图的端到端互信息最大化通用框架，利用边际和条件得分函数计算信息梯度，通过自动微分优化复杂网络，并扩展到数字孪生校准新范式。


<details>
  <summary>Details</summary>
Motivation: 通信和感知系统中端到端互信息最大化缺乏通用框架，需要处理复杂网络结构和全局资源约束下的优化问题。

Method: 基于随机有向无环图建模系统，推导出针对任意内部参数的统一互信息梯度公式，利用边际和条件得分函数，通过向量-雅可比积在自动微分框架中高效计算梯度。

Result: 在线性多路径DAG和非线性信道上的数值实验验证了框架有效性，基于去噪得分匹配学习的得分函数能准确复现真实梯度并成功最大化端到端互信息。

Conclusion: 该框架不仅实现了互信息最大化，还扩展到数字孪生校准的新无监督范式，通过Fisher散度最小化实现系统建模优化。

Abstract: This paper presents a general framework for end-to-end mutual information maximization in communication and sensing systems represented by stochastic directed acyclic graphs (DAGs). We derive a unified formula for the (mutual) information gradient with respect to arbitrary internal parameters, utilizing marginal and conditional score functions. We demonstrate that this gradient can be efficiently computed using vector-Jacobian products (VJP) within standard automatic differentiation frameworks, enabling the optimization of complex networks under global resource constraints. Numerical experiments on both linear multipath DAGs and nonlinear channels validate the proposed framework; the results confirm that the estimator, utilizing score functions learned via denoising score matching, accurately reproduces ground-truth gradients and successfully maximizes end-to-end mutual information. Beyond maximization, we extend our score-based framework to a novel unsupervised paradigm: digital twin calibration via Fisher divergence minimization.

</details>


### [48] [Information Flow in geophysical systems](https://arxiv.org/abs/2601.01795)
*Peter Jan van Leeuwen*

Main category: cs.IT

TL;DR: 提出分析地球物理系统中信息演化的新框架，应用于Kuramoto-Sivashinsky模型和浅水方程，发现信息可逆流传播，不同变量呈现不同的信息演化模式。


<details>
  <summary>Details</summary>
Motivation: 理解信息和不确定性在地球物理系统中的传播对于可预测性研究至关重要，对预报不确定性量化和风险管理有重要应用价值，同时能提供对系统底层物理机制的深入洞察。

Method: 开发了一个新的分析框架，将信息传播与因果关系联系起来，研究系统各部分如何相互影响以及某些区域如何保持动态隔离。将该框架应用于一维高度非线性的Kuramoto-Sivashinsky模型和代表中纬度大气带的浅水方程。

Result: 观察到信息可以逆着流体流动方向传播，不同模型变量展现出不同的信息演化模式。例如，与压力相关的信息传播方式不同于相对涡度，这反映了重力波与平衡流动力学的影响差异。

Conclusion: 这个新框架为研究复杂动力系统提供了一个有前景的诊断工具补充，能够揭示信息传播的独特特征和不同物理过程的影响。

Abstract: We present a new framework for analyzing the evolution of information in geophysical systems. Understanding how information, and its counterpart, uncertainty, propagates is central to predictability studies and has significant implications for applications such as forecast uncertainty quantification and risk management. It also offers valuable insight into the underlying physics of the system. Information propagation is closely linked to causality: how one part of a system influences another, and how some regions remain dynamically isolated. We apply this framework to the one-dimensional, highly nonlinear Kuramoto-Sivashinsky model and to the shallow-water equations, representing a mid-latitude atmospheric strip. Notably, we observe that information can propagate against the fluid flow, and that different model variables exhibit distinct patterns of information evolution. For example, pressure-related information propagates differently from relative vorticity, reflecting the influence of gravity waves versus balanced flow dynamics. This new framework offers a promising addition to the diagnostic tools available for studying complex dynamical systems.

</details>


### [49] [Information Geometry of Imaging Operators](https://arxiv.org/abs/2601.02111)
*Charles Wood*

Main category: cs.IT

TL;DR: 论文提出了一种基于成像算子奇异值谱的几何结构，通过将谱等价类映射到概率单纯形上，并赋予Fisher-Rao信息度量，构建了一个具有恒定正曲率的黎曼几何框架。


<details>
  <summary>Details</summary>
Motivation: 成像系统通常表示为线性算子，其奇异值谱描述了算子层面可恢复的结构。现有分析缺乏对成像算子谱结构的几何理解，需要建立一个不依赖于特定模态或优化原则的抽象几何框架，为后续成像流程中的信息流分析提供基础。

Method: 基于算子信息论框架，将归一化奇异值谱的等价类识别为概率单纯形上的点，并在该空间上装备Fisher-Rao信息度量，从而获得一个在酉变换和全局缩放下不变的黎曼几何结构。

Result: 构建的几何结构具有闭式距离和测地线表达式，呈现恒定正曲率。在特定限制下，组合操作通过秩约束引入边界面，在理想化对齐模型中诱导谱状态的非线性重加权。Fisher-Rao距离仅在谱均匀情况下保持。

Conclusion: 该研究提供了一个抽象的算子层面几何构造，不引入优化原则、随机模型或模态特定假设，旨在为成像流程中的信息流和约束分析提供一个固定的几何背景框架。

Abstract: Imaging systems are represented as linear operators, and their singular value spectra describe the structure recoverable at the operator level. Building on an operator-based information-theoretic framework, this paper introduces a minimal geometric structure induced by the normalised singular spectra of imaging operators. By identifying spectral equivalence classes with points on a probability simplex, and equipping this space with the Fisher--Rao information metric, a well-defined Riemannian geometry can be obtained that is invariant under unitary transformations and global rescaling. The resulting geometry admits closed-form expressions for distances and geodesics, and has constant positive curvature. Under explicit restrictions, composition enforces boundary faces through rank constraints and, in an aligned model with stated idealisations, induces a non-linear re-weighting of spectral states. Fisher--Rao distances are preserved only in the spectrally uniform case. The construction is abstract and operator-level, introducing no optimisation principles, stochastic models, or modality-specific assumptions. It is intended to provide a fixed geometric background for subsequent analysis of information flow and constraints in imaging pipelines.

</details>


### [50] [Single- and Multi-Objective Stochastic Optimization for Next-Generation Networks in the Generative AI and Quantum Computing Era](https://arxiv.org/abs/2601.02175)
*Trinh Van Chien,Bui Trong Duc,Nguyen Xuan Tung,Van Duc Nguyen,Waqas Khalid,Symeon Chatzinotas,Lajos Hanzo*

Main category: cs.IT

TL;DR: 这篇综述论文探讨了下一代网络（NG）与随机优化（SO）算法之间的关系，重点分析了SO如何解决NG网络中的大规模、高密度部署挑战，并提出了八个开放性问题。


<details>
  <summary>Details</summary>
Motivation: 下一代网络（包括6G）需要处理大规模部署、高密度网络和多样化功能，传统优化方法在现实场景中面临高计算复杂度和模型依赖性问题。随机优化算法因其能适应高密度和网络可扩展性而成为有前景的解决方案，但目前相关研究有限。

Method: 采用综述研究方法：1）详细概述NG系统和SO技术，涵盖从单目标到多目标的信号处理；2）探索不同算法如何解决NG挑战（负载均衡、能效优化、频谱效率等）；3）通过八个开放性问题分析两者关系；4）识别当前研究挑战并提出未来方向。

Result: 系统性地建立了NG网络与SO算法之间的联系框架，展示了SO在解决NG网络优化问题中的潜力，特别是针对大规模、高密度部署场景。提出了八个关键开放性问题，为未来研究提供了明确方向。

Conclusion: 随机优化算法是解决下一代网络大规模优化问题的有力工具，但需要进一步研究以适应6G等未来网络需求。论文为NG网络与SO的交叉研究提供了系统框架和未来发展方向。

Abstract: Next Generation (NG) networks move beyond simply connecting devices to creating an ecosystem of connected intelligence, especially with the support of generative Artificial Intelligence (AI) and quantum computation. These systems are expected to handle large-scale deployments and high-density networks with diverse functionalities. As a result, there is an increasing demand for efficient and intelligent algorithms that can operate under uncertainty from both propagation environments and networking systems. Traditional optimization methods often depend on accurate theoretical models of data transmission, but in real-world NG scenarios, they suffer from high computational complexity in large-scale settings. Stochastic Optimization (SO) algorithms, designed to accommodate extremely high density and extensive network scalability, have emerged as a powerful solution for optimizing wireless networks. This includes various categories that range from model-based approaches to learning-based approaches. These techniques are capable of converging within a feasible time frame while addressing complex, large-scale optimization problems. However, there is currently limited research on SO applied for NG networks, especially the upcoming Sixth-Generation (6G). In this survey, we emphasize the relationship between NG systems and SO by eight open questions involving the background, key features, and lesson learned. Overall, our study starts by providing a detailed overview of both areas, covering fundamental and widely used SO techniques, spanning from single to multi-objective signal processing. Next, we explore how different algorithms can solve NG challenges, such as load balancing, optimizing energy efficiency, improving spectral efficiency, or handling multiple performance trade-offs. Lastly, we highlight the challenges in the current research and propose new directions for future studies.

</details>


### [51] [Generative Site-Specific Beamforming for Next-Generation Spatial Intelligence](https://arxiv.org/abs/2601.02301)
*Zhaolin Wang,Zihao Zhou,Cheng-Jie Zhao,Yuanwei Liu*

Main category: cs.IT

TL;DR: 本文提出生成式站点特定波束成形（GenSSBF），利用条件生成模型学习可行波束成形器的条件分布，解决传统基于判别式深度学习的SSBF在表示无线传播多模态性和捕获波束成形器结构特征方面的不足，实现从粗略信道测量中合成多样且高保真的波束候选。


<details>
  <summary>Details</summary>
Motivation: 传统基于判别式深度学习的站点特定波束成形（SSBF）存在两个主要问题：1）难以正确表示无线传播固有的多模态性；2）无法有效捕获波束成形器的结构特征。这些限制阻碍了SSBF在多天线系统中利用环境先验缓解信道获取瓶颈的潜力。

Method: 提出生成式站点特定波束成形（GenSSBF），采用条件生成模型学习可行波束成形器的条件分布。通过这种方法，可以从粗略的信道感知测量中合成多样且高保真的波束候选。文章详细介绍了GenSSBF的基本原理、系统设计和实现方法。

Result: 室内和室外场景的案例研究表明，GenSSBF能够以极低的信道获取开销实现接近最优的波束成形增益。该方法显著降低了信道获取的开销，同时保持了高性能。

Conclusion: GenSSBF通过条件生成模型有效解决了传统SSBF的局限性，为下一代无线网络的空间智能提供了有前景的解决方案。文章还指出了几个开放的研究问题，为该领域的进一步发展指明了方向。

Abstract: This article proposes generative site-specific beamforming (GenSSBF) for next-generation spatial intelligence in wireless networks. Site-specific beamforming (SSBF) has emerged as a promising paradigm to mitigate the channel acquisition bottleneck in multiantenna systems by exploiting environmental priors. However, classical SSBF based on discriminative deep learning struggles: 1) to properly represent the inherent multimodality of wireless propagation and 2) to effectively capture the structural features of beamformers. In contrast, by leveraging conditional generative models, GenSSBF addresses these issues via learning a conditional distribution over feasible beamformers. By doing so, the synthesis of diverse and high-fidelity beam candidates from coarse channel sensing measurements can be guaranteed. This article presents the fundamentals, system designs, and implementation methods of GenSSBF. Case studies in both indoor and outdoor scenarios show that GenSSBF attains near-optimal beamforming gain with ultra-low channel acquisition overhead. Finally, several open research problems are highlighted.

</details>


### [52] [Error-Building Decoding of Linear Block Codes](https://arxiv.org/abs/2601.02330)
*Guoda Qiu,Ling Liu,Yuejun Wei,Liping Li*

Main category: cs.IT

TL;DR: 提出了一种基于最大似然的软判决解码框架EBD，仅需校验矩阵即可完成解码，无需预构建信息，并通过递归定理高效构建最优错误块，在扩展汉明码上实现复杂度显著降低。


<details>
  <summary>Details</summary>
Motivation: 传统软判决解码方法通常需要预构建网格图或错误模式列表等额外信息，增加了存储和计算开销。本文旨在开发一种仅依赖校验矩阵、无需预构建信息的通用解码框架，同时能够利用码的代数特性进行定制化优化。

Method: 提出错误构建解码（EBD）框架，定义错误构建块，推导递归定理从小块高效构建大块以搜索最可能错误模式。针对扩展汉明码，通过离线和在线排除机制优化，大幅降低复杂度而不损失ML性能。

Result: 对于长度64、128和256的扩展汉明码，完全优化的EBD在帧错误率10^-3时，平均浮点运算量比最小边网格Viterbi解码减少约一个数量级，同时保持最大似然性能。

Conclusion: EBD框架为线性分组码提供了一种高效的最大似然软判决解码方法，仅需校验矩阵，无需预构建信息，且可通过代数特性定制优化，在扩展汉明码上展示了显著的复杂度优势。

Abstract: This paper proposes a novel maximum-likelihood (ML) soft-decision decoding framework for linear block codes, termed error-building decoding (EBD). The complete decoding process can be performed using only the parity-check matrix, without requiring any other pre-constructed information (such as trellis diagrams or error-pattern lists), and it can also be customized by exploiting the algebraic properties of the code. We formally define error-building blocks, and derive a recursive theorem that allows efficient construction of larger locally optimal blocks from smaller ones, thereby effectively searching for the block associated with the most likely error pattern. The EBD framework is further optimized for extended Hamming codes as an example, through offline and online exclusion mechanisms, leading to a substantial complexity reduction without loss of ML performance. Complexity analysis shows that, for extended Hamming codes of lengths 64, 128, and 256, the fully optimized EBD requires approximately an order of magnitude fewer floating-point operations on average than minimum-edge trellis Viterbi decoding at a frame error rate of $10^{-3}$.

</details>
