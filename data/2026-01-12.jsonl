{"id": "2601.05681", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.05681", "abs": "https://arxiv.org/abs/2601.05681", "authors": ["Martin Hitz", "Michaela Hitz"], "title": "On the closest pair of points problem", "comment": null, "summary": "We introduce two novel algorithms for the problem of finding the closest pair in a cloud of $n$ points based on findings from mathematical optimal packing theory. Both algorithms are deterministic, show fast effective runtimes, and are very easy to implement. For our main algorithm, cppMM, we prove $O(n)$ time complexity for the case of uniformly distributed points. Our second algorithm, cppAPs, is almost as simple as the brute-force approach, but exhibits an extremely fast empirical running time, although its worst-case time complexity is also $O(n^2)$. We embed the new algorithms in a review of the most prominent contenders and empirically demonstrate their runtime behavior for problem sizes up to $n =$ 33,554,432 points observed in our C++ test environment. For large $n$, cppMM dominates the other algorithms under study."}
{"id": "2601.05883", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.05883", "abs": "https://arxiv.org/abs/2601.05883", "authors": ["Michael Kapralov", "Ekaterina Kochetkova", "Weronika Wrzos-Kaminska"], "title": "Spectral Clustering in Birthday Paradox Time", "comment": "Abstract shortened to meet the arXiv character limit", "summary": "Given a vertex in a $(k, \\varphi, ε)$-clusterable graph, i.e. a graph whose vertex set can be partitioned into a disjoint union of $\\varphi$-expanders of size $\\approx n/k$ with outer conductance bounded by $ε$, can one quickly tell which cluster it belongs to? This question goes back to the expansion testing problem of Goldreich and Ron'11. For $k=2$ a sample of $\\approx n^{1/2+O(ε/\\varphi^2)}$ logarithmic length walks from a given vertex approximately determines its cluster membership by the birthday paradox: two vertices whose random walk samples are `close' are likely in the same cluster.\n  The study of the general case $k>2$ was initiated by Czumaj, Peng and Sohler [STOC'15], and the works of Chiplunkar et al. [FOCS'18], Gluch et al. [SODA'21] showed that $\\approx \\text{poly}(k)\\cdot n^{1/2+O(ε/\\varphi^2)}$ random walk samples suffice for general $k$. This matches the $k=2$ result up to polynomial factors in $k$, but creates a conceptual inconsistency: if the birthday paradox is the guiding phenomenon, then the query complexity should decrease with the number of clusters $k$! Since clusters have size $\\approx n/k$, we expect to need $\\approx (n/k)^{1/2+O(ε/\\varphi^2)}$ random walk samples, which decreases with $k$.\n  We design a novel representation of vertices in a $(k, \\varphi, ε)$-clusterable graph by a mixture of logarithmic length walks. This representation uses the optimal $\\approx (n/k)^{1/2+O(ε/\\varphi^2)}$ walks per vertex, and allows for a fast nearest neighbor search: given $k$ vertices representing the clusters, we can find the cluster of a given query vertex $x$ using nearly linear time in the representation size of $x$. This gives a clustering oracle with query time $\\approx (n/k)^{1/2+O(ε/\\varphi^2)}$ and space complexity $k\\cdot (n/k)^{1/2+O(ε/\\varphi^2)}$, matching the birthday paradox bound."}
{"id": "2601.05263", "categories": ["cs.IR", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.05263", "abs": "https://arxiv.org/abs/2601.05263", "authors": ["Zhen Yi Lau"], "title": "A General Metric-Space Formulation of the Time Warp Edit Distance (TWED)", "comment": "20 pages, 1 algorithm, small technical note on the generalization of the Time Warp Edit Distance (TWED) to arbitrary metric spaces", "summary": "This short technical note presents a formal generalization of the Time Warp Edit Distance (TWED) proposed by Marteau (2009) to arbitrary metric spaces. By viewing both the observation and temporal domains as metric spaces $(X, d)$ and $(T, Δ)$, we define a Generalized TWED (GTWED) that remains a true metric under mild assumptions. We provide self-contained proofs of its metric properties and show that the classical TWED is recovered as a special case when $X = \\mathbb{R}^d$, $T \\subset \\mathbb{R}$, and $g(x) = x$. This note focuses on the theoretical structure of GTWED and its implications for extending elastic distances beyond time series, which enables the use of TWED-like metrics on sequences over arbitrary domains such as symbolic data, manifolds, or embeddings."}
{"id": "2601.05347", "categories": ["cs.DB", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.05347", "abs": "https://arxiv.org/abs/2601.05347", "authors": ["Ziyang Men", "Bo Huang", "Yan Gu", "Yihan Sun"], "title": "Parallel Dynamic Spatial Indexes", "comment": null, "summary": "Maintaining spatial data (points in two or three dimensions) is crucial and has a wide range of applications, such as graphics, GIS, and robotics. To handle spatial data, many data structures, called spatial indexes, have been proposed, e.g. kd-trees, oct/quadtrees (also called Orth-trees), R-trees, and bounding volume hierarchies (BVHs). In real-world applications, spatial datasets tend to be highly dynamic, requiring batch updates of points with low latency. This calls for efficient parallel batch updates on spatial indexes. Unfortunately, there is very little work that achieves this.\n  In this paper, we systematically study parallel spatial indexes, with a special focus on achieving high-performance update performance for highly dynamic workloads. We select two types of spatial indexes that are considered optimized for low-latency updates: Orth-tree and R-tree/BVH. We propose two data structures: the P-Orth tree, a parallel Orth-tree, and the SPaC-tree family, a parallel R-tree/BVH. Both the P-Orth tree and the SPaC-tree deliver superior performance in batch updates compared to existing parallel kd-trees and Orth-trees, while preserving better or competitive query performance relative to their corresponding Orth-tree and R-tree counterparts. We also present comprehensive experiments comparing the performance of various parallel spatial indexes and share our findings at the end of the paper."}
{"id": "2601.05416", "categories": ["cs.MM"], "pdf": "https://arxiv.org/pdf/2601.05416", "abs": "https://arxiv.org/abs/2601.05416", "authors": ["Arman Nik Khah", "Arvin Bahreini", "Ravi Prakash"], "title": "Meaning over Motion: A Semantic-First Approach to 360° Viewport Prediction", "comment": "10 pages, 5 figures", "summary": "Ultra-high-resolution 360-degree video streaming is severely constrained by the massive bandwidth required to deliver immersive experiences. Current viewport prediction techniques predominately rely on kinematics or low-level visual saliency, treating users as passive physical objects governed by inertia. This theoretical limitation leads to the \"Saccade Trap\" -- a critical failure mode where predictors fail to anticipate rapid, meaning-driven shifts in attention, causing rebuffering stalls exactly when user engagement is highest. To resolve this, we propose Semantically-Adaptive Conformal Tiling with Associative Lookahead, a novel framework that integrates cognitive intent into network control. Unlike \"one-size-fits-all\" approaches, our method utilizes an architectural inversion strategy: heavy semantic reasoning is offloaded to the server to generate lightweight association graphs, which guide a low-latency client-side controller. We construct a personalized Multi-Modal Prediction Set that dynamically tightens safety margins during stable fixation to maximize efficiency, while simultaneously pre-fetching non-adjacent tiles containing semantically linked objects (Associative Lookahead). This mechanism effectively converts the \"calm\" of fixation into a preparation phase for the next interaction. Trace-driven evaluation on the 360-AV-HM dataset demonstrates that this approach successfully mitigates the Saccade Trap, reducing stall duration by $\\ge$ 20% and lowering effective bandwidth consumption by $\\ge$ 18% compared to state-of-the-art trajectory-based baselines."}
{"id": "2601.05273", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05273", "abs": "https://arxiv.org/abs/2601.05273", "authors": ["Angshul Majumdar"], "title": "Bayesian Recovery for Probabilistic Coalition Structures", "comment": "15 pages", "summary": "Probabilistic Coalition Structure Generation (PCSG) is NP-hard and can be recast as an $l_0$-type sparse recovery problem by representing coalition structures as sparse coefficient vectors over a coalition-incidence design. A natural question is whether standard sparse methods, such as $l_1$ relaxations and greedy pursuits, can reliably recover the optimal coalition structure in this setting. We show that the answer is negative in a PCSG-inspired regime where overlapping coalitions generate highly coherent, near-duplicate columns: the irrepresentable condition fails for the design, and $k$-step Orthogonal Matching Pursuit (OMP) exhibits a nonvanishing probability of irreversible mis-selection. In contrast, we prove that Sparse Bayesian Learning (SBL) with a Gaussian-Gamma hierarchy is support consistent under the same structural assumptions. The concave sparsity penalty induced by SBL suppresses spurious near-duplicates and recovers the true coalition support with probability tending to one. This establishes a rigorous separation between convex, greedy, and Bayesian sparse approaches for PCSG."}
{"id": "2601.05280", "categories": ["cs.IT", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05280", "abs": "https://arxiv.org/abs/2601.05280", "authors": ["Hector Zenil"], "title": "On the Limits of Self-Improving in LLMs and Why AGI, ASI and the Singularity Are Not Near Without Symbolic Model Synthesis", "comment": "26 pages", "summary": "We formalise recursive self-training in Large Language Models (LLMs) and Generative AI as a discrete-time dynamical system and prove that, as training data become increasingly self-generated ($α_t \\to 0$), the system undergoes inevitably degenerative dynamics. We derive two fundamental failure modes: (1) Entropy Decay, where finite sampling effects cause a monotonic loss of distributional diversity (mode collapse), and (2) Variance Amplification, where the loss of external grounding causes the model's representation of truth to drift as a random walk, bounded only by the support diameter. We show these behaviours are not contingent on architecture but are consequences of distributional learning on finite samples. We further argue that Reinforcement Learning with imperfect verifiers suffers similar semantic collapse. To overcome these limits, we propose a path involving symbolic regression and program synthesis guided by Algorithmic Probability. The Coding Theorem Method (CTM) allows for identifying generative mechanisms rather than mere correlations, escaping the data-processing inequality that binds standard statistical learning. We conclude that while purely distributional learning leads to model collapse, hybrid neurosymbolic approaches offer a coherent framework for sustained self-improvement."}
{"id": "2601.05253", "categories": ["cs.IR", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05253", "abs": "https://arxiv.org/abs/2601.05253", "authors": ["Hadi Hosseini", "Debmalya Mandal", "Amrit Puhan"], "title": "SP-Rank: A Dataset for Ranked Preferences with Secondary Information", "comment": null, "summary": "We introduce $\\mathbf{SP-Rank}$, the first large-scale, publicly available dataset for benchmarking algorithms that leverage both first-order preferences and second-order predictions in ranking tasks. Each datapoint includes a personal vote (first-order signal) and a meta-prediction of how others will vote (second-order signal), allowing richer modeling than traditional datasets that capture only individual preferences. SP-Rank contains over 12,000 human-generated datapoints across three domains -- geography, movies, and paintings, and spans nine elicitation formats with varying subset sizes. This structure enables empirical analysis of preference aggregation when expert identities are unknown but presumed to exist, and individual votes represent noisy estimates of a shared ground-truth ranking. We benchmark SP-Rank by comparing traditional aggregation methods that use only first-order votes against SP-Voting, a second-order method that jointly reasons over both signals to infer ground-truth rankings. While SP-Rank also supports models that rely solely on second-order predictions, our benchmarks emphasize the gains from combining both signals. We evaluate performance across three core tasks: (1) full ground-truth rank recovery, (2) subset-level rank recovery, and (3) probabilistic modeling of voter behavior. Results show that incorporating second-order signals substantially improves accuracy over vote-only methods. Beyond social choice, SP-Rank supports downstream applications in learning-to-rank, extracting expert knowledge from noisy crowds, and training reward models in preference-based fine-tuning pipelines. We release the dataset, code, and baseline evaluations (available at https://github.com/amrit19/SP-Rank-Dataset ) to foster research in human preference modeling, aggregation theory, and human-AI alignment."}
{"id": "2601.05347", "categories": ["cs.DB", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.05347", "abs": "https://arxiv.org/abs/2601.05347", "authors": ["Ziyang Men", "Bo Huang", "Yan Gu", "Yihan Sun"], "title": "Parallel Dynamic Spatial Indexes", "comment": null, "summary": "Maintaining spatial data (points in two or three dimensions) is crucial and has a wide range of applications, such as graphics, GIS, and robotics. To handle spatial data, many data structures, called spatial indexes, have been proposed, e.g. kd-trees, oct/quadtrees (also called Orth-trees), R-trees, and bounding volume hierarchies (BVHs). In real-world applications, spatial datasets tend to be highly dynamic, requiring batch updates of points with low latency. This calls for efficient parallel batch updates on spatial indexes. Unfortunately, there is very little work that achieves this.\n  In this paper, we systematically study parallel spatial indexes, with a special focus on achieving high-performance update performance for highly dynamic workloads. We select two types of spatial indexes that are considered optimized for low-latency updates: Orth-tree and R-tree/BVH. We propose two data structures: the P-Orth tree, a parallel Orth-tree, and the SPaC-tree family, a parallel R-tree/BVH. Both the P-Orth tree and the SPaC-tree deliver superior performance in batch updates compared to existing parallel kd-trees and Orth-trees, while preserving better or competitive query performance relative to their corresponding Orth-tree and R-tree counterparts. We also present comprehensive experiments comparing the performance of various parallel spatial indexes and share our findings at the end of the paper."}
{"id": "2601.06001", "categories": ["cs.DB", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.06001", "abs": "https://arxiv.org/abs/2601.06001", "authors": ["Christoph Standke", "Nikolaos Tziavelis", "Wolfgang Gatterbauer", "Benny Kimelfeld"], "title": "The Importance of Parameters in Ranking Functions", "comment": "Extended version of ICDT 2026 paper", "summary": "How important is the weight of a given column in determining the ranking of tuples in a table? To address such an explanation question about a ranking function, we investigate the computation of SHAP scores for column weights, adopting a recent framework by Grohe et al.[ICDT'24]. The exact definition of this score depends on three key components: (1) the ranking function in use, (2) an effect function that quantifies the impact of using alternative weights on the ranking, and (3) an underlying weight distribution. We analyze the computational complexity of different instantiations of this framework for a range of fundamental ranking and effect functions, focusing on probabilistically independent finite distributions for individual columns.\n  For the ranking functions, we examine lexicographic orders and score-based orders defined by the summation, minimum, and maximum functions. For the effect functions, we consider global, top-k, and local perspectives: global measures quantify the divergence between the perturbed and original rankings, top-k measures inspect the change in the set of top-k answers, and local measures capture the impact on an individual tuple of interest. Although all cases admit an additive fully polynomial-time randomized approximation scheme (FPRAS), we establish the complexity of exact computation, identifying which cases are solvable in polynomial time and which are #P-hard. We further show that all complexity results, lower bounds and upper bounds, extend to a related task of computing the Shapley value of whole columns (regardless of their weight)."}
{"id": "2601.05375", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2601.05375", "abs": "https://arxiv.org/abs/2601.05375", "authors": ["Doris E. M. Brown", "Sajal K. Das"], "title": "Congestion Mitigation in Vehicular Traffic Networks with Multiple Operational Modalities", "comment": "10 pages, 4 figures; This is a working draft and can potentially have errors. Any feedback will be greatly appreciated, and will be acknowledged in the subsequent versions", "summary": "Modern commercial ground vehicles are increasingly equipped with multiple operational modalities (e.g., human driving, advanced driver assistance, remote tele-operation, full autonomy). These often rely on heterogeneous sensing infrastructures and distinct routing algorithms, which can yield misaligned perceptions of the traffic environment and route preferences. While such technologies accelerate the transition toward increasingly intelligent transportation networks, their current deployment fails to avoid challenges associated with selfish routing behavior, in which drivers or automated agents prioritize individually optimal routes instead of network-wide congestion mitigation. Existing traffic flow management strategies can address leader-follower dynamics in traffic routing problems but are not designed to account for vehicles capable of dynamically switching between multiple operational modes. This paper models the interaction between a vehicle control arbitration system and a multi-modal vehicle as a repeated single-leader, multiple follower Stackelberg game with asymmetric information. To address the intractability of computing an exact solution in this setting, we propose a Trust-Aware Control Trading Strategy (TACTS) utilizing a regret matching-based algorithm to adaptively update the arbitration system's mixed strategy over sequential, dynamic routing decisions. Theoretical results provide bounds on the realized total network travel time under TACTS algorithm relative to the system-optimal total network travel time. Experimental results of simulations between the system and a vehicle in several real-world traffic networks under various different congestion levels demonstrate that TACTS consistently reduces network-wide congestion and generally outperforms alternative routing and control-allocation strategies, particularly under high congestion and heavy induced vehicle flows."}
{"id": "2601.05281", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05281", "abs": "https://arxiv.org/abs/2601.05281", "authors": ["Yujie Ling", "Zan Li", "Lei Guan", "Zheng Zhang", "Dusit Niyato"], "title": "Multi-User Covert Communications via Intelligent Spectrum Control", "comment": "5 pages, 5 figures, journal article", "summary": "This paper investigates the performance of multi-user covert communications over a fixed bandwidth in a multi-cell scenario with both eavesdroppers and malicious jammers. We propose an intelligent spectrum control (ISC) scheme that combines high-accuracy spectrum sensing with AI-assisted real-time decision-making to generate time-frequency dynamic occupation patterns for multiple legitimate users. The scheme can proactively avoid external interference and intra-system co-channel collisions, thereby improving covertness and reliability. Within this framework, we derive closed-form expressions for the detection error probability (DEP) of the eavesdropper and the reliable transmission probability (RTP) of legitimate users under multi-user joint detection. We then analytically optimize the transmission power that can maximize the covert rate (CR), as well as the maximum number of users that can access the system covertly and concurrently under given covertness and reliability constraints. Simulation results confirm the tight match between the analytical and Monte Carlo curves, and show that the proposed scheme can achieve a higher DEP, a larger RTP, and a greater multi-user capacity than the benchmark scheme."}
{"id": "2601.05254", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05254", "abs": "https://arxiv.org/abs/2601.05254", "authors": ["Wenbiao Tao", "Yunshi Lan", "Weining Qian"], "title": "TagRAG: Tag-guided Hierarchical Knowledge Graph Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-Augmented Generation enhances language models by retrieving external knowledge to support informed and grounded responses. However, traditional RAG methods rely on fragment-level retrieval, limiting their ability to address query-focused summarization queries. GraphRAG introduces a graph-based paradigm for global knowledge reasoning, yet suffers from inefficiencies in information extraction, costly resource consumption, and poor adaptability to incremental updates. To overcome these limitations, we propose TagRAG, a tag-guided hierarchical knowledge graph RAG framework designed for efficient global reasoning and scalable graph maintenance. TagRAG introduces two key components: (1) Tag Knowledge Graph Construction, which extracts object tags and their relationships from documents and organizes them into hierarchical domain tag chains for structured knowledge representation, and (2) Tag-Guided Retrieval-Augmented Generation, which retrieves domain-centric tag chains to localize and synthesize relevant knowledge during inference. This design significantly adapts to smaller language models, improves retrieval granularity, and supports efficient knowledge increment. Extensive experiments on UltraDomain datasets spanning Agriculture, Computer Science, Law, and cross-domain settings demonstrate that TagRAG achieves an average win rate of 95.41\\% against baselines while maintaining about 14.6x construction and 1.9x retrieval efficiency compared with GraphRAG."}
{"id": "2601.05536", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.05536", "abs": "https://arxiv.org/abs/2601.05536", "authors": ["Shreya Shankar", "Sepanta Zeighami", "Aditya Parameswaran"], "title": "Task Cascades for Efficient Unstructured Data Processing", "comment": "SIGMOD 2026. 21 pages, 8 figures, 5 tables", "summary": "Modern database systems allow users to query or process unstructured text or document columns using LLM-powered functions. Users can express an operation in natural language (e.g., \"identify if this review mentions billing issues\"), with the system executing the operation on each document, in a row-by-row fashion. One way to reduce cost on a batch of documents is to employ the model cascade framework: a cheap proxy model processes each document, and only uncertain cases are escalated to a more accurate, expensive oracle. However, model cascades miss important optimization opportunities; for example, often only part of a document is needed to answer a query, or other related, but simpler operations (e.g., \"is the review sentiment negative?\", \"does the review mention money?\") can be handled by cheap models more effectively than the original operation, while still being correlated with it.\n  We introduce the task cascades framework, which generalizes model cascades by varying not just the model, but also the document portion and operation at each stage. Our framework uses an LLM agent to generate simplified, decomposed, or otherwise related operations and selects the most relevant document portions, constructing hundreds of candidate tasks from which it assembles a task cascade. We show that optimal cascade selection is intractable via reduction from Minimum Sum Set Cover, but our iterative approach constructs effective cascades. We also provide an extension that offers statistical accuracy guarantees: the resulting cascade meets a user-defined accuracy target (with respect to the oracle) up to a bounded failure probability. Across eight real-world document processing tasks at a 90% target accuracy, task cascades reduce end-to-end cost by an average of 36% compared to model cascades, at a production scale."}
{"id": "2601.05417", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2601.05417", "abs": "https://arxiv.org/abs/2601.05417", "authors": ["Yanni Georghiades", "Takashi Tanaka", "Sriram Vishwanath"], "title": "Mean Field Analysis of Blockchain Systems", "comment": null, "summary": "We present a novel framework for analyzing blockchain consensus mechanisms by modeling blockchain growth as a Partially Observable Stochastic Game (POSG) which we reduce to a set of Partially Observable Markov Decision Processes (POMDPs) through the use of the mean field approximation. This approach formalizes the decision-making process of miners in Proof-of-Work (PoW) systems and enables a principled examination of block selection strategies as well as steady state analysis of the induced Markov chain. By leveraging a mean field game formulation, we efficiently characterize the information asymmetries that arise in asynchronous blockchain networks.\n  Our first main result is an exact characterization of the tradeoff between network delay and PoW efficiency--the fraction of blocks which end up in the longest chain. We demonstrate that the tradeoff observed in our model at steady state aligns closely with theoretical findings, validating our use of the mean field approximation.\n  Our second main result is a rigorous equilibrium analysis of the Longest Chain Rule (LCR). We show that the LCR is a mean field equilibrium and that it is uniquely optimal in maximizing PoW efficiency under certain mild assumptions. This result provides the first formal justification for continued use of the LCR in decentralized consensus protocols, offering both theoretical validation and practical insights.\n  Beyond these core results, our framework supports flexible experimentation with alternative block selection strategies, system dynamics, and reward structures. It offers a systematic and scalable substitute for expensive test-net deployments or ad hoc analysis. While our primary focus is on Nakamoto-style blockchains, the model is general enough to accommodate other architectures through modifications to the underlying MDP."}
{"id": "2601.05292", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05292", "abs": "https://arxiv.org/abs/2601.05292", "authors": ["Jingyi Wang", "Fanggang Wang"], "title": "Secure Communication via Modulation Order Confusion", "comment": null, "summary": "With the increasing threat posed by modulation classification to wireless security, this paper proposes a secure communication framework based on modulation order confusion (MOC), which intentionally disguises the original modulation as a higher- or lower-order one to mislead eavesdroppers. For single-antenna systems, two schemes are developed: symbol random mapping and symbol time diversity, enabling modulation order confusion with customized receivers. For multi-antenna systems, receiver-transparent MOC schemes are proposed, including series-expansion-based and constellation-path-based signal designs, and are further extended to RIS-assisted systems with joint beamformer and RIS reflection design. Numerical results show that the proposed schemes effectively defeat both deep-learning-based and expert-knowledge-based modulation classifiers without degrading communication performance."}
{"id": "2601.05255", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05255", "abs": "https://arxiv.org/abs/2601.05255", "authors": ["Sai Khadloya", "Kush Juvekar", "Arghya Bhattacharya", "Utkarsh Saxena"], "title": "CourtNav: Voice-Guided, Anchor-Accurate Navigation of Long Legal Documents in Courtrooms", "comment": null, "summary": "Judicial work depends on close reading of long records, charge sheets, pleadings, annexures, orders, often spanning hundreds of pages. With limited staff support, exhaustive reading during hearings is impractical. We present CourtNav, a voice-guided, anchor-first navigator for legal PDFs that maps a judge's spoken command (e.g., \"go to paragraph 23\", \"highlight the contradiction in the cross-examination\") directly to a highlighted paragraph in seconds. CourtNav transcribes the command, classifies intent with a grammar-first(Exact regex matching), LLM-backed router classifying the queries using few shot examples, retrieves over a layout-aware hybrid index, and auto-scrolls the viewer to the cited span while highlighting it and close alternates. By design, the interface shows only grounded passages, never free text, keeping evidence verifiable and auditable. This need is acute in India, where judgments and cross-examinations are notoriously long.In a pilot on representative charge sheets, pleadings, and orders, median time-to-relevance drops from 3-5 minutes (manual navigation) to 10-15 seconds; with quick visual verification included, 30-45 seconds. Under fixed time budgets, this navigation-first design increases the breadth of the record actually consulted while preserving control and transparency."}
{"id": "2601.05579", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.05579", "abs": "https://arxiv.org/abs/2601.05579", "authors": ["Xudong Xie", "Yuwei Zhang", "Wensheng Dou", "Yu Gao", "Ziyu Cui", "Jiansen Song", "Rui Yang", "Jun Wei"], "title": "RISE: Rule-Driven SQL Dialect Translation via Query Reduction", "comment": "Accepted by ICSE 2026", "summary": "Translating SQL dialects across different relational database management systems (RDBMSs) is crucial for migrating RDBMS-based applications to the cloud. Traditional SQL dialect translation tools rely on manually-crafted rules, necessitating significant manual effort to support new RDBMSs and dialects. Although large language models (LLMs) can assist in translating SQL dialects, they often struggle with lengthy and complex SQL queries.\n  In this paper, we propose RISE, a novel LLM-based SQL dialect translation approach that can accurately handle lengthy and complex SQL queries. Given a complex source query $Q_c$ that contains a SQL dialect $d$, we first employ a dialect-aware query reduction technique to derive a simplified query $Q_{s}$ by removing $d$-irrelevant SQL elements from $Q_c$. Subsequently, we utilize LLMs to translate $Q_{s}$ into $Q_{s^{'}}$, and automatically extract the translation rule $r_d$ for dialect $d$ based on the relationship between $Q_{s}$ and $Q_{s^{'}}$. By applying $r_d$ to $Q_c$, we can effectively translate the dialect $d$ within $Q_c$, thereby bypassing the complexity of the source query $Q_c$. We evaluate RISE on two real-world benchmarks, i.e., TPC-DS and SQLProcBench, comparing its performance against both the traditional rule-based tools and the LLM-based approaches with respect to translation accuracy. RISE achieves accuracies of 97.98% on TPC-DS and 100% on SQLProcBench, outperforming the baselines by an average improvement of 24.62% and 238.41%, respectively."}
{"id": "2601.05427", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2601.05427", "abs": "https://arxiv.org/abs/2601.05427", "authors": ["Etienne Gauthier", "Francis Bach", "Michael I. Jordan"], "title": "Betting on Equilibrium: Monitoring Strategic Behavior in Multi-Agent Systems", "comment": "Code at: https://github.com/GauthierE/betting-equilibrium", "summary": "In many multi-agent systems, agents interact repeatedly and are expected to settle into equilibrium behavior over time. Yet in practice, behavior often drifts, and detecting such deviations in real time remains an open challenge. We introduce a sequential testing framework that monitors whether observed play in repeated games is consistent with equilibrium, without assuming a fixed sample size. Our approach builds on the e-value framework for safe anytime-valid inference: by \"betting\" against equilibrium, we construct a test supermartingale that accumulates evidence whenever observed payoffs systematically violate equilibrium conditions. This yields a statistically sound, interpretable measure of departure from equilibrium that can be monitored online. We also leverage Benjamini-Hochberg-type procedures to increase detection power in large games while rigorously controlling the false discovery rate. Our framework unifies the treatment of Nash, correlated, and coarse correlated equilibria, offering finite-time guarantees and a detailed analysis of detection times. Moreover, we extend our method to stochastic games, broadening its applicability beyond repeated-play settings."}
{"id": "2601.05340", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05340", "abs": "https://arxiv.org/abs/2601.05340", "authors": ["Roxana Smarandache", "David G. M. Mitchell"], "title": "The Number of Cycles of Bi-regular Tanner Graphs in Terms of the Eigenvalues of the Adjacency Matrix", "comment": "25 pages, submitted to IT Transactions", "summary": "In this paper, we explore new connections between the cycles in the graph of low-density parity-check (LDPC) codes and the eigenvalues of the corresponding adjacency matrix. The resulting observations are used to derive fast, simple, recursive formulas for the number of cycles $N_{2k}$ of length $2k$, $k<g$, in a bi-regular graph of girth $g$. Moreover, we derive explicit formulas for $N_{2k}$, $k\\leq 7$, in terms of the nonzero eigenvalues of the adjacency matrix. Throughout, we focus on the practically interesting class of bi-regular quasi-cyclic LDPC (QC-LDPC) codes, for which the eigenvalues can be obtained efficiently by applying techniques used for block-circulant matrices."}
{"id": "2601.05257", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05257", "abs": "https://arxiv.org/abs/2601.05257", "authors": ["Hou-Wan Long", "Yicheng Song", "Zidong Wang", "Tianshu Sun"], "title": "KP-Agent: Keyword Pruning in Sponsored Search Advertising via LLM-Powered Contextual Bandits", "comment": null, "summary": "Sponsored search advertising (SSA) requires advertisers to constantly adjust keyword strategies. While bid adjustment and keyword generation are well-studied, keyword pruning-refining keyword sets to enhance campaign performance-remains under-explored. This paper addresses critical inefficiencies in current practices as evidenced by a dataset containing 0.5 million SSA records from a pharmaceutical advertiser on search engine Meituan, China's largest delivery platform. We propose KP-Agent, an LLM agentic system with domain tool set and a memory module. By modeling keyword pruning within a contextual bandit framework, KP-Agent generates code snippets to refine keyword sets through reinforcement learning. Experiments show KP-Agent improves cumulative profit by up to 49.28% over baselines."}
{"id": "2601.05813", "categories": ["cs.DB", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.05813", "abs": "https://arxiv.org/abs/2601.05813", "authors": ["Enrique Feito-Casares", "Ismael Gómez-Talal", "José-Luis Rojo-Álvarez"], "title": "Descriptor: Multi-Regional Cloud Honeypot Dataset (MURHCAD)", "comment": null, "summary": "This data article introduces a comprehensive, high-resolution honeynet dataset designed to support standalone analyses of global cyberattack behaviors. Collected over a continuous 72-hour window (June 9 to 11, 2025) on Microsoft Azure, the dataset comprises 132,425 individual attack events captured by three honeypots (Cowrie, Dionaea, and SentryPeer) deployed across four geographically dispersed virtual machines. Each event record includes enriched metadata (UTC timestamps, source/destination IPs, autonomous system and organizational mappings, geolocation coordinates, targeted ports, and honeypot identifiers alongside derived temporal features and standardized protocol classifications). We provide actionable guidance for researchers seeking to leverage this dataset in anomaly detection, protocol-misuse studies, threat intelligence, and defensive policy design. Descriptive statistics highlight significant skew: 2,438 unique source IPs span 95 countries, yet the top 1% of IPs account for 1% of all events, and three protocols dominate: Session Initiation Protocol (SIP), Telnet, Server Message Block (SMB). Temporal analysis uncovers pronounced rush-hour peaks at 07:00 and 23:00 UTC, interspersed with maintenance-induced gaps that reveal operational blind spots. Geospatial mapping further underscores platform-specific biases: SentryPeer captures concentrated SIP floods in North America and Southeast Asia, Cowrie logs Telnet/SSH scans predominantly from Western Europe and the U.S., and Dionaea records SMB exploits around European nodes. By combining fine-grained temporal resolution with rich, contextual geolocation and protocol metadata, this standalone dataset aims to empower reproducible, cloud-scale investigations into evolving cyber threats. Accompanying analysis code and data access details are provided."}
{"id": "2601.05581", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05581", "abs": "https://arxiv.org/abs/2601.05581", "authors": ["Chao Liu", "Hao Chen", "Qinqin Ji", "Ziyan Xie", "Dabin Zheng"], "title": "Strong Singleton-Like Bounds, Quasi-Perfect Codes and Distance-Optimal Codes in the Sum-Rank Metric", "comment": "20 pages", "summary": "Codes in the sum-rank metric have received many attentions in recent years, since they have wide applications in the multishot network coding, the space-time coding and the distributed storage. In this paper, by constructing covering codes in the sum-rank metric from covering codes in the Hamming metric, we derive new upper bounds on sizes, the covering radii and the block length functions of codes in the sum-rank metric. As applications, we present several strong Singleton-like bounds that are tighter than the classical Singleton-like bound when block lengths are large. In addition, we give the explicit constructions of the distance-optimal sum-rank codes of matrix sizes $s\\times s$ and $2\\times 2$ with minimum sum-rank distance four respectively by using cyclic codes in the Hamming metric. More importantly, we present an infinite families of quasi-perfect $q$-ary sum-rank codes with matrix sizes $2\\times m$. Furthermore, we construct almost MSRD codes with larger block lengths and demonstrate how the Plotkin sum can be used to give more distance-optimal sum-rank codes."}
{"id": "2601.05258", "categories": ["cs.IR", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05258", "abs": "https://arxiv.org/abs/2601.05258", "authors": ["Kaichun Wang", "Yanguang Chen", "Ting Zhang", "Mengyao Bao", "Keyu Chen", "Xu Hu", "Yongliang Wang", "Jingsheng Yang", "Jinsong Zhang", "Fei Lu"], "title": "From Events to Trending: A Multi-Stage Hotspots Detection Method Based on Generative Query Indexing", "comment": null, "summary": "LLM-based conversational systems have become a popular gateway for information access, yet most existing chatbots struggle to handle news-related trending queries effectively. To improve user experience, an effective trending query detection method is urgently needed to enable differentiated processing of such target traffic. However, current research on trending detection tailored to the dialogue system scenario remains largely unexplored, and methods designed for traditional search engines often underperform in conversational contexts due to radically distinct query distributions and expression patterns. To fill this gap, we propose a multi-stage framework for trending detection, which achieves systematic optimization from both offline generation and online identification perspectives. Specifically, our framework first exploits selected hot events to generate index queries, establishing a key bridge between static events and dynamic user queries. It then employs a retrieval matching mechanism for real-time online detection of trending queries, where we introduce a cascaded recall and ranking architecture to balance detection efficiency and accuracy. Furthermore, to better adapt to the practical application scenario, our framework adopts a single-recall module as a cold-start strategy to collect online data for fine-tuning the reranker. Extensive experiments demonstrate that our framework significantly outperforms baseline methods in both offline evaluations and online A/B tests, and user satisfaction is relatively improved by 27\\% in terms of positive-negative feedback ratio."}
{"id": "2601.06001", "categories": ["cs.DB", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.06001", "abs": "https://arxiv.org/abs/2601.06001", "authors": ["Christoph Standke", "Nikolaos Tziavelis", "Wolfgang Gatterbauer", "Benny Kimelfeld"], "title": "The Importance of Parameters in Ranking Functions", "comment": "Extended version of ICDT 2026 paper", "summary": "How important is the weight of a given column in determining the ranking of tuples in a table? To address such an explanation question about a ranking function, we investigate the computation of SHAP scores for column weights, adopting a recent framework by Grohe et al.[ICDT'24]. The exact definition of this score depends on three key components: (1) the ranking function in use, (2) an effect function that quantifies the impact of using alternative weights on the ranking, and (3) an underlying weight distribution. We analyze the computational complexity of different instantiations of this framework for a range of fundamental ranking and effect functions, focusing on probabilistically independent finite distributions for individual columns.\n  For the ranking functions, we examine lexicographic orders and score-based orders defined by the summation, minimum, and maximum functions. For the effect functions, we consider global, top-k, and local perspectives: global measures quantify the divergence between the perturbed and original rankings, top-k measures inspect the change in the set of top-k answers, and local measures capture the impact on an individual tuple of interest. Although all cases admit an additive fully polynomial-time randomized approximation scheme (FPRAS), we establish the complexity of exact computation, identifying which cases are solvable in polynomial time and which are #P-hard. We further show that all complexity results, lower bounds and upper bounds, extend to a related task of computing the Shapley value of whole columns (regardless of their weight)."}
{"id": "2601.05636", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05636", "abs": "https://arxiv.org/abs/2601.05636", "authors": ["Avraham Kreindel", "Isaac Barouch Essayag", "Aryeh Lev Zabokritskiy"], "title": "Multiset Deletion-Correcting Codes: Bounds and Constructions", "comment": "24 pages", "summary": "We study error-correcting codes in the space $\\mathcal{S}_{n,q}$ of length-$n$ multisets over a $q$-ary alphabet, motivated by permutation channels in which ordering is completely lost and errors act solely by deletions of symbols, i.e., by reducing symbol multiplicities.\n  Our focus is on the \\emph{extremal deletion regime}, where the channel output contains $k=n-t$ symbols. In this regime, we establish tight or near-tight bounds on the maximum code size. In particular, we determine the exact optimal code sizes for $t=n-1$ and for $t=n-2$, develop a refined analysis for $t=n-3$, and derive a general recursive puncturing upper bound for $t=n-k$ via a reduction from parameters $(n,k)$ to $(n-1,k-1)$.\n  On the constructive side, we completely resolve the binary multiset model: for all $t\\ge1$ we determine $S_2(n,t)$ exactly and give an explicit optimal congruence-based construction. We then study single-deletion codes beyond the binary case, presenting general $q$-ary constructions and showing, via explicit small-parameter examples, that the natural modular construction need not be optimal for $q\\ge3$. Finally, we present an explicit cyclic Sidon-type linear construction for general $(q,t)$ based on a single congruence constraint, with redundancy $\\log_q\\!\\bigl(t(t+1)^{q-2}+1\\bigr)$ and encoding and decoding complexity linear in the blocklength $n$."}
{"id": "2601.05259", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05259", "abs": "https://arxiv.org/abs/2601.05259", "authors": ["Haotao Xie", "Ruilin Chen", "Yicheng Wu", "Zhan Zhao", "Yuanyuan Liu"], "title": "A Technical Report on the Second Place Solution for the CIKM 2025 AnalytiCup Competition", "comment": null, "summary": "In this work, we address the challenge of multilingual category relevance judgment in e-commerce search, where traditional ensemble-based systems improve accuracy but at the cost of heavy training, inference, and maintenance complexity. To overcome this limitation, we propose a simplified yet effective framework that leverages prompt engineering with Chain-of-Thought task decomposition to guide reasoning within a single large language model. Specifically, our approach decomposes the relevance judgment process into four interpretable subtasks: translation, intent understanding, category matching, and relevance judgment -- and fine-tunes a base model (Qwen2.5-14B) using Low-Rank Adaptation (LoRA) for efficient adaptation. This design not only reduces computational and storage overhead but also enhances interpretability by explicitly structuring the model's reasoning path. Experimental results show that our single-model framework achieves competitive accuracy and high inference efficiency, processing 20 samples per second on a single A100 GPU. In the CIKM 2025 AnalytiCup Competition Proposals, our method achieved 0.8902 on the public leaderboard and 0.8889 on the private leaderboard, validating the effectiveness and robustness of the proposed approach. These results highlight that structured prompting combined with lightweight fine-tuning can outperform complex ensemble systems, offering a new paradigm for scalable industrial AI applications."}
{"id": "2601.06013", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.06013", "abs": "https://arxiv.org/abs/2601.06013", "authors": ["Jiayin Hu", "Nikolaos Tziavelis"], "title": "Database Theory in Action: Direct Access to Query Answers", "comment": null, "summary": "Direct access asks for the retrieval of query answers by their ranked position, given a query and a desired order. While the time complexity of data structures supporting such accesses has been studied in depth, and efficient algorithms for many queries and common orders are known, their practical performance has received little attention. We provide an implementation covering a wide range of queries and orders; it allows us to investigate intriguing practical aspects, including the comparative performance of database systems and the relationship between direct access and its single-access counterpart."}
{"id": "2601.05652", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05652", "abs": "https://arxiv.org/abs/2601.05652", "authors": ["Irina Bocharova", "Maiara F. Bollauf", "Boris Kudryashov"], "title": "Coset Shaping for Coded Modulation", "comment": "Paper accepted for presentation at the 2026 International Zurich Seminar on Information and Communication (IZS 2026)", "summary": "A new shaping technique called coset shaping for coded QAM and PAM signaling is introduced and analyzed. This technique can be applied not only to information bits but also to parity bits without incurring additional complexity costs. It is proven that as the length of the error-correcting code and the modulation order tend to infinity, the gap to capacity for the proposed shaping scheme can be made arbitrarily small. Numerical results and comparisons for the shaping scheme, along with nonbinary LDPC-coded QAM signaling, are presented."}
{"id": "2601.05260", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05260", "abs": "https://arxiv.org/abs/2601.05260", "authors": ["Armin Gerami", "Kazem Faghih", "Ramani Duraiswami"], "title": "Quantifying Document Impact in RAG-LLMs", "comment": null, "summary": "Retrieval Augmented Generation (RAG) enhances Large Language Models (LLMs) by connecting them to external knowledge, improving accuracy and reducing outdated information. However, this introduces challenges such as factual inconsistencies, source conflicts, bias propagation, and security vulnerabilities, which undermine the trustworthiness of RAG systems. A key gap in current RAG evaluation is the lack of a metric to quantify the contribution of individual retrieved documents to the final output. To address this, we introduce the Influence Score (IS), a novel metric based on Partial Information Decomposition that measures the impact of each retrieved document on the generated response. We validate IS through two experiments. First, a poison attack simulation across three datasets demonstrates that IS correctly identifies the malicious document as the most influential in $86\\%$ of cases. Second, an ablation study shows that a response generated using only the top-ranked documents by IS is consistently judged more similar to the original response than one generated from the remaining documents. These results confirm the efficacy of IS in isolating and quantifying document influence, offering a valuable tool for improving the transparency and reliability of RAG systems."}
{"id": "2601.05270", "categories": ["cs.IR", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.05270", "abs": "https://arxiv.org/abs/2601.05270", "authors": ["Tarun Prajapati"], "title": "LiveVectorLake: A Real-Time Versioned Knowledge Base Architecture for Streaming Vector Updates and Temporal Retrieval", "comment": "7 pages, 1 figure. Preprint; work in progress", "summary": "Modern Retrieval-Augmented Generation (RAG) systems struggle with a fundamental architectural tension: vector indices are optimized for query latency but poorly handle continuous knowledge updates, while data lakes excel at versioning but introduce query latency penalties. We introduce LiveVectorLake, a dual-tier temporal knowledge base architecture that enables real-time semantic search on current knowledge while maintaining complete version history for compliance, auditability, and point-in-time retrieval. The system introduces three core architectural contributions: (1) Content-addressable chunk-level synchronization using SHA-256 hashing for deterministic change detection without external state tracking; (2) Dual-tier storage separating hot-tier vector indices (Milvus with HNSW) from cold-tier columnar versioning (Delta Lake with Parquet), optimizing query latency and storage cost independently; (3) Temporal query routing enabling point-in-time knowledge retrieval via delta-versioning with ACID consistency across tiers. Evaluation on a 100-document corpus versioned across five time points demonstrates: (i) 10-15% re-processing of content during updates compared to 100% for full re-indexing; (ii) sub-100ms retrieval latency on current knowledge; (iii) sub-2s latency for temporal queries across version history; and (iv) storage cost optimization through hot/cold tier separation (only current chunks in expensive vector indices). The approach enables production RAG deployments requiring simultaneous optimization for query performance, update efficiency, and regulatory compliance. Code and resources: [https://github.com/praj-tarun/LiveVectorLake]"}
{"id": "2601.05655", "categories": ["cs.IT", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.05655", "abs": "https://arxiv.org/abs/2601.05655", "authors": ["Stella Civelli", "Marco Secondini", "Luca Potì"], "title": "Nonlinearity Mitigation for Coherent Ground-to-Satellite Optical Links", "comment": "The paper has been accepted for poster presentation at the optical fiber communication (OFC) conference 2026", "summary": "We propose digital signal processing techniques for nonlinearity mitigation in high power optical amplifiers used in satellite communications. The acceptable link loss increases by 6dB with negligible complexity."}
{"id": "2601.05261", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05261", "abs": "https://arxiv.org/abs/2601.05261", "authors": ["Muhammad Mufti", "Omar Hammad", "Mahfuzur Rahman"], "title": "Improving User Experience with Personalized Review Ranking and Summarization", "comment": null, "summary": "Online consumer reviews play a crucial role in guiding purchase decisions by offering insights into product quality, usability, and performance. However, the increasing volume of user-generated reviews has led to information overload, making it difficult for consumers to identify content that aligns with their specific preferences. Existing review ranking systems typically rely on metrics such as helpfulness votes, star ratings, and recency, but these fail to capture individual user interests and often treat textual sentiment and rating signals separately. This research addresses these limitations by proposing a personalized framework that integrates review ranking and abstractive summarization to enhance decision-making efficiency. The proposed system begins by modeling each user's sentiment through a hybrid analysis of star ratings and review content. Simultaneously, user preferences were derived from historical reviews using sentence embeddings and clustering, forming semantic profiles aligned with thematic and sentiment dimensions. A relevance scoring algorithm matched these profiles with unseen reviews based on sentiment and aspect similarity. Top-matched reviews were then summarized to reflect individual interests. A user study with 70 participants demonstrated that the personalized approach improved satisfaction, perceived relevance, and decision-making confidence, while reducing time spent reading. The results highlight the method's effectiveness in alleviating information overload and delivering content tailored to user-specific preferences, emphasizing its value in enhancing user experience in review-rich decision-making environments."}
{"id": "2601.05674", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.05674", "abs": "https://arxiv.org/abs/2601.05674", "authors": ["Torben Kölle", "Alexander Stutz-Tirri", "Christoph Studer"], "title": "On the Complexity of Electromagnetic Far-Field Modeling", "comment": "Accepted for presentation at the 2026 International Zurich Seminar on Information and Communication", "summary": "Modern wireless systems are envisioned to employ antenna architectures that not only transmit and receive electromagnetic (EM) waves, but also intentionally reflect and possibly transform incident EM waves. In this paper, we propose a mathematically rigorous framework grounded in Maxwell's equations for analyzing the complexity of EM far-field modeling of general antenna architectures. We show that-under physically meaningful assumptions-such antenna architectures exhibit limited complexity, i.e., can be modeled by finite-rank operators using finitely many parameters. Furthermore, we construct a sequence of finite-rank operators whose approximation error decays super-exponentially once the operator rank exceeds an effective bandwidth associated with the antenna architecture and the analysis frequency. These results constitute a fundamental prerequisite for the efficient and accurate modeling of general antenna architectures on digital computing platforms."}
{"id": "2601.05262", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05262", "abs": "https://arxiv.org/abs/2601.05262", "authors": ["Xiaocong Yang"], "title": "LLM2IR: simple unsupervised contrastive learning makes long-context LLM great retriever", "comment": "MS Thesis", "summary": "Modern dense information retrieval (IR) models usually rely on costly large-scale pretraining. In this paper, we introduce LLM2IR, an efficient unsupervised contrastive learning framework to convert any decoder-only large language model (LLM) to an information retrieval model. Despite its simplicity, the effectiveness is proven among different LLMs on multiple IR benchmarks including LoCo, LongEmbed and BEIR. We also find that models with a longer context length tend to have a stronger IR capacity by comparing task performances of models in the same model family. Our work not only provides an effective way to build IR models on the state-of-the-art LLMs, but also shed light on the relationship between information retrieval ability and model context length, which helps the design of better information retrievers."}
{"id": "2601.05686", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.05686", "abs": "https://arxiv.org/abs/2601.05686", "authors": ["Zhenqiao Cheng", "Chongjun Ouyang", "Boqun Zhao", "Xingqi Zhang"], "title": "Secure Multiuser Beamforming With Movable Antenna Arrays", "comment": "6 pages; code available at https://github.com/DragonAim0597/Secure-Multiuser-Beamforming-With-Movable-Antenna-Arrays", "summary": "A movable antennas (MAs)-enabled secure multiuser transmission framework is developed to enhance physical-layer security. Novel expressions are derived to characterize the achievable sum secrecy rate based on the secure channel coding theorem. On this basis, a joint optimization algorithm for digital beamforming and MA placement is proposed to maximize the sum secrecy rate via fractional programming and block coordinate descent. In each iteration, every variable admits either a closed-form update or a low-complexity one-dimensional or bisection search, which yields an efficient implementation. Numerical results demonstrate the effectiveness of the proposed method and show that the MA-enabled design achieves higher secrecy rates than conventional fixed-position antenna arrays."}
{"id": "2601.05263", "categories": ["cs.IR", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.05263", "abs": "https://arxiv.org/abs/2601.05263", "authors": ["Zhen Yi Lau"], "title": "A General Metric-Space Formulation of the Time Warp Edit Distance (TWED)", "comment": "20 pages, 1 algorithm, small technical note on the generalization of the Time Warp Edit Distance (TWED) to arbitrary metric spaces", "summary": "This short technical note presents a formal generalization of the Time Warp Edit Distance (TWED) proposed by Marteau (2009) to arbitrary metric spaces. By viewing both the observation and temporal domains as metric spaces $(X, d)$ and $(T, Δ)$, we define a Generalized TWED (GTWED) that remains a true metric under mild assumptions. We provide self-contained proofs of its metric properties and show that the classical TWED is recovered as a special case when $X = \\mathbb{R}^d$, $T \\subset \\mathbb{R}$, and $g(x) = x$. This note focuses on the theoretical structure of GTWED and its implications for extending elastic distances beyond time series, which enables the use of TWED-like metrics on sequences over arbitrary domains such as symbolic data, manifolds, or embeddings."}
{"id": "2601.05873", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05873", "abs": "https://arxiv.org/abs/2601.05873", "authors": ["Javad Maheri", "K. K. Krishnan Namboodiri", "Petros Elia"], "title": "Universal and Asymptotically Optimal Data and Task Allocation in Distributed Computing", "comment": "49 pages, 2 figures", "summary": "We study the joint minimization of communication and computation costs in distributed computing, where a master node coordinates $N$ workers to evaluate a function over a library of $n$ files. Assuming that the function is decomposed into an arbitrary subfunction set $\\mathbf{X}$, with each subfunction depending on $d$ input files, renders our distributed computing problem into a $d$-uniform hypergraph edge partitioning problem wherein the edge set (subfunction set), defined by $d$-wise dependencies between vertices (files) must be partitioned across $N$ disjoint groups (workers). The aim is to design a file and subfunction allocation, corresponding to a partition of $\\mathbf{X}$, that minimizes the communication cost $π_{\\mathbf{X}}$, representing the maximum number of distinct files per server, while also minimizing the computation cost $δ_{\\mathbf{X}}$ corresponding to a maximal worker subfunction load. For a broad range of parameters, we propose a deterministic allocation solution, the \\emph{Interweaved-Cliques (IC) design}, whose information-theoretic-inspired interweaved clique structure simultaneously achieves order-optimal communication and computation costs, for a large class of decompositions $\\mathbf{X}$. This optimality is derived from our achievability and converse bounds, which reveal -- under reasonable assumptions on the density of $\\mathbf{X}$ -- that the optimal scaling of the communication cost takes the form $n/N^{1/d}$, revealing that our design achieves the order-optimal \\textit{partitioning gain} that scales as $N^{1/d}$, while also achieving an order-optimal computation cost. Interestingly, this order optimality is achieved in a deterministic manner, and very importantly, it is achieved blindly from $\\mathbf{X}$, therefore enabling multiple desired functions to be computed without reshuffling files."}
{"id": "2601.05264", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05264", "abs": "https://arxiv.org/abs/2601.05264", "authors": ["Dean Wampler", "Dave Nielson", "Alireza Seddighi"], "title": "Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems", "comment": "86 pages, 2 figures, 37 tables. A comprehensive review of Retrieval-Augmented Generation (RAG) architectures and trust frameworks (2018-2025), encompassing a unified taxonomy, evaluation benchmarks, and trust-safety modeling", "summary": "This article provides a comprehensive systematic literature review of academic studies, industrial applications, and real-world deployments from 2018 to 2025, providing a practical guide and detailed overview of modern Retrieval-Augmented Generation (RAG) architectures. RAG offers a modular approach for integrating external knowledge without increasing the capacity of the model as LLM systems expand. Research and engineering practices have been fragmented as a result of the increasing diversity of RAG methodologies, which encompasses a variety of fusion mechanisms, retrieval strategies, and orchestration approaches. We provide quantitative assessment frameworks, analyze the implications for trust and alignment, and systematically consolidate existing RAG techniques into a unified taxonomy. This document is a practical framework for the deployment of resilient, secure, and domain-adaptable RAG systems, synthesizing insights from academic literature, industry reports, and technical implementation guides. It also functions as a technical reference."}
{"id": "2601.05983", "categories": ["cs.IT", "cs.NI", "cs.SI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.05983", "abs": "https://arxiv.org/abs/2601.05983", "authors": ["Arunabh Srivastava", "Sennur Ulukus"], "title": "Age of Gossip With Cellular Drone Mobility", "comment": null, "summary": "We consider a cellular network containing $n$ nodes where nodes within a cell gossip with each other in a fully-connected fashion and a source shares updates with these nodes via a mobile drone. The mobile drone receives updates directly from the source and shares them with nodes in the cell where it currently resides. The drone moves between cells according to an underlying continuous-time Markov chain (CTMC). In this work, we evaluate the impact of the number of cells $f(n)$, drone speed $λ_m(n)$ and drone dissemination rate $λ_d(n)$ on the freshness of information of nodes in the network. We utilize the version age of information metric to quantify the freshness of information. We observe that the expected duration between two drone-to-cell service times depends on the stationary distribution of the underlying CTMC and $λ_d(n)$, but not on $λ_m(n)$. However, the version age instability in slow moving CTMCs makes high probability analysis for a general underlying CTMC difficult. Therefore, next we focus on the fully-connected drone mobility model. Under this model, we uncover a dual-bottleneck between drone mobility and drone dissemination speed: the version age is constrained by the slower of these two processes. If $λ_d(n) \\gg λ_m(n)$, then the version age scaling of nodes is dominated by the inverse of $λ_m(n)$ and is independent of $λ_d(n)$. If $λ_m(n) \\gg λ_d(n)$, then the version age scaling of nodes is dominated by the inverse of $λ_d(n)$ and is independent of $λ_m(n)$."}
{"id": "2601.05265", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05265", "abs": "https://arxiv.org/abs/2601.05265", "authors": ["Mile Stankovic"], "title": "Cross-Document Topic-Aligned Chunking for Retrieval-Augmented Generation", "comment": null, "summary": "Chunking quality determines RAG system performance. Current methods partition documents individually, but complex queries need information scattered across multiple sources: the knowledge fragmentation problem. We introduce Cross-Document Topic-Aligned (CDTA) chunking, which reconstructs knowledge at the corpus level. It first identifies topics across documents, maps segments to each topic, and synthesizes them into unified chunks.\n  On HotpotQA multi-hop reasoning, our method reached 0.93 faithfulness versus 0.83 for contextual retrieval and 0.78 for semantic chunking, a 12% improvement over current industry best practice (p < 0.05). On UAE Legal texts, it reached 0.94 faithfulness with 0.93 citation accuracy. At k = 3, it maintains 0.91 faithfulness while semantic methods drop to 0.68, with a single CDTA chunk containing information requiring multiple traditional fragments.\n  Indexing costs are higher, but synthesis produces information-dense chunks that reduce query-time retrieval needs. For high-query-volume applications with distributed knowledge, cross-document synthesis improves measurably over within-document optimization."}
{"id": "2601.05266", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05266", "abs": "https://arxiv.org/abs/2601.05266", "authors": ["Muzakkiruddin Ahmed Mohammed", "John R. Talburt", "Leon Claasssens", "Adriaan Marais"], "title": "Retrieval-Augmented Multi-LLM Ensemble for Industrial Part Specification Extraction", "comment": "The 17th International Conference on Knowledge and Systems Engineering", "summary": "Industrial part specification extraction from unstructured text remains a persistent challenge in manufacturing, procurement, and maintenance, where manual processing is both time-consuming and error-prone. This paper introduces a retrieval-augmented multi-LLM ensemble framework that orchestrates nine state-of-the-art Large Language Models (LLMs) within a structured three-phase pipeline. RAGsemble addresses key limitations of single-model systems by combining the complementary strengths of model families including Gemini (2.0, 2.5, 1.5), OpenAI (GPT-4o, o4-mini), Mistral Large, and Gemma (1B, 4B, 3n-e4b), while grounding outputs in factual data using FAISS-based semantic retrieval. The system architecture consists of three stages: (1) parallel extraction by diverse LLMs, (2) targeted research augmentation leveraging high-performing models, and (3) intelligent synthesis with conflict resolution and confidence-aware scoring. RAG integration provides real-time access to structured part databases, enabling the system to validate, refine, and enrich outputs through similarity-based reference retrieval. Experimental results using real industrial datasets demonstrate significant gains in extraction accuracy, technical completeness, and structured output quality compared to leading single-LLM baselines. Key contributions include a scalable ensemble architecture for industrial domains, seamless RAG integration throughout the pipeline, comprehensive quality assessment mechanisms, and a production-ready solution suitable for deployment in knowledge-intensive manufacturing environments."}
{"id": "2601.05267", "categories": ["cs.IR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05267", "abs": "https://arxiv.org/abs/2601.05267", "authors": ["Geonwoo Bang", "Dongho Kim", "Moohong Min"], "title": "Transforming User Defined Criteria into Explainable Indicators with an Integrated LLM AHP System", "comment": null, "summary": "Evaluating complex texts across domains requires converting user defined criteria into quantitative, explainable indicators, which is a persistent challenge in search and recommendation systems. Single prompt LLM evaluations suffer from complexity and latency issues, while criterion specific decomposition approaches rely on naive averaging or opaque black-box aggregation methods. We present an interpretable aggregation framework combining LLM scoring with the Analytic Hierarchy Process. Our method generates criterion specific scores via LLM as judge, measures discriminative power using Jensen Shannon distance, and derives statistically grounded weights through AHP pairwise comparison matrices. Experiments on Amazon review quality assessment and depression related text scoring demonstrate that our approach achieves high explainability and operational efficiency while maintaining comparable predictive power, making it suitable for real time latency sensitive web services."}
{"id": "2601.05268", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05268", "abs": "https://arxiv.org/abs/2601.05268", "authors": ["Rob Koopman"], "title": "Separating Semantic Expansion from Linear Geometry for PubMed-Scale Vector Search", "comment": "4 pages", "summary": "We describe a PubMed scale retrieval framework that separates semantic interpretation from metric geometry. A large language model expands a natural language query into concise biomedical phrases; retrieval then operates in a fixed, mean free, approximately isotropic embedding space. Each document and query vector is formed as a weighted mean of token embeddings, projected onto the complement of nuisance axes and compressed by a Johnson Lindenstrauss transform. No parameters are trained. The system retrieves coherent biomedical clusters across the full MEDLINE corpus (about 40 million records) using exact cosine search on 256 dimensional int8 vectors. Evaluation is purely geometric: head cosine, compactness, centroid closure, and isotropy are compared with random vector baselines. Recall is not defined, since the language-model expansion specifies the effective target set."}
{"id": "2601.05269", "categories": ["cs.IR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05269", "abs": "https://arxiv.org/abs/2601.05269", "authors": ["Yoav Evron", "Michal Bar-Asher Siegal", "Michael Fire"], "title": "Studying Illustrations in Manuscripts: An Efficient Deep-Learning Approach", "comment": "14 pages, 5 figures", "summary": "The recent Artificial Intelligence (AI) revolution has opened transformative possibilities for the humanities, particularly in unlocking the visual content embedded in historical manuscripts. While digital archives now offer unprecedented access to these materials, the ability to systematically study illustrations at a large scale remains challenging. Our study presents a fast and scalable AI approach for detecting, extracting, and describing illustrations in digitized manuscripts. Focusing on collections like the Vatican Library, our system enables efficient visual analysis across millions of pages. Our pipeline consists of three stages: (1) a fine-tuned image classification model filters out text-only pages; (2) an efficient object detection model identifies and crops illustrations; and (3) a multimodal image captioning model generates concise, human-readable descriptions. These are stored in a searchable database, allowing scholars to retrieve relevant visual materials through keyword queries. By harnessing the power of recent AI advancements, we enable large-scale visual research that was previously impractical, empowering scholars in historical studies, art history, and cultural heritage to explore visual motifs, artistic styles, and cross-cultural influences with new precision and speed. Applying our pipeline to over three million digitized manuscript pages, we automatically identified and extracted more than 200,000 unique illustrations. This scale of processing in under 0.06 seconds per page, dramatically outperforms traditional segmentation techniques in both efficiency and accessibility for visual scholarship. Our work demonstrates how cutting-edge AI tools can profoundly reshape scholarly workflows and open new avenues for multidisciplinary research in the age of digital manuscripts."}
{"id": "2601.05270", "categories": ["cs.IR", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.05270", "abs": "https://arxiv.org/abs/2601.05270", "authors": ["Tarun Prajapati"], "title": "LiveVectorLake: A Real-Time Versioned Knowledge Base Architecture for Streaming Vector Updates and Temporal Retrieval", "comment": "7 pages, 1 figure. Preprint; work in progress", "summary": "Modern Retrieval-Augmented Generation (RAG) systems struggle with a fundamental architectural tension: vector indices are optimized for query latency but poorly handle continuous knowledge updates, while data lakes excel at versioning but introduce query latency penalties. We introduce LiveVectorLake, a dual-tier temporal knowledge base architecture that enables real-time semantic search on current knowledge while maintaining complete version history for compliance, auditability, and point-in-time retrieval. The system introduces three core architectural contributions: (1) Content-addressable chunk-level synchronization using SHA-256 hashing for deterministic change detection without external state tracking; (2) Dual-tier storage separating hot-tier vector indices (Milvus with HNSW) from cold-tier columnar versioning (Delta Lake with Parquet), optimizing query latency and storage cost independently; (3) Temporal query routing enabling point-in-time knowledge retrieval via delta-versioning with ACID consistency across tiers. Evaluation on a 100-document corpus versioned across five time points demonstrates: (i) 10-15% re-processing of content during updates compared to 100% for full re-indexing; (ii) sub-100ms retrieval latency on current knowledge; (iii) sub-2s latency for temporal queries across version history; and (iv) storage cost optimization through hot/cold tier separation (only current chunks in expensive vector indices). The approach enables production RAG deployments requiring simultaneous optimization for query performance, update efficiency, and regulatory compliance. Code and resources: [https://github.com/praj-tarun/LiveVectorLake]"}
{"id": "2601.05461", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05461", "abs": "https://arxiv.org/abs/2601.05461", "authors": ["Mohammed Ali", "Abdelrahman Abdallah", "Amit Agarwal", "Hitesh Laxmichand Patel", "Adam Jatowt"], "title": "RECOR: Reasoning-focused Multi-turn Conversational Retrieval Benchmark", "comment": null, "summary": "Existing benchmarks treat multi-turn conversation and reasoning-intensive retrieval separately, yet real-world information seeking requires both. To bridge this gap, we present a benchmark for reasoning-based conversational information retrieval comprising 707 conversations (2,971 turns) across eleven domains. To ensure quality, our Decomposition-and-Verification framework transforms complex queries into fact-grounded multi-turn dialogues through multi-level validation, where atomic facts are verified against sources and explicit retrieval reasoning is generated for each turn. Comprehensive evaluation reveals that combining conversation history with reasoning doubles retrieval performance (Baseline .236 $\\rightarrow$ History+Reasoning .479 nDCG@10), while reasoning-specialized models substantially outperform dense encoders. Despite these gains, further analysis highlights that implicit reasoning remains challenging, particularly when logical connections are not explicitly stated in the text."}
{"id": "2601.05513", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05513", "abs": "https://arxiv.org/abs/2601.05513", "authors": ["Lei Wang", "Jinhang Wu", "Zhibin Wang", "Biye Li", "Haiping Hou"], "title": "LEAPS: An LLM-Empowered Adaptive Plugin for Taobao AI Search", "comment": null, "summary": "The rapid advancement of large language models has reshaped user search cognition, driving a paradigm shift from discrete keyword-based search to high-dimensional conversational interaction. However, existing e-commerce search architectures face a critical capability deficit in adapting to this change. Users are often caught in a dilemma: precise natural language descriptions frequently trigger zero-result scenarios, while the forced simplification of queries leads to decision overload from noisy, generic results. To tackle this challenge, we propose LEAPS (LLM-Empowered Adaptive Plugin for Taobao AI Search), which seamlessly upgrades traditional search systems via a \"Broaden-and-Refine\" paradigm. Specifically, it attaches plugins to both ends of the search pipeline: (1) Upstream, a Query Expander acts as an intent translator. It employs a novel three-stage training strategy--inverse data augmentation, posterior-knowledge supervised fine-tuning, and diversity-aware reinforcement learning--to generate adaptive and complementary query combinations that maximize the candidate product set. (2) Downstream, a Relevance Verifier serves as a semantic gatekeeper. By synthesizing multi-source data (e.g., OCR text, reviews) and leveraging chain-of-thought reasoning, it precisely filters noise to resolve selection overload. Extensive offline experiments and online A/B testing demonstrate that LEAPS significantly enhances conversational search experiences. Crucially, its non-invasive architecture preserves established retrieval performance optimized for short-text queries, while simultaneously allowing for low-cost integration into diverse back-ends. Fully deployed on Taobao AI Search since August 2025, LEAPS currently serves hundreds of millions of users monthly."}
{"id": "2601.05549", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05549", "abs": "https://arxiv.org/abs/2601.05549", "authors": ["Tuan-Luc Huynh", "Weiqing Wang", "Trung Le", "Thuy-Trang Vu", "Dragan Gašević", "Yuan-Fang Li", "Thanh-Toan Do"], "title": "Efficient Temporal-aware Matryoshka Adaptation for Temporal Information Retrieval", "comment": "18 pages", "summary": "Retrievers are a key bottleneck in Temporal Retrieval-Augmented Generation (RAG) systems: failing to retrieve temporally relevant context can degrade downstream generation, regardless of LLM reasoning. We propose Temporal-aware Matryoshka Representation Learning (TMRL), an efficient method that equips retrievers with temporal-aware Matryoshka embeddings. TMRL leverages the nested structure of Matryoshka embeddings to introduce a temporal subspace, enhancing temporal encoding while preserving general semantic representations. Experiments show that TMRL efficiently adapts diverse text embedding models, achieving competitive temporal retrieval and temporal RAG performance compared to prior Matryoshka-based non-temporal methods and prior temporal methods, while enabling flexible accuracy-efficiency trade-offs."}
{"id": "2601.05588", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05588", "abs": "https://arxiv.org/abs/2601.05588", "authors": ["Benjamin Rozonoyer", "Chong You", "Michael Boratko", "Himanshu Jain", "Nilesh Gupta", "Srinadh Bhojanapalli", "Andrew McCallum", "Felix Yu"], "title": "Autoregressive Ranking: Bridging the Gap Between Dual and Cross Encoders", "comment": "22 pages, 5 figures", "summary": "Dual and cross encoders have long been mainstays of information retrieval (IR), but are being challenged by the emergent capabilities of LLMs. An LLM-based approach we term pointwise generative ranking - generating tokens the length of a single docID as opposed to a list in order to enable ranking via beam search - combines efficiency and expressivity benefits while leveraging the in-context capabilities of Causal Transformers. Although there is ample evidence to suggest that pretrained LLMs are well-suited for ranking, we find that the vast majority of LLM-based approaches rely on next-token prediction, a loss function which is fundamentally rank-agnostic (and especially so with pointwise supervision). In this paper, we first prove that the expressivity of pointwise generative ranking with multi-token docIDs is superior to that of dual encoders. We then propose SToICaL - a Simple Token-Item Calibrated Loss - which can incorporate rank-aware supervision at both the item and token levels within the pointwise setup. We run a suite of experiments on ranking tasks derived from WordNet (Fellbaum, 1998) and ESCI (Reddy et al., arXiv:2206.06588). Two variants of SToICaL successfully suppress the probability of invalid docID generations and improve on common ranking metrics beyond top-1 retrieval."}
{"id": "2601.05603", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05603", "abs": "https://arxiv.org/abs/2601.05603", "authors": ["Watheq Mansour", "J. Shane Culpepper", "Joel Mackenzie", "Andrew Yates"], "title": "Revisiting Human-vs-LLM judgments using the TREC Podcast Track", "comment": "The paper has been accepted to appear at ECIR 2026", "summary": "Using large language models (LLMs) to annotate relevance is an increasingly important technique in the information retrieval community. While some studies demonstrate that LLMs can achieve high user agreement with ground truth (human) judgments, other studies have argued for the opposite conclusion. To the best of our knowledge, these studies have primarily focused on classic ad-hoc text search scenarios. In this paper, we conduct an analysis on user agreement between LLM and human experts, and explore the impact disagreement has on system rankings. In contrast to prior studies, we focus on a collection composed of audio files that are transcribed into two-minute segments -- the TREC 2020 and 2021 podcast track. We employ five different LLM models to re-assess all of the query-segment pairs, which were originally annotated by TREC assessors. Furthermore, we re-assess a small subset of pairs where LLM and TREC assessors have the highest disagreement, and found that the human experts tend to agree with LLMs more than with the TREC assessors. Our results reinforce the previous insights of Sormunen in 2002 -- that relying on a single assessor leads to lower user agreement."}
{"id": "2601.05649", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05649", "abs": "https://arxiv.org/abs/2601.05649", "authors": ["Giulio D'Erasmo", "Cesare Campagnano", "Antonio Mallia", "Pierpaolo Brutti", "Nicola Tonellotto", "Fabrizio Silvestri"], "title": "Statistical Foundations of DIME: Risk Estimation for Practical Index Selection", "comment": "Accepted to EACL 2026 (Main Conference)", "summary": "High-dimensional dense embeddings have become central to modern Information Retrieval, but many dimensions are noisy or redundant. Recently proposed DIME (Dimension IMportance Estimation), provides query-dependent scores to identify informative components of embeddings. DIME relies on a costly grid search to select a priori a dimensionality for all the query corpus's embeddings. Our work provides a statistically grounded criterion that directly identifies the optimal set of dimensions for each query at inference time. Experiments confirm achieving parity of effectiveness and reduces embedding size by an average of $\\sim50\\%$ across different models and datasets at inference time."}
