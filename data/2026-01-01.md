<div id=toc></div>

# Table of Contents

- [cs.GT](#cs.GT) [Total: 3]
- [cs.DB](#cs.DB) [Total: 3]
- [cs.IR](#cs.IR) [Total: 10]
- [cs.IT](#cs.IT) [Total: 8]
- [cs.DS](#cs.DS) [Total: 7]


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [1] [Personalized Promotions in Practice: Dynamic Allocation and Reference Effects](https://arxiv.org/abs/2512.23781)
*Jackie Baek,Will Ma,Dmitry Mitrofanov*

Main category: cs.GT

TL;DR: 本文提出了一种个性化促销策略，用于向2000万客户发送每日促销（折扣率5种），在满足全局分配约束的同时提升收入。该策略在A/B测试中实现了4.5%的收入增长，并建立了一个考虑客户参考效应的组合定价模型。


<details>
  <summary>Details</summary>
Motivation: 大型在线零售商需要向海量客户（超过2000万）发送每日个性化促销，同时需要满足全局促销分配约束。传统方法难以同时处理个性化推荐和资源约束，且需要考虑客户的跨期行为模式（参考效应）。

Method: 1. 提出高效的个性化促销策略，每天为每个客户确定最佳折扣率（10%、12%、15%、17%、20%），同时满足全局分配约束。2. 建立组合定价模型，考虑客户的参考效应：客户会记住过去ℓ天内看到的最佳促销作为"参考值"，当参考值较差时更可能购买。

Result: 1. 实际部署中，该策略在A/B测试中实现了4.5%的收入增长。2. 理论分析表明，在参考效应模型下，最优策略的结构是：循环提供ℓ次较差的促销值，然后提供一次好的促销值。

Conclusion: 本文提出的个性化促销策略在实际部署中显著提升了收入，同时建立的参考效应模型为理解客户跨期行为提供了理论框架，揭示了最优促销策略的周期性结构。

Abstract: Partnering with a large online retailer, we consider the problem of sending daily personalized promotions to a userbase of over 20 million customers. We propose an efficient policy for determining, every day, the promotion that each customer should receive (10%, 12%, 15%, 17%, or 20% off), while respecting global allocation constraints. This policy was successfully deployed to see a 4.5% revenue increase during an A/B test, by better targeting promotion-sensitive customers and also learning intertemporal patterns across customers.
  We also consider theoretically modeling the intertemporal state of the customer. The data suggests a simple new combinatorial model of pricing with reference effects, where the customer remembers the best promotion they saw over the past $\ell$ days as the "reference value", and is more likely to purchase if this value is poor. We tightly characterize the structure of optimal policies for maximizing long-run average revenue under this model -- they cycle between offering poor promotion values $\ell$ times and offering good values once.

</details>


### [2] [Multilevel Fair Allocation](https://arxiv.org/abs/2512.24105)
*Maxime Lucet,Nawal Benabbou,Aurélie Beynier,Nicolas Maudet*

Main category: cs.GT

TL;DR: 提出多层级公平资源分配框架，针对树状层次结构中的代理，设计两种算法：通用多项式时间顺序算法和扩展的General Yankee Swap算法


<details>
  <summary>Details</summary>
Motivation: 现实世界中资源分配通常具有层次结构（如组织架构），需要在多层级中保持公平性和效率，而现有研究主要关注单层分配问题

Method: 1. 通用多项式时间顺序算法：自上而下操作，兼容多种本地算法，具有理论保证
2. 扩展的General Yankee Swap算法：适应多层级设置，保持实际中的良好公平性

Result: 两种算法在树状层次结构中都能有效工作，第一种算法有理论和效率保证，第二种算法在实际中表现出优秀的公平性

Conclusion: 提出的多层级公平分配框架和算法为解决层次结构中的资源分配问题提供了有效工具，平衡了公平性和效率要求

Abstract: We introduce the concept of multilevel fair allocation of resources with tree-structured hierarchical relations among agents. While at each level it is possible to consider the problem locally as an allocation of an agent to its children, the multilevel allocation can be seen as a trace capturing the fact that the process is iterated until the leaves of the tree. In principle, each intermediary node may have its own local allocation mechanism. The main challenge is then to design algorithms which can retain good fairness and efficiency properties. In this paper we propose two original algorithms under the assumption that leaves of the tree have matroid-rank utility functions and the utility of any internal node is the sum of the utilities of its children. The first one is a generic polynomial-time sequential algorithm that comes with theoretical guarantees in terms of efficiency and fairness. It operates in a top-down fashion -- as commonly observed in real-world applications -- and is compatible with various local algorithms. The second one extends the recently proposed General Yankee Swap to the multilevel setting. This extension comes with efficiency guarantees only, but we show that it preserves excellent fairness properties in practice.

</details>


### [3] [On the Difficulty of Measuring Divisiveness of Proposals under Ranked Preferences](https://arxiv.org/abs/2512.24467)
*Ulle Endriss*

Main category: cs.GT

TL;DR: 该研究探讨如何从公众政策提案中识别"最具争议性"的提案，用于数字民主平台，但发现满足基本规范要求的争议性提案选择面临根本性困难


<details>
  <summary>Details</summary>
Motivation: 为数字民主平台设计功能，识别最具争议性的政策提案，以分析审议进展并引导讨论，但需要明确"争议性"的定义

Method: 采用社会选择理论中的公理化方法，基于人们对提案的偏好陈述，探索选择最具争议性提案的可能性，并检验其规范性要求

Result: 研究发现，以看似温和的规范性要求来选择最具争议性提案的任务面临一系列根本性困难

Conclusion: 在数字民主平台中设计争议性提案识别功能时，需要认识到满足基本规范要求的选择机制存在理论上的根本挑战

Abstract: Given the stated preferences of several people over a number of proposals regarding public policy initiatives, some of those proposals might be judged to be more ``divisive'' than others. When designing online participatory platforms to support digital democracy initiatives enabling citizens to deliberate over such proposals, we might wish to equip those platforms with the functionality to retrieve the most divisive proposals currently under discussion. Such a service would be useful for analysing the progress of deliberation and steering discussion towards issues that still require further debate. Guided by this use case, we explore possibilities for providing a clear definition of what it means to select a set of most divisive proposals on the basis of people's stated preferences over proposals. Then, employing the axiomatic method familiar from social choice theory, we show that the task of selecting the most divisive proposals in a manner that satisfies certain seemingly mild normative requirements faces a number of fundamental difficulties.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [4] [Hojabr: Towards a Theory of Everything for AI and Data Analytics](https://arxiv.org/abs/2512.23925)
*Amir Shaikhha*

Main category: cs.DB

TL;DR: Hojabr是一个统一的声明性中间语言，将关系代数、张量代数和基于约束的推理集成到单一的高阶代数框架中，解决数据分析管道中不同范式之间的碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 现代数据分析管道越来越多地在单个应用中结合关系查询、图处理和Tensor计算，但现有系统在不同范式、执行模型和研究社区之间仍然碎片化。这种碎片化导致重复的优化工作、有限的互操作性以及逻辑抽象与物理执行策略之间的严格分离。

Method: 提出Hojabr作为统一的声明性中间语言，将关系代数、张量代数和基于约束的推理集成到单一的高阶代数框架中。在该框架中，连接、聚合、张量收缩和递归计算可以统一表达。物理选择（如连接算法、执行模型、稀疏与密集张量表示）作为约束专门化决策处理，而不是单独的形式化方法。

Result: Hojabr支持与现有声明性语言的双向翻译，使程序既能降级到Hojabr进行分析和优化，又能提升回原始声明形式。通过使语义、结构和代数属性显式化，并支持编译堆栈的可扩展性，Hojabr实现了跨数据库系统、机器学习框架和编译器基础设施的系统化推理和优化技术重用。

Conclusion: Hojabr通过统一的代数框架解决了数据分析中的范式碎片化问题，为跨不同计算范式的系统化优化和互操作性提供了基础。

Abstract: Modern data analytics pipelines increasingly combine relational queries, graph processing, and tensor computation within a single application, but existing systems remain fragmented across paradigms, execution models, and research communities. This fragmentation results in repeated optimization efforts, limited interoperability, and strict separation between logical abstractions and physical execution strategies.
  We propose Hojabr as a unified declarative intermediate language to address this problem. Hojabr integrates relational algebra, tensor algebra, and constraint-based reasoning within a single higher-order algebraic framework, in which joins, aggregations, tensor contractions, and recursive computations are expressed uniformly. Physical choices, such as join algorithms, execution models, and sparse versus dense tensor representations, are handled as constraint-specialization decisions rather than as separate formalisms. Hojabr supports bidirectional translation with existing declarative languages, enabling programs to be both lowered into Hojabr for analysis and optimization and lifted back into their original declarative form. By making semantic, structural, and algebraic properties explicit, and by supporting extensibility across the compilation stack, Hojabr enables systematic reasoning and reuse of optimization techniques across database systems, machine learning frameworks, and compiler infrastructures.

</details>


### [5] [High-dimensional Regret Minimization](https://arxiv.org/abs/2512.24078)
*Junyu Liao,Ashwin Lall,Mitsunori Ogihara,Raymond Wong*

Main category: cs.DB

TL;DR: FHDR框架通过少于30轮交互和0.01秒处理时间，解决了高维数据集交互查询的扩展性问题，相比现有方法有数量级提升。


<details>
  <summary>Details</summary>
Motivation: 现有交互查询算法在处理具有数百个属性的高维数据集时，要么无法扩展，要么需要过多用户交互（常超过1000轮），这在住房、金融产品等现代应用中存在严重限制。

Method: 提出FHDR（快速高维约简）框架，通过高效降维和优化交互策略，显著减少处理时间和用户交互轮数。

Result: FHDR在少于30轮交互和0.01秒内完成处理，相比最佳现有算法在执行时间上至少提升一个数量级，在交互轮数上提升数个数量级，建立了可扩展交互后悔最小化的新标准。

Conclusion: FHDR是交互查询领域的突破性进展，首次实现了对高维数据集的高效可扩展处理，为实际应用提供了实用解决方案。

Abstract: Multi-criteria decision making in large databases is very important in real world applications. Recently, an interactive query has been studied extensively in the database literature with the advantage of both the top-k query (with limited output size) and the skyline query (which does not require users to explicitly specify their preference function). This approach iteratively asks the user to select the one preferred within a set of options. Based on rounds of feedback, the query learns the implicit preference and returns the most favorable as a recommendation.
  However, many modern applications in areas like housing or financial product markets feature datasets with hundreds of attributes. Existing interactive algorithms either fail to scale or require excessive user interactions (often exceeding 1000 rounds). Motivated by this, we propose FHDR (Fast High-Dimensional Reduction), a novel framework that takes less than 0.01s with fewer than 30 rounds of interaction. It is considered a breakthrough in the field of interactive queries since most, if not all, existing studies are not scalable to high-dimensional datasets.
  Extensive experiments demonstrate that FHDR outperforms the best-known algorithms by at least an order of magnitude in execution time and up to several orders of magnitude in terms of the number of interactions required, establishing a new state of the art for scalable interactive regret minimization.

</details>


### [6] [LMG Index: A Robust Learned Index for Multi-Dimensional Performance Balance](https://arxiv.org/abs/2512.24824)
*Yuzhen Chen,Bin Yao*

Main category: cs.DB

TL;DR: LMIndex是一个鲁棒的机器学习索引框架，通过高效查询/更新顶层结构和最优误差阈值训练算法，结合间隙分配策略的LMG变体，在多维度性能上打破传统权衡。


<details>
  <summary>Details</summary>
Motivation: 现有学习索引大多只优化查询延迟或空间使用等有限目标，忽略了更新效率和稳定性等实际评估维度，且依赖数据分布假设，缺乏理论保证，限制了在实际系统中的通用性。

Method: 提出LMIndex框架：1) 高效查询/更新顶层结构（理论上O(1)复杂度）；2) 高效最优误差阈值训练算法（实践中接近O(1)）。在此基础上开发LMG变体，采用新颖的间隙分配策略提升更新性能和动态工作负载下的稳定性。

Result: LMG在多维度性能上表现优异：批量加载快8.25倍，点查询快1.49倍，范围查询比B+树快4.02倍，读写工作负载更新快1.5倍，稳定性提升82.59倍（变异系数更低），空间使用减少1.38倍。

Conclusion: LMG有效打破了现有方法在多维度性能上的权衡，提供了一个平衡且通用的框架，在实际系统中具有更好的适用性。

Abstract: Index structures are fundamental for efficient query processing on large-scale datasets. Learned indexes model the indexing process as a prediction problem to overcome the inherent trade-offs of traditional indexes. However, most existing learned indexes optimize only for limited objectives like query latency or space usage, neglecting other practical evaluation dimensions such as update efficiency and stability. Moreover, many learned indexes rely on assumptions about data distributions or workloads, lacking theoretical guarantees when facing unknown or evolving scenarios, which limits their generality in real-world systems.
  In this paper, we propose LMIndex, a robust framework for learned indexing that leverages a efficient query/update top-layer structure (theoretically $O(1)$ when the key type is fixed) and a efficient optimal error threshold training algorithm (approach $O(1)$ in practice). Building upon this, we develop LMG (LMIndex with gaps), a variant employing a novel gap allocation strategy to enhance update performance and maintain stability under dynamic workloads. Extensive evaluations show that LMG achieves competitive or leading performance, including bulk loading (up to 8.25$\times$ faster), point queries (up to 1.49$\times$ faster), range queries (up to 4.02$\times$ faster than B+Tree), update (up to 1.5$\times$ faster on read-write workloads), stability (up to 82.59$\times$ lower coefficient of variation), and space usage (up to 1.38$\times$ smaller). These results demonstrate that LMG effectively breaks the multi-dimensional performance trade-offs inherent in state-of-the-art approaches, offering a balanced and versatile framework.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [7] [An Comparative Analysis about KYC on a Recommendation System Toward Agentic Recommendation System](https://arxiv.org/abs/2512.23961)
*Junjie H. Xu*

Main category: cs.IR

TL;DR: 该研究提出了一种利用智能体AI的KYC推荐系统，并在五个内容垂直领域（广告、新闻、八卦、用户生成内容、技术）进行评估，通过nDCG指标比较不同KYC使用强度的实验组表现。


<details>
  <summary>Details</summary>
Motivation: 金融领域的KYC（了解你的客户）需要更智能的推荐系统来提升用户体验和业务效果，现有系统在多个内容垂直领域的表现需要系统性评估和优化。

Method: 使用智能体AI构建推荐系统，在五个内容垂直领域（广告、新闻、八卦、用户生成内容、技术）进行实验，将用户按KYC使用强度分为四个实验组，使用nDCG@k（k=1,3,5）作为评估指标，并参考百度、小红书等行业基准。

Result: 研究展示了不同KYC使用强度实验组在五个内容垂直领域的推荐性能对比，通过nDCG指标量化了智能体推荐系统的效果，并与行业基准进行了比较。

Conclusion: 智能体AI驱动的KYC推荐系统在多个内容垂直领域表现出色，为大规模智能体推荐系统的工程实现提供了实证依据和设计指导。

Abstract: This research presents a cutting-edge recommendation system utilizing agentic AI for KYC (Know Your Customer in the financial domain), and its evaluation across five distinct content verticals: Advertising (Ad), News, Gossip, Sharing (User-Generated Content), and Technology (Tech). The study compares the performance of four experimental groups, grouping by the intense usage of KYC, benchmarking them against the Normalized Discounted Cumulative Gain (nDCG) metric at truncation levels of $k=1$, $k=3$, and $k=5$. By synthesizing experimental data with theoretical frameworks and industry benchmarks from platforms such as Baidu and Xiaohongshu, this research provides insight by showing experimental results for engineering a large-scale agentic recommendation system.

</details>


### [8] [Time-Aware Adaptive Side Information Fusion for Sequential Recommendation](https://arxiv.org/abs/2512.24246)
*Jie Luo,Wenyu Zhang,Xinming Zhang,Yuan Fang*

Main category: cs.IR

TL;DR: TASIF框架通过时间感知、自适应降噪和高效融合机制，解决了序列推荐中侧信息融合的三个关键挑战：忽略时间动态、易受噪声影响和计算成本高。


<details>
  <summary>Details</summary>
Motivation: 当前序列推荐模型在融合商品侧信息（如类别、品牌）时存在三个主要局限：1）忽略时间戳中的细粒度时间动态；2）对用户交互序列中的噪声敏感；3）依赖计算昂贵的融合架构。

Method: 提出TASIF框架，包含三个协同组件：1）简单即插即用的时间跨度划分机制捕捉全局时间模式；2）自适应频率滤波器使用可学习门控自适应降噪特征序列；3）高效自适应侧信息融合层采用"引导不混合"架构，属性引导注意力机制但不混入内容表示的商品嵌入。

Result: 在四个公开数据集上的大量实验表明，TASIF显著优于最先进的基线方法，同时在训练中保持出色的效率。

Conclusion: TASIF框架通过系统性地解决时间动态、噪声鲁棒性和计算效率三个挑战，为序列推荐中的侧信息融合提供了有效的解决方案。

Abstract: Incorporating item-side information, such as category and brand, into sequential recommendation is a well-established and effective approach for improving performance. However, despite significant advancements, current models are generally limited by three key challenges: they often overlook the fine-grained temporal dynamics inherent in timestamps, exhibit vulnerability to noise in user interaction sequences, and rely on computationally expensive fusion architectures. To systematically address these challenges, we propose the Time-Aware Adaptive Side Information Fusion (TASIF) framework. TASIF integrates three synergistic components: (1) a simple, plug-and-play time span partitioning mechanism to capture global temporal patterns; (2) an adaptive frequency filter that leverages a learnable gate to denoise feature sequences adaptively, thereby providing higher-quality inputs for subsequent fusion modules; and (3) an efficient adaptive side information fusion layer, this layer employs a "guide-not-mix" architecture, where attributes guide the attention mechanism without being mixed into the content-representing item embeddings, ensuring deep interaction while ensuring computational efficiency. Extensive experiments on four public datasets demonstrate that TASIF significantly outperforms state-of-the-art baselines while maintaining excellent efficiency in training. Our source code is available at https://github.com/jluo00/TASIF.

</details>


### [9] [RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation](https://arxiv.org/abs/2512.24268)
*Pankayaraj Pathmanathan,Michael-Andrei Panaitescu-Liess,Cho-Yu Jason Chiang,Furong Huang*

Main category: cs.IR

TL;DR: 提出RAGPart和RAGMask两种检索阶段防御方法，对抗RAG系统中的语料库投毒攻击，无需修改生成模型，在保持良性性能的同时显著降低攻击成功率。


<details>
  <summary>Details</summary>
Motivation: RAG系统虽然能增强LLM的外部知识并减少幻觉，但面临语料库投毒攻击的严重漏洞，攻击者可通过注入恶意文档操纵模型输出，需要有效的防御机制。

Method: 提出两种互补的检索阶段防御：1) RAGPart利用稠密检索器的训练动态，通过文档分区减轻中毒点的影响；2) RAGMask基于目标令牌掩码下的显著相似度偏移识别可疑令牌。

Result: 在两个基准测试、四种投毒策略和四种最先进检索器上，防御方法能持续降低攻击成功率，同时在良性条件下保持效用。还引入了可解释的攻击来压力测试防御机制。

Conclusion: 研究展示了检索阶段防御的潜力和局限性，为稳健的RAG部署提供了实用见解，强调在检索阶段直接防御的轻量级优势。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to enhance large language models (LLMs) with external knowledge, reducing hallucinations and compensating for outdated information. However, recent studies have exposed a critical vulnerability in RAG pipelines corpus poisoning where adversaries inject malicious documents into the retrieval corpus to manipulate model outputs. In this work, we propose two complementary retrieval-stage defenses: RAGPart and RAGMask. Our defenses operate directly on the retriever, making them computationally lightweight and requiring no modification to the generation model. RAGPart leverages the inherent training dynamics of dense retrievers, exploiting document partitioning to mitigate the effect of poisoned points. In contrast, RAGMask identifies suspicious tokens based on significant similarity shifts under targeted token masking. Across two benchmarks, four poisoning strategies, and four state-of-the-art retrievers, our defenses consistently reduce attack success rates while preserving utility under benign conditions. We further introduce an interpretable attack to stress-test our defenses. Our findings highlight the potential and limitations of retrieval-stage defenses, providing practical insights for robust RAG deployments.

</details>


### [10] [MaRCA: Multi-Agent Reinforcement Learning for Dynamic Computation Allocation in Large-Scale Recommender Systems](https://arxiv.org/abs/2512.24325)
*Wan Jiang,Xinyi Zang,Yudong Zhao,Yusi Zou,Yunfei Lu,Junbo Tong,Yang Liu,Ming Li,Jiani Shi,Xin Yang*

Main category: cs.IR

TL;DR: MaRCA：基于多智能体强化学习的推荐系统端到端计算资源分配框架，在保持现有计算资源不变的情况下实现16.67%的收入提升


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统面临模型复杂度和流量规模增长带来的计算挑战，现有方法通常简化多阶段计算资源分配，忽略阶段间依赖关系，限制了全局最优性

Method: 提出MaRCA框架：1）将推荐系统各阶段建模为合作智能体，采用集中训练分散执行（CTDE）优化资源约束下的收入；2）引入AutoBucket TestBench进行精确计算成本估计；3）使用基于模型预测控制（MPC）的收入-成本平衡器预测流量负载并调整权衡

Result: 自2024年11月在领先全球电商平台的广告流水线端到端部署以来，MaRCA每天稳定处理数千亿广告请求，在现有计算资源下实现16.67%的收入提升

Conclusion: MaRCA通过多智能体强化学习框架有效解决了大规模推荐系统中的计算资源分配问题，实现了端到端的优化，显著提升了业务收入

Abstract: Modern recommender systems face significant computational challenges due to growing model complexity and traffic scale, making efficient computation allocation critical for maximizing business revenue. Existing approaches typically simplify multi-stage computation resource allocation, neglecting inter-stage dependencies, thus limiting global optimality. In this paper, we propose MaRCA, a multi-agent reinforcement learning framework for end-to-end computation resource allocation in large-scale recommender systems. MaRCA models the stages of a recommender system as cooperative agents, using Centralized Training with Decentralized Execution (CTDE) to optimize revenue under computation resource constraints. We introduce an AutoBucket TestBench for accurate computation cost estimation, and a Model Predictive Control (MPC)-based Revenue-Cost Balancer to proactively forecast traffic loads and adjust the revenue-cost trade-off accordingly. Since its end-to-end deployment in the advertising pipeline of a leading global e-commerce platform in November 2024, MaRCA has consistently handled hundreds of billions of ad requests per day and has delivered a 16.67% revenue uplift using existing computation resources.

</details>


### [11] [On the Factual Consistency of Text-based Explainable Recommendation Models](https://arxiv.org/abs/2512.24366)
*Ben Kabongo,Vincent Guigue*

Main category: cs.IR

TL;DR: 论文提出评估文本可解释推荐系统事实一致性的框架，发现现有模型虽然语义相似度高，但事实一致性极低，揭示了可解释推荐中事实性评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的文本可解释推荐系统能生成流畅的解释，但其解释是否与可用证据事实一致的问题尚未充分探索。需要建立评估框架来衡量解释的事实一致性。

Method: 设计基于提示的流水线，使用LLM从评论中提取原子解释语句构建事实基准；提出结合LLM和NLI的语句级对齐指标，评估生成解释的事实一致性和相关性。

Result: 在6个SOTA可解释推荐模型上的实验显示：虽然BERTScore F1高达0.81-0.90，但所有事实性指标都极低（LLM语句级精度仅4.38%-32.88%），揭示了严重的事实一致性差距。

Conclusion: 可解释推荐需要事实感知的评估，现有模型在事实一致性方面表现不佳，该框架为开发更可信的解释系统奠定了基础。

Abstract: Text-based explainable recommendation aims to generate natural-language explanations that justify item recommendations, to improve user trust and system transparency. Although recent advances leverage LLMs to produce fluent outputs, a critical question remains underexplored: are these explanations factually consistent with the available evidence? We introduce a comprehensive framework for evaluating the factual consistency of text-based explainable recommenders. We design a prompting-based pipeline that uses LLMs to extract atomic explanatory statements from reviews, thereby constructing a ground truth that isolates and focuses on their factual content. Applying this pipeline to five categories from the Amazon Reviews dataset, we create augmented benchmarks for fine-grained evaluation of explanation quality. We further propose statement-level alignment metrics that combine LLM- and NLI-based approaches to assess both factual consistency and relevance of generated explanations. Across extensive experiments on six state-of-the-art explainable recommendation models, we uncover a critical gap: while models achieve high semantic similarity scores (BERTScore F1: 0.81-0.90), all our factuality metrics reveal alarmingly low performance (LLM-based statement-level precision: 4.38%-32.88%). These findings underscore the need for factuality-aware evaluation in explainable recommendation and provide a foundation for developing more trustworthy explanation systems.

</details>


### [12] [MEIC-DT: Memory-Efficient Incremental Clustering for Long-Text Coreference Resolution with Dual-Threshold Constraints](https://arxiv.org/abs/2512.24711)
*Kangyang Luo,Shuzheng Si,Yuzhuo Bai,Cheng Gao,Zhitong Wang,Cheng Huang,Yingli Shen,Yufeng Han,Wenhao Li,Cunliang Kong,Maosong Sun*

Main category: cs.IR

TL;DR: MEIC-DT是一种基于轻量级Transformer的双阈值内存高效增量聚类方法，用于共指消解，在严格内存约束下实现高性能。


<details>
  <summary>Details</summary>
Motivation: 在LLM时代，监督神经方法仍然是共指消解的SOTA，但其在增量聚类方面的潜力未充分探索，特别是面临长文本中效率与性能平衡的关键挑战。

Method: 提出MEIC-DT：1) 双阈值约束机制，精确控制Transformer输入规模在预定义内存预算内；2) 统计感知驱逐策略(SAES)，利用训练和推理阶段的统计特征进行智能缓存管理；3) 内部正则化策略(IRP)，通过选择最具代表性的提及来战略性地压缩聚类，保持语义完整性。

Result: 在常见基准测试上的广泛实验表明，MEIC-DT在严格内存约束下实现了高度竞争力的共指性能。

Conclusion: MEIC-DT通过创新的双阈值机制和内存管理策略，成功解决了增量聚类中效率与性能的平衡问题，为长文本共指消解提供了有效的解决方案。

Abstract: In the era of large language models (LLMs), supervised neural methods remain the state-of-the-art (SOTA) for Coreference Resolution. Yet, their full potential is underexplored, particularly in incremental clustering, which faces the critical challenge of balancing efficiency with performance for long texts. To address the limitation, we propose \textbf{MEIC-DT}, a novel dual-threshold, memory-efficient incremental clustering approach based on a lightweight Transformer. MEIC-DT features a dual-threshold constraint mechanism designed to precisely control the Transformer's input scale within a predefined memory budget. This mechanism incorporates a Statistics-Aware Eviction Strategy (\textbf{SAES}), which utilizes distinct statistical profiles from the training and inference phases for intelligent cache management. Furthermore, we introduce an Internal Regularization Policy (\textbf{IRP}) that strategically condenses clusters by selecting the most representative mentions, thereby preserving semantic integrity. Extensive experiments on common benchmarks demonstrate that MEIC-DT achieves highly competitive coreference performance under stringent memory constraints.

</details>


### [13] [MDiffFR: Modality-Guided Diffusion Generation for Cold-start Items in Federated Recommendation](https://arxiv.org/abs/2512.24715)
*Kang Fu,Honglei Zhang,Xuechao Zou,Yidong Li*

Main category: cs.IR

TL;DR: 提出MDiffFR方法，使用模态引导的扩散模型为联邦推荐中的冷启动物品生成嵌入，解决现有映射方法导致的嵌入错位问题，并在隐私保护方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 联邦推荐系统在保护用户隐私的同时，由于严格的数据隔离限制，难以学习冷启动物品的全局有效表示。现有基于属性到嵌入映射的方法存在一对一固定对应关系，无法适应不同数据分布，导致嵌入错位问题。

Method: 提出MDiffFR方法：1）在服务器端使用定制的扩散模型为冷启动物品生成嵌入；2）部署预训练的模态编码器提取模态特征作为条件信号，指导反向去噪过程；3）将生成的嵌入分发给客户端进行冷启动推理。

Result: 在四个真实数据集上的实验表明，该方法在联邦推荐场景中始终优于所有基线方法。理论分析验证了该方法相比现有映射方法具有更强的隐私保证。

Conclusion: MDiffFR通过模态引导的扩散生成方法有效解决了联邦推荐中的物品冷启动问题，不仅提升了推荐性能，还提供了更强的隐私保护。

Abstract: Federated recommendations (FRs) provide personalized services while preserving user privacy by keeping user data on local clients, which has attracted significant attention in recent years. However, due to the strict privacy constraints inherent in FRs, access to user-item interaction data and user profiles across clients is highly restricted, making it difficult to learn globally effective representations for new (cold-start) items. Consequently, the item cold-start problem becomes even more challenging in FRs. Existing solutions typically predict embeddings for new items through the attribute-to-embedding mapping paradigm, which establishes a fixed one-to-one correspondence between item attributes and their embeddings. However, this one-to-one mapping paradigm often fails to model varying data distributions and tends to cause embedding misalignment, as verified by our empirical studies. To this end, we propose MDiffFR, a novel generation-based modality-guided diffusion method for cold-start items in FRs. In this framework, we employ a tailored diffusion model on the server to generate embeddings for new items, which are then distributed to clients for cold-start inference. To align item semantics, we deploy a pre-trained modality encoder to extract modality features as conditional signals to guide the reverse denoising process. Furthermore, our theoretical analysis verifies that the proposed method achieves stronger privacy guarantees compared to existing mapping-based approaches. Extensive experiments on four real datasets demonstrate that our method consistently outperforms all baselines in FRs.

</details>


### [14] [OpenOneRec Technical Report](https://arxiv.org/abs/2512.24762)
*Guorui Zhou,Honghui Bao,Jiaming Huang,Jiaxin Deng,Jinghao Zhang,Junda She,Kuo Cai,Lejian Ren,Lu Ren,Qiang Luo,Qianqian Wang,Qigen Hu,Rongzhou Zhang,Ruiming Tang,Shiyao Wang,Wuchao Li,Xiangyu Wu,Xinchen Luo,Xingmei Wang,Yifei Hu,Yunfan Wu,Zhanyu Liu,Zhiyang Zhang,Zixing Zhang,Bo Chen,Bin Wen,Chaoyi Ma,Chengru Song,Chenglong Chu,Defu Lian,Fan Yang,Feng Jiang,Hongtao Cheng,Huanjie Wang,Kun Gai,Pengfei Zheng,Qiang Wang,Rui Huang,Siyang Mao,Tingting Gao,Wei Yuan,Yan Wang,Yang Zhou,Yi Su,Zexuan Cheng,Zhixin Ling,Ziming Li*

Main category: cs.IR

TL;DR: OneRec系列提出RecIF-Bench评测基准和OneRec-Foundation模型，在推荐系统中融入世界知识、推理和指令跟随能力，向通用智能推荐系统迈进。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统虽然通过OneRec系列实现了端到端生成框架，但仍局限于孤立数据，缺乏世界知识、推理能力和指令跟随能力，与通用智能存在显著差距，且缺乏综合评测基准。

Method: 1) 提出RecIF-Bench评测基准，涵盖8个多样化任务；2) 发布9600万交互的大规模训练数据集；3) 开源完整训练框架；4) 发布OneRec-Foundation模型系列(1.7B和8B)。

Result: OneRec-Foundation在RecIF-Bench所有任务上取得SOTA；在Amazon基准测试中，Recall@10平均提升26.8%；模型规模可预测扩展，同时缓解通用知识的灾难性遗忘。

Conclusion: 该工作向构建真正智能的推荐系统迈进了一步，但实现这一愿景仍面临重大技术和理论挑战，需要更广泛的研究参与。

Abstract: While the OneRec series has successfully unified the fragmented recommendation pipeline into an end-to-end generative framework, a significant gap remains between recommendation systems and general intelligence. Constrained by isolated data, they operate as domain specialists-proficient in pattern matching but lacking world knowledge, reasoning capabilities, and instruction following. This limitation is further compounded by the lack of a holistic benchmark to evaluate such integrated capabilities. To address this, our contributions are: 1) RecIF Bench & Open Data: We propose RecIF-Bench, a holistic benchmark covering 8 diverse tasks that thoroughly evaluate capabilities from fundamental prediction to complex reasoning. Concurrently, we release a massive training dataset comprising 96 million interactions from 160,000 users to facilitate reproducible research. 2) Framework & Scaling: To ensure full reproducibility, we open-source our comprehensive training pipeline, encompassing data processing, co-pretraining, and post-training. Leveraging this framework, we demonstrate that recommendation capabilities can scale predictably while mitigating catastrophic forgetting of general knowledge. 3) OneRec-Foundation: We release OneRec Foundation (1.7B and 8B), a family of models establishing new state-of-the-art (SOTA) results across all tasks in RecIF-Bench. Furthermore, when transferred to the Amazon benchmark, our models surpass the strongest baselines with an average 26.8% improvement in Recall@10 across 10 diverse datasets (Figure 1). This work marks a step towards building truly intelligent recommender systems. Nonetheless, realizing this vision presents significant technical and theoretical challenges, highlighting the need for broader research engagement in this promising direction.

</details>


### [15] [HiGR: Efficient Generative Slate Recommendation via Hierarchical Planning and Multi-Objective Preference Alignment](https://arxiv.org/abs/2512.24787)
*Yunsheng Pang,Zijian Liu,Yudong Li,Shaojie Zhu,Zijian Luo,Chenyun Yu,Sikai Wu,Shichen Shen,Cong Xu,Bin Wang,Kai Jiang,Hongyong Yu,Chengxiang Zhuo,Zang Li*

Main category: cs.IR

TL;DR: HiGR是一个高效的生成式slate推荐框架，通过分层规划和列表级偏好对齐解决现有自回归方法的语义纠缠和低效解码问题，在商业媒体平台上实现了显著的离线质量提升和在线效果改进。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归slate推荐方法存在两个主要问题：1）项目标记化过程中语义纠缠，导致生成控制困难；2）顺序解码效率低下，缺乏对slate的整体规划。这限制了生成模型在slate推荐中的实际应用效果。

Method: HiGR采用三层设计：1）使用残差量化和对比约束的自动编码器，将项目标记化为语义结构化的ID；2）将生成过程解耦为列表级规划阶段（全局slate意图）和项目级解码阶段（具体项目选择）；3）引入列表级偏好对齐目标，直接利用隐式用户反馈优化slate质量。

Result: 在大规模商业媒体平台上的实验表明，HiGR在离线评估中比最先进方法提升超过10%，推理速度提升5倍；在线A/B测试中，平均观看时间增加1.22%，平均视频观看量增加1.73%。

Conclusion: HiGR通过分层规划和列表级偏好对齐，有效解决了生成式slate推荐中的语义纠缠和低效解码问题，实现了显著的性能提升和实际部署效果，为生成模型在推荐系统中的应用提供了有效框架。

Abstract: Slate recommendation, where users are presented with a ranked list of items simultaneously, is widely adopted in online platforms. Recent advances in generative models have shown promise in slate recommendation by modeling sequences of discrete semantic IDs autoregressively. However, existing autoregressive approaches suffer from semantically entangled item tokenization and inefficient sequential decoding that lacks holistic slate planning. To address these limitations, we propose HiGR, an efficient generative slate recommendation framework that integrates hierarchical planning with listwise preference alignment. First, we propose an auto-encoder utilizing residual quantization and contrastive constraints to tokenize items into semantically structured IDs for controllable generation. Second, HiGR decouples generation into a list-level planning stage for global slate intent, followed by an item-level decoding stage for specific item selection. Third, we introduce a listwise preference alignment objective to directly optimize slate quality using implicit user feedback. Experiments on our large-scale commercial media platform demonstrate that HiGR delivers consistent improvements in both offline evaluations and online deployment. Specifically, it outperforms state-of-the-art methods by over 10% in offline recommendation quality with a 5x inference speedup, while further achieving a 1.22% and 1.73% increase in Average Watch Time and Average Video Views in online A/B tests.

</details>


### [16] [RAIR: A Rule-Aware Benchmark Uniting Challenging Long-Tail and Visual Salience Subset for E-commerce Relevance Assessment](https://arxiv.org/abs/2512.24943)
*Chenji Lu,Zhuo Chen,Hui Zhao,Zhenyi Wang,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.IR

TL;DR: RAIR是一个中文电商搜索相关性评估基准，包含通用、长尾困难和视觉显著性三个子集，为行业提供标准化评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有相关性评估基准缺乏足够的复杂性，导致行业缺乏标准化的相关性评估指标，需要构建更全面的评估体系。

Method: 构建RAIR数据集，包含三个子集：通用子集（行业平衡采样）、长尾困难子集（挑战性案例）、视觉显著性子集（多模态理解）。建立标准化评估框架和通用规则。

Result: 在14个开源和闭源模型上测试，RAIR对GPT-5等先进模型仍构成足够挑战，GPT-5表现最佳。数据集已公开可用。

Conclusion: RAIR为电商搜索相关性评估提供了行业基准，同时为通用LLM和视觉语言模型评估提供了新见解。

Abstract: Search relevance plays a central role in web e-commerce. While large language models (LLMs) have shown significant results on relevance task, existing benchmarks lack sufficient complexity for comprehensive model assessment, resulting in an absence of standardized relevance evaluation metrics across the industry. To address this limitation, we propose Rule-Aware benchmark with Image for Relevance assessment(RAIR), a Chinese dataset derived from real-world scenarios. RAIR established a standardized framework for relevance assessment and provides a set of universal rules, which forms the foundation for standardized evaluation. Additionally, RAIR analyzes essential capabilities required for current relevance models and introduces a comprehensive dataset consists of three subset: (1) a general subset with industry-balanced sampling to evaluate fundamental model competencies; (2) a long-tail hard subset focus on challenging cases to assess performance limits; (3) a visual salience subset for evaluating multimodal understanding capabilities. We conducted experiments on RAIR using 14 open and closed-source models. The results demonstrate that RAIR presents sufficient challenges even for GPT-5, which achieved the best performance. RAIR data are now available, serving as an industry benchmark for relevance assessment while providing new insights into general LLM and Visual Language Model(VLM) evaluation.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [17] [Hierarchical Quasi-cyclic Codes from Reed-Solomon and Polynomial Evaluation Codes](https://arxiv.org/abs/2512.23872)
*Emily McMillon,Kathryn Haymaker*

Main category: cs.IT

TL;DR: 本文首次提出了代数构造的分层准循环码，基于Reed-Solomon码和Kautz-Singleton叠加码构造，层级数和指标由域大小决定，部分码达到已知最佳最小距离。


<details>
  <summary>Details</summary>
Motivation: 现有相关码的文献主要基于仿真方法，缺乏代数分析。本文旨在通过代数方法构造分层准循环码，并推导其参数的理论界限。

Method: 使用Reed-Solomon码和Kautz-Singleton（1964）的叠加码构造方法，代数构造分层准循环码。特别地，从维度k=2的RS码出发，构造具有围长6的Tanner图的分层准循环码。

Result: 证明了分层数和指标由域大小决定；给出了显式的码参数和性质；推导了秩和距离等参数的界限；提供了小参数码表，部分码达到已知最佳最小距离；建立了与文献中类似构造的联系。

Conclusion: 本文首次代数构造了分层准循环码，提供了新的参数界限分析方法，弥补了现有文献主要依赖仿真的不足，为这类码的设计和分析提供了代数基础。

Abstract: We introduce the first example of algebraically constructed hierarchical quasi-cyclic codes. These codes are built from Reed-Solomon codes using a 1964 construction of superimposed codes by Kautz and Singleton. We show both the number of levels in the hierarchy and the index of these Reed-Solomon derived codes are determined by the field size. We show that this property also holds for certain additional classes of polynomial evaluation codes.
  We provide explicit code parameters and properties as well as some additional bounds on parameters such as rank and distance. In particular, starting with Reed-Solomon codes of dimension $k=2$ yields hierarchical quasi-cyclic codes with Tanner graphs of girth 6.
  We present a table of small code parameters and note that some of these codes meet the best known minimum distance for binary codes, with the additional hierarchical quasi-cyclic structure. We draw connections to similar constructions in the literature, but importantly, while existing literature on related codes is largely simulation-based, we present a novel algebraic approach to determining new bounds on parameters of these codes.

</details>


### [18] [Continuous Angular Power Spectrum Recovery From Channel Covariance via Chebyshev Polynomials](https://arxiv.org/abs/2512.24039)
*Shengsong Luo,Ruilin Wu,Chongbin Xu,Junjie Ma,Xiaojun Yuan,Xin Wang*

Main category: cs.IT

TL;DR: 提出基于切比雪夫多项式展开的框架，用于从信道协方差中恢复连续角度功率谱，将病态反演问题转化为有限维线性回归，并通过半定规划和导数正则化确保非负性和平滑性。


<details>
  <summary>Details</summary>
Motivation: 在多天线系统中，从信道协方差恢复连续角度功率谱是一个病态反演问题。现有方法通常需要离散化或强假设，难以同时保证非负性、平滑性和计算效率。本文旨在开发一个既能准确恢复APS，又能支持FDD系统中上下行协方差预测的框架。

Method: 1. 利用切比雪夫多项式在变换域中的正交性，推导协方差的精确级数表示；2. 通过截断将病态APS反演转化为有限维线性回归问题；3. 推导非负APS的精确半定特征；4. 引入基于导数的正则化器，促进平滑变化的APS轮廓同时保留簇的过渡。

Result: 仿真结果表明：1. 提出的切比雪夫框架能准确重建APS；2. 在频分双工（FDD）设置中，能从上行测量可靠预测下行协方差；3. 近似误差直接由APS切比雪夫级数的尾部控制，随着角度平滑度的增加而快速衰减。

Conclusion: 在切比雪夫域中联合利用平滑性和非负性，为多天线系统中的协方差域处理提供了有效工具。该框架不仅能准确恢复连续角度功率谱，还能实现FDD系统中上下行协方差的可靠预测。

Abstract: This paper proposes a Chebyshev polynomial expansion framework for the recovery of a continuous angular power spectrum (APS) from channel covariance. By exploiting the orthogonality of Chebyshev polynomials in a transformed domain, we derive an exact series representation of the covariance and reformulate the inherently ill-posed APS inversion as a finite-dimensional linear regression problem via truncation. The associated approximation error is directly controlled by the tail of the APS's Chebyshev series and decays rapidly with increasing angular smoothness. Building on this representation, we derive an exact semidefinite characterization of nonnegative APS and introduce a derivative-based regularizer that promotes smoothly varying APS profiles while preserving transitions of clusters. Simulation results show that the proposed Chebyshev-based framework yields accurate APS reconstruction, and enables reliable downlink (DL) covariance prediction from uplink (UL) measurements in a frequency division duplex (FDD) setting. These findings indicate that jointly exploiting smoothness and nonnegativity in a Chebyshev domain provides an effective tool for covariance-domain processing in multi-antenna systems.

</details>


### [19] [Random Multiplexing](https://arxiv.org/abs/2512.24087)
*Lei Liu,Yuhao Chi,Shunqi Huang,Zhaoyang Zhang*

Main category: cs.IT

TL;DR: 论文提出随机复用技术，通过构建随机变换域中的等效输入各向同性信道矩阵，实现统计衰落信道遍历性，支持任意范数有界、谱收敛信道矩阵，并保证AMP类检测器的渐近最优性。


<details>
  <summary>Details</summary>
Motivation: 传统复用技术（如SC-FDE、OFDM、OTFS、AFDM）依赖特定信道结构，在动态现实环境中鲁棒性有限。需要一种与物理信道解耦、适用于任意范数有界和谱收敛信道矩阵的复用技术。

Method: 提出随机复用技术，构建随机变换域中的等效输入各向同性信道矩阵。采用低复杂度跨域记忆AMP（CD-MAMP）检测器，利用时域信道稀疏性和等效信道随机性。推导最优功率分配以最小化BER和最大化约束容量。

Result: 随机复用技术实现统计衰落信道遍历性，保证AMP类检测器在任意范数有界、谱收敛信道矩阵下的渐近最优性。CD-MAMP检测器在随机复用系统中具有最优编码原理和约束容量最优性。

Conclusion: 随机复用技术突破了传统复用技术对信道结构的依赖，为动态无线环境提供了鲁棒解决方案，并在多种无线应用中展现出良好适应性。

Abstract: As wireless communication applications evolve from traditional multipath environments to high-mobility scenarios like unmanned aerial vehicles, multiplexing techniques have advanced accordingly. Traditional single-carrier frequency-domain equalization (SC-FDE) and orthogonal frequency-division multiplexing (OFDM) have given way to emerging orthogonal time-frequency space (OTFS) and affine frequency-division multiplexing (AFDM). These approaches exploit specific channel structures to diagonalize or sparsify the effective channel, thereby enabling low-complexity detection. However, their reliance on these structures significantly limits their robustness in dynamic, real-world environments. To address these challenges, this paper studies a random multiplexing technique that is decoupled from the physical channels, enabling its application to arbitrary norm-bounded and spectrally convergent channel matrices. Random multiplexing achieves statistical fading-channel ergodicity for transmitted signals by constructing an equivalent input-isotropic channel matrix in the random transform domain. It guarantees the asymptotic replica MAP bit-error rate (BER) optimality of AMP-type detectors for linear systems with arbitrary norm-bounded, spectrally convergent channel matrices and signaling configurations, under the unique fixed point assumption. A low-complexity cross-domain memory AMP (CD-MAMP) detector is considered, leveraging the sparsity of the time-domain channel and the randomness of the equivalent channel. Optimal power allocations are derived to minimize the replica MAP BER and maximize the replica constrained capacity of random multiplexing systems. The optimal coding principle and replica constrained-capacity optimality of CD-MAMP detector are investigated for random multiplexing systems. Additionally, the versatility of random multiplexing in diverse wireless applications is explored.

</details>


### [20] [When Wires Can't Keep Up: Reconfigurable AI Data Centers Empowered by Terahertz Wireless Communications](https://arxiv.org/abs/2512.24110)
*Chong Han,Mingjie Zhu,Wenqi Zhao,Ziming Yu,Guolong Huang,Guangjian Wang,Wen Tong,Wenjun Zhang*

Main category: cs.IT

TL;DR: 太赫兹无线数据中心（THz-WDC）利用太赫兹频段实现超高带宽、低延迟、高能效的短中距离无线互连，为AI数据中心提供可重构、可持续的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统铜缆和光缆互连在延迟、功耗和刚性方面面临根本性挑战，限制了分布式AI集群的可扩展性。AI工作负载的爆炸式增长需要数据中心互连架构的根本性变革。

Method: 提出太赫兹无线数据中心愿景，探索关键使能技术：数字孪生编排、低复杂度波束操纵技术、全硅太赫兹收发器、低复杂度模拟基带架构。通过数值分析比较太赫兹与光缆、铜缆互连的延迟和功耗特性。

Result: 太赫兹无线链路可实现单链路高达1Tbps、通过空间复用总吞吐量达10Tbps、单跳延迟低于50ns、20米距离内能效低于10pJ/bit的性能。在特定距离和吞吐量域内，太赫兹链路可超越传统有线解决方案。

Conclusion: 太赫兹无线互连为未来AI数据中心提供了灵活、可重构、可持续的解决方案，支持量子计算和chiplet模块化架构的发展，是实现无线定义、可重构、可持续AI数据中心的关键技术路径。

Abstract: The explosive growth of artificial intelligence (AI) workloads in modern data centers demands a radical transformation of interconnect architectures. Traditional copper and optical wiring face fundamental challenges in latency, power consumption, and rigidity, constraining the scalability of distributed AI clusters. This article introduces a vision for Terahertz (THz) Wireless Data Center (THz-WDC) that combines ultra-broadband capacity, one-hop low-latency communication, and energy efficiency in the short-to-medium range (1-100m). Performance and technical requirements are first articulated, including up to 1 Tbps per link, aggregate throughput up to 10 Tbps via spatial multiplexing, sub-50 ns single-hop latency, and sub-10 pJ/bit energy efficiency over 20m. To achieve these ambitious goals, key enabling technologies are explored, including digital-twin-based orchestration, low-complexity beam manipulation technologies, all-silicon THz transceivers, and low-complexity analog baseband architectures. Moreover, as future data centers shift toward quantum and chiplet-based modular architectures, THz wireless links provide a flexible mechanism for interconnecting, testing, and reconfiguring these modules. Finally, numerical analysis is presented on the latency and power regimes of THz versus optical and copper interconnects, identifying the specific distance and throughput domains where THz links can surpass conventional wired solutions. The article concludes with a roadmap toward wireless-defined, reconfigurable, and sustainable AI data centers.

</details>


### [21] [Efficient Decoding of Twisted GRS Codes and Roth--Lempel Codes](https://arxiv.org/abs/2512.24217)
*Runtian Zhu,Lingfei Jin*

Main category: cs.IT

TL;DR: 提出针对TGRS码和Roth-Lempel码的高效列表解码和唯一解码算法，基于Guruswami-Sudan算法，实现近线性时间复杂度，显著改进现有二次复杂度，并首次为Roth-Lempel码提供高效解码器。


<details>
  <summary>Details</summary>
Motivation: MDS码在实践中应用广泛，但大多数已知MDS码都是GRS码或其等价形式。研究非GRS码具有理论意义，且在密码学应用中，GRS码的强代数结构可能不受欢迎。TGRS码和Roth-Lempel码是两类重要的非GRS码，虽然已有大量构造和结构分析工作，但解码问题研究相对较少，许多问题仍待解决。

Method: 基于Guruswami-Sudan算法，为TGRS码和Roth-Lempel码设计列表解码和唯一解码算法。算法在适当参数条件下实现近线性运行时间。TGRS解码器支持最多O(n²)个扭曲的固定速率TGRS码，大幅扩展了先前仅处理单扭曲情况的工作。首次为Roth-Lempel码提供高效解码器，并将代数操作检测(AMD)码集成到列表解码框架中。

Result: 算法在代码长度上实现近线性运行时间，改进先前已知的最佳二次时间复杂度。TGRS解码器支持最多O(n²)个扭曲，显著扩展了处理范围。为Roth-Lempel码提供首个高效解码器。列表解码器在广泛参数范围内超越经典唯一解码半径。通过集成AMD码，能够以高概率从输出列表中恢复正确消息。

Conclusion: 本文为两类重要的非GRS码提供了高效解码算法，填补了该领域的研究空白。提出的算法不仅显著提升了时间复杂度，还扩展了可处理码的范围，为实际应用提供了更好的解码工具。将AMD码集成到列表解码框架中增强了消息恢复的可靠性。

Abstract: MDS codes play a central role in practice due to their broad applications. To date, most known MDS codes are generalized Reed-Solomon (GRS) codes, leaving codes that are not equivalent to GRS codes comparatively less understood. Studying this non-GRS regime is therefore of intrinsic theoretical interest, and is also practically relevant since the strong algebraic structure of GRS codes can be undesirable in cryptographic settings. Among the known non-GRS codes, twisted generalized Reed-Solomon (TGRS) codes and Roth-Lempel codes are two representative families of non-GRS codes that have attracted significant attention. Though substantial work has been devoted to the construction and structural analysis of TGRS and Roth-Lempel codes, comparatively little attention has been paid to their decoding, and many problems remain open. In this paper, we propose list and unique decoding algorithms for TGRS codes and Roth-Lempel codes based on the Guruswami-Sudan algorithm. Under suitable parameter conditions, our algorithms achieve near-linear running time in the code length, improving upon the previously best-known quadratic-time complexity. Our TGRS decoder supports fixed-rate TGRS codes with up to O(n^2) twists, substantially extending prior work that only handled the single-twist case. For Roth-Lempel codes, we provide what appears to be the first efficient decoder. Moreover, our list decoders surpass the classical unique-decoding radius for a broad range of parameters. Finally, we incorporate algebraic manipulation detection (AMD) codes into the list-decoding framework, enabling recovery of the correct message from the output list with high probability.

</details>


### [22] [SC-LDPC Codes Over $\mathbb{F}_q$: Minimum Distance, Decoding Analysis and Threshold Saturation](https://arxiv.org/abs/2512.24232)
*Jiaxin Lyu,Guanghui He*

Main category: cs.IT

TL;DR: 本文研究了有限域上的随机空间耦合LDPC码，提出了改进型耦合方案，证明了其具有渐进良好的最小距离和停止集大小，并建立了通用阈值饱和理论。


<details>
  <summary>Details</summary>
Motivation: 研究有限域上空间耦合LDPC码的性能，特别是如何通过不同的变量节点边扩展规则来改进距离性能，并建立统一的阈值分析框架。

Method: 使用随机Tanner图定义多个耦合集合，通过独立的均匀随机单项式映射。引入对称概率测度理论，分析其退化性质，建立度量拓扑框架，研究q元输入对称信道下的迭代解码阈值。

Result: 证明了标准耦合和改进耦合集合都具有渐进良好的最小距离和最小停止集大小。改进型耦合集合能获得更好的距离性能。建立了通用阈值饱和结果：随着耦合参数增加，BP阈值会饱和到一个仅取决于基础集合和信道族的确定阈值。

Conclusion: 有限域上的空间耦合LDPC码通过改进的耦合方案可以获得更好的距离性能，并且存在通用的阈值饱和现象，为q元有限域上的信道编码设计提供了理论框架。

Abstract: We investigate random spatially coupled low-density parity-check (SC-LDPC) code ensembles over finite fields. Under different variable-node edge-spreading rules, the random Tanner graphs of several coupled ensembles are defined by multiple independent, uniformly random monomial maps. The two main coupled ensembles considered are referred to as the standard coupled ensemble and the improved coupled ensemble. We prove that both coupled ensembles exhibit asymptotically good minimum distance and minimum stopping set size. Theoretical and numerical results show that the improved coupled ensemble can achieve better distance performance than the standard coupled ensemble. We introduce the essential preliminaries and analytical tools needed to analyze the iterative decoding threshold of coupled ensembles over any finite field. We consider a class of memoryless channels with special symmetry, termed q-ary input memoryless symmetric channels (QMSCs), and show that, for these channels, the distribution of channel messages (in form of probability vectors) likewise exhibits this symmetry. Consequently, we define symmetric probability measures and their reference measures on a finite-dimensional probability simplex, analyze their foundational properties and those of their linear functionals, endow their respective spaces with metric topologies, and conduct an in-depth study of their degradation theory. Based on our analytical framework, we establish a universal threshold saturation result for both of the coupled ensembles over a q-ary finite field on QMSCs. Specifically, as the coupling parameters increase, the belief-propagation threshold of a coupled system saturates to a well-defined threshold that depends only on the underlying ensemble and the channel family.

</details>


### [23] [Infinite families of graphs and stable completion of arbitrary matrices, Part I](https://arxiv.org/abs/2512.24468)
*Augustin Cosse*

Main category: cs.IT

TL;DR: 研究确定性构造图，使得低秩矩阵的补全在任意元素值下都可行，通过分析特定模式存在性建立理论框架。


<details>
  <summary>Details</summary>
Motivation: 研究在何种图结构下，低秩矩阵补全问题能够保证存在唯一解，而不依赖于矩阵元素的具体数值。这对于矩阵补全的理论基础和应用具有重要意义。

Method: 将矩阵补全可行性关联到图结构中的特定模式（自回避行走的并集），分析支撑矩阵对应的二分图子图中这些模式的存在性，建立理论框架。

Result: 建立了图结构与矩阵补全可行性的理论联系，使得能够设计无限图族，在这些图上通过平方和层次结构可以精确稳定地补全任意固定秩矩阵。

Conclusion: 提出了基于图结构模式的确定性构造方法，为低秩矩阵补全问题提供了理论保证和实际构造方案，扩展了矩阵补全问题的可解范围。

Abstract: We study deterministic constructions of graphs for which the unique completion of low rank matrices is generically possible regardless of the values of the entries. We relate the completability to the presence of some patterns (particular unions of self-avoiding walks) in the subgraph of the lattice graph generated from the support of the bi-adjacency matrix. The construction makes it possible to design infinite families of graphs on which exact and stable completion is possible for every fixed rank matrix through the sum-of-squares hierarchy.

</details>


### [24] [Throughput Optimization in UAV-Mounted RIS under Jittering and Imperfect CSI via DRL](https://arxiv.org/abs/2512.24773)
*Anas K. Saeed,Mahmoud M. Salim,Ali Arshad Nasir,Ali H. Muqaibel*

Main category: cs.IT

TL;DR: 本文提出了一种基于深度强化学习的无人机载RIS系统优化方法，用于应对无人机抖动和信道不确定性，实现了比传统优化方法更高的吞吐量和更快的在线推理速度。


<details>
  <summary>Details</summary>
Motivation: 无人机载可重构智能表面(RIS)能够按需重塑无线传播，但其性能对无人机抖动和级联信道不确定性非常敏感。现有方法在应对这些实际损伤时存在局限性，需要更鲁棒的优化方案。

Method: 设计了一个基于上下文赌博机的模型无关深度强化学习框架，采用可微分可行性层将连续动作映射为可行解，奖励函数为期望吞吐量的蒙特卡洛估计。实例化了不使用目标网络的约束型DDPG和TD3算法。

Result: 在严重抖动和低CSI质量下，所提算法比传统的交替优化加权最小均方误差(AO-WMMSE)基准获得更高吞吐量。在不同场景下，性能与基于样本平均近似的AO-WMMSE基准相当或略低，相对差距为0-12%。在线推理时间仅0.6ms/决策，而AO-WMMSE需要370-550ms。

Conclusion: 所提出的深度强化学习方法能够有效处理无人机载RIS系统中的随机抖动和信道不确定性，在保持良好性能的同时显著降低了计算复杂度，实现了高效的在线优化。

Abstract: Reconfigurable intelligent surfaces (RISs) mounted on unmanned aerial vehicles (UAVs) can reshape wireless propagation on-demand. However, their performance is sensitive to UAV jitter and cascaded channel uncertainty. This paper investigates a downlink multiple-input single-output UAV-mounted RIS system in which a ground multiple-antenna base station (BS) serves multiple single-antenna users under practical impairments. Our goal is to maximize the expected throughput under stochastic three-dimensional UAV jitter and imperfect cascaded channel state information (CSI) based only on the available channel estimates. This leads to a stochastic nonconvex optimization problem subject to a BS transmit power constraint and strict unit-modulus constraints on all RIS elements. To address this problem, we design a model-free deep reinforcement learning (DRL) framework with a contextual bandit formulation. A differentiable feasibility layer is utilized to map continuous actions to feasible solutions, while the reward is a Monte Carlo estimate of the expected throughput. We instantiate this framework with constrained variants of deep deterministic policy gradient (DDPG) and twin delayed deep deterministic policy gradient (TD3) that do not use target networks. Simulations show that the proposed algorithms yield higher throughput than conventional alternating optimization-based weighted minimum mean-square error (AO-WMMSE) baselines under severe jitter and low CSI quality. Across different scenarios, the proposed methods achieve performance that is either comparable to or slightly below the AO-WMMSE benchmark, based on sample average approximation (SAA) with a relative gap ranging from 0-12%. Moreover, the proposed DRL controllers achieve online inference times of 0.6 ms per decision versus roughly 370-550 ms for AO-WMMSE solvers.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [25] [Sparse Random Matrices for Dimensionality Reduction](https://arxiv.org/abs/2512.23756)
*Pierre Mackenzie*

Main category: cs.DS

TL;DR: 本文回顾了Johnson-Lindenstrauss定理的稀疏随机矩阵构造方法，包括Achlioptas(2003)和Kane & Nelson(2014)的方案，并通过实验比较了这些稀疏构造与标准高斯JL矩阵的性能。


<details>
  <summary>Details</summary>
Motivation: 标准JL定理使用稠密高斯随机矩阵，但稀疏随机矩阵在某些应用中更受欢迎，因为它们允许更快的矩阵向量乘法。需要研究稀疏构造方法的理论和实际性能。

Method: 回顾了Achlioptas(2003)提出的稀疏随机矩阵构造方法，以及Kane & Nelson(2014)的当代标准方案。通过实现这些稀疏构造方法，并与标准高斯JL矩阵进行实证比较。

Result: 通过实验比较了不同稀疏构造方法与标准高斯JL矩阵的性能差异，验证了稀疏矩阵在保持距离近似的同时能够提供计算效率优势。

Conclusion: 稀疏随机矩阵构造为Johnson-Lindenstrauss嵌入提供了实用的替代方案，在保持理论保证的同时显著提高了计算效率，适用于需要快速矩阵向量乘法的应用场景。

Abstract: The Johnson-Lindenstrauss (JL) theorem states that a set of points in high-dimensional space can be embedded into a lower-dimensional space while approximately preserving pairwise distances with high probability Johnson and Lindenstrauss (1984). The standard JL theorem uses dense random matrices with Gaussian entries. However, for some applications, sparse random matrices are preferred as they allow for faster matrix-vector multiplication. I outline the constructions and proofs introduced by Achlioptas (2003) and the contemporary standard by Kane and Nelson (2014). Further, I implement and empirically compare these sparse constructions with standard Gaussian JL matrices.

</details>


### [26] [Kidney Exchange: Faster Parameterized Algorithms and Tighter Lower Bounds](https://arxiv.org/abs/2512.24037)
*Aritra Banik,Sujoy Bhore,Palash Dey,Abhishek Sahu*

Main category: cs.DS

TL;DR: 本文改进了肾脏交换问题的FPT算法，将时间复杂度从O*(14^t)提升到O*((4e)^t)≈O*(10.88^t)，同时证明了该问题在路径宽度参数下是W[1]-难的。


<details>
  <summary>Details</summary>
Motivation: 肾脏交换机制允许不兼容的患者-供体配对通过交换获得匹配的肾脏，但由于基础设施和法律限制，实践中只能在小的循环中进行交换。存在无配对患者的利他性供体，使得交换可以沿着从利他性供体开始的路径进行。然而，该计算问题是NP完全的，需要设计更快的算法来克服计算障碍。

Method: 采用参数化复杂度框架，以接受健康肾脏的患者数量t为标准参数。设计确定性FPT算法，将时间复杂度改进到O*((4e)^t)。同时研究该问题在底层无向图的路径宽度参数下的复杂性，证明该问题是W[1]-难的。

Result: 提出了运行时间为O*((4e)^t)≈O*(10.88^t)的确定性FPT算法，显著改进了之前O*(14^t)的最好结果。证明了肾脏交换问题在路径宽度参数下是W[1]-难的，回答了该领域的一个自然问题。还提供了其他参数化不可行性结果。

Conclusion: 本文在肾脏交换问题的参数化算法设计方面取得了重要进展，显著改进了标准参数t下的FPT算法时间复杂度。同时，通过证明该问题在路径宽度参数下是W[1]-难的，深化了对该问题计算复杂性的理解，为后续研究提供了重要参考。

Abstract: The kidney exchange mechanism allows many patient-donor pairs who are otherwise incompatible with each other to come together and exchange kidneys along a cycle. However, due to infrastructure and legal constraints, kidney exchange can only be performed in small cycles in practice. In reality, there are also some altruistic donors who do not have any paired patients. This allows us to also perform kidney exchange along paths that start from some altruistic donor. Unfortunately, the computational task is NP-complete. To overcome this computational barrier, an important line of research focuses on designing faster algorithms, both exact and using the framework of parameterized complexity.
  The standard parameter for the kidney exchange problem is the number $t$ of patients that receive a healthy kidney. The current fastest known deterministic FPT algorithm for this problem, parameterized by $t$, is $O^\star\left(14^t\right)$. In this work, we improve this by presenting a deterministic FPT algorithm that runs in time $O^\star\left((4e)^t\right)\approx O^\star\left(10.88^t\right)$. This problem is also known to be W[1]-hard parameterized by the treewidth of the underlying undirected graph. A natural question here is whether the kidney exchange problem admits an FPT algorithm parameterized by the pathwidth of the underlying undirected graph. We answer this negatively in this paper by proving that this problem is W[1]-hard parameterized by the pathwidth of the underlying undirected graph. We also present some parameterized intractability results improving the current understanding of the problem under the framework of parameterized complexity.

</details>


### [27] [Faster Algorithms for Global Minimum Vertex-Cut in Directed Graphs](https://arxiv.org/abs/2512.24355)
*Julia Chuzhoy,Ron Mosenzon,Ohad Trabelsi*

Main category: cs.DS

TL;DR: 本文首次打破了有向全局最小顶点割问题的Θ(mn)时间复杂度壁垒，提出了两个随机算法：一个用于加权版本，运行时间为O(mn^0.976·polylog W)；另一个用于无权版本，运行时间为O(min{m^{1+o(1)}·k, n^{2+o(1)}})。


<details>
  <summary>Details</summary>
Motivation: 有向全局最小顶点割问题是图论和算法中最基本的问题之一，但自1996年以来，其时间复杂度一直停留在Õ(mn)，29年来未有突破。虽然其他版本（无向边割、有向边割、无向顶点割）都有更快算法，但有向顶点割版本始终是瓶颈。

Method: 本文提出了随机算法来解决有向全局最小顶点割问题。对于加权版本，算法运行时间为O(mn^0.976·polylog W)，其中W是最大与最小顶点权重之比。对于无权版本，算法运行时间为O(min{m^{1+o(1)}·k, n^{2+o(1)}})，其中k是最优解的值。

Result: 首次打破了有向全局最小顶点割问题的Θ(mn)时间复杂度壁垒，将运行时间从Õ(mn)改进到O(mn^0.976·polylog W)。对于无权版本，算法运行时间也优于先前最好的Õ(min{k^2·m, mn^{11/12+o(1)}, n^{2+o(1)}})算法。

Conclusion: 本文在有向全局最小顶点割问题上取得了突破性进展，打破了29年来的时间复杂度壁垒，为这一经典问题提供了第一个次mn时间复杂度的算法，填补了该领域的重要空白。

Abstract: We study the directed global minimum vertex-cut problem: given a directed vertex-weighted graph $G$, compute a vertex-cut $(L,S,R)$ in $G$ of minimum value, which is defined to be the total weight of all vertices in $S$. The problem, together with its edge-based variant, is one of the most basic in graph theory and algorithms, and has been studied extensively. The fastest currently known algorithm for directed global minimum vertex-cut (Henzinger, Rao and Gabow, FOCS 1996 and J. Algorithms 2000) has running time $\tilde{O}(mn)$, where $m$ and $n$ denote the number of edges and vertices in the input graph, respectively. A long line of work over the past decades led to faster algorithms for other main versions of the problem, including the undirected edge-based setting (Karger, STOC 1996 and J. ACM 2000), directed edge-based setting (Cen et al., FOCS 2021), and undirected vertex-based setting (Chuzhoy and Trabelsi, STOC 2025). However, for the vertex-based version in directed graphs, the 29 year-old $\tilde{O}(mn)$-time algorithm of Henzinger, Rao and Gabow remains the state of the art to this day, in all edge-density regimes. In this paper we break the $Θ(mn)$ running time barrier for the first time, by providing a randomized algorithm for directed global minimum vertex-cut, with running time $O\left(mn^{0.976}\cdot\operatorname{polylog} W\right)$ where $W$ is the ratio of largest to smallest vertex weight. Additionally, we provide a randomized $O\left(\min\left\{m^{1+o(1)}\cdot k,n^{2+o(1)}\right\}\right)$-time algorithm for the unweighted version of directed global minimum vertex-cut, where $k$ is the value of the optimal solution. The best previous algorithm for the problem achieved running time $\tilde O\left(\min\left\{k^2 \cdot m, mn^{11/12+o(1)}, n^{2+o(1)}\right\}\right)$ (Forster et al., SODA 2020, Li et al., STOC 2021).

</details>


### [28] [Fair Committee Selection under Ordinal Preferences and Limited Cardinal Information](https://arxiv.org/abs/2512.24934)
*Ameet Gadekar,Aristides Gionis,Suhas Thejaswi,Sijing Tu*

Main category: cs.DS

TL;DR: 本文研究公平k委员会选择问题，提出在仅能查询有限基数信息的情况下，通过O(k log² k)次查询实现因子5的失真算法。


<details>
  <summary>Details</summary>
Motivation: 在公平k委员会选择中，当只有序数信息（偏好排序）而没有基数信息（实际距离）时，无法获得常数失真。需要探索如何在有限基数信息查询下实现公平且高效的委员会选择。

Method: 将问题建模为序数公平k中心问题，允许对度量空间进行有限查询。提出两种算法：1）使用O(k²)查询实现因子3失真；2）使用O(k log² k)查询实现因子5失真。

Result: 证明了在允许有限基数信息查询的情况下，可以克服仅有序数信息时的硬度结果，实现常数失真。具体获得了因子3和因子5的失真算法。

Conclusion: 通过允许有限的基数信息查询，可以在公平k委员会选择问题中实现常数失真，平衡了信息获取成本与算法性能，为实际应用提供了可行的解决方案。

Abstract: We study the problem of fair $k$-committee selection under an egalitarian objective. Given $n$ agents partitioned into $m$ groups (\eg, demographic quotas), the goal is to aggregate their preferences to form a committee of size $k$ that guarantees minimum representation from each group while minimizing the maximum \emph{cost} incurred by any agent. We model this setting as the ordinal fair $k$-center problem, where agents are embedded in an unknown metric space, and each agent reports a complete preference ranking (i.e., ordinal information) over all agents, consistent with the underlying distance metric (i.e., cardinal information). The cost incurred by an agent with respect to a committee is defined as its distance to the closest committee member. The quality of an algorithm is evaluated using the notion of distortion, which measures the worst-case ratio between the cost of the committee produced by the algorithm and the cost of an optimal committee, when given complete access to the underlying metric space.
  When cardinal information is not available, no constant distortion is possible for the ordinal $k$-center problem, even without fairness constraints, when $k\geq 3$ [Burkhardt et.al., AAAI'24]. To overcome this hardness, we allow limited access to cardinal information by querying the metric space. In this setting, our main contribution is a factor-$5$ distortion algorithm that requires only $O(k \log^2 k)$ queries. Along the way, we present an improved factor-$3$ distortion algorithm using $O(k^2)$ queries.

</details>


### [29] [Approximations for the Weighted Reversal, Transposition, and Indel Distance Problem with Intergenic Region Information](https://arxiv.org/abs/2512.25016)
*Gabriel Siqueira,Alexsandro Oliveira Alexandrino,Zanoni Dias*

Main category: cs.DS

TL;DR: 提出了一种基于标记基因间断点图的算法，用于解决加权反转、转座和插入缺失距离问题，并保证在某些权重设置下的近似解。


<details>
  <summary>Details</summary>
Motivation: 基因组重排距离是基因组比较的重要方法，但现有方法通常只考虑重排操作，而忽略了基因方向、基因间区域长度以及不同操作的预期频率权重。需要一种更全面的模型来准确计算基因组间的距离。

Method: 使用标记基因间断点图结构，开发了一种算法来解决加权反转、转座和插入缺失距离问题。该算法考虑了基因序列、方向、基因间区域长度，并为每种操作分配权重。

Result: 提出的算法能够找到将一种基因组转换为另一种基因组的最小成本序列，并在某些操作权重设置下保证近似解的质量。

Conclusion: 通过整合基因方向、基因间区域长度和操作权重，该研究为基因组重排距离计算提供了更全面的框架，标记基因间断点图是解决此类问题的有效工具。

Abstract: Genome rearrangement distances are an established method in genome comparison. Works in this area may include various rearrangement operations representing large-scale mutations, gene orientation information, the number of nucleotides in intergenic regions, and weights reflecting the expected frequency of each operation. In this article, we model genomes containing at most one copy of each gene by considering gene sequences, with orientations, and representing intergenic regions according to their nucleotide lengths. We looked at a problem called Weighted Reversal, Transposition, and Indel Distance, which seeks the minimal cost sequence composed by the rearrangement operations of reversals, transposition, and indels, capable of transforming one genome into another. We leverage a structure called Labeled Intergenic Breakpoint Graph to show an algorithm for that problem with guaranteed approximations considering some sets of weights for the operations.

</details>


### [30] [Approximation Algorithms for Fair Repetitive Scheduling](https://arxiv.org/abs/2512.25020)
*Danny Hermelin,Danny Segev,Dvir Shabtay*

Main category: cs.DS

TL;DR: 本文针对公平重复调度问题，提出了多种近似算法：对于时间依赖的处理时间，设计了基于线性规划的2-近似算法和多项式时间近似方案；对于时间不变的处理时间，提出了简单高效的(1+√2)/2+ε近似算法和拟多项式时间近似方案。


<details>
  <summary>Details</summary>
Motivation: 解决公平重复调度问题，该问题涉及多个客户，每个客户的工作需要在有限规划周期内每天调度。目标是确定每天的作业处理顺序，以最小化任何客户经历的最大总完成时间。该问题在限制性设置下是NP难的，先前工作仅针对高度结构化的特殊情况提供精确解法。

Method: 1. 对于时间依赖的处理时间：开发基于线性规划的2-近似算法，以及针对常数天数的多项式时间近似方案。
2. 对于时间不变的处理时间：设计简单高效的(1+√2)/2+ε近似算法，并证明该设置允许任意天数的拟多项式时间近似方案。
3. 关键技术：创新的批处理技术，将作业概念上分组为批次，随后导出低维动态规划或紧凑配置线性规划。
4. 提出多种下界机制，对开发常数因子近似算法至关重要。

Result: 1. 对于时间依赖的处理时间：实现了多项式时间的2-近似算法和针对常数天数的多项式时间近似方案。
2. 对于时间不变的处理时间：获得了多项式时间的(1+√2)/2+ε近似算法，并证明该问题允许任意天数的拟多项式时间近似方案。
3. 提出的批处理技术和下界机制为近似算法设计提供了有效工具。

Conclusion: 本文为公平重复调度问题开发了具有理论性能保证的近似算法，解决了先前工作中仅针对高度结构化特殊情况提供精确解法的局限性。提出的批处理技术和下界机制不仅解决了当前问题，也可能对更广泛的调度问题具有借鉴意义。

Abstract: We consider a recently introduced fair repetitive scheduling problem involving a set of clients, each asking for their associated job to be daily scheduled on a single machine across a finite planning horizon. The goal is to determine a job processing permutation for each day, aiming to minimize the maximum total completion time experienced by any client. This problem is known to be NP-hard for quite restrictive settings, with previous work offering exact solution methods for highly-structured special cases.
  In this paper, we focus on the design of approximation algorithms with provable performance guarantees. Our main contributions can be briefly summarized as follows:
  (i) When job processing times are day-dependent, we devise a polynomial-time LP-based $2$-approximation, as well as a polynomial-time approximation scheme for a constant number of days.
  (ii) With day-invariant processing times, we obtain a surprisingly simple $(\frac{1+\sqrt{2}}{2}+ε)$-approximation in polynomial time. This setting is also shown to admit a quasi-polynomial-time approximation scheme for an arbitrary number of days.
  The key technical component driving our approximation schemes is a novel batching technique, where jobs are conceptually grouped into batches, subsequently leading either to a low-dimensional dynamic program or to a compact configuration LP. Concurrently, while developing our constant-factor approximations, we propose a host of lower-bounding mechanisms that may be of broader interest.

</details>


### [31] [EF(X) Orientations: A Parameterized Complexity Perspective](https://arxiv.org/abs/2512.25033)
*Sotiris Kanellopoulos,Edouard Nemery,Christos Pergaminelis,Minas Marios Sotiriou,Manolis Vasilakis*

Main category: cs.DS

TL;DR: 该论文首次系统研究了图中的公平定向（EF orientations）问题，从参数化复杂度角度分析其可解性，并与EFX定向进行对比，同时考虑了慈善场景下的最小边删除问题。


<details>
  <summary>Details</summary>
Motivation: 公平定向模型自然地模拟了资源分配场景，其中资源仅由相邻代理争夺。虽然EFX定向已被广泛研究，但EF定向尚未被探索。本文旨在填补这一空白，从参数化复杂度角度系统研究EF定向问题。

Method: 采用参数化复杂度理论框架，分析简单图和多重图中的EF定向问题。通过设计算法、证明硬度结果和探索不同参数化方案，系统研究问题的可解性边界。同时考虑慈善场景下的最小边删除问题。

Result: 1) 发现了EF定向的多个可解情况和硬度结果；2) 许多结果可迁移到EFX定向，补充并改进了先前工作；3) 回答了关于多项式有界估值图上EFX定向结构参数化复杂度的开放问题；4) 证明在二元估值情况下，EF定向比EFX定向更易处理；5) 建立了寻找最小边删除集以实现EF(X)定向的算法。

Conclusion: 本文首次系统研究了图中的公平定向（EF）问题，从参数化复杂度角度提供了全面的可解性分析。研究不仅填补了EF定向的研究空白，还通过结果迁移改进了EFX定向的现有理解，并揭示了两种公平概念在不同场景下的计算复杂性差异。

Abstract: The concept of fair orientations in graphs was introduced by Christodoulou, Fiat, Koutsoupias, and Sgouritsa in 2023, naturally modeling fair division scenarios in which resources are only contested by neighbors. In this model, vertices represent agents and undirected edges represent goods; edges have to be oriented towards one of their endpoints, i.e., allocated to one of their adjacent agents. Although EFX orientations (envy-free up to any good) have been extensively studied in this setting, EF orientations (envy-free) remain unexplored. In this work, we initiate their study, mostly under the lens of parameterized complexity, presenting various tractable cases, hardness results, and parameterizations. Our results concern both simple graphs and multigraphs. Interestingly, many of our results transfer to EFX orientations, thus complementing and improving upon previous work; notably, we answer an open question regarding the structural parameterized complexity of the latter problem on graphs of polynomially-bounded valuations. We also show that EF orientations are tractable in cases in which EFX orientations are not, particularly for binary valuations. Lastly, we consider charity in the orientation setting, establishing algorithms for finding the minimum amount of edges that have to be removed from a graph in order for EF(X) orientations to exist.

</details>
