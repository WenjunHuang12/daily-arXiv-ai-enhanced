{"id": "2601.04433", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04433", "abs": "https://arxiv.org/abs/2601.04433", "authors": ["Yuhao Chi", "Zhiyuan Peng", "Lei Liu", "Ying Li", "Yao Ge", "Chau Yuen"], "title": "Achievable Rate and Coding Principle for MIMO Multicarrier Systems With Cross-Domain MAMP Receiver Over Doubly Selective Channels", "comment": "16 pages, 11 figures, accepted in IEEE Transactions on Wireless Communications", "summary": "The integration of multicarrier modulation and multiple-input-multiple-output (MIMO) is critical for reliable transmission of wireless signals in complex environments, which significantly improve spectrum efficiency. Existing studies have shown that popular orthogonal time frequency space (OTFS) and affine frequency division multiplexing (AFDM) offer significant advantages over orthogonal frequency division multiplexing (OFDM) in uncoded doubly selective channels. However, it remains uncertain whether these benefits extend to coded systems. Meanwhile, the information-theoretic limit analysis of coded MIMO multicarrier systems and the corresponding low-complexity receiver design remain unclear. To overcome these challenges, this paper proposes a multi-slot cross-domain memory approximate message passing (MS-CD-MAMP) receiver as well as develops its information-theoretic (i.e., achievable rate) limit and optimal coding principle for MIMO-multicarrier modulation (e.g., OFDM, OTFS, and AFDM) systems. The proposed MS-CD-MAMP receiver can exploit not only the time domain channel sparsity for low complexity but also the corresponding symbol domain constellation constraints for performance enhancement. Meanwhile, limited by the high-dimensional complex state evolution (SE), a simplified single-input single-output variational SE is proposed to derive the achievable rate of MS-CD-MAMP and the optimal coding principle with the goal of maximizing the achievable rate. Numerical results show that coded MIMO-OFDM/OTFS/AFDM with MS-CD-MAMP achieve the same maximum achievable rate in doubly selective channels, whose finite-length performance with practical optimized low-density parity-check (LDPC) codes is only 0.5 $\\sim$ 1.8 dB away from the associated theoretical limit, and has 0.8 $\\sim$ 4.4 dB gain over the well-designed point-to-point LDPC codes.", "AI": {"tldr": "\u63d0\u51faMS-CD-MAMP\u63a5\u6536\u673a\u7528\u4e8eMIMO\u591a\u8f7d\u6ce2\u7cfb\u7edf\uff0c\u5206\u6790\u5176\u53ef\u8fbe\u901f\u7387\u6781\u9650\u548c\u6700\u4f18\u7f16\u7801\u539f\u5219\uff0c\u5728\u53cc\u9009\u62e9\u6027\u4fe1\u9053\u4e2dOFDM/OTFS/AFDM\u53ef\u8fbe\u76f8\u540c\u6700\u5927\u901f\u7387", "motivation": "\u73b0\u6709\u7814\u7a76\u663e\u793aOTFS\u548cAFDM\u5728\u975e\u7f16\u7801\u53cc\u9009\u62e9\u6027\u4fe1\u9053\u4e2d\u4f18\u4e8eOFDM\uff0c\u4f46\u7f16\u7801\u7cfb\u7edf\u4e2d\u8fd9\u4e9b\u4f18\u52bf\u662f\u5426\u5ef6\u7eed\u5c1a\u4e0d\u660e\u786e\uff0c\u4e14\u7f16\u7801MIMO\u591a\u8f7d\u6ce2\u7cfb\u7edf\u7684\u4fe1\u606f\u8bba\u6781\u9650\u5206\u6790\u548c\u4f4e\u590d\u6742\u5ea6\u63a5\u6536\u673a\u8bbe\u8ba1\u4ecd\u4e0d\u6e05\u695a", "method": "\u63d0\u51fa\u591a\u65f6\u9699\u8de8\u57df\u8bb0\u5fc6\u8fd1\u4f3c\u6d88\u606f\u4f20\u9012\uff08MS-CD-MAMP\uff09\u63a5\u6536\u673a\uff0c\u5229\u7528\u65f6\u57df\u4fe1\u9053\u7a00\u758f\u6027\u964d\u4f4e\u590d\u6742\u5ea6\uff0c\u5229\u7528\u7b26\u53f7\u57df\u661f\u5ea7\u7ea6\u675f\u63d0\u5347\u6027\u80fd\uff1b\u63d0\u51fa\u7b80\u5316\u7684\u5355\u8f93\u5165\u5355\u8f93\u51fa\u53d8\u5206\u72b6\u6001\u6f14\u5316\u5206\u6790\u53ef\u8fbe\u901f\u7387\u548c\u6700\u4f18\u7f16\u7801\u539f\u5219", "result": "\u7f16\u7801MIMO-OFDM/OTFS/AFDM\u5728\u53cc\u9009\u62e9\u6027\u4fe1\u9053\u4e2d\u53ef\u8fbe\u76f8\u540c\u6700\u5927\u901f\u7387\uff0c\u5b9e\u9645\u4f18\u5316\u7684LDPC\u7801\u6027\u80fd\u8ddd\u7406\u8bba\u6781\u9650\u4ec50.5-1.8dB\uff0c\u6bd4\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u70b9\u5bf9\u70b9LDPC\u7801\u67090.8-4.4dB\u589e\u76ca", "conclusion": "MS-CD-MAMP\u63a5\u6536\u673a\u4e3aMIMO\u591a\u8f7d\u6ce2\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u4fe1\u606f\u8bba\u6781\u9650\u5206\u6790\u548c\u4f4e\u590d\u6742\u5ea6\u63a5\u6536\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u7f16\u7801\u7cfb\u7edf\u4e2dOTFS/AFDM\u4f18\u52bf\u5ef6\u7eed\u6027\u7684\u4e0d\u786e\u5b9a\u95ee\u9898"}}
{"id": "2601.04517", "categories": ["cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04517", "abs": "https://arxiv.org/abs/2601.04517", "authors": ["Zimo Yan", "Zheng Xie", "Runfan Duan", "Chang Liu", "Wumei Du"], "title": "Bridging Distance and Spectral Positional Encodings via Anchor-Based Diffusion Geometry Approximation", "comment": null, "summary": "Molecular graph learning benefits from positional signals that capture both local neighborhoods and global topology. Two widely used families are spectral encodings derived from Laplacian or diffusion operators and anchor-based distance encodings built from shortest-path information, yet their precise relationship is poorly understood. We interpret distance encodings as a low-rank surrogate of diffusion geometry and derive an explicit trilateration map that reconstructs truncated diffusion coordinates from transformed anchor distances and anchor spectral positions, with pointwise and Frobenius-gap guarantees on random regular graphs. On DrugBank molecular graphs using a shared GNP-based DDI prediction backbone, a distance-driven Nystr\u00f6m scheme closely recovers diffusion geometry, and both Laplacian and distance encodings substantially outperform a no-encoding baseline.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u8ddd\u79bb\u7f16\u7801\u4e0e\u6269\u6563\u51e0\u4f55\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u8fb9\u6d4b\u91cf\u6620\u5c04\u65b9\u6cd5\uff0c\u5e76\u5728\u5206\u5b50\u56fe\u5b66\u4e60\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u4f4d\u7f6e\u7f16\u7801\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5206\u5b50\u56fe\u5b66\u4e60\u9700\u8981\u4f4d\u7f6e\u4fe1\u53f7\u6765\u6355\u6349\u5c40\u90e8\u90bb\u57df\u548c\u5168\u5c40\u62d3\u6251\u7ed3\u6784\u3002\u867d\u7136\u8c31\u7f16\u7801\u548c\u57fa\u4e8e\u951a\u70b9\u7684\u8ddd\u79bb\u7f16\u7801\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u4e24\u8005\u4e4b\u95f4\u7684\u7cbe\u786e\u5173\u7cfb\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u8ddd\u79bb\u7f16\u7801\u4f5c\u4e3a\u6269\u6563\u51e0\u4f55\u4f4e\u79e9\u66ff\u4ee3\u7684\u672c\u8d28\uff0c\u5e76\u5efa\u7acb\u4e24\u8005\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\u3002", "method": "1. \u5c06\u8ddd\u79bb\u7f16\u7801\u89e3\u91ca\u4e3a\u6269\u6563\u51e0\u4f55\u7684\u4f4e\u79e9\u66ff\u4ee3\uff1b2. \u63a8\u5bfc\u51fa\u663e\u5f0f\u7684\u4e09\u8fb9\u6d4b\u91cf\u6620\u5c04\uff0c\u4ece\u53d8\u6362\u540e\u7684\u951a\u70b9\u8ddd\u79bb\u548c\u951a\u70b9\u8c31\u4f4d\u7f6e\u91cd\u5efa\u622a\u65ad\u7684\u6269\u6563\u5750\u6807\uff1b3. \u5728\u968f\u673a\u6b63\u5219\u56fe\u4e0a\u63d0\u4f9b\u70b9\u6001\u548cFrobenius\u95f4\u9699\u4fdd\u8bc1\uff1b4. \u5728DrugBank\u5206\u5b50\u56fe\u4e0a\u4f7f\u7528\u57fa\u4e8eGNP\u7684DDI\u9884\u6d4b\u9aa8\u5e72\uff0c\u901a\u8fc7\u8ddd\u79bb\u9a71\u52a8\u7684Nystr\u00f6m\u65b9\u6848\u6062\u590d\u6269\u6563\u51e0\u4f55\u3002", "result": "1. \u7406\u8bba\u5206\u6790\u8868\u660e\u8ddd\u79bb\u7f16\u7801\u53ef\u4ee5\u51c6\u786e\u91cd\u5efa\u6269\u6563\u51e0\u4f55\uff1b2. \u5728DrugBank\u5206\u5b50\u56fe\u7684DDI\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u8ddd\u79bb\u9a71\u52a8\u7684Nystr\u00f6m\u65b9\u6848\u80fd\u7d27\u5bc6\u6062\u590d\u6269\u6563\u51e0\u4f55\uff1b3. \u62c9\u666e\u62c9\u65af\u7f16\u7801\u548c\u8ddd\u79bb\u7f16\u7801\u90fd\u663e\u8457\u4f18\u4e8e\u65e0\u7f16\u7801\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u8ddd\u79bb\u7f16\u7801\u4e0e\u6269\u6563\u51e0\u4f55\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u8bc1\u660e\u4e86\u8ddd\u79bb\u7f16\u7801\u53ef\u4ee5\u4f5c\u4e3a\u6269\u6563\u51e0\u4f55\u7684\u6709\u6548\u4f4e\u79e9\u66ff\u4ee3\u3002\u5728\u5206\u5b50\u56fe\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0c\u4f4d\u7f6e\u7f16\u7801\uff08\u65e0\u8bba\u662f\u8c31\u7f16\u7801\u8fd8\u662f\u8ddd\u79bb\u7f16\u7801\uff09\u5bf9\u6027\u80fd\u63d0\u5347\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u4f4d\u7f6e\u7f16\u7801\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2601.04665", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.04665", "abs": "https://arxiv.org/abs/2601.04665", "authors": ["Xiao Fan", "Wenkun Wen", "Peiran Wu", "Junhui Zhao", "Minghua Xia"], "title": "Air-to-Ground Communications for Internet of Things: UAV-based Coverage Hole Detection and Recovery", "comment": "17 pages, 14 figures, 2 tables; to appear in IEEE Internet of Things Journal", "summary": "Uncrewed aerial vehicles (UAVs) play a pivotal role in ensuring seamless connectivity for Internet of Things (IoT) devices, particularly in scenarios where conventional terrestrial networks are constrained or temporarily unavailable. However, traditional coverage-hole detection approaches, such as minimizing drive tests, are costly, time-consuming, and reliant on outdated radio-environment data, making them unsuitable for real-time applications. To address these limitations, this paper proposes a UAV-assisted framework for real-time detection and recovery of coverage holes in IoT networks. In the proposed scheme, a patrol UAV is first dispatched to identify coverage holes in regions where the operational status of terrestrial base stations (BSs) is uncertain. Once a coverage hole is detected, one or more UAVs acting as aerial BSs are deployed by a satellite or nearby operational BSs to restore connectivity. The UAV swarm is organized based on Delaunay triangulation, enabling scalable deployment and tractable analytical characterization using stochastic geometry. Moreover, a collision-avoidance mechanism grounded in multi-agent system theory ensures safe and coordinated motion among multiple UAVs. Simulation results demonstrate that the proposed framework achieves high efficiency in both coverage-hole detection and on-demand connectivity restoration while significantly reducing operational cost and time.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u65e0\u4eba\u673a\u7fa4\u7684\u7269\u8054\u7f51\u7f51\u7edc\u8986\u76d6\u7a7a\u6d1e\u5b9e\u65f6\u68c0\u6d4b\u4e0e\u6062\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u5de1\u903b\u65e0\u4eba\u673a\u68c0\u6d4b\u7a7a\u6d1e\uff0c\u7136\u540e\u90e8\u7f72\u65e0\u4eba\u673a\u4f5c\u4e3a\u7a7a\u4e2d\u57fa\u7ad9\u6062\u590d\u8fde\u63a5\uff0c\u91c7\u7528Delaunay\u4e09\u89d2\u5256\u5206\u7ec4\u7ec7\u65e0\u4eba\u673a\u7fa4\uff0c\u5e76\u5305\u542b\u9632\u649e\u673a\u5236\u3002", "motivation": "\u4f20\u7edf\u8986\u76d6\u7a7a\u6d1e\u68c0\u6d4b\u65b9\u6cd5\uff08\u5982\u6700\u5c0f\u5316\u8def\u6d4b\uff09\u6210\u672c\u9ad8\u3001\u8017\u65f6\u957f\u3001\u4f9d\u8d56\u8fc7\u65f6\u6570\u636e\uff0c\u4e0d\u9002\u5408\u5b9e\u65f6\u5e94\u7528\u3002\u65e0\u4eba\u673a\u5728\u7269\u8054\u7f51\u8fde\u63a5\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728\u5730\u9762\u7f51\u7edc\u53d7\u9650\u6216\u6682\u65f6\u4e0d\u53ef\u7528\u7684\u60c5\u51b5\u4e0b\u3002", "method": "1) \u6d3e\u9063\u5de1\u903b\u65e0\u4eba\u673a\u68c0\u6d4b\u5730\u9762\u57fa\u7ad9\u72b6\u6001\u4e0d\u786e\u5b9a\u533a\u57df\u7684\u8986\u76d6\u7a7a\u6d1e\uff1b2) \u68c0\u6d4b\u5230\u7a7a\u6d1e\u540e\uff0c\u901a\u8fc7\u536b\u661f\u6216\u9644\u8fd1\u8fd0\u884c\u57fa\u7ad9\u90e8\u7f72\u4e00\u4e2a\u6216\u591a\u4e2a\u65e0\u4eba\u673a\u4f5c\u4e3a\u7a7a\u4e2d\u57fa\u7ad9\u6062\u590d\u8fde\u63a5\uff1b3) \u57fa\u4e8eDelaunay\u4e09\u89d2\u5256\u5206\u7ec4\u7ec7\u65e0\u4eba\u673a\u7fa4\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u90e8\u7f72\u548c\u53ef\u5206\u6790\u7684\u968f\u673a\u51e0\u4f55\u7279\u5f81\uff1b4) \u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7406\u8bba\u8bbe\u8ba1\u9632\u649e\u673a\u5236\uff0c\u786e\u4fdd\u591a\u65e0\u4eba\u673a\u5b89\u5168\u534f\u8c03\u8fd0\u52a8\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u8986\u76d6\u7a7a\u6d1e\u68c0\u6d4b\u548c\u6309\u9700\u8fde\u63a5\u6062\u590d\u65b9\u9762\u5747\u5b9e\u73b0\u9ad8\u6548\u7387\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u548c\u65f6\u95f4\u3002", "conclusion": "\u63d0\u51fa\u7684\u65e0\u4eba\u673a\u8f85\u52a9\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u7269\u8054\u7f51\u7f51\u7edc\u8986\u76d6\u7a7a\u6d1e\u7684\u5b9e\u65f6\u68c0\u6d4b\u548c\u6062\u590d\u95ee\u9898\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u6210\u672c\u4f4e\u3001\u5b9e\u65f6\u6027\u5f3a\u3001\u53ef\u6269\u5c55\u6027\u597d\u7b49\u4f18\u52bf\u3002"}}
{"id": "2601.04723", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04723", "abs": "https://arxiv.org/abs/2601.04723", "authors": ["Zhenyu Li", "Ozan Alp Topal", "\u00d6zlem Tu\u011ffe Demir", "Emil Bj\u00f6rnson", "Cicek Cavdar"], "title": "Feasibility Study Regarding Self-sustainable Reconfigurable Intelligent Surfaces", "comment": "5pages, 3 figures, submitted and accepted by IEEE Wireless Communication Letter", "summary": "Without requiring operational costs such as cabling and powering while maintaining reconfigurable phase-shift capability, self-sustainable reconfigurable intelligent surfaces (ssRISs) can be deployed in locations inaccessible to conventional relays or base stations, offering a novel approach to enhance wireless coverage. This study assesses the feasibility of ssRIS deployment by analyzing two harvest-and-reflect (HaR) schemes: element-splitting (ES) and time-splitting (TS). We examine how element requirements scale with key system parameters, transmit power, data rate demands, and outage constraints under both line-of-sight (LOS) and non-line-of-sight (NLOS) ssRIS-to-user equipment (UE) channels. Analytical and numerical results reveal distinct feasibility characteristics. The TS scheme demonstrates better channel hardening gain, maintaining stable element requirements across varying outage margins, making it advantageous for indoor deployments with favorable harvesting conditions and moderate data rates. However, TS exhibits an element requirement that exponentially scales to harvesting difficulty and data rate. Conversely, the ES scheme shows only linear growth with harvesting difficulty, providing better feasibility under challenging outdoor scenarios. These findings establish that TS excels in benign environments, prioritizing reliability, while ES is preferable for demanding conditions requiring operational robustness.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u81ea\u4f9b\u80fd\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08ssRIS\uff09\u7684\u90e8\u7f72\u53ef\u884c\u6027\uff0c\u5206\u6790\u4e86\u4e24\u79cd\u80fd\u91cf\u6536\u96c6\u4e0e\u53cd\u5c04\u65b9\u6848\uff1a\u5143\u4ef6\u5206\u5272\uff08ES\uff09\u548c\u65f6\u95f4\u5206\u5272\uff08TS\uff09\uff0c\u6bd4\u8f83\u4e86\u5b83\u4eec\u5728LOS\u548cNLOS\u4fe1\u9053\u4e0b\u7684\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "ssRIS\u65e0\u9700\u5e03\u7ebf\u4f9b\u7535\u5373\u53ef\u5b9e\u73b0\u53ef\u91cd\u6784\u76f8\u79fb\uff0c\u80fd\u90e8\u7f72\u5728\u4f20\u7edf\u4e2d\u7ee7\u6216\u57fa\u7ad9\u65e0\u6cd5\u8986\u76d6\u7684\u533a\u57df\uff0c\u4e3a\u589e\u5f3a\u65e0\u7ebf\u8986\u76d6\u63d0\u4f9b\u4e86\u65b0\u65b9\u6848\u3002\u4f46\u9700\u8981\u8bc4\u4f30\u5176\u5b9e\u9645\u90e8\u7f72\u53ef\u884c\u6027\uff0c\u7279\u522b\u662f\u4e0d\u540c\u80fd\u91cf\u6536\u96c6\u65b9\u6848\u5728\u4e0d\u540c\u73af\u5883\u4e0b\u7684\u9002\u7528\u6027\u3002", "method": "\u5206\u6790\u4e86\u4e24\u79cd\u80fd\u91cf\u6536\u96c6\u4e0e\u53cd\u5c04\u65b9\u6848\uff1a\u5143\u4ef6\u5206\u5272\uff08ES\uff09\u548c\u65f6\u95f4\u5206\u5272\uff08TS\uff09\u3002\u7814\u7a76\u4e86\u5143\u4ef6\u9700\u6c42\u5982\u4f55\u968f\u7cfb\u7edf\u53c2\u6570\uff08\u53d1\u5c04\u529f\u7387\u3001\u6570\u636e\u901f\u7387\u9700\u6c42\u3001\u4e2d\u65ad\u7ea6\u675f\uff09\u53d8\u5316\uff0c\u5e76\u5728LOS\u548cNLOS ssRIS\u5230\u7528\u6237\u8bbe\u5907\u7684\u4fe1\u9053\u6761\u4ef6\u4e0b\u8fdb\u884c\u4e86\u5206\u6790\u3002", "result": "TS\u65b9\u6848\u5177\u6709\u66f4\u597d\u7684\u4fe1\u9053\u786c\u5316\u589e\u76ca\uff0c\u5143\u4ef6\u9700\u6c42\u5728\u4e0d\u540c\u4e2d\u65ad\u88d5\u5ea6\u4e0b\u4fdd\u6301\u7a33\u5b9a\uff0c\u9002\u5408\u5ba4\u5185\u90e8\u7f72\u548c\u4e2d\u7b49\u6570\u636e\u901f\u7387\u573a\u666f\u3002\u4f46TS\u7684\u5143\u4ef6\u9700\u6c42\u968f\u80fd\u91cf\u6536\u96c6\u96be\u5ea6\u548c\u6570\u636e\u901f\u7387\u5448\u6307\u6570\u589e\u957f\u3002ES\u65b9\u6848\u4ec5\u968f\u80fd\u91cf\u6536\u96c6\u96be\u5ea6\u7ebf\u6027\u589e\u957f\uff0c\u5728\u6076\u52a3\u6237\u5916\u573a\u666f\u4e0b\u66f4\u5177\u53ef\u884c\u6027\u3002", "conclusion": "TS\u5728\u73af\u5883\u826f\u597d\u7684\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u5148\u8003\u8651\u53ef\u9760\u6027\uff1b\u800cES\u5728\u9700\u8981\u64cd\u4f5c\u9c81\u68d2\u6027\u7684\u82db\u523b\u6761\u4ef6\u4e0b\u66f4\u4f18\u3002\u8fd9\u4e3assRIS\u5728\u4e0d\u540c\u90e8\u7f72\u73af\u5883\u4e0b\u7684\u65b9\u6848\u9009\u62e9\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2601.04648", "categories": ["cs.GT", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04648", "abs": "https://arxiv.org/abs/2601.04648", "authors": ["Xiang Li", "Bing Luo", "Jianwei Huang", "Yuan Luo"], "title": "Mechanism Design for Federated Learning with Non-Monotonic Network Effects", "comment": "Journal extension of Mobihoc conference version, under review of IEEE TMC", "summary": "Mechanism design is pivotal to federated learning (FL) for maximizing social welfare by coordinating self-interested clients. Existing mechanisms, however, often overlook the network effects of client participation and the diverse model performance requirements (i.e., generalization error) across applications, leading to suboptimal incentives and social welfare, or even inapplicability in real deployments. To address this gap, we explore incentive mechanism design for FL with network effects and application-specific requirements of model performance. We develop a theoretical model to quantify the impact of network effects on heterogeneous client participation, revealing the non-monotonic nature of such effects. Based on these insights, we propose a Model Trading and Sharing (MoTS) framework, which enables clients to obtain FL models through either participation or purchase. To further address clients' strategic behaviors, we design a Social Welfare maximization with Application-aware and Network effects (SWAN) mechanism, exploiting model customer payments for incentivization. Experimental results on a hardware prototype demonstrate that our SWAN mechanism outperforms existing FL mechanisms, improving social welfare by up to $352.42\\%$ and reducing extra incentive costs by $93.07\\%$.", "AI": {"tldr": "\u63d0\u51faSWAN\u673a\u5236\uff0c\u901a\u8fc7\u6a21\u578b\u4ea4\u6613\u4e0e\u5171\u4eab\u6846\u67b6\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u7f51\u7edc\u6548\u5e94\u548c\u4e2a\u6027\u5316\u6027\u80fd\u9700\u6c42\u7684\u6fc0\u52b1\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u793e\u4f1a\u798f\u5229\u5e76\u964d\u4f4e\u6fc0\u52b1\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u6fc0\u52b1\u673a\u5236\u5ffd\u7565\u7f51\u7edc\u6548\u5e94\u548c\u4e0d\u540c\u5e94\u7528\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5dee\u5f02\u5316\u9700\u6c42\uff0c\u5bfc\u81f4\u6fc0\u52b1\u6548\u679c\u4e0d\u4f73\u3001\u793e\u4f1a\u798f\u5229\u4f4e\u4e0b\uff0c\u751a\u81f3\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u4e0d\u9002\u7528\u3002", "method": "\u63d0\u51fa\u6a21\u578b\u4ea4\u6613\u4e0e\u5171\u4eab\u6846\u67b6\uff0c\u5141\u8bb8\u5ba2\u6237\u7aef\u901a\u8fc7\u53c2\u4e0e\u8bad\u7ec3\u6216\u8d2d\u4e70\u6a21\u578b\u83b7\u53d6FL\u6a21\u578b\uff1b\u8bbe\u8ba1SWAN\u673a\u5236\uff0c\u5229\u7528\u6a21\u578b\u5ba2\u6237\u652f\u4ed8\u8fdb\u884c\u6fc0\u52b1\uff0c\u6700\u5927\u5316\u793e\u4f1a\u798f\u5229\u3002", "result": "\u5728\u786c\u4ef6\u539f\u578b\u5b9e\u9a8c\u4e2d\uff0cSWAN\u673a\u5236\u76f8\u6bd4\u73b0\u6709FL\u673a\u5236\u63d0\u5347\u793e\u4f1a\u798f\u5229\u9ad8\u8fbe352.42%\uff0c\u51cf\u5c11\u989d\u5916\u6fc0\u52b1\u6210\u672c93.07%\u3002", "conclusion": "\u8003\u8651\u7f51\u7edc\u6548\u5e94\u548c\u4e2a\u6027\u5316\u6027\u80fd\u9700\u6c42\u7684\u6fc0\u52b1\u673a\u5236\u80fd\u663e\u8457\u63d0\u5347\u8054\u90a6\u5b66\u4e60\u7684\u793e\u4f1a\u798f\u5229\u548c\u6fc0\u52b1\u6548\u7387\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.04432", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.04432", "abs": "https://arxiv.org/abs/2601.04432", "authors": ["Harshavardhan Kamarthi", "Harshil Shah", "Henry Milner", "Sayan Sinha", "Yan Li", "B. Aditya Prakash", "Vyas Sekar"], "title": "AHA: Scalable Alternative History Analysis for Operational Timeseries Applications", "comment": "To Appear at KDD 2026", "summary": "Many operational systems collect high-dimensional timeseries data about users/systems on key performance metrics. For instance, ISPs, content distribution networks, and video delivery services collect quality of experience metrics for user sessions associated with metadata (e.g., location, device, ISP). Over such historical data, operators and data analysts often need to run retrospective analysis; e.g., analyze anomaly detection algorithms, experiment with different configurations for alerts, evaluate new algorithms, and so on. We refer to this class of workloads as alternative history analysis for operational datasets. We show that in such settings, traditional data processing solutions (e.g., data warehouses, sampling, sketching, big-data systems) either pose high operational costs or do not guarantee accurate replay. We design and implement a system, called AHA (Alternative History Analytics), that overcomes both challenges to provide cost efficiency and fidelity for high-dimensional data. The design of AHA is based on analytical and empirical insights about such workloads: 1) the decomposability of underlying statistics; 2) sparsity in terms of active number of subpopulations over attribute-value combinations; and 3) efficiency structure of aggregation operations in modern analytics databases. Using multiple real-world datasets and as well as case-studies on production pipelines at a large video analytics company, we show that AHA provides 100% accuracy for a broad range of downstream tasks and up to 85x lower total cost of ownership (i.e., compute + storage) compared to conventional methods.", "AI": {"tldr": "AHA\u7cfb\u7edf\u4e3a\u9ad8\u7ef4\u65f6\u5e8f\u6570\u636e\u7684\u66ff\u4ee3\u5386\u53f2\u5206\u6790\u63d0\u4f9b\u4f4e\u6210\u672c\u9ad8\u4fdd\u771f\u89e3\u51b3\u65b9\u6848\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u964d\u4f4e85%\u603b\u62e5\u6709\u6210\u672c", "motivation": "\u8fd0\u8425\u5546\u548c\u5206\u6790\u5e08\u9700\u8981\u5bf9\u9ad8\u7ef4\u65f6\u5e8f\u6570\u636e\uff08\u5982\u7528\u6237\u4f53\u9a8c\u6307\u6807\uff09\u8fdb\u884c\u56de\u987e\u6027\u5206\u6790\uff0c\u4f46\u4f20\u7edf\u6570\u636e\u5904\u7406\u65b9\u6848\u8981\u4e48\u8fd0\u8425\u6210\u672c\u9ad8\uff0c\u8981\u4e48\u65e0\u6cd5\u4fdd\u8bc1\u51c6\u786e\u91cd\u653e", "method": "\u8bbe\u8ba1AHA\u7cfb\u7edf\uff0c\u57fa\u4e8e\u4e09\u4e2a\u5173\u952e\u6d1e\u5bdf\uff1a1) \u5e95\u5c42\u7edf\u8ba1\u7684\u53ef\u5206\u89e3\u6027\uff1b2) \u5c5e\u6027\u503c\u7ec4\u5408\u4e2d\u5b50\u7fa4\u6d3b\u8dc3\u5ea6\u7684\u7a00\u758f\u6027\uff1b3) \u73b0\u4ee3\u5206\u6790\u6570\u636e\u5e93\u4e2d\u805a\u5408\u64cd\u4f5c\u7684\u9ad8\u6548\u7ed3\u6784", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u548c\u5927\u578b\u89c6\u9891\u5206\u6790\u516c\u53f8\u751f\u4ea7\u6d41\u6c34\u7ebf\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cAHA\u4e3a\u5e7f\u6cdb\u4e0b\u6e38\u4efb\u52a1\u63d0\u4f9b100%\u51c6\u786e\u5ea6\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u964d\u4f4e\u9ad8\u8fbe85%\u7684\u603b\u62e5\u6709\u6210\u672c\uff08\u8ba1\u7b97+\u5b58\u50a8\uff09", "conclusion": "AHA\u7cfb\u7edf\u6210\u529f\u89e3\u51b3\u4e86\u9ad8\u7ef4\u65f6\u5e8f\u6570\u636e\u66ff\u4ee3\u5386\u53f2\u5206\u6790\u7684\u6210\u672c\u6548\u7387\u548c\u4fdd\u771f\u5ea6\u95ee\u9898\uff0c\u4e3a\u8fd0\u8425\u5546\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.04423", "categories": ["cs.DS", "cs.LG", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.04423", "abs": "https://arxiv.org/abs/2601.04423", "authors": ["Flavio Chierichetti", "Mirko Giacchini", "Ravi Kumar", "Silvio Lattanzi", "Alessandro Panconesi", "Erasmo Tani", "Andrew Tomkins"], "title": "Learning Multinomial Logits in $O(n \\log n)$ time", "comment": null, "summary": "A Multinomial Logit (MNL) model is composed of a finite universe of items $[n]=\\{1,..., n\\}$, each assigned a positive weight. A query specifies an admissible subset -- called a slate -- and the model chooses one item from that slate with probability proportional to its weight. This query model is also known as the Plackett-Luce model or conditional sampling oracle in the literature. Although MNLs have been studied extensively, a basic computational question remains open: given query access to slates, how efficiently can we learn weights so that, for every slate, the induced choice distribution is within total variation distance $\\varepsilon$ of the ground truth? This question is central to MNL learning and has direct implications for modern recommender system interfaces.\n  We provide two algorithms for this task, one with adaptive queries and one with non-adaptive queries. Each algorithm outputs an MNL $M'$ that induces, for each slate $S$, a distribution $M'_S$ on $S$ that is within $\\varepsilon$ total variation distance of the true distribution. Our adaptive algorithm makes $O\\left(\\frac{n}{\\varepsilon^{3}}\\log n\\right)$ queries, while our non-adaptive algorithm makes $O\\left(\\frac{n^{2}}{\\varepsilon^{3}}\\log n \\log\\frac{n}{\\varepsilon}\\right)$ queries. Both algorithms query only slates of size two and run in time proportional to their query complexity.\n  We complement these upper bounds with lower bounds of $\u03a9\\left(\\frac{n}{\\varepsilon^{2}}\\log n\\right)$ for adaptive queries and $\u03a9\\left(\\frac{n^{2}}{\\varepsilon^{2}}\\log n\\right)$ for non-adaptive queries, thus proving that our adaptive algorithm is optimal in its dependence on the support size $n$, while the non-adaptive one is tight within a $\\log n$ factor.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4ece\u6210\u5bf9\u6bd4\u8f83\u67e5\u8be2\u4e2d\u5b66\u4e60MNL\u6a21\u578b\u6743\u91cd\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u548c\u975e\u81ea\u9002\u5e94\u4e24\u79cd\u7b97\u6cd5\uff0c\u5206\u522b\u8fbe\u5230O(n/\u03b5\u00b3 log n)\u548cO(n\u00b2/\u03b5\u00b3 log n log(n/\u03b5))\u7684\u67e5\u8be2\u590d\u6742\u5ea6\uff0c\u5e76\u7ed9\u51fa\u4e86\u76f8\u5e94\u7684\u4e0b\u754c\u8bc1\u660e\u3002", "motivation": "MNL\u6a21\u578b\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5982\u4f55\u901a\u8fc7\u67e5\u8be2\u5b66\u4e60\u6a21\u578b\u6743\u91cd\u7684\u57fa\u672c\u8ba1\u7b97\u95ee\u9898\u5c1a\u672a\u89e3\u51b3\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u67e5\u8be2\u590d\u6742\u5ea6\u7684\u7cfb\u7edf\u5206\u6790\uff0c\u7279\u522b\u662f\u4ece\u6210\u5bf9\u6bd4\u8f83\u4e2d\u5b66\u4e60MNL\u6a21\u578b\u7684\u7406\u8bba\u4fdd\u8bc1\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u7b97\u6cd5\uff1a1\uff09\u81ea\u9002\u5e94\u7b97\u6cd5\u901a\u8fc7\u987a\u5e8f\u67e5\u8be2\u6210\u5bf9\u6bd4\u8f83\u6765\u5b66\u4e60\u6743\u91cd\uff1b2\uff09\u975e\u81ea\u9002\u5e94\u7b97\u6cd5\u901a\u8fc7\u6279\u91cf\u67e5\u8be2\u6210\u5bf9\u6bd4\u8f83\u6765\u5b66\u4e60\u6743\u91cd\u3002\u4e24\u79cd\u7b97\u6cd5\u90fd\u53ea\u4f7f\u7528\u5927\u5c0f\u4e3a2\u7684slate\u67e5\u8be2\u3002", "result": "\u81ea\u9002\u5e94\u7b97\u6cd5\u67e5\u8be2\u590d\u6742\u5ea6\u4e3aO(n/\u03b5\u00b3 log n)\uff0c\u975e\u81ea\u9002\u5e94\u7b97\u6cd5\u4e3aO(n\u00b2/\u03b5\u00b3 log n log(n/\u03b5))\u3002\u540c\u65f6\u8bc1\u660e\u4e86\u81ea\u9002\u5e94\u67e5\u8be2\u7684\u4e0b\u754c\u4e3a\u03a9(n/\u03b5\u00b2 log n)\uff0c\u975e\u81ea\u9002\u5e94\u67e5\u8be2\u7684\u4e0b\u754c\u4e3a\u03a9(n\u00b2/\u03b5\u00b2 log n)\u3002", "conclusion": "\u81ea\u9002\u5e94\u7b97\u6cd5\u5728\u652f\u6301\u5927\u5c0fn\u7684\u4f9d\u8d56\u4e0a\u662f\u6700\u4f18\u7684\uff0c\u975e\u81ea\u9002\u5e94\u7b97\u6cd5\u5728log n\u56e0\u5b50\u5185\u662f\u7d27\u7684\u3002\u8fd9\u4e3aMNL\u6a21\u578b\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\uff0c\u5bf9\u63a8\u8350\u7cfb\u7edf\u754c\u9762\u8bbe\u8ba1\u6709\u76f4\u63a5\u610f\u4e49\u3002"}}
{"id": "2601.04291", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04291", "abs": "https://arxiv.org/abs/2601.04291", "authors": ["Minglei Yin", "Chuanbo Hu", "Bin Liu", "Neil Zhenqiang Gong", "Yanfang", "Ye", "Xin Li"], "title": "Correct and Weight: A Simple Yet Effective Loss for Implicit Feedback Recommendation", "comment": "arXiv admin note: text overlap with arXiv:2508.05673 by other authors", "summary": "Learning from implicit feedback has become the standard paradigm for modern recommender systems. However, this setting is fraught with the persistent challenge of false negatives, where unobserved user-item interactions are not necessarily indicative of negative preference. To address this issue, this paper introduces a novel and principled loss function, named Corrected and Weighted (CW) loss, that systematically corrects for the impact of false negatives within the training objective. Our approach integrates two key techniques. First, inspired by Positive-Unlabeled learning, we debias the negative sampling process by re-calibrating the assumed negative distribution. By theoretically approximating the true negative distribution (p-) using the observable general data distribution (p) and the positive interaction distribution (p^+), our method provides a more accurate estimate of the likelihood that a sampled unlabeled item is truly negative. Second, we introduce a dynamic re-weighting mechanism that modulates the importance of each negative instance based on the model's current prediction. This scheme encourages the model to enforce a larger ranking margin between positive items and confidently predicted (i.e., easy) negative items, while simultaneously down-weighting the penalty on uncertain negatives that have a higher probability of being false negatives. A key advantage of our approach is its elegance and efficiency; it requires no complex modifications to the data sampling process or significant computational overhead, making it readily applicable to a wide array of existing recommendation models. Extensive experiments conducted on four large-scale, sparse benchmark datasets demonstrate the superiority of our proposed loss. The results show that our method consistently and significantly outperforms a suite of state-of-the-art loss functions across multiple ranking-oriented metrics.", "AI": {"tldr": "\u63d0\u51fa\u540d\u4e3aCW\u635f\u5931\u7684\u65b0\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u4fee\u6b63\u8d1f\u6837\u672c\u5206\u5e03\u548c\u52a8\u6001\u91cd\u52a0\u6743\u673a\u5236\uff0c\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u9690\u5f0f\u53cd\u9988\u7684\u5047\u9634\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u4ee3\u63a8\u8350\u7cfb\u7edf\u666e\u904d\u91c7\u7528\u9690\u5f0f\u53cd\u9988\u5b66\u4e60\uff0c\u4f46\u9762\u4e34\u5047\u9634\u6027\u7684\u6301\u7eed\u6311\u6218\u2014\u2014\u672a\u89c2\u6d4b\u5230\u7684\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\u4e0d\u4e00\u5b9a\u8868\u793a\u8d1f\u9762\u504f\u597d\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u7cfb\u7edf\u6027\u5730\u5728\u8bad\u7ec3\u76ee\u6807\u4e2d\u4fee\u6b63\u5047\u9634\u6027\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51faCW\u635f\u5931\u51fd\u6570\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u6280\u672f\uff1a1) \u57fa\u4e8e\u6b63-\u672a\u6807\u8bb0\u5b66\u4e60\u601d\u60f3\uff0c\u901a\u8fc7\u53ef\u89c2\u6d4b\u7684\u901a\u7528\u6570\u636e\u5206\u5e03\u548c\u6b63\u4ea4\u4e92\u5206\u5e03\u6765\u8fd1\u4f3c\u771f\u5b9e\u8d1f\u5206\u5e03\uff0c\u4fee\u6b63\u8d1f\u91c7\u6837\u8fc7\u7a0b\u7684\u504f\u5dee\uff1b2) \u5f15\u5165\u52a8\u6001\u91cd\u52a0\u6743\u673a\u5236\uff0c\u6839\u636e\u6a21\u578b\u5f53\u524d\u9884\u6d4b\u8c03\u6574\u6bcf\u4e2a\u8d1f\u6837\u672c\u7684\u91cd\u8981\u6027\uff0c\u5bf9\u7f6e\u4fe1\u5ea6\u9ad8\u7684\u8d1f\u6837\u672c\u65bd\u52a0\u66f4\u5927\u6392\u5e8f\u95f4\u9694\uff0c\u540c\u65f6\u964d\u4f4e\u5bf9\u53ef\u80fd\u662f\u5047\u9634\u6027\u7684\u4e0d\u786e\u5b9a\u8d1f\u6837\u672c\u7684\u60e9\u7f5a\u3002", "result": "\u5728\u56db\u4e2a\u5927\u89c4\u6a21\u7a00\u758f\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6392\u5e8f\u5bfc\u5411\u6307\u6807\u4e0a\u4e00\u81f4\u4e14\u663e\u8457\u4f18\u4e8e\u4e00\u7cfb\u5217\u6700\u5148\u8fdb\u7684\u635f\u5931\u51fd\u6570\u3002", "conclusion": "CW\u635f\u5931\u51fd\u6570\u4f18\u96c5\u9ad8\u6548\uff0c\u65e0\u9700\u5bf9\u6570\u636e\u91c7\u6837\u8fc7\u7a0b\u8fdb\u884c\u590d\u6742\u4fee\u6539\u6216\u663e\u8457\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\uff0c\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u73b0\u6709\u63a8\u8350\u6a21\u578b\uff0c\u6709\u6548\u89e3\u51b3\u9690\u5f0f\u53cd\u9988\u4e2d\u7684\u5047\u9634\u6027\u95ee\u9898\u3002"}}
{"id": "2601.04815", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.04815", "abs": "https://arxiv.org/abs/2601.04815", "authors": ["Amirreza Zamani", "Parastoo Sadeghi", "Mikael Skoglund"], "title": "Privacy-Utility Trade-offs Under Multi-Level Point-Wise Leakage Constraints", "comment": null, "summary": "An information-theoretic privacy mechanism design is studied, where an agent observes useful data $Y$ which is correlated with the private data $X$. The agent wants to reveal the information to a user, hence, the agent utilizes a privacy mechanism to produce disclosed data $U$ that can be revealed. We assume that the agent has no direct access to $X$, i.e., the private data is hidden. We study privacy mechanism design that maximizes the disclosed information about $Y$, measured by the mutual information between $Y$ and $U$, while satisfying a point-wise constraint with different privacy leakage budgets. We introduce a new measure, called the \\emph{multi-level point-wise leakage}, which allows us to impose different leakage levels for different realizations of $U$. In contrast to previous studies on point-wise measures, which use the same leakage level for each realization, we consider a more general scenario in which each data point can leak information up to a different threshold. As a result, this concept also covers cases in which some data points should not leak any information about the private data, i.e., they must satisfy perfect privacy. In other words, a combination of perfect privacy and non-zero leakage can be considered. When the leakage is sufficiently small, concepts from information geometry allow us to locally approximate the mutual information. We show that when the leakage matrix $P_{X|Y}$ is invertible, utilizing this approximation leads to a quadratic optimization problem that has closed-form solution under some constraints. In particular, we show that it is sufficient to consider only binary $U$ to attain the optimal utility. This leads to simple privacy designs with low complexity which are based on finding the maximum singular value and singular vector of a matrix.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u9690\u79c1\u673a\u5236\u8bbe\u8ba1\uff0c\u5728\u65e0\u6cd5\u76f4\u63a5\u8bbf\u95ee\u79c1\u6709\u6570\u636eX\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u8bbe\u8ba1\u9690\u79c1\u673a\u5236\u751f\u6210\u62ab\u9732\u6570\u636eU\uff0c\u5728\u6ee1\u8db3\u4e0d\u540c\u9690\u79c1\u6cc4\u9732\u9884\u7b97\u7684\u70b9\u5bf9\u70b9\u7ea6\u675f\u4e0b\u6700\u5927\u5316\u5173\u4e8e\u6709\u7528\u6570\u636eY\u7684\u4fe1\u606f\u62ab\u9732\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u901a\u5e38\u5bf9\u6bcf\u4e2a\u6570\u636e\u70b9\u4f7f\u7528\u76f8\u540c\u7684\u6cc4\u9732\u6c34\u5e73\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u4e0d\u540c\u6570\u636e\u70b9\u53ef\u80fd\u9700\u8981\u4e0d\u540c\u7684\u9690\u79c1\u4fdd\u62a4\u7ea7\u522b\uff0c\u6709\u4e9b\u751a\u81f3\u9700\u8981\u5b8c\u5168\u9690\u79c1\uff08\u96f6\u6cc4\u9732\uff09\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u9690\u79c1\u673a\u5236\uff0c\u80fd\u591f\u4e3a\u4e0d\u540c\u6570\u636e\u70b9\u5206\u914d\u4e0d\u540c\u7684\u6cc4\u9732\u9884\u7b97\u3002", "method": "\u5f15\u5165\u591a\u7ea7\u70b9\u5bf9\u70b9\u6cc4\u9732\u5ea6\u91cf\uff0c\u5141\u8bb8\u4e3aU\u7684\u4e0d\u540c\u5b9e\u73b0\u65bd\u52a0\u4e0d\u540c\u7684\u6cc4\u9732\u6c34\u5e73\u3002\u5f53\u6cc4\u9732\u8db3\u591f\u5c0f\u65f6\uff0c\u5229\u7528\u4fe1\u606f\u51e0\u4f55\u6982\u5ff5\u5bf9\u4e92\u4fe1\u606f\u8fdb\u884c\u5c40\u90e8\u8fd1\u4f3c\uff0c\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u6c42\u89e3\u7684\u4e8c\u6b21\u4f18\u5316\u95ee\u9898\u3002\u8bc1\u660e\u5728\u53ef\u9006\u6cc4\u9732\u77e9\u9635\u6761\u4ef6\u4e0b\uff0c\u4ec5\u9700\u8003\u8651\u4e8c\u5143U\u5373\u53ef\u8fbe\u5230\u6700\u4f18\u6548\u7528\u3002", "result": "\u5f53\u6cc4\u9732\u77e9\u9635\u53ef\u9006\u65f6\uff0c\u5229\u7528\u5c40\u90e8\u8fd1\u4f3c\u53ef\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u5177\u6709\u95ed\u5f0f\u89e3\u7684\u4e8c\u6b21\u4f18\u5316\u95ee\u9898\u3002\u7279\u522b\u5730\uff0c\u8bc1\u660e\u4ec5\u9700\u4e8c\u5143U\u5373\u53ef\u8fbe\u5230\u6700\u4f18\u6548\u7528\uff0c\u8fd9\u5bfc\u81f4\u57fa\u4e8e\u77e9\u9635\u6700\u5927\u5947\u5f02\u503c\u548c\u5947\u5f02\u5411\u91cf\u7684\u4f4e\u590d\u6742\u5ea6\u9690\u79c1\u8bbe\u8ba1\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u7ea7\u70b9\u5bf9\u70b9\u6cc4\u9732\u6846\u67b6\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff0c\u80fd\u591f\u540c\u65f6\u5904\u7406\u5b8c\u5168\u9690\u79c1\u548c\u975e\u96f6\u6cc4\u9732\u7684\u60c5\u51b5\u3002\u901a\u8fc7\u4fe1\u606f\u51e0\u4f55\u8fd1\u4f3c\u548c\u4e8c\u5143U\u7684\u5145\u5206\u6027\u8bc1\u660e\uff0c\u5b9e\u73b0\u4e86\u7b80\u5355\u6709\u6548\u7684\u9690\u79c1\u8bbe\u8ba1\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2601.04722", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.04722", "abs": "https://arxiv.org/abs/2601.04722", "authors": ["Chrysanthi Kosyfaki", "Ruiyuan Zhang", "Nikos Mamoulis", "Xiaofang Zhou"], "title": "Does Provenance Interact?", "comment": null, "summary": "Data provenance (the process of determining the origin and derivation of data outputs) has applications across multiple domains including explaining database query results and auditing scientific workflows. Despite decades of research, provenance tracing remains challenging due to computational costs and storage overhead. In streaming systems such as Apache Flink, provenance graphs can grow super-linearly with data volume, posing significant scalability challenges. Temporal provenance is a promising direction, attaching timestamps to provenance information, enabling time-focused queries without maintaining complete historical records. However, existing temporal provenance methods primarily focus on system-level debugging, leaving a gap in data management applications. This paper proposes an agenda that uses Temporal Interaction Networks (TINs) to represent temporal provenance efficiently. We demonstrate TINs' applicability across streaming systems, transportation networks, and financial networks. We classify data into discrete and liquid types, define five temporal provenance query types, and propose a state-based indexing approach. Our vision outlines research directions toward making temporal provenance a practical tool for large-scale dataflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u65f6\u95f4\u4ea4\u4e92\u7f51\u7edc(TINs)\u9ad8\u6548\u8868\u793a\u65f6\u95f4\u6eaf\u6e90\u4fe1\u606f\uff0c\u89e3\u51b3\u6d41\u5f0f\u7cfb\u7edf\u4e2d\u6eaf\u6e90\u56fe\u968f\u6570\u636e\u91cf\u8d85\u7ebf\u6027\u589e\u957f\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u6570\u636e\u6d41\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002", "motivation": "\u6570\u636e\u6eaf\u6e90\u5728\u6570\u636e\u5e93\u67e5\u8be2\u89e3\u91ca\u548c\u79d1\u5b66\u5de5\u4f5c\u6d41\u5ba1\u8ba1\u7b49\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u4f20\u7edf\u6eaf\u6e90\u8ffd\u8e2a\u9762\u4e34\u8ba1\u7b97\u6210\u672c\u548c\u5b58\u50a8\u5f00\u9500\u7684\u6311\u6218\u3002\u5728\u6d41\u5f0f\u7cfb\u7edf\u4e2d\uff0c\u6eaf\u6e90\u56fe\u4f1a\u968f\u6570\u636e\u91cf\u8d85\u7ebf\u6027\u589e\u957f\uff0c\u5b58\u5728\u663e\u8457\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002\u73b0\u6709\u65f6\u95f4\u6eaf\u6e90\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7cfb\u7edf\u7ea7\u8c03\u8bd5\uff0c\u5728\u6570\u636e\u7ba1\u7406\u5e94\u7528\u65b9\u9762\u5b58\u5728\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u65f6\u95f4\u4ea4\u4e92\u7f51\u7edc(TINs)\u8868\u793a\u65f6\u95f4\u6eaf\u6e90\u4fe1\u606f\uff0c\u5c06\u6570\u636e\u5206\u4e3a\u79bb\u6563\u578b\u548c\u6d41\u52a8\u578b\u4e24\u79cd\u7c7b\u578b\uff0c\u5b9a\u4e49\u4e94\u79cd\u65f6\u95f4\u6eaf\u6e90\u67e5\u8be2\u7c7b\u578b\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u72b6\u6001\u7684\u7d22\u5f15\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u6d41\u5f0f\u7cfb\u7edf\u3001\u4ea4\u901a\u7f51\u7edc\u548c\u91d1\u878d\u7f51\u7edc\u7b49\u591a\u79cd\u573a\u666f\u3002", "result": "\u5c55\u793a\u4e86TINs\u5728\u591a\u4e2a\u9886\u57df\u7684\u9002\u7528\u6027\uff0c\u5305\u62ec\u6d41\u5f0f\u7cfb\u7edf\u3001\u4ea4\u901a\u7f51\u7edc\u548c\u91d1\u878d\u7f51\u7edc\u3002\u63d0\u51fa\u7684\u5206\u7c7b\u3001\u67e5\u8be2\u7c7b\u578b\u548c\u7d22\u5f15\u65b9\u6cd5\u4e3a\u65f6\u95f4\u6eaf\u6e90\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6846\u67b6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7814\u7a76\u8bae\u7a0b\uff0c\u65e8\u5728\u4f7f\u65f6\u95f4\u6eaf\u6e90\u6210\u4e3a\u5927\u89c4\u6a21\u6570\u636e\u6d41\u7684\u5b9e\u7528\u5de5\u5177\u3002\u901a\u8fc7TINs\u8868\u793a\u3001\u6570\u636e\u5206\u7c7b\u3001\u67e5\u8be2\u5b9a\u4e49\u548c\u7d22\u5f15\u65b9\u6cd5\uff0c\u4e3a\u89e3\u51b3\u6eaf\u6e90\u8ffd\u8e2a\u7684\u53ef\u6269\u5c55\u6027\u6311\u6218\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2601.04626", "categories": ["cs.DS", "cs.CG"], "pdf": "https://arxiv.org/pdf/2601.04626", "abs": "https://arxiv.org/abs/2601.04626", "authors": ["Therese Biedl", "Prashant Gokhale"], "title": "Using Ray-shooting Queries for Sublinear Algorithms for Dominating Sets in RDV Graphs", "comment": "To appear at SOFSEM'26", "summary": "In this paper, we study the dominating set problem in \\emph{RDV graphs}, a graph class that lies between interval graphs and chordal graphs and is defined as the \\textbf{v}ertex-intersection graphs of \\textbf{d}ownward paths in a \\textbf{r}ooted tree. It was shown in a previous paper that adjacency queries in an RDV graph can be reduced to the question whether a horizontal segment intersects a vertical segment. This was then used to find a maximum matching in an $n$-vertex RDV graph, using priority search trees, in $O(n\\log n)$ time, i.e., without even looking at all edges. In this paper, we show that if additionally we also use a ray shooting data structure, we can also find a minimum dominating set in an RDV graph $O(n\\log n)$ time (presuming a linear-sized representation of the graph is given). The same idea can also be used for a new proof to find a minimum dominating set in an interval graph in $O(n)$ time.", "AI": {"tldr": "\u5728RDV\u56fe\u4e2d\uff0c\u901a\u8fc7\u7ed3\u5408\u6c34\u5e73-\u5782\u76f4\u7ebf\u6bb5\u76f8\u4ea4\u67e5\u8be2\u548c\u5c04\u7ebf\u5c04\u51fb\u6570\u636e\u7ed3\u6784\uff0c\u53ef\u4ee5\u5728O(n log n)\u65f6\u95f4\u5185\u627e\u5230\u6700\u5c0f\u652f\u914d\u96c6\u3002", "motivation": "RDV\u56fe\u662f\u4ecb\u4e8e\u533a\u95f4\u56fe\u548c\u5f26\u56fe\u4e4b\u95f4\u7684\u56fe\u7c7b\uff0c\u4e4b\u524d\u7684\u7814\u7a76\u5df2\u7ecf\u5c55\u793a\u4e86\u5982\u4f55\u5728O(n log n)\u65f6\u95f4\u5185\u627e\u5230\u6700\u5927\u5339\u914d\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u662f\u5426\u80fd\u5728\u7c7b\u4f3c\u65f6\u95f4\u590d\u6742\u5ea6\u5185\u89e3\u51b3\u66f4\u590d\u6742\u7684\u652f\u914d\u96c6\u95ee\u9898\u3002", "method": "\u5229\u7528RDV\u56fe\u7684\u7279\u6b8a\u7ed3\u6784\uff1a\u9876\u70b9\u53ef\u8868\u793a\u4e3a\u6709\u6839\u6811\u4e2d\u5411\u4e0b\u8def\u5f84\u7684\u4ea4\u96c6\u56fe\u3002\u7ed3\u5408\u4e24\u79cd\u6570\u636e\u7ed3\u6784\uff1a1) \u6c34\u5e73-\u5782\u76f4\u7ebf\u6bb5\u76f8\u4ea4\u67e5\u8be2\uff08\u7528\u4e8e\u90bb\u63a5\u5173\u7cfb\uff09\uff0c2) \u5c04\u7ebf\u5c04\u51fb\u6570\u636e\u7ed3\u6784\u3002\u901a\u8fc7\u8fd9\u79cd\u7ec4\u5408\u65b9\u6cd5\u9ad8\u6548\u5904\u7406\u652f\u914d\u96c6\u95ee\u9898\u3002", "result": "\u6210\u529f\u5728O(n log n)\u65f6\u95f4\u5185\u627e\u5230RDV\u56fe\u7684\u6700\u5c0f\u652f\u914d\u96c6\uff08\u5047\u8bbe\u7ed9\u5b9a\u56fe\u7684\u7ebf\u6027\u5927\u5c0f\u8868\u793a\uff09\u3002\u8be5\u65b9\u6cd5\u8fd8\u53ef\u4e3a\u533a\u95f4\u56fe\u7684\u6700\u5c0f\u652f\u914d\u96c6\u95ee\u9898\u63d0\u4f9b\u65b0\u7684O(n)\u65f6\u95f4\u8bc1\u660e\u3002", "conclusion": "\u901a\u8fc7\u5de7\u5999\u7ed3\u5408\u7ebf\u6bb5\u76f8\u4ea4\u67e5\u8be2\u548c\u5c04\u7ebf\u5c04\u51fb\u6570\u636e\u7ed3\u6784\uff0c\u53ef\u4ee5\u5728\u63a5\u8fd1\u7ebf\u6027\u7684\u65f6\u95f4\u5185\u89e3\u51b3RDV\u56fe\u7684\u6700\u5c0f\u652f\u914d\u96c6\u95ee\u9898\uff0c\u6269\u5c55\u4e86\u4e4b\u524d\u4ec5\u7528\u4e8e\u6700\u5927\u5339\u914d\u7684\u6280\u672f\uff0c\u5e76\u4e3a\u533a\u95f4\u56fe\u63d0\u4f9b\u4e86\u65b0\u7684\u7b97\u6cd5\u89c6\u89d2\u3002"}}
{"id": "2601.04395", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.04395", "abs": "https://arxiv.org/abs/2601.04395", "authors": ["Tomer Wullach", "Ori Shapira", "Amir DN Cohen"], "title": "The Overlooked Role of Graded Relevance Thresholds in Multilingual Dense Retrieval", "comment": null, "summary": "Dense retrieval models are typically fine-tuned with contrastive learning objectives that require binary relevance judgments, even though relevance is inherently graded. We analyze how graded relevance scores and the threshold used to convert them into binary labels affect multilingual dense retrieval. Using a multilingual dataset with LLM-annotated relevance scores, we examine monolingual, multilingual mixture, and cross-lingual retrieval scenarios. Our findings show that the optimal threshold varies systematically across languages and tasks, often reflecting differences in resource level. A well-chosen threshold can improve effectiveness, reduce the amount of fine-tuning data required, and mitigate annotation noise, whereas a poorly chosen one can degrade performance. We argue that graded relevance is a valuable but underutilized signal for dense retrieval, and that threshold calibration should be treated as a principled component of the fine-tuning pipeline.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u591a\u8bed\u8a00\u5bc6\u96c6\u68c0\u7d22\u4e2d\uff0c\u5982\u4f55\u5229\u7528\u5206\u7ea7\u76f8\u5173\u6027\u5206\u6570\u53ca\u5176\u4e8c\u503c\u5316\u9608\u503c\u6765\u4f18\u5316\u6a21\u578b\u6027\u80fd\uff0c\u53d1\u73b0\u6700\u4f18\u9608\u503c\u56e0\u8bed\u8a00\u548c\u4efb\u52a1\u800c\u5f02\uff0c\u5408\u7406\u9009\u62e9\u9608\u503c\u53ef\u63d0\u5347\u6548\u679c\u3001\u51cf\u5c11\u8bad\u7ec3\u6570\u636e\u9700\u6c42\u5e76\u7f13\u89e3\u6807\u6ce8\u566a\u58f0\u3002", "motivation": "\u5bc6\u96c6\u68c0\u7d22\u6a21\u578b\u901a\u5e38\u4f7f\u7528\u9700\u8981\u4e8c\u503c\u76f8\u5173\u6027\u5224\u65ad\u7684\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\u8fdb\u884c\u5fae\u8c03\uff0c\u4f46\u76f8\u5173\u6027\u672c\u8d28\u4e0a\u662f\u5206\u7ea7\u7684\u3002\u76ee\u524d\u5206\u7ea7\u76f8\u5173\u6027\u4fe1\u53f7\u5728\u5bc6\u96c6\u68c0\u7d22\u4e2d\u672a\u88ab\u5145\u5206\u5229\u7528\uff0c\u4e14\u4e8c\u503c\u5316\u9608\u503c\u7684\u9009\u62e9\u5bf9\u591a\u8bed\u8a00\u68c0\u7d22\u6027\u80fd\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u4f7f\u7528\u5e26\u6709LLM\u6807\u6ce8\u7684\u5206\u7ea7\u76f8\u5173\u6027\u5206\u6570\u7684\u591a\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u5206\u6790\u5206\u7ea7\u76f8\u5173\u6027\u5206\u6570\u53ca\u5176\u4e8c\u503c\u5316\u9608\u503c\u5bf9\u5355\u8bed\u8a00\u3001\u591a\u8bed\u8a00\u6df7\u5408\u548c\u8de8\u8bed\u8a00\u68c0\u7d22\u573a\u666f\u7684\u5f71\u54cd\uff0c\u7cfb\u7edf\u7814\u7a76\u4e0d\u540c\u9608\u503c\u9009\u62e9\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6700\u4f18\u9608\u503c\u5728\u4e0d\u540c\u8bed\u8a00\u548c\u4efb\u52a1\u4e2d\u7cfb\u7edf\u6027\u53d8\u5316\uff0c\u901a\u5e38\u53cd\u6620\u8d44\u6e90\u6c34\u5e73\u7684\u5dee\u5f02\u3002\u5408\u7406\u9009\u62e9\u7684\u9608\u503c\u53ef\u4ee5\u63d0\u5347\u68c0\u7d22\u6548\u679c\u3001\u51cf\u5c11\u5fae\u8c03\u6240\u9700\u6570\u636e\u91cf\u5e76\u7f13\u89e3\u6807\u6ce8\u566a\u58f0\uff0c\u800c\u4e0d\u5f53\u9608\u503c\u5219\u4f1a\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "\u5206\u7ea7\u76f8\u5173\u6027\u662f\u5bc6\u96c6\u68c0\u7d22\u4e2d\u5b9d\u8d35\u4f46\u672a\u88ab\u5145\u5206\u5229\u7528\u7684\u4fe1\u53f7\uff0c\u9608\u503c\u6821\u51c6\u5e94\u88ab\u89c6\u4e3a\u5fae\u8c03\u6d41\u7a0b\u4e2d\u4e00\u4e2a\u539f\u5219\u6027\u7684\u7ec4\u6210\u90e8\u5206\uff0c\u9700\u8981\u9488\u5bf9\u4e0d\u540c\u8bed\u8a00\u548c\u4efb\u52a1\u8fdb\u884c\u7cfb\u7edf\u4f18\u5316\u3002"}}
{"id": "2601.04849", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.04849", "abs": "https://arxiv.org/abs/2601.04849", "authors": ["Yijun Zhong", "Yi Shen"], "title": "Stability of Constrained Optimization Models for Structured Signal Recovery", "comment": "29 pages", "summary": "Recovering an unknown but structured signal from its measurements is a challenging problem with significant applications in fields such as imaging restoration, wireless communications, and signal processing. In this paper, we consider the inherent problem stems from the prior knowledge about the signal's structure, such as sparsity which is critical for signal recovery models. We investigate three constrained optimization models that effectively address this challenge, each leveraging distinct forms of structural priors to regularize the solution space. Our theoretical analysis demonstrates that these models exhibit robustness to noise while maintaining stability with respect to tuning parameters that is a crucial property for practical applications, when the parameter selection is often nontrivial. By providing theoretical foundations, our work supports their practical use in scenarios where measurement imperfections and model uncertainties are unavoidable. Furthermore, under mild conditions, we establish tradeoff between the sample complexity and the mismatch error.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5229\u7528\u4fe1\u53f7\u7ed3\u6784\u5148\u9a8c\u77e5\u8bc6\uff08\u5982\u7a00\u758f\u6027\uff09\u8fdb\u884c\u4fe1\u53f7\u6062\u590d\u7684\u7ea6\u675f\u4f18\u5316\u6a21\u578b\uff0c\u5206\u6790\u4e86\u6a21\u578b\u5bf9\u566a\u58f0\u7684\u9c81\u68d2\u6027\u548c\u53c2\u6570\u7a33\u5b9a\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u6837\u672c\u590d\u6742\u5ea6\u4e0e\u5931\u914d\u8bef\u5dee\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "motivation": "\u4ece\u6d4b\u91cf\u4e2d\u6062\u590d\u672a\u77e5\u4f46\u7ed3\u6784\u5316\u7684\u4fe1\u53f7\u662f\u6210\u50cf\u6062\u590d\u3001\u65e0\u7ebf\u901a\u4fe1\u548c\u4fe1\u53f7\u5904\u7406\u7b49\u9886\u57df\u7684\u91cd\u8981\u6311\u6218\u6027\u95ee\u9898\u3002\u4fe1\u53f7\u7ed3\u6784\u5148\u9a8c\u77e5\u8bc6\uff08\u5982\u7a00\u758f\u6027\uff09\u5bf9\u4e8e\u4fe1\u53f7\u6062\u590d\u6a21\u578b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u53c2\u6570\u9009\u62e9\u5f80\u5f80\u56f0\u96be\uff0c\u9700\u8981\u7406\u8bba\u5206\u6790\u652f\u6301\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u7ea6\u675f\u4f18\u5316\u6a21\u578b\uff0c\u6bcf\u79cd\u6a21\u578b\u5229\u7528\u4e0d\u540c\u5f62\u5f0f\u7684\u7ed3\u6784\u5148\u9a8c\u6765\u6b63\u5219\u5316\u89e3\u7a7a\u95f4\u3002\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\uff0c\u8bc1\u660e\u8fd9\u4e9b\u6a21\u578b\u5bf9\u566a\u58f0\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u5bf9\u8c03\u8c10\u53c2\u6570\u4fdd\u6301\u7a33\u5b9a\u6027\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u6d4b\u91cf\u4e0d\u5b8c\u7f8e\u548c\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4e0d\u53ef\u907f\u514d\u7684\u573a\u666f\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\uff0c\u5efa\u7acb\u4e86\u6837\u672c\u590d\u6742\u5ea6\u4e0e\u5931\u914d\u8bef\u5dee\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\uff0c\u8be5\u5de5\u4f5c\u652f\u6301\u8fd9\u4e9b\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\uff0c\u7279\u522b\u662f\u5728\u6d4b\u91cf\u4e0d\u5b8c\u7f8e\u548c\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4e0d\u53ef\u907f\u514d\u7684\u573a\u666f\u4e2d\u3002\u5efa\u7acb\u7684\u6743\u8861\u5173\u7cfb\u4e3a\u5b9e\u9645\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2601.04757", "categories": ["cs.DB", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.04757", "abs": "https://arxiv.org/abs/2601.04757", "authors": ["Cristian Riveros", "Benjamin Scheidt", "Nicole Schweikardt"], "title": "Structural Indexing of Relational Databases for the Evaluation of Free-Connex Acyclic Conjunctive Queries", "comment": "This paper supersedes the preprint arXiv:2405.12358 by the same authors that only considered the special case of binary schemas", "summary": "We present an index structure to boost the evaluation of free-connex acyclic conjunctive queries (fc-ACQs) over relational databases. The main ingredient of the index associated with a given database $D$ is an auxiliary database $D_{col}$. Our main result states that for any fc-ACQ $Q$ over $D$, we can count the number of answers of $Q$ or enumerate them with constant delay after a preprocessing phase that takes time linear in the size of $D_{col}$.\n  Unlike previous indexing methods based on values or order (e.g., B+ trees), our index is based on structural symmetries among tuples in a database, and the size of $D_{col}$ is related to the number of colors assigned to $D$ by Scheidt and Schweikardt's \"relational color refinement\" (2025). In the particular case of graphs, this coincides with the minimal size of an equitable partition of the graph. For example, the size of $D_{col}$ is logarithmic in the case of binary trees and constant for regular graphs. Even in the worst-case that $D$ has no structural symmetries among tuples at all, the size of $D_{col}$ is still linear in the size of $D$.\n  Given that the size of $D_{col}$ is bounded by the size of $D$ and can be much smaller (even constant for some families of databases), our index is the first foundational result on indexing internal structural symmetries of a database to evaluate all fc-ACQs with performance potentially strictly smaller than the database size.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7ed3\u6784\u5bf9\u79f0\u6027\u7684\u7d22\u5f15\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u8bc4\u4f30\u81ea\u7531\u8fde\u63a5\u65e0\u73af\u8fde\u63a5\u67e5\u8be2\uff0c\u9884\u5904\u7406\u65f6\u95f4\u4e0e\u8f85\u52a9\u6570\u636e\u5e93\u5927\u5c0f\u7ebf\u6027\u76f8\u5173\uff0c\u540e\u8005\u901a\u5e38\u8fdc\u5c0f\u4e8e\u539f\u6570\u636e\u5e93\u3002", "motivation": "\u73b0\u6709\u7d22\u5f15\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u503c\u6216\u987a\u5e8f\uff08\u5982B+\u6811\uff09\uff0c\u65e0\u6cd5\u6709\u6548\u5229\u7528\u6570\u636e\u5e93\u5185\u90e8\u7684\u7ed3\u6784\u5bf9\u79f0\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5229\u7528\u7ed3\u6784\u5bf9\u79f0\u6027\u6765\u63d0\u5347\u81ea\u7531\u8fde\u63a5\u65e0\u73af\u8fde\u63a5\u67e5\u8be2\u8bc4\u4f30\u6548\u7387\u7684\u7d22\u5f15\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u7ed3\u6784\u5bf9\u79f0\u6027\u7684\u7d22\u5f15\u7ed3\u6784\uff0c\u6838\u5fc3\u662f\u6784\u5efa\u8f85\u52a9\u6570\u636e\u5e93D_col\uff0c\u5176\u5927\u5c0f\u4e0eScheidt\u548cSchweikardt\u7684\"\u5173\u7cfb\u989c\u8272\u7ec6\u5316\"\u7b97\u6cd5\u5206\u914d\u7684\u989c\u8272\u6570\u91cf\u76f8\u5173\u3002\u5728\u56fe\u4e2d\uff0c\u8fd9\u5bf9\u5e94\u4e8e\u56fe\u7684\u6700\u5c0f\u516c\u5e73\u5212\u5206\u5927\u5c0f\u3002", "result": "\u5bf9\u4e8e\u4efb\u4f55\u81ea\u7531\u8fde\u63a5\u65e0\u73af\u8fde\u63a5\u67e5\u8be2\uff0c\u53ef\u4ee5\u5728\u4e0eD_col\u5927\u5c0f\u7ebf\u6027\u7684\u9884\u5904\u7406\u65f6\u95f4\u540e\uff0c\u4ee5\u5e38\u6570\u5ef6\u8fdf\u8ba1\u6570\u6216\u679a\u4e3e\u67e5\u8be2\u7ed3\u679c\u3002D_col\u5927\u5c0f\u901a\u5e38\u8fdc\u5c0f\u4e8e\u539f\u6570\u636e\u5e93\uff0c\u5982\u4e8c\u53c9\u6811\u4e2d\u5bf9\u6570\u5927\u5c0f\uff0c\u6b63\u5219\u56fe\u4e2d\u5e38\u6570\u5927\u5c0f\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u57fa\u4e8e\u6570\u636e\u5e93\u5185\u90e8\u7ed3\u6784\u5bf9\u79f0\u6027\u7684\u7d22\u5f15\u57fa\u7840\u7ed3\u679c\uff0c\u80fd\u591f\u4ee5\u53ef\u80fd\u4e25\u683c\u5c0f\u4e8e\u6570\u636e\u5e93\u5927\u5c0f\u7684\u6027\u80fd\u8bc4\u4f30\u6240\u6709\u81ea\u7531\u8fde\u63a5\u65e0\u73af\u8fde\u63a5\u67e5\u8be2\uff0c\u4e3a\u9ad8\u6548\u67e5\u8be2\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.04756", "categories": ["cs.DS", "cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2601.04756", "abs": "https://arxiv.org/abs/2601.04756", "authors": ["Tuukka Korhonen", "Sang-il Oum"], "title": "Branch-width of connectivity functions is fixed-parameter tractable", "comment": "13 pages", "summary": "A connectivity function on a finite set $V$ is a symmetric submodular function $f \\colon 2^V \\to \\mathbb{Z}$ with $f(\\emptyset)=0$. We prove that finding a branch-decomposition of width at most $k$ for a connectivity function given by an oracle is fixed-parameter tractable (FPT), by providing an algorithm of running time $2^{O(k^2)} \u03b3n^6 \\log n$, where $\u03b3$ is the time to compute $f(X)$ for any set $X$, and $n = |V|$. This improves the previous algorithm by Oum and Seymour [J. Combin. Theory Ser.~B, 2007], which runs in time $\u03b3n^{O(k)}$. Our algorithm can be applied to rank-width of graphs, branch-width of matroids, branch-width of (hyper)graphs, and carving-width of graphs. This resolves an open problem asked by Hlin\u011bn\u00fd [SIAM J. Comput., 2005], who asked whether branch-width of matroids given by the rank oracle is fixed-parameter tractable. Furthermore, our algorithm improves the best known dependency on $k$ in the running times of FPT algorithms for graph branch-width, rank-width, and carving-width.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u56fa\u5b9a\u53c2\u6570\u53ef\u5904\u7406\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u7ed9\u5b9a\u9884\u8a00\u673a\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3a\u8fde\u901a\u51fd\u6570\u627e\u5230\u5bbd\u5ea6\u81f3\u591a\u4e3ak\u7684\u5206\u652f\u5206\u89e3\uff0c\u8fd0\u884c\u65f6\u95f4\u4e3a2^{O(k^2)}\u03b3n^6 log n\uff0c\u6539\u8fdb\u4e86\u4e4b\u524dOum\u548cSeymour\u7684\u03b3n^{O(k)}\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3Hlin\u011bn\u00fd\u63d0\u51fa\u7684\u5f00\u653e\u95ee\u9898\uff1a\u5bf9\u4e8e\u7531\u79e9\u9884\u8a00\u673a\u7ed9\u51fa\u7684\u62df\u9635\u5206\u652f\u5bbd\u5ea6\uff0c\u662f\u5426\u5177\u6709\u56fa\u5b9a\u53c2\u6570\u53ef\u5904\u7406\u6027\u3002\u540c\u65f6\u6539\u8fdb\u56fe\u5206\u652f\u5bbd\u5ea6\u3001\u79e9\u5bbd\u5ea6\u548c\u96d5\u523b\u5bbd\u5ea6\u7b49FPT\u7b97\u6cd5\u4e2d\u5bf9\u53c2\u6570k\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65b0\u7684\u56fa\u5b9a\u53c2\u6570\u53ef\u5904\u7406\u7b97\u6cd5\uff0c\u901a\u8fc7\u8fde\u901a\u51fd\u6570\u9884\u8a00\u673a\u8ba1\u7b97f(X)\uff0c\u7b97\u6cd5\u6838\u5fc3\u601d\u60f3\u662f\u5229\u7528\u5206\u652f\u5206\u89e3\u7684\u7ed3\u6784\u7279\u6027\uff0c\u901a\u8fc7\u7cfb\u7edf\u641c\u7d22\u548c\u4f18\u5316\u6280\u672f\u6765\u627e\u5230\u5bbd\u5ea6\u4e0d\u8d85\u8fc7k\u7684\u5206\u652f\u5206\u89e3\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u5728\u7ed9\u5b9a\u9884\u8a00\u673a\u7684\u60c5\u51b5\u4e0b\uff0c\u5bfb\u627e\u5bbd\u5ea6\u81f3\u591a\u4e3ak\u7684\u5206\u652f\u5206\u89e3\u662f\u56fa\u5b9a\u53c2\u6570\u53ef\u5904\u7406\u7684\uff0c\u8fd0\u884c\u65f6\u95f4\u4e3a2^{O(k^2)}\u03b3n^6 log n\uff0c\u663e\u8457\u6539\u8fdb\u4e86\u5148\u524d\u7ed3\u679c\uff0c\u5e76\u89e3\u51b3\u4e86\u76f8\u5173\u5f00\u653e\u95ee\u9898\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u4e0d\u4ec5\u89e3\u51b3\u4e86\u62df\u9635\u5206\u652f\u5bbd\u5ea6\u7684\u56fa\u5b9a\u53c2\u6570\u53ef\u5904\u7406\u6027\u95ee\u9898\uff0c\u8fd8\u7edf\u4e00\u6539\u8fdb\u4e86\u56fe\u5206\u652f\u5bbd\u5ea6\u3001\u79e9\u5bbd\u5ea6\u548c\u96d5\u523b\u5bbd\u5ea6\u7684FPT\u7b97\u6cd5\uff0c\u5728\u53c2\u6570k\u7684\u4f9d\u8d56\u5173\u7cfb\u4e0a\u53d6\u5f97\u4e86\u6307\u6570\u7ea7\u6539\u8fdb\u3002"}}
{"id": "2601.04455", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04455", "abs": "https://arxiv.org/abs/2601.04455", "authors": ["Chuan Meng", "Jiqun Liu", "Mohammad Aliannejadi", "Fengran Mo", "Jeff Dalton", "Maarten de Rijke"], "title": "Re-Rankers as Relevance Judges", "comment": null, "summary": "Using large language models (LLMs) to predict relevance judgments has shown promising results. Most studies treat this task as a distinct research line, e.g., focusing on prompt design for predicting relevance labels given a query and passage. However, predicting relevance judgments is essentially a form of relevance prediction, a problem extensively studied in tasks such as re-ranking. Despite this potential overlap, little research has explored reusing or adapting established re-ranking methods to predict relevance judgments, leading to potential resource waste and redundant development. To bridge this gap, we reproduce re-rankers in a re-ranker-as-relevance-judge setup. We design two adaptation strategies: (i) using binary tokens (e.g., \"true\" and \"false\") generated by a re-ranker as direct judgments, and (ii) converting continuous re-ranking scores into binary labels via thresholding. We perform extensive experiments on TREC-DL 2019 to 2023 with 8 re-rankers from 3 families, ranging from 220M to 32B, and analyse the evaluation bias exhibited by re-ranker-based judges. Results show that re-ranker-based relevance judges, under both strategies, can outperform UMBRELA, a state-of-the-art LLM-based relevance judge, in around 40% to 50% of the cases; they also exhibit strong self-preference towards their own and same-family re-rankers, as well as cross-family bias.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u5c06\u91cd\u6392\u5e8f\u5668\u7528\u4f5c\u76f8\u5173\u6027\u5224\u65ad\u5de5\u5177\uff0c\u53d1\u73b0\u91cd\u6392\u5e8f\u5668\u572840-50%\u60c5\u51b5\u4e0b\u80fd\u8d85\u8d8a\u73b0\u6709LLM\u76f8\u5173\u6027\u5224\u65ad\u65b9\u6cd5\uff0c\u4f46\u5b58\u5728\u81ea\u504f\u597d\u548c\u8de8\u5bb6\u65cf\u504f\u89c1\u3002", "motivation": "\u76ee\u524d\u4f7f\u7528LLM\u9884\u6d4b\u76f8\u5173\u6027\u5224\u65ad\u7684\u7814\u7a76\u5927\u591a\u5c06\u5176\u89c6\u4e3a\u72ec\u7acb\u4efb\u52a1\uff0c\u4e13\u6ce8\u4e8e\u63d0\u793a\u8bbe\u8ba1\u3002\u7136\u800c\uff0c\u9884\u6d4b\u76f8\u5173\u6027\u5224\u65ad\u672c\u8d28\u4e0a\u662f\u76f8\u5173\u6027\u9884\u6d4b\u95ee\u9898\uff0c\u8fd9\u5728\u91cd\u6392\u5e8f\u4efb\u52a1\u4e2d\u5df2\u6709\u6df1\u5165\u7814\u7a76\u3002\u73b0\u6709\u7814\u7a76\u5f88\u5c11\u63a2\u7d22\u91cd\u7528\u6216\u8c03\u6574\u6210\u719f\u7684\u91cd\u6392\u5e8f\u65b9\u6cd5\u6765\u9884\u6d4b\u76f8\u5173\u6027\u5224\u65ad\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d6a\u8d39\u548c\u91cd\u590d\u5f00\u53d1\u3002", "method": "\u5728\u91cd\u6392\u5e8f\u5668\u4f5c\u4e3a\u76f8\u5173\u6027\u5224\u65ad\u5668\u7684\u6846\u67b6\u4e0b\uff0c\u8bbe\u8ba1\u4e86\u4e24\u79cd\u9002\u5e94\u7b56\u7565\uff1a(1) \u4f7f\u7528\u91cd\u6392\u5e8f\u5668\u751f\u6210\u7684\u4e8c\u5143\u6807\u8bb0\uff08\u5982\"true\"\u548c\"false\"\uff09\u4f5c\u4e3a\u76f4\u63a5\u5224\u65ad\uff1b(2) \u901a\u8fc7\u9608\u503c\u5316\u5c06\u8fde\u7eed\u7684\u91cd\u6392\u5e8f\u5206\u6570\u8f6c\u6362\u4e3a\u4e8c\u5143\u6807\u7b7e\u3002\u5728TREC-DL 2019-2023\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u4f7f\u7528\u4e86\u6765\u81ea3\u4e2a\u5bb6\u65cf\u76848\u4e2a\u91cd\u6392\u5e8f\u5668\uff0c\u53c2\u6570\u91cf\u4ece220M\u523032B\u4e0d\u7b49\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8e\u91cd\u6392\u5e8f\u5668\u7684\u76f8\u5173\u6027\u5224\u65ad\u5668\u5728\u4e24\u79cd\u7b56\u7565\u4e0b\uff0c\u5728\u7ea640%\u523050%\u7684\u60c5\u51b5\u4e0b\u80fd\u591f\u8d85\u8d8aUMBRELA\uff08\u6700\u5148\u8fdb\u7684\u57fa\u4e8eLLM\u7684\u76f8\u5173\u6027\u5224\u65ad\u5668\uff09\u3002\u540c\u65f6\uff0c\u8fd9\u4e9b\u5224\u65ad\u5668\u8868\u73b0\u51fa\u5f3a\u70c8\u7684\u81ea\u504f\u597d\uff08\u504f\u5411\u81ea\u5df1\u548c\u540c\u5bb6\u65cf\u7684\u91cd\u6392\u5e8f\u5668\uff09\u4ee5\u53ca\u8de8\u5bb6\u65cf\u504f\u89c1\u3002", "conclusion": "\u91cd\u6392\u5e8f\u5668\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u76f8\u5173\u6027\u5224\u65ad\u5de5\u5177\uff0c\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u6027\u80fd\u4f18\u4e8e\u4e13\u95e8\u7684LLM\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u5176\u5b58\u5728\u7684\u81ea\u504f\u597d\u548c\u504f\u89c1\u95ee\u9898\u9700\u8981\u5728\u5e94\u7528\u4e2d\u52a0\u4ee5\u8003\u8651\u3002\u8fd9\u9879\u7814\u7a76\u4e3a\u76f8\u5173\u6027\u5224\u65ad\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u51cf\u5c11\u4e86\u8d44\u6e90\u6d6a\u8d39\u548c\u91cd\u590d\u5f00\u53d1\u3002"}}
{"id": "2601.04862", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.04862", "abs": "https://arxiv.org/abs/2601.04862", "authors": ["Ailing Zheng", "Qingqing Wu", "Ziyuan Zheng", "Qiaoyan Peng", "Yanze Zhu", "Honghao Wang", "Wen Chen", "Guoying Zhang"], "title": "Wireless Communication with Cross-Linked Rotatable Antenna Array: Architecture Design and Rotation Optimization", "comment": null, "summary": "Rotatable antenna (RA) technology can harness additional spatial degrees of freedom by enabling the dynamic three-dimensional orientation control of each antenna. Unfortunately, the hardware cost and control complexity of traditional RA systems is proportional to the number of RAs. To address the issue, we consider a cross-linked (CL) RA structure, which enables the coordinated rotation of multiple antennas, thereby offering a cost-effective solution. To evaluate the performance of the CL-RA array, we investigate a CL-RA-aided uplink system. Specifically, we first establish system models for both antenna element-level and antenna panel-level rotation. Then, we formulate a sum rate maximization problem by jointly optimizing the receive beamforming at the base station and the rotation angles. For the antenna element-level rotation, we derive the optimal solution of the CL-RA array under the single-user case. Subsequently, for two rotation schemes, we propose an alternating optimization algorithm to solve the formulated problem in the multi-user case, where the receive beamforming and the antenna rotation angles are obtained by applying the minimum mean square error method and feasible direction method, respectively. In addition, considering the hardware limitations, we apply the genetic algorithm to address the discrete rotation angles selection problem. Simulation results show that by carefully designing the row-column partition scheme, the performance of the CL-RA architecture is quite close to that of the flexible antenna orientation scheme. Moreover, the CL antenna element-level scheme surpasses the CL antenna panel-level scheme by 25% and delivers a 128% performance improvement over conventional fixed-direction antennas.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ea4\u53c9\u94fe\u63a5\u53ef\u65cb\u8f6c\u5929\u7ebf\u7ed3\u6784\uff0c\u901a\u8fc7\u534f\u8c03\u591a\u4e2a\u5929\u7ebf\u65cb\u8f6c\u964d\u4f4e\u6210\u672c\uff0c\u5728\u5355\u7528\u6237\u548c\u591a\u7528\u6237\u573a\u666f\u4e0b\u4f18\u5316\u63a5\u6536\u6ce2\u675f\u6210\u5f62\u548c\u65cb\u8f6c\u89d2\u5ea6\uff0c\u6027\u80fd\u63a5\u8fd1\u7075\u6d3b\u5929\u7ebf\u65b9\u5411\u65b9\u6848\u3002", "motivation": "\u4f20\u7edf\u53ef\u65cb\u8f6c\u5929\u7ebf\u7cfb\u7edf\u7684\u786c\u4ef6\u6210\u672c\u548c\u63a7\u5236\u590d\u6742\u5ea6\u4e0e\u5929\u7ebf\u6570\u91cf\u6210\u6b63\u6bd4\uff0c\u9700\u8981\u4e00\u79cd\u6210\u672c\u6548\u76ca\u66f4\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5229\u7528\u7a7a\u95f4\u81ea\u7531\u5ea6\u3002", "method": "\u91c7\u7528\u4ea4\u53c9\u94fe\u63a5\u53ef\u65cb\u8f6c\u5929\u7ebf\u7ed3\u6784\uff0c\u5efa\u7acb\u5929\u7ebf\u5355\u5143\u7ea7\u548c\u5929\u7ebf\u9762\u677f\u7ea7\u65cb\u8f6c\u7684\u7cfb\u7edf\u6a21\u578b\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u8054\u5408\u4f18\u5316\u57fa\u7ad9\u63a5\u6536\u6ce2\u675f\u6210\u5f62\u548c\u65cb\u8f6c\u89d2\u5ea6\uff0c\u4f7f\u7528\u6700\u5c0f\u5747\u65b9\u8bef\u5dee\u65b9\u6cd5\u548c\u53ef\u884c\u65b9\u5411\u6cd5\u6c42\u89e3\u3002", "result": "\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u884c\u5217\u5206\u533a\u65b9\u6848\uff0cCL-RA\u67b6\u6784\u6027\u80fd\u63a5\u8fd1\u7075\u6d3b\u5929\u7ebf\u65b9\u5411\u65b9\u6848\uff1bCL\u5929\u7ebf\u5355\u5143\u7ea7\u65b9\u6848\u6bd4\u9762\u677f\u7ea7\u65b9\u6848\u6027\u80fd\u63d0\u534725%\uff0c\u6bd4\u4f20\u7edf\u56fa\u5b9a\u65b9\u5411\u5929\u7ebf\u6027\u80fd\u63d0\u5347128%\u3002", "conclusion": "\u4ea4\u53c9\u94fe\u63a5\u53ef\u65cb\u8f6c\u5929\u7ebf\u7ed3\u6784\u63d0\u4f9b\u4e86\u4e00\u79cd\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5229\u7528\u7a7a\u95f4\u81ea\u7531\u5ea6\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u5728\u786c\u4ef6\u9650\u5236\u4e0b\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u5904\u7406\u79bb\u6563\u65cb\u8f6c\u89d2\u5ea6\u9009\u62e9\u95ee\u9898\u3002"}}
{"id": "2601.04820", "categories": ["cs.DB", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.04820", "abs": "https://arxiv.org/abs/2601.04820", "authors": ["Chotanansub Sophaken", "Thanadej Rattanakornphan", "Piyanon Charoenpoonpanich", "Thanapol Phungtua-eng", "Chainarong Amornbunchornvej"], "title": "LGTD: Local-Global Trend Decomposition for Season-Length-Free Time Series Analysis", "comment": "First draft", "summary": "Time series decomposition into trend, seasonal structure, and residual components is a core primitive for downstream analytics such as anomaly detection, change-point detection, and forecasting. However, most existing seasonal-trend decomposition methods rely on user-specified or estimated season lengths and implicitly assume stable periodic structure. These assumptions limit robustness and deployability in large, heterogeneous collections where recurring patterns may drift, appear intermittently, or exist at multiple time scales.\n  We propose LGTD (Local-Global Trend Decomposition), a season-length-free decomposition framework that represents a time series as the sum of a smooth global trend, adaptive local trends whose recurrence induces implicit (emergent) seasonal structure, and a residual component. Rather than explicitly modeling seasonality through a fixed or estimated period, LGTD treats seasonal structure as an emergent property arising from repeated local trend regimes. Concretely, LGTD first estimates a global trend capturing long-term evolution, then applies AutoTrend, an adaptive error-driven local linear trend inference module, to segment the detrended signal into short-lived piecewise-linear regimes. Residuals are obtained after removing both global and local trends.\n  By eliminating manual season-length specification, LGTD supports automated, low-touch deployment across time series with irregular, drifting, or weakly periodic structure. We analyze computational complexity and show that LGTD scales linearly with series length under mild conditions. Experiments on synthetic benchmarks demonstrate robust and balanced decomposition performance across fixed, transitive, and variable season-length settings, especially where period-based methods degrade.", "AI": {"tldr": "LGTD\u662f\u4e00\u79cd\u65e0\u9700\u6307\u5b9a\u5b63\u8282\u957f\u5ea6\u7684\u65f6\u5e8f\u5206\u89e3\u6846\u67b6\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u8868\u793a\u4e3a\u5168\u5c40\u8d8b\u52bf\u3001\u81ea\u9002\u5e94\u5c40\u90e8\u8d8b\u52bf\uff08\u5176\u91cd\u590d\u51fa\u73b0\u5f62\u6210\u9690\u542b\u7684\u5b63\u8282\u7ed3\u6784\uff09\u548c\u6b8b\u5dee\u9879\u7684\u548c\uff0c\u9002\u7528\u4e8e\u4e0d\u89c4\u5219\u3001\u6f02\u79fb\u6216\u5f31\u5468\u671f\u6027\u7ed3\u6784\u7684\u65f6\u95f4\u5e8f\u5217\u3002", "motivation": "\u73b0\u6709\u5b63\u8282-\u8d8b\u52bf\u5206\u89e3\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u7528\u6237\u6307\u5b9a\u6216\u4f30\u8ba1\u7684\u5b63\u8282\u957f\u5ea6\uff0c\u5e76\u9690\u542b\u5047\u8bbe\u7a33\u5b9a\u7684\u5468\u671f\u7ed3\u6784\uff0c\u8fd9\u9650\u5236\u4e86\u5728\u5927\u578b\u5f02\u6784\u96c6\u5408\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u53ef\u90e8\u7f72\u6027\uff0c\u56e0\u4e3a\u91cd\u590d\u6a21\u5f0f\u53ef\u80fd\u6f02\u79fb\u3001\u95f4\u6b47\u51fa\u73b0\u6216\u5b58\u5728\u4e8e\u591a\u4e2a\u65f6\u95f4\u5c3a\u5ea6\u3002", "method": "LGTD\u9996\u5148\u4f30\u8ba1\u6355\u83b7\u957f\u671f\u6f14\u5316\u7684\u5168\u5c40\u8d8b\u52bf\uff0c\u7136\u540e\u5e94\u7528AutoTrend\uff08\u81ea\u9002\u5e94\u8bef\u5dee\u9a71\u52a8\u7684\u5c40\u90e8\u7ebf\u6027\u8d8b\u52bf\u63a8\u65ad\u6a21\u5757\uff09\u5c06\u53bb\u8d8b\u52bf\u4fe1\u53f7\u5206\u5272\u4e3a\u77ed\u671f\u5206\u6bb5\u7ebf\u6027\u533a\u95f4\uff0c\u901a\u8fc7\u5c40\u90e8\u8d8b\u52bf\u7684\u91cd\u590d\u51fa\u73b0\u5f62\u6210\u9690\u542b\u7684\u5b63\u8282\u7ed3\u6784\uff0c\u6700\u540e\u83b7\u5f97\u53bb\u9664\u5168\u5c40\u548c\u5c40\u90e8\u8d8b\u52bf\u540e\u7684\u6b8b\u5dee\u3002", "result": "LGTD\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0a\u5728\u7ebf\u6027\u6761\u4ef6\u4e0b\u968f\u5e8f\u5217\u957f\u5ea6\u7ebf\u6027\u6269\u5c55\uff0c\u5728\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u56fa\u5b9a\u3001\u8fc7\u6e21\u548c\u53ef\u53d8\u5b63\u8282\u957f\u5ea6\u8bbe\u7f6e\u4e0b\u8868\u73b0\u51fa\u7a33\u5065\u4e14\u5e73\u8861\u7684\u5206\u89e3\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u57fa\u4e8e\u5468\u671f\u7684\u65b9\u6cd5\u6027\u80fd\u4e0b\u964d\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "\u901a\u8fc7\u6d88\u9664\u624b\u52a8\u6307\u5b9a\u5b63\u8282\u957f\u5ea6\u7684\u9700\u6c42\uff0cLGTD\u652f\u6301\u5728\u5177\u6709\u4e0d\u89c4\u5219\u3001\u6f02\u79fb\u6216\u5f31\u5468\u671f\u6027\u7ed3\u6784\u7684\u65f6\u95f4\u5e8f\u5217\u4e0a\u5b9e\u73b0\u81ea\u52a8\u5316\u3001\u4f4e\u63a5\u89e6\u90e8\u7f72\uff0c\u5c06\u5b63\u8282\u6027\u7ed3\u6784\u89c6\u4e3a\u5c40\u90e8\u8d8b\u52bf\u533a\u95f4\u91cd\u590d\u51fa\u73b0\u800c\u4ea7\u751f\u7684\u6d8c\u73b0\u5c5e\u6027\u3002"}}
{"id": "2601.05044", "categories": ["cs.DS", "cs.CC"], "pdf": "https://arxiv.org/pdf/2601.05044", "abs": "https://arxiv.org/abs/2601.05044", "authors": ["Jesper Nederlof"], "title": "An Invitation to \"Fine-grained Complexity of NP-Complete Problems\"", "comment": "40 pages. Invited survey (currently under review, remarks are welcome)", "summary": "Assuming that P is not equal to NP, the worst-case run time of any algorithm solving an NP-complete problem must be super-polynomial. But what is the fastest run time we can get? Before one can even hope to approach this question, a more provocative question presents itself: Since for many problems the naive brute-force baseline algorithms are still the fastest ones, maybe their run times are already optimal?\n  The area that we call in this survey \"fine-grained complexity of NP-complete problems\" studies exactly this question. We invite the reader to catch up on selected classic results as well as delve into exciting recent developments in a riveting tour through the area passing by (among others) algebra, complexity theory, extremal and additive combinatorics, cryptography, and, of course, last but not least, algorithm design.", "AI": {"tldr": "\u8be5\u8c03\u67e5\u8bba\u6587\u63a2\u8ba8NP\u5b8c\u5168\u95ee\u9898\u7684\u7ec6\u7c92\u5ea6\u590d\u6742\u5ea6\uff0c\u7814\u7a76\u662f\u5426\u5b58\u5728\u6bd4\u66b4\u529b\u641c\u7d22\u66f4\u5feb\u7684\u7b97\u6cd5\uff0c\u4ee5\u53ca\u66b4\u529b\u641c\u7d22\u662f\u5426\u5df2\u7ecf\u662f\u6700\u4f18\u89e3\u3002", "motivation": "\u867d\u7136\u5df2\u77e5P\u2260NP\u610f\u5473\u7740NP\u5b8c\u5168\u95ee\u9898\u7684\u6700\u574f\u60c5\u51b5\u8fd0\u884c\u65f6\u95f4\u5fc5\u987b\u662f\u8d85\u591a\u9879\u5f0f\u7684\uff0c\u4f46\u5177\u4f53\u80fd\u8fbe\u5230\u591a\u5feb\u7684\u8fd0\u884c\u65f6\u95f4\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002\u8bb8\u591a\u95ee\u9898\u7684\u6734\u7d20\u66b4\u529b\u641c\u7d22\u7b97\u6cd5\u4ecd\u7136\u662f\u76ee\u524d\u6700\u5feb\u7684\uff0c\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u6839\u672c\u6027\u95ee\u9898\uff1a\u8fd9\u4e9b\u66b4\u529b\u641c\u7d22\u7b97\u6cd5\u662f\u5426\u5df2\u7ecf\u662f\u6700\u4f18\u7684\uff1f", "method": "\u901a\u8fc7\u8c03\u67e5\u8bba\u6587\u7684\u5f62\u5f0f\uff0c\u7efc\u5408\u8fd0\u7528\u4ee3\u6570\u3001\u590d\u6742\u6027\u7406\u8bba\u3001\u6781\u503c\u4e0e\u52a0\u6cd5\u7ec4\u5408\u5b66\u3001\u5bc6\u7801\u5b66\u7b49\u591a\u5b66\u79d1\u65b9\u6cd5\uff0c\u5206\u6790NP\u5b8c\u5168\u95ee\u9898\u7684\u7ec6\u7c92\u5ea6\u590d\u6742\u5ea6\u3002\u7814\u7a76\u7ecf\u5178\u7ed3\u679c\u548c\u6700\u65b0\u8fdb\u5c55\uff0c\u63a2\u7d22\u7b97\u6cd5\u8bbe\u8ba1\u7684\u8fb9\u754c\u3002", "result": "\u8be5\u9886\u57df\u7684\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u4e8e\u8bb8\u591aNP\u5b8c\u5168\u95ee\u9898\uff0c\u66b4\u529b\u641c\u7d22\u7b97\u6cd5\u53ef\u80fd\u786e\u5b9e\u662f\u6700\u4f18\u7684\uff0c\u6216\u8005\u81f3\u5c11\u5b58\u5728\u6761\u4ef6\u6027\u4e0b\u754c\u8bc1\u660e\u652f\u6301\u8fd9\u4e00\u7ed3\u8bba\u3002\u7ec6\u7c92\u5ea6\u590d\u6742\u5ea6\u7406\u8bba\u4e3a\u7406\u89e3\u8ba1\u7b97\u95ee\u9898\u7684\u7cbe\u786e\u65f6\u95f4\u754c\u9650\u63d0\u4f9b\u4e86\u6846\u67b6\u3002", "conclusion": "\u7ec6\u7c92\u5ea6\u590d\u6742\u5ea6\u7814\u7a76\u63ed\u793a\u4e86NP\u5b8c\u5168\u95ee\u9898\u8ba1\u7b97\u590d\u6742\u6027\u7684\u6df1\u5c42\u7ed3\u6784\uff0c\u8868\u660e\u8bb8\u591a\u95ee\u9898\u7684\u6734\u7d20\u7b97\u6cd5\u53ef\u80fd\u5df2\u7ecf\u8fbe\u5230\u6700\u4f18\u3002\u8fd9\u4e00\u9886\u57df\u8fde\u63a5\u4e86\u591a\u4e2a\u6570\u5b66\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u5206\u652f\uff0c\u4e3a\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2601.04531", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04531", "abs": "https://arxiv.org/abs/2601.04531", "authors": ["Jessica Ryan", "Alexander I. Gumilang", "Robert Wiliam", "Derwin Suhartono"], "title": "Self-MedRAG: a Self-Reflective Hybrid Retrieval-Augmented Generation Framework for Reliable Medical Question Answering", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant potential in medical Question Answering (QA), yet they remain prone to hallucinations and ungrounded reasoning, limiting their reliability in high-stakes clinical scenarios. While Retrieval-Augmented Generation (RAG) mitigates these issues by incorporating external knowledge, conventional single-shot retrieval often fails to resolve complex biomedical queries requiring multi-step inference. To address this, we propose Self-MedRAG, a self-reflective hybrid framework designed to mimic the iterative hypothesis-verification process of clinical reasoning. Self-MedRAG integrates a hybrid retrieval strategy, combining sparse (BM25) and dense (Contriever) retrievers via Reciprocal Rank Fusion (RRF) to maximize evidence coverage. It employs a generator to produce answers with supporting rationales, which are then assessed by a lightweight self-reflection module using Natural Language Inference (NLI) or LLM-based verification. If the rationale lacks sufficient evidentiary support, the system autonomously reformulates the query and iterates to refine the context. We evaluated Self-MedRAG on the MedQA and PubMedQA benchmarks. The results demonstrate that our hybrid retrieval approach significantly outperforms single-retriever baselines. Furthermore, the inclusion of the self-reflective loop yielded substantial gains, increasing accuracy on MedQA from 80.00% to 83.33% and on PubMedQA from 69.10% to 79.82%. These findings confirm that integrating hybrid retrieval with iterative, evidence-based self-reflection effectively reduces unsupported claims and enhances the clinical reliability of LLM-based systems.", "AI": {"tldr": "Self-MedRAG\uff1a\u7ed3\u5408\u6df7\u5408\u68c0\u7d22\u4e0e\u81ea\u6211\u53cd\u601d\u7684\u4e34\u5e8a\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u5047\u8bbe\u9a8c\u8bc1\u51cf\u5c11\u5e7b\u89c9\uff0c\u5728\u533b\u5b66QA\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u95ee\u7b54\u4e2d\u5b58\u5728\u5e7b\u89c9\u548c\u7f3a\u4e4f\u4f9d\u636e\u7684\u63a8\u7406\u95ee\u9898\uff0c\u4f20\u7edf\u5355\u6b21\u68c0\u7d22\u65e0\u6cd5\u5904\u7406\u9700\u8981\u591a\u6b65\u63a8\u7406\u7684\u590d\u6742\u751f\u7269\u533b\u5b66\u67e5\u8be2\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u573a\u666f\u4e0b\u7684\u53ef\u9760\u6027", "method": "\u63d0\u51faSelf-MedRAG\u6846\u67b6\uff1a1\uff09\u6df7\u5408\u68c0\u7d22\u7b56\u7565\u7ed3\u5408\u7a00\u758f\u68c0\u7d22\uff08BM25\uff09\u548c\u5bc6\u96c6\u68c0\u7d22\uff08Contriever\uff09\uff0c\u901a\u8fc7RRF\u878d\u5408\uff1b2\uff09\u751f\u6210\u5668\u4ea7\u751f\u7b54\u6848\u548c\u63a8\u7406\u4f9d\u636e\uff1b3\uff09\u8f7b\u91cf\u7ea7\u81ea\u6211\u53cd\u601d\u6a21\u5757\u4f7f\u7528NLI\u6216LLM\u9a8c\u8bc1\uff1b4\uff09\u82e5\u4f9d\u636e\u4e0d\u8db3\u5219\u81ea\u4e3b\u91cd\u5199\u67e5\u8be2\u5e76\u8fed\u4ee3\u4f18\u5316", "result": "\u5728MedQA\u548cPubMedQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6df7\u5408\u68c0\u7d22\u663e\u8457\u4f18\u4e8e\u5355\u68c0\u7d22\u5668\u57fa\u7ebf\u3002\u81ea\u6211\u53cd\u601d\u5faa\u73af\u5e26\u6765\u663e\u8457\u63d0\u5347\uff1aMedQA\u51c6\u786e\u7387\u4ece80.00%\u63d0\u5347\u81f383.33%\uff0cPubMedQA\u4ece69.10%\u63d0\u5347\u81f379.82%", "conclusion": "\u6df7\u5408\u68c0\u7d22\u4e0e\u57fa\u4e8e\u8bc1\u636e\u7684\u8fed\u4ee3\u81ea\u6211\u53cd\u601d\u76f8\u7ed3\u5408\uff0c\u80fd\u6709\u6548\u51cf\u5c11\u65e0\u4f9d\u636e\u7684\u65ad\u8a00\uff0c\u589e\u5f3a\u57fa\u4e8eLLM\u7cfb\u7edf\u7684\u4e34\u5e8a\u53ef\u9760\u6027\uff0c\u4e3a\u9ad8\u98ce\u9669\u7684\u4e34\u5e8a\u573a\u666f\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.04980", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04980", "abs": "https://arxiv.org/abs/2601.04980", "authors": ["Sueda Taner", "Christoph Studer"], "title": "Learning Sparsifying Transforms for mmWave Communication via $\\ell^4$-Norm Maximization", "comment": "Submitted to a journal", "summary": "The high directionality of wave propagation at millimeter-wave (mmWave) carrier frequencies results in only a small number of significant transmission paths between user equipments and the basestation (BS). This sparse nature of wave propagation is revealed in the beamspace domain, which is traditionally obtained by taking the spatial discrete Fourier transform (DFT) across a uniform linear antenna array at the BS, where each DFT output is associated with a distinct beam. In recent years, beamspace processing has emerged as a promising technique to reduce baseband complexity and power consumption in all-digital massive multiuser (MU) multiple-input multiple-output (MIMO) systems operating at mmWave frequencies. However, it remains unclear whether the DFT is the optimal sparsifying transform for finite-dimensional antenna arrays. In this paper, we extend the framework of Zhai et al. for complete dictionary learning via $\\ell^4$-norm maximization to the complex case in order to learn new sparsifying transforms. We provide a theoretical foundation for $\\ell^4$-norm maximization and propose two suitable learning algorithms. We then utilize these algorithms (i) to assess the optimality of the DFT for sparsifying channel vectors theoretically and via simulations and (ii) to learn improved sparsifying transforms for real-world and synthetically generated channel vectors.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u2113\u2074\u8303\u6570\u6700\u5927\u5316\u5b66\u4e60\u590d\u6570\u57df\u7a00\u758f\u53d8\u6362\uff0c\u8bc4\u4f30DFT\u5728\u6beb\u7c73\u6ce2\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u7684\u6700\u4f18\u6027\uff0c\u5e76\u5b66\u4e60\u6539\u8fdb\u7684\u7a00\u758f\u53d8\u6362\u3002", "motivation": "\u6beb\u7c73\u6ce2\u9891\u6bb5\u6ce2\u4f20\u64ad\u7684\u9ad8\u65b9\u5411\u6027\u5bfc\u81f4\u7528\u6237\u8bbe\u5907\u4e0e\u57fa\u7ad9\u4e4b\u95f4\u53ea\u6709\u5c11\u91cf\u663e\u8457\u4f20\u8f93\u8def\u5f84\uff0c\u8fd9\u79cd\u7a00\u758f\u7279\u6027\u5728\u6ce2\u675f\u7a7a\u95f4\u57df\u4e2d\u4f53\u73b0\u3002\u4f20\u7edf\u4e0a\u4f7f\u7528DFT\u4f5c\u4e3a\u7a00\u758f\u53d8\u6362\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695aDFT\u662f\u5426\u662f\u6709\u9650\u7ef4\u5929\u7ebf\u9635\u5217\u7684\u6700\u4f18\u7a00\u758f\u53d8\u6362\u3002", "method": "\u5c06Zhai\u7b49\u4eba\u7684\u2113\u2074\u8303\u6570\u6700\u5927\u5316\u5b8c\u5168\u5b57\u5178\u5b66\u4e60\u6846\u67b6\u6269\u5c55\u5230\u590d\u6570\u57df\uff0c\u63d0\u51fa\u4e24\u79cd\u5b66\u4e60\u7b97\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30DFT\u7684\u6700\u4f18\u6027\u5e76\u5b66\u4e60\u6539\u8fdb\u7684\u7a00\u758f\u53d8\u6362\u3002", "result": "\u5efa\u7acb\u4e86\u2113\u2074\u8303\u6570\u6700\u5927\u5316\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5f00\u53d1\u4e86\u4e24\u79cd\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u548c\u4eff\u771f\u8bc4\u4f30DFT\u7684\u6700\u4f18\u6027\uff0c\u5e76\u4e3a\u5b9e\u9645\u548c\u5408\u6210\u4fe1\u9053\u5411\u91cf\u5b66\u4e60\u5230\u6539\u8fdb\u7684\u7a00\u758f\u53d8\u6362\u3002", "conclusion": "DFT\u53ef\u80fd\u4e0d\u662f\u6beb\u7c73\u6ce2\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u6700\u4f18\u7684\u7a00\u758f\u53d8\u6362\uff0c\u901a\u8fc7\u2113\u2074\u8303\u6570\u6700\u5927\u5316\u5b66\u4e60\u7684\u590d\u6570\u57df\u7a00\u758f\u53d8\u6362\u80fd\u591f\u63d0\u4f9b\u66f4\u597d\u7684\u7a00\u758f\u8868\u793a\u6027\u80fd\u3002"}}
{"id": "2601.04868", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.04868", "abs": "https://arxiv.org/abs/2601.04868", "authors": ["Meghyn Bienvenu", "Diego Figueira", "Pierre Lafourcade"], "title": "Responsibility Measures for Conjunctive Queries with Negation", "comment": "Full version of ICDT'26 paper", "summary": "We contribute to the recent line of work on responsibility measures that quantify the contributions of database facts to obtaining a query result. In contrast to existing work which has almost exclusively focused on monotone queries, here we explore how to define responsibility measures for unions of conjunctive queries with negated atoms (UCQ${}^\\lnot$). Starting from the question of what constitutes a reasonable notion of explanation or relevance for queries with negated atoms, we propose two approaches, one assigning scores to (positive) database facts and the other also considering negated facts. Our approaches, which are orthogonal to the previously studied score of Reshef et al., can be used to lift previously studied scores for monotone queries, known as drastic Shapley and weighted sums of minimal supports (WSMS), to UCQ$^\\lnot$. We investigate the data and combined complexity of the resulting measures, notably showing that the WSMS measures are tractable in data complexity for all UCQ${}^\\lnot$ queries and further establishing tractability in combined complexity for suitable classes of conjunctive queries with negation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u6570\u636e\u5e93\u67e5\u8be2\u4e2d\u4e8b\u5b9e\u5bf9\u67e5\u8be2\u7ed3\u679c\u8d21\u732e\u7684\u8d23\u4efb\u5ea6\u91cf\uff0c\u7279\u522b\u9488\u5bf9\u5e26\u5426\u5b9a\u539f\u5b50\u7684\u8054\u5408\u5408\u53d6\u67e5\u8be2(UCQ\u00ac)\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u8d23\u4efb\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u8d23\u4efb\u5ea6\u91cf\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u8c03\u67e5\u8be2\u4e0a\uff0c\u7f3a\u4e4f\u5bf9\u5e26\u5426\u5b9a\u539f\u5b50\u7684\u8054\u5408\u5408\u53d6\u67e5\u8be2(UCQ\u00ac)\u7684\u8d23\u4efb\u5ea6\u91cf\u65b9\u6cd5\u3002\u9700\u8981\u5b9a\u4e49\u5408\u7406\u7684\u89e3\u91ca\u6216\u76f8\u5173\u6027\u6982\u5ff5\u6765\u5904\u7406\u5305\u542b\u5426\u5b9a\u539f\u5b50\u7684\u67e5\u8be2\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a\u4e00\u79cd\u4ec5\u5bf9\u6b63\u6570\u636e\u5e93\u4e8b\u5b9e\u5206\u914d\u5206\u6570\uff0c\u53e6\u4e00\u79cd\u540c\u65f6\u8003\u8651\u5426\u5b9a\u4e8b\u5b9e\u3002\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u5c06\u5148\u524d\u7814\u7a76\u7684drastic Shapley\u548cWSMS\u5206\u6570\u4ece\u5355\u8c03\u67e5\u8be2\u6269\u5c55\u5230UCQ\u00ac\u67e5\u8be2\u3002", "result": "\u5206\u6790\u4e86\u6240\u5f97\u5ea6\u91cf\u7684\u6570\u636e\u548c\u7ec4\u5408\u590d\u6742\u5ea6\uff0c\u7279\u522b\u8bc1\u660e\u4e86WSMS\u5ea6\u91cf\u5bf9\u6240\u6709UCQ\u00ac\u67e5\u8be2\u5728\u6570\u636e\u590d\u6742\u5ea6\u4e0a\u662f\u53ef\u5904\u7406\u7684\uff0c\u5e76\u5bf9\u5408\u9002\u7684\u5e26\u5426\u5b9a\u7684\u5408\u53d6\u67e5\u8be2\u7c7b\u5728\u7ec4\u5408\u590d\u6742\u5ea6\u4e0a\u4e5f\u662f\u53ef\u5904\u7406\u7684\u3002", "conclusion": "\u8be5\u7814\u7a76\u6269\u5c55\u4e86\u8d23\u4efb\u5ea6\u91cf\u5230\u5e26\u5426\u5b9a\u539f\u5b50\u7684\u67e5\u8be2\uff0c\u63d0\u4f9b\u4e86\u4e24\u79cd\u5b9e\u7528\u7684\u65b9\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u91cd\u8981\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u7ed3\u679c\uff0c\u4e3aUCQ\u00ac\u67e5\u8be2\u7684\u89e3\u91ca\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.05157", "categories": ["cs.DS", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.05157", "abs": "https://arxiv.org/abs/2601.05157", "authors": ["Alkis Kalavasis", "Pravesh K. Kothari", "Shuchen Li", "Manolis Zampetakis"], "title": "Learning Mixture Models via Efficient High-dimensional Sparse Fourier Transforms", "comment": null, "summary": "In this work, we give a ${\\rm poly}(d,k)$ time and sample algorithm for efficiently learning the parameters of a mixture of $k$ spherical distributions in $d$ dimensions. Unlike all previous methods, our techniques apply to heavy-tailed distributions and include examples that do not even have finite covariances. Our method succeeds whenever the cluster distributions have a characteristic function with sufficiently heavy tails. Such distributions include the Laplace distribution but crucially exclude Gaussians.\n  All previous methods for learning mixture models relied implicitly or explicitly on the low-degree moments. Even for the case of Laplace distributions, we prove that any such algorithm must use super-polynomially many samples. Our method thus adds to the short list of techniques that bypass the limitations of the method of moments.\n  Somewhat surprisingly, our algorithm does not require any minimum separation between the cluster means. This is in stark contrast to spherical Gaussian mixtures where a minimum $\\ell_2$-separation is provably necessary even information-theoretically [Regev and Vijayaraghavan '17]. Our methods compose well with existing techniques and allow obtaining ''best of both worlds\" guarantees for mixtures where every component either has a heavy-tailed characteristic function or has a sub-Gaussian tail with a light-tailed characteristic function.\n  Our algorithm is based on a new approach to learning mixture models via efficient high-dimensional sparse Fourier transforms. We believe that this method will find more applications to statistical estimation. As an example, we give an algorithm for consistent robust mean estimation against noise-oblivious adversaries, a model practically motivated by the literature on multiple hypothesis testing. It was formally proposed in a recent Master's thesis by one of the authors, and has already inspired follow-up works.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u80fd\u6709\u6548\u5b66\u4e60\u91cd\u5c3e\u5206\u5e03\u6df7\u5408\u6a21\u578b\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u65e0\u9700\u6700\u5c0f\u5747\u503c\u5206\u79bb\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u77e9\u65b9\u6cd5\u7684\u9650\u5236\u3002", "motivation": "\u4f20\u7edf\u6df7\u5408\u6a21\u578b\u5b66\u4e60\u65b9\u6cd5\u90fd\u4f9d\u8d56\u4f4e\u9636\u77e9\uff0c\u65e0\u6cd5\u5904\u7406\u91cd\u5c3e\u5206\u5e03\uff08\u5982\u62c9\u666e\u62c9\u65af\u5206\u5e03\uff09\u6216\u65e0\u9650\u534f\u65b9\u5dee\u7684\u5206\u5e03\u3002\u9700\u8981\u5f00\u53d1\u80fd\u7ed5\u8fc7\u77e9\u65b9\u6cd5\u9650\u5236\u7684\u65b0\u6280\u672f\u3002", "method": "\u57fa\u4e8e\u9ad8\u6548\u9ad8\u7ef4\u7a00\u758f\u5085\u91cc\u53f6\u53d8\u6362\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u5206\u5e03\u7279\u5f81\u51fd\u6570\u7684\u91cd\u5c3e\u7279\u6027\uff0c\u65e0\u9700\u6700\u5c0f\u5747\u503c\u5206\u79bb\u6761\u4ef6\u3002", "result": "\u5b9e\u73b0\u4e86\u5728d\u7ef4\u7a7a\u95f4\u4e2d\u5b66\u4e60k\u4e2a\u7403\u5f62\u91cd\u5c3e\u5206\u5e03\u6df7\u5408\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u548c\u6837\u672c\u590d\u6742\u5ea6\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u62c9\u666e\u62c9\u65af\u5206\u5e03\u7b49\u91cd\u5c3e\u5206\u5e03\uff0c\u4f46\u4e0d\u9002\u7528\u4e8e\u9ad8\u65af\u5206\u5e03\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7a81\u7834\u4e86\u4f20\u7edf\u77e9\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u7edf\u8ba1\u4f30\u8ba1\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u5e76\u80fd\u4e0e\u73b0\u6709\u6280\u672f\u7ed3\u5408\u5b9e\u73b0\"\u4e24\u5168\u5176\u7f8e\"\u7684\u4fdd\u8bc1\uff0c\u5728\u9c81\u68d2\u5747\u503c\u4f30\u8ba1\u7b49\u5e94\u7528\u4e2d\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2601.04554", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.04554", "abs": "https://arxiv.org/abs/2601.04554", "authors": ["Wenlin Zhang", "Xiangyang Li", "Qiyuan Ge", "Kuicai Dong", "Pengyue Jia", "Xiaopeng Li", "Zijian Zhang", "Maolin Wang", "Yichao Wang", "Huifeng Guo", "Ruiming Tang", "Xiangyu Zhao"], "title": "Exploring Recommender System Evaluation: A Multi-Modal User Agent Framework for A/B Testing", "comment": null, "summary": "In recommender systems, online A/B testing is a crucial method for evaluating the performance of different models. However, conducting online A/B testing often presents significant challenges, including substantial economic costs, user experience degradation, and considerable time requirements. With the Large Language Models' powerful capacity, LLM-based agent shows great potential to replace traditional online A/B testing. Nonetheless, current agents fail to simulate the perception process and interaction patterns, due to the lack of real environments and visual perception capability. To address these challenges, we introduce a multi-modal user agent for A/B testing (A/B Agent). Specifically, we construct a recommendation sandbox environment for A/B testing, enabling multimodal and multi-page interactions that align with real user behavior on online platforms. The designed agent leverages multimodal information perception, fine-grained user preferences, and integrates profiles, action memory retrieval, and a fatigue system to simulate complex human decision-making. We validated the potential of the agent as an alternative to traditional A/B testing from three perspectives: model, data, and features. Furthermore, we found that the data generated by A/B Agent can effectively enhance the capabilities of recommendation models. Our code is publicly available at https://github.com/Applied-Machine-Learning-Lab/ABAgent.", "AI": {"tldr": "\u63d0\u51faA/B Agent\u591a\u6a21\u6001\u7528\u6237\u4ee3\u7406\uff0c\u901a\u8fc7\u6784\u5efa\u63a8\u8350\u6c99\u7bb1\u73af\u5883\u548c\u6a21\u62df\u771f\u5b9e\u7528\u6237\u884c\u4e3a\uff0c\u66ff\u4ee3\u4f20\u7edf\u5728\u7ebfA/B\u6d4b\u8bd5\uff0c\u964d\u4f4e\u7ecf\u6d4e\u6210\u672c\u548c\u65f6\u95f4\u9700\u6c42", "motivation": "\u4f20\u7edf\u5728\u7ebfA/B\u6d4b\u8bd5\u5b58\u5728\u7ecf\u6d4e\u6210\u672c\u9ad8\u3001\u7528\u6237\u4f53\u9a8c\u4e0b\u964d\u548c\u65f6\u95f4\u9700\u6c42\u5927\u7b49\u95ee\u9898\uff0c\u800c\u73b0\u6709LLM\u4ee3\u7406\u7f3a\u4e4f\u771f\u5b9e\u73af\u5883\u548c\u89c6\u89c9\u611f\u77e5\u80fd\u529b\uff0c\u65e0\u6cd5\u6a21\u62df\u771f\u5b9e\u7528\u6237\u4ea4\u4e92", "method": "\u6784\u5efa\u63a8\u8350\u6c99\u7bb1\u73af\u5883\u652f\u6301\u591a\u6a21\u6001\u591a\u9875\u9762\u4ea4\u4e92\uff0c\u8bbe\u8ba1\u4ee3\u7406\u5177\u5907\u591a\u6a21\u6001\u4fe1\u606f\u611f\u77e5\u3001\u7ec6\u7c92\u5ea6\u7528\u6237\u504f\u597d\u3001\u6863\u6848\u6574\u5408\u3001\u884c\u52a8\u8bb0\u5fc6\u68c0\u7d22\u548c\u75b2\u52b3\u7cfb\u7edf\uff0c\u6a21\u62df\u590d\u6742\u4eba\u7c7b\u51b3\u7b56", "result": "\u4ece\u6a21\u578b\u3001\u6570\u636e\u548c\u7279\u5f81\u4e09\u4e2a\u89d2\u5ea6\u9a8c\u8bc1\u4e86A/B Agent\u66ff\u4ee3\u4f20\u7edfA/B\u6d4b\u8bd5\u7684\u6f5c\u529b\uff0c\u53d1\u73b0\u5176\u751f\u6210\u7684\u6570\u636e\u80fd\u6709\u6548\u589e\u5f3a\u63a8\u8350\u6a21\u578b\u80fd\u529b", "conclusion": "A/B Agent\u4e3a\u89e3\u51b3\u4f20\u7edf\u5728\u7ebfA/B\u6d4b\u8bd5\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\uff0c\u5c55\u793a\u4e86LLM\u4ee3\u7406\u5728\u63a8\u8350\u7cfb\u7edf\u8bc4\u4f30\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2601.05030", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05030", "abs": "https://arxiv.org/abs/2601.05030", "authors": ["Sambhab Mishra"], "title": "Refinements of Jensen's Inequality for Twice-Differentiable Convex Functions with Bounded Hessian", "comment": "15 Pages. Comments welcome!", "summary": "Jensen's inequality, attributed to Johan Jensen -- a Danish mathematician and engineer noted for his contributions to the theory of functions -- is a ubiquitous result in convex analysis, providing a fundamental lower bound for the expectation of a convex function. In this paper, we establish rigorous refinements of this inequality specifically for twice-differentiable functions with bounded Hessians. By utilizing Taylor expansions with integral remainders, we tried to bridge the gap between classical variance-based bounds and higher-precision estimates. We also discover explicit error terms governed by Gruss-type inequalities, allowing for the incorporation of skewness and kurtosis into the bound. Using these new theoretical tools, we improve upon existing estimates for the Shannon entropy of continuous distributions and the ergodic capacity of Rayleigh fading channels, demonstrating the practical efficacy of our refinements.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5177\u6709\u6709\u754cHessian\u77e9\u9635\u7684\u4e8c\u9636\u53ef\u5fae\u51fd\u6570\uff0c\u5efa\u7acb\u4e86Jensen\u4e0d\u7b49\u5f0f\u7684\u4e25\u683c\u6539\u8fdb\uff0c\u901a\u8fc7\u79ef\u5206\u4f59\u9879\u7684\u6cf0\u52d2\u5c55\u5f00\u548cGruss\u578b\u4e0d\u7b49\u5f0f\uff0c\u5c06\u504f\u5ea6\u548c\u5cf0\u5ea6\u7eb3\u5165\u8bef\u5dee\u9879\uff0c\u6539\u8fdb\u4e86\u8fde\u7eed\u5206\u5e03\u9999\u519c\u71b5\u548c\u745e\u5229\u8870\u843d\u4fe1\u9053\u904d\u5386\u5bb9\u91cf\u7684\u4f30\u8ba1\u3002", "motivation": "Jensen\u4e0d\u7b49\u5f0f\u662f\u51f8\u5206\u6790\u4e2d\u7684\u57fa\u672c\u7ed3\u679c\uff0c\u4f46\u4f20\u7edf\u65b9\u5dee\u754c\u7cbe\u5ea6\u6709\u9650\u3002\u4f5c\u8005\u5e0c\u671b\u5efa\u7acb\u66f4\u7cbe\u786e\u7684\u6539\u8fdb\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5177\u6709\u6709\u754cHessian\u7684\u4e8c\u9636\u53ef\u5fae\u51fd\u6570\uff0c\u4ee5\u586b\u8865\u7ecf\u5178\u65b9\u5dee\u754c\u4e0e\u9ad8\u7cbe\u5ea6\u4f30\u8ba1\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u4f7f\u7528\u79ef\u5206\u4f59\u9879\u7684\u6cf0\u52d2\u5c55\u5f00\uff0c\u7ed3\u5408Gruss\u578b\u4e0d\u7b49\u5f0f\u63a8\u5bfc\u663e\u5f0f\u8bef\u5dee\u9879\uff0c\u5c06\u504f\u5ea6\u548c\u5cf0\u5ea6\u7b49\u9ad8\u9636\u77e9\u4fe1\u606f\u7eb3\u5165\u8fb9\u754c\u4f30\u8ba1\u4e2d\u3002", "result": "\u5efa\u7acb\u4e86Jensen\u4e0d\u7b49\u5f0f\u7684\u4e25\u683c\u6539\u8fdb\u5f62\u5f0f\uff0c\u83b7\u5f97\u4e86\u7531Gruss\u578b\u4e0d\u7b49\u5f0f\u63a7\u5236\u7684\u663e\u5f0f\u8bef\u5dee\u9879\uff0c\u6210\u529f\u6539\u8fdb\u4e86\u8fde\u7eed\u5206\u5e03\u9999\u519c\u71b5\u548c\u745e\u5229\u8870\u843d\u4fe1\u9053\u904d\u5386\u5bb9\u91cf\u7684\u73b0\u6709\u4f30\u8ba1\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u9ad8\u9636\u77e9\u4fe1\u606f\uff08\u504f\u5ea6\u548c\u5cf0\u5ea6\uff09\u5230Jensen\u4e0d\u7b49\u5f0f\u7684\u6539\u8fdb\u4e2d\uff0c\u83b7\u5f97\u4e86\u66f4\u7cbe\u786e\u7684\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u5728\u4fe1\u606f\u8bba\u548c\u901a\u4fe1\u7406\u8bba\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2601.05108", "categories": ["cs.DB", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.05108", "abs": "https://arxiv.org/abs/2601.05108", "authors": ["Philipp Hanisch", "Markus Kr\u00f6tzsch"], "title": "Rule Rewriting Revisited: A Fresh Look at Static Filtering for Datalog and ASP", "comment": "Technical report of our ICDT'26 paper", "summary": "Static filtering is a data-independent optimisation method for Datalog, which generalises algebraic query rewriting techniques from relational databases. In spite of its early discovery by Kifer and Lozinskii in 1986, the method has been overlooked in recent research and system development, and special cases are being rediscovered independently. We therefore recall the original approach, using updated terminology and more general filter predicates that capture features of modern systems, and we show how to extend its applicability to answer set programming (ASP). The outcome is strictly more general but also more complex than the classical approach: double exponential in general and single exponential even for predicates of bounded arity. As a solution, we propose tractable approximations of the algorithm that can still yield much improved logic programs in typical cases, e.g., it can improve the performance of rule systems over real-world data in the order of magnitude.", "AI": {"tldr": "\u9759\u6001\u8fc7\u6ee4\u662f\u4e00\u79cd\u6570\u636e\u65e0\u5173\u7684Datalog\u4f18\u5316\u65b9\u6cd5\uff0c\u63a8\u5e7f\u4e86\u5173\u7cfb\u6570\u636e\u5e93\u4e2d\u7684\u4ee3\u6570\u67e5\u8be2\u91cd\u5199\u6280\u672f\u3002\u672c\u6587\u56de\u987e\u5e76\u6269\u5c55\u4e86\u8be5\u65b9\u6cd5\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u7b54\u6848\u96c6\u7f16\u7a0b\uff0c\u63d0\u51fa\u4e86\u53ef\u5904\u7406\u7684\u8fd1\u4f3c\u7b97\u6cd5\u6765\u6539\u5584\u5b9e\u9645\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u9759\u6001\u8fc7\u6ee4\u65b9\u6cd5\u65e9\u57281986\u5e74\u5c31\u88abKifer\u548cLozinskii\u53d1\u73b0\uff0c\u4f46\u8be5\u65b9\u6cd5\u5728\u8fd1\u671f\u7814\u7a76\u548c\u7cfb\u7edf\u5f00\u53d1\u4e2d\u88ab\u5ffd\u89c6\uff0c\u5176\u7279\u4f8b\u88ab\u72ec\u7acb\u91cd\u65b0\u53d1\u73b0\u3002\u56e0\u6b64\u9700\u8981\u56de\u987e\u539f\u59cb\u65b9\u6cd5\uff0c\u4f7f\u7528\u66f4\u65b0\u672f\u8bed\u548c\u66f4\u901a\u7528\u7684\u8fc7\u6ee4\u5668\u8c13\u8bcd\u6765\u6355\u6349\u73b0\u4ee3\u7cfb\u7edf\u7279\u6027\uff0c\u5e76\u5c06\u5176\u6269\u5c55\u5230\u7b54\u6848\u96c6\u7f16\u7a0b\u3002", "method": "\u4f7f\u7528\u66f4\u65b0\u672f\u8bed\u548c\u66f4\u901a\u7528\u7684\u8fc7\u6ee4\u5668\u8c13\u8bcd\u6765\u91cd\u65b0\u8868\u8ff0\u539f\u59cb\u9759\u6001\u8fc7\u6ee4\u65b9\u6cd5\uff0c\u5c06\u5176\u6269\u5c55\u5230\u7b54\u6848\u96c6\u7f16\u7a0b\u3002\u7531\u4e8e\u6269\u5c55\u540e\u7684\u65b9\u6cd5\u590d\u6742\u5ea6\u8f83\u9ad8\uff08\u53cc\u6307\u6570\u7ea7\uff09\uff0c\u63d0\u51fa\u4e86\u53ef\u5904\u7406\u7684\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u8fd9\u4e9b\u8fd1\u4f3c\u7b97\u6cd5\u5728\u5178\u578b\u60c5\u51b5\u4e0b\u4ecd\u80fd\u663e\u8457\u6539\u8fdb\u903b\u8f91\u7a0b\u5e8f\u6027\u80fd\u3002", "result": "\u6269\u5c55\u540e\u7684\u65b9\u6cd5\u6bd4\u7ecf\u5178\u65b9\u6cd5\u66f4\u901a\u7528\u4f46\u4e5f\u66f4\u590d\u6742\uff1a\u4e00\u822c\u60c5\u51b5\u4e0b\u662f\u53cc\u6307\u6570\u7ea7\u590d\u6742\u5ea6\uff0c\u5373\u4f7f\u5bf9\u4e8e\u6709\u754c\u5143\u6570\u7684\u8c13\u8bcd\u4e5f\u662f\u5355\u6307\u6570\u7ea7\u3002\u63d0\u51fa\u7684\u53ef\u5904\u7406\u8fd1\u4f3c\u7b97\u6cd5\u5728\u5b9e\u9645\u6570\u636e\u4e0a\u7684\u89c4\u5219\u7cfb\u7edf\u6027\u80fd\u53ef\u4ee5\u63d0\u5347\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u9759\u6001\u8fc7\u6ee4\u4f5c\u4e3a\u4e00\u79cd\u6570\u636e\u65e0\u5173\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u6269\u5c55\u548c\u8fd1\u4f3c\u5904\u7406\uff0c\u53ef\u4ee5\u663e\u8457\u6539\u5584Datalog\u548c\u7b54\u6848\u96c6\u7f16\u7a0b\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u503c\u5f97\u5728\u73b0\u4ee3\u7cfb\u7edf\u4e2d\u91cd\u65b0\u5173\u6ce8\u548c\u5e94\u7528\u3002"}}
{"id": "2601.05166", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.05166", "abs": "https://arxiv.org/abs/2601.05166", "authors": ["Michal Opler"], "title": "Inapproximability of Counting Permutation Patterns", "comment": null, "summary": "Detecting and counting copies of permutation patterns are fundamental algorithmic problems, with applications in the analysis of rankings, nonparametric statistics, and property testing tasks such as independence and quasirandomness testing. From an algorithmic perspective, there is a sharp difference in complexity between detecting and counting the copies of a given length-$k$ pattern in a length-$n$ permutation. The former admits a $2^{\\mathcal{O}(k^2)} \\cdot n$ time algorithm (Guillemot and Marx, 2014) while the latter cannot be solved in time $f(k)\\cdot n^{o(k/\\log k)}$ unless the Exponential Time Hypothesis (ETH) fails (Berendsohn, Kozma, and Marx, 2021). In fact already for patterns of length 4, exact counting is unlikely to admit near-linear time algorithms under standard fine-grained complexity assumptions (Dudek and Gawrychowski, 2020).\n  Recently, Ben-Eliezer, Mitrovi\u0107 and Sristava (2026) showed that for patterns of length up to 5, a $(1+\\varepsilon)$-approximation of the pattern count can be computed in near-linear time, yielding a separation between exact and approximate counting for small patterns, and conjectured that approximate counting is asymptotically easier than exact counting in general. We strongly refute their conjecture by showing that, under ETH, no algorithm running in time $f(k)\\cdot n^{o(k/\\log k)}$ can approximate the number of copies of a length-$k$ pattern within a multiplicative factor $n^{(1/2-\\varepsilon)k}$. The lower bound on runtime matches the conditional lower bound for exact pattern counting, and the obtained bound on the multiplicative error factor is essentially tight, as an $n^{k/2}$-approximation can be computed in $2^{\\mathcal{O}(k^2)}\\cdot n$ time using an algorithm for pattern detection.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f3a\u70c8\u53cd\u9a73\u4e86\u8fd1\u4f3c\u8ba1\u6570\u6bd4\u7cbe\u786e\u8ba1\u6570\u66f4\u5bb9\u6613\u7684\u731c\u60f3\uff0c\u8bc1\u660e\u4e86\u5728\u6307\u6570\u65f6\u95f4\u5047\u8bf4\u4e0b\uff0c\u957f\u5ea6k\u6a21\u5f0f\u7684\u8fd1\u4f3c\u8ba1\u6570\u4e0e\u7cbe\u786e\u8ba1\u6570\u5177\u6709\u76f8\u540c\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0b\u754c\u3002", "motivation": "\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\u5bf9\u4e8e\u957f\u5ea6\u4e0d\u8d85\u8fc75\u7684\u6a21\u5f0f\uff0c\u8fd1\u4f3c\u8ba1\u6570\u53ef\u4ee5\u5728\u8fd1\u7ebf\u6027\u65f6\u95f4\u5185\u5b8c\u6210\uff0c\u8fd9\u5f15\u53d1\u4e86\u8fd1\u4f3c\u8ba1\u6570\u662f\u5426\u666e\u904d\u6bd4\u7cbe\u786e\u8ba1\u6570\u66f4\u5bb9\u6613\u7684\u731c\u60f3\u3002\u672c\u6587\u65e8\u5728\u68c0\u9a8c\u8fd9\u4e00\u731c\u60f3\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u5728\u6307\u6570\u65f6\u95f4\u5047\u8bf4\uff08ETH\uff09\u4e0b\uff0c\u8bc1\u660e\u4e86\u5bf9\u4e8e\u957f\u5ea6k\u7684\u6a21\u5f0f\uff0c\u4efb\u4f55\u5728\u65f6\u95f4f(k)\u00b7n^{o(k/log k)}\u5185\u8fd0\u884c\u7684\u7b97\u6cd5\u90fd\u65e0\u6cd5\u5c06\u6a21\u5f0f\u526f\u672c\u6570\u91cf\u8fd1\u4f3c\u5230n^{(1/2-\u03b5)k}\u7684\u4e58\u6cd5\u56e0\u5b50\u5185\u3002", "result": "\u8bc1\u660e\u4e86\u8fd1\u4f3c\u8ba1\u6570\u4e0e\u7cbe\u786e\u8ba1\u6570\u5177\u6709\u76f8\u540c\u7684\u6761\u4ef6\u590d\u6742\u5ea6\u4e0b\u754c\uff0c\u5373\u90fd\u9700\u8981f(k)\u00b7n^{\u03a9(k/log k)}\u65f6\u95f4\uff0c\u4e14\u8bef\u5dee\u56e0\u5b50\u4e0b\u754cn^{(1/2-\u03b5)k}\u672c\u8d28\u4e0a\u662f\u7d27\u7684\uff0c\u56e0\u4e3an^{k/2}\u8fd1\u4f3c\u53ef\u4ee5\u57282^{O(k\u00b2)}\u00b7n\u65f6\u95f4\u5185\u5b8c\u6210\u3002", "conclusion": "\u8fd1\u4f3c\u8ba1\u6570\u5e76\u4e0d\u6bd4\u7cbe\u786e\u8ba1\u6570\u66f4\u5bb9\u6613\uff0c\u4e24\u8005\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0a\u5177\u6709\u76f8\u540c\u7684\u4e0b\u754c\uff0c\u8fd9\u5f3a\u70c8\u53cd\u9a73\u4e86\u5148\u524d\u5173\u4e8e\u8fd1\u4f3c\u8ba1\u6570\u666e\u904d\u66f4\u7b80\u5355\u7684\u731c\u60f3\u3002"}}
{"id": "2601.04618", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.04618", "abs": "https://arxiv.org/abs/2601.04618", "authors": ["Jongho Kim", "Jaeyoung Kim", "Seung-won Hwang", "Jihyuk Kim", "Yu Jin Kim", "Moontae Lee"], "title": "Adaptive Retrieval for Reasoning-Intensive Retrieval", "comment": null, "summary": "We study leveraging adaptive retrieval to ensure sufficient \"bridge\" documents are retrieved for reasoning-intensive retrieval. Bridge documents are those that contribute to the reasoning process yet are not directly relevant to the initial query. While existing reasoning-based reranker pipelines attempt to surface these documents in ranking, they suffer from bounded recall. Naive solution with adaptive retrieval into these pipelines often leads to planning error propagation. To address this, we propose REPAIR, a framework that bridges this gap by repurposing reasoning plans as dense feedback signals for adaptive retrieval. Our key distinction is enabling mid-course correction during reranking through selective adaptive retrieval, retrieving documents that support the pivotal plan. Experimental results on reasoning-intensive retrieval and complex QA tasks demonstrate that our method outperforms existing baselines by 5.6%pt.", "AI": {"tldr": "REPAIR\u6846\u67b6\u901a\u8fc7\u5c06\u63a8\u7406\u8ba1\u5212\u91cd\u65b0\u7528\u4f5c\u81ea\u9002\u5e94\u68c0\u7d22\u7684\u5bc6\u96c6\u53cd\u9988\u4fe1\u53f7\uff0c\u89e3\u51b3\u63a8\u7406\u5bc6\u96c6\u578b\u68c0\u7d22\u4e2d\"\u6865\u6881\u6587\u6863\"\u53ec\u56de\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u76f8\u6bd4\u57fa\u7ebf\u63d0\u53475.6%", "motivation": "\u73b0\u6709\u57fa\u4e8e\u63a8\u7406\u7684\u91cd\u65b0\u6392\u5e8f\u7ba1\u9053\u8bd5\u56fe\u5728\u6392\u5e8f\u4e2d\u5448\u73b0\"\u6865\u6881\u6587\u6863\"\uff08\u5bf9\u63a8\u7406\u8fc7\u7a0b\u6709\u8d21\u732e\u4f46\u4e0d\u76f4\u63a5\u76f8\u5173\u521d\u59cb\u67e5\u8be2\u7684\u6587\u6863\uff09\uff0c\u4f46\u5b58\u5728\u53ec\u56de\u7387\u53d7\u9650\u7684\u95ee\u9898\u3002\u6734\u7d20\u7684\u81ea\u9002\u5e94\u68c0\u7d22\u89e3\u51b3\u65b9\u6848\u5e38\u5bfc\u81f4\u89c4\u5212\u9519\u8bef\u4f20\u64ad\u3002", "method": "\u63d0\u51faREPAIR\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u63a8\u7406\u8ba1\u5212\u91cd\u65b0\u7528\u4f5c\u5bc6\u96c6\u53cd\u9988\u4fe1\u53f7\u8fdb\u884c\u81ea\u9002\u5e94\u68c0\u7d22\u3002\u5173\u952e\u533a\u522b\u5728\u4e8e\u901a\u8fc7\u9009\u62e9\u6027\u81ea\u9002\u5e94\u68c0\u7d22\u5b9e\u73b0\u91cd\u65b0\u6392\u5e8f\u8fc7\u7a0b\u4e2d\u7684\u4e2d\u9014\u4fee\u6b63\uff0c\u68c0\u7d22\u652f\u6301\u5173\u952e\u8ba1\u5212\u7684\u6587\u6863\u3002", "result": "\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u68c0\u7d22\u548c\u590d\u6742QA\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf5.6\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "REPAIR\u6846\u67b6\u901a\u8fc7\u5229\u7528\u63a8\u7406\u8ba1\u5212\u4f5c\u4e3a\u53cd\u9988\u4fe1\u53f7\u8fdb\u884c\u9009\u62e9\u6027\u81ea\u9002\u5e94\u68c0\u7d22\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u63a8\u7406\u5bc6\u96c6\u578b\u68c0\u7d22\u4e2d\u6865\u6881\u6587\u6863\u53ec\u56de\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u6027\u80fd\u3002"}}
{"id": "2601.05092", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05092", "abs": "https://arxiv.org/abs/2601.05092", "authors": ["Boyu Ning", "Haifan Yin", "Sixu Liu", "Hao Deng", "Songjie Yang", "Yuchen Zhang", "Weidong Mei", "David Gesbert", "Jaebum Park", "Robert W. Heath", "Emil Bj\u00f6rnson"], "title": "Precoding Matrix Indicator in the 5G NR Protocol: A Tutorial on 3GPP Beamforming Codebooks", "comment": "This work has been accepted by IEEE COMST with manuscript number 00802-2025.R1", "summary": "This paper bridges this critical gap by providing a systematic examination of the beamforming codebook technology, i.e., precoding matrix indicator (PMI), in the 5G NR from theoretical, standardization, and implementation perspectives. We begin by introducing the background of beamforming in multiple-input multiple-output (MIMO) systems and the signaling procedures for codebook-based beamforming in practical 5G systems. Then, we establish the fundamentals of regular codebooks and port-selection codebooks in 3GPP standards. Next, we provide rigorous technical analysis of 3GPP codebook evolution spanning Releases 15-18, with particular focus on: 1) We elucidate the core principles underlying codebook design, 2) provide clear physical interpretations for each symbolic variable in the codebook formulas, summarized in tabular form, and 3) offer intuitive visual illustrations to explain how codebook parameters convey information. These essential pedagogical elements are almost entirely absent in the often-obscure standardization documents. Through mathematical modeling, performance benchmarking, feedback comparisons, and scenario-dependent applicability analysis, we provide researchers and engineers with a unified understanding of beamforming codebooks in real-world systems. Furthermore, we identify future directions and other beamforming scenarios for ongoing research and development efforts. This work serves as both an informative tutorial and a guidance for future research, facilitating more effective collaboration between academia and industry in advancing wireless communication technologies.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u6027\u5730\u5206\u6790\u4e865G NR\u4e2d\u7684\u6ce2\u675f\u8d4b\u5f62\u7801\u672c\u6280\u672f\uff08PMI\uff09\uff0c\u4ece\u7406\u8bba\u3001\u6807\u51c6\u5316\u548c\u5b9e\u73b0\u4e09\u4e2a\u89d2\u5ea6\u5168\u9762\u63a2\u8ba8\u4e863GPP\u6807\u51c6\u4e2d\u7801\u672c\u7684\u8bbe\u8ba1\u539f\u7406\u3001\u6f14\u8fdb\u5386\u7a0b\u548c\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u6807\u51c6\u5316\u6587\u6863\u4e2d\u5bf9\u6ce2\u675f\u8d4b\u5f62\u7801\u672c\u6280\u672f\u7684\u63cf\u8ff0\u5f80\u5f80\u6666\u6da9\u96be\u61c2\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u7684\u7406\u8bba\u89e3\u91ca\u548c\u76f4\u89c2\u7684\u7269\u7406\u610f\u4e49\u9610\u91ca\uff0c\u8fd9\u7ed9\u7814\u7a76\u4eba\u5458\u548c\u5de5\u7a0b\u5e08\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5e26\u6765\u4e86\u56f0\u96be\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u89e3\u6846\u67b6\u3002", "method": "\u8bba\u6587\u91c7\u7528\u591a\u89d2\u5ea6\u5206\u6790\u65b9\u6cd5\uff1a1) \u4ecb\u7ecdMIMO\u7cfb\u7edf\u4e2d\u6ce2\u675f\u8d4b\u5f62\u7684\u80cc\u666f\u548c5G\u7cfb\u7edf\u4e2d\u7684\u7801\u672c\u4fe1\u4ee4\u6d41\u7a0b\uff1b2) \u5efa\u7acb3GPP\u6807\u51c6\u4e2d\u5e38\u89c4\u7801\u672c\u548c\u7aef\u53e3\u9009\u62e9\u7801\u672c\u7684\u57fa\u7840\u7406\u8bba\uff1b3) \u5bf93GPP Release 15-18\u7684\u7801\u672c\u6f14\u8fdb\u8fdb\u884c\u4e25\u683c\u6280\u672f\u5206\u6790\uff0c\u5305\u62ec\u8bbe\u8ba1\u539f\u7406\u3001\u7b26\u53f7\u53d8\u91cf\u7684\u7269\u7406\u89e3\u91ca\u548c\u53ef\u89c6\u5316\u8bf4\u660e\uff1b4) \u901a\u8fc7\u6570\u5b66\u5efa\u6a21\u3001\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\u3001\u53cd\u9988\u6bd4\u8f83\u548c\u573a\u666f\u9002\u7528\u6027\u5206\u6790\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86\u5bf95G NR\u6ce2\u675f\u8d4b\u5f62\u7801\u672c\u6280\u672f\u7684\u7cfb\u7edf\u6027\u7406\u89e3\uff0c\u5305\u62ec\uff1a1) \u6e05\u6670\u89e3\u91ca\u4e86\u7801\u672c\u8bbe\u8ba1\u7684\u6838\u5fc3\u539f\u7406\uff1b2) \u4ee5\u8868\u683c\u5f62\u5f0f\u603b\u7ed3\u4e86\u7801\u672c\u516c\u5f0f\u4e2d\u6bcf\u4e2a\u7b26\u53f7\u53d8\u91cf\u7684\u7269\u7406\u542b\u4e49\uff1b3) \u63d0\u4f9b\u4e86\u76f4\u89c2\u7684\u53ef\u89c6\u5316\u8bf4\u660e\u6765\u89e3\u91ca\u7801\u672c\u53c2\u6570\u5982\u4f55\u4f20\u9012\u4fe1\u606f\uff1b4) \u5efa\u7acb\u4e86\u5b9e\u9645\u7cfb\u7edf\u4e2d\u6ce2\u675f\u8d4b\u5f62\u7801\u672c\u7684\u7edf\u4e00\u7406\u89e3\u6846\u67b6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u65e2\u662f\u4e00\u4e2a\u4fe1\u606f\u4e30\u5bcc\u7684\u6559\u7a0b\uff0c\u4e5f\u662f\u672a\u6765\u7814\u7a76\u7684\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u5728\u65e0\u7ebf\u901a\u4fe1\u6280\u672f\u53d1\u5c55\u65b9\u9762\u66f4\u6709\u6548\u7684\u5408\u4f5c\u3002\u8bba\u6587\u8fd8\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u548c\u5176\u4ed6\u6ce2\u675f\u8d4b\u5f62\u573a\u666f\uff0c\u4e3a\u6301\u7eed\u7684\u7814\u7a76\u548c\u5f00\u53d1\u5de5\u4f5c\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2601.05225", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.05225", "abs": "https://arxiv.org/abs/2601.05225", "authors": ["Evan Wrench", "Ajay Singh", "Younghun Roh", "Panagiota Fatourou", "Siddhartha Jayanti", "Eric Ruppert", "Yuanhao Wei"], "title": "Concurrent Balanced Augmented Trees", "comment": "To appear in PPoPP 2026", "summary": "Augmentation makes search trees tremendously more versatile, allowing them to support efficient aggregation queries, order-statistic queries, and range queries in addition to insertion, deletion, and lookup. In this paper, we present the first lock-free augmented balanced search tree. Our algorithmic ideas build upon a recent augmented unbalanced search tree presented by Fatourou and Ruppert [DISC, 2024]. We implement both data structures, solving some memory reclamation challenges in the process, and provide an experimental performance analysis of them. We also present optimized versions of our balanced tree that use delegation to achieve better scalability and performance (by more than 2x in some workloads). Our experiments show that our augmented balanced tree is 2.2 to 30 times faster than the unbalanced augmented tree, and up to several orders of magnitude faster than unaugmented trees on 120 threads.", "AI": {"tldr": "\u9996\u4e2a\u65e0\u9501\u589e\u5f3a\u5e73\u8861\u641c\u7d22\u6811\uff0c\u652f\u6301\u9ad8\u6548\u805a\u5408\u67e5\u8be2\u3001\u987a\u5e8f\u7edf\u8ba1\u67e5\u8be2\u548c\u8303\u56f4\u67e5\u8be2\uff0c\u6027\u80fd\u6bd4\u975e\u5e73\u8861\u589e\u5f3a\u6811\u5feb2.2-30\u500d", "motivation": "\u589e\u5f3a\u641c\u7d22\u6811\u80fd\u652f\u6301\u805a\u5408\u67e5\u8be2\u3001\u987a\u5e8f\u7edf\u8ba1\u67e5\u8be2\u548c\u8303\u56f4\u67e5\u8be2\u7b49\u591a\u79cd\u64cd\u4f5c\uff0c\u4f46\u73b0\u6709\u65e0\u9501\u589e\u5f3a\u641c\u7d22\u6811\u90fd\u662f\u975e\u5e73\u8861\u7684\uff0c\u6027\u80fd\u53d7\u9650\u3002\u9700\u8981\u8bbe\u8ba1\u65e0\u9501\u589e\u5f3a\u5e73\u8861\u641c\u7d22\u6811\u6765\u83b7\u5f97\u66f4\u597d\u7684\u6027\u80fd", "method": "\u57fa\u4e8eFatourou\u548cRuppert\u7684\u65e0\u9501\u589e\u5f3a\u975e\u5e73\u8861\u641c\u7d22\u6811\uff0c\u8bbe\u8ba1\u9996\u4e2a\u65e0\u9501\u589e\u5f3a\u5e73\u8861\u641c\u7d22\u6811\u3002\u4f7f\u7528\u59d4\u6258\u673a\u5236\u4f18\u5316\u7248\u672c\u4ee5\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\u548c\u6027\u80fd\uff0c\u5e76\u89e3\u51b3\u5185\u5b58\u56de\u6536\u95ee\u9898", "result": "\u4f18\u5316\u7248\u672c\u6027\u80fd\u63d0\u5347\u8d85\u8fc72\u500d\uff0c\u589e\u5f3a\u5e73\u8861\u6811\u6bd4\u975e\u5e73\u8861\u589e\u5f3a\u6811\u5feb2.2-30\u500d\uff0c\u5728120\u7ebf\u7a0b\u4e0a\u6bd4\u975e\u589e\u5f3a\u6811\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7", "conclusion": "\u6210\u529f\u5b9e\u73b0\u9996\u4e2a\u65e0\u9501\u589e\u5f3a\u5e73\u8861\u641c\u7d22\u6811\uff0c\u901a\u8fc7\u59d4\u6258\u4f18\u5316\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e3a\u5e76\u53d1\u6570\u636e\u7ed3\u6784\u63d0\u4f9b\u9ad8\u6548\u7684\u591a\u529f\u80fd\u67e5\u8be2\u652f\u6301"}}
{"id": "2601.04646", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04646", "abs": "https://arxiv.org/abs/2601.04646", "authors": ["Prateek Jain", "Shabari S Nair", "Ritesh Goru", "Prakhar Agarwal", "Ajay Yadav", "Yoga Sri Varshan Varadharajan", "Constantine Caramanis"], "title": "Succeeding at Scale: Automated Multi-Retriever Fusion and Query-Side Adaptation for Multi-Tenant Search", "comment": null, "summary": "Large-scale multi-tenant retrieval systems amass vast user query logs yet critically lack the curated relevance labels required for effective domain adaptation. This \"dark data\" problem is exacerbated by the operational cost of model updates: jointly fine-tuning query and document encoders requires re-indexing the entire corpus, which is prohibitive in multi-tenant environments with thousands of isolated indices. To address these dual challenges, we introduce \\textbf{DevRev Search}, a passage retrieval benchmark for technical customer support constructed through a fully automatic pipeline. We employ a \\textbf{fusion-based candidate generation} strategy, pooling results from diverse sparse and dense retrievers, and utilize an LLM-as-a-Judge to perform rigorous \\textbf{consistency filtering} and relevance assignment. We further propose a practical \\textbf{Index-Preserving Adaptation} strategy: by fine-tuning only the query encoder via Low-Rank Adaptation (LoRA), we achieve competitive performance improvements while keeping the document index frozen. Our experiments on DevRev Search and SciFact demonstrate that targeting specific transformer layers in the query encoder yields optimal quality-efficiency trade-offs, offering a scalable path for personalized enterprise search.", "AI": {"tldr": "\u63d0\u51faDevRev Search\u57fa\u51c6\u6d4b\u8bd5\u548cIndex-Preserving Adaptation\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ec5\u5fae\u8c03\u67e5\u8be2\u7f16\u7801\u5668\uff08\u4fdd\u6301\u6587\u6863\u7d22\u5f15\u51bb\u7ed3\uff09\u89e3\u51b3\u5927\u89c4\u6a21\u591a\u79df\u6237\u68c0\u7d22\u7cfb\u7edf\u4e2d\u7684\"\u6697\u6570\u636e\"\u95ee\u9898\u548c\u6a21\u578b\u66f4\u65b0\u6210\u672c\u6311\u6218\u3002", "motivation": "\u5927\u89c4\u6a21\u591a\u79df\u6237\u68c0\u7d22\u7cfb\u7edf\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a1) \u7f3a\u4e4f\u6807\u6ce8\u6570\u636e\u7684\"\u6697\u6570\u636e\"\u95ee\u9898\uff1b2) \u8054\u5408\u5fae\u8c03\u67e5\u8be2\u548c\u6587\u6863\u7f16\u7801\u5668\u9700\u8981\u91cd\u65b0\u7d22\u5f15\u6574\u4e2a\u8bed\u6599\u5e93\uff0c\u8fd9\u5728\u591a\u79df\u6237\u73af\u5883\u4e2d\u6210\u672c\u8fc7\u9ad8\u3002", "method": "1) \u6784\u5efaDevRev Search\u57fa\u51c6\u6d4b\u8bd5\uff1a\u4f7f\u7528\u878d\u5408\u5019\u9009\u751f\u6210\u7b56\u7565\uff08\u7ed3\u5408\u7a00\u758f\u548c\u5bc6\u96c6\u68c0\u7d22\u5668\uff09\u548cLLM-as-a-Judge\u8fdb\u884c\u4e00\u81f4\u6027\u8fc7\u6ee4\u548c\u76f8\u5173\u6027\u6807\u6ce8\uff1b2) \u63d0\u51faIndex-Preserving Adaptation\u7b56\u7565\uff1a\u4ec5\u901a\u8fc7LoRA\u5fae\u8c03\u67e5\u8be2\u7f16\u7801\u5668\uff0c\u4fdd\u6301\u6587\u6863\u7d22\u5f15\u51bb\u7ed3\uff0c\u5e76\u9488\u5bf9\u7279\u5b9atransformer\u5c42\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5728DevRev Search\u548cSciFact\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4ec5\u5fae\u8c03\u67e5\u8be2\u7f16\u7801\u5668\u7684\u65b9\u6cd5\u80fd\u591f\u83b7\u5f97\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u6587\u6863\u7d22\u5f15\u4e0d\u53d8\uff0c\u5b9e\u73b0\u4e86\u8d28\u91cf\u4e0e\u6548\u7387\u7684\u6700\u4f73\u6743\u8861\u3002", "conclusion": "\u63d0\u51fa\u7684Index-Preserving Adaptation\u7b56\u7565\u4e3a\u4e2a\u6027\u5316\u4f01\u4e1a\u641c\u7d22\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u6269\u5c55\u7684\u8def\u5f84\uff0c\u901a\u8fc7\u4ec5\u5fae\u8c03\u67e5\u8be2\u7f16\u7801\u5668\u89e3\u51b3\u4e86\u591a\u79df\u6237\u73af\u5883\u4e2d\u7684\u6a21\u578b\u66f4\u65b0\u6210\u672c\u95ee\u9898\u3002"}}
{"id": "2601.05165", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05165", "abs": "https://arxiv.org/abs/2601.05165", "authors": ["Zhentian Zhang", "Christos Masouros", "Kai-Kit Wong", "Jian Dang", "Zaichen Zhang", "Kaitao Meng", "Farshad Rostami Ghadi", "Mohammad Javad Ahmadi"], "title": "Fundamental Tradeoffs for ISAC Multiple Access in Finite-Blocklength Regime", "comment": null, "summary": "This paper investigates the fundamental communication--sensing tradeoffs of uplink dual-functional integrated sensing and communication (ISAC) multiple access under finite blocklength (FBL) constraints. Unlike conventional asymptotic analyses, we explicitly account for the limitations under FBL constraints imposed by short packets and low-latency transmission. By examining the unbiased channel state sensing estimator, we establish a geometric decomposition of the sensing error, indicating that it is jointly determined by the signal-to-noise ratio and the correlation structure of the information codebook. This insight reveals how cross-correlation among active users in the codebook geometry fundamentally constrains dual-functional ISAC performance. Consequently, we derive achievability and converse bounds that characterize the tradeoff between communication code rate and sensing accuracy in the FBL regime, with the converse further bounded by Shannon capacity. Moreover, by treating channel state sensing as a high-level sensing objective, a universal Cram\u00e9r--Rao bound is derived to link channel estimation accuracy to practical sensing parameters. Examples of parameter sensing are also provided based on 3GPP standard. Numerical results validate the theoretical analysis and demonstrate the impact of blocklength, antenna dimensions, and sensing requirements.", "AI": {"tldr": "\u7814\u7a76\u6709\u9650\u5757\u957f\u7ea6\u675f\u4e0b\u4e0a\u884c\u94fe\u8def\u53cc\u529f\u80fdISAC\u591a\u5740\u63a5\u5165\u7684\u901a\u4fe1-\u611f\u77e5\u6743\u8861\uff0c\u5efa\u7acb\u4e86\u611f\u77e5\u8bef\u5dee\u7684\u51e0\u4f55\u5206\u89e3\uff0c\u63a8\u5bfc\u4e86FBL\u4f53\u5236\u4e0b\u7684\u53ef\u8fbe\u6027\u548c\u9006\u754c\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u3002", "motivation": "\u4f20\u7edf\u6e10\u8fd1\u5206\u6790\u65e0\u6cd5\u51c6\u786e\u63cf\u8ff0\u77ed\u5305\u548c\u4f4e\u5ef6\u8fdf\u4f20\u8f93\u4e0b\u7684\u6709\u9650\u5757\u957f\u7ea6\u675f\uff0c\u9700\u8981\u7814\u7a76\u53cc\u529f\u80fdISAC\u5728FBL\u4f53\u5236\u4e0b\u7684\u901a\u4fe1-\u611f\u77e5\u57fa\u672c\u6743\u8861\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u65e0\u504f\u4fe1\u9053\u72b6\u6001\u611f\u77e5\u4f30\u8ba1\u5668\u5efa\u7acb\u611f\u77e5\u8bef\u5dee\u7684\u51e0\u4f55\u5206\u89e3\uff0c\u63a8\u5bfc\u901a\u4fe1\u7801\u7387\u4e0e\u611f\u77e5\u7cbe\u5ea6\u6743\u8861\u7684\u53ef\u8fbe\u6027\u548c\u9006\u754c\uff0c\u5e76\u5efa\u7acb\u4fe1\u9053\u4f30\u8ba1\u7cbe\u5ea6\u4e0e\u5b9e\u9645\u611f\u77e5\u53c2\u6570\u7684\u901a\u7528Cram\u00e9r-Rao\u754c\u8054\u7cfb\u3002", "result": "\u611f\u77e5\u8bef\u5dee\u7531\u4fe1\u566a\u6bd4\u548c\u4fe1\u606f\u7801\u672c\u76f8\u5173\u7ed3\u6784\u5171\u540c\u51b3\u5b9a\uff0c\u63ed\u793a\u4e86\u7801\u672c\u51e0\u4f55\u4e2d\u6d3b\u8dc3\u7528\u6237\u95f4\u7684\u4e92\u76f8\u5173\u5982\u4f55\u7ea6\u675f\u53cc\u529f\u80fdISAC\u6027\u80fd\uff0c\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u5757\u957f\u3001\u5929\u7ebf\u7ef4\u5ea6\u548c\u611f\u77e5\u9700\u6c42\u7684\u5f71\u54cd\u3002", "conclusion": "\u5728FBL\u7ea6\u675f\u4e0b\uff0c\u53cc\u529f\u80fdISAC\u6027\u80fd\u53d7\u7801\u672c\u51e0\u4f55\u76f8\u5173\u7ed3\u6784\u663e\u8457\u5f71\u54cd\uff0c\u5efa\u7acb\u4e86\u901a\u4fe1-\u611f\u77e5\u6743\u8861\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u5b9e\u9645\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2601.04674", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.04674", "abs": "https://arxiv.org/abs/2601.04674", "authors": ["Chengcheng Guo", "Kuo Cai", "Yu Zhou", "Qiang Luo", "Ruiming Tang", "Han Li", "Kun Gai", "Guorui Zhou"], "title": "PROMISE: Process Reward Models Unlock Test-Time Scaling Laws in Generative Recommendations", "comment": null, "summary": "Generative Recommendation has emerged as a promising paradigm, reformulating recommendation as a sequence-to-sequence generation task over hierarchical Semantic IDs. However, existing methods suffer from a critical issue we term Semantic Drift, where errors in early, high-level tokens irreversibly divert the generation trajectory into irrelevant semantic subspaces. Inspired by Process Reward Models (PRMs) that enhance reasoning in Large Language Models, we propose Promise, a novel framework that integrates dense, step-by-step verification into generative models. Promise features a lightweight PRM to assess the quality of intermediate inference steps, coupled with a PRM-guided Beam Search strategy that leverages dense feedback to dynamically prune erroneous branches. Crucially, our approach unlocks Test-Time Scaling Laws for recommender systems: by increasing inference compute, smaller models can match or surpass larger models. Extensive offline experiments and online A/B tests on a large-scale platform demonstrate that Promise effectively mitigates Semantic Drift, significantly improving recommendation accuracy while enabling efficient deployment.", "AI": {"tldr": "Promise\u6846\u67b6\u901a\u8fc7\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u548c\u5f15\u5bfc\u6ce2\u675f\u641c\u7d22\u89e3\u51b3\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684\u8bed\u4e49\u6f02\u79fb\u95ee\u9898\uff0c\u5b9e\u73b0\u63a8\u7406\u65f6\u8ba1\u7b97\u6269\u5c55\uff0c\u8ba9\u5c0f\u6a21\u578b\u8fbe\u5230\u6216\u8d85\u8d8a\u5927\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u65b9\u6cd5\u5b58\u5728\"\u8bed\u4e49\u6f02\u79fb\"\u95ee\u9898\uff0c\u5373\u65e9\u671f\u9ad8\u5c42\u7ea7token\u7684\u9519\u8bef\u4f1a\u4e0d\u53ef\u9006\u8f6c\u5730\u5c06\u751f\u6210\u8f68\u8ff9\u5bfc\u5411\u4e0d\u76f8\u5173\u7684\u8bed\u4e49\u5b50\u7a7a\u95f4\uff0c\u4e25\u91cd\u5f71\u54cd\u63a8\u8350\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faPromise\u6846\u67b6\uff1a1) \u8f7b\u91cf\u7ea7\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u8d28\u91cf\uff1b2) PRM\u5f15\u5bfc\u7684\u6ce2\u675f\u641c\u7d22\u7b56\u7565\uff0c\u5229\u7528\u5bc6\u96c6\u53cd\u9988\u52a8\u6001\u526a\u679d\u9519\u8bef\u5206\u652f\uff1b3) \u5b9e\u73b0\u63a8\u8350\u7cfb\u7edf\u7684\u63a8\u7406\u65f6\u6269\u5c55\u5b9a\u5f8b\u3002", "result": "\u5927\u89c4\u6a21\u5e73\u53f0\u4e0a\u7684\u79bb\u7ebf\u5b9e\u9a8c\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u8868\u660e\uff0cPromise\u6709\u6548\u7f13\u89e3\u8bed\u4e49\u6f02\u79fb\uff0c\u663e\u8457\u63d0\u9ad8\u63a8\u8350\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u90e8\u7f72\uff0c\u5c0f\u6a21\u578b\u901a\u8fc7\u589e\u52a0\u63a8\u7406\u8ba1\u7b97\u53ef\u5339\u914d\u6216\u8d85\u8d8a\u5927\u6a21\u578b\u3002", "conclusion": "Promise\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684\u8bed\u4e49\u6f02\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u5bc6\u96c6\u9010\u6b65\u9a8c\u8bc1\u548c\u63a8\u7406\u65f6\u8ba1\u7b97\u6269\u5c55\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u3001\u9ad8\u6548\u7684\u751f\u6210\u5f0f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05173", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05173", "abs": "https://arxiv.org/abs/2601.05173", "authors": ["Chun Hei Michael Shiu", "Hei Victor Cheng", "Lele Wang"], "title": "Information-Theoretic Limits on Exact Subgraph Alignment Problem", "comment": "This work was presented in part at the 2025 IEEE International Symposium on Information Theory and submitted in part to the 2026 IEEE International Symposium on Information Theory", "summary": "The graph alignment problem aims to identify the vertex correspondence between two correlated graphs. Most existing studies focus on the scenario in which the two graphs share the same vertex set. However, in many real-world applications, such as computer vision, social network analysis, and bioinformatics, the task often involves locating a small graph pattern within a larger graph. Existing graph alignment algorithms and analysis cannot directly address these scenarios because they are not designed to identify the specific subset of vertices where the small graph pattern resides within the larger graph. Motivated by this limitation, we introduce the subgraph alignment problem, which seeks to recover both the vertex set and/or the vertex correspondence of a small graph pattern embedded in a larger graph. In the special case where the small graph pattern is an induced subgraph of the larger graph and both the vertex set and correspondence are to be recovered, the problem reduces to the subgraph isomorphism problem, which is NP-complete in the worst case. In this paper, we formally formulate the subgraph alignment problem by proposing the Erdos-Renyi subgraph pair model together with some appropriate recovery criterion. We then establish almost-tight information-theoretic results for the subgraph alignment problem and present some novel approaches for the analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5b50\u56fe\u5bf9\u9f50\u95ee\u9898\uff0c\u65e8\u5728\u4ece\u5927\u56fe\u4e2d\u6062\u590d\u5c0f\u56fe\u6a21\u5f0f\u7684\u9876\u70b9\u96c6\u548c\u5bf9\u5e94\u5173\u7cfb\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u56fe\u5bf9\u9f50\u7b97\u6cd5\u65e0\u6cd5\u76f4\u63a5\u5904\u7406\u5b50\u56fe\u5b9a\u4f4d\u573a\u666f\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u56fe\u5bf9\u9f50\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4e24\u4e2a\u56fe\u5171\u4eab\u76f8\u540c\u9876\u70b9\u96c6\u7684\u60c5\u51b5\uff0c\u4f46\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u548c\u751f\u7269\u4fe1\u606f\u5b66\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u7ecf\u5e38\u9700\u8981\u5728\u5927\u56fe\u4e2d\u5b9a\u4f4d\u5c0f\u56fe\u6a21\u5f0f\u3002\u73b0\u6709\u7b97\u6cd5\u65e0\u6cd5\u76f4\u63a5\u5904\u7406\u8fd9\u79cd\u5b50\u56fe\u5b9a\u4f4d\u573a\u666f\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u5b50\u56fe\u5bf9\u9f50\u95ee\u9898\u7684\u6b63\u5f0f\u8868\u8ff0\uff0c\u5f15\u5165\u4e86Erdos-Renyi\u5b50\u56fe\u5bf9\u6a21\u578b\uff0c\u5e76\u5efa\u7acb\u4e86\u9002\u5f53\u7684\u91cd\u5efa\u51c6\u5219\u3002\u5efa\u7acb\u4e86\u51e0\u4e4e\u4e25\u683c\u7684\u4fe1\u606f\u8bba\u7ed3\u679c\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e9b\u65b0\u9896\u7684\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u5efa\u7acb\u4e86\u5b50\u56fe\u5bf9\u9f50\u95ee\u9898\u7684\u51e0\u4e4e\u4e25\u683c\u7684\u4fe1\u606f\u8bba\u7ed3\u679c\uff0c\u8868\u660e\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u53ef\u4ee5\u6062\u590d\u5b50\u56fe\u7684\u9876\u70b9\u96c6\u548c\u5bf9\u5e94\u5173\u7cfb\u3002\u5f53\u5c0f\u56fe\u6a21\u5f0f\u662f\u5927\u56fe\u7684\u8bf1\u5bfc\u5b50\u56fe\u4e14\u9700\u8981\u540c\u65f6\u6062\u590d\u9876\u70b9\u96c6\u548c\u5bf9\u5e94\u5173\u7cfb\u65f6\uff0c\u95ee\u9898\u7b80\u5316\u4e3aNP\u5b8c\u5168\u7684\u56fe\u540c\u6784\u95ee\u9898\u3002", "conclusion": "\u5b50\u56fe\u5bf9\u9f50\u95ee\u9898\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u56fe\u6a21\u5f0f\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u586b\u8865\u4e86\u73b0\u6709\u56fe\u5bf9\u9f50\u7814\u7a76\u7684\u7a7a\u767d\u3002\u63d0\u51fa\u7684\u4fe1\u606f\u8bba\u7ed3\u679c\u4e3a\u8be5\u95ee\u9898\u7684\u53ef\u89e3\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u4e3a\u672a\u6765\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2601.04918", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04918", "abs": "https://arxiv.org/abs/2601.04918", "authors": ["Ziwen Wang", "Shangshang Yang", "Xiaoshan Yu", "Haiping Ma", "Xingyi Zhang"], "title": "Breaking Robustness Barriers in Cognitive Diagnosis: A One-Shot Neural Architecture Search Perspective", "comment": "KDD2026, 15 pages", "summary": "With the advancement of network technologies, intelligent tutoring systems (ITS) have emerged to deliver increasingly precise and tailored personalized learning services. Cognitive diagnosis (CD) has emerged as a core research task in ITS, aiming to infer learners' mastery of specific knowledge concepts by modeling the mapping between learning behavior data and knowledge states. However, existing research prioritizes model performance enhancement while neglecting the pervasive noise contamination in observed response data, significantly hindering practical deployment. Furthermore, current cognitive diagnosis models (CDMs) rely heavily on researchers' domain expertise for structural design, which fails to exhaustively explore architectural possibilities, thus leaving model architectures' full potential untapped. To address this issue, we propose OSCD, an evolutionary multi-objective One-Shot neural architecture search method for Cognitive Diagnosis, designed to efficiently and robustly improve the model's capability in assessing learner proficiency. Specifically, OSCD operates through two distinct stages: training and searching. During the training stage, we construct a search space encompassing diverse architectural combinations and train a weight-sharing supernet represented via the complete binary tree topology, enabling comprehensive exploration of potential architectures beyond manual design priors. In the searching stage, we formulate the optimal architecture search under heterogeneous noise scenarios as a multi-objective optimization problem (MOP), and develop an optimization framework integrating a Pareto-optimal solution search strategy with cross-scenario performance evaluation for resolution. Extensive experiments on real-world educational datasets validate the effectiveness and robustness of the optimal architectures discovered by our OSCD model for CD tasks.", "AI": {"tldr": "\u63d0\u51faOSCD\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fdb\u5316\u591a\u76ee\u6807\u4e00\u6b21\u6027\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff0c\u4e3a\u8ba4\u77e5\u8bca\u65ad\u4efb\u52a1\u5bfb\u627e\u6700\u4f18\u6a21\u578b\u67b6\u6784\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u6570\u636e\u566a\u58f0\u548c\u4f9d\u8d56\u4e13\u5bb6\u8bbe\u8ba1\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8ba4\u77e5\u8bca\u65ad\u7814\u7a76\u8fc7\u4e8e\u5173\u6ce8\u6a21\u578b\u6027\u80fd\u63d0\u5347\uff0c\u5ffd\u89c6\u4e86\u89c2\u6d4b\u54cd\u5e94\u6570\u636e\u4e2d\u666e\u904d\u5b58\u5728\u7684\u566a\u58f0\u6c61\u67d3\u95ee\u9898\uff0c\u8fd9\u4e25\u91cd\u963b\u788d\u4e86\u5b9e\u9645\u90e8\u7f72\u3002\u540c\u65f6\uff0c\u5f53\u524d\u8ba4\u77e5\u8bca\u65ad\u6a21\u578b\u4e25\u91cd\u4f9d\u8d56\u7814\u7a76\u4eba\u5458\u7684\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u8fdb\u884c\u7ed3\u6784\u8bbe\u8ba1\uff0c\u65e0\u6cd5\u5145\u5206\u63a2\u7d22\u67b6\u6784\u53ef\u80fd\u6027\uff0c\u672a\u80fd\u53d1\u6325\u6a21\u578b\u67b6\u6784\u7684\u5168\u90e8\u6f5c\u529b\u3002", "method": "\u63d0\u51faOSCD\u65b9\u6cd5\uff0c\u5305\u542b\u8bad\u7ec3\u548c\u641c\u7d22\u4e24\u4e2a\u9636\u6bb5\uff1a1\uff09\u8bad\u7ec3\u9636\u6bb5\u6784\u5efa\u5305\u542b\u591a\u6837\u5316\u67b6\u6784\u7ec4\u5408\u7684\u641c\u7d22\u7a7a\u95f4\uff0c\u8bad\u7ec3\u57fa\u4e8e\u5b8c\u5168\u4e8c\u53c9\u6811\u62d3\u6251\u7684\u6743\u91cd\u5171\u4eab\u8d85\u7f51\u7edc\uff1b2\uff09\u641c\u7d22\u9636\u6bb5\u5c06\u5f02\u6784\u566a\u58f0\u573a\u666f\u4e0b\u7684\u6700\u4f18\u67b6\u6784\u641c\u7d22\u5efa\u6a21\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u5f00\u53d1\u96c6\u6210\u5e15\u7d2f\u6258\u6700\u4f18\u89e3\u641c\u7d22\u7b56\u7565\u548c\u8de8\u573a\u666f\u6027\u80fd\u8bc4\u4f30\u7684\u4f18\u5316\u6846\u67b6\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6559\u80b2\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86OSCD\u6a21\u578b\u53d1\u73b0\u7684\u8ba4\u77e5\u8bca\u65ad\u4efb\u52a1\u6700\u4f18\u67b6\u6784\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "OSCD\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u4e14\u9c81\u68d2\u5730\u63d0\u5347\u6a21\u578b\u8bc4\u4f30\u5b66\u4e60\u8005\u719f\u7ec3\u5ea6\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8ba4\u77e5\u8bca\u65ad\u6a21\u578b\u5ffd\u89c6\u6570\u636e\u566a\u58f0\u548c\u4f9d\u8d56\u4e13\u5bb6\u8bbe\u8ba1\u7684\u95ee\u9898\uff0c\u4e3a\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u4e2d\u7684\u8ba4\u77e5\u8bca\u65ad\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05081", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05081", "abs": "https://arxiv.org/abs/2601.05081", "authors": ["Franziska Pradel", "Fabian Haak", "Sven-Oliver Proksch", "Philipp Schaer"], "title": "Dynamics in Search Engine Query Suggestions for European Politicians", "comment": "11 pages; 3 figures; 6 tables; published as a conference paper at WebSci '24 (May 21-24, 2024, Stuttgart, Germany)", "summary": "Search engines are commonly used for online political information seeking. Yet, it remains unclear how search query suggestions for political searches that reflect the latent interest of internet users vary across countries and over time. We provide a systematic analysis of Google search engine query suggestions for European and national politicians. Using an original dataset of search query suggestions for European politicians collected in ten countries, we find that query suggestions are less stable over time in politicians' countries of origin, when the politicians hold a supranational role, and for female politicians. Moreover, query suggestions for political leaders and male politicians are more similar across countries. We conclude by discussing possible future directions for studying information search about European politicians in online search.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u6b27\u6d32\u5404\u56fdGoogle\u641c\u7d22\u4e2d\u653f\u6cbb\u4eba\u7269\u67e5\u8be2\u5efa\u8bae\u7684\u5dee\u5f02\uff0c\u53d1\u73b0\u67e5\u8be2\u5efa\u8bae\u5728\u653f\u6cbb\u4eba\u7269\u672c\u56fd\u3001\u62c5\u4efb\u8d85\u56fd\u5bb6\u89d2\u8272\u53ca\u5973\u6027\u653f\u6cbb\u4eba\u7269\u4e2d\u66f4\u4e0d\u7a33\u5b9a\uff0c\u800c\u653f\u6cbb\u9886\u8896\u548c\u7537\u6027\u653f\u6cbb\u4eba\u7269\u7684\u67e5\u8be2\u5efa\u8bae\u5728\u5404\u56fd\u95f4\u66f4\u76f8\u4f3c\u3002", "motivation": "\u641c\u7d22\u5f15\u64ce\u662f\u83b7\u53d6\u5728\u7ebf\u653f\u6cbb\u4fe1\u606f\u7684\u4e3b\u8981\u6e20\u9053\uff0c\u4f46\u4eba\u4eec\u5bf9\u653f\u6cbb\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u5982\u4f55\u53cd\u6620\u4e92\u8054\u7f51\u7528\u6237\u7684\u6f5c\u5728\u5174\u8da3\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u5efa\u8bae\u5728\u4e0d\u540c\u56fd\u5bb6\u548c\u65f6\u95f4\u4e0a\u7684\u53d8\u5316\u4e86\u89e3\u4e0d\u8db3\u3002\u7279\u522b\u662f\u9488\u5bf9\u6b27\u6d32\u653f\u6cbb\u4eba\u7269\u7684\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u7f3a\u4e4f\u7cfb\u7edf\u6027\u5206\u6790\u3002", "method": "\u4f7f\u7528\u5728\u5341\u4e2a\u56fd\u5bb6\u6536\u96c6\u7684\u6b27\u6d32\u653f\u6cbb\u4eba\u7269\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u539f\u59cb\u6570\u636e\u96c6\uff0c\u5206\u6790\u67e5\u8be2\u5efa\u8bae\u7684\u7a33\u5b9a\u6027\u3002\u7814\u7a76\u8003\u5bdf\u4e86\u67e5\u8be2\u5efa\u8bae\u5728\u653f\u6cbb\u4eba\u7269\u672c\u56fd\u3001\u8d85\u56fd\u5bb6\u89d2\u8272\u548c\u6027\u522b\u7b49\u56e0\u7d20\u4e0b\u7684\u65f6\u95f4\u7a33\u5b9a\u6027\uff0c\u4ee5\u53ca\u653f\u6cbb\u9886\u8896\u548c\u7537\u6027\u653f\u6cbb\u4eba\u7269\u67e5\u8be2\u5efa\u8bae\u7684\u8de8\u56fd\u76f8\u4f3c\u6027\u3002", "result": "\u67e5\u8be2\u5efa\u8bae\u5728\u653f\u6cbb\u4eba\u7269\u672c\u56fd\u3001\u62c5\u4efb\u8d85\u56fd\u5bb6\u89d2\u8272\u7684\u653f\u6cbb\u4eba\u7269\u4ee5\u53ca\u5973\u6027\u653f\u6cbb\u4eba\u7269\u4e2d\u66f4\u4e0d\u7a33\u5b9a\u3002\u76f8\u53cd\uff0c\u653f\u6cbb\u9886\u8896\u548c\u7537\u6027\u653f\u6cbb\u4eba\u7269\u7684\u67e5\u8be2\u5efa\u8bae\u5728\u4e0d\u540c\u56fd\u5bb6\u95f4\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u76f8\u4f3c\u6027\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u653f\u6cbb\u4eba\u7269\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u7684\u65f6\u7a7a\u53d8\u5316\u6a21\u5f0f\uff0c\u4e3a\u7406\u89e3\u5728\u7ebf\u653f\u6cbb\u4fe1\u606f\u641c\u7d22\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002\u672a\u6765\u7814\u7a76\u53ef\u8fdb\u4e00\u6b65\u63a2\u8ba8\u6b27\u6d32\u653f\u6cbb\u4eba\u7269\u5728\u7ebf\u641c\u7d22\u4fe1\u606f\u7684\u76f8\u5173\u65b9\u5411\u3002"}}
{"id": "2601.05200", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05200", "abs": "https://arxiv.org/abs/2601.05200", "authors": ["Silvio Martinico", "Franco Maria Nardini", "Cosimo Rulli", "Rossano Venturini"], "title": "Multivector Reranking in the Era of Strong First-Stage Retrievers", "comment": "17 pages, 2 figures, ECIR 2026", "summary": "Learned multivector representations power modern search systems with strong retrieval effectiveness, but their real-world use is limited by the high cost of exhaustive token-level retrieval. Therefore, most systems adopt a \\emph{gather-and-refine} strategy, where a lightweight gather phase selects candidates for full scoring. However, this approach requires expensive searches over large token-level indexes and often misses the documents that would rank highest under full similarity. In this paper, we reproduce several state-of-the-art multivector retrieval methods on two publicly available datasets, providing a clear picture of the current multivector retrieval field and observing the inefficiency of token-level gathering. Building on top of that, we show that replacing the token-level gather phase with a single-vector document retriever -- specifically, a learned sparse retriever (LSR) -- produces a smaller and more semantically coherent candidate set. This recasts the gather-and-refine pipeline into the well-established two-stage retrieval architecture. As retrieval latency decreases, query encoding with two neural encoders becomes the dominant computational bottleneck. To mitigate this, we integrate recent inference-free LSR methods, demonstrating that they preserve the retrieval effectiveness of the dual-encoder pipeline while substantially reducing query encoding time. Finally, we investigate multiple reranking configurations that balance efficiency, memory, and effectiveness, and we introduce two optimization techniques that prune low-quality candidates early. Empirical results show that these techniques improve retrieval efficiency by up to 1.8$\\times$ with no loss in quality. Overall, our two-stage approach achieves over $24\\times$ speedup over the state-of-the-art multivector retrieval systems, while maintaining comparable or superior retrieval quality.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u68c0\u7d22\u67b6\u6784\uff0c\u7528\u5355\u5411\u91cf\u68c0\u7d22\u5668\u66ff\u4ee3\u591a\u5411\u91cf\u68c0\u7d22\u7684token\u7ea7\u6536\u96c6\u9636\u6bb5\uff0c\u7ed3\u5408\u63a8\u7406\u65e0\u5173\u7684\u7a00\u758f\u68c0\u7d22\u548c\u5019\u9009\u526a\u679d\u6280\u672f\uff0c\u5b9e\u73b024\u500d\u52a0\u901f\u4e14\u4fdd\u6301\u68c0\u7d22\u8d28\u91cf", "motivation": "\u591a\u5411\u91cf\u8868\u793a\u68c0\u7d22\u6548\u679c\u597d\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709gather-and-refine\u7b56\u7565\u9700\u8981\u6602\u8d35\u7684token\u7ea7\u7d22\u5f15\u641c\u7d22\u4e14\u53ef\u80fd\u9519\u8fc7\u6700\u4f18\u6587\u6863\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u68c0\u7d22\u65b9\u6848", "method": "1) \u7528\u5b66\u4e60\u7a00\u758f\u68c0\u7d22\u5668(LSR)\u66ff\u4ee3token\u7ea7\u6536\u96c6\u9636\u6bb5\uff1b2) \u96c6\u6210\u63a8\u7406\u65e0\u5173LSR\u65b9\u6cd5\u51cf\u5c11\u67e5\u8be2\u7f16\u7801\u65f6\u95f4\uff1b3) \u5f15\u5165\u4e24\u79cd\u65e9\u671f\u526a\u679d\u4f4e\u8d28\u91cf\u5019\u9009\u7684\u4f18\u5316\u6280\u672f", "result": "\u4e24\u9636\u6bb5\u65b9\u6cd5\u6bd4\u73b0\u6709\u6700\u4f73\u591a\u5411\u91cf\u68c0\u7d22\u7cfb\u7edf\u5feb24\u500d\u4ee5\u4e0a\uff0c\u68c0\u7d22\u6548\u7387\u63d0\u53471.8\u500d\u4e14\u65e0\u8d28\u91cf\u635f\u5931\uff0c\u4fdd\u6301\u53ef\u6bd4\u6216\u66f4\u4f18\u7684\u68c0\u7d22\u8d28\u91cf", "conclusion": "\u5c06\u591a\u5411\u91cf\u68c0\u7d22\u91cd\u65b0\u6784\u5efa\u4e3a\u4e24\u9636\u6bb5\u67b6\u6784\uff0c\u7ed3\u5408\u9ad8\u6548\u5355\u5411\u91cf\u68c0\u7d22\u548c\u4f18\u5316\u6280\u672f\uff0c\u80fd\u5728\u663e\u8457\u63d0\u5347\u6548\u7387\u7684\u540c\u65f6\u4fdd\u6301\u68c0\u7d22\u6548\u679c\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u53ef\u884c\u65b9\u6848"}}
