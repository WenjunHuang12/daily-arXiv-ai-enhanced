<div id=toc></div>

# Table of Contents

- [cs.GT](#cs.GT) [Total: 9]
- [cs.DB](#cs.DB) [Total: 9]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.DS](#cs.DS) [Total: 12]
- [cs.IR](#cs.IR) [Total: 29]
- [cs.IT](#cs.IT) [Total: 10]


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [1] [Stability in Online Assignment Games](https://arxiv.org/abs/2510.09814)
*Emile Martinez,Felipe Garrido-Lucero,Umberto Grandi*

Main category: cs.GT

TL;DR: 该论文研究了在线分配博弈中次优匹配下的不稳定性度量，建立了这些度量与匹配最优性比率之间的联系，并分析了随机算法在在线分配博弈中的稳定性表现。


<details>
  <summary>Details</summary>
Motivation: 在实践中，稳定分配很少能实现，因为匹配往往是次优的，特别是在在线环境中，代理顺序到达市场。

Method: 引入并比较了两种互补的次优匹配分配不稳定性度量，建立了它们与基础匹配最优性比率的联系。

Result: 使用该框架研究了随机算法在在线分配博弈中的稳定性表现。

Conclusion: 为在线分配博弈中次优匹配下的稳定性分析提供了理论框架和度量方法。

Abstract: The assignment game models a housing market where buyers and sellers are
matched, and transaction prices are set so that the resulting allocation is
stable. Shapley and Shubik showed that every stable allocation is necessarily
built on a maximum social welfare matching. In practice, however, stable
allocations are rarely attainable, as matchings are often sub-optimal,
particularly in online settings where eagents arrive sequentially to the
market. In this paper, we introduce and compare two complementary measures of
instability for allocations with sub-optimal matchings, establish their
connections to the optimality ratio of the underlying matching, and use this
framework to study the stability performances of randomized algorithms in
online assignment games.

</details>


### [2] [Proportional and Pareto-Optimal Allocation of Chores with Subsidy](https://arxiv.org/abs/2510.10335)
*Jugal Garg,Eklavya Sharma,Xiaowei Wu*

Main category: cs.GT

TL;DR: 本文提出了一种多项式时间算法，在保证比例公平性的同时实现帕累托最优，且所需补贴总额不超过n/3 - 1/6。相比之前的工作，该算法更简单且保证了经济效率。


<details>
  <summary>Details</summary>
Motivation: 解决不可分割杂务在带权重代理间的公平分配问题。由于比例分配可能不存在，需要使用补贴来确保比例公平性，同时希望最小化总补贴并保证经济效率。

Method: 首先计算比例公平的竞争均衡，然后应用基于最小痛苦每美元边的舍入程序。

Result: 算法在多项式时间内实现了比例公平性和帕累托最优性，所需总补贴不超过n/3 - 1/6。

Conclusion: 提出的算法比现有方法更简单，同时保证了经济效率和公平性，为不可分割杂务的公平分配提供了有效的解决方案。

Abstract: We consider the problem of allocating $m$ indivisible chores among $n$ agents
with possibly different weights, aiming for a solution that is both fair and
efficient. Specifically, we focus on the classic fairness notion of
proportionality and efficiency notion of Pareto-optimality. Since proportional
allocations may not always exist in this setting, we allow the use of subsidies
(monetary compensation to agents) to ensure agents are
proportionally-satisfied, and aim to minimize the total subsidy required. Wu
and Zhou (WINE 2024) showed that when each chore has disutility at most 1, a
total subsidy of at most $n/3 - 1/6$ is sufficient to guarantee
proportionality. However, their approach is based on a complex technique, which
does not guarantee economic efficiency - a key desideratum in fair division.
  In this work, we give a polynomial-time algorithm that achieves the same
subsidy bound while also ensuring Pareto-optimality. Moreover, both our
algorithm and its analysis are significantly simpler than those of Wu and Zhou
(WINE 2024). Our approach first computes a proportionally-fair competitive
equilibrium, and then applies a rounding procedure guided by
minimum-pain-per-buck edges.

</details>


### [3] [Improved Maximin Share Guarantee for Additive Valuations](https://arxiv.org/abs/2510.10423)
*Ehsan Heidari,Alireza Kaviani,Masoud Seddighin,AmirMohammad Shahrezaei*

Main category: cs.GT

TL;DR: 本文改进了不可分割物品公平分配中最大化份额(MMS)的近似保证，将最佳已知近似比从3/4+3/3836提高到10/13。


<details>
  <summary>Details</summary>
Motivation: 最大化份额是公平分配中最突出的基于份额的公平概念。虽然已知某些实例无法保证优于1-1/n^4的近似比，但现有最佳算法只能达到3/4+3/3836的近似保证，存在改进空间。

Method: 未在摘要中明确说明具体方法，但通过改进算法设计来提高MMS的近似保证。

Result: 成功将MMS的最佳已知近似保证从3/4+3/3836提高到10/13，显著缩小了理论界限与实际可实现保证之间的差距。

Conclusion: 这项工作在不可分割物品的公平分配领域取得了重要进展，为最大化份额概念提供了更好的近似算法保证。

Abstract: The maximin share ($\textsf{MMS}$) is the most prominent share-based fairness
notion in the fair allocation of indivisible goods. Recent years have seen
significant efforts to improve the approximation guarantees for $\textsf{MMS}$
for different valuation classes, particularly for additive valuations. For the
additive setting, it has been shown that for some instances, no allocation can
guarantee a factor better than $1-\tfrac{1}{n^4}$ of maximin share value to all
agents. However, the best currently known algorithm achieves an approximation
guarantee of $\tfrac{3}{4} + \tfrac{3}{3836}$ for $\textsf{MMS}$. In this work,
we narrow this gap and improve the best-known approximation guarantee for
$\textsf{MMS}$ to $\tfrac{10}{13}$.

</details>


### [4] [Fair Assignment of Indivisible Chores to Asymmetric Agents](https://arxiv.org/abs/2510.10698)
*Masoud Seddighin,Saeed Seddighin*

Main category: cs.GT

TL;DR: 本文改进了不可分割家务分配问题的上界，从O(log n)-WMMS保证提升到常数-WMMS保证（具体为20-WMMS）。


<details>
  <summary>Details</summary>
Motivation: 在代理人具有不同权益的加权最大最小份额(WMMS)背景下，虽然对称设置下常数-MMS分配存在，但不同权益的情况更复杂。对于不可分割物品，n-WMMS是最佳保证；对于家务，之前已知存在O(log n)-WMMS分配，本文旨在改进这一上界。

Method: 未在摘要中详细说明具体方法，但提到通过更严格的分析可以获得略好的边界。

Result: 证明了20-WMMS分配的存在性，将不可分割家务分配的上界从对数级别改进到常数级别。

Conclusion: 对于具有不同权益的代理人，不可分割家务分配可以实现常数-WMMS保证，显著改进了之前的结果。

Abstract: We consider the problem of assigning indivisible chores to agents with
different entitlements in the maximin share value (\MMS) context. While
constant-\MMS\ allocations/assignments are guaranteed to exist for both goods
and chores in the symmetric setting, the situation becomes much more complex
when agents have different entitlements. For the allocation of indivisible
goods, it has been proven that an $n$-\WMMS\ (weighted \MMS) guarantee is the
best one can hope for. For indivisible chores, however, it was recently
discovered that an $O(\log n)$-\WMMS\ assignment is guaranteed to exist. In
this work, we improve this upper bound to a constant-\WMMS\
guarantee.\footnote{We prove the existence of a 20-\WMMS\ assignment, but we
did not attempt to optimize the constant factor. We believe our methods already
yield a slightly better bound with a tighter analysis.}

</details>


### [5] [Achieving Coordination in Non-Cooperative Joint Replenishment Games](https://arxiv.org/abs/2510.10929)
*Junjie Luo,Changjun Wang*

Main category: cs.GT

TL;DR: 本文从非合作博弈论角度分析无限期确定性联合补货模型，研究成本分配规则设计，以最小化长期平均系统成本，同时考虑零售商独立选择补货间隔以最小化自身成本。


<details>
  <summary>Details</summary>
Motivation: 研究联合补货模型中的成本分配问题，旨在设计能够激励零售商合作并降低系统总成本的分配规则，同时考虑零售商的自私行为。

Method: 引入一类成本分配规则，按预定义权重在相关零售商间分配主要设置成本。建立代理更好响应的单调性，证明支付主导纯纳什均衡的存在性。

Result: 发现利用零售商自身持有成本率的规则可实现接近最优的稳定性价格比（PoS）为1.25，另一无需零售商私有信息的规则也能获得有利的PoS。

Conclusion: 提出的成本分配规则能有效协调零售商行为，在存在自私决策的情况下实现接近最优的系统性能。

Abstract: We analyze an infinite-horizon deterministic joint replenishment model from a
non-cooperative game-theoretical approach. In this model, a group of retailers
can choose to jointly place an order, which incurs a major setup cost
independent of the group, and a minor setup cost for each retailer.
Additionally, each retailer is associated with a holding cost. Our objective is
to design cost allocation rules that minimize the long-run average system cost
while accounting for the fact that each retailer independently selects its
replenishment interval to minimize its own cost. We introduce a class of cost
allocation rules that distribute the major setup cost among the associated
retailers in proportion to their predefined weights. For these rules, we
establish a monotonicity property of agent better responses, which enables us
to prove the existence of a payoff dominant pure Nash equilibrium that can also
be computed efficiently. We then analyze the efficiency of these equilibria by
examining the price of stability (PoS), the ratio of the best Nash
equilibrium's system cost to the social optimum, across different information
settings. In particular, our analysis reveals that one rule, which leverages
retailers' own holding cost rates, achieves a near-optimal PoS of 1.25, while
another rule that does not require access to retailers' private information
also yields a favorable PoS.

</details>


### [6] [Likes, Budgets, and Equilibria: Designing Contests for Socially Optimal Advertising](https://arxiv.org/abs/2510.11253)
*Sayantika Mandal,Harman Agrawal,Swaprava Nath*

Main category: cs.GT

TL;DR: 该论文研究企业在社交网络上的广告竞争博弈，提出一个双时间尺度模型来分析企业如何分配预算以最大化品牌知名度，证明了最佳响应动态会收敛到纯策略纳什均衡，并设计了能使纳什均衡唯一且社会福利最大化的竞赛成功函数。


<details>
  <summary>Details</summary>
Motivation: 企业在社交网络上进行广告竞争时，需要决定如何通过网络节点分配预算来最大化品牌知名度，这形成了一个竞争性博弈问题。

Method: 提出双时间尺度决策模型：顶点间的通信发生在快速时间尺度，企业策略更新发生在慢速时间尺度。在标准条件下分析最佳响应动态的收敛性。

Result: 证明了最佳响应动态会收敛到纯策略纳什均衡，但这些均衡可能偏离社会最优。设计了特定的竞赛成功函数，使得纳什均衡唯一且社会福利最大化。

Conclusion: 对于现实场景，所设计的竞赛成功函数表现良好，为竞赛设计者（如监管机构、社交网络提供商）提供了实用的解决方案。

Abstract: Firms (businesses, service providers, entertainment organizations, political
parties, etc.) advertise on social networks to draw people's attention and
improve their awareness of the brands of the firms. In all such cases, the
competitive nature of their engagements gives rise to a game where the firms
need to decide how to distribute their budget over the agents on a network to
maximize their brand's awareness. The firms (players) therefore need to
optimize how much budget they should put on the vertices of the network so that
the spread improves via direct (via advertisements or free promotional offers)
and indirect marketing (words-of-mouth). We propose a two-timescale model of
decisions where the communication between the vertices happen in a faster
timescale and the strategy update of the firms happen in a slower timescale. We
show that under fairly standard conditions, the best response dynamics of the
firms converge to a pure strategy Nash equilibrium. However, such equilibria
can be away from a socially optimal one. We provide a characterization of the
contest success functions and provide examples for the designers of such
contests (e.g., regulators, social network providers, etc.) such that the Nash
equilibrium becomes unique and social welfare maximizing. Our experiments show
that for realistic scenarios, such contest success functions perform fairly
well.

</details>


### [7] [Temporal Cooperative Games](https://arxiv.org/abs/2510.11255)
*Ashwin Goyal,Drashthi Doshi,Swaprava Nath*

Main category: cs.GT

TL;DR: 本文提出了时序合作博弈(TCG)框架，其中联盟价值取决于代理加入的顺序而非仅代理集合。定义了三个关键属性(I4OA、OIR、SE)，并发现满足这些属性的奖励分配机制与Shapley值的自然扩展存在根本冲突。


<details>
  <summary>Details</summary>
Motivation: 传统合作博弈假设联盟价值仅取决于代理集合，但实践中价值可能受代理加入顺序影响。需要重新思考时序场景下的博弈理论框架。

Method: 引入时序合作博弈(TCG)概念，定义三个关键属性：最优到达激励(I4OA)、在线个体理性(OIR)和序列效率(SE)。构建Shapley值在时序场景下的两种自然扩展变体。

Result: 识别了满足I4OA、OIR、SE三属性的奖励分配机制类，发现这些机制与Shapley值的时序扩展存在根本性冲突，即使在凸和简单TCG等受限类别中也是如此。

Conclusion: 当代理顺序到达时，满足理想时序属性的奖励分配机制必须与Shapley启发的机制本质上不同，这为TCG中定义公平高效解概念提出了新问题。

Abstract: Classical cooperative game theory assumes that the worth of a coalition
depends only on the set of agents involved, but in practice, it may also depend
on the order in which agents arrive. Motivated by such scenarios, we introduce
temporal cooperative games (TCG), where the worth $v$ becomes a function of the
sequence of agents $\pi$ rather than just the set $S$. This shift calls for
rethinking the underlying axioms. A key property in this temporal framework is
the incentive for optimal arrival (I4OA), which encourages agents to join in
the order maximizing total worth. Alongside, we define two additional
properties: online individual rationality (OIR), incentivizing earlier agents
to invite more participants, and sequential efficiency (SE), ensuring that the
total worth of any sequence is fully distributed among its agents. We identify
a class of reward-sharing mechanisms uniquely characterized by these three
properties. The classical Shapley value does not directly apply here, so we
construct its natural analogs in two variants: the sequential world, where
rewards are defined for each sequence-player pair, and the extended world,
where rewards are defined for each player alone. Properties of efficiency,
additivity, and null player uniquely determine these Shapley analogs in both
worlds. Importantly, the Shapley analogs are disjoint from mechanisms
satisfying I4OA, OIR, and SE, and this conflict persists even for restricted
classes such as convex and simple TCGs. Our findings thus uncover a fundamental
tension: when players arrive sequentially, reward-sharing mechanisms satisfying
desirable temporal properties must inherently differ from Shapley-inspired
ones, opening new questions for defining fair and efficient solution concepts
in TCGs.

</details>


### [8] [On the Complexity of Stationary Nash Equilibria in Discounted Perfect Information Stochastic Games](https://arxiv.org/abs/2510.11550)
*Kristoffer Arnsfelt Hansen,Xinhao Nie*

Main category: cs.GT

TL;DR: 该论文研究了完美信息随机博弈中计算平稳纳什均衡的计算复杂度问题，证明了两人博弈是PPAD完全问题，并给出了更简单的PPAD难度证明。对于三人博弈，证明了有理值平稳纳什均衡不一定存在，并证明了四人博弈中计算平稳纳什均衡是SqrtSum困难的。


<details>
  <summary>Details</summary>
Motivation: 研究完美信息随机博弈中计算平稳纳什均衡的计算复杂度，旨在精确分类该问题的复杂度类别，特别是针对不同玩家数量的博弈。

Method: 使用计算复杂度理论方法，包括PPAD完全性证明、构造反例证明有理值均衡不存在性，以及SqrtSum难度证明。

Result: 证明了两人完美信息随机博弈中计算平稳纳什均衡是PPAD完全问题；构造了三人博弈实例表明有理值平稳纳什均衡不一定存在；证明了四人博弈中该问题是SqrtSum困难的。

Conclusion: 完美信息随机博弈中计算平稳纳什均衡的复杂度随玩家数量增加而显著提高，从两人博弈的PPAD完全性到四人博弈的SqrtSum困难性。

Abstract: We study the problem of computing stationary Nash equilibria in discounted
perfect information stochastic games from the viewpoint of computational
complexity. For two-player games we prove the problem to be in PPAD, which
together with a previous PPAD-hardness result precisely classifies the problem
as PPAD-complete. In addition to this we give an improved and simpler
PPAD-hardness proof for computing a stationary epsilon-Nash equilibrium. For
3-player games we construct games showing that rational-valued stationary Nash
equilibria are not guaranteed to exist, and we use these to prove
SqrtSum-hardness of computing a stationary Nash equilibrium in 4-player games.

</details>


### [9] [Multiwinner Voting with Interval Preferences under Incomplete Information](https://arxiv.org/abs/2510.11625)
*Drew Springham,Edith Elkind,Bart de Keijzer,Maria Polukarov*

Main category: cs.GT

TL;DR: 该论文研究多赢家批准选举中的公平性保证问题，提出了一种在低通信成本下计算满足PJR+公平性要求的委员会的算法。


<details>
  <summary>Details</summary>
Motivation: 在多候选人选举中，选民可能难以确定对所有候选人的偏好，因此需要探索在减少通信的情况下能提供哪些公平性保证。

Method: 提出概率偏好模型，将选民分为σ个组，每组关联一个在实数区间上的分布，选民从所属组的分布中抽取批准区间的端点。设计了查询选民偏好的算法来计算满足PJR+的委员会。

Result: 算法在期望上对每个选民进行O(log(σ·k))次查询，其中k是委员会规模。

Conclusion: 该算法能够在低通信成本下有效计算满足PJR+公平性要求的委员会。

Abstract: In multiwinner approval elections with many candidates, voters may struggle
to determine their preferences over the entire slate of candidates. It is
therefore of interest to explore which (if any) fairness guarantees can be
provided under reduced communication. In this paper, we consider voters with
one-dimensional preferences: voters and candidates are associated with points
in $\mathbb R$, and each voter's approval set forms an interval of $\mathbb R$.
We put forward a probabilistic preference model, where the voter set consists
of $\sigma$ different groups; each group is associated with a distribution over
an interval of $\mathbb R$, so that each voter draws the endpoints of her
approval interval from the distribution associated with her group. We present
an algorithm for computing committees that provide Proportional Justified
Representation + (PJR+), which proceeds by querying voters' preferences, and
show that, in expectation, it makes $\mathcal{O}(\log( \sigma\cdot k))$ queries
per voter, where $k$ is the desired committee size.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [10] [Real-Time Health Analytics Using Ontology-Driven Complex Event Processing and LLM Reasoning: A Tuberculosis Case Study](https://arxiv.org/abs/2510.09646)
*Ritesh Chandra,Sonali Agarwal,Navjot Singh*

Main category: cs.DB

TL;DR: 提出一个结合本体论、复杂事件处理和大型语言模型的实时健康分析框架，用于在医疗大数据环境中检测关键健康事件。


<details>
  <summary>Details</summary>
Motivation: 解决医疗大数据环境中高容量、高速度、多样化临床数据的实时关键健康条件检测挑战。

Method: 使用基础形式本体和语义网规则语言建模诊断规则，结合Apache Kafka和Spark Streaming处理数据流，CEP引擎检测事件模式，LLM支持自适应推理和本体优化。

Result: 在1000名结核病患者数据集上验证，展示了低延迟事件检测、可扩展推理和高模型性能（精确率、召回率和F1分数）。

Conclusion: 该框架在复杂大数据场景中具有通用实时健康分析的潜力。

Abstract: Timely detection of critical health conditions remains a major challenge in
public health analytics, especially in Big Data environments characterized by
high volume, rapid velocity, and diverse variety of clinical data. This study
presents an ontology-enabled real-time analytics framework that integrates
Complex Event Processing (CEP) and Large Language Models (LLMs) to enable
intelligent health event detection and semantic reasoning over heterogeneous,
high-velocity health data streams. The architecture leverages the Basic Formal
Ontology (BFO) and Semantic Web Rule Language (SWRL) to model diagnostic rules
and domain knowledge. Patient data is ingested and processed using Apache Kafka
and Spark Streaming, where CEP engines detect clinically significant event
patterns. LLMs support adaptive reasoning, event interpretation, and ontology
refinement. Clinical information is semantically structured as Resource
Description Framework (RDF) triples in Graph DB, enabling SPARQL-based querying
and knowledge-driven decision support. The framework is evaluated using a
dataset of 1,000 Tuberculosis (TB) patients as a use case, demonstrating
low-latency event detection, scalable reasoning, and high model performance (in
terms of precision, recall, and F1-score). These results validate the system's
potential for generalizable, real-time health analytics in complex Big Data
scenarios.

</details>


### [11] [Targeted Sequential Pattern Mining with High Average Utility](https://arxiv.org/abs/2510.10115)
*Kai Cao,Yucong Duan,Wensheng Gan*

Main category: cs.DB

TL;DR: 提出TAUSQ-PG算法，将平均效用引入目标序列模式挖掘，通过高效过滤剪枝策略和紧致上界模型，显著提升大规模长序列数据集中的挖掘效率和内存利用率。


<details>
  <summary>Details</summary>
Motivation: 传统基于频率的模式挖掘存在实用性限制，而基于效用的方法往往产生大量冗长复杂序列。平均效用通过平衡效用和序列长度提供更均衡的度量，结合用户定义查询目标可增强可用性和交互性。

Method: 设计TAUSQ-PG算法，引入平均效用到目标序列模式挖掘，采用高效过滤剪枝策略、紧致上界模型，以及专门设计的评估指标和查询标志。

Result: 在不同数据集上的对比实验表明，TAUSQ-PG能有效控制候选集大小，减少冗余序列生成，显著提升运行时间和内存效率。

Conclusion: TAUSQ-PG算法成功解决了大规模长序列数据集中的挖掘效率挑战，为目标高平均效用序列模式挖掘提供了有效解决方案。

Abstract: Incorporating utility into targeted pattern mining can address the practical
limitations of traditional frequency-based approaches. However, utility-based
methods often suffer from generating a large number of long and complicated
sequences. To improve pattern relevance and interpretability, average utility
provides a more balanced metric by considering both utility and sequence
length. Moreover, incorporating user-defined query targets into the mining
process enhances usability and interactivity by retaining only patterns
containing user-specified goals. To address challenges related to mining
efficiency in large-scale, long-sequence datasets, this study introduces
average utility into targeted sequential pattern mining. A novel algorithm,
TAUSQ-PG, is designed to find targeted high average utility sequential
patterns. It incorporates efficient filtering and pruning strategies, tighter
upper bound models, as well as novel specialized evaluation metrics and query
flags tailored to this task. Extensive comparative experiments on different
datasets demonstrate that TAUSQ-PG effectively controls the candidate set size,
thereby reducing redundant sequence generation and significantly improving
runtime and memory efficiency.

</details>


### [12] [The Hybrid Multimodal Graph Index (HMGI): A Comprehensive Framework for Integrated Relational and Vector Search](https://arxiv.org/abs/2510.10123)
*Joydeep Chandra,Satyam Kumar Navneet,Yong Zhang*

Main category: cs.DB

TL;DR: HMGI是一个混合多模态图索引框架，旨在弥合向量数据库和图数据库之间的能力差距，通过统一系统支持多模态数据的高效混合查询。


<details>
  <summary>Details</summary>
Motivation: 复杂多模态数据集的激增暴露了专用向量数据库和传统图数据库之间的关键差距——向量数据库擅长语义相似性搜索但缺乏深度关系查询能力，而图数据库精通复杂遍历但不原生优化高维向量搜索。

Method: HMGI利用原生图数据库架构和集成向量搜索能力，结合近似最近邻搜索(ANNS)和图遍历查询，采用模态感知嵌入分区优化索引结构和查询性能，并支持自适应低开销索引更新。

Result: 通过将语义相似性搜索与关系上下文直接集成，HMGI旨在在复杂、关系密集的查询场景中超越纯向量数据库，并为混合任务实现亚线性查询时间。

Conclusion: HMGI框架成功构建了一个统一系统，能够有效处理多模态数据的混合查询需求，弥合了向量数据库和图数据库之间的功能鸿沟。

Abstract: The proliferation of complex, multimodal datasets has exposed a critical gap
between the capabilities of specialized vector databases and traditional graph
databases. While vector databases excel at semantic similarity search, they
lack the capacity for deep relational querying. Conversely, graph databases
master complex traversals but are not natively optimized for high-dimensional
vector search. This paper introduces the Hybrid Multimodal Graph Index (HMGI),
a novel framework designed to bridge this gap by creating a unified system for
efficient, hybrid queries on multimodal data. HMGI leverages the native graph
database architecture and integrated vector search capabilities, exemplified by
platforms like Neo4j, to combine Approximate Nearest Neighbor Search (ANNS)
with expressive graph traversal queries. Key innovations of the HMGI framework
include modality-aware partitioning of embeddings to optimize index structure
and query performance, and a system for adaptive, low-overhead index updates to
support dynamic data ingestion, drawing inspiration from the architectural
principles of systems like TigerVector. By integrating semantic similarity
search directly with relational context, HMGI aims to outperform pure vector
databases like Milvus in complex, relationship-heavy query scenarios and
achieve sub-linear query times for hybrid tasks.

</details>


### [13] [Efficient Mining of Low-Utility Sequential Patterns](https://arxiv.org/abs/2510.10243)
*Jian Zhu,Zhidong Lin,Wensheng Gan,Ruichu Cai,Zhifeng Hao,Philip S. Yu*

Main category: cs.DB

TL;DR: 本文提出了首个专门用于挖掘低效用序列模式(LUSPM)的算法框架，包括三个算法：LUSPM_b、LUSPM_s和LUSPM_e，通过重新定义序列效用和引入序列效用链数据结构来高效发现完整的低效用序列模式集。


<details>
  <summary>Details</summary>
Motivation: 现有的基于效用的序列模式挖掘主要关注高效用模式，而低效用序列模式在入侵检测和基因组序列分析等领域具有重要应用价值，但尚无专门针对低效用序列模式挖掘的算法。

Method: 重新定义序列效用，引入序列效用链数据结构，提出三种算法：LUSPM_b作为基准算法，LUSPM_s和LUSPM_e分别通过收缩和扩展操作生成子序列，并引入最大非互包含序列集和多种剪枝策略。

Result: 实验结果表明LUSPM_s和LUSPM_e显著优于LUSPM_b，具有良好的可扩展性，其中LUSPM_e在运行时间和内存消耗方面表现最优。

Conclusion: 本文成功解决了低效用序列模式挖掘问题，提出的算法框架能够高效发现完整的低效用序列模式集，为相关应用领域提供了有效的工具。

Abstract: Discovering valuable insights from rich data is a crucial task for
exploratory data analysis. Sequential pattern mining (SPM) has found widespread
applications across various domains. In recent years, low-utility sequential
pattern mining (LUSPM) has shown strong potential in applications such as
intrusion detection and genomic sequence analysis. However, existing research
in utility-based SPM focuses on high-utility sequential patterns, and the
definitions and strategies used in high-utility SPM cannot be directly applied
to LUSPM. Moreover, no algorithms have yet been developed specifically for
mining low-utility sequential patterns. To address these problems, we formalize
the LUSPM problem, redefine sequence utility, and introduce a compact data
structure called the sequence-utility chain to efficiently record utility
information. Furthermore, we propose three novel algorithm--LUSPM_b, LUSPM_s,
and LUSPM_e--to discover the complete set of low-utility sequential patterns.
LUSPM_b serves as an exhaustive baseline, while LUSPM_s and LUSPM_e build upon
it, generating subsequences through shrinkage and extension operations,
respectively. In addition, we introduce the maximal non-mutually contained
sequence set and incorporate multiple pruning strategies, which significantly
reduce redundant operations in both LUSPM_s and LUSPM_e. Finally, extensive
experimental results demonstrate that both LUSPM_s and LUSPM_e substantially
outperform LUSPM_b and exhibit excellent scalability. Notably, LUSPM_e achieves
superior efficiency, requiring less runtime and memory consumption than
LUSPM_s. Our code is available at https://github.com/Zhidong-Lin/LUSPM.

</details>


### [14] [Regular Expression Indexing for Log Analysis. Extended Version](https://arxiv.org/abs/2510.10348)
*Ling Zhang,Shaleen Deep,Jignesh M. Patel,Karthikeyan Sankaralingam*

Main category: cs.DB

TL;DR: REI是一个用于日志数据正则表达式查询索引的新系统，采用n-gram索引策略和高效存储机制，相比无索引的正则处理引擎速度提升达14倍，仅占用2.1%额外空间。


<details>
  <summary>Details</summary>
Motivation: 现有正则表达式处理引擎在处理日志分析任务时缺乏有效的索引机制，导致查询性能不佳。

Method: 提出基于n-gram的索引策略和高效存储机制，可与现有正则表达式包协同工作。

Result: 相比最先进的无索引正则处理引擎，速度提升高达14倍，仅使用2.1%额外存储空间。

Conclusion: REI方法在日志数据正则表达式查询评估方面提供了显著性能提升，且模块化设计便于在各种环境中部署。

Abstract: In this paper, we present the design and architecture of REI, a novel system
for indexing log data for regular expression queries. Our main contribution is
an $n$-gram-based indexing strategy and an efficient storage mechanism that
results in a speedup of up to 14x compared to state-of-the-art regex processing
engines that do not use indexing, using only 2.1% of extra space. We perform a
detailed study that analyzes the space usage of the index and the improvement
in workload execution time, uncovering interesting insights. Specifically, we
show that even an optimized implementation of strategies such as inverted
indexing, which are widely used in text processing libraries, may lead to
suboptimal performance for regex indexing on log analysis tasks. Overall, the
REI approach presented in this paper provides a significant boost when
evaluating regular expression queries on log data. REI is also modular and can
work with existing regular expression packages, making it easy to deploy in a
variety of settings. The code of REI is available at
https://github.com/mush-zhang/REI-Regular-Expression-Indexing.

</details>


### [15] [AQORA: A Learned Adaptive Query Optimizer for Spark SQL](https://arxiv.org/abs/2510.10580)
*Jiahao He,Yutao Cui,Cuiping Li,Jikang Jiang,Yuheng Hou,Hong Chen*

Main category: cs.DB

TL;DR: AQORA是一个结合学习查询优化和自适应查询处理优势的强化学习架构，通过四种核心策略显著提升查询性能。


<details>
  <summary>Details</summary>
Motivation: 传统LQO方法需要预先固定查询计划且依赖单一反馈信号，而AQP依赖启发式规则且无法从经验中学习，两者都有明显局限性。

Method: 采用强化学习架构，通过现实特征编码、查询阶段级反馈与干预、自动策略适应和低成本集成四个核心策略。

Result: 相比其他学习方法减少端到端执行时间达90%，相比Spark SQL默认配置减少70%。

Conclusion: AQORA成功结合了LQO和AQP的优势，在查询优化方面取得了显著性能提升。

Abstract: Recent studies have identified two main approaches to improve query
optimization: learned query optimization (LQO), which generates or selects
better query plans before execution based on models trained in advance, and
adaptive query processing (AQP), which adapts the query plan during execution
based on statistical feedback collected at runtime. Although both approaches
have shown promise, they also face critical limitations. LQO must commit to a
fixed plan without access to actual cardinalities and typically rely on a
single end-to-end feedback signal, making learning inefficient. On the other
hand, AQP depends heavily on rule-based heuristics and lacks the ability to
learn from experience. In this paper, we present AQORA, an adaptive query
optimizer with a reinforcement learning architecture that combines the
strengths of both LQO and AQP. AQORA addresses the above challenges through
four core strategies: (1) realistic feature encoding, (2) query stage-level
feedback and intervention, (3) automatic strategy adaptation, and (4) low-cost
integration. Experiments show that AQORA reduces end-to-end execution time by
up to 90% compared to other learned methods and by up to 70% compared to Spark
SQL's default configuration with adaptive query execution.

</details>


### [16] [DriftBench: Defining and Generating Data and Query Workload Drift for Benchmarking](https://arxiv.org/abs/2510.10858)
*Guanli Liu,Renata Borovica-Gajic*

Main category: cs.DB

TL;DR: 提出数据和工作负载漂移的统一分类法，并开发DriftBench框架来生成基准测试中的漂移，填补现有基准测试缺乏漂移建模支持的空白。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试是静态的，缺乏对数据和工作负载漂移建模的支持，这源于缺乏明确的定义和生成漂移的工具。

Method: 提出基于学术界和工业界观察的统一分类法，并开发轻量级可扩展的DriftBench框架来生成基准测试输入中的漂移。

Result: 通过涉及数据漂移、工作负载漂移和漂移感知基数估计的案例研究证明了该方法的有效性。

Conclusion: 分类法和DriftBench为基准测试中的漂移建模和生成提供了标准化的词汇和机制。

Abstract: Data and workload drift are key to evaluating database components such as
caching, cardinality estimation, indexing, and query optimization. Yet,
existing benchmarks are static, offering little to no support for modeling
drift. This limitation stems from the lack of clear definitions and tools for
generating data and workload drift. Motivated by this gap, we propose a unified
taxonomy for data and workload drift, grounded in observations from both
academia and industry. Building on this foundation, we introduce DriftBench, a
lightweight and extensible framework for generating data and workload drift in
benchmark inputs. Together, the taxonomy and DriftBench provide a standardized
vocabulary and mechanism for modeling and generating drift in benchmarking. We
demonstrate their effectiveness through case studies involving data drift,
workload drift, and drift-aware cardinality estimation.

</details>


### [17] [GrASP: A Generalizable Address-based Semantic Prefetcher for Scalable Transactional and Analytical Workloads](https://arxiv.org/abs/2510.11011)
*Farzaneh Zirak,Farhana Choudhury,Renata Borovica-Gajic*

Main category: cs.DB

TL;DR: GrASP是一种基于学习的预取器，通过逻辑块地址增量建模和上下文感知多标签分类，能够从少量训练数据泛化到大规模动态数据集，显著提升数据库性能。


<details>
  <summary>Details</summary>
Motivation: 传统预取器主要关注顺序模式，而基于学习的方法虽然对复杂访问模式更准确，但难以适应动态增长的数据集，且需要频繁微调。隐私约束也限制了完整数据集的访问，需要能够从样本中有效学习的预取器。

Method: GrASP利用逻辑块地址增量，结合查询表示和结果编码，将预取建模为上下文感知多标签分类任务，使用多层LSTM从嵌入上下文中预测增量模式。

Result: 在真实数据集和工业基准测试中，GrASP能够泛化到比训练数据大250倍的数据集，命中率提高45%，I/O时间降低60%，端到端查询执行延迟降低55%。平均达到91.4%命中率、90.8% I/O时间减少和57.1%执行延迟减少。

Conclusion: GrASP通过增量建模方法实现了从少量样本到大规模动态数据集的有效泛化，无需大量重新训练，在数据库预取方面表现出卓越的性能和可扩展性。

Abstract: Data prefetching--loading data into the cache before it is requested--is
essential for reducing I/O overhead and improving database performance. While
traditional prefetchers focus on sequential patterns, recent learning-based
approaches, especially those leveraging data semantics, achieve higher accuracy
for complex access patterns. However, these methods often struggle with today's
dynamic, ever-growing datasets and require frequent, timely fine-tuning.
Privacy constraints may also restrict access to complete datasets,
necessitating prefetchers that can learn effectively from samples. To address
these challenges, we present GrASP, a learning-based prefetcher designed for
both analytical and transactional workloads. GrASP enhances prefetching
accuracy and scalability by leveraging logical block address deltas and
combining query representations with result encodings. It frames prefetching as
a context-aware multi-label classification task, using multi-layer LSTMs to
predict delta patterns from embedded context. This delta modeling approach
enables GrASP to generalize predictions from small samples to larger, dynamic
datasets without requiring extensive retraining. Experiments on real-world
datasets and industrial benchmarks demonstrate that GrASP generalizes to
datasets 250 times larger than the training data, achieving up to 45% higher
hit ratios, 60% lower I/O time, and 55% lower end-to-end query execution
latency than existing baselines. On average, GrASP attains a 91.4% hit ratio, a
90.8% I/O time reduction, and a 57.1% execution latency reduction.

</details>


### [18] [Poseidon: A OneGraph Engine](https://arxiv.org/abs/2510.11166)
*Brad Bebee,Ümit V. Çatalyürek,Olaf Hartig,Ankesh Khandelwal,Simone Rondelli,Michael Schmidt,Lefteris Sidirourgos,Bryan Thompson*

Main category: cs.DB

TL;DR: Poseidon是Neptune Analytics图数据库服务的引擎，支持openCypher查询语言，结合了传统查询与算法调用，适用于从简单事务到复杂图分析的各种工作负载。


<details>
  <summary>Details</summary>
Motivation: 解决动态图场景下的实时需求，如实时欺诈检测需要反映图的当前状态变化，当用户手机被入侵时，该用户的所有新行为应立即被视为可疑。

Method: 结合先进的事务处理与创新的图数据索引技术，包括无锁维护邻接表、二级简洁索引、分区堆存储、统一放置的数据元组存储，以及基于成本的查询优化统计。

Result: 批量数据加载在多数数据集上达到每秒超过1000万属性值，简单事务在存储引擎上执行时间低于20ms。

Conclusion: Poseidon引擎通过逻辑日志实现持久性，支持内存数据结构的快速演进，能够有效处理动态图用例。

Abstract: We present the Poseidon engine behind the Neptune Analytics graph database
service. Customers interact with Poseidon using the declarative openCypher
query language, which enables requests that seamlessly combine traditional
querying paradigms (such as graph pattern matching, variable length paths,
aggregation) with algorithm invocations and has been syntactically extended to
facilitate OneGraph interoperability, such as the disambiguation between
globally unique IRIs (as exposed via RDF) vs. local identifiers (as encountered
in LPG data). Poseidon supports a broad range of graph workloads, from simple
transactions, to top-k beam search algorithms on dynamic graphs, to whole graph
analytics requiring multiple full passes over the data. For example, real-time
fraud detection, like many other use cases, needs to reflect current committed
state of the dynamic graph. If a users cell phone is compromised, then all
newer actions by that user become immediately suspect. To address such dynamic
graph use cases, Poseidon combines state-of-the-art transaction processing with
novel graph data indexing, including lock-free maintenance of adjacency lists,
secondary succinct indices, partitioned heaps for data tuple storage with
uniform placement, and innovative statistics for cost-based query optimization.
The Poseidon engine uses a logical log for durability, enabling rapid evolution
of in-memory data structures. Bulk data loads achieve more than 10 million
property values per second on many data sets while simple transactions can
execute in under 20ms against the storage engine.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [19] [Building and Evaluating a Realistic Virtual World for Large Scale Urban Exploration from 360° Videos](https://arxiv.org/abs/2510.11447)
*Mizuki Takenawa,Naoki Sugimoto,Leslie Wöhler,Satoshi Ikehata,Kiyoharu Aizawa*

Main category: cs.MM

TL;DR: 从360度视频构建真实城市虚拟世界360RVW，支持用户通过化身自由导航探索，提供交互式界面和碰撞检测功能


<details>
  <summary>Details</summary>
Motivation: 利用360度视频的高度真实性和沉浸感，为大型城市环境创建可直接在浏览器中访问的虚拟探索系统

Method: 通过四个主要操作：视频分割（交叉口检测）、视频补全（移除拍摄者）、语义分割（虚拟碰撞检测）、投影到移动球体上，构建虚拟世界

Result: 系统支持用户通过改变行走方向或点击地图选择新位置来探索城市环境，无需3D模型即可实现碰撞检测，可通过浏览器直接访问

Conclusion: 系统在用户存在感和交互探索方面表现出色，特别适合城市环境的虚拟游览，通过感知实验验证了系统质量

Abstract: We propose to build realistic virtual worlds, called 360RVW, for large urban
environments directly from 360{\deg} videos. We provide an interface for
interactive exploration, where users can freely navigate via their own avatars.
360{\deg} videos record the entire environment of the shooting location
simultaneously leading to highly realistic and immersive representations. Our
system uses 360{\deg} videos recorded along streets and builds a 360RVW through
four main operations: video segmentation by intersection detection, video
completion to remove the videographer, semantic segmentation for virtual
collision detection with the avatar, and projection onto a distorted sphere
that moves along the camera trajectory following the avatar's movements. Our
interface allows users to explore large urban environments by changing their
walking direction at intersections or choosing a new location by clicking on a
map. Even without a 3D model, the users can experience collision with buildings
using metadata produced by semantic segmentation. Furthermore, we stream the
360{\deg} videos so users can directly access 360RVW via their web browser. We
fully evaluate our system, including a perceptual experiment comparing our
approach to previous exploratory interfaces. The results confirm the quality of
our system, especially regarding the presence of users and the interactive
exploration, making it most suitable for a virtual tour of urban environments.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [20] [Distributed clustering in partially overlapping feature spaces](https://arxiv.org/abs/2510.09799)
*Alessio Maritan,Luca Schenato*

Main category: cs.DS

TL;DR: 提出了两种解决分布式聚类问题的算法，其中每个参与者的数据集只包含部分特征，且某些特征可能出现在多个数据集中。


<details>
  <summary>Details</summary>
Motivation: 现实应用中（如医疗领域）不同机构拥有相似患者但特征互补的数据，需要在不共享原始数据的情况下进行聚类分析。

Method: 1. 联邦算法：参与者协作更新全局质心；2. 一次性算法：参与者共享本地聚类的统计参数化，中央服务器生成并合并合成代理数据集。

Result: 在三个公共数据集上测试了算法的实际性能，并识别了收敛到最优集中式解的条件。

Conclusion: 提出的算法在特征空间异构的分布式聚类场景中表现良好，提供了灵活性和个性化计算成本。

Abstract: We introduce and address a novel distributed clustering problem where each
participant has a private dataset containing only a subset of all available
features, and some features are included in multiple datasets. This scenario
occurs in many real-world applications, such as in healthcare, where different
institutions have complementary data on similar patients. We propose two
different algorithms suitable for solving distributed clustering problems that
exhibit this type of feature space heterogeneity. The first is a federated
algorithm in which participants collaboratively update a set of global
centroids. The second is a one-shot algorithm in which participants share a
statistical parametrization of their local clusters with the central server,
who generates and merges synthetic proxy datasets. In both cases, participants
perform local clustering using algorithms of their choice, which provides
flexibility and personalized computational costs. Pretending that local
datasets result from splitting and masking an initial centralized dataset, we
identify some conditions under which the proposed algorithms are expected to
converge to the optimal centralized solution. Finally, we test the practical
performance of the algorithms on three public datasets.

</details>


### [21] [Combinatorial Philosopher Inequalities](https://arxiv.org/abs/2510.10039)
*Enze Sun,Zhihao Gavin Tang,Yifan Wang*

Main category: cs.DS

TL;DR: 本文针对在线组合分配问题，为次模估值代理建立了0.5+Ω(1)的近似比，同时为XOS估值代理提供了0.5的积分间隙。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注与离线基准的比较，但存在0.5竞争比的不可能性结果。新兴研究方向是设计相对于最优在线算法的近似算法，目标是突破0.5的限制。

Method: 构建了一个新的在线配置线性规划松弛，并针对次模估值代理设计了近似算法。对于XOS估值代理，分析了该线性规划的积分间隙。

Result: 对于次模估值代理，获得了0.5+Ω(1)的近似比；对于XOS估值代理，证明了在线配置线性规划存在0.5的积分间隙。

Conclusion: 本文扩展了在线组合分配问题的正面结果到次模估值代理，同时揭示了现有方法在处理XOS估值代理时的局限性。

Abstract: In online combinatorial allocation, agents arrive sequentially and items are
allocated in an online manner. The algorithm designer only knows the
distribution of each agent's valuation, while the actual realization of the
valuation is revealed only upon her arrival. Against the offline benchmark,
Feldman, Gravin, and Lucier (SODA 2015) designed an optimal $0.5$-competitive
algorithm for XOS agents. An emerging line of work focuses on designing
approximation algorithms against the (computationally unbounded) optimal online
algorithm. The primary goal is to design algorithms with approximation ratios
strictly greater than $0.5$, surpassing the impossibility result against the
offline optimum. Positive results are established for unit-demand agents
(Papadimitriou, Pollner, Saberi, Wajc, MOR 2024), and for $k$-demand agents
(Braun, Kesselheim, Pollner, Saberi, EC 2024).
  In this paper, we extend the existing positive results for agents with
submodular valuations by establishing a $0.5 + \Omega(1)$ approximation against
a newly constructed online configuration LP relaxation for the combinatorial
allocation setting. Meanwhile, we provide negative results for agents with XOS
valuations by providing a $0.5$ integrality gap for the online configuration
LP, showing an obstacle of existing approaches.

</details>


### [22] [Simple Length-Constrained Expander Decompositions](https://arxiv.org/abs/2510.10227)
*Greg Bodwin,Bernhard Haeupler,D Ellis Hershkowitz,Zihan Tan*

Main category: cs.DS

TL;DR: 本文改进了长度约束扩展图分解的构造方法，将分解规模从原来的log n·s n^{O(1/s)}·φm降低到s n^{O(1/s)}·φm，通过优化稀疏长度约束割的并集操作实现。


<details>
  <summary>Details</summary>
Motivation: 长度约束扩展图分解是图算法领域的重要工具，但现有构造方法的规模存在log n因子，限制了其在实际应用中的效率。本文旨在消除这一因子，提供更紧凑的分解构造。

Method: 利用稀疏长度约束割的并集本身也是稀疏长度约束割这一事实，通过优化并集操作的稀疏度损失，从原来的log^3 n·s^3 n^{O(1/s)}改进到s·n^{O(1/s)}。

Result: 成功证明了存在规模为s n^{O(1/s)}·φm的(h,s)-长度φ-扩展图分解，相比之前的结果消除了log n因子。

Conclusion: 通过简单而有效的方法，本文显著改进了长度约束扩展图分解的构造，为快速图算法提供了更优的基础工具。

Abstract: Length-constrained expander decompositions are a new graph decomposition that
has led to several recent breakthroughs in fast graph algorithms. Roughly, an
$(h, s)$-length $\phi$-expander decomposition is a small collection of length
increases to a graph so that nodes within distance $h$ can route flow over
paths of length $hs$ while using each edge to an extent at most $1/\phi$. Prior
work showed that every $n$-node and $m$-edge graph admits an $(h, s)$-length
$\phi$-expander decomposition of size $\log n \cdot s n^{O(1/s)} \cdot \phi m$.
  In this work, we give a simple proof of the existence of $(h, s)$-length
$\phi$-expander decompositions with an improved size of $s n^{O(1/s)}\cdot \phi
m$. Our proof is a straightforward application of the fact that the union of
sparse length-constrained cuts is itself a sparse length-constrained cut. In
deriving our result, we improve the loss in sparsity when taking the union of
sparse length-constrained cuts from $\log ^3 n\cdot s^3 n^{O(1/s)}$ to $s\cdot
n^{O(1/s)}$.

</details>


### [23] [Explicit Min-wise Hash Families with Optimal Size](https://arxiv.org/abs/2510.10431)
*Xue Chen,Shengtang Huang,Xin Li*

Main category: cs.DS

TL;DR: 本文提出了首个使用最优随机比特数（O(k log N)）且达到亚常数误差的显式k-min-wise哈希族构造，改进了之前的所有结果。


<details>
  <summary>Details</summary>
Motivation: min-wise哈希在计算机科学中广泛应用，但之前的构造要么需要较多随机比特，要么无法达到亚常数误差。需要找到使用最优随机比特数且误差较小的显式构造。

Method: 基于组合矩形和只读分支程序的伪随机性，采用新的技术来适配经典的Nisan-Zuckerman伪随机生成器，以欺骗具有乘法误差的min-wise哈希。

Result: 构建了显式的k-min-wise哈希族，使用O(k log N)比特随机数，达到2^{-O(log N/log log N)}的误差，对于k=log^{O(1)}N的情况改进了之前的所有结果。

Conclusion: 这是首个使用最优随机比特数且达到亚常数误差的显式min-wise哈希族构造，为相关应用提供了更高效的解决方案。

Abstract: We study explicit constructions of min-wise hash families and their extension
to $k$-min-wise hash families. Informally, a min-wise hash family guarantees
that for any fixed subset $X\subseteq[N]$, every element in $X$ has an equal
chance to have the smallest value among all elements in $X$; a $k$-min-wise
hash family guarantees this for every subset of size $k$ in $X$. Min-wise hash
is widely used in many areas of computer science such as sketching, web page
detection, and $\ell_0$ sampling.
  The classical works by Indyk and P\u{a}tra\c{s}cu and Thorup have shown
$\Theta(\log(1/\delta))$-wise independent families give min-wise hash of
multiplicative (relative) error $\delta$, resulting in a construction with
$\Theta(\log(1/\delta)\log N)$ random bits. Based on a reduction from
pseudorandom generators for combinatorial rectangles by Saks, Srinivasan, Zhou
and Zuckerman, Gopolan and Yehudayoff improved the number of bits to $O(\log
N\log\log N)$ for polynomially small errors $\delta$. However, no construction
with $O(\log N)$ bits (polynomial size family) and sub-constant error was known
before.
  In this work, we continue and extend the study of constructing ($k$-)min-wise
hash families from pseudorandomness for combinatorial rectangles and read-once
branching programs. Our main result gives the first explicit min-wise hash
families that use an optimal (up to constant) number of random bits and achieve
a sub-constant (in fact, almost polynomially small) error, specifically, an
explicit family of $k$-min-wise hash with $O(k\log N)$ bits and $2^{-O(\log
N/\log\log N)}$ error. This improves all previous results for any
$k=\log^{O(1)}N$ under $O(k \log N)$ bits. Our main techniques involve several
new ideas to adapt the classical Nisan-Zuckerman pseudorandom generator to fool
min-wise hashing with a multiplicative error.

</details>


### [24] [Information-Computation Tradeoffs for Noiseless Linear Regression with Oblivious Contamination](https://arxiv.org/abs/2510.10665)
*Ilias Diakonikolas,Chao Gao,Daniel M. Kane,John Lafferty,Ankit Pensia*

Main category: cs.DS

TL;DR: 该论文研究了高斯协变量下存在加性污染的无噪声线性回归问题，证明了高效算法需要样本量与1/α²成二次依赖关系，提供了计算复杂度的形式化证据。


<details>
  <summary>Details</summary>
Motivation: 研究在存在加性污染的无噪声线性回归中，高效算法所需的样本复杂度，特别是探索1/α的二次依赖关系是否不可避免。

Method: 使用统计查询(SQ)框架分析，证明任何高效的SQ算法需要至少Ω̃(d¹/²/α²)的VSTAT复杂度。

Result: 证明了高效算法需要样本量与1/α²成二次依赖关系，而忽略计算考虑的最优算法只需要O(d/α)样本。

Conclusion: 对于存在加性污染的无噪声线性回归问题，高效算法确实需要1/α的二次依赖关系，这为计算复杂度提供了形式化证据。

Abstract: We study the task of noiseless linear regression under Gaussian covariates in
the presence of additive oblivious contamination. Specifically, we are given
i.i.d.\ samples from a distribution $(x, y)$ on $\mathbb{R}^d \times
\mathbb{R}$ with $x \sim \mathcal{N}(0,\mathbf{I}_d)$ and $y = x^\top \beta +
z$, where $z$ is drawn independently of $x$ from an unknown distribution $E$.
Moreover, $z$ satisfies $\mathbb{P}_E[z = 0] = \alpha>0$. The goal is to
accurately recover the regressor $\beta$ to small $\ell_2$-error. Ignoring
computational considerations, this problem is known to be solvable using
$O(d/\alpha)$ samples. On the other hand, the best known polynomial-time
algorithms require $\Omega(d/\alpha^2)$ samples. Here we provide formal
evidence that the quadratic dependence in $1/\alpha$ is inherent for efficient
algorithms. Specifically, we show that any efficient Statistical Query
algorithm for this task requires VSTAT complexity at least
$\tilde{\Omega}(d^{1/2}/\alpha^2)$.

</details>


### [25] [Learning-Augmented Streaming Algorithms for Correlation Clustering](https://arxiv.org/abs/2510.10705)
*Yinhao Dong,Shan Jiang,Shi Li,Pan Peng*

Main category: cs.DS

TL;DR: 提出了首个学习增强的流式相关聚类算法，在完全图和一般图上改进了空间-近似权衡，利用顶点间距离预测来提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有流式相关聚类算法在空间效率和近似比方面存在局限，希望通过引入学习预测来改进性能。

Method: 基于Cambus等人和Ahn等人的工作，使用预测器提供的顶点间距离预测，设计流式算法处理边流。

Result: 在完全图上实现了优于3的近似比，在一般图上实现了O(log|E^-|)近似比，均使用O~(n)总空间，实验显示优于非学习方法。

Conclusion: 学习增强方法能显著提升流式相关聚类算法的性能，在保持低空间复杂度的同时获得更好的近似保证。

Abstract: We study streaming algorithms for Correlation Clustering. Given a graph as an
arbitrary-order stream of edges, with each edge labeled as positive or
negative, the goal is to partition the vertices into disjoint clusters, such
that the number of disagreements is minimized. In this paper, we give the first
learning-augmented streaming algorithms for the problem on both complete and
general graphs, improving the best-known space-approximation tradeoffs. Based
on the works of Cambus et al. (SODA'24) and Ahn et al. (ICML'15), our
algorithms use the predictions of pairwise distances between vertices provided
by a predictor. For complete graphs, our algorithm achieves a better-than-$3$
approximation under good prediction quality, while using $\tilde{O}(n)$ total
space. For general graphs, our algorithm achieves an $O(\log |E^-|)$
approximation under good prediction quality using $\tilde{O}(n)$ total space,
improving the best-known non-learning algorithm in terms of space efficiency.
Experimental results on synthetic and real-world datasets demonstrate the
superiority of our proposed algorithms over their non-learning counterparts.

</details>


### [26] [Crane Scheduling Problem with Energy Saving](https://arxiv.org/abs/2510.10989)
*Yixiong Gao,Florian Jaehn,Minming Li,Wenhao Ma,Xinbo Zhang*

Main category: cs.DS

TL;DR: 提出一种考虑能量节约的单起重机调度问题，通过重用已提升集装箱的能量来减少总能耗，建立了基本模型并进行了系统复杂性分析。


<details>
  <summary>Details</summary>
Motivation: 在集装箱装卸过程中，起重机提升集装箱消耗能量，而放下集装箱时能量往往被浪费。通过优化起重机调度可以减少能耗，降低运营成本和环境影响。

Method: 首先研究问题与半欧拉化问题的联系，提出加法近似算法；然后为有界能量缓冲和处理长度的情况提出多项式时间动态规划算法；最后采用哈密顿视角处理一般情况，提出精确DP算法，并证明当问题可转化为无环区间有向图的路径覆盖问题时是多项式可解的。

Result: 提出了整合欧拉和哈密顿视角的范式，为解决问题提供了稳健框架。

Conclusion: 该研究为能量节约的单起重机调度问题提供了系统的复杂性分析和多种算法解决方案，整合了欧拉和哈密顿两种视角，为解决此类问题建立了理论框架。

Abstract: During loading and unloading steps, energy is consumed when cranes lift
containers, while energy is often wasted when cranes drop containers. By
optimizing the scheduling of cranes, it is possible to reduce energy
consumption, thereby lowering operational costs and environmental impacts. In
this paper, we introduce a single-crane scheduling problem with energy savings,
focusing on reusing the energy from containers that have already been lifted
and reducing the total energy consumption of the entire scheduling plan. We
establish a basic model considering a one-dimensional storage area and provide
a systematic complexity analysis of the problem. First, we investigate the
connection between our problem and the semi-Eulerization problem and propose an
additive approximation algorithm. Then, we present a polynomial-time Dynamic
Programming (DP) algorithm for the case of bounded energy buffer and processing
lengths. Next, adopting a Hamiltonian perspective, we address the general case
with arbitrary energy buffer and processing lengths. We propose an exact DP
algorithm and show that the variation of the problem is polynomially solvable
when it can be transformed into a path cover problem on acyclic interval
digraphs. We introduce a paradigm that integrates both the Eulerian and
Hamiltonian perspectives, providing a robust framework for addressing the
problem.

</details>


### [27] [Online Allocation with Concave, Diminishing-Returns Objectives](https://arxiv.org/abs/2510.11266)
*Kalen Patton*

Main category: cs.DS

TL;DR: 本文提出了一种通用的(1-1/e)-竞争性分数分配算法，统一了在线资源分配问题中具有凹函数和收益递减性质的各种特殊情况。


<details>
  <summary>Details</summary>
Motivation: 在线资源分配问题中，虽然已有许多针对特定情况设计的高竞争性算法，但缺乏一个通用的理论框架来证明对于任意凹函数和收益递减目标函数都存在(1-1/e)-竞争性算法。

Method: 使用在线原始对偶方法，设计基于辅助目标函数U(x)的连续贪婪分配算法，通过证明U满足相对于f的"平衡"性质来保证竞争性。

Result: 发现了一个简单的U表达式，该表达式对任意f都具有平衡性质，从而得到了通用的(1-1/e)-竞争性算法。

Conclusion: 对于具有凹函数和收益递减性质的在线资源分配问题，总是存在(1-1/e)-竞争性的分数分配算法，统一并推广了先前针对特殊情况的结果。

Abstract: Online resource allocation problems are central challenges in economics and
computer science, modeling situations in which $n$ items arriving one at a time
must each be immediately allocated among $m$ agents. In such problems, our
objective is to maximize a monotone reward function $f(\mathbf{x})$ over the
allocation vector $\mathbf{x} = (x_{ij})_{i, j}$, which describes the amount of
each item given to each agent. In settings where $f$ is concave and has
"diminishing returns" (monotone decreasing gradient), several lines of work
over the past two decades have had great success designing constant-competitive
algorithms, including the foundational work of Mehta et al. (2005) on the
Adwords problem and many follow-ups. Notably, while a greedy algorithm is
$\frac{1}{2}$-competitive in such settings, these works have shown that one can
often obtain a competitive ratio of $1-\frac{1}{e} \approx 0.632$ in a variety
of settings when items are divisible (i.e. allowing fractional allocations).
However, prior works have thus far used a variety of problem-specific
techniques, leaving open the general question: Does a
$(1-\frac{1}{e})$-competitive fractional algorithm always exist for online
resource allocation problems with concave, diminishing-returns objectives?
  In this work, we answer this question affirmatively, thereby unifying and
generalizing prior results for special cases. Our algorithm is one which makes
continuous greedy allocations with respect to an auxiliary objective
$U(\mathbf{x})$. Using the online primal-dual method, we show that if $U$
satisfies a "balanced" property with respect to $f$, then one can bound the
competitiveness of such an algorithm. Our crucial observation is that there is
a simple expression for $U$ which has this balanced property for any $f$,
yielding our general $(1-\frac{1}{e})$-competitive algorithm.

</details>


### [28] [An $O(n\log n)$ Algorithm for Single-Item Capacitated Lot Sizing with a One-Breakpoint All-Units Discount and Non-Increasing Prices](https://arxiv.org/abs/2510.11368)
*Kleitos Papadopoulos*

Main category: cs.DS

TL;DR: 本文针对具有1断点全单位数量折扣的单品容量批量问题，在采购价格随时间递减的单调设置下，提出了一种混合动态规划方法，将时间复杂度从O(n²)改进到O(n log n)。


<details>
  <summary>Details</summary>
Motivation: 解决具有数量折扣的容量批量问题在单调价格环境下的计算效率问题，改进现有算法的性能。

Method: 建立最优解的新性质，开发混合动态规划方法，通过存储状态的关键信息和线性方程来压缩解空间表示。

Result: 算法在O(n log n)时间内运行，相比之前O(n²)的最优算法有显著改进。

Conclusion: 提出的混合动态规划方法在单调价格设置下有效解决了具有数量折扣的容量批量问题，显著提升了计算效率。

Abstract: This paper addresses the single-item capacitated lot sizing problem with a
1-breakpoint all-units quantity discount in a monotonic setting where the
purchase prices are non-increasing over the planning horizon. For this case, we
establish several novel properties of the optimal solution and develop a hybrid
dynamic programming approach that maintains a compact representation of the
solution space by storing only essential information about the states and using
linear equations for intermediate values. Our algorithm runs in \(O(n\log n)\)
time, where \(n\) denotes the number of periods. Our result is an improvement
over the previous state-of-the-art algorithm, which has an \(O(n^2)\) time
complexity.

</details>


### [29] [Sublinear Algorithms for Estimating Single-Linkage Clustering Costs](https://arxiv.org/abs/2510.11547)
*Pan Peng,Christian Sohler,Yi Xu*

Main category: cs.DS

TL;DR: 本文提出了一种基于采样的算法，用于高效估计单链接层次聚类中所有k-聚类的成本，运行时间为Õ(d√W/ε³)，能够以平均(1+ε)的近似比估计每个k-聚类的成本。


<details>
  <summary>Details</summary>
Motivation: 单链接聚类是数据分析的基本方法，但计算所有k-聚类的成本通常很耗时。本文旨在开发高效的算法来近似估计层次聚类中每个k-聚类的成本，特别是针对大规模图数据。

Method: 使用基于采样的方法，通过查询图的邻接表，计算所有k-聚类成本的简洁表示。算法运行时间为Õ(d√W/ε³)，其中d是平均度数，W是最大边权重。

Result: 算法能够以Õ(d√W/ε³)的时间复杂度估计所有k-聚类的成本，满足∑|估计值-真实值| ≤ ε·总成本。同时扩展到相似性图设置，运行时间为Õ(dW/ε³)。

Conclusion: 本文提供了高效的单链接层次聚类成本估计算法，在理论和实践中都具有重要意义，并证明了相应的下界结果。

Abstract: Single-linkage clustering is a fundamental method for data analysis.
Algorithmically, one can compute a single-linkage $k$-clustering (a partition
into $k$ clusters) by computing a minimum spanning tree and dropping the $k-1$
most costly edges. This clustering minimizes the sum of spanning tree weights
of the clusters. This motivates us to define the cost of a single-linkage
$k$-clustering as the weight of the corresponding spanning forest, denoted by
$\mathrm{cost}_k$. Besides, if we consider single-linkage clustering as
computing a hierarchy of clusterings, the total cost of the hierarchy is
defined as the sum of the individual clusterings, denoted by $\mathrm{cost}(G)
= \sum_{k=1}^{n} \mathrm{cost}_k$.
  In this paper, we assume that the distances between data points are given as
a graph $G$ with average degree $d$ and edge weights from $\{1,\dots, W\}$.
Given query access to the adjacency list of $G$, we present a sampling-based
algorithm that computes a succinct representation of estimates
$\widehat{\mathrm{cost}}_k$ for all $k$. The running time is $\tilde
O(d\sqrt{W}/\varepsilon^3)$, and the estimates satisfy $\sum_{k=1}^{n}
|\widehat{\mathrm{cost}}_k - \mathrm{cost}_k| \le \varepsilon\cdot
\mathrm{cost}(G)$, for any $0<\varepsilon <1$. Thus we can approximate the cost
of every $k$-clustering upto $(1+\varepsilon)$ factor \emph{on average}. In
particular, our result ensures that we can estimate $\cost(G)$ upto a factor of
$1\pm \varepsilon$ in the same running time.
  We also extend our results to the setting where edges represent similarities.
In this case, the clusterings are defined by a maximum spanning tree, and our
algorithms run in $\tilde{O}(dW/\varepsilon^3)$ time. We futher prove nearly
matching lower bounds for estimating the total clustering cost and we extend
our algorithms to metric space settings.

</details>


### [30] [Sublinear Metric Steiner Forest via Maximal Independent Set](https://arxiv.org/abs/2510.11627)
*Sepideh Mahabadi,Mohammad Roghani,Jakub Tarnawski,Ali Vakilian*

Main category: cs.DS

TL;DR: 提出了度量Steiner森林问题的首个亚线性时间算法，运行时间为Õ(n^{3/2})，达到O(log k)近似比。同时首次给出了最大独立集(MIS)的亚线性时间估计算法。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究针对最小生成树和度量Steiner树问题提出了亚线性时间算法，但度量Steiner森林问题尚未有亚线性时间算法。该问题在距离矩阵查询模型下具有重要应用价值。

Method: 使用距离矩阵查询访问度量空间中的点对距离，设计Õ(n^{3/2})时间复杂度的算法。同时开发了在邻接矩阵预言模型下运行时间为Õ(n^{3/2}/ε²)的MIS估计算法。

Result: 获得了度量Steiner森林问题的O(log k)近似算法，运行时间为Õ(n^{3/2})。MIS估计算法实现了(1+ε)乘性近似，突破了之前仅适用于有界度图的限制。

Conclusion: 首次解决了度量Steiner森林问题的亚线性时间近似计算，同时扩展了MIS估计算法的适用范围，为图论问题在亚线性时间模型下的研究提供了新工具。

Abstract: In this work we consider the Metric Steiner Forest problem in the sublinear
time model. Given a set $V$ of $n$ points in a metric space where distances are
provided by means of query access to an $n\times n$ distance matrix, along with
a set of $k$ terminal pairs $(s_1,t_1), \dots, (s_k,t_k)\in V\times V$, the
goal is to find a minimum-weight subset of edges that connects each terminal
pair. Although sublinear time algorithms have been studied for estimating the
weight of a minimum spanning tree in both general and metric settings, as well
as for the metric Steiner Tree problem, no sublinear time algorithm was known
for the metric Steiner Forest problem.
  Here, we give an $O(\log k)$-approximation algorithm for the problem that
runs in time $\widetilde{O}(n^{3/2})$. Along the way, we provide the first
sublinear-time algorithm for estimating the size of a Maximal Independent Set
(MIS). Our algorithm runs in time $\widetilde{O}(n^{3/2}/\varepsilon^2)$ under
the adjacency matrix oracle model and obtains a purely multiplicative
$(1+\varepsilon)$-approximation. Previously, sublinear-time algorithms for MIS
were only known for bounded-degree graphs.

</details>


### [31] [Continual Release of Densest Subgraphs: Privacy Amplification & Sublinear Space via Subsampling](https://arxiv.org/abs/2510.11640)
*Felix Zhou*

Main category: cs.DS

TL;DR: 提出了首个在持续发布模型下实现边缘差分隐私的图稠密子图算法，在插入流设置中同时达到最佳静态DP算法的误差界和最佳非私有流算法的空间复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究在子线性空间持续发布模型下的边缘差分隐私图算法，特别关注插入流设置中的稠密子图问题，旨在同时实现隐私保护和高效空间利用。

Method: 通过改进的采样技术同时实现隐私放大和稀疏化，引入图稠密化概念在DP图设置中添加边以触发早期采样，并通过黑盒归约到静态设置。

Result: 获得了纯DP和近似DP算法，具有O(log n)加性误差和O(n log n)空间复杂度，在准确性和空间复杂度上都优于先前最佳结果。

Conclusion: 提出的采样技术连接了隐私放大和稀疏化，这一简单思想可能具有独立的研究价值，同时解决了先前工作中额外的对数因子问题。

Abstract: We study the sublinear space continual release model for edge-differentially
private (DP) graph algorithms, with a focus on the densest subgraph problem
(DSG) in the insertion-only setting. Our main result is the first continual
release DSG algorithm that matches the additive error of the best static DP
algorithms and the space complexity of the best non-private streaming
algorithms, up to constants. The key idea is a refined use of subsampling that
simultaneously achieves privacy amplification and sparsification, a connection
not previously formalized in graph DP. Via a simple black-box reduction to the
static setting, we obtain both pure and approximate-DP algorithms with $O(\log
n)$ additive error and $O(n\log n)$ space, improving both accuracy and space
complexity over the previous state of the art. Along the way, we introduce
graph densification in the graph DP setting, adding edges to trigger earlier
subsampling, which removes the extra logarithmic factors in error and space
incurred by prior work [ELMZ25]. We believe this simple idea may be of
independent interest.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [32] [MTMD: A Multi-Task Multi-Domain Framework for Unified Ad Lightweight Ranking at Pinterest](https://arxiv.org/abs/2510.09857)
*Xiao Yang,Peifeng Yin,Abe Engle,Jinfeng Zhuang,Ling Leng*

Main category: cs.IR

TL;DR: 提出了一种多任务多领域（MTMD）架构，在轻量级广告排序层中统一处理不同优化目标、广告产品和展示场景，通过专家混合架构实现领域专业知识和共享知识的平衡学习。


<details>
  <summary>Details</summary>
Motivation: 解决工业级广告推荐系统中，由于存在多个优化任务（如CTR、CVR）、不同展示场景和广告产品，如何在轻量级排序层进行联合整体优化的挑战。

Method: 基于双塔范式构建MTMD架构，采用专家混合架构学习领域专业知识和共享知识，包含领域适应模块促进专家间知识迁移，并对不同预测任务进行约束建模。

Result: 离线损失值降低12%-36%，对应在线点击成本降低2%，已在Pinterest广告推荐系统中部署，替代了9个生产模型。

Conclusion: MTMD框架能够有效统一处理多任务多领域广告推荐问题，通过知识共享和迁移显著提升系统性能，实现平台、广告主和用户价值的最大化。

Abstract: The lightweight ad ranking layer, living after the retrieval stage and before
the fine ranker, plays a critical role in the success of a cascaded ad
recommendation system. Due to the fact that there are multiple optimization
tasks depending on the ad domain, e.g., Click Through Rate (CTR) for click ads
and Conversion Rate (CVR) for conversion ads, as well as multiple surfaces
where an ad is served (home feed, search, or related item recommendation) with
diverse ad products (shopping or standard ad); it is an essentially challenging
problem in industry on how to do joint holistic optimization in the lightweight
ranker, such that the overall platform's value, advertiser's value, and user's
value are maximized.
  Deep Neural Network (DNN)-based multitask learning (MTL) can handle multiple
goals naturally, with each prediction head mapping to a particular optimization
goal. However, in practice, it is unclear how to unify data from different
surfaces and ad products into a single model. It is critical to learn
domain-specialized knowledge and explicitly transfer knowledge between domains
to make MTL effective. We present a Multi-Task Multi-Domain (MTMD) architecture
under the classic Two-Tower paradigm, with the following key contributions: 1)
handle different prediction tasks, ad products, and ad serving surfaces in a
unified framework; 2) propose a novel mixture-of-expert architecture to learn
both specialized knowledge each domain and common knowledge shared between
domains; 3) propose a domain adaption module to encourage knowledge transfer
between experts; 4) constrain the modeling of different prediction tasks. MTMD
improves the offline loss value by 12% to 36%, mapping to 2% online reduction
in cost per click. We have deployed this single MTMD framework into production
for Pinterest ad recommendation replacing 9 production models.

</details>


### [33] [PairSem: LLM-Guided Pairwise Semantic Matching for Scientific Document Retrieval](https://arxiv.org/abs/2510.09897)
*Wonbin Kweon,Runchu Tian,SeongKu Kang,Pengcheng Jiang,Zhiyong Lu,Jiawei Han,Hwanjo Yu*

Main category: cs.IR

TL;DR: 提出PairSem框架，通过实体-方面对表示相关语义，捕捉复杂多方面的科学概念，显著提升科学文档检索性能


<details>
  <summary>Details</summary>
Motivation: 现有密集检索方法难以捕捉文本中的细粒度科学概念，因为它们依赖整体嵌入且领域理解有限；而基于LLM的方法通常将实体视为独立片段，忽略了科学概念的多方面性质

Method: 提出Pairwise Semantic Matching (PairSem)框架，将相关语义表示为实体-方面对，捕捉复杂多方面的科学概念；该框架是无监督的、基础检索器无关的、即插即用的

Result: 在多个数据集和检索器上的广泛实验表明，PairSem显著提高了检索性能

Conclusion: 建模多方面语义在科学信息检索中具有重要意义，PairSem框架有效解决了现有方法的局限性

Abstract: Scientific document retrieval is a critical task for enabling knowledge
discovery and supporting research across diverse domains. However, existing
dense retrieval methods often struggle to capture fine-grained scientific
concepts in texts due to their reliance on holistic embeddings and limited
domain understanding. Recent approaches leverage large language models (LLMs)
to extract fine-grained semantic entities and enhance semantic matching, but
they typically treat entities as independent fragments, overlooking the
multi-faceted nature of scientific concepts. To address this limitation, we
propose Pairwise Semantic Matching (PairSem), a framework that represents
relevant semantics as entity-aspect pairs, capturing complex, multi-faceted
scientific concepts. PairSem is unsupervised, base retriever-agnostic, and
plug-and-play, enabling precise and context-aware matching without requiring
query-document labels or entity annotations. Extensive experiments on multiple
datasets and retrievers demonstrate that PairSem significantly improves
retrieval performance, highlighting the importance of modeling multi-aspect
semantics in scientific information retrieval.

</details>


### [34] [CardRewriter: Leveraging Knowledge Cards for Long-Tail Query Rewriting on Short-Video Platforms](https://arxiv.org/abs/2510.10095)
*Peiyuan Gong,Feiran Zhu,Yaqi Yin,Chenglei Dai,Chao Zhang,Kai Zheng,Wentian Bao,Jiaxin Mao,Yi Zhang*

Main category: cs.IR

TL;DR: CardRewriter是一个基于LLM的查询重写框架，通过整合领域特定知识来改进短视频平台上的长尾查询重写效果，已在快手平台部署并服务数亿用户。


<details>
  <summary>Details</summary>
Motivation: 短视频平台用户查询（特别是长尾查询）存在拼写错误、表述不完整和意图模糊等问题，导致检索结果与用户期望不匹配。传统LLM在短视频平台上表现不佳，因为专有内容（如短视频、直播、微短剧等）不在其训练分布中。

Method: 提出CardRewriter框架：为每个查询聚合多源相关知识并总结成信息丰富的知识卡片，指导LLM更好地捕捉用户意图并生成更有效的查询重写。采用两阶段训练流程：监督微调后接组相对策略优化，配以平衡查询相关性和检索效果的定制奖励系统。

Result: 离线实验显示CardRewriter显著提高了针对专有内容的查询重写质量。在线A/B测试证实长观看率(LVR)和点击率(CTR)显著提升，同时主动查询重构率(IQRR)明显降低。

Conclusion: CardRewriter成功解决了短视频平台上长尾查询重写的挑战，通过整合领域知识显著提升了查询重写效果，已在快手平台大规模部署并取得显著业务成效。

Abstract: Short-video platforms have rapidly become a new generation of information
retrieval systems, where users formulate queries to access desired videos.
However, user queries, especially long-tail ones, often suffer from spelling
errors, incomplete phrasing, and ambiguous intent, resulting in mismatches
between user expectations and retrieved results. While large language models
(LLMs) have shown success in long-tail query rewriting within e-commerce, they
struggle on short-video platforms, where proprietary content such as short
videos, live streams, micro dramas, and user social networks falls outside
their training distribution. To address this challenge, we introduce
\textbf{CardRewriter}, an LLM-based framework that incorporates domain-specific
knowledge to enhance long-tail query rewriting. For each query, our method
aggregates multi-source knowledge relevant to the query and summarizes it into
an informative and query-relevant knowledge card. This card then guides the LLM
to better capture user intent and produce more effective query rewrites. We
optimize CardRewriter using a two-stage training pipeline: supervised
fine-tuning followed by group relative policy optimization, with a tailored
reward system balancing query relevance and retrieval effectiveness. Offline
experiments show that CardRewriter substantially improves rewriting quality for
queries targeting proprietary content. Online A/B testing further confirms
significant gains in long-view rate (LVR) and click-through rate (CTR), along
with a notable reduction in initiative query reformulation rate (IQRR). Since
September 2025, CardRewriter has been deployed on Kuaishou, one of China's
largest short-video platforms, serving hundreds of millions of users daily.

</details>


### [35] [Integrating Structure-Aware Attention and Knowledge Graphs in Explainable Recommendation Systems](https://arxiv.org/abs/2510.10109)
*Shuangquan Lyu,Ming Wang,Huajun Zhang,Jiasen Zheng,Junjiang Lin,Xiaoxuan Sun*

Main category: cs.IR

TL;DR: 提出了一种结合知识图谱和结构感知注意力机制的可解释推荐模型，通过图神经网络和多跳邻居聚合策略提升隐式偏好关系捕捉能力。


<details>
  <summary>Details</summary>
Motivation: 为了增强推荐系统对隐式偏好关系的捕捉能力，并提高推荐的可解释性，需要整合知识图谱的结构信息和动态注意力机制。

Method: 使用图神经网络构建统一图结构，基于知识图谱实体和关系构建多级语义路径，采用结构感知注意力机制动态分配邻居重要性，使用二元交叉熵损失函数优化模型。

Result: 在Amazon Books数据集上的实验验证了模型在各项评估指标上的优越性能，模型表现出良好的收敛性和稳定性。

Conclusion: 结构感知注意力机制在知识图谱增强推荐中具有显著的有效性和实用性。

Abstract: This paper designs and implements an explainable recommendation model that
integrates knowledge graphs with structure-aware attention mechanisms. The
model is built on graph neural networks and incorporates a multi-hop neighbor
aggregation strategy. By integrating the structural information of knowledge
graphs and dynamically assigning importance to different neighbors through an
attention mechanism, the model enhances its ability to capture implicit
preference relationships. In the proposed method, users and items are embedded
into a unified graph structure. Multi-level semantic paths are constructed
based on entities and relations in the knowledge graph to extract richer
contextual information. During the rating prediction phase, recommendations are
generated through the interaction between user and target item representations.
The model is optimized using a binary cross-entropy loss function. Experiments
conducted on the Amazon Books dataset validate the superior performance of the
proposed model across various evaluation metrics. The model also shows good
convergence and stability. These results further demonstrate the effectiveness
and practicality of structure-aware attention mechanisms in knowledge
graph-enhanced recommendation.

</details>


### [36] [Breaking the Likelihood Trap: Consistent Generative Recommendation with Graph-structured Model](https://arxiv.org/abs/2510.10127)
*Qiya Yang,Xiaoxi Liang,Zeping Xiao,Yingjie Deng,Yalong Wang,Yongqi Liu,Han Li*

Main category: cs.IR

TL;DR: 提出Congrats框架解决生成式重排序中的"似然陷阱"问题，通过图结构解码器提升多样性和准确性，并在快手平台验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式重排序方法存在"似然陷阱"，高似然序列往往质量低，导致重复推荐高频物品和列表同质化，限制了用户参与度。

Method: 提出Congrats框架，包含图结构解码器捕获多路径的多样化序列，以及可微分级联系统结合评估器直接学习用户偏好。

Result: 离线实验显示优于现有重排序方法，在快手3亿日活用户平台上显著提升了推荐质量和多样性。

Conclusion: Congrats通过图结构解码器成功突破了似然陷阱，在工业环境中有效提升了推荐系统的多样性和准确性。

Abstract: Reranking, as the final stage of recommender systems, demands real-time
inference, accuracy, and diversity. It plays a crucial role in determining the
final exposure, directly influencing user experience. Recently, generative
reranking has gained increasing attention for its strong ability to model
complex dependencies among items. However, most existing methods suffer from
the "likelihood trap", where high-likelihood sequences are often perceived as
low-quality by humans. These models tend to repeatedly recommend a set of
high-frequency items, resulting in list homogeneity, thereby limiting user
engagement. In this work, we propose Consistent Graph-structured Generative
Recommendation (Congrats), a novel generative reranking framework. To break the
likelihood trap, we introduce a novel graph-structured decoder that can capture
diverse sequences along multiple paths. This design not only expands the
decoding space to promote diversity, but also improves prediction accuracy by
implicit item dependencies derived from vertex transitions. Furthermore, we
design a differentiable cascade system that incorporates an evaluator, enabling
the model to learn directly from user preferences as the training objective.
Extensive offline experiments validate the superior performance of Congrats
over state-of-the-art reranking methods. Moreover, Congrats has been evaluated
on a large-scale video-sharing app, Kuaishou, with over 300 million daily
active users, demonstrating that our approach significantly improves both
recommendation quality and diversity, validating our effectiveness in practical
industrial environments.

</details>


### [37] [ZeroGR: A Generalizable and Scalable Framework for Zero-Shot Generative Retrieval](https://arxiv.org/abs/2510.10419)
*Weiwei Sun,Keyi Kong,Xinyu Ma,Shuaiqiang Wang,Dawei Yin,Maarten de Rijke,Zhaochun Ren,Yiming Yang*

Main category: cs.IR

TL;DR: ZeroGR是一个零样本生成式检索框架，通过自然语言指令将生成式检索扩展到广泛的IR任务，在零样本设置下优于密集检索和生成基线


<details>
  <summary>Details</summary>
Motivation: 解决生成式检索在零样本IR场景中的泛化问题，这在现实应用中很常见

Method: 包含三个关键组件：基于语言模型的文档ID生成器、指令调优的查询生成器、以及平衡精度和召回的反向退火解码策略

Result: 在BEIR和MAIR基准测试中，ZeroGR在零样本设置下优于强基线方法，建立了指令驱动生成式检索的新SOTA

Conclusion: 通过指令微调可以显著提升生成式检索的零样本性能，且性能随训练中遇到的IR任务数量增加而持续提升

Abstract: Generative retrieval (GR) reformulates information retrieval (IR) by framing
it as the generation of document identifiers (docids), thereby enabling an
end-to-end optimization and seamless integration with generative language
models (LMs). Despite notable progress under supervised training, GR still
struggles to generalize to zero-shot IR scenarios, which are prevalent in
real-world applications. To tackle this challenge, we propose \textsc{ZeroGR},
a zero-shot generative retrieval framework that leverages natural language
instructions to extend GR across a wide range of IR tasks. Specifically,
\textsc{ZeroGR} is composed of three key components: (i) an LM-based docid
generator that unifies heterogeneous documents (e.g., text, tables, code) into
semantically meaningful docids; (ii) an instruction-tuned query generator that
generates diverse types of queries from natural language task descriptions to
enhance corpus indexing; and (iii) a reverse annealing decoding strategy to
balance precision and recall during docid generation. We investigate the impact
of instruction fine-tuning scale and find that performance consistently
improves as the number of IR tasks encountered during training increases.
Empirical results on the BEIR and MAIR benchmarks demonstrate that
\textsc{ZeroGR} outperforms strong dense retrieval and generative baselines in
zero-shot settings, establishing a new state-of-the-art for instruction-driven
GR.

</details>


### [38] [Does Weighting Improve Matrix Factorization for Recommender Systems?](https://arxiv.org/abs/2510.10440)
*Alex Ayoub,Samuel Robertson,Dawen Liang,Harald Steck,Nathan Kallus*

Main category: cs.IR

TL;DR: 对隐式反馈数据中矩阵分解的权重策略进行系统研究，发现未加权数据训练在大模型中表现与加权相当甚至更好，挑战了传统认知，同时识别了权重在低容量模型中的优势。


<details>
  <summary>Details</summary>
Motivation: 矩阵分解在隐式反馈推荐系统中广泛使用，传统做法是对观测交互进行加权以提升性能，但缺乏系统研究来验证这一策略的有效性。

Method: 系统研究各种权重方案和矩阵分解算法，推导出高效算法来精确最小化之前被认为计算不可行的加权目标函数。

Result: 未加权数据训练在大模型中表现与加权相当甚至更好，但在低容量模型和特定正则化方案中权重仍有益处。

Conclusion: 权重策略的效果取决于模型容量和正则化方案，为推荐系统中的矩阵分解提供了关于权重、正则化和模型容量相互作用的全面分析。

Abstract: Matrix factorization is a widely used approach for top-N recommendation and
collaborative filtering. When implemented on implicit feedback data (such as
clicks), a common heuristic is to upweight the observed interactions. This
strategy has been shown to improve performance for certain algorithms. In this
paper, we conduct a systematic study of various weighting schemes and matrix
factorization algorithms. Somewhat surprisingly, we find that training with
unweighted data can perform comparably to, and sometimes outperform, training
with weighted data, especially for large models. This observation challenges
the conventional wisdom. Nevertheless, we identify cases where weighting can be
beneficial, particularly for models with lower capacity and specific
regularization schemes. We also derive efficient algorithms for exactly
minimizing several weighted objectives that were previously considered
computationally intractable. Our work provides a comprehensive analysis of the
interplay between weighting, regularization, and model capacity in matrix
factorization for recommender systems.

</details>


### [39] [Towards Long-Term User Welfare in Recommender Systems via Creator-Oriented Information Revelation](https://arxiv.org/abs/2510.10511)
*Xu Zhao,Xiaopeng Ye,Chen Xu,Weiran Shen,Jun Xu*

Main category: cs.IR

TL;DR: 提出LoRe框架，通过信息揭示而非推荐算法设计来优化推荐系统的长期用户福利，使用贝叶斯说服方法将平台作为发送者、创作者作为接收者，通过MDP建模解决传统经济方法假设不现实的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于重排算法的方法在优化长期用户福利时与短期推荐准确性目标冲突，导致性能下降。受经济学研究启发，通过信息揭示来改变创作者行为，从而构建更健康的推荐系统生态系统。

Method: 提出LoRe框架，使用贝叶斯说服方法进行信息揭示，将平台作为发送者、创作者作为接收者。将信息揭示过程建模为马尔可夫决策过程，并提出在有限理性创作者环境中的学习算法。

Result: 在两个真实世界推荐系统数据集上的实验表明，该方法在提升长期用户福利方面优于现有的公平重排方法和信息揭示策略。

Conclusion: 信息揭示框架LoRe能有效提升推荐系统的长期用户福利，为优化推荐生态系统提供了新的方法路径。

Abstract: Improving the long-term user welfare (e.g., sustained user engagement) has
become a central objective of recommender systems (RS). In real-world
platforms, the creation behaviors of content creators plays a crucial role in
shaping long-term welfare beyond short-term recommendation accuracy, making the
effective steering of creator behavior essential to foster a healthier RS
ecosystem. Existing works typically rely on re-ranking algorithms that
heuristically adjust item exposure to steer creators' behavior. However, when
embedded within recommendation pipelines, such a strategy often conflicts with
the short-term objective of improving recommendation accuracy, leading to
performance degradation and suboptimal long-term welfare. The well-established
economics studies offer us valuable insights for an alternative approach
without relying on recommendation algorithmic design: revealing information
from an information-rich party (sender) to a less-informed party (receiver) can
effectively change the receiver's beliefs and steer their behavior. Inspired by
this idea, we propose an information-revealing framework, named Long-term
Welfare Optimization via Information Revelation (LoRe). In this framework, we
utilize a classical information revelation method (i.e., Bayesian persuasion)
to map the stakeholders in RS, treating the platform as the sender and creators
as the receivers. To address the challenge posed by the unrealistic assumption
of traditional economic methods, we formulate the process of information
revelation as a Markov Decision Process (MDP) and propose a learning algorithm
trained and inferred in environments with boundedly rational creators.
Extensive experiments on two real-world RS datasets demonstrate that our method
can effectively outperform existing fair re-ranking methods and information
revealing strategies in improving long-term user welfare.

</details>


### [40] [Self-Supervised Representation Learning with ID-Content Modality Alignment for Sequential Recommendation](https://arxiv.org/abs/2510.10556)
*Donglin Zhou,Weike Pan,Zhong Ming*

Main category: cs.IR

TL;DR: 提出SICSRec模型，通过自监督表示学习和ID-内容模态对齐，解决基于内容的序列推荐中的三个关键挑战：模态表示语义鸿沟、行为偏好与内容偏好联合建模、ID与内容表示对齐训练策略。


<details>
  <summary>Details</summary>
Motivation: 传统序列推荐模型依赖历史交互物品ID，在交互历史有限时性能不佳。基于内容的序列推荐利用物品的文本和视觉特征增强偏好学习，但仍面临模态表示语义鸿沟、偏好联合建模和表示对齐等挑战。

Method: 1) 提出LLM驱动的样本构建方法和监督微调方法对齐物品级模态表示；2) 设计基于Transformer的序列模型，包含ID模态序列编码器、内容模态序列编码器和混合模态序列解码器；3) 采用两步训练策略和内容感知对比学习任务对齐模态表示和ID表示。

Result: 在四个公共视频流数据集上的实验表明，SICSRec在NDCG@5和NDCG@10上分别平均优于最先进的ID模态序列推荐器和内容模态序列推荐器8.04%和6.62%。

Conclusion: SICSRec通过有效的模态对齐和联合建模方法，显著提升了序列推荐的性能，特别是在交互历史有限的情况下。

Abstract: Sequential recommendation (SR) models often capture user preferences based on
the historically interacted item IDs, which usually obtain sub-optimal
performance when the interaction history is limited. Content-based sequential
recommendation has recently emerged as a promising direction that exploits
items' textual and visual features to enhance preference learning. However,
there are still three key challenges: (i) how to reduce the semantic gap
between different content modality representations; (ii) how to jointly model
user behavior preferences and content preferences; and (iii) how to design an
effective training strategy to align ID representations and content
representations. To address these challenges, we propose a novel model,
self-supervised representation learning with ID-Content modality alignment,
named SICSRec. Firstly, we propose a LLM-driven sample construction method and
develop a supervised fine-tuning approach to align item-level modality
representations. Secondly, we design a novel Transformer-based sequential
model, where an ID-modality sequence encoder captures user behavior
preferences, a content-modality sequence encoder learns user content
preferences, and a mix-modality sequence decoder grasps the intrinsic
relationship between these two types of preferences. Thirdly, we propose a
two-step training strategy with a content-aware contrastive learning task to
align modality representations and ID representations, which decouples the
training process of content modality dependency and item collaborative
dependency. Extensive experiments conducted on four public video streaming
datasets demonstrate our SICSRec outperforms the state-of-the-art ID-modality
sequential recommenders and content-modality sequential recommenders by 8.04%
on NDCG@5 and 6.62% on NDCD@10 on average, respectively.

</details>


### [41] [Multi-Granularity Sequence Denoising with Weakly Supervised Signal for Sequential Recommendation](https://arxiv.org/abs/2510.10564)
*Liang Li,Zhou Yang,Xiaofei Zhu*

Main category: cs.IR

TL;DR: 提出MGSD-WSS方法，通过多粒度序列去噪和弱监督信号解决序列推荐中的噪声问题，在五个数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 历史交互序列常包含无关噪声项，现有无监督方法缺乏显式噪声标签，容易误判用户兴趣项为噪声，且只关注项目粒度噪声而忽略兴趣粒度噪声。

Method: 使用多高斯核感知器模块映射序列到共同表示空间，利用弱监督信号识别噪声项；采用噪声加权对比学习获得去噪的项目表示和兴趣表示；基于去噪表示预测下一个项目。

Result: 在五个数据集上的大量实验表明，该方法显著优于最先进的序列推荐和去噪模型。

Conclusion: MGSD-WSS通过多粒度序列去噪和弱监督信号有效解决了序列推荐中的噪声问题，提升了推荐性能。

Abstract: Sequential recommendation aims to predict the next item based on user
interests in historical interaction sequences. Historical interaction sequences
often contain irrelevant noisy items, which significantly hinders the
performance of recommendation systems. Existing research employs unsupervised
methods that indirectly identify item-granularity irrelevant noise by
predicting the ground truth item. Since these methods lack explicit noise
labels, they are prone to misidentify users' interested items as noise.
Additionally, while these methods focus on removing item-granularity noise
driven by the ground truth item, they overlook interest-granularity noise,
limiting their ability to perform broader denoising based on user interests. To
address these issues, we propose Multi-Granularity Sequence Denoising with
Weakly Supervised Signal for Sequential Recommendation(MGSD-WSS). MGSD-WSS
first introduces the Multiple Gaussian Kernel Perceptron module to map the
original and enhance sequence into a common representation space and utilizes
weakly supervised signals to accurately identify noisy items in the historical
interaction sequence. Subsequently, it employs the item-granularity denoising
module with noise-weighted contrastive learning to obtain denoised item
representations. Then, it extracts target interest representations from the
ground truth item and applies noise-weighted contrastive learning to obtain
denoised interest representations. Finally, based on the denoised item and
interest representations, MGSD-WSS predicts the next item. Extensive
experiments on five datasets demonstrate that the proposed method significantly
outperforms state-of-the-art sequence recommendation and denoising models. Our
code is available at https://github.com/lalunex/MGSD-WSS.

</details>


### [42] [VeritasFi: An Adaptable, Multi-tiered RAG Framework for Multi-modal Financial Question Answering](https://arxiv.org/abs/2510.10828)
*Zhenghan Tai,Hanwei Wu,Qingchen Hu,Jijun Chi,Hailin He,Lei Ding,Tung Sum Thomas Kwok,Bohuai Xiao,Yuchen Hua,Suyuchen Wang,Peng Lu,Muzhi Li,Yihong Wu,Liheng Ma,Jerry Huang,Jiayi Zhang,Gonghao Zhang,Chaolong Jiang,Jingrui Tian,Sicheng Lyu,Zeyu Li,Boyu Han,Fengran Mo,Xinyue Yu,Yufei Cui,Ling Zhou,Xinyu Wang*

Main category: cs.IR

TL;DR: VeritasFi是一个创新的混合检索增强生成框架，专门针对金融领域问答系统，通过多模态预处理、三重混合检索引擎和两阶段训练策略，解决了处理异构数据和平衡通用性与公司特定适应性两大挑战。


<details>
  <summary>Details</summary>
Motivation: 现有金融RAG系统面临两大挑战：难以处理文本、表格、图形等异构数据格式，以及在通用领域适用性和公司特定适应性之间难以平衡。这些问题限制了金融问答系统的准确性和实用性。

Method: 1. 多模态预处理管道将异构数据转换为连贯的机器可读格式；2. 三重混合检索引擎并行运行，包括基于语义索引的深度多路径检索、通过工具获取实时数据、专家策划的记忆库；3. 两阶段训练策略：先用匿名数据构建通用领域特定模型，再在公司特定数据上快速微调。

Result: VeritasFi显著提升了金融RAG系统的适应性和鲁棒性，为通用领域和公司特定问答任务提供了可扩展的解决方案。代码已在GitHub开源。

Conclusion: VeritasFi通过集成多模态处理、混合检索和两阶段训练，为金融问答系统提供了一个突破性的框架，有效解决了现有系统的局限性，提升了系统的全面性、准确性和效率。

Abstract: Retrieval-Augmented Generation (RAG) is becoming increasingly essential for
Question Answering (QA) in the financial sector, where accurate and
contextually grounded insights from complex public disclosures are crucial.
However, existing financial RAG systems face two significant challenges: (1)
they struggle to process heterogeneous data formats, such as text, tables, and
figures; and (2) they encounter difficulties in balancing general-domain
applicability with company-specific adaptation. To overcome these challenges,
we present VeritasFi, an innovative hybrid RAG framework that incorporates a
multi-modal preprocessing pipeline alongside a cutting-edge two-stage training
strategy for its re-ranking component. VeritasFi enhances financial QA through
three key innovations: (1) A multi-modal preprocessing pipeline that seamlessly
transforms heterogeneous data into a coherent, machine-readable format. (2) A
tripartite hybrid retrieval engine that operates in parallel, combining deep
multi-path retrieval over a semantically indexed document corpus, real-time
data acquisition through tool utilization, and an expert-curated memory bank
for high-frequency questions, ensuring comprehensive scope, accuracy, and
efficiency. (3) A two-stage training strategy for the document re-ranker, which
initially constructs a general, domain-specific model using anonymized data,
followed by rapid fine-tuning on company-specific data for targeted
applications. By integrating our proposed designs, VeritasFi presents a
groundbreaking framework that greatly enhances the adaptability and robustness
of financial RAG systems, providing a scalable solution for both general-domain
and company-specific QA tasks. Code accompanying this work is available at
https://github.com/simplew4y/VeritasFi.git.

</details>


### [43] [Comparative Explanations via Counterfactual Reasoning in Recommendations](https://arxiv.org/abs/2510.10920)
*Yi Yu,Zhenxing Hu*

Main category: cs.IR

TL;DR: 提出CoCountER方法，通过软交换操作生成反事实数据，为任意对比商品对提供推荐解释，解决现有方法导致解释事实不准确的问题。


<details>
  <summary>Details</summary>
Motivation: 现有可解释推荐方法通过最小化商品属性变化来反转推荐决策，但常导致解释存在事实不准确问题。

Method: CoCountER方法基于软交换操作创建反事实数据，能够为任意对比商品对生成推荐解释。

Result: 实证实验验证了该方法的有效性。

Conclusion: CoCountER方法通过比较性反事实解释改进了推荐系统的可解释性，解决了事实不准确问题。

Abstract: Explainable recommendation through counterfactual reasoning seeks to identify
the influential aspects of items in recommendations, which can then be used as
explanations. However, state-of-the-art approaches, which aim to minimize
changes in product aspects while reversing their recommended decisions
according to an aggregated decision boundary score, often lead to factual
inaccuracies in explanations. To solve this problem, in this work we propose a
novel method of Comparative Counterfactual Explanations for Recommendation
(CoCountER). CoCountER creates counterfactual data based on soft swap
operations, enabling explanations for recommendations of arbitrary pairs of
comparative items. Empirical experiments validate the effectiveness of our
approach.

</details>


### [44] [HatLLM: Hierarchical Attention Masking for Enhanced Collaborative Modeling in LLM-based Recommendation](https://arxiv.org/abs/2510.10955)
*Yu Cui,Feng Liu,Jiawei Chen,Canghong Jin,Xingyu Lou,Changwang Zhang,Jun Wang,Yuegang Sun,Can Wang*

Main category: cs.IR

TL;DR: 提出了一种名为HatLLM的分层注意力掩码策略，用于解决LLM在序列推荐中难以有效建模协同信号的问题，通过浅层屏蔽跨项注意力、深层屏蔽项内注意力，显著提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: LLM在序列推荐中虽然能进行细粒度语义推理，但难以有效建模用户历史交互中的协同信号，且注意力机制倾向于过度关注同一项目内的token，阻碍了跨项目相关性的捕捉。

Method: 提出分层注意力掩码策略HatLLM：在浅层屏蔽不同项目间token的注意力，促进项目内语义理解；在深层屏蔽项目内token的注意力，强制模型捕捉跨项目相关性。

Result: 在三个真实世界数据集上的实验表明，HatLLM相比现有LLM方法平均提升了9.13%的性能。

Conclusion: 分层注意力掩码策略能有效解决LLM在推荐系统中的协同信号建模问题，实现了token级和项目级依赖关系的联合建模。

Abstract: Recent years have witnessed a surge of research on leveraging large language
models (LLMs) for sequential recommendation. LLMs have demonstrated remarkable
potential in inferring users' nuanced preferences through fine-grained semantic
reasoning. However, they also exhibit a notable limitation in effectively
modeling collaborative signals, i.e., behavioral correlations inherent in
users' historical interactions. Our empirical analysis further reveals that the
attention mechanisms in LLMs tend to disproportionately focus on tokens within
the same item, thereby impeding the capture of cross-item correlations.
  To address this limitation, we propose a novel hierarchical attention masking
strategy for LLM-based recommendation, termed HatLLM. Specifically, in shallow
layers, HatLLM masks attention between tokens from different items,
facilitating intra-item semantic understanding; in contrast, in deep layers,
HatLLM masks attention within items, thereby compelling the model to capture
cross-item correlations. This progressive, layer-wise approach enables LLMs to
jointly model both token-level and item-level dependencies. Extensive
experiments on three real-world datasets demonstrate that HatLLM achieves
significant performance gains (9.13% on average) over existing LLM-based
methods.

</details>


### [45] [Does LLM Focus on the Right Words? Diagnosing Language Bias in LLM-based Recommenders](https://arxiv.org/abs/2510.10978)
*Bohao Wang,Jiawei Chen,Feng Liu,Changwang Zhang,Jun Wang,Canghong Jin,Chun Chen,Can Wang*

Main category: cs.IR

TL;DR: 提出GDRT方法解决LLM在推荐系统中因监督微调导致的语言偏见问题，通过组分布鲁棒优化确保模型在不同token组间性能一致，显著提升推荐准确性和公平性。


<details>
  <summary>Details</summary>
Motivation: LLM在推荐系统中存在预训练目标与推荐任务需求之间的差距，监督微调虽然能提升预测能力，但会引发语言偏见——模型过度依赖辅助token而忽视核心用户交互token，影响推荐准确性和公平性。

Method: 提出GDRT（组分布鲁棒优化调优）方法，通过强制模型在与辅助token相关性不同的token组间保持一致的性能表现，自适应地提升表现较差组的权重，使模型从表面辅助线索转向信息丰富的用户交互token。

Result: 在三个公开数据集上的实验表明，GDRT有效缓解了语言偏见，推荐准确性显著提升（NDCG@10平均增益24.29%），同时大幅改善了推荐公平性。

Conclusion: GDRT通过组分布鲁棒优化有效解决了LLM在推荐系统中的语言偏见问题，实现了更准确和公平的推荐效果。

Abstract: Large language models (LLMs), owing to their extensive open-domain knowledge
and semantic reasoning capabilities, have been increasingly integrated into
recommender systems (RS). However, a substantial gap remains between the
pre-training objectives of LLMs and the specific requirements of recommendation
tasks. To address this gap, supervised fine-tuning (SFT) is commonly performed
on specially curated recommendation datasets to further enhance their
predictive ability. Despite its success, SFT exhibits a critical limitation: it
induces Language Bias, whereby the model over-relies on auxiliary tokens-such
as task descriptions and prefix-generated tokens-while underutilizing core user
interaction tokens that encode user-specific preferences. This bias not only
undermines recommendation accuracy but also raises unfairness concerns.
  To address this issue, we propose Group Distributionally Robust
Optimization-based Tuning (GDRT), a novel fine-tuning paradigm that enforces
consistent model performance across token groups with varying degrees of
relevance to auxiliary tokens. By adaptively upweighting underperforming
groups, typically those weakly correlated with auxiliary tokens, GDRT shifts
the model's attention from superficial auxiliary cues to informative user
interaction tokens, thereby mitigating language bias. Extensive experiments
conducted on three public datasets demonstrate that GDRT effectively mitigates
language bias, yielding substantial improvements in recommendation accuracy
(with an average NDCG@10 gain of 24.29%) and significantly enhancing
recommendation fairness.

</details>


### [46] [From Reasoning LLMs to BERT: A Two-Stage Distillation Framework for Search Relevance](https://arxiv.org/abs/2510.11056)
*Runze Xia,Yupeng Ji,Yuxi Zhou,Haodong Liu,Teng Zhang,Piji Li*

Main category: cs.IR

TL;DR: 提出两阶段推理蒸馏框架，将大型语言模型的推理能力迁移到轻量级学生模型中，解决电商搜索中查询-服务相关性预测的延迟限制问题。


<details>
  <summary>Details</summary>
Motivation: 电商搜索系统中的查询-服务相关性预测面临严格的延迟要求，无法直接应用大型语言模型，需要开发轻量级但具备推理能力的模型。

Method: 第一阶段构建领域适应教师模型：领域自适应预训练注入平台知识，监督微调激发推理技能，多维度奖励模型偏好优化。第二阶段引入对比推理自蒸馏，通过标准输入和推理增强输入的对比学习，让学生模型内化教师决策机制。

Result: 在美团搜索广告系统的离线和在线A/B测试中，该框架在多个指标上取得显著改进，验证了其有效性和实用价值。

Conclusion: 该两阶段推理蒸馏框架成功解决了LLM在电商搜索中的延迟限制，实现了推理能力的有效迁移，具有重要的实际应用价值。

Abstract: Query-service relevance prediction in e-commerce search systems faces strict
latency requirements that prevent the direct application of Large Language
Models (LLMs). To bridge this gap, we propose a two-stage reasoning
distillation framework to transfer reasoning capabilities from a powerful
teacher LLM to a lightweight, deployment-friendly student model. In the first
stage, we address the limitations of general-purpose LLMs by constructing a
domain-adapted teacher model. This is achieved through a three-step process:
domain-adaptive pre-training to inject platform knowledge, supervised
fine-tuning to elicit reasoning skills, and preference optimization with a
multi-dimensional reward model to ensure the generation of reliable and
preference-aligned reasoning paths. This teacher can then automatically
annotate massive query-service pairs from search logs with both relevance
labels and reasoning chains. In the second stage, to address the challenges of
architectural heterogeneity in standard distillation, we introduce Contrastive
Reasoning Self-Distillation (CRSD). By modeling the behavior of the same
student model under "standard" and "reasoning-augmented" inputs as a
teacher-student relationship, CRSD enables the lightweight model to internalize
the teacher's complex decision-making mechanisms without needing the explicit
reasoning path at inference. Offline evaluations and online A/B testing in the
Meituan search advertising system demonstrate that our framework achieves
significant improvements across multiple metrics, validating its effectiveness
and practical value.

</details>


### [47] [Decoupled Multimodal Fusion for User Interest Modeling in Click-Through Rate Prediction](https://arxiv.org/abs/2510.11066)
*Alin Fan,Hanqing Li,Sihan Lu,Jingsong Yuan,Jiandong Zhang*

Main category: cs.IR

TL;DR: 提出解耦多模态融合(DMF)方法，通过模态增强建模策略实现ID协作表示与多模态表示之间的细粒度交互，提升推荐系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法采用模态中心建模策略，独立处理ID和多模态嵌入，无法捕捉内容语义与行为信号之间的细粒度交互。

Method: 构建目标感知特征桥接不同嵌入空间的语义鸿沟，设计推理优化的注意力机制解耦目标感知特征与ID嵌入的计算，结合模态中心和模态增强建模策略。

Result: 在公共和工业数据集上验证有效性，在Lazada电商平台部署后，CTCVR相对提升5.30%，GMV相对提升7.43%，计算开销可忽略。

Conclusion: DMF通过模态增强建模和优化注意力机制，有效提升多模态推荐系统性能，具有实际部署价值。

Abstract: Modern industrial recommendation systems improve recommendation performance
by integrating multimodal representations from pre-trained models into ID-based
Click-Through Rate (CTR) prediction frameworks. However, existing approaches
typically adopt modality-centric modeling strategies that process ID-based and
multimodal embeddings independently, failing to capture fine-grained
interactions between content semantics and behavioral signals. In this paper,
we propose Decoupled Multimodal Fusion (DMF), which introduces a
modality-enriched modeling strategy to enable fine-grained interactions between
ID-based collaborative representations and multimodal representations for user
interest modeling. Specifically, we construct target-aware features to bridge
the semantic gap across different embedding spaces and leverage them as side
information to enhance the effectiveness of user interest modeling.
Furthermore, we design an inference-optimized attention mechanism that
decouples the computation of target-aware features and ID-based embeddings
before the attention layer, thereby alleviating the computational bottleneck
introduced by incorporating target-aware features. To achieve comprehensive
multimodal integration, DMF combines user interest representations learned
under the modality-centric and modality-enriched modeling strategies. Offline
experiments on public and industrial datasets demonstrate the effectiveness of
DMF. Moreover, DMF has been deployed on the product recommendation system of
the international e-commerce platform Lazada, achieving relative improvements
of 5.30% in CTCVR and 7.43% in GMV with negligible computational overhead.

</details>


### [48] [HoMer: Addressing Heterogeneities by Modeling Sequential and Set-wise Contexts for CTR Prediction](https://arxiv.org/abs/2510.11100)
*Shuwei Chen,Jiajun Cui,Zhengqi Xu,Fan Zhang,Jiangke Fan,Teng Zhang,Xingxing Wang*

Main category: cs.IR

TL;DR: HoMer是一个面向同质化的Transformer模型，用于解决CTR预测中的特征异构性、上下文异构性和架构异构性问题，通过特征对齐、集合预测和统一架构实现性能提升和资源节省。


<details>
  <summary>Details</summary>
Motivation: 解决工业推荐系统中CTR预测面临的三种异构性问题：特征异构性（序列特征与非序列特征的不平衡）、上下文异构性（点预测忽略跨项目交互）、架构异构性（模块化集成导致效率问题）。

Method: 1. 序列侧特征与非序列特征对齐；2. 从点预测转向集合预测；3. 采用统一的编码器-解码器架构实现结构简化和计算共享。

Result: 在工业基准上AUC提升0.0099，在线业务指标CTR/RPM分别提升1.99%/2.46%，通过工程优化节省27%GPU资源。

Conclusion: HoMer通过同质化设计有效解决了CTR预测中的异构性问题，在保持可扩展性的同时显著提升了预测性能和计算效率。

Abstract: Click-through rate (CTR) prediction, which models behavior sequence and
non-sequential features (e.g., user/item profiles or cross features) to infer
user interest, underpins industrial recommender systems. However, most methods
face three forms of heterogeneity that degrade predictive performance: (i)
Feature Heterogeneity persists when limited sequence side features provide less
granular interest representation compared to extensive non-sequential features,
thereby impairing sequence modeling performance; (ii) Context Heterogeneity
arises because a user's interest in an item will be influenced by other items,
yet point-wise prediction neglects cross-item interaction context from the
entire item set; (iii) Architecture Heterogeneity stems from the fragmented
integration of specialized network modules, which compounds the model's
effectiveness, efficiency and scalability in industrial deployments. To tackle
the above limitations, we propose HoMer, a Homogeneous-Oriented TransforMer for
modeling sequential and set-wise contexts. First, we align sequence side
features with non-sequential features for accurate sequence modeling and
fine-grained interest representation. Second, we shift the prediction paradigm
from point-wise to set-wise, facilitating cross-item interaction in a highly
parallel manner. Third, HoMer's unified encoder-decoder architecture achieves
dual optimization through structural simplification and shared computation,
ensuring computational efficiency while maintaining scalability with model
size. Without arduous modification to the prediction pipeline, HoMer
successfully scales up and outperforms our industrial baseline by 0.0099 in the
AUC metric, and enhances online business metrics like CTR/RPM by 1.99%/2.46%.
Additionally, HoMer saves 27% of GPU resources via preliminary engineering
optimization, further validating its superiority and practicality.

</details>


### [49] [DyKnow-RAG: Dynamic Knowledge Utilization Reinforcement Framework for Noisy Retrieval-Augmented Generation in E-commerce Search Relevance](https://arxiv.org/abs/2510.11122)
*Tingqiao Xu,Shaowei Yao,Chenhe Dong,Yiming Jin,Zerui Huang,Dan Ou,Haihong Tang*

Main category: cs.IR

TL;DR: DyKnow-RAG是一个动态噪声RAG框架，用于电商排序中的查询-商品相关性建模。它通过Group Relative Policy Optimization训练两个rollout组（无外部上下文vs单个检索块），并应用后验驱动的组间优势缩放，自适应地根据每个查询的正确性差距重新加权它们的贡献。


<details>
  <summary>Details</summary>
Motivation: 准确建模查询-商品相关性对电商排序至关重要，但长尾、知识密集和快速演变的查询超出了参数化LLM的覆盖范围。外部上下文（评论、属性百科、UGC）有帮助但存在噪声，且单次延迟和成本不允许任何先清理后总结的步骤。

Method: 基于Group Relative Policy Optimization构建动态噪声RAG框架，训练两个rollout组，应用后验驱动的组间优势缩放。训练结合：(1)带结构化原理的监督初始化；(2)基于SFT不确定性的RL池优先；(3)可选的轻量级DPO预热启动。

Result: 在统一的检索/索引和固定延迟预算下，DyKnow-RAG在离线测试中优于SFT、DPO和普通GRPO，在淘宝A/B测试中对GSB、Query Goodrate和Item Goodrate指标带来持续提升。

Conclusion: DyKnow-RAG已部署在淘宝生产相关性系统中服务实时流量，是首批用于电商相关性的单次RAG解决方案之一，将噪声外部信号转化为可靠收益而不增加在线复杂性。

Abstract: Accurately modeling query-item relevance drives e-commerce ranking, yet
long-tail, knowledge-heavy, and fast-evolving queries exceed parametric LLM
coverage. External context (reviews, attribute encyclopedias, UGC) can help but
is noisy, and single-pass latency and cost forbid any clean-then-summarize
step. The model must, per query, judge relevance and decide whether to use,
partially use, or ignore the context. DyKnow-RAG is a dynamic noisy-RAG
framework built on Group Relative Policy Optimization. It trains two rollout
groups (no external context vs a single retrieved chunk) and applies
posterior-driven inter-group advantage scaling that adaptively reweights their
contributions by the per-query correctness gap. This teaches when to trust
retrieval versus fall back to parametric knowledge, without process labels,
value networks, or extra inference passes, preserving single-pass, single-chunk
deployment under production latency. Training combines: (1) supervised
initialization with a structured rationale that explicitly records the
context-usage decision; (2) an RL pool prioritized by SFT uncertainty to focus
where context choice is most consequential; and (3) an optional lightweight DPO
warm start to stabilize with-context calibration. Under a unified
retrieval/index and fixed latency budget, DyKnow-RAG outperforms SFT, DPO, and
vanilla GRPO in offline tests, and delivers consistent lifts on GSB, Query
Goodrate, and Item Goodrate in Taobao A/B testing. It is deployed in Taobao's
production relevance system, serving live traffic. To our knowledge, it is
among the first single-pass RAG solutions for e-commerce relevance, turning
noisy external signals into reliable gains without added online complexity.

</details>


### [50] [Next Interest Flow: A Generative Pre-training Paradigm for Recommender Systems by Modeling All-domain Movelines](https://arxiv.org/abs/2510.11317)
*Chen Gao,Zixin Zhao,Lv Shao,Tong Liu*

Main category: cs.IR

TL;DR: 提出AMEN框架，通过生成式预训练预测用户未来兴趣流，解决现有CTR预测方法中语义不匹配和冷启动问题，并通过双向对齐策略协调生成和判别阶段。


<details>
  <summary>Details</summary>
Motivation: 现有CTR预测主要基于判别模型，被动响应用户历史行为而非主动建模用户意图。基于LLM的方法存在语义不匹配问题，而基于ID的生成方法受限于物品记忆和冷启动问题。

Method: 提出AMEN框架：1）生成式预训练预测Next Interest Flow（密集向量序列）；2）建模兴趣多样性和演化速度；3）双向对齐策略协调生成和判别阶段；4）TSP机制增强时序因果关系建模。

Result: 离线实验显示AMEN优于强基线，大规模在线A/B测试证明其在关键业务指标上带来显著提升。

Conclusion: AMEN通过生成式预训练和双向对齐策略，成功解决了CTR预测中的意图建模问题，在实际应用中取得了显著效果。

Abstract: Click-Through Rate (CTR) prediction, a cornerstone of modern recommender
systems, has been dominated by discriminative models that react to past user
behavior rather than proactively modeling user intent. Existing generative
paradigms attempt to address this but suffer from critical limitations: Large
Language Model (LLM) based methods create a semantic mismatch by forcing
e-commerce signals into a linguistic space, while ID-based generation is
constrained by item memorization and cold-start issues. To overcome these
limitations, we propose a novel generative pre-training paradigm. Our model
learns to predict the Next Interest Flow, a dense vector sequence representing
a user's future intent, while simultaneously modeling its internal Interest
Diversity and Interest Evolution Velocity to ensure the representation is both
rich and coherent. However, this two-stage approach introduces a critical
objective mismatch between the generative and discriminative stages. We resolve
this via a bidirectional alignment strategy, which harmonizes the two stages
through cross-stage weight initialization and a dynamic Semantic Alignment
Module for fine-tuning. Additionally, we enhance the underlying discriminative
model with a Temporal Sequential Pairwise (TSP) mechanism to better capture
temporal causality. We present the All-domain Moveline Evolution Network
(AMEN), a unified framework implementing our entire pipeline. Extensive offline
experiments validate AMEN's superiority over strong baselines, and a
large-scale online A/B test demonstrates its significant real-world impact,
delivering substantial improvements in key business metrics.

</details>


### [51] [Dynamic Network-Based Two-Stage Time Series Forecasting for Affiliate Marketing](https://arxiv.org/abs/2510.11323)
*Zhe Wang,Yaming Yang,Ziyu Guan,Bin Tong,Rui Wang,Wei Zhao,Hongbo Deng*

Main category: cs.IR

TL;DR: 本文提出了一种评估联盟营销中推广者间接贡献的新指标——传播规模，并开发了一个两阶段预测模型来解决现有时间序列预测技术无法准确预测该指标的问题。


<details>
  <summary>Details</summary>
Motivation: 联盟营销中准确评估和预测推广者在产品推广中的贡献是一个关键但未被充分探索的挑战，现有技术由于传播规模受多种因素影响和动态场景的复杂性而无法提供准确预测。

Method: 提出两阶段解决方案：首先分别进行基础自销售和网络结构预测，然后合成传播规模。设计了基于后代邻居的图卷积编码方案，并引入超图卷积来有效捕捉复杂的推广动态。使用三个辅助任务：自销售预测、后代预测和推广者激活预测。

Result: 在大规模工业数据集上的离线实验验证了方法的优越性。在Alimama平台上部署了包含超过10万推广者的模型，GMV提升了9.29%，销售量增加了5.89%。

Conclusion: 该方法能够有效解决联盟营销中推广者贡献评估的挑战，在实际应用中取得了显著的业务提升。

Abstract: In recent years, affiliate marketing has emerged as a revenue-sharing
strategy where merchants collaborate with promoters to promote their products.
It not only increases product exposure but also allows promoters to earn a
commission. This paper addresses the pivotal yet under-explored challenge in
affiliate marketing: accurately assessing and predicting the contributions of
promoters in product promotion. We design a novel metric for evaluating the
indirect contributions of the promoter, called propagation scale.
Unfortunately, existing time series forecasting techniques fail to deliver
accurate predictions due to the propagation scale being influenced by multiple
factors and the inherent complexities arising from dynamic scenarios. To
address this issue, we decouple the network structure from the node signals and
propose a two-stage solution: initially, the basic self-sales and network
structure prediction are conducted separately, followed by the synthesis of the
propagation scale. Specifically, we design a graph convolution encoding scheme
based on descendant neighbors and incorporate hypergraph convolution to
efficiently capture complex promotional dynamics. Additionally, three auxiliary
tasks are employed: self-sales prediction for base estimations, descendant
prediction to synthesize propagation scale, and promoter activation prediction
to mitigate high volatility issues. Extensive offline experiments on
large-scale industrial datasets validate the superiority of our method. We
further deploy our model on Alimama platform with over $100,000$ promoters,
achieving a $9.29\%$ improvement in GMV and a $5.89\%$ increase in sales
volume.

</details>


### [52] [VeriCite: Towards Reliable Citations in Retrieval-Augmented Generation via Rigorous Verification](https://arxiv.org/abs/2510.11394)
*Haosheng Qian,Yixing Fan,Jiafeng Guo,Ruqing Zhang,Qi Chen,Dawei Yin,Xueqi Cheng*

Main category: cs.IR

TL;DR: 提出VeriCite框架，通过三阶段生成过程（初始答案生成、支持证据选择、最终答案精炼）来验证RAG生成内容并增强答案归因，显著提升引用质量同时保持答案正确性。


<details>
  <summary>Details</summary>
Motivation: RAG方法在复杂问答任务中表现出色，但仍存在幻觉问题。现有引用生成方法要么需要大量标注数据和计算资源进行微调，要么在管理多个引用时效果不佳。需要一种更有效的方法来验证支持证据并增强答案归因。

Method: VeriCite框架包含三阶段：1）初始答案生成，基于所有可用上下文生成响应并通过NLI模型验证声明；2）支持证据选择，评估每个文档的效用并提取有用证据；3）最终答案精炼，整合初始响应和收集的证据生成最终精炼答案。

Result: 在五个开源LLM和四个数据集上的实验表明，VeriCite能够显著提高引用质量，同时保持答案的正确性。

Conclusion: VeriCite框架通过严谨的证据验证和答案归因机制，有效解决了RAG中的幻觉问题，提供了一种高效的引用生成方法。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a crucial approach for
enhancing the responses of large language models (LLMs) with external knowledge
sources. Despite the impressive performance in complex question-answering
tasks, RAG still struggles with hallucinations. Attributing RAG-generated
content through in-line citations has demonstrated potential in reducing
hallucinations and facilitating human verification. Existing citation
generation methods primarily rely on either fine-tuning the generator or
employing post-processing approaches for citation matching. However, the former
approach demands substantial annotated data and computational resources, while
the latter often encounters difficulties in managing multiple citations and
frequently produces suboptimal results. In this paper, we introduce a novel
framework, called VeriCite, designed to rigorously validate supporting evidence
and enhance answer attribution. Specifically, VeriCite breaks down into a
three-stage generation: 1) The initial answer generation first generates a
response based on all available contexts and has its claims verified through
the NLI model; 2) the supporting evidence selection assesses the utility of
each document and extracts useful supporting evidences; 3) the final answer
refinement integrates the initial response and collected evidences to produce
the final, refined answer.We conduct experiments across five open-source LLMs
and four datasets, demonstrating that VeriCite can significantly improve
citation quality while maintaining the correctness of the answers.

</details>


### [53] [On Inherited Popularity Bias in Cold-Start Item Recommendation](https://arxiv.org/abs/2510.11402)
*Gregor Meehan,Johan Pauwels*

Main category: cs.IR

TL;DR: 冷启动推荐系统会继承热模型中的流行度偏差，甚至更严重，因为它们只能基于内容特征来估计流行度，导致对与热门物品内容相似的冷物品过度预测。


<details>
  <summary>Details</summary>
Motivation: 现有冷启动推荐系统通过监督学习模仿热CF模型的行为，但可能同时学习其预测偏差，特别是流行度偏差，这会加剧推荐系统的不公平性。

Method: 在三个多媒体数据集上分析三种生成式冷启动方法，并提出一种简单的后处理偏差缓解方法，使用嵌入向量大小作为预测流行度的代理。

Result: 实验表明冷启动推荐器不仅镜像热模型的流行度偏差，而且受影响更严重，会过度预测与热门物品内容相似的冷物品，即使其真实流行度很低。

Conclusion: 通过使用嵌入向量大小作为流行度代理的后处理方法，可以在有限损害用户导向冷启动准确性的情况下，产生更平衡的推荐结果。

Abstract: Collaborative filtering (CF) recommender systems struggle with making
predictions on unseen, or 'cold', items. Systems designed to address this
challenge are often trained with supervision from warm CF models in order to
leverage collaborative and content information from the available interaction
data. However, since they learn to replicate the behavior of CF methods,
cold-start models may therefore also learn to imitate their predictive biases.
In this paper, we show that cold-start systems can inherit popularity bias, a
common cause of recommender system unfairness arising when CF models overfit to
more popular items, thereby maximizing user-oriented accuracy but neglecting
rarer items. We demonstrate that cold-start recommenders not only mirror the
popularity biases of warm models, but are in fact affected more severely:
because they cannot infer popularity from interaction data, they instead
attempt to estimate it based solely on content features. This leads to
significant over-prediction of certain cold items with similar content to
popular warm items, even if their ground truth popularity is very low. Through
experiments on three multimedia datasets, we analyze the impact of this
behavior on three generative cold-start methods. We then describe a simple
post-processing bias mitigation method that, by using embedding magnitude as a
proxy for predicted popularity, can produce more balanced recommendations with
limited harm to user-oriented cold-start accuracy.

</details>


### [54] [What Generative Search Engines Like and How to Optimize Web Content Cooperatively](https://arxiv.org/abs/2510.11438)
*Yujiang Wu,Shanshan Zhong,Yubin Kim,Chenyan Xiong*

Main category: cs.IR

TL;DR: AutoGEO是一个自动学习生成式搜索引擎偏好的框架，通过重写网页内容来提升在生成式搜索引擎中的曝光度。


<details>
  <summary>Details</summary>
Motivation: 随着生成式搜索引擎（如Google AI Overview和ChatGPT）的快速普及，内容提供商迫切需要获得更多曝光机会，这推动了生成式搜索引擎优化（GEO）的需求。

Method: AutoGEO首先提示前沿LLMs解释生成式搜索引擎的偏好并从中提取偏好规则，然后将这些规则用作AutoGEO_API的上下文工程，并作为基于规则的奖励来训练成本效益更高的AutoGEO_Mini模型。

Result: 在标准GEO-Bench和两个使用真实用户查询构建的新基准测试中，AutoGEO在提升内容曝光度的同时保持了搜索效用。分析证实了学习规则的鲁棒性和在不同领域捕捉独特偏好的能力。

Conclusion: AutoGEO框架能够有效学习生成式搜索引擎的偏好并优化内容，为内容提供商在生成式搜索引擎中获得更多曝光提供了可行方案。

Abstract: By employing large language models (LLMs) to retrieve documents and generate
natural language responses, Generative Engines, such as Google AI overview and
ChatGPT, provide significantly enhanced user experiences and have rapidly
become the new form of search. Their rapid adoption also drives the needs of
Generative Engine Optimization (GEO), as content providers are eager to gain
more traction from them. In this paper, we introduce AutoGEO, a framework to
automatically learn generative engine preferences when using retrieved contents
for response generation, and rewrite web contents for more such traction.
AutoGEO first prompts frontier LLMs to explain generative engine preferences
and extract meaningful preference rules from these explanations. Then it uses
preference rules as context engineering for AutoGEO$_\text{API}$, a
prompt-based GEO system, and as rule-based rewards to train
AutoGEO$_\text{Mini}$, a cost-effective GEO model. Experiments on the standard
GEO-Bench and two newly constructed benchmarks using real user queries
demonstrate the effectiveness of AutoGEO in enhancing content traction while
preserving search utility. Analyses confirm the learned rules' robustness and
abilities to capture unique preferences in variant domains, and AutoGEO
systems' ability to embed them in content optimization. The code is released at
https://github.com/cxcscmu/AutoGEO.

</details>


### [55] [Uncertainty Quantification for Retrieval-Augmented Reasoning](https://arxiv.org/abs/2510.11483)
*Heydar Soudani,Hamed Zamani,Faegheh Hasibi*

Main category: cs.IR

TL;DR: 提出了R2C方法，一种用于检索增强推理（RAR）的不确定性量化技术，通过扰动多步推理过程来捕捉检索和生成的不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有的不确定性量化方法主要处理简单查询或无检索/单步检索场景，无法有效处理RAR设置中的多步推理不确定性。

Method: R2C通过对推理步骤应用各种扰动操作，改变检索器的输入，从而通过迭代反馈循环捕捉检索器和生成器的不确定性。

Result: 在五个流行的RAR系统和多个QA数据集上的实验显示，R2C相比最先进的不确定性量化基线平均提升AUROC超过5%。

Conclusion: R2C是一种有效的RAR不确定性量化方法，在弃权和模型选择等下游任务中表现出显著性能提升。

Abstract: Retrieval-augmented reasoning (RAR) is a recent evolution of
retrieval-augmented generation (RAG) that employs multiple reasoning steps for
retrieval and generation. While effective for some complex queries, RAR remains
vulnerable to errors and misleading outputs. Uncertainty quantification (UQ)
offers methods to estimate the confidence of systems' outputs. These methods,
however, often handle simple queries with no retrieval or single-step
retrieval, without properly handling RAR setup. Accurate estimation of UQ for
RAR requires accounting for all sources of uncertainty, including those arising
from retrieval and generation. In this paper, we account for all these sources
and introduce Retrieval-Augmented Reasoning Consistency (R2C)--a novel UQ
method for RAR. The core idea of R2C is to perturb the multi-step reasoning
process by applying various actions to reasoning steps. These perturbations
alter the retriever's input, which shifts its output and consequently modifies
the generator's input at the next step. Through this iterative feedback loop,
the retriever and generator continuously reshape one another's inputs, enabling
us to capture uncertainty arising from both components. Experiments on five
popular RAR systems across diverse QA datasets show that R2C improves AUROC by
over 5% on average compared to the state-of-the-art UQ baselines. Extrinsic
evaluations using R2C as an external signal further confirm its effectiveness
for two downstream tasks: in Abstention, it achieves ~5% gains in both
F1Abstain and AccAbstain; in Model Selection, it improves the exact match by
~7% over single models and ~3% over selection methods.

</details>


### [56] [Characterizing Web Search in The Age of Generative AI](https://arxiv.org/abs/2510.11560)
*Elisabeth Kirsten,Jost Grosse Perdekamp,Mihir Upadhyay,Krishna P. Gummadi,Muhammad Bilal Zafar*

Main category: cs.IR

TL;DR: 比较传统搜索引擎与生成式搜索引擎在搜索结果方面的差异，发现生成式搜索覆盖更广的来源，在内部知识与外部知识使用上存在差异，并创造了增强搜索多样性和偶然性的机会。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的发展，生成式搜索作为一种新型网络搜索方式出现，与传统列表式搜索结果形成鲜明对比，需要探索两者在哪些维度上存在差异。

Method: 比较Google传统搜索引擎与来自Google和OpenAI的四个生成式搜索引擎，使用来自四个领域的查询进行分析。

Result: 生成式搜索引擎覆盖更广泛的信息来源；不同生成式引擎在依赖内部模型知识vs外部网络知识方面存在差异；生成式搜索呈现不同的概念集合，为增强搜索多样性和偶然性创造了新机会。

Conclusion: 研究结果强调了在生成式AI时代需要重新审视网络搜索的评估标准。

Abstract: The advent of LLMs has given rise to a new type of web search: Generative
search, where LLMs retrieve web pages related to a query and generate a single,
coherent text as a response. This output modality stands in stark contrast to
traditional web search, where results are returned as a ranked list of
independent web pages. In this paper, we ask: Along what dimensions do
generative search outputs differ from traditional web search? We compare
Google, a traditional web search engine, with four generative search engines
from two providers (Google and OpenAI) across queries from four domains. Our
analysis reveals intriguing differences. Most generative search engines cover a
wider range of sources compared to web search. Generative search engines vary
in the degree to which they rely on internal knowledge contained within the
model parameters v.s. external knowledge retrieved from the web. Generative
search engines surface varying sets of concepts, creating new opportunities for
enhancing search diversity and serendipity. Our results also highlight the need
for revisiting evaluation criteria for web search in the age of Generative AI.

</details>


### [57] [QDER: Query-Specific Document and Entity Representations for Multi-Vector Document Re-Ranking](https://arxiv.org/abs/2510.11589)
*Shubham Chatterjee,Jeff Dalton*

Main category: cs.IR

TL;DR: QDER是一个神经重排序模型，通过将知识图谱语义整合到多向量模型中，统一了实体导向方法和多向量方法。其核心创新是"延迟聚合"策略，在最终评分阶段才进行表示聚合，显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 当前神经信息检索存在两条发展路径：基于知识图谱的实体导向方法和捕捉细粒度语义的多向量模型。作者希望统一这两种方法，将知识图谱语义整合到多向量模型中。

Method: QDER采用"延迟聚合"策略，在排序过程中保持独立的token和实体表示，只在最终评分阶段进行聚合。首先通过学习的注意力模式转换细粒度表示，然后应用精心选择的数学运算进行精确匹配。

Result: 在五个标准基准测试中，QDER实现了显著的性能提升：在TREC Robust 2004上nDCG@20比最强基线提高了36%，在其他数据集上也有类似改进。特别是在困难查询上表现优异，达到nDCG@20=0.70，而传统方法完全失败(nDCG@20=0.0)。

Conclusion: QDER为实体感知检索的未来工作奠定了基础，通过统一实体导向和多向量方法，在保持细粒度语义的同时整合知识图谱信息，显著提升了检索性能。

Abstract: Neural IR has advanced through two distinct paths: entity-oriented approaches
leveraging knowledge graphs and multi-vector models capturing fine-grained
semantics. We introduce QDER, a neural re-ranking model that unifies these
approaches by integrating knowledge graph semantics into a multi-vector model.
QDER's key innovation lies in its modeling of query-document relationships:
rather than computing similarity scores on aggregated embeddings, we maintain
individual token and entity representations throughout the ranking process,
performing aggregation only at the final scoring stage - an approach we call
"late aggregation." We first transform these fine-grained representations
through learned attention patterns, then apply carefully chosen mathematical
operations for precise matches. Experiments across five standard benchmarks
show that QDER achieves significant performance gains, with improvements of 36%
in nDCG@20 over the strongest baseline on TREC Robust 2004 and similar
improvements on other datasets. QDER particularly excels on difficult queries,
achieving an nDCG@20 of 0.70 where traditional approaches fail completely
(nDCG@20 = 0.0), setting a foundation for future work in entity-aware
retrieval.

</details>


### [58] [REGENT: Relevance-Guided Attention for Entity-Aware Multi-Vector Neural Re-Ranking](https://arxiv.org/abs/2510.11592)
*Shubham Chatterjee*

Main category: cs.IR

TL;DR: REGENT是一个神经重排序模型，通过将实体作为"语义骨架"来引导注意力机制，结合细粒度词汇匹配和高层次语义推理，在三个挑战性数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前神经重排序模型在处理复杂信息需求和长文档时存在困难，主要问题在于智能内容选择——识别长文本中真正重要的内容。人类理解自然围绕关键实体和概念，而神经模型在固定token窗口内处理文本，忽略了关键语义信号。

Method: REGENT模型使用实体作为语义骨架来引导注意力，将相关性指导直接集成到注意力机制中，结合细粒度词汇匹配和高层次语义推理，使模型能够聚焦概念上重要的内容同时保持对精确术语匹配的敏感性。

Result: REGENT在三个挑战性数据集上实现了最先进的性能，相比BM25提供高达108%的改进，并持续优于包括ColBERT和RankVicuna在内的强基线模型。

Conclusion: 这是首个成功将实体语义直接集成到神经注意力中的工作，为实体感知信息检索建立了新范式。

Abstract: Current neural re-rankers often struggle with complex information needs and
long, content-rich documents. The fundamental issue is not computational--it is
intelligent content selection: identifying what matters in lengthy,
multi-faceted texts. While humans naturally anchor their understanding around
key entities and concepts, neural models process text within rigid token
windows, treating all interactions as equally important and missing critical
semantic signals. We introduce REGENT, a neural re-ranking model that mimics
human-like understanding by using entities as a "semantic skeleton" to guide
attention. REGENT integrates relevance guidance directly into the attention
mechanism, combining fine-grained lexical matching with high-level semantic
reasoning. This relevance-guided attention enables the model to focus on
conceptually important content while maintaining sensitivity to precise term
matches. REGENT achieves new state-of-the-art performance in three challenging
datasets, providing up to 108% improvement over BM25 and consistently
outperforming strong baselines including ColBERT and RankVicuna. To our
knowledge, this is the first work to successfully integrate entity semantics
directly into neural attention, establishing a new paradigm for entity-aware
information retrieval.

</details>


### [59] [OneRec-Think: In-Text Reasoning for Generative Recommendation](https://arxiv.org/abs/2510.11639)
*Zhanyu Liu,Shiyao Wang,Xingmei Wang,Rongzhou Zhang,Jiaxin Deng,Honghui Bao,Jinghao Zhang,Wuchao Li,Pengfei Zheng,Xiangyu Wu,Yifei Hu,Qigen Hu,Xinchen Luo,Lejian Ren,Zixing Zhang,Qianqian Wang,Kuo Cai,Yunfan Wu,Hongtao Cheng,Zexuan Cheng,Lu Ren,Huanjie Wang,Yi Su,Ruiming Tang,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: OneRec-Think是一个统一的推荐框架，将对话、推理和个性化推荐无缝集成，通过项目对齐、推理激活和推理增强三个组件，在公开基准测试中达到最先进性能，并在快手平台上成功部署验证。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐模型（如OneRec）作为隐式预测器运行，缺乏显式和可控的推理能力，这是LLMs的关键优势。为了弥补这一差距，需要开发能够进行显式推理的推荐框架。

Method: 提出OneRec-Think框架，包含三个核心组件：(1) 项目对齐：跨模态项目-文本对齐实现语义基础；(2) 推理激活：推理支架在推荐上下文中激活LLM推理；(3) 推理增强：设计考虑用户偏好多有效性特征的推荐特定奖励函数。

Result: 在公开基准测试中达到最先进性能。在快手平台部署的"Think-Ahead"架构实现了0.159%的APP停留时间增益，验证了模型显式推理能力的实际效果。

Conclusion: OneRec-Think成功将LLM的显式推理能力融入推荐系统，通过统一的对话、推理和推荐框架，在学术基准和工业部署中都取得了显著成效，证明了显式推理在推荐系统中的重要价值。

Abstract: The powerful generative capacity of Large Language Models (LLMs) has
instigated a paradigm shift in recommendation. However, existing generative
models (e.g., OneRec) operate as implicit predictors, critically lacking the
capacity for explicit and controllable reasoning-a key advantage of LLMs. To
bridge this gap, we propose OneRec-Think, a unified framework that seamlessly
integrates dialogue, reasoning, and personalized recommendation. OneRec-Think
incorporates: (1) Itemic Alignment: cross-modal Item-Textual Alignment for
semantic grounding; (2) Reasoning Activation: Reasoning Scaffolding to activate
LLM reasoning within the recommendation context; and (3) Reasoning Enhancement,
where we design a recommendation-specific reward function that accounts for the
multi-validity nature of user preferences. Experiments across public benchmarks
show state-of-the-art performance. Moreover, our proposed "Think-Ahead"
architecture enables effective industrial deployment on Kuaishou, achieving a
0.159\% gain in APP Stay Time and validating the practical efficacy of the
model's explicit reasoning capability.

</details>


### [60] [FinVet: A Collaborative Framework of RAG and External Fact-Checking Agents for Financial Misinformation Detection](https://arxiv.org/abs/2510.11654)
*Daniel Berhane Araya,Duoduo Liao*

Main category: cs.IR

TL;DR: FinVet是一个多代理框架，通过集成两个RAG管道和外部事实核查，采用置信度加权投票机制来检测金融市场中的虚假信息，相比现有方法在准确性和透明度方面有显著提升。


<details>
  <summary>Details</summary>
Motivation: 金融市场面临虚假信息的严重威胁，可能导致巨额损失。现有方法缺乏决策透明度且难以溯源可信来源，需要更可靠的验证系统。

Method: FinVet采用多代理框架，集成两个RAG管道与外部事实核查，通过置信度加权投票机制进行决策。使用自适应三层处理策略，根据检索置信度动态调整验证方法。

Result: 在FinFact数据集上的实验表明，FinVet达到0.85的F1分数，比最佳单个管道提升10.4%，比独立RAG方法提升37%。

Conclusion: FinVet通过多代理集成和自适应处理策略，在金融市场虚假信息检测方面实现了显著性能提升，同时提供证据支持、来源归因和不确定性标记等透明化功能。

Abstract: Financial markets face growing threats from misinformation that can trigger
billions in losses in minutes. Most existing approaches lack transparency in
their decision-making and provide limited attribution to credible sources. We
introduce FinVet, a novel multi-agent framework that integrates two
Retrieval-Augmented Generation (RAG) pipelines with external fact-checking
through a confidence-weighted voting mechanism. FinVet employs adaptive
three-tier processing that dynamically adjusts verification strategies based on
retrieval confidence, from direct metadata extraction to hybrid reasoning to
full model-based analysis. Unlike existing methods, FinVet provides
evidence-backed verdicts, source attribution, confidence scores, and explicit
uncertainty flags when evidence is insufficient. Experimental evaluation on the
FinFact dataset shows that FinVet achieves an F1 score of 0.85, which is a
10.4% improvement over the best individual pipeline (fact-check pipeline) and
37% improvement over standalone RAG approaches.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [61] [Remote Interference Mitigation through Null Precoding and Fractional Programming](https://arxiv.org/abs/2510.09989)
*Xuyang Sun,Hussein A. Ammar,Israfil Bahceci,Raviraj Adve,Gary Boudreau,Zehua Li*

Main category: cs.IT

TL;DR: 本文提出了一种针对5G系统中由大气波导效应引起的远程干扰的解决方案，通过角度估计和干扰消除技术，在低发射功率条件下实现了可用的上行链路通信。


<details>
  <summary>Details</summary>
Motivation: 随着5G系统的快速部署，由大气波导效应引起的远程干扰已成为一个关键挑战。这种干扰会严重破坏本地基站的上行链路接收，特别是在低发射功率条件下。

Method: 分析远程干扰对网络性能的影响，识别干扰的到达角估计，设计预编码器和组合器来消除干扰。采用零预编码和分数规划等干扰消除技术。

Result: 在之前因干扰而无法使用的低上行链路发射功率条件下，实现了5.23dB的信道估计归一化均方误差降低，并达到约5.8bit/s/Hz的数据速率。

Conclusion: 所提出的方案有效缓解了5G系统中的远程干扰问题，使上行链路通信在低发射功率条件下成为可能，显著提升了网络性能。

Abstract: With the rapid deployment of 5G systems, remote interference (RI) caused by
atmospheric ducting has emerged as an occasional, but critical challenge. This
phenomenon occurs when the downlink (DL) signals from distant base stations
(BSs) propagate over long distances through tropospheric ducting, severely
disrupting uplink (UL) reception at local BSs. To address this challenge, we
analyze the effect of RI on network performance, including the channel
estimation phase. We then develop a solution that identifies the
angle-of-arrival (AOA) estimation of RI and designs precoders and combiners
that mitigate RI. Our approach employs interference cancellation techniques
through null precoding and fractional programming which enhance the performance
of the network. Interestingly, we show that using our scheme, uplink
communication is possible at low transmit power regimes that were unusable due
to RI. Our results further show a 5.23~dB reduction in normalized mean square
error for channel estimation and achieved data rates around 5.8~bit/s/Hz at the
previously unusable low uplink transmit power conditions.

</details>


### [62] [Data-Driven Deployment of Reconfigurable Intelligent Surfaces in Cellular Networks](https://arxiv.org/abs/2510.10190)
*Sina Beyraghi,Javad Shabanpour,Giovanni Geraci,Paul Almasan,Angel Lozano*

Main category: cs.IT

TL;DR: 提出了一个全自动、数据驱动的可重构智能表面大规模部署框架，在密集城市环境中联合优化RIS放置、方向、配置和基站波束成形，评估了覆盖增益与基础设施成本之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 解决在蜂窝网络中大规模部署可重构智能表面时面临的部署复杂性和成本效益问题，利用实际商业部署数据来验证方法的有效性。

Method: 利用物理一致的射线追踪和英国商业部署的实证数据，通过反射和散射启发式方法识别候选RIS位置，使用Sionna射线追踪引擎中的校准电磁模型，对中断用户进行聚类以降低部署复杂性。

Result: 研究表明，在城市区域实现有意义的覆盖改进需要密集部署大孔径RIS单元，这引发了成本效益的疑问。

Conclusion: 为促进可重复性和未来研究，提供了完整的仿真框架和RIS部署算法作为开源软件。

Abstract: This paper presents a fully automated, data-driven framework for the
large-scale deployment of reconfigurable intelligent surfaces (RISs) in
cellular networks. Leveraging physically consistent ray tracing and empirical
data from a commercial deployment in the UK, the proposed method jointly
optimizes RIS placement, orientation, configuration, and base station
beamforming in dense urban environments across frequency bands (corresponding
to 4G, 5G, and a hypothetical 6G system). Candidate RIS locations are
identified via reflection- and scattering-based heuristics using calibrated
electromagnetic models within the Sionna Ray Tracing (RT) engine. Outage users
are clustered to reduce deployment complexity, and the tradeoff between
coverage gains and infrastructure cost is systematically evaluated. It is shown
that achieving meaningful coverage improvement in urban areas requires a dense
deployment of large-aperture RIS units, raising questions about
cost-effectiveness. To facilitate reproducibility and future research, the
complete simulation framework and RIS deployment algorithms are provided as
open-source software.

</details>


### [63] [An information theorist's tour of differential privacy](https://arxiv.org/abs/2510.10316)
*Anand D. Sarwate,Flavio P. Calmon,Oliver Kosut,Lalitha Sankar*

Main category: cs.IT

TL;DR: 本文探讨了差分隐私与信息论之间的关键联系，将差分隐私算法视为数据与输出之间的信道，从信息论角度理解其隐私保证。


<details>
  <summary>Details</summary>
Motivation: 差分隐私自2006年提出以来已成为量化敏感数据分析发布风险的标准方法。其核心是通过概率分布差异衡量风险，这正是信息论的核心主题。

Method: 将差分隐私算法建模为底层数据与分析输出之间的信道，从信道特性角度理解差分隐私的保证机制。

Result: 建立了差分隐私与信息论之间的关键联系，为相关信息度量提供了操作意义。

Conclusion: 信息论为差分隐私的制定和应用提供了理论基础，通过信道视角可以更好地理解差分隐私的隐私保护机制。

Abstract: Since being proposed in 2006, differential privacy has become a standard
method for quantifying certain risks in publishing or sharing analyses of
sensitive data. At its heart, differential privacy measures risk in terms of
the differences between probability distributions, which is a central topic in
information theory. A differentially private algorithm is a channel between the
underlying data and the output of the analysis. Seen in this way, the
guarantees made by differential privacy can be understood in terms of
properties of this channel. In this article we examine a few of the key
connections between information theory and the formulation/application of
differential privacy, giving an ``operational significance'' for relevant
information measures.

</details>


### [64] [Quantum-Resistant Cryptography via Universal Gröbner Bases](https://arxiv.org/abs/2510.10429)
*Sergio Da Silva,Aniya Stewart*

Main category: cs.IT

TL;DR: 提出了一种基于通用Gröbner基的抗量子攻击密钥交换协议，利用生成通用Gröbner基的计算复杂性来保障安全性。


<details>
  <summary>Details</summary>
Motivation: 探索通用Gröbner基在公钥密码学中的应用，开发能够抵抗量子攻击的密钥交换协议。

Method: 使用多项式理想的通用Gröbner基作为私钥，利用生成通用Gröbner基与单一Gröbner基之间的计算差异来设计协议。

Result: 提供了协议的安全性分析和参数复杂度分析，并为图的环面理想开发了递归生成通用Gröbner基的高效方法。

Conclusion: 基于通用Gröbner基的协议具有抗量子攻击潜力，其安全性依赖于计算Gröbner扇形的难度。

Abstract: In this article, we explore the use of universal Gr\"obner bases in
public-key cryptography by proposing a key establishment protocol that is
resistant to quantum attacks. By utilizing a universal Gr\"obner basis
$\mathcal{U}_I$ of a polynomial ideal $I$ as a private key, this protocol
leverages the computational disparity between generating the universal
Gr\"obner basis needed for decryption compared with the single Gr\"obner basis
used for encryption. The security of the system lies in the difficulty of
directly computing the Gr\"obner fan of $I$ required to construct
$\mathcal{U}_I$. We provide an analysis of the security of the protocol and the
complexity of its various parameters. Additionally, we provide efficient ways
to recursively generate $\mathcal{U}_I$ for toric ideals of graphs with
techniques which are also of independent interest to the study of these ideals.

</details>


### [65] [On the Capacity of Distributed Quantum Storage](https://arxiv.org/abs/2510.10568)
*Hua Sun,Syed A. Jafar*

Main category: cs.IT

TL;DR: 该论文研究了分布式量子存储代码的容量问题，通过存储图模型分析不同拓扑结构（如MDS图、轮图、Fano图等）的存储容量，并建立了量子CSS码与经典安全存储问题的联系。


<details>
  <summary>Details</summary>
Motivation: 研究分布式量子存储代码的容量极限，解决在任意指定存储节点大小和擦除模式下的量子消息存储问题，特别是处理非均匀的存储节点和擦除模式。

Method: 使用存储图模型表示解码集，通过量子CSS码与经典安全存储问题建立联系，利用非平凡对齐结构确保恢复和安全性，并基于量子信息不等式（如强次可加性和弱单调性）进行逆推分析。

Result: 针对多种图结构（包括MDS图、轮图、Fano图和交集图）给出了存储容量的精确特征描述，证明了通过量子CSS码可以实现经典安全存储问题的解决方案。

Conclusion: 分布式量子存储容量可以通过存储图拓扑结构精确表征，量子CSS码与经典安全存储问题的联系为构建非平凡的量子代码提供了有效途径，量子信息不等式为容量分析提供了理论基础。

Abstract: A distributed quantum storage code maps a quantum message to N storage nodes,
of arbitrary specified sizes, such that the stored message is robust to an
arbitrary specified set of erasure patterns. The sizes of the storage nodes,
and erasure patterns may not be homogeneous. The capacity of distributed
quantum storage is the maximum feasible size of the quantum message (relative
to the sizes of the storage nodes), when the scaling of the size of the message
and all storage nodes by the same scaling factor is allowed. Representing the
decoding sets as hyperedges in a storage graph, the capacity is characterized
for various graphs, including MDS graph, wheel graph, Fano graph, and
intersection graph. The achievability is related via quantum CSS codes to a
classical secure storage problem. Remarkably, our coding schemes utilize
non-trivial alignment structures to ensure recovery and security in the
corresponding classical secure storage problem, which leads to similarly
non-trivial quantum codes. The converse is based on quantum information
inequalities, e.g., strong sub-additivity and weak monotonicity of quantum
entropy, tailored to the topology of the storage graphs.

</details>


### [66] [Soft-Decoding Reverse Reconciliation in Discrete-Modulation CV-QKD](https://arxiv.org/abs/2510.10674)
*Marco Origlia,Marco Secondini*

Main category: cs.IT

TL;DR: 提出了一种用于PAM/QAM调制的反向协调新方法，通过Bob向Alice提供精心设计的软度量来帮助Alice恢复Bob的密钥，同时不向窃听者泄露额外信息。


<details>
  <summary>Details</summary>
Motivation: 在连续变量量子密钥分发中，当采用离散调制格式时，Bob拥有软信息而Alice只有硬信息，这迫使Alice依赖硬判决解码来恢复Bob的密钥，限制了性能。

Method: Bob向Alice披露精心设计的软度量，使用二进制LDPC码和置信传播解码在编码层面实现该方案。

Result: 所提方法可实现密钥率接近理论上界，相比硬判决反向协调有显著增益，并通过数值仿真评估了比特错误率。

Conclusion: 该方法有效提升了离散调制下反向协调的性能，但存在与理论预测的残余差距需要进一步研究。

Abstract: In continuous-variable quantum key distribution, information reconciliation
is required to extract a shared secret key from correlated random variables
obtained through the quantum channel. Reverse reconciliation (RR) is generally
preferred, since the eavesdropper has less information about Bob's measurements
than about Alice's transmitted symbols. When discrete modulation formats are
employed, however, soft information is available only at Bob's side, while
Alice has access only to hard information (her transmitted sequence). This
forces her to rely on hard-decision decoding to recover Bob's key.
  In this work, we introduce a novel RR technique for PAM (and QAM) in which
Bob discloses a carefully designed soft metric to help Alice recover Bob's key,
while leaking no additional information about the key to an eavesdropper. We
assess the performance of the proposed technique in terms of achievable secret
key rate (SKR) and its bounds, showing that the achievable SKR closely
approaches the upper bound, with a significant gain over hard-decision RR.
Finally, we implement the scheme at the coded level using binary LDPC codes
with belief-propagation decoding, assess its bit-error rate through numerical
simulations, compare the observed gain with theoretical predictions from the
achievable SKR, and discuss the residual gap.

</details>


### [67] [Throughput Maximization for Multiuser Communications with Flexible-Sector 6DMA](https://arxiv.org/abs/2510.10944)
*Xiaoming Shi,Yunli Li,Xiaodan Shao,Jie Xu,Rui Zhang*

Main category: cs.IT

TL;DR: 提出了一种低成本、易部署的灵活扇区6DMA架构，通过灵活移动天线来匹配用户空间分布以提升网络容量


<details>
  <summary>Details</summary>
Motivation: 传统基站使用固定位置天线，无法灵活适应用户的空间分布变化，导致容量受限

Method: 采用可沿圆形轨道移动的定向扇区天线阵列，联合优化扇区旋转和天线分配，基于用户空间分布最大化平均公共吞吐量

Result: 推导出闭式解，证明用户在各扇区均匀分布时能最大化公共吞吐量，并提出低复杂度次优解来最小化扇区间用户数方差

Conclusion: 灵活扇区基站相比基准方案显著提升了网络吞吐量，验证了所提架构和优化方法的有效性

Abstract: This paper presents a cost-effective and easily-deployable flexible-sector
six-dimensional movable antenna (6DMA) architecture for future wireless
communication networks, which enables flexible antenna configurations to match
users' spatial distribution for capacity enhancement. Different from
conventional sectorized base station (BS) with fixed-position antennas (FPAs),
the flexible-sector 6DMA-enabled BS employs multiple directional sector antenna
arrays that can flexibly move along a common circular track. By properly moving
antennas across sectors and rotating all sector antenna arrays synchronously,
the flexible-sector BS can adjust the coverage regions of all sectors with
flexible antenna allocations over them. In particular, we consider the
multiuser downlink communication employing the orthogonal multiple access (OMA)
to serve users in each sector. Under this setup, we jointly optimize the sector
rotation and the antenna allocation at the flexible-sector BS to maximize the
average common throughput achievable for all users based on their spatial
distribution. We solve this non-convex optimization problem by deriving
closed-form solutions and thereby analyze the effect of users' spatial
distribution on the achievable common throughput. It is shown that equal user
distribution over sectors is optimal for maximizing the common throughput.
Motivated by this result, we further develop a low-complexity suboptimal
solution for the sector rotation that minimizes the variance of user numbers
across sectors. Finally, we provide simulation results to verify our analytical
results and validate the performance of our proposed solutions. It is
demonstrated that the flexible-sector BS significantly improves the network
throughput as compared to other benchmark schemes.

</details>


### [68] [Forward-Forward Autoencoder Architectures for Energy-Efficient Wireless Communications](https://arxiv.org/abs/2510.11418)
*Daniel Seifert,Onur Günlü,Rafael F. Schaefer*

Main category: cs.IT

TL;DR: 本文研究了在前向-前向学习算法基础上设计端到端学习的自动编码器，用于通信系统中的联合编码和调制任务，并在高斯白噪声和瑞利块衰落信道中评估其性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习在通信系统中的应用日益受到关注。前向-前向学习是反向传播算法的高效替代方案，具有不需要通信信道可微分、不依赖全局偏导数可用性等优势，可实现节能实现。

Method: 设计基于前向-前向算法的端到端学习自动编码器，在加性高斯白噪声和瑞利块衰落信道中进行数值评估。比较前向-前向训练系统与反向传播训练系统的性能。

Result: 在联合编码和调制以及固定不可微分调制阶段场景下，前向-前向训练系统展现出与反向传播训练系统的竞争力。同时实现了显著的内存和处理时间节省。

Conclusion: 前向-前向算法为通信系统中的深度学习应用提供了有效的替代训练方法，在保持性能的同时实现了更高的能效和计算效率。

Abstract: The application of deep learning to the area of communications systems has
been a growing field of interest in recent years. Forward-forward (FF) learning
is an efficient alternative to the backpropagation (BP) algorithm, which is the
typically used training procedure for neural networks. Among its several
advantages, FF learning does not require the communication channel to be
differentiable and does not rely on the global availability of partial
derivatives, allowing for an energy-efficient implementation. In this work, we
design end-to-end learned autoencoders using the FF algorithm and numerically
evaluate their performance for the additive white Gaussian noise and Rayleigh
block fading channels. We demonstrate their competitiveness with BP-trained
systems in the case of joint coding and modulation, and in a scenario where a
fixed, non-differentiable modulation stage is applied. Moreover, we provide
further insights into the design principles of the FF network, its training
convergence behavior, and significant memory and processing time savings
compared to BP-based approaches.

</details>


### [69] [Repeated-and-Offset QPSK for DFT-s-OFDM in Satellite Access](https://arxiv.org/abs/2510.11445)
*Renaud-Alexandre Pitaval*

Main category: cs.IT

TL;DR: 提出了一种新的RO-QPSK调制方案，用于卫星与地面网络融合场景，相比5G中的π/2-BPSK具有更低的PAPR和更好的SINR性能。


<details>
  <summary>Details</summary>
Motivation: 地面蜂窝网络与卫星网络融合的需求，需要将卫星系统中使用的OQPSK调制适配到地面系统使用的DFT-s-OFDM波形上。

Method: 引入了一种称为RO-QPSK的一阶星座调制方案，推导其基本特性，并与5G支持的π/2-BPSK加频域频谱整形进行比较。

Result: RO-QPSK自然产生汉宁窗形状的频谱，PAPR极低（约2dB），在窄带和中等频率选择性信道中，通过单抽头均衡和符号合并可提高SINR。

Conclusion: RO-QPSK在卫星通信中具有优越性能，可进一步结合FDSS进一步降低PAPR，同时提供类似性能。

Abstract: Motivated by the convergence of terrestrial cellular networks with satellite
networks, we consider an adaptation of offset quadrature phase shift keying
(OQPSK), used with single-carrier waveform in traditional satellite systems, to
discrete Fourier transform spread (DFT-s-) orthogonal frequency-division
multiplexed (OFDM) waveform employed in the uplink of terrestrial systems. We
introduce a new order-one constellation modulation, termed repeated-and-offset
QPSK (RO-QPSK), derive its basic properties, and compare it with pi/2-BPSK with
frequency-domain spectral shaping (FDSS), as supported in 5G. RO-QPSK naturally
produces a Hann-window-shaped spectrum, resulting in a very low maximum
peak-to-average power ratio (PAPR) on the order of 2 dB. Moreover, with
single-tap equalization and symbol combining at the receiver, RO-QSPK can
improve the signal-to-interference-plus-noise (SINR) compared to pi/2-BPSK with
FDSS, in narrowband and/or moderately frequency-selective channels, as
encountered in satellite communications. A moderate FDSS can also be combined
with RO-QSPK to further reduce the PAPR while providing similar performance. Of
independent interest, general SINR expressions for DFT-s-OFDM are also
provided.

</details>


### [70] [List Decoding Reed--Solomon Codes in the Lee, Euclidean, and Other Metrics](https://arxiv.org/abs/2510.11453)
*Chris Peikert,Alexandra Veliche Hostetler*

Main category: cs.IT

TL;DR: 提出了一个多项式时间算法，用于在ℓp半度量下对广义Reed-Solomon码进行列表解码，其中0<p≤2。相比现有算法，该算法能解码到任意大的距离，并在大多数解码距离上具有更好的距离-速率权衡。


<details>
  <summary>Details</summary>
Motivation: 传统Reed-Solomon码纠错算法主要关注汉明度量，但在某些应用中，依赖于具体错误值的其他度量可能更合适。需要开发在ℓp度量下的高效解码算法。

Method: 开发了多项式时间列表解码算法，适用于广义Reed-Solomon码在ℓp半度量下的解码，其中0<p≤2。算法基于代数解码技术，能够处理任意大的解码距离。

Result: 算法在ℓ1和ℓ2度量下解码距离超过中等阈值时，比现有算法具有更好的距离-速率权衡。证明了特定GRS码子类的最小距离下界，表明列表解码器在许多参数下实际上是唯一解码器。在随机拉普拉斯和高斯错误下，算法支持比最坏情况错误更大的速率。

Conclusion: 该工作为Reed-Solomon码在ℓp度量下的高效解码提供了新的多项式时间算法，扩展了传统汉明度量解码的适用范围，在理论和实际性能上均有显著改进。

Abstract: Reed--Solomon error-correcting codes are ubiquitous across computer science
and information theory, with applications in cryptography, computational
complexity, communication and storage systems, and more. Most works on
efficient error correction for these codes, like the celebrated
Berlekamp--Welch unique decoder and the (Guruswami--)Sudan list decoders, are
focused on measuring error in the Hamming metric, which simply counts the
number of corrupted codeword symbols. However, for some applications, other
metrics that depend on the specific values of the errors may be more
appropriate.
  This work gives a polynomial-time algorithm that list decodes (generalized)
Reed--Solomon codes over prime fields in $\ell_p$ (semi)metrics, for any $0 < p
\leq 2$. Compared to prior algorithms for the Lee ($\ell_1$) and Euclidean
($\ell_2$) metrics, ours decodes to arbitrarily large distances (for
correspondingly small rates), and has better distance-rate tradeoffs for all
decoding distances above some moderate thresholds. We also prove lower bounds
on the $\ell_{1}$ and $\ell_{2}$ minimum distances of a certain natural
subclass of GRS codes, which establishes that our list decoder is actually a
unique decoder for many parameters of interest. Finally, we analyze our
algorithm's performance under random Laplacian and Gaussian errors, and show
that it supports even larger rates than for corresponding amounts of worst-case
error in $\ell_{1}$ and $\ell_{2}$ (respectively).

</details>
