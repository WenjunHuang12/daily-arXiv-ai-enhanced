<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 21]
- [cs.GT](#cs.GT) [Total: 6]
- [cs.IR](#cs.IR) [Total: 15]
- [cs.DS](#cs.DS) [Total: 9]
- [cs.MM](#cs.MM) [Total: 4]
- [cs.DB](#cs.DB) [Total: 14]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Design of a Turbo-based Deep Semantic Autoencoder for Marine Internet of Things](https://arxiv.org/abs/2511.00377)
*Xiaoling Han,Bin Lin,Nan Wu,Ping Wang,Zhenyu Na,Miyuan Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种基于Turbo结构的深度语义自动编码器(Turbo-DSA)，用于海洋物联网中的端到端语义通信，通过结合Transformer和Turbo编码技术，在低信噪比条件下显著提升了语义传输效率和环境适应性。


<details>
  <summary>Details</summary>
Motivation: 随着全球海洋经济和海事活动的快速发展，海洋物联网面临数据传输效率和语义理解能力不足的问题，需要开发更高效的语义通信方案。

Method: 提出Turbo-DSA端到端编码方案，使用Transformer构建语义编码器和解码器，将消息转换为语义向量，并采用Turbo结构进行信道编码和解码，通过迭代优化语义向量表示。

Result: 仿真结果表明，Turbo-DSA在双语评估替代分数和句子相似度等关键指标上超越现有基准，特别是在低信噪比条件下表现出优越的文本语义传输效率和海洋信道环境适应性。

Conclusion: Turbo-DSA通过深度集成Transformer和Turbo结构，实现了高效的语义级联合信源信道编码，为海洋物联网通信提供了更优的解决方案。

Abstract: With the rapid growth of the global marine economy and flourishing maritime
activities, the marine Internet of Things (IoT) is gaining unprecedented
momentum. However, current marine equipment is deficient in data transmission
efficiency and semantic comprehension. To address these issues, this paper
proposes a novel End-to-End (E2E) coding scheme, namely the Turbo-based Deep
Semantic Autoencoder (Turbo-DSA). The Turbo-DSA achieves joint source-channel
coding at the semantic level through the E2E design of transmitter and
receiver, while learning to adapt to environment changes. The semantic encoder
and decoder are composed of transformer technology, which efficiently converts
messages into semantic vectors. These vectors are dynamically adjusted during
neural network training according to channel characteristics and background
knowledge base. The Turbo structure further enhances the semantic vectors.
Specifically, the channel encoder utilizes Turbo structure to separate semantic
vectors, ensuring precise transmission of meaning, while the channel decoder
employs Turbo iterative decoding to optimize the representation of semantic
vectors. This deep integration of the transformer and Turbo structure is
ensured by the design of the objective function, semantic extraction, and the
entire training process. Compared with traditional Turbo coding techniques, the
Turbo-DSA shows a faster convergence speed, thanks to its efficient processing
of semantic vectors. Simulation results demonstrate that the Turbo-DSA
surpasses existing benchmarks in key performance indicators, such as bilingual
evaluation understudy scores and sentence similarity. This is particularly
evident under low signal-to-noise ratio conditions, where it shows superior
text semantic transmission efficiency and adaptability to variable marine
channel environments.

</details>


### [2] [Multi-Sensor Distributed Hypothesis Testing in the Low-Power Regime](https://arxiv.org/abs/2511.00645)
*Cécile Bouette,Michèle Wigger*

Main category: cs.IT

TL;DR: 该论文分析了分布式假设检验场景中的Stein指数，发现在特定条件下传感器到决策中心的通信对Stein指数没有帮助。


<details>
  <summary>Details</summary>
Motivation: 研究在具有子线性输入成本约束的多址接入信道下，分布式假设检验的性能极限，特别是确定通信是否有益于Stein指数。

Method: 通过分析多址接入信道特性和成本函数，推导Stein指数的上下界，特别关注完全连通离散多址接入信道和非完全连通信道的情况。

Result: 对于完全连通DMMACs和加性高斯噪声MACs，传感器通信不能提高Stein指数；对于非完全连通DMMACs，Stein指数更高且等于零速率无噪声通信链路的性能。

Conclusion: 在特定信道条件下，分布式传感器通信对假设检验的Stein指数没有增益，通信是无用的；但在非完全连通信道中通信能带来性能提升。

Abstract: We characterize the Stein-exponent of a distributed hypothesis testing
scenario where two sensors transmit information through a memoryless multiple
access channel (MAC) subject to a sublinear input cost constraint with respect
to the number of channel uses and where the decision center has access to an
additional local observation. Our main theorem provides conditions on the
channel and cost functions for which the Stein-exponent of this distributed
setup is no larger than the Stein-exponent of the local test at the decision
center. Under these conditions, communication from the sensors to the decision
center is thus useless in terms of Stein-exponent. The conditions are satisfied
for additive noise MACs with generalized Gaussian noise under a p-th moment
constraint (including the Gaussian channel with second-moment constraint) and
for the class of fully-connected (where all inputs can induce all outputs)
discrete memoryless multiple-access channels (DMMACs) under arbitrary cost
constraints. We further show that for DMMACs that are not fully-connected, the
Stein-exponent is larger and coincides with that of a setup with zero-rate
noiseless communication links from either both sensors or only one sensor, as
studied in [1].

</details>


### [3] [Improved Decoding Algorithms for MDS and Almost-MDS Codesfrom Twisted GRS Codes](https://arxiv.org/abs/2511.00766)
*Guodong Wang,Hongwei Liu,Jinquan Luo*

Main category: cs.IT

TL;DR: 提出了两种更高效的扭曲广义里德-所罗门码解码算法，分别针对一般TGRS码和几乎MDS TGRS码，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有TGRS码解码算法效率不够高，需要开发更高效的解码方法来提升性能。

Method: 研究TGRS码的关键方程特性，提出针对一般TGRS码和几乎MDS TGRS码的解码算法。

Result: 提出的两种解码算法在性能上比Sun等人和Sui等人的方法更高效。

Conclusion: 成功开发了更高效的TGRS码解码算法，为相关编码理论提供了改进方案。

Abstract: In this paper, firstly, we study decoding of a general class of twisted
generalized Reed-Solomon (TGRS) codes and provide a precise characterization of
the key equation for TGRS codes and propose a decoding algorithm. Secondly, we
further study decoding of almost-MDS TGRS codes and provide a decoding
algorithm. These two decoding algorithms are more efficient in terms of
performance compared with the decoding algorithms presented in [Sun et al.,
IEEE-TIT, 2024] and [Sui et al., IEEE-TIT, 2023] respectively.

</details>


### [4] [An Elementary Approach to MacWilliams Extension Property and Constant Weight Code with Respect to Weighted Hamming Metric](https://arxiv.org/abs/2511.00809)
*Yang Xu,Haibin Kan,Guangyue Han*

Main category: cs.IT

TL;DR: 本文通过初等方法研究了有限域上ω-权重的MacWilliams扩展性质和常重码，当ω为常数1时恢复Hamming度量码的两个经典结果。


<details>
  <summary>Details</summary>
Motivation: 研究有限域上ω-权重定义的MacWilliams扩展性质和常重码，提供一种仅依赖初等线性代数的统一方法。

Method: 使用初等线性代数和通过双重计数论证推导出的ω-权重子空间的两个关键恒等式。

Result: 建立了ω-权重下的MacWilliams扩展性质和常重码的完整刻画，当ω为常数1时与Hamming度量码的经典结果一致。

Conclusion: 该方法为研究各种权重度量下的编码性质提供了统一的初等框架，成功推广了Hamming度量码的经典理论。

Abstract: In this paper, we characterize the MacWilliams extension property (MEP) and
constant weight codes with respect to $\omega$-weight defined on
$\mathbb{F}^{\Omega}$ via an elementary approach, where $\mathbb{F}$ is a
finite field, $\Omega$ is a finite set, and
$\omega:\Omega\longrightarrow\mathbb{R}^{+}$ is a weight function. Our approach
relies solely on elementary linear algebra and two key identities for
$\omega$-weight of subspaces derived from a double-counting argument. When
$\omega$ is the constant $1$ map, our results recover two well-known results
for Hamming metric code: (1) any Hamming weight preserving map between linear
codes extends to a Hamming weight isometry of the entire ambient space; and (2)
any constant weight Hamming metric code is a repetition of the dual of Hamming
code.

</details>


### [5] [Fairness Designs for Load Balancing Optimization in Satellite-Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2511.00887)
*Trinh Van Chien,Ngo Tran Anh Thu,Nguyen Hoang Lam,Hien Quoc Ngo,Symeon Chatzinotas,Huynh Thi Thanh Binh*

Main category: cs.IT

TL;DR: 本文研究了天地一体化通信系统中考虑异构接收器（接入点和卫星）的负载均衡公平性设计，提出了基于遗传算法的高效关联模式优化方法，并验证了其在提升网络吞吐量方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 天地一体化通信系统需要在大范围区域内提供普遍服务，但异构接收器（AP和卫星）之间的负载均衡和公平性设计面临挑战，特别是在大规模网络中寻找最优关联模式的计算复杂度很高。

Method: 推导了任意关联模式下用户的上行链路遍历吞吐量，建立了通用公平性优化问题，针对小规模网络使用穷举搜索，针对大规模网络设计了基于遗传算法的低复杂度优化算法，并结合功率控制提出了混合遗传算法。

Result: 数值结果表明，用户关联模式对网络吞吐量有显著影响，提出的GA算法在小规模网络中与穷举搜索性能相同，在大规模网络中能发现实用的关联模式，负载均衡结合功率控制相比传统方案显著提升系统性能。

Conclusion: 基于遗传算法的负载均衡公平性设计方法能有效解决天地一体化通信系统中的关联优化问题，在保证公平性的同时显著提升系统吞吐量性能。

Abstract: Space-ground communication systems are important in providing ubiquitous
services in a large area. This paper considers the fairness designs under a
load-balancing framework with heterogeneous receivers comprising access points
(APs) and a satellite. We derive an ergodic throughput of each user in the
uplink data transmission for an arbitrary association pattern and imperfect
channel state information, followed by a closed-form expression with the
maximum-ratio combining and rich scattering environments. We further formulate
a generic fairness optimization problem, subject to the optimal association
patterns for all the users. Despite the combinatorial structure, the global
optimal solution to the association patterns can be obtained by an exhaustive
search for small-scale networks with several APs and users. We design a low
computational complexity algorithm for large-scale networks based on
evolutionary computation that obtains good patterns in polynomial time.
Specifically, the genetic algorithm (GA) is adapted to the discrete feasible
region and the concrete fairness metrics. We extensively observe the fairness
design problem by incorporating transmit power control and propose a hybrid
genetic algorithm to address the problem. Numerical results demonstrate that
the association pattern to each user has a significant impact on the network
throughput. Moreover, the proposed GA-based algorithm offers the same
performance as an exhaustive search for small-scale networks, while it unveils
interesting practical association patterns as the network dimensions go large.
The load-balancing approach, combined with power control factors, significantly
enhances system performance compared to conventional schemes and configurations
with fixed factors.

</details>


### [6] [HyRES: A Hybrid Replication and Erasure Coding Approach to Data Storage](https://arxiv.org/abs/2511.00896)
*Daniel E. Lucani,Marcell Fehér*

Main category: cs.IT

TL;DR: HyRES是一种混合存储方案，结合了复制和纠删码的最佳特性，提供更好的设计灵活性和潜在性能。


<details>
  <summary>Details</summary>
Motivation: 传统分布式存储系统通常单独设计复制或纠删码技术，缺乏将两者优势结合的灵活方案。

Method: 提出HyRES混合方案，综合考虑存储网络规模的影响，通过理论分析和仿真验证性能。

Result: HyRES相比纯复制方案降低存储成本，相比复制和纠删码降低文件丢失概率，在网络规模考虑下甚至比复制方案有更低的修复流量。

Conclusion: HyRES能够同时实现更低的存储成本、更低的文件丢失概率和更好的修复性能，是分布式存储系统的有效解决方案。

Abstract: Reliability in distributed storage systems has typically focused on the
design and deployment of data replication or erasure coding techniques.
Although some scenarios have considered the use of replication for hot data and
erasure coding for cold data in the same system, each is designed in isolation.
We propose HyRES, a hybrid scheme incorporates the best characteristics of each
scheme, thus, resulting in additional design flexibility and better potential
performance for the system. We show that HyRES generalizes previously proposed
hybrid schemes. We characterize the theoretical performance of HyRES as well as
that of replication and erasure coding considering the effects of the size of
the storage networks. We validate our theoretical results using simulations.
These results show that HyRES can yield simultaneously lower storage costs than
replication, lower probabilities of file loss than replication and erasure
coding with similar worst case performance, and even lower effective repair
traffic than replication when considering the network size.

</details>


### [7] [Lower Bounds on Conversion Bandwidth for MDS Convertible Codes in Split Regime](https://arxiv.org/abs/2511.00953)
*Lewen Wang,Sihuang Hu*

Main category: cs.IT

TL;DR: 提出了几个新的MDS可转换码带宽成本下界，改进了特定参数范围内的先前结果，并在某些情况下与现有构造匹配，证明这些下界是紧的。


<details>
  <summary>Details</summary>
Motivation: 现有MDS可转换码的带宽成本下界在某些参数范围内不够紧，需要更精确的理论界限来指导最优编码设计。

Method: 使用线性代数框架推导MDS可转换码的带宽成本下界。

Result: 推导的下界改进了先前结果，并在r^F ≤ r^I ≤ k^F参数范围内与Maturana和Rashmi的构造匹配，证明下界是紧的。

Conclusion: 提出的线性代数方法有效推导了MDS可转换码的紧带宽成本下界，为最优编码设计提供了理论基础。

Abstract: We propose several new lower bounds on the bandwidth costs of MDS convertible
codes using a linear-algebraic framework. The derived bounds improve previous
results in certain parameter regimes and match the bandwidth cost of the
construction proposed by Maturana and Rashmi (2022 IEEE International Symposium
on Information Theory) for $r^F\le r^I\le k^F$, implying that our bounds are
tight in this case.

</details>


### [8] [Secure Distributed RIS-MIMO over Double Scattering Channels: Adversarial Attack, Defense, and SER Improvement](https://arxiv.org/abs/2511.00959)
*Bui Duc Son,Gaosheng Zhao,Trinh Van Chien,Dong In Kim*

Main category: cs.IT

TL;DR: 该论文研究了分布式多RIS辅助MIMO通信系统中基于自动编码器的对抗攻击与防御，分析了RIS数量与系统性能的关系，并提出了有效的对抗训练防御机制。


<details>
  <summary>Details</summary>
Motivation: 当前无线通信系统广泛采用机器学习和深度学习技术进行优化，但这些技术在面对对抗攻击时的脆弱性研究不足，特别是在分布式多RIS辅助的MIMO系统中。

Method: 建立了分布式多RIS的信道传播模型，推导了聚合信道的闭式统计信息表达式，使用符号错误率(SER)评估系统性能，并提出基于对抗训练的防御机制。

Result: 数值结果表明：增加RIS数量能降低系统SER，但会使白盒攻击更具破坏性；提出的防御方法能显著减轻攻击影响，并在无攻击时相比原始模型进一步降低SER；该方法在包含多普勒效应的移动场景中仍保持鲁棒性。

Conclusion: 分布式多RIS系统在对抗攻击下存在脆弱性，但通过对抗训练可以有效提升系统鲁棒性，同时该方法在移动场景中依然有效。

Abstract: There has been a growing trend toward leveraging machine learning (ML) and
deep learning (DL) techniques to optimize and enhance the performance of
wireless communication systems. However, limited attention has been given to
the vulnerabilities of these techniques, particularly in the presence of
adversarial attacks. This paper investigates the adversarial attack and defense
in distributed multiple reconfigurable intelligent surfaces (RISs)-aided
multiple-input multiple-output (MIMO) communication systems-based autoencoder
in finite scattering environments. We present the channel propagation model for
distributed multiple RIS, including statistical information driven in closed
form for the aggregated channel. The symbol error rate (SER) is selected to
evaluate the collaborative dynamics between the distributed RISs and MIMO
communication in depth. The relationship between the number of RISs and the SER
of the proposed system based on an autoencoder, as well as the impact of
adversarial attacks on the system's SER, is analyzed in detail. We also propose
a defense mechanism based on adversarial training against the considered
attacks to enhance the model's robustness. Numerical results indicate that
increasing the number of RISs effectively reduces the system's SER but leads to
the adversarial attack-based algorithm becoming more destructive in the
white-box attack scenario. The proposed defense method demonstrates strong
effectiveness by significantly mitigating the attack's impact. It also
substantially reduces the system's SER in the absence of an attack compared to
the original model. Moreover, we extend the phenomenon to include decoder
mobility, demonstrating that the proposed method maintains robustness under
Doppler-induced channel variations.

</details>


### [9] [Transformer-Based Decoding in Concatenated Coding Schemes Under Synchronization Errors](https://arxiv.org/abs/2511.00999)
*Julian Streit,Franziska Weindel,Reinhard Heckel*

Main category: cs.IT

TL;DR: 提出BCJRFormer，一种基于Transformer的神经内解码器，用于从多个受插入、删除和替换错误影响的噪声副本中重建码字，特别适用于DNA数据存储场景。


<details>
  <summary>Details</summary>
Motivation: 解决DNA数据存储中从多个噪声副本重建码字的问题，传统BCJR算法在副本数量增加时计算复杂度呈指数增长，限制了实际应用。

Method: 使用基于Transformer的BCJRFormer作为内解码器替代BCJR算法，将计算复杂度从指数级降低到平方级；同时用基于Transformer的解码器替换置信传播外解码器。

Result: BCJRFormer在二进制和四进制单消息传输中达到与BCJR算法相当的误码率，且能高效处理更多副本数量。

Conclusion: BCJRFormer为DNA数据存储提供了一种高效且性能良好的端到端Transformer解码管道，并提出了ConvBCJRFormer架构作为向更通用线性码类联合解码的初步探索。

Abstract: We consider the reconstruction of a codeword from multiple noisy copies that
are independently corrupted by insertions, deletions, and substitutions. This
problem arises, for example, in DNA data storage. A common code construction
uses a concatenated coding scheme that combines an outer linear block code with
an inner code, which can be either a nonlinear marker code or a convolutional
code. Outer decoding is done with Belief Propagation, and inner decoding is
done with the Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm. However, the BCJR
algorithm scales exponentially with the number of noisy copies, which makes it
infeasible to reconstruct a codeword from more than about four copies. In this
work, we introduce BCJRFormer, a transformer-based neural inner decoder.
BCJRFormer achieves error rates comparable to the BCJR algorithm for binary and
quaternary single-message transmissions of marker codes. Importantly,
BCJRFormer scales quadratically with the number of noisy copies. This property
makes BCJRFormer well-suited for DNA data storage, where multiple reads of the
same DNA strand occur. To lower error rates, we replace the Belief Propagation
outer decoder with a transformer-based decoder. Together, these modifications
yield an efficient and performant end-to-end transformer-based pipeline for
decoding multiple noisy copies affected by insertion, deletion, and
substitution errors. Additionally, we propose a novel cross-attending
transformer architecture called ConvBCJRFormer. This architecture extends
BCJRFormer to decode transmissions of convolutional codewords, serving as an
initial step toward joint inner and outer decoding for more general linear code
classes.

</details>


### [10] [Sequence Reconstruction over the Deletion Channel](https://arxiv.org/abs/2511.01071)
*Fengxing Zhu*

Main category: cs.IT

TL;DR: 本文研究了Levenshtein序列重构问题，确定了在最多删除t个符号的情况下，重构大小为ℓ-1的候选序列列表所需的最小信道输出数量。


<details>
  <summary>Details</summary>
Motivation: 研究在删除信道下序列重构的理论界限，为纠错码和序列重构提供理论基础。

Method: 通过分析ℓ≥3个不同删除球的最大交集大小，其中每个球以{0,1}^n中的序列为中心，半径为t。

Result: 确定了在n≥t+ℓ-1且t≥1条件下，ℓ个不同删除球的最大可能交集大小。

Conclusion: 为Levenshtein序列重构问题提供了精确的理论界限，对理解删除信道下的序列重构能力有重要意义。

Abstract: In this paper, we consider the Levenshtein's sequence reconstruction problem
in the case where the transmitted codeword is chosen from $\{0,1\}^n$ and the
channel can delete up to $t$ symbols from the transmitted codeword. We
determine the minimum number of channel outputs (assuming that they are
distinct) required to reconstruct a list of size $\ell-1$ of candidate
sequences, one of which corresponds to the original transmitted sequence. More
specifically, we determine the maximum possible size of the intersection of
$\ell \geq 3$ deletion balls of radius $t$ centered at $x_1, x_2, \dots,
x_{\ell}$, where $x_i \in \{0,1\}^n$ for all $i \in \{1,2,\dots,\ell\}$ and
$x_i \neq x_j$ for $i \neq j$, with $n \geq t+ \ell-1$ and $t \geq 1$.

</details>


### [11] [Coverage Analysis and Optimization of FIRES-Assisted NOMA and OMA Systems](https://arxiv.org/abs/2511.01111)
*Farshad Rostami Ghadi,Kai-Kit Wong,Masoud Kaveh,Hanjiang Hong,Chan-Byoung Chae,Lajos Hanzo*

Main category: cs.IT

TL;DR: 本文研究了流体集成反射和发射表面(FIRES)，这是一种能够同时控制传输和反射、相位及几何定位的智能超表面。针对两用户下行链路场景，建立了覆盖中心系统模型，推导了覆盖范围闭式解，并提出了双层优化框架来最大化覆盖范围。相比传统STAR-RIS，FIRES通过联合利用几何重定位和被动能量控制，显著扩大了覆盖区域。


<details>
  <summary>Details</summary>
Motivation: 传统的同时传输和反射可重构智能表面(STAR-RIS)在覆盖范围方面存在局限性，需要开发能够同时控制传输反射、相位和几何定位的智能超表面，以提升无线通信系统的覆盖性能。

Method: 1. 建立了两用户下行链路场景下的覆盖中心系统模型，考虑空间相关Rician衰落和不完美相位控制；2. 推导了远场视距覆盖范围的闭式边界；3. 提出了双层优化框架：外层搜索FIRES元素位置，内层根据多址方案进行资源分配；4. 分别针对OMA和NOMA设计了相应的优化方法。

Result: 仿真结果表明，FIRES相比传统STAR-RIS在相同元素预算下显著扩大了覆盖区域。NOMA在可行时能提供额外的覆盖增益。分析得到的覆盖边界与仿真结果高度匹配，并量化了FIRES对相位控制不完美的鲁棒性。

Conclusion: FIRES通过联合利用几何重定位和被动能量控制，为智能超表面设计提供了新的方向，能够显著提升无线通信系统的覆盖性能，特别是在存在相位控制不完美的情况下表现出良好的鲁棒性。

Abstract: Fluid integrated reflecting and emitting surfaces (FIRES) are investigated.
In these metasurfaces, each subarea hosts an active element capable of
simultaneous transmission and reflection, phase, and geometric positioning
control within the subarea. We develop a coverage-centric system model for the
two-user downlink scenario (one user per half-space) under spatially correlated
Rician fading and imperfect phase control. First, we derive closed-form
far-field line-of-sight (LoS) coverage bounds that reveal the effects of
aperture size, base station (BS) distance, transmit power, energy-splitting
(ES), and phase errors. Protocol-aware corollaries are then presented for both
orthogonal multiple access (OMA) and non-orthogonal multiple access (NOMA),
including conditions for successful successive interference cancellation (SIC).
Second, we formulate coverage maximization as a bi-level optimization problem
consisting of (i) an outer search over FIRES element positions, selecting one
active preset per subarea under minimum-spacing constraints, and (ii) an inner
resource allocation problem tailored to the multiple-access scheme, which is
one-dimensional for OMA and a small convex program for NOMA. The proposed
framework explicitly accounts for target rate constraints, ES conservation,
power budgets, geometric placement limits, and decoding-order feasibility.
Extensive simulations demonstrate that FIRES, by jointly exploiting geometric
repositioning and passive energy control, substantially enlarges the coverage
region compared with a conventional simultaneously transmitting and reflecting
reconfigurable intelligent surface (STAR-RIS) under the same element budget.
Furthermore, NOMA yields additional coverage gains when feasible. The
analytical coverage bounds closely match the simulation results and quantify
the robustness of FIRES to phase-control imperfections.

</details>


### [12] [Distributed Matrix Multiplication-Friendly Algebraic Function Fields](https://arxiv.org/abs/2511.01162)
*Yun Long Zhu,Chang-An Zhao*

Main category: cs.IT

TL;DR: 本文提出了适用于分布式矩阵乘法的代数函数域构造，为多项式码和Matdot码提供了支持，建立了最优恢复阈值，并在特定参数下提供超过基域大小的有理点。


<details>
  <summary>Details</summary>
Motivation: 扩展多项式码和Matdot码到代数函数域的主要挑战在于构造最优解码方案，需要解决分布式矩阵乘法中的恢复阈值问题。

Method: 通过有理函数域的扩展构造分布式矩阵乘法友好的代数函数域，为多项式代数几何码和Matdot代数几何码建立最优恢复阈值。

Result: 提出的函数域支持具有最优恢复阈值的分布式矩阵乘法，在特定参数机制下提供超过基有限域大小的有理点。

Conclusion: 虽然这些函数域可能无法达到最优计算效率，但结果为矩阵乘法实现提供了实际改进，并给出了适用的函数域具体示例。

Abstract: In this paper, we introduce distributed matrix multiplication (DMM)-friendly
algebraic function fields for polynomial codes and Matdot codes, and present
several constructions for such function fields through extensions of the
rational function field. The primary challenge in extending polynomial codes
and Matdot codes to algebraic function fields lies in constructing optimal
decoding schemes. We establish optimal recovery thresholds for both polynomial
algebraic geometry (AG) codes and Matdot AG codes for fixed matrix
multiplication. Our proposed function fields support DMM with optimal recovery
thresholds, while offering rational places that exceed the base finite field
size in specific parameter regimes. Although these fields may not achieve
optimal computational efficiency, our results provide practical improvements
for matrix multiplication implementations. Explicit examples of applicable
function fields are provided.

</details>


### [13] [Conditional Diffusion Model-Enabled Scenario-Specific Neural Receivers for Superimposed Pilot Schemes](https://arxiv.org/abs/2511.01173)
*Xingyu Zhou,Le Liang,Xinjie Li,Jing Zhang,Peiwen Jiang,Xiao Li,Shi Jin*

Main category: cs.IT

TL;DR: 提出基于条件扩散模型的场景特定信道生成方法，用于数据增强以提升神经接收机性能


<details>
  <summary>Details</summary>
Motivation: 神经接收机需要大量场景特定的信道数据进行训练，但实际中难以获取，因此需要生成高质量合成信道数据

Method: 使用条件扩散模型，根据用户位置和速度信息生成信道数据，然后用于叠加导频传输的神经接收机训练

Result: 生成高保真信道样本，显著提升神经接收机在目标场景中的性能，优于传统数据增强和生成对抗网络方法

Conclusion: 条件扩散模型能有效生成场景特定信道数据，为神经接收机训练提供可靠的数据增强方案

Abstract: Neural receivers have demonstrated strong performance in wireless
communication systems. However, their effectiveness typically depends on access
to large-scale, scenario-specific channel data for training, which is often
difficult to obtain in practice. Recently, generative artificial intelligence
(AI) models, particularly diffusion models (DMs), have emerged as effective
tools for synthesizing high-dimensional data. This paper presents a
scenario-specific channel generation method based on conditional DMs, which
accurately model channel distributions conditioned on user location and
velocity information. The generated synthetic channel data are then employed
for data augmentation to improve the training of a neural receiver designed for
superimposed pilot-based transmission. Experimental results show that the
proposed method generates high-fidelity channel samples and significantly
enhances neural receiver performance in the target scenarios, outperforming
conventional data augmentation and generative adversarial network-based
techniques.

</details>


### [14] [Forget BIT, It is All about TOKEN: Towards Semantic Information Theory for LLMs](https://arxiv.org/abs/2511.01202)
*Bo Bai*

Main category: cs.IT

TL;DR: 本文从信息论角度提出了LLMs的语义信息理论框架，将基本单位从无意义的比特改为有语义的token，建立了预训练、后训练和推理阶段的信息理论度量，并理论推导了Transformer等架构的性能界限。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs研究主要依赖实验方法，需要大量计算资源和数据，因此需要从理论角度打开LLMs的黑箱，理解其背后的信息论原理。

Method: 采用率失真函数、有向信息和Granger因果关系理论，定义LLMs的概率模型，提出结构无关的信息论度量，包括预训练的有向率失真函数、后训练的有向率奖励函数和推理阶段的语义信息流。

Result: 建立了token级语义嵌入理论和信息论最优向量化方法，理论推导了Transformer架构的ELBO、泛化误差界限、记忆容量和语义信息度量，并将Mamba/Mamba2和LLaDA等架构纳入框架。

Conclusion: 为从语义信息论角度理解LLMs提供了理论框架，为后续深入研究提供了必要的理论工具。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
numerous real- world applications. While the vast majority of research
conducted from an experimental perspective is progressing rapidly, it demands
substantial computational power, data, and other resources. Therefore, how to
open the black-box of LLMs from a theoretical standpoint has become a critical
challenge. This paper takes the theory of rate-distortion function, directed
information, and Granger causality as its starting point to investigate the
information-theoretic principles behind LLMs, leading to the development of
semantic information theory for LLMs, where the fundamental unit is token,
rather than bits that lacks any semantic meaning. By defining the probabilistic
model of LLMs, we discuss structure-agnostic information-theoretic measures,
such as the directed rate- distortion function in pre-training, the directed
rate-reward function in post-training, and the semantic information flow in
inference phase. This paper also delves deeply into the theory of token-level
semantic embedding and the information-theoretically optimal vectorization
method. Thereafter, we propose a general definition of autoregression LLM,
where the Transformer architecture and its performance such as ELBO,
generalization error bound, memory capacity, and semantic information measures
can be derived theoretically. Other architectures, such as Mamba/Mamba2 and
LLaDA, are also discussed in our framework. Consequently, this paper provides a
theoretical framework for understanding LLMs from the perspective of semantic
information theory, which also offers the necessary theoretical tools for
further in-depth research.

</details>


### [15] [Error-Correcting Codes for Labeled DNA Sequences](https://arxiv.org/abs/2511.01280)
*Dganit Hanania,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 开发用于标记DNA序列的纠错码，针对单替换、插入和删除错误建立界限并构建显式系统编码器，重点关注两种标记集情况。


<details>
  <summary>Details</summary>
Motivation: DNA分子标记是DNA可视化和分析的基础技术，需要建立数学模型来处理标记过程中可能出现的错误。

Method: 建立标记DNA序列的纠错码理论框架，针对单替换、插入和删除错误推导界限，并构造显式系统编码器。研究两种标记集：完整长度二标记集和最小长度二标记集。

Result: 开发了能够纠正单替换、插入和删除错误的编码方案，并建立了相应的理论界限。

Conclusion: 所提出的纠错码框架为DNA标记序列的错误校正提供了有效的数学工具，特别是在使用不同标记集的情况下都能确保DNA序列的恢复。

Abstract: Labeling of DNA molecules is a fundamental technique for DNA visualization
and analysis. This process was mathematically modeled in [1], where the
received sequence indicates the positions of the used labels. In this work, we
develop error correcting codes for labeled DNA sequences, establishing bounds
and constructing explicit systematic encoders for single substitution,
insertion, and deletion errors. We focus on two cases: (1) using the complete
set of length-two labels and (2) using the minimal set of length-two labels
that ensures the recovery of DNA sequences from their labeling for 'almost' all
DNA sequences.

</details>


### [16] [On the Ding and Helleseth's 9th open problem about optimal ternary cyclic codes](https://arxiv.org/abs/2511.01306)
*Peipei Zheng,Dong He,Qunying Liao*

Main category: cs.IT

TL;DR: 本文研究了最优三元循环码的第9个开放问题，通过确定有限域上特殊多项式的根集，给出了不完整的答案，并基于特殊多项式构造了两类满足球填充界的最优三元循环码。


<details>
  <summary>Details</summary>
Motivation: 循环码是线性码的子类，在消费电子、数据存储和通信系统中具有应用价值。2013年Ding等人提出了关于最优三元循环码的9个开放问题，其中第9个问题尚未完全解决。

Method: 通过确定有限域上特殊多项式的根集，分析这些多项式的性质，并基于这些特殊多项式构造循环码。

Result: 给出了第9个问题的不完整答案，并成功构造了两类满足球填充界的最优三元循环码。

Conclusion: 本研究推进了对最优三元循环码第9个问题的理解，并提供了新的最优码构造方法。

Abstract: The cyclic code is a subclass of linear codes and has applications in
consumer electronics, data storage systems and communication systems as they
have efficient encoding and decoding algorithms. In 2013, Ding, et al.
presented nine open problems about optimal ternary cyclic codes. Till now, the
1st, 2nd and 6th problems were completely solved, and the 3rd, 7th, 8th and 9th
problems were partially solved. In this manuscript, we focus on the 9th
problem. By determining the root set of some special polynomials over finite
fields, we give an incomplete answer for the 9th problem, and then we construct
two classes of optimal ternary cyclic codes with respect to the Sphere Packing
Bound basing on some special polynomials over finite fields

</details>


### [17] [Several classes of three-weight or four-weight linear codes](https://arxiv.org/abs/2511.01309)
*Qunying Liao,Zhaohui Zhang,Peipei Zheng*

Main category: cs.IT

TL;DR: 构建了有限域F2上的一类射影三权重线性码和两类射影四权重线性码，使用加法特征确定了它们的重量分布，并探讨了在秘密共享方案中的应用


<details>
  <summary>Details</summary>
Motivation: 研究射影线性码的构造及其在密码学中的应用，特别是秘密共享方案

Method: 使用定义集构造方法，通过加法特征分析确定重量分布

Result: 成功构造了一类射影三权重线性码和两类射影四权重线性码，并确定了它们的重量分布

Conclusion: 所构造的射影三权重线性码和一类射影四权重线性码适用于秘密共享方案

Abstract: In this manuscript, we construct a class of projective three- weight linear
codes and two classes of projective four-weight linear codes over F2 from the
defining sets construction, and determine their weight distributions by using
additive characters. Especially, the projective three-weight linear code and
one class of projective four-weight linear codes (Theorem 4.1) can be applied
in secret sharing schemes.

</details>


### [18] [On the Computability of Finding Capacity-Achieving Codes](https://arxiv.org/abs/2511.01414)
*Angelos Gkekas,Nikos A. Mitsiou,Ioannis Souldatos,George K. Karagiannidis*

Main category: cs.IT

TL;DR: 证明存在图灵机能够为任意离散无记忆信道构造容量可达码，只要信道转移概率、目标速率和误差容限都是可计算实数。


<details>
  <summary>Details</summary>
Motivation: 从算法角度研究信道编码问题，探索在可计算性框架下构造容量可达码的可能性。

Method: 基于香农信道编码定理，采用穷举搜索方法系统枚举所有递增块长的码，直到找到满足速率和误码率要求的有效码。使用递归函数理论形式化构造过程。

Result: 证明了存在μ-递归函数FindCode，在R<信道容量时能够输出有效码的编码。通过Kleene范式定理，等价于图灵机可解。

Conclusion: 在信道转移概率、目标速率和误差容限均为可计算实数的条件下，构造容量可达码的问题是图灵机可解的，且这些假设无法进一步弱化。

Abstract: This work studies the problem of constructing capacity-achieving codes from
an algorithmic perspective. Specifically, we prove that there exists a Turing
machine which, given a discrete memoryless channel $p_{Y|X}$, a target rate $R$
less than the channel capacity $C(p_{Y|X})$, and an error tolerance $\epsilon >
0$, outputs a block code $\mathcal{C}$ achieving a rate at least $R$ and a
maximum block error probability below $\epsilon$. The machine operates in the
general case where all transition probabilities of $p_{Y|X}$ are computable
real numbers, and the parameters $R$ and $\epsilon$ are rational. The proof
builds on Shannon's Channel Coding Theorem and relies on an exhaustive search
approach that systematically enumerates all codes of increasing block length
until a valid code is found. This construction is formalized using the theory
of recursive functions, yielding a $\mu$-recursive function $\mathrm{FindCode}
: \mathbb{N}^3 \rightharpoonup \mathbb{N}$ that takes as input appropriate
encodings of $p_{Y|X}$, $R$, and $\epsilon$, and, whenever $R < C(p_{Y|X})$,
outputs an encoding of a valid code. By Kleene's Normal Form Theorem, which
establishes the computational equivalence between Turing machines and
$\mu$-recursive functions, we conclude that the problem is solvable by a Turing
machine. This result can also be extended to the case where $\epsilon$ is a
computable real number, while we further discuss an analogous generalization of
our analysis when $R$ is computable as well. We note that the assumptions that
the probabilities of $p_{Y|X}$, as well as $\epsilon$ and $R$, are computable
real numbers cannot be further weakened, since computable reals constitute the
largest subset of $\mathbb{R}$ representable by algorithmic means.

</details>


### [19] [A Hypergraph based lower bound on Pliable Index Coding based on Nested Side-Information Sets](https://arxiv.org/abs/2511.01539)
*Tulasi Sowjanya B.,Prasad Krishnan*

Main category: cs.IT

TL;DR: 本文提出了基于嵌套数的新下界来分析PICOD问题的最优长度，虽然不比其他已知下界更强，但具有计算优势，并对特殊结构的PICOD问题给出了紧下界。


<details>
  <summary>Details</summary>
Motivation: 在PICOD问题中，寻找最优编码长度和设计短长度编码方案是核心问题。现有下界方法在计算上可能不够高效，需要开发新的结构参数来改进分析。

Method: 引入新的结构参数——嵌套数η(ℋ)，该参数与表示PICOD问题的超图ℋ相关联，用于推导最优PICOD长度的新下界。

Result: 嵌套数下界虽然不比其他已知下界更强，但提供了计算优势。对于某些特殊结构的PICOD问题，基于嵌套数的下界是紧的。

Conclusion: 嵌套数作为新的结构参数，为PICOD问题的最优长度分析提供了新的视角和计算优势，特别适用于具有特殊结构的PICOD问题。

Abstract: In pliable index coding (PICOD), a number of clients are connected via a
noise-free broadcast channel to a server which has a list of messages. Each
client has a unique subset of messages at the server as side-information, and
requests for any one message not in the side-information. A PICOD scheme of
length $\ell$ is a set of $\ell$ encoded transmissions broadcast from the
server such that all clients are satisfied. Finding the optimal (minimum)
length of PICOD and designing PICOD schemes that have small length are the
fundamental questions in PICOD. In this paper, we present a new lower bound for
the optimal PICOD length using a new structural parameter called the nesting
number, denoted by $\eta(\ch)$ associated with the hypergraph $\ch$ that
represents the PICOD problem. While the nesting number bound is not stronger
than previously known bounds, it can provide some computational advantages over
them. Also, using the nesting number bound, we obtain novel lower bounds for
some PICOD problems with special structures, which are tight in some cases.

</details>


### [20] [Ergodic Rate Analysis of Two-State Pinching-Antenna Systems](https://arxiv.org/abs/2511.01798)
*Dimitrios Tyrovolas,Sotiris A. Tegos,Yue Xiao,Panagiotis D. Diamantoulakis,Sotiris Ioannidis,Christos Liaskos,George K. Karagiannidis,Stylianos D. Asimonis*

Main category: cs.IT

TL;DR: 本文分析了可编程无线环境中夹持天线系统的性能，重点研究了离散位置配置对数据速率的影响，提出了量化性能偏差的指标。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设夹持天线位置可连续调节，但实际实现中只能有有限个固定位置，需要分析这种离散化对性能的影响。

Method: 开发了分析框架评估双状态夹持天线系统的速率性能，考虑了波导的离散空间结构，推导了遍历可达数据速率的闭式表达式。

Result: 仿真结果表明，有限数量的夹持天线就能实现接近连续配置的性能，为系统设计和扩展提供了重要参考。

Conclusion: 夹持天线系统在可编程无线环境中具有实用价值，离散位置配置不会显著影响性能，系统具有良好的可扩展性。

Abstract: Programmable wireless environments (PWEs) represent a central paradigm in
next-generation communication networks, aiming to transform wireless
propagation from a passive medium into an intelligent and reconfigurable entity
capable of dynamically adapting to network demands. In this context,
pinching-antenna systems (PASs) have emerged as a promising enabler capable of
reconfiguring both the channel characteristics and the path loss itself by
selectively exciting radiation points along dielectric waveguides. However,
existing studies largely rely on the assumption of continuously reconfigurable
pinching antenna (PA) positions, overlooking the discreteness imposed by
practical implementations, which allow for only a finite number of PA position.
In this paper, an analytical framework is developed for evaluating the rate
performance of two-state PASs, where the antenna locations are fixed, and only
their activation states can be controlled. The analysis incorporates the
discrete spatial structure of the waveguide and leads to a closed-form
expression for the ergodic achievable data rate, while pinching discretization
efficiency is introduced to quantify the performance deviation from the ideal
continuous configuration. Simulation results demonstrate that near-continuous
performance can be achieved with a limited number of PAs, offering valuable
insights into the design and scalability of PASs in PWEs.

</details>


### [21] [Efficient Vector Symbolic Architectures from Histogram Recovery](https://arxiv.org/abs/2511.01838)
*Zirui Deng,Netanel Raviv*

Main category: cs.IT

TL;DR: 本文提出了一种基于级联Reed-Solomon和Hadamard码的噪声弹性向量符号架构，通过解决直方图恢复问题实现了高效编码、准正交性和恢复能力。


<details>
  <summary>Details</summary>
Motivation: 随机线性码在向量符号架构中难以在噪声下解码，限制了信息恢复能力，需要一种具有正式保证的噪声弹性解决方案。

Method: 使用Reed-Solomon和Hadamard码级联，提出直方图恢复问题，并利用列表解码相关算法提供最优解。

Result: 开发出具有正式保证的噪声弹性VSA，在高效编码、准正交性和恢复方面优于类似解决方案如Hadamard码。

Conclusion: 该方法为向量符号架构提供了不依赖启发式或训练的噪声弹性解决方案，具有改进的参数性能。

Abstract: Vector symbolic architectures (VSAs) are a family of information
representation techniques which enable composition, i.e., creating complex
information structures from atomic vectors via binding and superposition, and
have recently found wide ranging applications in various neurosymbolic
artificial intelligence (AI) systems. Recently, Raviv proposed the use of
random linear codes in VSAs, suggesting that their subcode structure enables
efficient binding, while preserving the quasi-orthogonality that is necessary
for neural processing. Yet, random linear codes are difficult to decode under
noise, which severely limits the resulting VSA's ability to support recovery,
i.e., the retrieval of information objects and their attributes from a noisy
compositional representation.
  In this work we bridge this gap by utilizing coding theoretic tools. First,
we argue that the concatenation of Reed-Solomon and Hadamard codes is suitable
for VSA, due to the mutual quasi-orthogonality of the resulting codewords (a
folklore result). Second, we show that recovery of the resulting compositional
representations can be done by solving a problem we call histogram recovery. In
histogram recovery, a collection of $N$ histograms over a finite field is given
as input, and one must find a collection of Reed-Solomon codewords of length
$N$ whose entry-wise symbol frequencies obey those histograms. We present an
optimal solution to the histogram recovery problem by using algorithms related
to list-decoding, and analyze the resulting noise resilience. Our results give
rise to a noise-resilient VSA with formal guarantees regarding efficient
encoding, quasi-orthogonality, and recovery, without relying on any heuristics
or training, and while operating at improved parameters relative to similar
solutions such as the Hadamard code.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [22] [Optimal Allocations under Strongly Pigou-Dalton Criteria: Hidden Layer Structure & Efficient Combinatorial Approach](https://arxiv.org/abs/2511.00835)
*Taikun Zhu,Kai Jin,Ruixi Luo,Song Cao*

Main category: cs.GT

TL;DR: 该论文研究了在二元加性或次模估值下，最优社会福利分配与稳定分配的关系，并设计了高效算法来寻找稳定分配。


<details>
  <summary>Details</summary>
Motivation: 研究在二元加性或次模估值下，如何找到最优社会福利分配，并探索其与稳定分配的关系，以提供更高效的算法解决方案。

Method: 证明了在SPD对称标准下，最优分配集与稳定分配集重合；设计了O(m²n)时间算法处理不可分物品，O(m²n⁵)时间算法处理可分物品，后者通过隐藏层划分将可分物品问题简化为不可分物品问题。

Result: 发现不同最优分配的配置具有较小的切比雪夫距离：在可分物品二元加性估值下为0，在不可分物品二元次模估值下最多为1。

Conclusion: 稳定分配与最优社会福利分配在SPD对称标准下等价，且设计的算法在效率和简化分析方面优于现有方法。

Abstract: We investigate optimal social welfare allocations of $m$ items to $n$ agents
with binary additive or submodular valuations. For binary additive valuations,
we prove that the set of optimal allocations coincides with the set of
so-called \emph{stable allocations}, as long as the employed criterion for
evaluating social welfare is strongly Pigou-Dalton (SPD) and symmetric. Many
common criteria are SPD and symmetric, such as Nash social welfare, leximax,
leximin, Gini index, entropy, and envy sum. We also design efficient algorithms
for finding a stable allocation, including an $O(m^2n)$ time algorithm for the
case of indivisible items, and an $O(m^2n^5)$ time one for the case of
divisible items. The first is faster than the existing algorithms or has a
simpler analysis. The latter is the first combinatorial algorithm for that
problem. It utilizes a hidden layer partition of items and agents admitted by
all stable allocations, and cleverly reduces the case of divisible items to the
case of indivisible items.
  In addition, we show that the profiles of different optimal allocations have
a small Chebyshev distance, which is 0 for the case of divisible items under
binary additive valuations, and is at most 1 for the case of indivisible items
under binary submodular valuations.

</details>


### [23] [Pay for The Second-Best Service: A Game-Theoretic Approach Against Dishonest LLM Providers](https://arxiv.org/abs/2511.00847)
*Yuhan Cao,Yu Wang,Sitong Liu,Miao Li,Yixin Tao,Tianxing He*

Main category: cs.GT

TL;DR: 本文针对LLM API服务中的提供商欺诈问题，提出了首个形式化经济模型和近似激励兼容机制，确保用户效用并防止提供商操纵。


<details>
  <summary>Details</summary>
Motivation: LLM API的广泛使用带来了服务提供商可能进行欺诈操纵的严重漏洞，如秘密替换模型或填充无用标记来增加计费。

Method: 采用算法博弈论和机制设计方法，建立用户-提供商生态系统模型，设计近似激励兼容机制来处理连续策略空间。

Result: 证明了存在近似激励兼容机制，具有O(T^{1-ϵ}logT)的加性近似比和准线性次优用户效用保证，并通过仿真实验验证了有效性。

Conclusion: 该机制在理论上和实践中都能有效应对LLM API服务中的欺诈问题，且无法找到比该机制渐近更好的用户效用保证机制。

Abstract: The widespread adoption of Large Language Models (LLMs) through Application
Programming Interfaces (APIs) induces a critical vulnerability: the potential
for dishonest manipulation by service providers. This manipulation can manifest
in various forms, such as secretly substituting a proclaimed high-performance
model with a low-cost alternative, or inflating responses with meaningless
tokens to increase billing. This work tackles the issue through the lens of
algorithmic game theory and mechanism design. We are the first to propose a
formal economic model for a realistic user-provider ecosystem, where a user can
iteratively delegate $T$ queries to multiple model providers, and providers can
engage in a range of strategic behaviors. As our central contribution, we prove
that for a continuous strategy space and any $\epsilon\in(0,\frac12)$, there
exists an approximate incentive-compatible mechanism with an additive
approximation ratio of $O(T^{1-\epsilon}\log T)$, and a guaranteed quasi-linear
second-best user utility. We also prove an impossibility result, stating that
no mechanism can guarantee an expected user utility that is asymptotically
better than our mechanism. Furthermore, we demonstrate the effectiveness of our
mechanism in simulation experiments with real-world API settings.

</details>


### [24] [Deliberation via Matching](https://arxiv.org/abs/2511.00986)
*Kamesh Munagala,Qilin Ye,Ian Zhang*

Main category: cs.GT

TL;DR: 提出了一种通过匹配讨论的审议式社会选择协议，该协议在度量失真框架下达到了紧致的失真界限3，突破了无审议情况下3.11的下界。


<details>
  <summary>Details</summary>
Motivation: 研究审议式社会选择，让选民通过小组讨论来完善偏好，然后进行集体聚合，旨在提高社会选择的质量。

Method: 引入审议-匹配协议：对每对候选人，在意见不同的选民中形成最大匹配，匹配对进行审议，然后使用加权未覆盖集锦标赛规则聚合偏好。

Result: 该协议在度量失真框架下具有紧致的失真界限3，突破了无审议情况下3.11的下界，匹配了无审议确定性社会选择规则的下界。

Conclusion: 锦标赛规则在获得成对审议的最小附加能力后，与一般社会选择规则同样强大，技术洞察为失真目标函数在度量距离上具有超模性和凸性。

Abstract: We study deliberative social choice, where voters refine their preferences
through small-group discussions before collective aggregation. We introduce a
simple and easily implementable deliberation-via-matching protocol: for each
pair of candidates, we form an arbitrary maximum matching among voters who
disagree on that pair, and each matched pair deliberates. The resulting
preferences (individual and deliberative) are then appropriately weighted and
aggregated using the weighted uncovered set tournament rule.
  We show that our protocol has a tight distortion bound of $3$ within the
metric distortion framework. This breaks the previous lower bound of $3.11$ for
tournament rules without deliberation and matches the lower bound for
deterministic social choice rules without deliberation. Our result conceptually
shows that tournament rules are just as powerful as general social choice
rules, when the former are given the minimal added power of pairwise
deliberations. We prove our bounds via a novel bilinear relaxation of the
non-linear program capturing optimal distortion, whose vertices we can
explicitly enumerate, leading to an analytic proof. Loosely speaking, our key
technical insight is that the distortion objective, as a function of metric
distances to any three alternatives, is both supermodular and convex. We
believe this characterization provides a general analytical framework for
studying the distortion of other deliberative protocols, and may be of
independent interest.

</details>


### [25] [From Best Responses to Learning: Investment Efficiency in Dynamic Environment](https://arxiv.org/abs/2511.01157)
*Ce Li,Qianfan Zhang,Weiqiang Zheng*

Main category: cs.GT

TL;DR: 研究动态环境中学习型投资者的福利保障，分析近似分配算法在投资者使用无悔在线学习而非最优响应时的福利保证。


<details>
  <summary>Details</summary>
Motivation: 现实世界中投资者由于动态环境中的不完全信息，无法总是做出最优响应决策，需要研究学习型投资者的福利保障问题。

Method: 考虑使用无悔在线学习算法的投资者，分析近似分配算法在动态学习环境中的福利保证，通过近似比率衡量算法性能。

Result: 静态环境中的近似比率在动态环境中相对于事后最优基准保持不变；对更强的时间变化基准给出了紧致的近似上下界刻画。

Conclusion: 将机制设计与在线学习理论结合，表明即使代理无法做出最优响应但在复杂不确定环境中学习投资策略时，仍能保持稳健的福利保证。

Abstract: We study the welfare of a mechanism in a dynamic environment where a learning
investor can make a costly investment to change her value. In many real-world
problems, the common assumption that the investor always makes the best
responses, i.e., choosing her utility-maximizing investment option, is
unrealistic due to incomplete information in a dynamically evolving
environment. To address this, we consider an investor who uses a no-regret
online learning algorithm to adaptively select investments through repeated
interactions with the environment. We analyze how the welfare guarantees of
approximation allocation algorithms extend from static to dynamic settings when
the investor learns rather than best-responds, by studying the approximation
ratio for optimal welfare as a measurement of an algorithm's performance
against different benchmarks in the dynamic learning environment. First, we
show that the approximation ratio in the static environment remains unchanged
in the dynamic environment against the best-in-hindsight benchmark. Second, we
provide tight characterizations of the approximation upper and lower bounds
relative to a stronger time-varying benchmark. Bridging mechanism design with
online learning theory, our work shows how robust welfare guarantees can be
maintained even when an agent cannot make best responses but learns their
investment strategies in complex, uncertain environments.

</details>


### [26] [Designing Non-monetary Intersection Control Mechanisms for Efficient Selfish Routing](https://arxiv.org/abs/2511.01421)
*Yusuf Saltan,Jyun-Jhe Wang,Arda Kosay,Chung-Wei Lin,Muhammed O. Sayin*

Main category: cs.GT

TL;DR: 提出一种非货币机制，通过战略性地调整车辆通过交叉口的时间戳来激励社会效率最优的路由选择，在Sioux Falls网络上实现了均衡流与最优流之间效率差距减少68%的效果。


<details>
  <summary>Details</summary>
Motivation: 城市交通拥堵源于自利路由决策与社会最优流之间的不匹配。交叉口作为关键瓶颈放大了这些低效率，因为现有控制方案往往忽略驾驶员的战略行为。

Method: 采用分层架构，将路边单元负责的本地调度与中央规划器负责的网络范围时间戳调整分离。建立实验验证的分析模型，证明均衡流的存在性和唯一性，并将规划器问题表述为可离线求解的双层优化程序。

Result: 在Sioux Falls网络上的实验显示，均衡流与最优流之间的效率差距减少了高达68%，证明了该方法的可扩展性和有效性。

Conclusion: 利用车辆到基础设施通信实现的精细控制，通过非货币机制战略性地调整请求时间戳，能够有效激励社会效率最优的路由选择，显著改善交通拥堵问题。

Abstract: Urban traffic congestion stems from the misalignment between self-interested
routing decisions and socially optimal flows. Intersections, as critical
bottlenecks, amplify these inefficiencies because existing control schemes
often neglect drivers' strategic behavior. Autonomous intersections, enabled by
vehicle-to-infrastructure communication, permit vehicle-level scheduling based
on individual requests. Leveraging this fine-grained control, we propose a
non-monetary mechanism that strategically adjusts request timestamps-delaying
or advancing passage times-to incentivize socially efficient routing. We
present a hierarchical architecture separating local scheduling by roadside
units from network-wide timestamp adjustments by a central planner. We
establish an experimentally validated analytical model, prove the existence and
essential uniqueness of equilibrium flows and formulate the planner's problem
as an offline bilevel optimization program solvable with standard tools.
Experiments on the Sioux Falls network show up to a 68% reduction in the
efficiency gap between equilibrium and optimal flows, demonstrating scalability
and effectiveness.

</details>


### [27] [Proximal Regret and Proximal Correlated Equilibria: A New Tractable Solution Concept for Online Learning and Games](https://arxiv.org/abs/2511.01852)
*Yang Cai,Constantinos Daskalakis,Haipeng Luo,Chen-Yu Wei,Weiqiang Zheng*

Main category: cs.GT

TL;DR: 本文提出了近端遗憾的新概念，它介于外部遗憾和交换遗憾之间。当所有玩家在一般凸博弈中使用无近端遗憾算法时，经验分布会收敛到近端相关均衡。主要结果表明在线梯度下降算法实现了最优的O(√T)近端遗憾界。


<details>
  <summary>Details</summary>
Motivation: 学习和计算均衡是算法博弈论的核心问题。现有遗憾概念如外部遗憾和交换遗憾存在局限性，需要引入更精细的遗憾概念来更好地理解在线学习和博弈中的收敛行为。

Method: 引入基于近端算子的近端遗憾概念，分析在线梯度下降、镜像下降和乐观梯度下降算法在近端遗憾下的性能。

Result: 在线梯度下降算法实现了最优的O(√T)近端遗憾界，镜像下降在Bregman设置下也有效，乐观梯度下降在光滑凸博弈中能获得更快的收敛速度。

Conclusion: 近端遗憾框架统一了在线学习和博弈论中的多个新兴概念，为梯度下降在在线学习和博弈中优越的实证表现提供了新的理论解释。

Abstract: Learning and computation of equilibria are central problems in algorithmic
game theory. In this work, we introduce proximal regret, a new notion of regret
based on proximal operators that lies strictly between external and swap
regret. When every player employs a no-proximal-regret algorithm in a general
convex game, the empirical distribution of play converges to proximal
correlated equilibria (PCE), a refinement of coarse correlated equilibria. Our
framework unifies several emerging notions in online learning and game theory
-- such as gradient equilibrium and semicoarse correlated equilibrium -- and
introduces new ones. Our main result shows that the classic Online Gradient
Descent (GD) algorithm achieves an optimal $O(\sqrt{T})$ bound on proximal
regret, revealing that GD, without modification, minimizes a stronger regret
notion than external regret. This provides a new explanation for the
empirically superior performance of gradient descent in online learning and
games. We further extend our analysis to Mirror Descent in the Bregman setting
and to Optimistic Gradient Descent, which yields faster convergence in smooth
convex games.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [28] [LookSync: Large-Scale Visual Product Search System for AI-Generated Fashion Looks](https://arxiv.org/abs/2511.00072)
*Pradeep M,Ritesh Pallod,Satyen Abrol,Muthu Raman,Ian Anderson*

Main category: cs.IR

TL;DR: 提出并部署了一个端到端的产品搜索系统，用于将AI生成的时尚造型与最相似的实体产品进行匹配，该系统每天处理超过35万个AI造型，覆盖1200万产品。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在时尚领域的应用，需要找到与AI生成造型最匹配的真实产品，以提升用户体验和商业价值。

Method: 系统包含四个关键组件：查询生成、向量化、候选检索和基于AI造型的重排序，使用CLIP模型进行向量表示。

Result: 在实验中，CLIP模型在平均意见分数上比其他模型高出3-7%，虽然绝对改进不大，但显著提升了用户感知匹配度。

Conclusion: CLIP被确立为生产部署中最可靠的骨干模型，能够有效匹配AI生成的时尚造型与真实产品。

Abstract: Generative AI is reshaping fashion by enabling virtual looks and avatars
making it essential to find real products that best match AI-generated styles.
We propose an end-to-end product search system that has been deployed in a
real-world, internet scale which ensures that AI-generated looks presented to
users are matched with the most visually and semantically similar products from
the indexed vector space. The search pipeline is composed of four key
components: query generation, vectorization, candidate retrieval, and reranking
based on AI-generated looks. Recommendation quality is evaluated using
human-judged accuracy scores. The system currently serves more than 350,000 AI
Looks in production per day, covering diverse product categories across global
markets of over 12 million products. In our experiments, we observed that
across multiple annotators and categories, CLIP outperformed alternative models
by a small relative margin of 3--7\% in mean opinion scores. These
improvements, though modest in absolute numbers, resulted in noticeably better
user perception matches, establishing CLIP as the most reliable backbone for
production deployment.

</details>


### [29] [Effectiveness of LLMs in Temporal User Profiling for Recommendation](https://arxiv.org/abs/2511.00176)
*Milad Sabouri,Masoud Mansoury,Kun Lin,Bamshad Mobasher*

Main category: cs.IR

TL;DR: 利用大语言模型区分用户短期和长期兴趣，提升推荐系统准确性和可解释性，但在用户参与度不同的领域效果存在差异。


<details>
  <summary>Details</summary>
Motivation: 传统用户画像方法忽视了短期兴趣和长期偏好的区别，需要更好地建模用户偏好的动态特性来提升推荐准确性和透明度。

Method: 使用大语言模型从用户交互历史中生成独立的短期和长期文本摘要，创建更丰富的用户表示。

Result: 在用户参与度高的领域（如电影电视）LLM能显著提升推荐质量，但在稀疏环境中效果不明显，因为不同领域短期和长期兴趣的可区分性不同。

Conclusion: LLM驱动的时序用户画像在提升性能的同时提供内在可解释性，但需要根据具体应用场景权衡计算成本，为开发自适应和透明的推荐系统指明了新方向。

Abstract: Effectively modeling the dynamic nature of user preferences is crucial for
enhancing recommendation accuracy and fostering transparency in recommender
systems. Traditional user profiling often overlooks the distinction between
transitory short-term interests and stable long-term preferences. This paper
examines the capability of leveraging Large Language Models (LLMs) to capture
these temporal dynamics, generating richer user representations through
distinct short-term and long-term textual summaries of interaction histories.
Our observations suggest that while LLMs tend to improve recommendation quality
in domains with more active user engagement, their benefits appear less
pronounced in sparser environments. This disparity likely stems from the
varying distinguishability of short-term and long-term preferences across
domains; the approach shows greater utility where these temporal interests are
more clearly separable (e.g., Movies\&TV) compared to domains with more stable
user profiles (e.g., Video Games). This highlights a critical trade-off between
enhanced performance and computational costs, suggesting context-dependent LLM
application. Beyond predictive capability, this LLM-driven approach inherently
provides an intrinsic potential for interpretability through its natural
language profiles and attention weights. This work contributes insights into
the practical capability and inherent interpretability of LLM-driven temporal
user profiling, outlining new research directions for developing adaptive and
transparent recommender systems.

</details>


### [30] [Simple and Behavior-Driven Augmentation for Recommendation with Rich Collaborative Signals](https://arxiv.org/abs/2511.00436)
*Doyun Choi,Cheonwoo Lee,Jaemin Yoo*

Main category: cs.IR

TL;DR: 提出SCAR方法，通过生成伪交互而非删除信息来增强图协同过滤的对比学习效果，在稀疏数据场景下表现优异


<details>
  <summary>Details</summary>
Motivation: 传统对比学习方法通过删除噪声交互来生成增强视图，但定义"噪声"存在模糊性，可能导致核心信息丢失和不可靠的视图生成，同时增加了增强过程的复杂度

Method: SCAR方法从用户-物品交互中提取协同信号来生成伪交互，然后将这些伪交互添加到现有交互中或替换现有交互，从而生成更鲁棒的表示

Result: 在四个基准数据集上的实验表明，SCAR在关键评估指标上优于之前的基于对比学习的图协同过滤方法和其他最先进的自监督学习方法，在不同超参数设置下表现出强鲁棒性，在稀疏数据场景下特别有效

Conclusion: SCAR提供了一种简单而有效的增强方法，通过生成伪交互而非删除信息来最大化图协同过滤中对比学习的效果，避免了复杂增强模块的缺陷

Abstract: Contrastive learning (CL) has been widely used for enhancing the performance
of graph collaborative filtering (GCF) for personalized recommendation. Since
data augmentation plays a crucial role in the success of CL, previous works
have designed augmentation methods to remove noisy interactions between users
and items in order to generate effective augmented views. However, the
ambiguity in defining ''noisiness'' presents a persistent risk of losing core
information and generating unreliable data views, while increasing the overall
complexity of augmentation. In this paper, we propose Simple Collaborative
Augmentation for Recommendation (SCAR), a novel and intuitive augmentation
method designed to maximize the effectiveness of CL for GCF. Instead of
removing information, SCAR leverages collaborative signals extracted from
user-item interactions to generate pseudo-interactions, which are then either
added to or used to replace existing interactions. This results in more robust
representations while avoiding the pitfalls of overly complex augmentation
modules. We conduct experiments on four benchmark datasets and show that SCAR
outperforms previous CL-based GCF methods as well as other state-of-the-art
self-supervised learning approaches across key evaluation metrics. SCAR
exhibits strong robustness across different hyperparameter settings and is
particularly effective in sparse data scenarios.

</details>


### [31] [LIR: The First Workshop on Late Interaction and Multi Vector Retrieval @ ECIR 2026](https://arxiv.org/abs/2511.00444)
*Benjamin Clavié,Xianming Li,Antoine Chaffin,Omar Khattab,Tom Aarsen,Manuel Faysse,Jing Li*

Main category: cs.IR

TL;DR: 该论文讨论了延迟交互检索方法（以ColBERT为代表）的优势、挑战及其在新型应用场景中的适用性，并提出了一个旨在促进相关研究和实践交流的研讨会。


<details>
  <summary>Details</summary>
Motivation: 延迟交互检索方法在泛化性和鲁棒性方面表现出色，尤其适用于跨领域和新型应用场景，但存在效率、可用性和系统集成等挑战。当前研究分散且缺乏实践者参与，需要促进交流与合作。

Method: 通过组织LIR研讨会，为来自不同背景的研究者和实践者提供一个高度互动的环境，讨论延迟交互的各个方面，包括早期研究探索、实际应用成果以及负面或令人困惑的结果。

Result: 研讨会旨在促进延迟交互检索方法的研究和实践交流，推动进一步合作，解决当前研究分散和缺乏实践者参与的问题。

Conclusion: 延迟交互检索方法具有显著优势，但也面临挑战。通过LIR研讨会，可以促进相关研究和实践的交流与合作，推动该领域的进一步发展。

Abstract: Late interaction retrieval methods, pioneered by ColBERT, have emerged as a
powerful alternative to single-vector neural IR. By leveraging fine-grained,
token-level representations, they have been demonstrated to deliver strong
generalisation and robustness, particularly in out-of-domain settings. They
have recently been shown to be particularly well-suited for novel use cases,
such as reasoning-based or cross-modality retrieval. At the same time, these
models pose significant challenges of efficiency, usability, and integrations
into fully fledged systems; as well as the natural difficulties encountered
while researching novel application domains. Recent years have seen rapid
advances across many of these areas, but research efforts remain fragmented
across communities and frequently exclude practitioners. The purpose of this
workshop is to create an environment where all aspects of late interaction can
be discussed, with a focus on early research explorations, real-world outcomes,
and negative or puzzling results to be freely shared and discussed. The aim of
LIR is to provide a highly-interactive environment for researchers from various
backgrounds and practitioners to freely discuss their experience, fostering
further collaboration.

</details>


### [32] [Listwise Preference Diffusion Optimization for User Behavior Trajectories Prediction](https://arxiv.org/abs/2511.00530)
*Hongtao Huang,Chengkai Huang,Junda Wu,Tong Yu,Julian McAuley,Lina Yao*

Main category: cs.IR

TL;DR: 提出了Listwise Preference Diffusion Optimization (LPDO)框架，用于预测用户行为轨迹，通过扩散模型直接优化整个项目序列的结构化偏好，克服了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统序列推荐方法无法捕捉序列项之间的全局列表依赖关系，这在预测多步用户行为轨迹时至关重要，特别是在个性化商务和自适应内容交付等应用中。

Method: 引入LPDO扩散训练框架，结合Plackett-Luce监督信号，推导出与列表排序似然对齐的紧密变分下界，实现跨去噪步骤的连贯偏好生成。

Result: 在真实世界用户行为基准测试中，LPDO始终优于最先进的基线方法，为扩散模型的结构化偏好学习建立了新基准。

Conclusion: LPDO通过直接优化结构化偏好，成功解决了多步用户行为轨迹预测中的全局依赖建模问题，为序列推荐提供了更有效的解决方案。

Abstract: Forecasting multi-step user behavior trajectories requires reasoning over
structured preferences across future actions, a challenge overlooked by
traditional sequential recommendation. This problem is critical for
applications such as personalized commerce and adaptive content delivery, where
anticipating a user's complete action sequence enhances both satisfaction and
business outcomes. We identify an essential limitation of existing paradigms:
their inability to capture global, listwise dependencies among sequence items.
To address this, we formulate User Behavior Trajectory Prediction (UBTP) as a
new task setting that explicitly models long-term user preferences. We
introduce Listwise Preference Diffusion Optimization (LPDO), a diffusion-based
training framework that directly optimizes structured preferences over entire
item sequences. LPDO incorporates a Plackett-Luce supervision signal and
derives a tight variational lower bound aligned with listwise ranking
likelihoods, enabling coherent preference generation across denoising steps and
overcoming the independent-token assumption of prior diffusion methods. To
rigorously evaluate multi-step prediction quality, we propose the task-specific
metric Sequential Match (SeqMatch), which measures exact trajectory agreement,
and adopt Perplexity (PPL), which assesses probabilistic fidelity. Extensive
experiments on real-world user behavior benchmarks demonstrate that LPDO
consistently outperforms state-of-the-art baselines, establishing a new
benchmark for structured preference learning with diffusion models.

</details>


### [33] [Structurally Refined Graph Transformer for Multimodal Recommendation](https://arxiv.org/abs/2511.00584)
*Ke Shi,Yan Zhang,Miao Zhang,Lifan Chen,Jiali Yi,Kui Xiao,Xiaoju Hou,Zhifei Li*

Main category: cs.IR

TL;DR: SRGFormer是一个结构优化的多模态推荐模型，通过改进Transformer捕获用户整体行为模式，使用超图结构增强局部结构学习，并通过自监督任务整合多模态信息，在三个公开数据集上表现优于基准模型。


<details>
  <summary>Details</summary>
Motivation: 当前多模态推荐模型存在三个主要问题：1）忽视冗余与有价值数据的区分；2）依赖单一语义框架导致用户偏好表示不完整；3）未能充分捕捉用户与物品间的复杂交互。

Method: 1）改进Transformer以捕获用户整体行为模式；2）将多模态信息嵌入超图结构学习局部结构；3）应用自监督任务增强多模态信息整合。

Result: 在三个公开数据集上的实验表明，SRGFormer超越先前基准模型，在Sports数据集上平均性能提升4.47%。

Conclusion: SRGFormer通过结构优化和自监督学习有效解决了多模态推荐中的关键挑战，显著提升了推荐性能。

Abstract: Multimodal recommendation systems utilize various types of information,
including images and text, to enhance the effectiveness of recommendations. The
key challenge is predicting user purchasing behavior from the available data.
Current recommendation models prioritize extracting multimodal information
while neglecting the distinction between redundant and valuable data. They also
rely heavily on a single semantic framework (e.g., local or global semantics),
resulting in an incomplete or biased representation of user preferences,
particularly those less expressed in prior interactions. Furthermore, these
approaches fail to capture the complex interactions between users and items,
limiting the model's ability to meet diverse users. To address these
challenges, we present SRGFormer, a structurally optimized multimodal
recommendation model. By modifying the transformer for better integration into
our model, we capture the overall behavior patterns of users. Then, we enhance
structural information by embedding multimodal information into a hypergraph
structure to aid in learning the local structures between users and items.
Meanwhile, applying self-supervised tasks to user-item collaborative signals
enhances the integration of multimodal information, thereby revealing the
representational features inherent to the data's modality. Extensive
experiments on three public datasets reveal that SRGFormer surpasses previous
benchmark models, achieving an average performance improvement of 4.47 percent
on the Sports dataset. The code is publicly available online.

</details>


### [34] [Taxonomy-based Negative Sampling In Personalized Semantic Search for E-commerce](https://arxiv.org/abs/2511.00694)
*Uthman Jinadu,Siawpeng Er,Le Yu,Chen Liang,Bingxin Li,Yi Ding,Aleksandar Velkoski*

Main category: cs.IR

TL;DR: 提出了一种用于电商搜索的语义检索模型，采用基于分类的困难负样本采样策略，并整合用户个性化信息，显著提升了检索效果和业务指标。


<details>
  <summary>Details</summary>
Motivation: 传统电商搜索模型难以理解特定领域的细微商品差异，采样方法计算成本高，且未考虑用户历史购买行为，导致检索结果不相关。

Method: 构建查询和商品共享向量空间，采用基于分类的困难负样本采样策略挖掘上下文相关但具有挑战性的负样本，并整合用户历史购买行为进行个性化建模。

Result: 线下实验在Recall@K指标上优于BM25、ANCE等基线方法，线上A/B测试显示转化率、加购率和客单价均有显著提升，分类驱动的负样本减少了训练开销并加速收敛。

Conclusion: 该语义检索模型通过有效的负样本采样和个性化整合，在电商搜索中实现了显著性能提升，并分享了大规模部署的实践经验。

Abstract: Large retail outlets offer products that may be domain-specific, and this
requires having a model that can understand subtle differences in similar
items. Sampling techniques used to train these models are most of the time,
computationally expensive or logistically challenging. These models also do not
factor in users' previous purchase patterns or behavior, thereby retrieving
irrelevant items for them. We present a semantic retrieval model for e-commerce
search that embeds queries and products into a shared vector space and
leverages a novel taxonomy-based hard-negative sampling(TB-HNS) strategy to
mine contextually relevant yet challenging negatives. To further tailor
retrievals, we incorporate user-level personalization by modeling each
customer's past purchase history and behavior. In offline experiments, our
approach outperforms BM25, ANCE and leading neural baselines on Recall@K, while
live A/B testing shows substantial uplifts in conversion rate, add-to-cart
rate, and average order value. We also demonstrate that our taxonomy-driven
negatives reduce training overhead and accelerate convergence, and we share
practical lessons from deploying this system at scale.

</details>


### [35] [REaR: Retrieve, Expand and Refine for Effective Multitable Retrieval](https://arxiv.org/abs/2511.00805)
*Rishita Agarwal,Himanshu Singhal,Peter Baile Chen,Manan Roy Choudhury,Dan Roth,Vivek Gupta*

Main category: cs.IR

TL;DR: REAR是一个三阶段、无需LLM的多表检索框架，通过分离语义相关性和结构可连接性来改进复杂表格问答中的多表检索质量。


<details>
  <summary>Details</summary>
Motivation: 现有检索器主要优化查询-表格相关性，但忽略了表格间的结构兼容性，导致在需要多表推理的自然语言查询中表现不佳。

Method: 采用三阶段方法：(1)检索查询对齐的表格，(2)通过预计算的列嵌入比较扩展结构可连接的表格，(3)通过修剪噪声或弱相关候选表格进行精炼。

Result: 在BIRD、MMQA和Spider等复杂表格问答数据集上，REAR显著提升了密集/稀疏检索器的性能，在多表检索质量和下游SQL执行方面都有改进。

Conclusion: REAR是一个实用、可扩展的构建块，无需LLM就能达到与最先进LLM增强检索系统竞争的性能，同时具有更低的延迟和成本。

Abstract: Answering natural language queries over relational data often requires
retrieving and reasoning over multiple tables, yet most retrievers optimize
only for query-table relevance and ignore table table compatibility. We
introduce REAR (Retrieve, Expand and Refine), a three-stage, LLM-free framework
that separates semantic relevance from structural joinability for efficient,
high-fidelity multi-table retrieval. REAR (i) retrieves query-aligned tables,
(ii) expands these with structurally joinable tables via fast, precomputed
column-embedding comparisons, and (iii) refines them by pruning noisy or weakly
related candidates. Empirically, REAR is retriever-agnostic and consistently
improves dense/sparse retrievers on complex table QA datasets (BIRD, MMQA, and
Spider) by improving both multi-table retrieval quality and downstream SQL
execution. Despite being LLM-free, it delivers performance competitive with
state-of-the-art LLM-augmented retrieval systems (e.g.,ARM) while achieving
much lower latency and cost. Ablations confirm complementary gains from
expansion and refinement, underscoring REAR as a practical, scalable building
block for table-based downstream tasks (e.g., Text-to-SQL).

</details>


### [36] [Controlling Gender Bias in Retrieval via a Backpack Architecture](https://arxiv.org/abs/2511.00875)
*Amirabbas Afzali,Amirreza Velae,Iman Ahmadi,Mohammad Aliannejadi*

Main category: cs.IR

TL;DR: 提出了一个基于Backpack语言模型的去偏框架，用于减轻文本检索和排序任务中的性别偏见，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中的社会偏见会传播有害刻板印象，当集成到排序系统中时会导致不公平结果，需要有效的去偏方法。

Method: 利用Backpack语言模型的架构特点，通过非上下文学习的词方面组合生成输出，构建去偏框架。

Result: 实验结果显示该框架能有效减轻文本检索和排序中的性别偏见，且性能下降最小。

Conclusion: Backpack语言模型的架构特性为排序任务去偏提供了有效途径，能在保持性能的同时减轻社会偏见。

Abstract: The presence of social biases in large language models (LLMs) has become a
significant concern in AI research. These biases, often embedded in training
data, can perpetuate harmful stereotypes and distort decision-making processes.
When LLMs are integrated into ranking systems, they can propagate these biases,
leading to unfair outcomes in critical applications such as search engines and
recommendation systems. Backpack Language Models, unlike traditional
transformer-based models that treat text sequences as monolithic structures,
generate outputs as weighted combinations of non-contextual, learned word
aspects, also known as senses. Leveraging this architecture, we propose a
framework for debiasing ranking tasks. Our experimental results show that this
framework effectively mitigates gender bias in text retrieval and ranking with
minimal degradation in performance.

</details>


### [37] [Contextual Relevance and Adaptive Sampling for LLM-Based Document Reranking](https://arxiv.org/abs/2511.01208)
*Jerry Huang,Siddarth Madala,Cheng Niu,Julia Hockenmaier,Tong Zhang*

Main category: cs.IR

TL;DR: 提出上下文相关性概念和TS-SetRank算法，通过考虑文档批次组合和排序位置来改进需要深度推理的查询的文档重排序效果


<details>
  <summary>Details</summary>
Motivation: 现有重排序算法在处理需要深度推理的查询时效果有限，这类查询具有多面性信息需求和细微解释差异，文档相关性高度依赖上下文

Method: 提出上下文相关性定义，开发TS-SetRank算法，这是一种基于采样的不确定性感知重排序方法，同时考虑文档批次组合和排序位置

Result: 在BRIGHT数据集上nDCG@10提升15-25%，在BEIR数据集上提升6-21%，显著优于现有检索和重排序基线

Conclusion: 建模相关性为上下文依赖对于改进重排序性能至关重要，文档批次组合与排序位置共同影响重排序效果

Abstract: Reranking algorithms have made progress in improving document retrieval
quality by efficiently aggregating relevance judgments generated by large
language models (LLMs). However, identifying relevant documents for queries
that require in-depth reasoning remains a major challenge. Reasoning-intensive
queries often exhibit multifaceted information needs and nuanced
interpretations, rendering document relevance inherently context dependent. To
address this, we propose contextual relevance, which we define as the
probability that a document is relevant to a given query, marginalized over the
distribution of different reranking contexts it may appear in (i.e., the set of
candidate documents it is ranked alongside and the order in which the documents
are presented to a reranking model). While prior works have studied methods to
mitigate the positional bias LLMs exhibit by accounting for the ordering of
documents, we empirically find that the compositions of these batches also
plays an important role in reranking performance. To efficiently estimate
contextual relevance, we propose TS-SetRank, a sampling-based,
uncertainty-aware reranking algorithm. Empirically, TS-SetRank improves nDCG@10
over retrieval and reranking baselines by 15-25% on BRIGHT and 6-21% on BEIR,
highlighting the importance of modeling relevance as context-dependent.

</details>


### [38] [A semantic-based deep learning approach for mathematical expression retrieval](https://arxiv.org/abs/2511.01364)
*Pavan Kumar Perepu*

Main category: cs.IR

TL;DR: 提出了一种基于深度循环神经网络(DRNN)的数学表达式检索方法，通过提取语义特征进行匹配，将数学表达式按嵌套深度分为简单、中等和复杂三类。


<details>
  <summary>Details</summary>
Motivation: 传统的基于字符串匹配和向量空间模型的数学表达式检索方法主要依赖句法相似性，缺乏语义理解。需要利用深度学习方法来提取语义特征以提高检索效果。

Method: 使用深度循环神经网络(DRNN)训练数学表达式复杂度分类任务，提取最后一层全连接层之前的输出作为语义特征，基于欧几里得距离进行特征匹配和检索。

Result: 在包含829个数学表达式的数据库上验证了该方法，能够根据用户定义的参数k返回最相似的k个匹配结果。

Conclusion: 基于深度学习的语义特征提取方法能够有效解决数学表达式的检索问题，克服了传统方法在语义理解方面的局限性。

Abstract: Mathematical expressions (MEs) have complex two-dimensional structures in
which symbols can be present at any nested depth like superscripts, subscripts,
above, below etc. As MEs are represented using LaTeX format, several text
retrieval methods based on string matching, vector space models etc., have also
been applied for ME retrieval problem in the literature. As these methods are
based on syntactic similarity, recently deep learning approaches based on
embedding have been used for semantic similarity. In our present work, we have
focused on the retrieval of mathematical expressions using deep learning
approaches. In our approach, semantic features are extracted from the MEs using
a deep recurrent neural network (DRNN) and these features have been used for
matching and retrieval. We have trained the network for a classification task
which determines the complexity of an ME. ME complexity has been quantified in
terms of its nested depth. Based on the nested depth, we have considered three
complexity classes of MEs: Simple, Medium and Complex. After training the
network, outputs just before the the final fully connected layer are extracted
for all the MEs. These outputs form the semantic features of MEs and are stored
in a database. For a given ME query, its semantic features are computed using
the trained DRNN and matched against the semantic feature database. Matching is
performed based on the standard euclidean distance and top 'k' nearest matches
are retrieved, where 'k' is a user-defined parameter. Our approach has been
illustrated on a database of 829 MEs.

</details>


### [39] [A Soft-partitioned Semi-supervised Collaborative Transfer Learning Approach for Multi-Domain Recommendation](https://arxiv.org/abs/2511.01404)
*Xiaoyu Liu,Yiqing Wu,Ruidong Han,Fuzhen Zhuang,Xiang Li,Wei Lin*

Main category: cs.IR

TL;DR: 提出了SSCTL方法解决多域推荐中的数据不平衡问题，通过动态参数和伪标签技术改善非主导域的性能，在线测试显示GMV提升0.54%-2.90%，CTR提升0.22%-1.69%。


<details>
  <summary>Details</summary>
Motivation: 解决多域推荐中数据不平衡导致的两个关键问题：主导域数据压倒模型性能，忽视非主导域；非主导域数据稀疏导致特定参数过拟合。

Method: 提出软分区半监督协同迁移学习(SSCTL)，使用动态参数解决压倒性问题，利用主导域实例的带权伪标签增强非主导域数据以防止过拟合。

Result: 在线测试显示在各个域都取得显著改进，GMV提升0.54%-2.90%，CTR提升0.22%-1.69%。

Conclusion: SSCTL方法有效解决了多域推荐中的数据不平衡问题，通过动态参数和伪标签技术显著提升了非主导域的性能表现。

Abstract: In industrial practice, Multi-domain Recommendation (MDR) plays a crucial
role. Shared-specific architectures are widely used in industrial solutions to
capture shared and unique attributes via shared and specific parameters.
However, with imbalanced data across different domains, these models face two
key issues: (1) Overwhelming: Dominant domain data skews model performance,
neglecting non-dominant domains. (2) Overfitting: Sparse data in non-dominant
domains leads to overfitting in specific parameters. To tackle these
challenges, we propose Soft-partitioned Semi-supervised Collaborative Transfer
Learning (SSCTL) for multi-domain recommendation. SSCTL generates dynamic
parameters to address the overwhelming issue, thus shifting focus towards
samples from non-dominant domains. To combat overfitting, it leverages
pseudo-labels with weights from dominant domain instances to enhance
non-dominant domain data. We conduct comprehensive experiments, both online and
offline, to validate the efficacy of our proposed method. Online tests yielded
significant improvements across various domains, with increases in GMV ranging
from 0.54% to 2.90% and enhancements in CTR ranging from 0.22% to 1.69%.

</details>


### [40] [LiCoMemory: Lightweight and Cognitive Agentic Memory for Efficient Long-Term Reasoning](https://arxiv.org/abs/2511.01448)
*Zhengjun Huang,Zhoujin Tian,Qintian Guo,Fangyuan Zhang,Yingli Zhou,Di Jiang,Xiaofang Zhou*

Main category: cs.IR

TL;DR: LiCoMemory是一个端到端的智能体记忆框架，通过引入轻量级分层图CogniGraph来解决LLM智能体上下文窗口有限和缺乏持久记忆的问题，在长期对话基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型智能体具有出色的对话和推理能力，但受到有限上下文窗口和缺乏持久记忆的限制。现有的外部记忆架构通常采用图表示，但大多采用扁平、纠缠的结构，导致表示冗余、检索无结构以及效率和准确性下降。

Method: 提出LiCoMemory框架，引入CogniGraph轻量级分层图，使用实体和关系作为语义索引层，并采用时间和层次感知搜索与集成重排序，实现自适应和连贯的知识检索。

Result: 在长期对话基准测试LoCoMo和LongMemEval上，LiCoMemory在时间推理、多会话一致性和检索效率方面优于现有基线，并显著降低了更新延迟。

Conclusion: LiCoMemory通过分层图结构和智能检索机制，有效解决了LLM智能体的记忆限制问题，在多个评估指标上取得了优越性能。

Abstract: Large Language Model (LLM) agents exhibit remarkable conversational and
reasoning capabilities but remain constrained by limited context windows and
the lack of persistent memory. Recent efforts address these limitations via
external memory architectures, often employing graph-based representations, yet
most adopt flat, entangled structures that intertwine semantics with topology,
leading to redundant representations, unstructured retrieval, and degraded
efficiency and accuracy. To resolve these issues, we propose LiCoMemory, an
end-to-end agentic memory framework for real-time updating and retrieval, which
introduces CogniGraph, a lightweight hierarchical graph that utilizes entities
and relations as semantic indexing layers, and employs temporal and
hierarchy-aware search with integrated reranking for adaptive and coherent
knowledge retrieval. Experiments on long-term dialogue benchmarks, LoCoMo and
LongMemEval, show that LiCoMemory not only outperforms established baselines in
temporal reasoning, multi-session consistency, and retrieval efficiency, but
also notably reduces update latency. Our official code and data are available
at https://github.com/EverM0re/LiCoMemory.

</details>


### [41] [CAT-ID$^2$: Category-Tree Integrated Document Identifier Learning for Generative Retrieval In E-commerce](https://arxiv.org/abs/2511.01461)
*Xiaoyu Liu,Fuwei Zhang,Yiqing Wu,Xinyu Jia,Zenghua Xia,Fuzhen Zhuang,Zhao Zhang,Fei Jiang,Wei Lin*

Main category: cs.IR

TL;DR: 提出CAT-ID²方法，通过整合类别信息改进生成式检索中的文档ID构建，使相似文档的ID更相似，同时保持不同文档ID的独特性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式检索方法忽略了电商场景中常见的类别信息，而好的文档ID应该具有相似文档ID相似、不同文档ID独特的特性。

Method: CAT-ID²包含三个关键模块：分层类别约束损失、聚类规模约束损失和分散损失，通过分层整合类别信息来改进语义ID的构建。

Result: 离线和在线实验验证了方法的有效性，在线A/B测试显示模糊意图查询的千用户平均订单增加0.33%，长尾查询增加0.24%。

Conclusion: CAT-ID²通过有效整合类别信息，显著提升了生成式检索在电商场景中的性能表现。

Abstract: Generative retrieval (GR) has gained significant attention as an effective
paradigm that integrates the capabilities of large language models (LLMs). It
generally consists of two stages: constructing discrete semantic identifiers
(IDs) for documents and retrieving documents by autoregressively generating ID
tokens.The core challenge in GR is how to construct document IDs (DocIDS) with
strong representational power. Good IDs should exhibit two key properties:
similar documents should have more similar IDs, and each document should
maintain a distinct and unique ID.However, most existing methods ignore native
category information, which is common and critical in E-commerce. Therefore, we
propose a novel ID learning method, CAtegory-Tree Integrated Document
IDentifier (CAT-ID$^2$), incorporating prior category information into the
semantic IDs.CAT-ID$^2$ includes three key modules: a Hierarchical Class
Constraint Loss to integrate category information layer by layer during
quantization, a Cluster Scale Constraint Loss for uniform ID token
distribution, and a Dispersion Loss to improve the distinction of reconstructed
documents. These components enable CAT-ID$^2$ to generate IDs that make similar
documents more alike while preserving the uniqueness of different documents'
representations.Extensive offline and online experiments confirm the
effectiveness of our method, with online A/B tests showing a 0.33% increase in
average orders per thousand users for ambiguous intent queries and 0.24% for
long-tail queries.

</details>


### [42] [Trove: A Flexible Toolkit for Dense Retrieval](https://arxiv.org/abs/2511.01857)
*Reza Esfandiarpoor,Max Zuo,Stephen H. Bach*

Main category: cs.IR

TL;DR: Trove是一个易于使用的开源检索工具包，简化研究实验而不牺牲灵活性或速度，提供高效数据管理功能，支持动态加载和处理检索数据集，具有高度可定制性。


<details>
  <summary>Details</summary>
Motivation: 为了解决检索研究中数据管理复杂、实验配置不灵活、计算资源消耗大的问题，开发一个既能简化实验流程又能保持高度灵活性的工具包。

Method: 引入高效数据管理功能，支持动态加载、过滤、选择、转换和组合数据集；提供高度可定制的组件系统；设计低代码统一评估和硬负例挖掘管道；支持多节点执行。

Result: 数据管理功能将内存消耗减少2.6倍；推理管道无额外开销，推理时间随节点数量线性减少；简化了检索实验流程，支持任意定制。

Conclusion: Trove通过简化检索实验流程和提供高度可定制性，有效促进了探索性研究，在保持性能的同时显著提升了实验效率。

Abstract: We introduce Trove, an easy-to-use open-source retrieval toolkit that
simplifies research experiments without sacrificing flexibility or speed. For
the first time, we introduce efficient data management features that load and
process (filter, select, transform, and combine) retrieval datasets on the fly,
with just a few lines of code. This gives users the flexibility to easily
experiment with different dataset configurations without the need to compute
and store multiple copies of large datasets. Trove is highly customizable: in
addition to many built-in options, it allows users to freely modify existing
components or replace them entirely with user-defined objects. It also provides
a low-code and unified pipeline for evaluation and hard negative mining, which
supports multi-node execution without any code changes. Trove's data management
features reduce memory consumption by a factor of 2.6. Moreover, Trove's
easy-to-use inference pipeline incurs no overhead, and inference times decrease
linearly with the number of available nodes. Most importantly, we demonstrate
how Trove simplifies retrieval experiments and allows for arbitrary
customizations, thus facilitating exploratory research.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [43] [Sorting by Strip Swaps is NP-Hard](https://arxiv.org/abs/2511.00015)
*Swapnoneel Roy,Asai Asaithambi,Debajyoti Mukhopadhyay*

Main category: cs.DS

TL;DR: 本文证明了排序带条交换问题（SbSS）是NP难的，通过将块排序问题多项式归约到该问题。


<details>
  <summary>Details</summary>
Motivation: 研究排序带条交换问题的计算复杂性，确定其是否属于NP难问题。

Method: 使用局部小工具（笼子）将每个递减邻接对替换为受保护的三元组，并通过铰链小工具耦合相邻笼子，建立SbSS调度与完美块调度之间的等价关系。

Result: 成功证明了排序带条交换问题是NP难的。

Conclusion: 排序带条交换问题具有NP难的计算复杂性。

Abstract: We show that \emph{Sorting by Strip Swaps} (SbSS) is NP-hard by a polynomial
reduction of \emph{Block Sorting}. The key idea is a local gadget, a
\emph{cage}, that replaces every decreasing adjacency $(a_i,a_{i+1})$ by a
guarded triple $a_i,m_i,a_{i+1}$ enclosed by guards $L_i,U_i$, so the only
decreasing adjacencies are the two inside the cage. Small \emph{hinge} gadgets
couple adjacent cages that share an element and enforce that a strip swap that
removes exactly two adjacencies corresponds bijectively to a block move that
removes exactly one decreasing adjacency in the source permutation. This yields
a clean equivalence between exact SbSS schedules and perfect block schedules,
establishing NP-hardness.

</details>


### [44] [Scheduling Problems with Constrained Rejections](https://arxiv.org/abs/2511.00184)
*Sami Davies,Venkatesan Guruswami,Xuandi Ren*

Main category: cs.DS

TL;DR: 本文研究了带约束拒绝的无关机调度和Santa Claus问题的双标准版本，在允许一定比例作业被拒绝的情况下，改进了makespan与调度作业比例之间的权衡关系，并首次给出了Santa Claus问题的硬度结果。


<details>
  <summary>Details</summary>
Motivation: 研究在允许部分作业被拒绝的情况下，makespan最小化和Santa Claus问题中目标值与调度比例之间的权衡关系，探索原始优化目标难度的鲁棒性。

Method: 对于无关机调度问题，提出改进算法在makespan为3T/2时调度比例可达0.6533；对于Santa Claus问题，通过引入双标准集合包装问题并证明其硬度结果。

Result: 改进了无关机调度的调度比例界限，从1-1/e+10^{-180}提升到0.6533；首次证明了Santa Claus问题存在常数δ,ε>0使得找到(1-δ)比例代理获得至少(1-ε)T值的分配是NP难的。

Conclusion: 双标准调度问题提供了理解原始优化目标难度鲁棒性的有趣视角，值得进一步研究权衡关系。

Abstract: We study bicriteria versions of Makespan Minimization on Unrelated Machines
and Santa Claus by allowing a constrained number of rejections. Given an
instance of Makespan Minimization on Unrelated Machines where the optimal
makespan for scheduling $n$ jobs on $m$ unrelated machines is $T$, (Feige and
Vondr\'ak, 2006) gave an algorithm that schedules a $(1-1/e+10^{-180})$
fraction of jobs in time $T$. We show the ratio can be improved to
$0.6533>1-1/e+0.02$ if we allow makespan $3T/2$. To the best our knowledge,
this is the first result examining the tradeoff between makespan and the
fraction of scheduled jobs when the makespan is not $T$ or $2T$.
  For the Santa Claus problem (the Max-Min version of Makespan Minimization),
the analogous bicriteria objective was studied by (Golovin, 2005), who gave an
algorithm providing an allocation so a $(1-1/k)$ fraction of agents receive
value at least $T/k$, for any $k \in \mathbb{Z}^+$ and $T$ being the optimal
minimum value every agent can receive. We provide the first hardness result by
showing there are constants $\delta,\varepsilon>0$ such that it is NP-hard to
find an allocation where a $(1-\delta)$ fraction of agents receive value at
least $(1-\varepsilon) T$. To prove this hardness result, we introduce a
bicriteria version of Set Packing, which may be of independent interest, and
prove some algorithmic and hardness results for it. Overall, we believe these
bicriteria scheduling problems warrant further study as they provide an
interesting lens to understand how robust the difficulty of the original
optimization goal might be.

</details>


### [45] [Uncrossed Multiflows and Applications to Disjoint Paths](https://arxiv.org/abs/2511.00254)
*Chandra Chekuri,Guyslain Naves,Joseph Poremba,F. Bruce Shepherd*

Main category: cs.DS

TL;DR: 该论文研究平面图中无交叉多流问题，分析了拥塞模型和最大化模型下的计算复杂度、近似性以及整数化间隙。


<details>
  <summary>Details</summary>
Motivation: 无交叉多流在先前路由算法中发挥重要作用，特别是在全平面实例的最大不相交路径近似算法中。本文研究在一般平面实例中寻找无交叉多流作为独立算法问题。

Method: 考虑两种模型：拥塞模型（必须路由所有需求）和最大化模型（尽可能多地打包流）。分析NP难度、多项式时间可解性、近似性以及整数化间隙。

Result: 拥塞模型中判断是否存在无交叉多流是NP难的，但需求跨越有限面数时可多项式时间求解。最大化模型存在强不可近似性。无交叉多流可常数比例舍入为整数多流。

Conclusion: 无交叉多流在平面图中具有重要的算法性质，拥塞模型可舍入为边拥塞2的整数流，最大化模型具有常数整数化间隙。

Abstract: A multiflow in a planar graph is uncrossed if the curves identified by its
support paths do not cross in the plane. Such flows have played a role in
previous routing algorithms, including Schrijver's Homotopy Method and
unsplittable flows in directed planar single-source instances. Recently
uncrossed flows have played a key role in approximation algorithms for maximum
disjoint paths in fully-planar instances, where the combined supply plus demand
graph is planar. In the fully-planar case, any fractional multiflow can be
converted into one that is uncrossed, which is then exploited to find a good
rounding of the fractional solution. We investigate finding an uncrossed
multiflow as a standalone algorithmic problem in general planar instances (not
necessarily fully-planar). We consider both a congestion model where the given
demands must all be routed, and a maximization model where the goal is to pack
as much flow in the supply graph as possible (not necessarily equitably).
  For the congestion model, we show that determining if an instance has an
uncrossed (fractional) multiflow is NP-hard, but the problem of finding an
integral uncrossed flow is polytime solvable if the demands span a bounded
number of faces. For the maximization model, we present a strong (almost
polynomial) inapproximability result. Regarding integrality gaps, for
maximization we show that an uncrossed multiflow in a planar instance can
always be rounded to an integral multiflow with a constant fraction of the
original value. This holds in both the edge-capacitated and node-capacitated
settings, and generalizes earlier bounds for fully-planar instances. In the
congestion model, given an uncrossed fractional multiflow, we give a rounding
procedure that produces an integral multiflow with edge congestion 2, which can
be made unsplittable with an additional additive error of the maximum demand.

</details>


### [46] [An Approximation Algorithm for Monotone Submodular Cost Allocation](https://arxiv.org/abs/2511.00470)
*Ryuhei Mizutani*

Main category: cs.DS

TL;DR: 本文研究了最小子模成本分配问题，针对单调子模函数情况，提出了LP松弛方法，证明了积分间隙为k/2，并给出了相应的近似算法。


<details>
  <summary>Details</summary>
Motivation: 解决最小子模成本分配问题，特别是在单调子模函数情况下的近似算法设计，填补了该问题理论分析的空白。

Method: 使用自然LP松弛方法，将其等价于Chekuri和Ene提出的凸规划松弛，分析积分间隙并设计近似算法。

Result: 证明了LP松弛的积分间隙最多为k/2，从而得到了k/2-近似算法；同时证明了当k固定时，积分间隙至少为k/2-ε。

Conclusion: 对于单调子模成本分配问题，LP松弛方法能够提供紧致的k/2近似保证，为该问题提供了有效的解决方案。

Abstract: In this paper, we consider the minimum submodular cost allocation (MSCA)
problem. The input of MSCA is $k$ non-negative submodular functions
$f_1,\ldots,f_k$ on the ground set $N$ given by evaluation oracles, and the
goal is to partition $N$ into $k$ (possibly empty) sets $X_1,\ldots,X_k$ so
that $\sum_{i=1}^k f_i(X_i)$ is minimized. In this paper, we focus on the case
when $f_1,\ldots,f_k$ are monotone (denoted by Mono-MSCA). We provide a natural
LP-relaxation for Mono-MSCA, which is equivalent to the convex program
relaxation introduced by Chekuri and Ene. We show that the integrality gap of
the LP-relaxation is at most $k/2$, which yields a $k/2$-approximation
algorithm for Mono-MSCA. We also show that the integrality gap of the
LP-relaxation is at least $k/2-\epsilon$ for any constant $\epsilon>0$ when $k$
is fixed.

</details>


### [47] [Fast Stochastic Greedy Algorithm for $k$-Submodular Cover Problem](https://arxiv.org/abs/2511.00869)
*Hue T. Nguyen,Tan D. Tran,Nguyen Long Giang,Canh V. Pham*

Main category: cs.DS

TL;DR: 提出了Fast Stochastic Greedy算法解决k-子模覆盖问题，在保持强双标准近似的同时显著降低查询复杂度


<details>
  <summary>Details</summary>
Motivation: 现有k-子模覆盖算法存在近似保证弱或查询复杂度高的问题，影响在影响力最大化、资源分配等AI应用中的实用性

Method: 使用快速随机贪心算法，通过减少函数评估次数来降低查询复杂度

Result: 算法在保持强双标准近似的同时，显著降低了查询复杂度，使其适用于大规模实际AI应用

Conclusion: 提出的算法解决了现有方法的效率瓶颈，为大规模k-子模覆盖问题提供了高效实用的解决方案

Abstract: We study the $k$-Submodular Cover ($kSC$) problem, a natural generalization
of the classical Submodular Cover problem that arises in artificial
intelligence and combinatorial optimization tasks such as influence
maximization, resource allocation, and sensor placement. Existing algorithms
for $\kSC$ often provide weak approximation guarantees or incur prohibitively
high query complexity. To overcome these limitations, we propose a \textit{Fast
Stochastic Greedy} algorithm that achieves strong bicriteria approximation
while substantially lowering query complexity compared to state-of-the-art
methods. Our approach dramatically reduces the number of function evaluations,
making it highly scalable and practical for large-scale real-world AI
applications where efficiency is essential.

</details>


### [48] [Dynamic Diameter in High-Dimensions against Adaptive Adversary and Beyond](https://arxiv.org/abs/2511.01065)
*Kiarash Banihashem,Jeff Giliberti,Samira Goudarzi,MohammadTaghi Hajiaghayi,Peyman Jabbarzade,Morteza Monemizadeh*

Main category: cs.DS

TL;DR: 本文研究了高维动态点集的直径和k-center聚类维护问题，提出了针对自适应对手的鲁棒算法，包括2-近似直径维护和(4+ε)-近似k-center聚类算法。


<details>
  <summary>Details</summary>
Motivation: 现有动态算法大多假设数据更新是随机的，但在实际应用中对手可能根据算法历史输出进行适应性攻击。需要设计能够抵抗自适应对手的高维动态算法。

Method: 通过识别需要较少更新的鲁棒数据集代表，结合仔细的去摊销化技术，实现高效的动态维护。对于k-center问题，改进了现有算法的更新时间复杂度。

Result: 提出了首个同时实现2-近似保证且能抵抗自适应对手的高维动态直径算法，最坏情况更新时间为poly(d, log n)。k-center算法将摊销更新时间从k⁶d改进到k².⁵d。

Conclusion: 证明了在高维动态环境下设计抵抗自适应对手的高效算法是可行的，为动态几何问题提供了新的鲁棒解决方案。

Abstract: In this paper, we study the fundamental problems of maintaining the diameter
and a $k$-center clustering of a dynamic point set $P \subset \mathbb{R}^d$,
where points may be inserted or deleted over time and the ambient dimension $d$
is not constant and may be high. Our focus is on designing algorithms that
remain effective even in the presence of an adaptive adversary -- an adversary
that, at any time $t$, knows the entire history of the algorithm's outputs as
well as all the random bits used by the algorithm up to that point. We present
a fully dynamic algorithm that maintains a $2$-approximate diameter with a
worst-case update time of $\text{poly}(d, \log n)$, where $n$ is the length of
the stream. Our result is achieved by identifying a robust representative of
the dataset that requires infrequent updates, combined with a careful
deamortization. To the best of our knowledge, this is the first efficient
fully-dynamic algorithm for diameter in high dimensions that simultaneously
achieves a 2-approximation guarantee and robustness against an adaptive
adversary. We also give an improved dynamic $(4+\epsilon)$-approximation
algorithm for the $k$-center problem, also resilient to an adaptive adversary.
Our clustering algorithm achieves an amortized update time of $k^{2.5} d \cdot
\text{poly}(\epsilon^{-1}, \log n)$, improving upon the amortized update time
of $k^6 d \cdot \text{poly}(\epsilon^{-1}, \log n)$ by Biabani et al.
[NeurIPS'24].

</details>


### [49] [Fault-Tolerant Approximate Distance Oracles with a Source Set](https://arxiv.org/abs/2511.01239)
*Dipan Dey,Telikepalli Kavitha*

Main category: cs.DS

TL;DR: 构建容错的源近似距离预言机，支持在单边故障情况下快速查询源集S到任意顶点v的近似距离。


<details>
  <summary>Details</summary>
Motivation: 解决在边故障情况下，快速估计源集S中顶点到其他顶点距离的问题，这在网络路由、故障恢复等场景中很重要。

Method: 基于Bilò等人的容错ST距离预言机，构建两种不同大小的源近似距离预言机：一种大小O(|S|n + n^{3/2})，另一种O(|S|n + n^{4/3})。

Result: 第一个预言机具有5倍乘法拉伸，第二个具有13倍乘法拉伸，两者都支持O(1)查询时间。

Conclusion: 成功构建了高效的容错源近似距离预言机，在存储空间和查询精度之间提供了权衡选择。

Abstract: Our input is an undirected weighted graph $G = (V,E)$ on $n$ vertices along
with a source set $S\subseteq V$. The problem is to preprocess $G$ and build a
compact data structure such that upon query $Qu(s,v,f)$ where $(s,v) \in
S\times V$ and $f$ is any faulty edge, we can quickly find a good estimate
(i.e., within a small multiplicative stretch) of the $s$-$v$ distance in $G-f$.
We use a fault-tolerant $ST$-distance oracle from the work of Bil{\`{o}} et al.
(STACS 2018) to construct an $S\times V$ approximate distance oracle or {\em
sourcewise} approximate distance oracle of size $\widetilde{O}(|S|n + n^{3/2})$
with multiplicative stretch at most 5. We construct another fault-tolerant
sourcewise approximate distance oracle of size $\widetilde{O}(|S|n + n^{4/3})$
with multiplicative stretch at most 13. Both the oracles have $O(1)$ query
answering time.

</details>


### [50] [Subtree Mode and Applications](https://arxiv.org/abs/2511.01376)
*Jialong Zhou,Ben Bals,Matei Tinca,Ai Guan,Panagiotis Charalampopoulos,Grigorios Loukides,Solon P. Pissis*

Main category: cs.DS

TL;DR: 本文提出了子树众数问题，在叶着色树中计算每个节点子树中出现最频繁的颜色，并给出了时间复杂度最优的O(N)算法。


<details>
  <summary>Details</summary>
Motivation: 子树众数问题在文本分析和生物学等具有层次结构数据的领域有重要应用，需要高效计算树结构中每个节点的众数颜色。

Method: 开发了时间最优算法，在O(N)时间内计算输入N节点树中每个节点的子树众数，并可扩展到节点着色树和计算前k个最频繁颜色。

Result: 在包含73亿个节点的真实数据集上，算法比基线方法快至少一个数量级，且空间效率更高。证明了在有向无环图上类似快速解法的可能性很低。

Conclusion: 提出的子树众数算法高效实用，在模式挖掘和序列到数据库搜索应用中表现出色，为层次数据结构中的众数计算提供了最优解决方案。

Abstract: The mode of a collection of values (i.e., the most frequent value in the
collection) is a key summary statistic. Finding the mode in a given range of an
array of values is thus of great importance, and constructing a data structure
to solve this problem is in fact the well-known Range Mode problem. In this
work, we introduce the Subtree Mode (SM) problem, the analogous problem in a
leaf-colored tree, where the task is to compute the most frequent color in the
leaves of the subtree of a given node. SM is motivated by several applications
in domains such as text analytics and biology, where the data are hierarchical
and can thus be represented as a (leaf-colored) tree. Our central contribution
is a time-optimal algorithm for SM that computes the answer for every node of
an input $N$-node tree in $O(N)$ time. We further show how our solution can be
adapted for node-colored trees, or for computing the $k$ most frequent colors,
in the optimal $O(N)$ time, for any given $k=O(1)$. Moreover, we prove that a
similarly fast solution for when the input is a sink-colored directed acyclic
graph instead of a leaf-colored tree is highly unlikely. Our experiments on
real datasets with trees of up to 7.3 billion nodes demonstrate that our
algorithm is faster than baselines by at least one order of magnitude and much
more space efficient. Last, we present case studies showing the effectiveness
of our approach in pattern mining and sequence-to-database search applications.

</details>


### [51] [Robust Streaming Against Low-Memory Adversaries](https://arxiv.org/abs/2511.01769)
*Omri Ben-Eliezer,Krzysztof Onak,Sandeep Silwal*

Main category: cs.DS

TL;DR: 该论文研究了针对低内存对抗者的鲁棒流算法，提出了内存无记忆和低内存对抗者模型，并设计了针对这类对抗者的高效算法，解决了传统鲁棒流算法在对抗者完全自适应时存在的指数级性能差距问题。


<details>
  <summary>Details</summary>
Motivation: 传统鲁棒流算法在面对完全自适应的对抗者时性能较差，存在指数级差距。作者认为这可能是因为对抗者模型过于强大，能够记住整个交互历史。因此研究当对抗者本身也是低内存实体时，能否缩小这一差距。

Method: 设计了内存无记忆和低内存对抗者模型，其中内存无记忆对抗者只能看到算法的最新输出，低内存对抗者额外维护一个小缓冲区。提出了类似计算路径框架的新方法，为广泛类别的顺序不变问题设计高效算法。

Result: 证明了该对抗模型足够强大，能够产生在F2估计中具有高翻转数和密度的流，排除了大多数已知的鲁棒化技术。成功设计了针对内存无记忆和低内存对抗者的高效算法。

Conclusion: 通过限制对抗者的内存能力，能够显著改善鲁棒流算法的性能，为缩小完全自适应对抗者与无意识对抗者之间的性能差距提供了新的研究方向和方法。

Abstract: Robust streaming, the study of streaming algorithms that provably work when
the stream is generated by an adaptive adversary, has seen tremendous progress
in recent years. However, fundamental barriers remain: the best known algorithm
for turnstile $F_p$-estimation in the robust streaming setting is exponentially
worse than in the oblivious setting, and closing this gap seems difficult.
Arguably, one possible cause of this barrier is the adversarial model, which
may be too strong: unlike the space-bounded streaming algorithm, the adversary
can memorize the entire history of the interaction with the algorithm. Can we
then close the exponential gap if we insist that the adversary itself is an
adaptive but low-memory entity, roughly as powerful as (or even weaker than)
the algorithm?
  In this work we present the first set of models and results aimed towards
this question. We design efficient robust streaming algorithms against
adversaries that are fully adaptive but have no long-term memory ("memoryless")
or very little memory of the history of interaction. Roughly speaking, a
memoryless adversary only sees, at any given round, the last output of the
algorithm (and does not even know the current time) and can generate an
unlimited number of independent coin tosses. A low-memory adversary is similar,
but maintains an additional small buffer. While these adversaries may seem
quite limited at first glance, we show that this adversarial model is strong
enough to produce streams that have high flip number and density in the context
of $F_2$-estimation, which rules out most of known robustification techniques.
We then design a new simple approach, similar to the computation paths
framework, to obtain efficient algorithms against memoryless and low-memory
adversaries for a wide class of order-invariant problems.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [52] [LongCat-Flash-Omni Technical Report](https://arxiv.org/abs/2511.00279)
*Meituan LongCat Team,Bairui Wang,Bayan,Bin Xiao,Bo Zhang,Bolin Rong,Borun Chen,Chang Wan,Chao Zhang,Chen Huang,Chen Chen,Chen Chen,Chengxu Yang,Chengzuo Yang,Cong Han,Dandan Peng,Delian Ruan,Detai Xin,Disong Wang,Dongchao Yang,Fanfan Liu,Fengjiao Chen,Fengyu Yang,Gan Dong,Gang Huang,Gang Xu,Guanglu Wan,Guoqiang Tan,Guoqiao Yu,Haibo Qiu,Hao Lu,Hongbo Liu,Hongyu Xiang,Jiaheng Wu,Jian Yang,Jiaxing Liu,Jing Huang,Jingang Wang,Jinrui Ding,Juchao Jiang,Jun Kuang,Jun Wang,Junhui Mei,Ke Ding,Kefeng Zhang,Lei Chen,Liang Shi,Limeng Qiao,Liming Zheng,Lin Ma,Liuyang Guo,Liya Ma,Luying Sun,Man Gao,Mengshen Zhu,Miao Cao,Minliang Lin,Nuo Xu,Peng Shi,Qi Zhang,Qian Fang,Qian Wang,Qian Yang,Quanxiu Wang,Rongxiang Weng,Rongxin Guo,Ruoxuan Liang,Senbin Yang,Shanbo Xu,Shanglin Lei,Shengze Ye,Shimin Chen,Shuaiqi Chen,Shujie Hu,Shuo Li,Siqi Yang,Siyu Xu,Siyu Ren,Song Li,Songxiang Liu,Tianhao Bai,Tianye Dai,Wei Hong,Wei Wang,Weixiao Zhao,Wengang Cao,Wenlong Zhu,Wenlong He,Xi Su,Xi Nan,Xiaohan Zhao,Xiaohao Wang,Xiaoyu Zhao,Xiaoyu Wang,Xiaoyu Li,Xin Pan,Xin Chen,Xiusong Sun,Xu Xiang,Xudong Xing,Xuezhi Cao,Xunliang Cai,Yang Yang,Yanli Tan,Yao Yao,Yerui Sun,Yi Chen,Yifan Lu,Yin Gong,Yining Zhang,Yitian Chen,Yiyang Gan,Yuchen Tang,Yuchen Xie,Yueqian Wang,Yuewen Zheng,Yufei Zhang,Yufeng Zhong,Yulei Qian,Yuqi Peng,Yuwei Jiang,Zeyang Hu,Zheng Zhang,Zhengkun Tian,Zhiqing Hong,Zhixiong Zeng,Zhuqi Mi,Ziran Li,Ziwen Wang,Ziyi Zhao,Ziyuan Zhuang,Zizhe Zhao*

Main category: cs.MM

TL;DR: LongCat-Flash-Omni是一个5600亿参数的开源全模态模型，采用渐进式训练策略和高效的多模态感知模块，在保持强大单模态能力的同时实现低延迟实时音视频交互。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够处理多种模态（文本、图像、视频、音频）并实现实时音视频交互的大规模开源模型，解决大规模多模态训练中的数据和方法异构性问题。

Method: 采用课程启发的渐进式训练策略，从简单到复杂的模态序列建模任务过渡；基于Shortcut连接的MoE架构，集成高效多模态感知和语音重构模块；开发模态解耦并行方案处理训练数据异构性。

Result: 在5600亿参数规模下（激活270亿参数）实现低延迟实时音视频交互；在开源模型中在全模态基准测试上达到最先进性能；在文本、图像、视频理解和音频理解与生成等任务上表现优异。

Conclusion: LongCat-Flash-Omni展示了大规模多模态模型的有效训练方法，通过创新的架构和训练策略实现了全面的多模态能力，为社区提供了强大的开源基础模型。

Abstract: We introduce LongCat-Flash-Omni, a state-of-the-art open-source omni-modal
model with 560 billion parameters, excelling at real-time audio-visual
interaction. By adopting a curriculum-inspired progressive training strategy
that transitions from simpler to increasingly complex modality sequence
modeling tasks, LongCat-Flash-Omni attains comprehensive multimodal
capabilities while maintaining strong unimodal capability. Building upon
LongCat-Flash, which adopts a high-performance Shortcut-connected
Mixture-of-Experts (MoE) architecture with zero-computation experts,
LongCat-Flash-Omni integrates efficient multimodal perception and speech
reconstruction modules. Despite its immense size of 560B parameters (with 27B
activated), LongCat-Flash-Omni achieves low-latency real-time audio-visual
interaction. For training infrastructure, we developed a modality-decoupled
parallelism scheme specifically designed to manage the data and model
heterogeneity inherent in large-scale multimodal training. This innovative
approach demonstrates exceptional efficiency by sustaining over 90% of the
throughput achieved by text-only training. Extensive evaluations show that
LongCat-Flash-Omni achieves state-of-the-art performance on omni-modal
benchmarks among open-source models. Furthermore, it delivers highly
competitive results across a wide range of modality-specific tasks, including
text, image, and video understanding, as well as audio understanding and
generation. We provide a comprehensive overview of the model architecture
design, training procedures, and data strategies, and open-source the model to
foster future research and development in the community.

</details>


### [53] [Predicting Encoding Energy from Low-Pass Anchors for Green Video Streaming](https://arxiv.org/abs/2511.00707)
*Zoha Azimi,Reza Farahani,Vignesh V Menon,Christian Timmerer*

Main category: cs.MM

TL;DR: 提出一种轻量级能耗预测方法，通过低分辨率参考编码预测高分辨率视频编码的能耗，实现编码能耗节省51.22%和解码能耗节省53.54%，同时保持感知质量在可接受范围内。


<details>
  <summary>Details</summary>
Motivation: 视频流媒体占互联网流量主导地位，高分辨率内容在异构设备上的分发带来了能源效率和碳排放问题，需要在能源消耗和用户体验质量(QoE)之间进行权衡。

Method: 使用低分辨率参考编码(锚点)预测高分辨率视频编码的能耗，自动选择编码参数(如分辨率和量化参数)，在保持VMAF感知质量在可接受范围内的同时实现能源节省。

Result: 在Inter4K数据集的100个视频序列上测试，平均VMAF分数仅降低1.68(低于JND阈值)，编码能耗节省51.22%，解码能耗节省53.54%。

Conclusion: 该方法提供了一种可行的能源-QoE权衡方案，通过轻量级能耗预测实现了显著的能源节省，同时维持了用户感知质量。

Abstract: Video streaming now represents the dominant share of Internet traffic, as
ever-higher-resolution content is distributed across a growing range of
heterogeneous devices to sustain user Quality of Experience (QoE). However,
this trend raises significant concerns about energy efficiency and carbon
emissions, requiring methods to provide a trade-off between energy and QoE.
This paper proposes a lightweight energy prediction method that estimates the
energy consumption of high-resolution video encodings using reference encodings
generated at lower resolutions (so-called anchors), eliminating the need for
exhaustive per-segment energy measurements, a process that is infeasible at
scale. We automatically select encoding parameters, such as resolution and
quantization parameter (QP), to achieve substantial energy savings while
maintaining perceptual quality, as measured by the Video Multimethod Fusion
Assessment (VMAF), within acceptable limits. We implement and evaluate our
approach with the open-source VVenC encoder on 100 video sequences from the
Inter4K dataset across multiple encoding settings. Results show that, for an
average VMAF score reduction of only 1.68, which stays below the Just
Noticeable Difference (JND) threshold, our method achieves 51.22% encoding
energy savings and 53.54% decoding energy savings compared to a scenario with
no quality degradation.

</details>


### [54] [Rhythm in the Air: Vision-based Real-Time Music Generation through Gestures](https://arxiv.org/abs/2511.00793)
*Barathi Subramanian,Rathinaraja Jeyaraj,Anand Paul,Kapilya Gangadharan*

Main category: cs.MM

TL;DR: 本文提出了一种基于视觉的动态手势识别系统，用于实时音乐创作。通过开发多层级注意力门控循环单元(MLA-GRU)模型，在自定义包含15000个样本的21类手势数据集上实现了96.83%的准确率。


<details>
  <summary>Details</summary>
Motivation: 手势识别是人机交互的重要组成部分，本文旨在通过视觉动态手势识别实现实时音乐创作，为用户提供无需物理接触的新型音乐交互方式。

Method: 生成了包含15000个样本、21个类别的手势数据集，每个音符包含三个不同音高。开发了MLA-GRU模型，使用GRU学习时间模式，注意力层聚焦音乐相关手势片段。

Result: MLA-GRU模型显著优于传统GRU模型，准确率达到96.83%（基线为86.7%），在效率和处理速度方面表现优异，适合交互应用。

Conclusion: 该系统为音乐交互提供了创新方式，不仅提升了人机交互体验，还证明了MLA-GRU在需要快速准确手势识别场景中的有效性。

Abstract: Gesture recognition is an essential component of human-computer interaction
(HCI), facilitating seamless interconnectivity between users and computer
systems without physical touch. This paper introduces an innovative application
of vision-based dynamic gesture recognition (VDGR) for real-time music
composition through gestures. To implement this application, we generate a
custom gesture dataset that encompasses over 15000 samples across 21 classes,
incorporating 7 musical notes each manifesting at three distinct pitch levels.
To effectively deal with the modest volume of training data and to accurately
discern and prioritize complex gesture sequences for music creation, we develop
a multi-layer attention-based gated recurrent unit (MLA-GRU) model, in which
gated recurrent unit (GRU) is used to learn temporal patterns from the observed
sequence and an attention layer is employed to focus on musically pertinent
gesture segments. Our empirical studies demonstrate that MLA-GRU significantly
surpasses the classical GRU model, achieving a remarkable accuracy of 96.83%
compared to the baseline's 86.7%. Moreover, our approach exhibits superior
efficiency and processing speed, which are crucial for interactive
applications. Using our proposed system, we believe that people will interact
with music in a new and exciting way. It not only advances HCI experiences but
also highlights MLA-GRU's effectiveness in scenarios demanding swift and
precise gesture recognition.

</details>


### [55] [EV-NVC: Efficient Variable bitrate Neural Video Compression](https://arxiv.org/abs/2511.01590)
*Yongcun Hu,Yingzhen Zhai,Jixiang Luo,Wenrui Dai,Dell Zhang,Hongkai Xiong,Xuelong Li*

Main category: cs.MM

TL;DR: 提出了一种高效的可变比特率神经视频编码器EV-NVC，通过分段线性采样器和长短时特征融合模块提升高比特率范围的率失真性能，并采用混合精度训练策略。


<details>
  <summary>Details</summary>
Motivation: 训练可变比特率神经视频编码器具有挑战性，因为其复杂的训练策略和模型结构。本文旨在提高高比特率范围的率失真性能并增强上下文建模能力。

Method: 使用分段线性采样器(PLS)提升高比特率范围的率失真性能，长短时特征融合模块(LSTFFM)增强上下文建模，并采用混合精度训练和分阶段训练策略。

Result: 实验结果显示，在低延迟模式下，与HM-16.25相比，该方法将BD-rate降低了30.56%。

Conclusion: 提出的EV-NVC方法在可变比特率神经视频编码中取得了显著的性能提升，特别是在高比特率范围，验证了所提出模块和训练策略的有效性。

Abstract: Training neural video codec (NVC) with variable rate is a highly challenging
task due to its complex training strategies and model structure. In this paper,
we train an efficient variable bitrate neural video codec (EV-NVC) with the
piecewise linear sampler (PLS) to improve the rate-distortion performance in
high bitrate range, and the long-short-term feature fusion module (LSTFFM) to
enhance the context modeling. Besides, we introduce mixed-precision training
and discuss the different training strategies for each stage in detail to fully
evaluate its effectiveness. Experimental results show that our approach reduces
the BD-rate by 30.56% compared to HM-16.25 within low-delay mode.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [56] [NOMAD - Navigating Optimal Model Application to Datastreams](https://arxiv.org/abs/2511.00290)
*Ashwin Gerard Colaco,Sharad Mehrotra,Michael J De Lucia,Kevin Hamlen,Murat Kantarcioglu,Latifur Khan,Ananthram Swami,Bhavani Thuraisingham*

Main category: cs.DB

TL;DR: NOMAD是一个智能数据流处理框架，通过动态构建模型链来优化实时多类分类，在保证分类质量的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 为了解决实时数据流处理中高质量模型计算成本高的问题，需要一种能动态选择模型、平衡成本与质量的方法。

Method: 采用动态模型链构建，基于效用标准选择模型序列，利用廉价模型作为初始过滤器，必要时才使用昂贵模型，并通过形式化链安全机制保证分类质量。

Result: 在多个数据集上的评估表明，NOMAD相比静态和朴素方法显著节省计算成本，同时保持与最准确（通常也是最昂贵）模型相当的分类质量。

Conclusion: NOMAD框架有效解决了实时数据流处理中的成本-质量权衡问题，为动态模型选择提供了实用解决方案。

Abstract: NOMAD (Navigating Optimal Model Application for Datastreams) is an
intelligent framework for data enrichment during ingestion that optimizes
realtime multiclass classification by dynamically constructing model chains,
i.e ,sequences of machine learning models with varying cost-quality tradeoffs,
selected via a utilitybased criterion. Inspired by predicate ordering
techniques from database query processing, NOMAD leverages cheaper models as
initial filters, proceeding to more expensive models only when necessary, while
guaranteeing classification quality remains comparable to a designated role
model through a formal chain safety mechanism. It employs a dynamic belief
update strategy to adapt model selection based on per event predictions and
shifting data distributions, and extends to scenarios with dependent models
such as earlyexit DNNs and stacking ensembles. Evaluation across multiple
datasets demonstrates that NOMAD achieves significant computational savings
compared to static and naive approaches while maintaining classification
quality comparable to that achieved by the most accurate (and often the most
expensive) model.

</details>


### [57] [Embedding based Encoding Scheme for Privacy Preserving Record Linkage](https://arxiv.org/abs/2511.00414)
*Sirintra Vaiwsri,Thilina Ranbaduge*

Main category: cs.DB

TL;DR: 提出了一种基于嵌入编码的隐私保护记录链接方法，将q-gram转换为嵌入空间，再转换为二进制表示用于记录匹配，在保护隐私的同时提高了短记录值的链接准确性。


<details>
  <summary>Details</summary>
Motivation: 由于隐私和保密问题，敏感数据库的所有者通常不愿意与其他组织交换或共享数据来进行相似性计算，因此需要隐私保护记录链接技术。

Method: 首先将单个q-gram转换为嵌入空间，然后将记录的q-gram集合嵌入转换为二进制表示，最终使用这些二进制表示进行记录匹配。

Result: 在真实世界数据集上的实验表明，与现有技术相比，该方法在短记录值上能提供更好的链接准确性，并能有效保护个人隐私免受攻击。

Conclusion: 基于嵌入的编码技术可以在隐私保护记录链接中有效平衡隐私保护和链接准确性，特别是对于短记录值。

Abstract: To discover new insights from data, there is a growing need to share
information that is often held by different organisations. One key task in data
integration is the calculation of similarities between records in different
databases to identify pairs or sets of records that correspond to the same
real-world entities. Due to privacy and confidentiality concerns, however, the
owners of sensitive databases are often not allowed or willing to exchange or
share their data with other organisations to allow such similarity
calculations. Privacy-preserving record linkage (PPRL) is the process of
matching records that refer to the same entity across sensitive databases held
by different organisations while ensuring no information about the entities is
revealed to the participating parties. In this paper, we study how embedding
based encoding techniques can be applied in the PPRL context to ensure the
privacy of the entities that are being linked. We first convert individual
q-grams into the embedded space and then convert the embedding of a set of
q-grams of a given record into a binary representation. The final binary
representations can be used to link records into matches and non-matches. We
empirically evaluate our proposed encoding technique against different
real-world datasets. The results suggest that our proposed encoding approach
can provide better linkage accuracy and protect the privacy of individuals
against attack compared to state-of-the-art techniques for short record values.

</details>


### [58] [Object-Centric Analysis of XES Event Logs: Integrating OCED Modeling with SPARQL Queries](https://arxiv.org/abs/2511.00693)
*Saba Latif,Huma Latif,Muhammad Rameez Ur Rahman*

Main category: cs.DB

TL;DR: 本文提出使用对象中心事件数据本体(OCEDO)来克服XES标准在流程挖掘事件日志中的局限性，通过BPIC 2013数据集展示OCEDO与SPARQL查询结合的方法，使事件与对象间的关系更加明确。


<details>
  <summary>Details</summary>
Motivation: 传统XES格式在流程挖掘中无法充分展示事件之间的依赖关系和详细操作，OCED模型能够揭示事件日志中更多信息，使流程概念更易理解。

Method: 采用对象中心事件数据本体(OCEDO)方法，结合SPARQL查询技术，应用于BPIC 2013数据集，处理OCEDO模型的元描述。

Result: OCEDO方法提高了流程数据的完整性和可读性，对象中心建模相比传统方法能够进行更丰富的分析。

Conclusion: 对象中心事件数据本体(OCEDO)能够克服XES标准的局限性，为流程挖掘提供更深入的分析能力，使事件与对象间的关系更加明确。

Abstract: Object Centric Event Data (OCED) has gained attention in recent years within
the field of process mining. However, there are still many challenges, such as
connecting the XES format to object-centric approaches to enable more
insightful analysis. It is important for a process miner to understand the
insights and dependencies of events in the event log to see what is going on in
our processes. In previous standards, the dependencies of event logs are only
used to show events, but not their dependencies among each other and actions in
detail as described in OCEDO. There is more information in the event log when
it is revealed using the OCEDO model. It becomes more understandable and easier
to grasp the concepts and deal with the processes. This paper proposes the use
of Object-Centric Event Data Ontology (OCEDO) to overcome the limitations of
the XES standard in event logs for process mining. We demonstrate how the OCEDO
approach, integrated with SPARQL queries, can be applied to the BPIC 2013
dataset to make the relationships between events and objects more explicit. It
describes dealing with the meta descriptions of the OCEDO model on a business
process challenge as an event log. It improves the completeness and readability
of process data, suggesting that object-centric modeling allows for richer
analyses than traditional approaches.

</details>


### [59] [Finding Non-Redundant Simpson's Paradox from Multidimensional Data](https://arxiv.org/abs/2511.00748)
*Yi Yang,Jian Pei,Jun Yang,Jichun Xie*

Main category: cs.DB

TL;DR: 提出了首个发现非冗余辛普森悖论的框架，通过形式化三种冗余类型并设计高效算法，显著减少计算成本并提高可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有辛普森悖论检测方法忽视了冗余问题，许多悖论源于等效的数据子集选择、相同子群体划分和相关结果变量，这掩盖了本质模式并增加了计算成本。

Method: 形式化了三种冗余类型（兄弟子集、分隔符和统计等价），提出简洁表示框架，并设计了结合深度优先基础表物化和冗余感知悖论发现的高效算法。

Result: 在真实数据集和合成基准测试中，冗余悖论普遍存在（某些真实数据集中超过40%），算法可扩展到数百万条记录，运行时间减少高达60%，发现的悖论在数据扰动下具有结构鲁棒性。

Conclusion: 辛普森悖论可以在大型多维数据集中被高效识别、简洁总结和有意义地解释。

Abstract: Simpson's paradox, a long-standing statistical phenomenon, describes the
reversal of an observed association when data are disaggregated into
sub-populations. It has critical implications across statistics, epidemiology,
economics, and causal inference. Existing methods for detecting Simpson's
paradox overlook a key issue: many paradoxes are redundant, arising from
equivalent selections of data subsets, identical partitioning of
sub-populations, and correlated outcome variables, which obscure essential
patterns and inflate computational cost. In this paper, we present the first
framework for discovering non-redundant Simpson's paradoxes. We formalize three
types of redundancy - sibling child, separator, and statistic equivalence - and
show that redundancy forms an equivalence relation. Leveraging this insight, we
propose a concise representation framework for systematically organizing
redundant paradoxes and design efficient algorithms that integrate depth-first
materialization of the base table with redundancy-aware paradox discovery.
Experiments on real-world datasets and synthetic benchmarks show that redundant
paradoxes are widespread, on some real datasets constituting over 40% of all
paradoxes, while our algorithms scale to millions of records, reduce run time
by up to 60%, and discover paradoxes that are structurally robust under data
perturbation. These results demonstrate that Simpson's paradoxes can be
efficiently identified, concisely summarized, and meaningfully interpreted in
large multidimensional datasets.

</details>


### [60] [Reliable Curation of EHR Dataset via Large Language Models under Environmental Constraints](https://arxiv.org/abs/2511.00772)
*Raymond M. Xiong,Panyu Chen,Tianze Dong,Jian Lu,Benjamin Goldstein,Danyang Zhuo,Anru R. Zhang*

Main category: cs.DB

TL;DR: CELEC是一个基于大语言模型的框架，用于自动化电子健康记录数据提取和分析，通过自然语言查询生成SQL，降低医疗研究人员的技术门槛。


<details>
  <summary>Details</summary>
Motivation: 许多研究人员缺乏数据库专业知识来编写复杂SQL查询或生成有效可视化，限制了电子健康记录数据的高效使用和科学发现。

Method: 使用提示策略将自然语言查询转换为SQL，整合模式信息、少样本演示和思维链推理，提高准确性和鲁棒性。

Result: 在EHRSQL基准测试子集上，CELEC实现了与先前系统相当的执行准确性，同时保持低延迟、成本效益和严格隐私保护。

Conclusion: CELEC通过降低技术障碍，使医学研究人员能够直接查询EHR数据库，简化研究流程并加速生物医学发现。

Abstract: Electronic health records (EHRs) are central to modern healthcare delivery
and research; yet, many researchers lack the database expertise necessary to
write complex SQL queries or generate effective visualizations, limiting
efficient data use and scientific discovery. To address this barrier, we
introduce CELEC, a large language model (LLM)-powered framework for automated
EHR data extraction and analytics. CELEC translates natural language queries
into SQL using a prompting strategy that integrates schema information,
few-shot demonstrations, and chain-of-thought reasoning, which together improve
accuracy and robustness. On a subset of the EHRSQL benchmark, CELEC achieves
execution accuracy comparable to prior systems while maintaining low latency,
cost efficiency, and strict privacy by exposing only database metadata to the
LLM. CELEC also adheres to strict privacy protocols: the LLM accesses only
database metadata (e.g., table and column names), while all query execution
occurs securely within the institutional environment, ensuring that no
patient-level data is ever transmitted to or shared with the LLM. Ablation
studies confirm that each component of the SQL generation pipeline,
particularly the few-shot demonstrations, plays a critical role in performance.
By lowering technical barriers and enabling medical researchers to query EHR
databases directly, CELEC streamlines research workflows and accelerates
biomedical discovery.

</details>


### [61] [Efficient Query Repair for Aggregate Constraints](https://arxiv.org/abs/2511.00826)
*Shatha Algarni,Boris Glavic,Seokki Lee,Adriane Chapman*

Main category: cs.DB

TL;DR: 提出一种新的查询修复技术，通过修改查询的过滤谓词来满足领域特定的聚合约束，利用候选解集的边界和区间算术高效剪枝搜索空间。


<details>
  <summary>Details</summary>
Motivation: 在现实场景中，查询结果需要满足领域特定的约束（如面试候选人中女性比例要求），这些约束可表示为查询结果上聚合计算的算术组合。

Method: 使用候选解集的边界和区间算术来高效剪枝搜索空间，通过修改查询的过滤谓词来修复查询以满足约束。

Result: 实验证明，该技术显著优于每次只考虑单个候选解的基线方法。

Conclusion: 提出的查询修复技术能有效处理聚合约束，通过智能剪枝大幅提升搜索效率。

Abstract: In many real-world scenarios, query results must satisfy domain-specific
constraints. For instance, a minimum percentage of interview candidates
selected based on their qualifications should be female. These requirements can
be expressed as constraints over an arithmetic combination of aggregates
evaluated on the result of the query. In this work, we study how to repair a
query to fulfill such constraints by modifying the filter predicates of the
query. We introduce a novel query repair technique that leverages bounds on
sets of candidate solutions and interval arithmetic to efficiently prune the
search space. We demonstrate experimentally, that our technique significantly
outperforms baselines that consider a single candidate at a time.

</details>


### [62] [All-in-one Graph-based Indexing for Hybrid Search on GPUs](https://arxiv.org/abs/2511.00855)
*Zhonggen Li,Yougen Li,Yifan Zhu,Zhaoqiang Chen,Yunjun Gao*

Main category: cs.DB

TL;DR: Allan-Poe是一个基于GPU加速的统一图索引，用于高效混合搜索，解决了现有方法在灵活性、效率和存储开销之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有混合搜索方法面临三难困境：要么牺牲灵活性换取效率，要么因分离检索导致精度下降，要么为灵活组合检索路径产生过高存储开销。

Method: 设计统一图索引整合四种检索路径（稠密向量、稀疏向量、全文、知识图谱），采用GPU加速构建流水线，支持动态融合框架处理任意路径组合。

Result: 在6个真实数据集上的实验表明，Allan-Poe在端到端查询精度上表现优异，吞吐量比现有最优方法提升1.5-186.4倍，同时显著降低存储开销。

Conclusion: Allan-Poe通过统一图索引和GPU加速，有效解决了混合搜索的灵活性与效率权衡问题，为推荐系统、信息检索和RAG应用提供了高效解决方案。

Abstract: Hybrid search has emerged as a promising paradigm to overcome the limitations
of single-path retrieval, enhancing accuracy for applications like
recommendations, information retrieval, and Retrieval-Augmented Generation.
However, existing methods are constrained by a trilemma: they sacrifice
flexibility for efficiency, suffer from accuracy degradation due to separate
retrievals, or incur prohibitive storage overhead for flexible combinations of
retrieval paths. This paper introduces Allan-Poe, a novel All-in-one graph
index accelerated by GPUs for efficient hybrid search. We first analyze the
limitations of existing retrieval paradigms and distill key design principles
for an effective hybrid search index. Guided by these principles, we architect
a unified graph-based index that flexibly integrates four retrieval paths-dense
vector, sparse vector, full-text, and knowledge graph-within a single, cohesive
structure. To enable efficient construction, we design a GPU-accelerated
pipeline featuring a warp-level hybrid distance kernel, RNG-IP joint pruning,
and keyword-aware neighbor recycling. For query processing, we introduce a
dynamic fusion framework that supports any combination of retrieval paths and
weights without index reconstruction, leveraging logical edges from the
knowledge graph to resolve complex multi-hop queries. Extensive experiments on
6 real-world datasets demonstrate that Allan-Poe achieves superior end-to-end
query accuracy and outperforms state-of-the-art methods by 1.5-186.4x in
throughput, while significantly reducing storage overhead.

</details>


### [63] [FlowLog: Efficient and Extensible Datalog via Incrementality](https://arxiv.org/abs/2511.00865)
*Hangdong Zhao,Zhenghong Yu,Srinag Rao,Simon Frisk,Zhiwei Fan,Paraschos Koutris*

Main category: cs.DB

TL;DR: FlowLog是一个新的Datalog引擎，通过显式关系IR分离递归控制和逻辑计划，结合Datalog特定优化和数据库原语，在递归工作负载中实现高性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有Datalog系统在效率和可扩展性之间存在权衡：Souffle等引擎效率高但缺乏通用灵活性，RecStep等系统模块化但难以集成Datalog特定优化。

Method: 使用显式关系IR按规则分离递归控制与逻辑计划，在逻辑层应用SQL优化（逻辑融合、子计划重用），采用稳健性优先方法结合结构优化器和侧向信息传递，基于Differential Dataflow构建。

Result: FlowLog在广泛的递归工作负载中优于最先进的Datalog引擎和现代数据库，实现卓越的可扩展性。

Conclusion: FlowLog通过分离关注点和重用现有组件，在保持简单可扩展架构的同时，实现了Datalog系统效率和灵活性的平衡。

Abstract: Datalog-based languages are regaining popularity as a powerful abstraction
for expressing recursive computations in domains such as program analysis and
graph processing. However, existing systems often face a trade-off between
efficiency and extensibility. Engines like Souffle achieve high efficiency
through domain-specific designs, but lack general-purpose flexibility. Others,
like RecStep, offer modularity by layering Datalog on traditional databases,
but struggle to integrate Datalog-specific optimizations.
  This paper bridges this gap by presenting FlowLog, a new Datalog engine that
uses an explicit relational IR per-rule to cleanly separate recursive control
(e.g., semi-naive execution) from each rule's logical plan. This boundary lets
us retain fine-grained, Datalog-aware optimizations at the logical layer, but
also reuse off-the-shelf database primitives at execution. At the logical level
(i.e. IR), we apply proven SQL optimizations, such as logic fusion and subplan
reuse. To address high volatility in recursive workloads, we adopt a
robustness-first approach that pairs a structural optimizer (avoiding
worst-case joins) with sideways information passing (early filtering). Built
atop Differential Dataflow--a mature framework for streaming analytics--FlowLog
supports both batch and incremental Datalog and adds novel recursion-aware
optimizations called Boolean (or algebraic) specialization. Our evaluation
shows that FlowLog outperforms state-of-the-art Datalog engines and modern
databases across a broad range of recursive workloads, achieving superior
scalability while preserving a simple and extensible architecture.

</details>


### [64] [ORANGE: An Online Reflection ANd GEneration framework with Domain Knowledge for Text-to-SQL](https://arxiv.org/abs/2511.00985)
*Yiwen Jiao,Tonghui Ren,Yuche Gao,Zhenying He,Yinan Jing,Kai Zhang,X. Sean Wang*

Main category: cs.DB

TL;DR: ORANGE是一个在线自进化框架，通过解析翻译日志中的SQL查询构建数据库特定知识库，逐步减少语义差距，提高SQL翻译准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言转SQL方面取得显著进展，但其通用知识与数据库领域特定语义之间存在显著语义鸿沟。历史翻译日志包含了这些缺失的领域内知识。

Method: 提出ORANGE框架，通过解析翻译日志中的SQL查询构建数据库特定知识库，采用嵌套思维链SQL到文本策略进行语义跟踪，确保知识生成的可靠性。

Result: 在多个基准测试上的实验证实了ORANGE的实用性，特别是在处理复杂和领域特定查询方面表现出色。

Conclusion: ORANGE框架通过积累领域内知识有效减少了语义鸿沟，提高了Text-to-SQL在实际部署中的准确性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in
translating natural language to SQL, but a significant semantic gap persists
between their general knowledge and domain-specific semantics of databases.
Historical translation logs constitute a rich source of this missing in-domain
knowledge, where SQL queries inherently encapsulate real-world usage patterns
of database schema. Existing methods primarily enhance the reasoning process
for individual translations but fail to accumulate in-domain knowledge from
past translations. We introduce ORANGE, an online self-evolutionary framework
that constructs database-specific knowledge bases by parsing SQL queries from
translation logs. By accumulating in-domain knowledge that contains schema and
data semantics, ORANGE progressively reduces the semantic gap and enhances the
accuracy of subsequent SQL translations. To ensure reliability, we propose a
novel nested Chain-of-Thought SQL-to-Text strategy with tuple-semantic
tracking, which reduces semantic errors during knowledge generation.
Experiments on multiple benchmarks confirm the practicality of ORANGE,
demonstrating its effectiveness for real-world Text-to-SQL deployment,
particularly in handling complex and domain-specific queries.

</details>


### [65] [PathFinder: Efficiently Supporting Conjunctions and Disjunctions for Filtered Approximate Nearest Neighbor Search](https://arxiv.org/abs/2511.00995)
*Tianming Wu,Dixin Tang*

Main category: cs.DB

TL;DR: PathFinder是一个新的过滤近似最近邻搜索索引框架，支持复杂多属性过滤条件，通过选择性创建属性特定索引和基于成本的优化器实现高效查询处理。


<details>
  <summary>Details</summary>
Motivation: 现有图基ANNS索引在处理复杂多属性过滤条件时存在局限性，要么只针对特定属性优化，要么无法有效支持包含合取和析取的复杂过滤条件。

Method: 1) 引入新的优化指标平衡查询执行时间和准确性；2) 两阶段优化处理合取和析取过滤条件；3) 索引借用优化，使用属性特定索引处理其他属性的过滤条件。

Result: 在四个真实数据集上的实验表明，PathFinder在召回率0.95时，查询吞吐量比最佳基线方法提升高达9.8倍。

Conclusion: PathFinder框架通过关系数据库的设计理念，有效解决了复杂过滤条件下的近似最近邻搜索问题，显著提升了查询性能。

Abstract: Filtered approximate nearest neighbor search (ANNS) restricts the search to
data objects whose attributes satisfy a given filter and retrieves the top-$K$
objects that are most semantically similar to the query object. Many
graph-based ANNS indexes are proposed to enable efficient filtered ANNS but
remain limited in applicability or performance: indexes optimized for a
specific attribute achieve high efficiency for filters on that attribute but
fail to support complex filters with arbitrary conjunctions and disjunctions
over multiple attributes. Inspired by the design of relational databases, this
paper presents PathFinder, a new indexing framework that allows users to
selectively create ANNS indexes optimized for filters on specific attributes
and employs a cost-based optimizer to efficiently utilize them for processing
complex filters. PathFinder includes three novel techniques: 1) a new
optimization metric that captures the tradeoff between query execution time and
accuracy, 2) a two-phase optimization for handling filters with conjunctions
and disjunctions, and 3) an index borrowing optimization that uses an
attribute-specific index to process filters on another attribute. Experiments
on four real-world datasets show that PathFinder outperforms the best baseline
by up to 9.8x in query throughput at recall 0.95.

</details>


### [66] [Fast Answering Pattern-Constrained Reachability Queries with Two-Dimensional Reachability Index](https://arxiv.org/abs/2511.01025)
*Huihui Yang,Pingpeng Yuan*

Main category: cs.DB

TL;DR: 提出模式约束可达性查询(PCR)和二维可达性索引(TDR)，用于在边标记有向图上高效处理复杂的模式约束可达性查询。


<details>
  <summary>Details</summary>
Motivation: 现有的标签约束可达性查询和正则路径查询无法通过组合查询模式来描述复杂的查询需求，需要一种能够表达复杂标签约束的可达性查询方法。

Method: 构建二维可达性索引(TDR)，包含多路索引(水平维度)和路径索引(垂直维度)，通过将可达顶点分解为块并分别哈希到两个维度的索引中，作为全局和局部过滤器来剪枝搜索空间。

Result: 在16个真实数据集上的实验表明，该方法在索引大小和索引构建时间上优于最先进的标签约束可达性索引技术，能够高效回答模式约束可达性查询。

Conclusion: 提出的PCR查询和TDR索引能够有效处理复杂的模式约束可达性查询，包括标签约束可达性查询，解决了现有方法的局限性。

Abstract: Reachability queries ask whether there exists a path from the source vertex
to the target vertex on a graph. Recently, several powerful reachability
queries, such as Label-Constrained Reachability (LCR) queries and Regular Path
Queries (RPQ), have been proposed for emerging complex edge-labeled digraphs.
However, they cannot allow users to describe complex query requirements by
composing query patterns. Here, we introduce composite patterns, a logical
expression of patterns that can express complex constraints on the set of
labels. Based on pattern, we propose pattern-constrained reachability queries
(PCR queries). However, answering PCR queries is NP-hard. Thus, to improve the
performance to answer PCR queries, we build a two-dimensional reachability (TDR
for short) index which consists of a multi-way index (horizontal dimension) and
a path index (vertical dimension). Because the number of combinations of both
labels and vertices is exponential, it is very expensive to build full indices
that contain all the reachability information. Thus, the reachable vertices of
a vertex are decomposed into blocks, each of which is hashed into the
horizontal dimension index and the vertical dimension index, respectively. The
indices in the horizontal dimension and the vertical dimension serve as a
global filter and a local filter, respectively, to prune the search space.
Experimental results demonstrate that our index size and indexing time
outperform the state-of-the-art label-constrained reachability indexing
technique on 16 real datasets. TDR can efficiently answer pattern-constrained
reachability queries, including label-constrained reachability queries.

</details>


### [67] [L2T-Tune:LLM-Guided Hybrid Database Tuning with LHS and TD3](https://arxiv.org/abs/2511.01602)
*Xinyue Yang,Chen Zheng,Yaoyang Hou,Renhao Zhang,Yiyan Zhang,Yanjun Wu,Heng Zhang*

Main category: cs.DB

TL;DR: L2T-Tune是一个基于大语言模型的混合数据库调优框架，通过三阶段流程解决传统调优方法在收敛速度、冷启动和可迁移性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决数据库配置调优中的三大挑战：巨大参数空间导致优化不稳定、强化学习缺乏有效预热指导、硬件或工作负载变化时模型迁移性差。

Method: 三阶段流程：1) 预热阶段生成均匀样本并存入共享池；2) 使用LLM从手册和社区文档挖掘调优提示；3) 降维后使用TD3算法微调配置。

Result: 相比最佳替代方法，在所有工作负载上平均性能提升37.1%，TPC-C上最高提升73%；离线调优阶段快速收敛，在线调优仅需30步达到最佳结果。

Conclusion: L2T-Tune通过LLM引导的混合方法有效解决了数据库调优的关键挑战，在性能和收敛速度方面显著优于现有方法。

Abstract: Configuration tuning is critical for database performance. Although recent
advancements in database tuning have shown promising results in throughput and
latency improvement, challenges remain. First, the vast knob space makes direct
optimization unstable and slow to converge. Second, reinforcement learning
pipelines often lack effective warm-start guidance and require long offline
training. Third, transferability is limited: when hardware or workloads change,
existing models typically require substantial retraining to recover
performance.
  To address these limitations, we propose L2T-Tune, a new LLM-guided hybrid
database tuning framework that features a three-stage pipeline: Stage one
performs a warm start that simultaneously generates uniform samples across the
knob space and logs them into a shared pool; Stage two leverages a large
language model to mine and prioritize tuning hints from manuals and community
documents for rapid convergence. Stage three uses the warm-start sample pool to
reduce the dimensionality of knobs and state features, then fine-tunes the
configuration with the Twin Delayed Deep Deterministic Policy Gradient
algorithm.
  We conduct experiments on L2T-Tune and the state-of-the-art models. Compared
with the best-performing alternative, our approach improves performance by an
average of 37.1% across all workloads, and by up to 73% on TPC-C. Compared with
models trained with reinforcement learning, it achieves rapid convergence in
the offline tuning stage on a single server. Moreover, during the online tuning
stage, it only takes 30 steps to achieve best results.

</details>


### [68] [UniDataBench: Evaluating Data Analytics Agents Across Structured and Unstructured Data](https://arxiv.org/abs/2511.01625)
*Han Weng,Zhou Liu,Yuanfeng Song,Xiaoming Yin,Xing Chen,Wentao Zhang*

Main category: cs.DB

TL;DR: 提出了UniDataBench基准测试和ReActInsight代理，用于评估数据智能代理在处理多样化数据源（关系数据库、CSV、NoSQL等）方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现实业务中数据存储在不同类型的数据源中，现有基准测试无法充分评估代理处理多样化数据类型的能力。

Method: 基于真实行业分析报告构建UniDataBench基准，提出隐私信息去除流程；开发ReActInsight代理，能够自动发现跨源关联、分解目标并生成自修正代码。

Result: 创建了涵盖多种数据类型的综合基准测试，并开发了能够进行端到端分析的自主代理。

Conclusion: 该基准测试和代理共同为提升现实应用中数据分析代理的能力提供了强大框架。

Abstract: In the real business world, data is stored in a variety of sources, including
structured relational databases, unstructured databases (e.g., NoSQL
databases), or even CSV/excel files. The ability to extract reasonable insights
across these diverse source is vital for business success. Existing benchmarks,
however, are limited in assessing agents' capabilities across these diverse
data types. To address this gap, we introduce UniDataBench, a comprehensive
benchmark designed to evaluate the performance of data analytics agents in
handling diverse data sources. Specifically, UniDataBench is originating from
real-life industry analysis report and we then propose a pipeline to remove the
privacy and sensitive information. It encompasses a wide array of datasets,
including relational databases, CSV files to NoSQL data, reflecting real-world
business scenarios, and provides unified framework to assess how effectively
agents can explore multiple data formats, extract valuable insights, and
generate meaningful summaries and recommendations. Based on UniDataBench, we
propose a novel LLM-based agent named ReActInsight, an autonomous agent that
performs end-to-end analysis over diverse data sources by automatically
discovering cross-source linkages, decomposing goals, and generating robust,
self-correcting code to extract actionable insights. Our benchmark and agent
together provide a powerful framework for advancing the capabilities of data
analytics agents in real-world applications.

</details>


### [69] [SemBench: A Benchmark for Semantic Query Processing Engines](https://arxiv.org/abs/2511.01716)
*Jiale Lao,Andreas Zimmerer,Olga Ovcharenko,Tianji Cong,Matthew Russo,Gerardo Vitagliano,Michael Cochez,Fatma Özcan,Gautam Gupta,Thibaud Hottelier,H. V. Jagadish,Kris Kissel,Sebastian Schelter,Andreas Kipf,Immanuel Trummer*

Main category: cs.DB

TL;DR: 提出了一个针对语义查询处理引擎的基准测试，这些系统利用大语言模型的生成和推理能力，通过自然语言指令扩展SQL语义操作符来处理多模态数据。


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的语义查询处理系统的发展，需要建立一个全面的基准来评估这些系统在不同场景、模态和操作符上的性能表现。

Method: 构建了一个包含多样化场景（电影评论分析、医疗问答等）、多模态数据（图像、音频、文本）和多种语义操作符（语义过滤、连接、映射、排序、分类）的基准测试。

Result: 评估了三个学术系统（LOTUS、Palimpzest、ThalamusDB）和一个工业系统（Google BigQuery），揭示了这些系统当前的优缺点和发展潜力。

Conclusion: 该基准为语义查询处理系统提供了重要的评估框架，指明了未来研究的有前景方向，尽管这些系统仍在持续开发中。

Abstract: We present a benchmark targeting a novel class of systems: semantic query
processing engines. Those systems rely inherently on generative and reasoning
capabilities of state-of-the-art large language models (LLMs). They extend SQL
with semantic operators, configured by natural language instructions, that are
evaluated via LLMs and enable users to perform various operations on multimodal
data.
  Our benchmark introduces diversity across three key dimensions: scenarios,
modalities, and operators. Included are scenarios ranging from movie review
analysis to medical question-answering. Within these scenarios, we cover
different data modalities, including images, audio, and text. Finally, the
queries involve a diverse set of operators, including semantic filters, joins,
mappings, ranking, and classification operators.
  We evaluated our benchmark on three academic systems (LOTUS, Palimpzest, and
ThalamusDB) and one industrial system, Google BigQuery. Although these results
reflect a snapshot of systems under continuous development, our study offers
crucial insights into their current strengths and weaknesses, illuminating
promising directions for future research.

</details>
