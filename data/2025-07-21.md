<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 82]
- [cs.AI](#cs.AI) [Total: 20]
- [cs.LG](#cs.LG) [Total: 53]
- [cs.DB](#cs.DB) [Total: 5]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.DS](#cs.DS) [Total: 10]
- [cs.IT](#cs.IT) [Total: 8]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.IR](#cs.IR) [Total: 8]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives](https://arxiv.org/abs/2507.13359)
*Yang Zhou,Junjie Li,CongYang Ou,Dawei Yan,Haokui Zhang,Xizhe Xue*

Main category: cs.CV

TL;DR: 本文综述了无人机航拍场景中的开放词汇目标检测（OVOD），探讨了其核心原理、方法分类、数据集及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统无人机目标检测方法局限于预定义类别，而OVOD通过跨模态文本-图像对齐技术（如CLIP）实现了对未见物体的检测，提升了无人机的智能性和自主性。

Method: 论文构建了系统化的分类法，对现有OVOD方法进行归类，并综述了相关数据集。

Result: 通过分析，论文指出了该领域的关键挑战和开放性问题。

Conclusion: 论文提出了未来研究方向和潜在应用前景，为研究者提供了清晰的路线图和参考。

Abstract: Due to its extensive applications, aerial image object detection has long
been a hot topic in computer vision. In recent years, advancements in Unmanned
Aerial Vehicles (UAV) technology have further propelled this field to new
heights, giving rise to a broader range of application requirements. However,
traditional UAV aerial object detection methods primarily focus on detecting
predefined categories, which significantly limits their applicability. The
advent of cross-modal text-image alignment (e.g., CLIP) has overcome this
limitation, enabling open-vocabulary object detection (OVOD), which can
identify previously unseen objects through natural language descriptions. This
breakthrough significantly enhances the intelligence and autonomy of UAVs in
aerial scene understanding. This paper presents a comprehensive survey of OVOD
in the context of UAV aerial scenes. We begin by aligning the core principles
of OVOD with the unique characteristics of UAV vision, setting the stage for a
specialized discussion. Building on this foundation, we construct a systematic
taxonomy that categorizes existing OVOD methods for aerial imagery and provides
a comprehensive overview of the relevant datasets. This structured review
enables us to critically dissect the key challenges and open problems at the
intersection of these fields. Finally, based on this analysis, we outline
promising future research directions and application prospects. This survey
aims to provide a clear road map and a valuable reference for both newcomers
and seasoned researchers, fostering innovation in this rapidly evolving domain.
We keep tracing related works at
https://github.com/zhouyang2002/OVOD-in-UVA-imagery

</details>


### [2] [HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors](https://arxiv.org/abs/2507.13677)
*Chuheng Wei,Ziye Qin,Walter Zimmer,Guoyuan Wu,Matthew J. Barth*

Main category: cs.CV

TL;DR: HeCoFuse是一个统一的框架，用于解决V2X协同感知中异构传感器配置的挑战，通过分层融合机制和自适应学习策略，显著提升了感知性能。


<details>
  <summary>Details</summary>
Motivation: 现实中的V2X协同感知系统常因成本和部署差异导致传感器配置异构，这给特征融合和感知可靠性带来挑战。

Method: 提出HeCoFuse框架，采用分层融合机制（通道和空间注意力加权）和自适应空间分辨率调整模块，并结合动态调整融合类型的协同学习策略。

Result: 在TUMTraf-V2X数据集上，HeCoFuse在多种传感器配置下表现优异，3D mAP最高达43.38%，并在CVPR 2025 DriveX挑战赛中取得第一名。

Conclusion: HeCoFuse在异构传感器配置下表现出色，成为当前TUM-Traf V2X数据集上的最先进方法。

Abstract: Real-world Vehicle-to-Everything (V2X) cooperative perception systems often
operate under heterogeneous sensor configurations due to cost constraints and
deployment variability across vehicles and infrastructure. This heterogeneity
poses significant challenges for feature fusion and perception reliability. To
address these issues, we propose HeCoFuse, a unified framework designed for
cooperative perception across mixed sensor setups where nodes may carry Cameras
(C), LiDARs (L), or both. By introducing a hierarchical fusion mechanism that
adaptively weights features through a combination of channel-wise and spatial
attention, HeCoFuse can tackle critical challenges such as cross-modality
feature misalignment and imbalanced representation quality. In addition, an
adaptive spatial resolution adjustment module is employed to balance
computational cost and fusion effectiveness. To enhance robustness across
different configurations, we further implement a cooperative learning strategy
that dynamically adjusts fusion type based on available modalities. Experiments
on the real-world TUMTraf-V2X dataset demonstrate that HeCoFuse achieves 43.22%
3D mAP under the full sensor configuration (LC+LC), outperforming the CoopDet3D
baseline by 1.17%, and reaches an even higher 43.38% 3D mAP in the L+LC
scenario, while maintaining 3D mAP in the range of 21.74% to 43.38% across nine
heterogeneous sensor configurations. These results, validated by our
first-place finish in the CVPR 2025 DriveX challenge, establish HeCoFuse as the
current state-of-the-art on TUM-Traf V2X dataset while demonstrating robust
performance across diverse sensor deployments.

</details>


### [3] [Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance](https://arxiv.org/abs/2507.13360)
*Le-Anh Tran,Chung Nguyen Tran,Ngoc-Luu Nguyen,Nhan Cach Dang,Jordi Carrabina,David Castells-Rufas,Minh Son Nguyen*

Main category: cs.CV

TL;DR: EDNIG是一种基于U-Net的新型深度学习框架，用于低光图像增强，通过亮度引导和SPP模块提升性能，并在GAN框架下优化。


<details>
  <summary>Details</summary>
Motivation: 解决低光图像增强问题，通过引入亮度引导和多尺度特征提取，提升模型在复杂光照条件下的表现。

Method: 结合U-Net架构，利用BCP生成的亮度图作为引导输入，加入SPP模块提取多尺度特征，使用Swish激活函数，并在GAN框架下优化。

Result: EDNIG在定量指标和视觉质量上均优于现有方法，同时模型复杂度较低。

Conclusion: EDNIG是一种高效且实用的低光图像增强方法，适用于实际应用。

Abstract: This paper introduces a novel deep learning framework for low-light image
enhancement, named the Encoder-Decoder Network with Illumination Guidance
(EDNIG). Building upon the U-Net architecture, EDNIG integrates an illumination
map, derived from Bright Channel Prior (BCP), as a guidance input. This
illumination guidance helps the network focus on underexposed regions,
effectively steering the enhancement process. To further improve the model's
representational power, a Spatial Pyramid Pooling (SPP) module is incorporated
to extract multi-scale contextual features, enabling better handling of diverse
lighting conditions. Additionally, the Swish activation function is employed to
ensure smoother gradient propagation during training. EDNIG is optimized within
a Generative Adversarial Network (GAN) framework using a composite loss
function that combines adversarial loss, pixel-wise mean squared error (MSE),
and perceptual loss. Experimental results show that EDNIG achieves competitive
performance compared to state-of-the-art methods in quantitative metrics and
visual quality, while maintaining lower model complexity, demonstrating its
suitability for real-world applications. The source code for this work is
available at https://github.com/tranleanh/ednig.

</details>


### [4] [VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs](https://arxiv.org/abs/2507.13361)
*Shmuel Berman,Jia Deng*

Main category: cs.CV

TL;DR: 论文评估了视觉语言模型（VLMs）在非局部视觉推理任务中的表现，发现即使表现优秀的模型（如Gemini 2.5 Pro）也难以完成人类轻松完成的任务。


<details>
  <summary>Details</summary>
Motivation: 研究VLMs在非局部视觉推理任务中的能力，揭示其在复杂视觉任务中的局限性。

Method: 设计了三种非局部视觉任务（比较感知、扫视搜索和平滑视觉搜索），测试旗舰模型的表现。

Result: 当前模型在这些任务中表现不佳，甚至接近随机准确率。

Conclusion: 尽管VLMs在原始视觉敏锐度上有进步，但仍缺乏核心视觉推理能力。

Abstract: Visual Language Models (VLMs) excel at complex visual tasks such as VQA and
chart understanding, yet recent work suggests they struggle with simple
perceptual tests. We present an evaluation that tests vision-language models'
capacity for nonlocal visual reasoning -- reasoning that requires chaining
evidence collected from multiple, possibly distant, regions of an image. We
isolate three distinct forms of non-local vision: comparative perception, which
demands holding two images in working memory and comparing them; saccadic
search, which requires making discrete, evidence-driven jumps to locate
successive targets; and smooth visual search, which involves searching smoothly
along a continuous contour. Flagship models (e.g., Gemini 2.5 Pro, Claude
Vision 3.7, GPT-o4-mini), even those that perform well on prior
primitive-vision benchmarks, fail these tests and barely exceed random accuracy
on two variants of our tasks that are trivial for humans. Our structured
evaluation suite allows us to test if VLMs can perform similar visual
algorithms to humans. Our findings show that despite gains in raw visual
acuity, current models lack core visual reasoning capabilities.

</details>


### [5] [TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views](https://arxiv.org/abs/2507.13929)
*Hsiang-Hui Hung,Huu-Phu Do,Yung-Hui Li,Ching-Chun Huang*

Main category: cs.CV

TL;DR: TimeNeRF是一种通用的神经渲染方法，能够在任意视角和时间渲染新视图，即使输入视图较少。它结合多视角立体、神经辐射场和解缠策略，实现少样本泛化，并支持时间动态场景建模。


<details>
  <summary>Details</summary>
Motivation: 现实应用中，多视图采集成本高且对未见场景重新优化效率低。元宇宙等数字领域需要能够自然模拟昼夜过渡的3D环境，而现有NeRF技术在时间动态场景建模方面仍有局限。

Method: 结合多视角立体、神经辐射场和解缠策略，构建隐式内容辐射场表示场景，并支持任意时间的神经辐射场建模，最终通过体渲染合成新视图。

Result: TimeNeRF在少样本设置下无需逐场景优化即可渲染新视图，尤其在模拟昼夜过渡时表现出色，能捕捉复杂的自然场景变化。

Conclusion: TimeNeRF为时间动态场景建模提供了一种高效且通用的解决方案，适用于元宇宙等需要动态3D环境的领域。

Abstract: We present TimeNeRF, a generalizable neural rendering approach for rendering
novel views at arbitrary viewpoints and at arbitrary times, even with few input
views. For real-world applications, it is expensive to collect multiple views
and inefficient to re-optimize for unseen scenes. Moreover, as the digital
realm, particularly the metaverse, strives for increasingly immersive
experiences, the ability to model 3D environments that naturally transition
between day and night becomes paramount. While current techniques based on
Neural Radiance Fields (NeRF) have shown remarkable proficiency in synthesizing
novel views, the exploration of NeRF's potential for temporal 3D scene modeling
remains limited, with no dedicated datasets available for this purpose. To this
end, our approach harnesses the strengths of multi-view stereo, neural radiance
fields, and disentanglement strategies across diverse datasets. This equips our
model with the capability for generalizability in a few-shot setting, allows us
to construct an implicit content radiance field for scene representation, and
further enables the building of neural radiance fields at any arbitrary time.
Finally, we synthesize novel views of that time via volume rendering.
Experiments show that TimeNeRF can render novel views in a few-shot setting
without per-scene optimization. Most notably, it excels in creating realistic
novel views that transition smoothly across different times, adeptly capturing
intricate natural scene changes from dawn to dusk.

</details>


### [6] [Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning](https://arxiv.org/abs/2507.13362)
*Binbin Ji,Siddharth Agrawal,Qiance Tang,Yvonne Wu*

Main category: cs.CV

TL;DR: 研究探讨了视觉语言模型（VLMs）的空间推理能力，通过链式思维（CoT）提示和强化学习优化表现。发现结构化多阶段提示（SceneGraph CoT）显著提升准确性，而简单CoT提示可能损害性能。强化学习方法GRPO在泛化性和鲁棒性上优于监督微调（SFT）。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过提示策略和强化学习提升VLMs的空间推理能力及其泛化表现。

Method: 采用链式思维（CoT）提示和强化学习（GRPO）方法，对比结构化提示（SceneGraph CoT）与简单CoT的效果，并在SAT数据集上微调模型。

Result: SceneGraph CoT显著提升空间推理准确性；GRPO在Pass@1评估和OOD条件下表现优于SFT，泛化性更强。

Conclusion: 结构化提示和强化学习能有效提升VLMs的空间推理能力和泛化性，避免SFT的过拟合问题。

Abstract: This study investigates the spatial reasoning capabilities of vision-language
models (VLMs) through Chain-of-Thought (CoT) prompting and reinforcement
learning. We begin by evaluating the impact of different prompting strategies
and find that simple CoT formats, where the model generates a reasoning step
before the answer, not only fail to help, but can even harm the model's
original performance. In contrast, structured multi-stage prompting based on
scene graphs (SceneGraph CoT) significantly improves spatial reasoning
accuracy. Furthermore, to improve spatial reasoning ability, we fine-tune
models using Group Relative Policy Optimization (GRPO) on the SAT dataset and
evaluate their performance on CVBench. Compared to supervised fine-tuning
(SFT), GRPO achieves higher accuracy on Pass@1 evaluations and demonstrates
superior robustness under out-of-distribution (OOD) conditions. In particular,
we find that SFT overfits to surface-level linguistic patterns and may degrade
performance when test-time phrasing changes (e.g., from "closer to" to "farther
from"). GRPO, on the other hand, generalizes more reliably and maintains stable
performance under such shifts. Our findings provide insights into how
reinforcement learning and structured prompting improve the spatial reasoning
capabilities and generalization behavior of modern VLMs. All code is open
source at: https://github.com/Yvonne511/spatial-vlm-investigator

</details>


### [7] [Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop](https://arxiv.org/abs/2507.13363)
*Atharv Goel,Mehar Khurana*

Main category: cs.CV

TL;DR: 利用2D视觉语言模型进行开放词汇3D物体检测，无需人工标注3D标签，通过几何策略推断3D边界框。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D检测数据集类别有限且标注成本高的问题，利用2D模型的丰富语义理解能力扩展至开放世界。

Method: 使用2D视觉语言检测器生成文本条件提案，结合SAM分割和相机几何投影到3D，引入DBSCAN和Rotating Calipers进行几何推断。

Result: 在LiDAR和RGB-D输入下实现竞争性定位性能，无需训练且支持开放词汇。

Conclusion: 展示了2D基础模型在可扩展3D感知中的潜力。

Abstract: Modern 3D object detection datasets are constrained by narrow class
taxonomies and costly manual annotations, limiting their ability to scale to
open-world settings. In contrast, 2D vision-language models trained on
web-scale image-text pairs exhibit rich semantic understanding and support
open-vocabulary detection via natural language prompts. In this work, we
leverage the maturity and category diversity of 2D foundation models to perform
open-vocabulary 3D object detection without any human-annotated 3D labels.
  Our pipeline uses a 2D vision-language detector to generate text-conditioned
proposals, which are segmented with SAM and back-projected into 3D using camera
geometry and either LiDAR or monocular pseudo-depth. We introduce a geometric
inflation strategy based on DBSCAN clustering and Rotating Calipers to infer 3D
bounding boxes without training. To simulate adverse real-world conditions, we
construct Pseudo-nuScenes, a fog-augmented, RGB-only variant of the nuScenes
dataset.
  Experiments demonstrate that our method achieves competitive localization
performance across multiple settings, including LiDAR-based and purely RGB-D
inputs, all while remaining training-free and open-vocabulary. Our results
highlight the untapped potential of 2D foundation models for scalable 3D
perception. We open-source our code and resources at
https://github.com/atharv0goel/open-world-3D-det.

</details>


### [8] [OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning](https://arxiv.org/abs/2507.13364)
*Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

TL;DR: 提出了一种新型多模态多任务网络及训练算法，支持12种模态数据输入，通过共享架构和跨模态注意力实现统一嵌入空间，并在25个数据集上取得先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态和多任务场景下的数据融合与任务协同问题，提升模型在多样化数据上的表现。

Method: 采用模态专用分词器、共享Transformer架构和跨注意力机制，提出迭代模态切换预训练策略和成对模态训练算法。

Result: 在12种模态的25个数据集上实现了先进性能，验证了架构和训练策略的有效性。

Conclusion: 提出的方法在多模态多任务场景中表现优异，为未来研究提供了新思路。

Abstract: We present a novel multimodal multitask network and associated training
algorithm. The method is capable of ingesting data from approximately 12
different modalities namely image, video, audio, text, depth, point cloud, time
series, tabular, graph, X-ray, infrared, IMU, and hyperspectral. The proposed
approach utilizes modality specialized tokenizers, a shared transformer
architecture, and cross-attention mechanisms to project the data from different
modalities into a unified embedding space. It addresses multimodal and
multitask scenarios by incorporating modality-specific task heads for different
tasks in respective modalities. We propose a novel pretraining strategy with
iterative modality switching to initialize the network, and a training
algorithm which trades off fully joint training over all modalities, with
training on pairs of modalities at a time. We provide comprehensive evaluation
across 25 datasets from 12 modalities and show state of the art performances,
demonstrating the effectiveness of the proposed architecture, pretraining
strategy and adapted multitask training.

</details>


### [9] [Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation](https://arxiv.org/abs/2507.13371)
*Yeming Cai,Yang Wang,Zhenglin Li*

Main category: cs.CV

TL;DR: 提出一种端到端深度学习框架，结合光学动作捕捉和Transformer模型，用于医疗康复，解决数据噪声和缺失问题，并实时检测异常动作。


<details>
  <summary>Details</summary>
Motivation: 医疗康复中，光学动作捕捉常因遮挡和环境因素导致数据噪声和缺失，影响康复效果和患者安全。

Method: 采用Transformer模型进行时间序列建模，对动作捕捉数据去噪和补全，同时实时检测异常动作。

Result: 在卒中和骨科康复数据集上表现优异，数据重建和异常检测性能优越。

Conclusion: 该框架为远程康复提供可扩展、经济高效的解决方案，减少现场监督需求。

Abstract: This paper proposes an end-to-end deep learning framework integrating optical
motion capture with a Transformer-based model to enhance medical
rehabilitation. It tackles data noise and missing data caused by occlusion and
environmental factors, while detecting abnormal movements in real time to
ensure patient safety. Utilizing temporal sequence modeling, our framework
denoises and completes motion capture data, improving robustness. Evaluations
on stroke and orthopedic rehabilitation datasets show superior performance in
data reconstruction and anomaly detection, providing a scalable, cost-effective
solution for remote rehabilitation with reduced on-site supervision.

</details>


### [10] [Enhancing Breast Cancer Detection with Vision Transformers and Graph Neural Networks](https://arxiv.org/abs/2507.13372)
*Yeming Cai,Zhenglin Li,Yang Wang*

Main category: cs.CV

TL;DR: 提出了一种结合Vision Transformers和Graph Neural Networks的框架，用于乳腺癌检测，准确率达84.2%。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性死亡的主要原因，早期检测对提高生存率至关重要。

Method: 整合Vision Transformers（ViT）和Graph Neural Networks（GNN），利用ViT捕捉全局图像特征和GNN建模结构关系。

Result: 在CBIS-DDSM数据集上达到84.2%的准确率，优于传统方法。

Conclusion: 该框架不仅提高了检测准确性，还通过可解释的注意力热图辅助临床决策。

Abstract: Breast cancer is a leading cause of death among women globally, and early
detection is critical for improving survival rates. This paper introduces an
innovative framework that integrates Vision Transformers (ViT) and Graph Neural
Networks (GNN) to enhance breast cancer detection using the CBIS-DDSM dataset.
Our framework leverages ViT's ability to capture global image features and
GNN's strength in modeling structural relationships, achieving an accuracy of
84.2%, outperforming traditional methods. Additionally, interpretable attention
heatmaps provide insights into the model's decision-making process, aiding
radiologists in clinical settings.

</details>


### [11] [Smart Routing for Multimodal Video Retrieval: When to Search What](https://arxiv.org/abs/2507.13374)
*Kevin Dela Rosa*

Main category: cs.CV

TL;DR: ModaRoute是一个基于LLM的智能路由系统，通过动态选择最优模态优化多模态视频检索，减少计算开销41%，同时保持60.9%的召回率。


<details>
  <summary>Details</summary>
Motivation: 传统密集文本标注虽然能达到75.9%的召回率，但需要昂贵的离线处理且会遗漏34%的视觉信息。

Method: 利用GPT-4.1分析查询意图并预测信息需求，动态路由查询到ASR、OCR和视觉索引，平均每查询使用1.78种模态。

Result: 在180万视频片段上的评估显示，智能路由减少了基础设施成本，同时保持实际部署的竞争力。

Conclusion: ModaRoute为扩展多模态检索系统提供了实用解决方案，平衡了计算效率和检索效果。

Abstract: We introduce ModaRoute, an LLM-based intelligent routing system that
dynamically selects optimal modalities for multimodal video retrieval. While
dense text captions can achieve 75.9% Recall@5, they require expensive offline
processing and miss critical visual information present in 34% of clips with
scene text not captured by ASR. By analyzing query intent and predicting
information needs, ModaRoute reduces computational overhead by 41% while
achieving 60.9% Recall@5. Our approach uses GPT-4.1 to route queries across ASR
(speech), OCR (text), and visual indices, averaging 1.78 modalities per query
versus exhaustive 3.0 modality search. Evaluation on 1.8M video clips
demonstrates that intelligent routing provides a practical solution for scaling
multimodal retrieval systems, reducing infrastructure costs while maintaining
competitive effectiveness for real-world deployment.

</details>


### [12] [Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection](https://arxiv.org/abs/2507.13373)
*Xiaojian Lin,Wenxin Zhang,Yuchu Jiang,Wangyu Wu,Yiran Guo,Kangxu Wang,Zongzheng Zhang,Guijin Wang,Lei Jin,Hao Zhao*

Main category: cs.CV

TL;DR: Butter提出了一种新型目标检测框架，通过频率自适应特征一致性增强和渐进式分层特征融合网络，提升了多尺度特征表示能力，显著提高了检测精度并降低了模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有架构（如YOLO和DETR）在多尺度特征一致性和检测精度与计算效率的平衡上存在不足，Butter旨在解决这些问题。

Method: Butter引入了FAFCE组件（频率自适应特征一致性增强）和PHFFNet模块（渐进式分层特征融合网络），分别优化多尺度特征一致性和分层特征融合。

Result: 在BDD100K、KITTI和Cityscapes数据集上的实验表明，Butter在检测精度和模型复杂度上均有显著提升。

Conclusion: Butter通过分层特征优化，在实时自动驾驶场景中实现了精度、可部署性和计算效率的平衡。

Abstract: Hierarchical feature representations play a pivotal role in computer vision,
particularly in object detection for autonomous driving. Multi-level semantic
understanding is crucial for accurately identifying pedestrians, vehicles, and
traffic signs in dynamic environments. However, existing architectures, such as
YOLO and DETR, struggle to maintain feature consistency across different scales
while balancing detection precision and computational efficiency. To address
these challenges, we propose Butter, a novel object detection framework
designed to enhance hierarchical feature representations for improving
detection robustness. Specifically, Butter introduces two key innovations:
Frequency-Adaptive Feature Consistency Enhancement (FAFCE) Component, which
refines multi-scale feature consistency by leveraging adaptive frequency
filtering to enhance structural and boundary precision, and Progressive
Hierarchical Feature Fusion Network (PHFFNet) Module, which progressively
integrates multi-level features to mitigate semantic gaps and strengthen
hierarchical feature learning. Through extensive experiments on BDD100K, KITTI,
and Cityscapes, Butter demonstrates superior feature representation
capabilities, leading to notable improvements in detection accuracy while
reducing model complexity. By focusing on hierarchical feature refinement and
integration, Butter provides an advanced approach to object detection that
achieves a balance between accuracy, deployability, and computational
efficiency in real-time autonomous driving scenarios. Our model and
implementation are publicly available at https://github.com/Aveiro-Lin/Butter,
facilitating further research and validation within the autonomous driving
community.

</details>


### [13] [A Comprehensive Survey for Real-World Industrial Defect Detection: Challenges, Approaches, and Prospects](https://arxiv.org/abs/2507.13378)
*Yuqi Cheng,Yunkang Cao,Haiming Yao,Wei Luo,Cheng Jiang,Hui Zhang,Weiming Shen*

Main category: cs.CV

TL;DR: 该论文综述了工业缺陷检测的进展，重点比较了闭集和开集检测方法，并探讨了未来趋势。


<details>
  <summary>Details</summary>
Motivation: 传统检测方法难以满足现代制造业对精度和自动化的需求，计算机视觉和深度学习的进步推动了缺陷检测的发展。

Method: 对2D和3D模态下的闭集和开集缺陷检测策略进行深入分析，总结其演变和挑战。

Result: 开集检测方法逐渐成为主流，减少了对大量标注的需求并能识别新异常。

Conclusion: 论文提供了工业缺陷检测领域的全面视角，强调了开集技术的重要性，并指出了未来研究方向。

Abstract: Industrial defect detection is vital for upholding product quality across
contemporary manufacturing systems. As the expectations for precision,
automation, and scalability intensify, conventional inspection approaches are
increasingly found wanting in addressing real-world demands. Notable progress
in computer vision and deep learning has substantially bolstered defect
detection capabilities across both 2D and 3D modalities. A significant
development has been the pivot from closed-set to open-set defect detection
frameworks, which diminishes the necessity for extensive defect annotations and
facilitates the recognition of novel anomalies. Despite such strides, a
cohesive and contemporary understanding of industrial defect detection remains
elusive. Consequently, this survey delivers an in-depth analysis of both
closed-set and open-set defect detection strategies within 2D and 3D
modalities, charting their evolution in recent years and underscoring the
rising prominence of open-set techniques. We distill critical challenges
inherent in practical detection environments and illuminate emerging trends,
thereby providing a current and comprehensive vista of this swiftly progressing
field.

</details>


### [14] [Using Multiple Input Modalities Can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery](https://arxiv.org/abs/2507.13385)
*Arjun Rao,Esther Rolf*

Main category: cs.CV

TL;DR: 论文探讨了在卫星图像机器学习（SatML）中融合其他地理数据层对模型性能的影响，发现多模态输入能显著提升性能，尤其在数据有限和跨地理样本场景中。


<details>
  <summary>Details</summary>
Motivation: 现有SatML模型主要依赖光学卫星图像，而忽略了其他地理数据层的潜在价值。研究旨在评估这些额外数据层对模型性能的影响。

Method: 通过将其他地理数据层附加到SatML基准任务中，生成增强数据集，用于分类、回归和分割任务，并比较不同融合策略的效果。

Result: 多模态输入显著提升了模型性能，尤其在数据有限和跨地理样本场景中。硬编码融合策略表现优于学习型策略。

Conclusion: 多模态输入对SatML模型的数据效率和跨样本性能具有重要价值，硬编码融合策略值得进一步研究。

Abstract: A large variety of geospatial data layers is available around the world
ranging from remotely-sensed raster data like satellite imagery, digital
elevation models, predicted land cover maps, and human-annotated data, to data
derived from environmental sensors such as air temperature or wind speed data.
A large majority of machine learning models trained on satellite imagery
(SatML), however, are designed primarily for optical input modalities such as
multi-spectral satellite imagery. To better understand the value of using other
input modalities alongside optical imagery in supervised learning settings, we
generate augmented versions of SatML benchmark tasks by appending additional
geographic data layers to datasets spanning classification, regression, and
segmentation. Using these augmented datasets, we find that fusing additional
geographic inputs with optical imagery can significantly improve SatML model
performance. Benefits are largest in settings where labeled data are limited
and in geographic out-of-sample settings, suggesting that multi-modal inputs
may be especially valuable for data-efficiency and out-of-sample performance of
SatML models. Surprisingly, we find that hard-coded fusion strategies
outperform learned variants, with interesting implications for future work.

</details>


### [15] [Minimalist Concept Erasure in Generative Models](https://arxiv.org/abs/2507.13386)
*Yang Zhang,Er Jin,Yanfei Dong,Yixuan Wu,Philip Torr,Ashkan Khakzar,Johannes Stegmaier,Kenji Kawaguchi*

Main category: cs.CV

TL;DR: 提出了一种基于生成输出分布距离的最小化概念擦除方法，通过端到端优化和神经元掩码技术，在不降低模型性能的情况下实现稳健的概念擦除。


<details>
  <summary>Details</summary>
Motivation: 生成模型依赖大规模无标注数据引发安全和版权问题，现有擦除方法过度修改模型，损害其整体效用。

Method: 基于生成输出分布距离的最小化目标，推导可微优化损失，结合神经元掩码技术替代微调。

Result: 在先进流匹配模型上验证，方法稳健擦除概念且不损害模型性能。

Conclusion: 为更安全、负责任的生成模型提供了新途径。

Abstract: Recent advances in generative models have demonstrated remarkable
capabilities in producing high-quality images, but their reliance on
large-scale unlabeled data has raised significant safety and copyright
concerns. Efforts to address these issues by erasing unwanted concepts have
shown promise. However, many existing erasure methods involve excessive
modifications that compromise the overall utility of the model. In this work,
we address these issues by formulating a novel minimalist concept erasure
objective based \emph{only} on the distributional distance of final generation
outputs. Building on our formulation, we derive a tractable loss for
differentiable optimization that leverages backpropagation through all
generation steps in an end-to-end manner. We also conduct extensive analysis to
show theoretical connections with other models and methods. To improve the
robustness of the erasure, we incorporate neuron masking as an alternative to
model fine-tuning. Empirical evaluations on state-of-the-art flow-matching
models demonstrate that our method robustly erases concepts without degrading
overall model performance, paving the way for safer and more responsible
generative models.

</details>


### [16] [From Binary to Semantic: Utilizing Large-Scale Binary Occupancy Data for 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2507.13387)
*Chihiro Noguchi,Takaki Yamamoto*

Main category: cs.CV

TL;DR: 论文提出了一种利用低成本二进制占用数据增强3D语义占用预测的框架，通过分解为二进制和语义模块，在预训练和自动标注任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 3D语义占用预测需要昂贵的LiDAR标注数据，而低成本的大规模二进制占用数据潜力未被充分挖掘。

Method: 提出了一种基于二进制占用的框架，将预测过程分解为二进制和语义占用模块。

Result: 实验表明，该框架在预训练和自动标注任务中优于现有方法。

Conclusion: 该框架有效提升了3D语义占用预测的性能，代码已开源。

Abstract: Accurate perception of the surrounding environment is essential for safe
autonomous driving. 3D occupancy prediction, which estimates detailed 3D
structures of roads, buildings, and other objects, is particularly important
for vision-centric autonomous driving systems that do not rely on LiDAR
sensors. However, in 3D semantic occupancy prediction -- where each voxel is
assigned a semantic label -- annotated LiDAR point clouds are required, making
data acquisition costly. In contrast, large-scale binary occupancy data, which
only indicate occupied or free space without semantic labels, can be collected
at a lower cost. Despite their availability, the potential of leveraging such
data remains unexplored. In this study, we investigate the utilization of
large-scale binary occupancy data from two perspectives: (1) pre-training and
(2) learning-based auto-labeling. We propose a novel binary occupancy-based
framework that decomposes the prediction process into binary and semantic
occupancy modules, enabling effective use of binary occupancy data. Our
experimental results demonstrate that the proposed framework outperforms
existing methods in both pre-training and auto-labeling tasks, highlighting its
effectiveness in enhancing 3D semantic occupancy prediction. The code is
available at https://github.com/ToyotaInfoTech/b2s-occupancy

</details>


### [17] [InSyn: Modeling Complex Interactions for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2507.13397)
*Kaiyuan Zhai,Juan Chen,Chao Wang,Zeyi Xu*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的模型InSyn，用于行人轨迹预测，通过显式捕捉多样交互模式和方向敏感行为，并结合SSOS训练策略提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖相对位置建模行人交互，忽略了特定交互模式（如配对行走或冲突行为），导致预测精度受限。

Method: 提出InSyn模型，基于Transformer显式捕捉多样交互模式；引入SSOS训练策略以减少初始步预测误差。

Result: 在ETH和UCY数据集上表现优于基线，尤其在高密度场景；SSOS策略将初始步预测误差降低约6.58%。

Conclusion: InSyn模型和SSOS策略有效提升了行人轨迹预测的准确性，特别是在复杂交互场景中。

Abstract: Accurate pedestrian trajectory prediction is crucial for intelligent
applications, yet it remains highly challenging due to the complexity of
interactions among pedestrians. Previous methods have primarily relied on
relative positions to model pedestrian interactions; however, they tend to
overlook specific interaction patterns such as paired walking or conflicting
behaviors, limiting the prediction accuracy in crowded scenarios. To address
this issue, we propose InSyn (Interaction-Synchronization Network), a novel
Transformer-based model that explicitly captures diverse interaction patterns
(e.g., walking in sync or conflicting) while effectively modeling
direction-sensitive social behaviors. Additionally, we introduce a training
strategy termed Seq-Start of Seq (SSOS), designed to alleviate the common issue
of initial-step divergence in numerical time-series prediction. Experiments on
the ETH and UCY datasets demonstrate that our model outperforms recent
baselines significantly, especially in high-density scenarios. Furthermore, the
SSOS strategy proves effective in improving sequential prediction performance,
reducing the initial-step prediction error by approximately 6.58%.

</details>


### [18] [MADI: Masking-Augmented Diffusion with Inference-Time Scaling for Visual Editing](https://arxiv.org/abs/2507.13401)
*Shreya Kadambi,Risheek Garrepalli,Shubhankar Borse,Munawar Hyatt,Fatih Porikli*

Main category: cs.CV

TL;DR: MADI框架通过Masking-Augmented gaussian Diffusion（MAgD）和推理时容量扩展机制，显著提升了扩散模型的可编辑性和可控性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在文本到图像生成中表现出色，但在结构化视觉编辑和组合控制方面仍面临挑战。

Method: 提出MAgD训练策略（结合去噪和掩码重建）和基于Pause Tokens的推理时容量扩展机制。

Result: MADI显著提升了扩散模型的编辑能力和组合性。

Conclusion: MADI为扩散模型在通用上下文生成架构中的应用铺平了道路。

Abstract: Despite the remarkable success of diffusion models in text-to-image
generation, their effectiveness in grounded visual editing and compositional
control remains challenging. Motivated by advances in self-supervised learning
and in-context generative modeling, we propose a series of simple yet powerful
design choices that significantly enhance diffusion model capacity for
structured, controllable generation and editing. We introduce Masking-Augmented
Diffusion with Inference-Time Scaling (MADI), a framework that improves the
editability, compositionality and controllability of diffusion models through
two core innovations. First, we introduce Masking-Augmented gaussian Diffusion
(MAgD), a novel training strategy with dual corruption process which combines
standard denoising score matching and masked reconstruction by masking noisy
input from forward process. MAgD encourages the model to learn discriminative
and compositional visual representations, thus enabling localized and
structure-aware editing. Second, we introduce an inference-time capacity
scaling mechanism based on Pause Tokens, which act as special placeholders
inserted into the prompt for increasing computational capacity at inference
time. Our findings show that adopting expressive and dense prompts during
training further enhances performance, particularly for MAgD. Together, these
contributions in MADI substantially enhance the editability of diffusion
models, paving the way toward their integration into more general-purpose,
in-context generative diffusion architectures.

</details>


### [19] [UL-DD: A Multimodal Drowsiness Dataset Using Video, Biometric Signals, and Behavioral Data](https://arxiv.org/abs/2507.13403)
*Morteza Bodaghi,Majid Hosseini,Raju Gottumukkala,Ravi Teja Bhupatiraju,Iftikhar Ahmad,Moncef Gabbouj*

Main category: cs.CV

TL;DR: 本研究提供了一个全面的多模态驾驶员疲劳检测数据集，包含面部、行为和生物信号，旨在捕捉疲劳状态的渐变过程。


<details>
  <summary>Details</summary>
Motivation: 现有数据集多为离散标签，缺乏疲劳状态的渐变记录，本研究旨在填补这一空白。

Method: 数据集整合了3D面部视频、红外摄像、后视视频、生物信号（如心率、皮肤电活动等）以及方向盘握力传感器和模拟器数据，通过KSS量表每4分钟自评疲劳程度。

Result: 数据集包含19名受试者在清醒和疲劳状态下的40分钟连续记录，总时长1400分钟，记录了疲劳状态的渐变。

Conclusion: 该数据集为疲劳检测研究提供了更全面的多模态信号，支持更精细的状态分析。

Abstract: In this study, we present a comprehensive public dataset for driver
drowsiness detection, integrating multimodal signals of facial, behavioral, and
biometric indicators. Our dataset includes 3D facial video using a depth
camera, IR camera footage, posterior videos, and biometric signals such as
heart rate, electrodermal activity, blood oxygen saturation, skin temperature,
and accelerometer data. This data set provides grip sensor data from the
steering wheel and telemetry data from the American truck simulator game to
provide more information about drivers' behavior while they are alert and
drowsy. Drowsiness levels were self-reported every four minutes using the
Karolinska Sleepiness Scale (KSS). The simulation environment consists of three
monitor setups, and the driving condition is completely like a car. Data were
collected from 19 subjects (15 M, 4 F) in two conditions: when they were fully
alert and when they exhibited signs of sleepiness. Unlike other datasets, our
multimodal dataset has a continuous duration of 40 minutes for each data
collection session per subject, contributing to a total length of 1,400
minutes, and we recorded gradual changes in the driver state rather than
discrete alert/drowsy labels. This study aims to create a comprehensive
multimodal dataset of driver drowsiness that captures a wider range of
physiological, behavioral, and driving-related signals. The dataset will be
available upon request to the corresponding author.

</details>


### [20] [AortaDiff: Volume-Guided Conditional Diffusion Models for Multi-Branch Aortic Surface Generation](https://arxiv.org/abs/2507.13404)
*Delin An,Pan Du,Jian-Xun Wang,Chaoli Wang*

Main category: cs.CV

TL;DR: AortaDiff是一种基于扩散的框架，直接从CT/MRI体积生成平滑的主动脉表面，解决了现有方法依赖大数据集和手动干预的问题，适用于CFD分析。


<details>
  <summary>Details</summary>
Motivation: 准确的3D主动脉构建对临床诊断和CFD模拟至关重要，但现有方法依赖大数据集和手动干预，且生成的网格几何一致性差。

Method: AortaDiff使用体积引导的条件扩散模型生成主动脉中心线，自动提取血管轮廓，并拟合为平滑3D表面。

Result: 实验表明，AortaDiff在有限训练数据下仍能有效构建正常和病理主动脉网格，几何保真度高。

Conclusion: AortaDiff是一种端到端解决方案，适用于心血管研究，能生成高质量CFD兼容网格。

Abstract: Accurate 3D aortic construction is crucial for clinical diagnosis,
preoperative planning, and computational fluid dynamics (CFD) simulations, as
it enables the estimation of critical hemodynamic parameters such as blood flow
velocity, pressure distribution, and wall shear stress. Existing construction
methods often rely on large annotated training datasets and extensive manual
intervention. While the resulting meshes can serve for visualization purposes,
they struggle to produce geometrically consistent, well-constructed surfaces
suitable for downstream CFD analysis. To address these challenges, we introduce
AortaDiff, a diffusion-based framework that generates smooth aortic surfaces
directly from CT/MRI volumes. AortaDiff first employs a volume-guided
conditional diffusion model (CDM) to iteratively generate aortic centerlines
conditioned on volumetric medical images. Each centerline point is then
automatically used as a prompt to extract the corresponding vessel contour,
ensuring accurate boundary delineation. Finally, the extracted contours are
fitted into a smooth 3D surface, yielding a continuous, CFD-compatible mesh
representation. AortaDiff offers distinct advantages over existing methods,
including an end-to-end workflow, minimal dependency on large labeled datasets,
and the ability to generate CFD-compatible aorta meshes with high geometric
fidelity. Experimental results demonstrate that AortaDiff performs effectively
even with limited training data, successfully constructing both normal and
pathologically altered aorta meshes, including cases with aneurysms or
coarctation. This capability enables the generation of high-quality
visualizations and positions AortaDiff as a practical solution for
cardiovascular research.

</details>


### [21] [COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark](https://arxiv.org/abs/2507.13405)
*Ishant Chintapatla,Kazuma Choji,Naaisha Agarwal,Andrew Lin,Hannah You,Charles Duong,Kevin Zhu,Sean O'Brien,Vasu Sharma*

Main category: cs.CV

TL;DR: COREVQA是一个新的视觉蕴含基准测试，用于评估视觉语言模型在拥挤场景中的推理能力，结果显示当前模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试很少评估视觉语言模型在视觉蕴含任务中的表现，尤其是在拥挤场景中。

Method: 提出了COREVQA基准测试，包含5608张图像和合成的真假陈述对，基于CrowdHuman数据集。

Result: 即使表现最好的模型准确率也低于80%，其他模型表现更差（39.98%-69.95%）。

Conclusion: 当前视觉语言模型在拥挤场景中的视觉蕴含推理能力存在显著不足。

Abstract: Recently, many benchmarks and datasets have been developed to evaluate
Vision-Language Models (VLMs) using visual question answering (VQA) pairs, and
models have shown significant accuracy improvements. However, these benchmarks
rarely test the model's ability to accurately complete visual entailment, for
instance, accepting or refuting a hypothesis based on the image. To address
this, we propose COREVQA (Crowd Observations and Reasoning Entailment), a
benchmark of 5608 image and synthetically generated true/false statement pairs,
with images derived from the CrowdHuman dataset, to provoke visual entailment
reasoning on challenging crowded images. Our results show that even the
top-performing VLMs achieve accuracy below 80%, with other models performing
substantially worse (39.98%-69.95%). This significant performance gap reveals
key limitations in VLMs' ability to reason over certain types of image-question
pairs in crowded scenes.

</details>


### [22] [IConMark: Robust Interpretable Concept-Based Watermark For AI Images](https://arxiv.org/abs/2507.13407)
*Vinu Sankar Sadasivan,Mehrdad Saberi,Soheil Feizi*

Main category: cs.CV

TL;DR: IConMark是一种新型的语义水印方法，通过嵌入可解释的概念到AI生成的图像中，提高对抗攻击的鲁棒性，并支持人工验证。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI和合成媒体的快速发展，区分AI生成的图像与真实图像对防止虚假信息和确保数字真实性至关重要。传统水印技术易受对抗攻击，效果有限。

Method: IConMark在生成过程中嵌入可解释的语义属性，而非传统的噪声或扰动，使其对人类可读且抗对抗操作。此外，还结合了StegaStamp和TrustMark形成混合方法（IConMark+SS和IConMark+TM）。

Result: IConMark及其变体在检测准确性和图像质量保持上优于基线方法，AUROC得分分别提高了10.8%、14.5%和15.9%。

Conclusion: IConMark为可解释水印技术提供了有效解决方案，其鲁棒性和可读性使其在对抗攻击和图像操作中表现优异。

Abstract: With the rapid rise of generative AI and synthetic media, distinguishing
AI-generated images from real ones has become crucial in safeguarding against
misinformation and ensuring digital authenticity. Traditional watermarking
techniques have shown vulnerabilities to adversarial attacks, undermining their
effectiveness in the presence of attackers. We propose IConMark, a novel
in-generation robust semantic watermarking method that embeds interpretable
concepts into AI-generated images, as a first step toward interpretable
watermarking. Unlike traditional methods, which rely on adding noise or
perturbations to AI-generated images, IConMark incorporates meaningful semantic
attributes, making it interpretable to humans and hence, resilient to
adversarial manipulation. This method is not only robust against various image
augmentations but also human-readable, enabling manual verification of
watermarks. We demonstrate a detailed evaluation of IConMark's effectiveness,
demonstrating its superiority in terms of detection accuracy and maintaining
image quality. Moreover, IConMark can be combined with existing watermarking
techniques to further enhance and complement its robustness. We introduce
IConMark+SS and IConMark+TM, hybrid approaches combining IConMark with
StegaStamp and TrustMark, respectively, to further bolster robustness against
multiple types of image manipulations. Our base watermarking technique
(IConMark) and its variants (+TM and +SS) achieve 10.8%, 14.5%, and 15.9%
higher mean area under the receiver operating characteristic curve (AUROC)
scores for watermark detection, respectively, compared to the best baseline on
various datasets.

</details>


### [23] [A Deep Learning-Based Ensemble System for Automated Shoulder Fracture Detection in Clinical Radiographs](https://arxiv.org/abs/2507.13408)
*Hemanth Kumar M,Karthika M,Saianiruth M,Vasanthakumar Venugopal,Anandakumar D,Revathi Ezhumalai,Charulatha K,Kishore Kumar J,Dayana G,Kalyan Sivasailam,Bargava Subramanian*

Main category: cs.CV

TL;DR: AI系统通过多模型深度学习在肩部X光片中高效检测骨折，准确率达95.5%。


<details>
  <summary>Details</summary>
Motivation: 解决肩部骨折在急诊和高流量临床环境中漏诊率高的问题。

Method: 使用10,000张标注肩部X光片，结合Faster R-CNN、EfficientDet和RF-DETR等多模型，并采用NMW融合等集成技术。

Result: NMW集成模型准确率95.5%，F1分数0.9610，优于单一模型。

Conclusion: 集成AI模型能可靠检测肩部骨折，适合实时诊断流程，但仅支持二元骨折检测。

Abstract: Background: Shoulder fractures are often underdiagnosed, especially in
emergency and high-volume clinical settings. Studies report up to 10% of such
fractures may be missed by radiologists. AI-driven tools offer a scalable way
to assist early detection and reduce diagnostic delays. We address this gap
through a dedicated AI system for shoulder radiographs. Methods: We developed a
multi-model deep learning system using 10,000 annotated shoulder X-rays.
Architectures include Faster R-CNN (ResNet50-FPN, ResNeXt), EfficientDet, and
RF-DETR. To enhance detection, we applied bounding box and classification-level
ensemble techniques such as Soft-NMS, WBF, and NMW fusion. Results: The NMW
ensemble achieved 95.5% accuracy and an F1-score of 0.9610, outperforming
individual models across all key metrics. It demonstrated strong recall and
localization precision, confirming its effectiveness for clinical fracture
detection in shoulder X-rays. Conclusion: The results show ensemble-based AI
can reliably detect shoulder fractures in radiographs with high clinical
relevance. The model's accuracy and deployment readiness position it well for
integration into real-time diagnostic workflows. The current model is limited
to binary fracture detection, reflecting its design for rapid screening and
triage support rather than detailed orthopedic classification.

</details>


### [24] [AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery](https://arxiv.org/abs/2507.13420)
*Alessandro Pistola,Valentina Orru',Nicolo' Marchetti,Marco Roccetti*

Main category: cs.CV

TL;DR: 通过结合古老的CORONA卫星影像升级深度学习模型，显著提升了考古遗址自动识别的精度，并发现了四个新遗址。


<details>
  <summary>Details</summary>
Motivation: 利用CORONA影像弥补现代环境变迁导致的考古遗址消失问题，提升AI在考古领域的应用效果。

Method: 基于Bing的卷积网络模型，使用CORONA影像对伊拉克阿布格莱布地区进行重新训练。

Result: 检测精度显著提升（IoU超过85%，总体准确率达90%），并发现四个新遗址。

Conclusion: AI结合CORONA影像是发现已消失考古遗址的有效方法，对考古研究具有重要突破意义。

Abstract: By upgrading an existing deep learning model with the knowledge provided by
one of the oldest sets of grayscale satellite imagery, known as CORONA, we
improved the AI model attitude towards the automatic identification of
archaeological sites in an environment which has been completely transformed in
the last five decades, including the complete destruction of many of those same
sites. The initial Bing based convolutional network model was retrained using
CORONA satellite imagery for the district of Abu Ghraib, west of Baghdad,
central Mesopotamian floodplain. The results were twofold and surprising.
First, the detection precision obtained on the area of interest increased
sensibly: in particular, the Intersection over Union (IoU) values, at the image
segmentation level, surpassed 85 percent, while the general accuracy in
detecting archeological sites reached 90 percent. Second, our retrained model
allowed the identification of four new sites of archaeological interest
(confirmed through field verification), previously not identified by
archaeologists with traditional techniques. This has confirmed the efficacy of
using AI techniques and the CORONA imagery from the 1960 to discover
archaeological sites currently no longer visible, a concrete breakthrough with
significant consequences for the study of landscapes with vanishing
archaeological evidence induced by anthropization

</details>


### [25] [CaSTFormer: Causal Spatio-Temporal Transformer for Driving Intention Prediction](https://arxiv.org/abs/2507.13425)
*Sirui Wang,Zhou Guan,Bingxi Zhao,Tongjia Gu*

Main category: cs.CV

TL;DR: 提出了一种名为CaSTFormer的因果时空Transformer模型，用于精确预测驾驶意图，通过新颖的机制和模块提升了预测的准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 当前方法难以准确建模驾驶行为的复杂时空依赖性和不可预测性，影响了人机共驾系统的安全性和交互效率。

Method: CaSTFormer结合了Reciprocal Shift Fusion（RSF）机制、Causal Pattern Extraction（CPE）模块和Feature Synthesis Network（FSN），分别用于特征对齐、消除虚假相关性和合成特征。

Result: 在Brain4Cars数据集上实现了最先进的性能，能够有效捕捉复杂的因果时空依赖关系。

Conclusion: CaSTFormer显著提升了驾驶意图预测的准确性和透明度，为高级自动驾驶提供了有力支持。

Abstract: Accurate prediction of driving intention is key to enhancing the safety and
interactive efficiency of human-machine co-driving systems. It serves as a
cornerstone for achieving high-level autonomous driving. However, current
approaches remain inadequate for accurately modeling the complex
spatio-temporal interdependencies and the unpredictable variability of human
driving behavior. To address these challenges, we propose CaSTFormer, a Causal
Spatio-Temporal Transformer to explicitly model causal interactions between
driver behavior and environmental context for robust intention prediction.
Specifically, CaSTFormer introduces a novel Reciprocal Shift Fusion (RSF)
mechanism for precise temporal alignment of internal and external feature
streams, a Causal Pattern Extraction (CPE) module that systematically
eliminates spurious correlations to reveal authentic causal dependencies, and
an innovative Feature Synthesis Network (FSN) that adaptively synthesizes these
purified representations into coherent spatio-temporal inferences. We evaluate
the proposed CaSTFormer on the public Brain4Cars dataset, and it achieves
state-of-the-art performance. It effectively captures complex causal
spatio-temporal dependencies and enhances both the accuracy and transparency of
driving intention prediction.

</details>


### [26] ["PhyWorldBench": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models](https://arxiv.org/abs/2507.13428)
*Jing Gu,Xian Liu,Yu Zeng,Ashwin Nagarajan,Fangrui Zhu,Daniel Hong,Yue Fan,Qianqi Yan,Kaiwen Zhou,Ming-Yu Liu,Xin Eric Wang*

Main category: cs.CV

TL;DR: PhyWorldBench是一个评估视频生成模型物理模拟能力的基准，涵盖基础物理现象和反物理场景，并通过人类评估和MLLM方法测试了12种先进模型。


<details>
  <summary>Details</summary>
Motivation: 视频生成模型在物理现象模拟方面仍存在挑战，需要系统评估其物理一致性。

Method: 提出PhyWorldBench基准，包含多级物理现象和反物理场景，结合人类评估和MLLM零样本方法。

Result: 测试了12种模型，发现其在物理一致性上的关键挑战，并提供了提升物理逼真度的建议。

Conclusion: PhyWorldBench为视频生成模型的物理模拟能力提供了系统评估，并指出了改进方向。

Abstract: Video generation models have achieved remarkable progress in creating
high-quality, photorealistic content. However, their ability to accurately
simulate physical phenomena remains a critical and unresolved challenge. This
paper presents PhyWorldBench, a comprehensive benchmark designed to evaluate
video generation models based on their adherence to the laws of physics. The
benchmark covers multiple levels of physical phenomena, ranging from
fundamental principles like object motion and energy conservation to more
complex scenarios involving rigid body interactions and human or animal motion.
Additionally, we introduce a novel ""Anti-Physics"" category, where prompts
intentionally violate real-world physics, enabling the assessment of whether
models can follow such instructions while maintaining logical consistency.
Besides large-scale human evaluation, we also design a simple yet effective
method that could utilize current MLLM to evaluate the physics realism in a
zero-shot fashion. We evaluate 12 state-of-the-art text-to-video generation
models, including five open-source and five proprietary models, with a detailed
comparison and analysis. we identify pivotal challenges models face in adhering
to real-world physics. Through systematic testing of their outputs across 1,050
curated prompts-spanning fundamental, composite, and anti-physics scenarios-we
identify pivotal challenges these models face in adhering to real-world
physics. We then rigorously examine their performance on diverse physical
phenomena with varying prompt types, deriving targeted recommendations for
crafting prompts that enhance fidelity to physical principles.

</details>


### [27] [Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation](https://arxiv.org/abs/2507.13486)
*Debao Huang,Rongjun Qin*

Main category: cs.CV

TL;DR: 提出了一种用于摄影测量点云不确定性量化的框架，填补了多视角立体（MVS）阶段不确定性估计的空白。


<details>
  <summary>Details</summary>
Motivation: 摄影测量点云的精度高度依赖场景，且MVS阶段的不确定性估计尚未标准化，亟需一种可靠的方法。

Method: 通过结合SfM和MVS阶段，提出了一种自校准方法，利用可靠的多视角点回归视差不确定性。

Result: 在多种公开数据集上验证，该方法优于现有方法，实现了高边界率且未高估不确定性。

Conclusion: 该框架为摄影测量过程提供了稳健且可验证的不确定性量化，适用于多样化场景。

Abstract: Uncertainty quantification of the photogrammetry process is essential for
providing per-point accuracy credentials of the point clouds. Unlike airborne
LiDAR, which typically delivers consistent accuracy across various scenes, the
accuracy of photogrammetric point clouds is highly scene-dependent, since it
relies on algorithm-generated measurements (i.e., stereo or multi-view stereo).
Generally, errors of the photogrammetric point clouds propagate through a
two-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA),
followed by Multi-view Stereo (MVS). While uncertainty estimation in the SfM
stage has been well studied using the first-order statistics of the
reprojection error function, that in the MVS stage remains largely unsolved and
non-standardized, primarily due to its non-differentiable and multi-modal
nature (i.e., from pixel values to geometry). In this paper, we present an
uncertainty quantification framework closing this gap by associating an error
covariance matrix per point accounting for this two-step photogrammetry
process. Specifically, to estimate the uncertainty in the MVS stage, we propose
a novel, self-calibrating method by taking reliable n-view points (n>=6)
per-view to regress the disparity uncertainty using highly relevant cues (such
as matching cost values) from the MVS stage. Compared to existing approaches,
our method uses self-contained, reliable 3D points extracted directly from the
MVS process, with the benefit of being self-supervised and naturally adhering
to error propagation path of the photogrammetry process, thereby providing a
robust and certifiable uncertainty quantification across diverse scenes. We
evaluate the framework using a variety of publicly available airborne and UAV
imagery datasets. Results demonstrate that our method outperforms existing
approaches by achieving high bounding rates without overestimating uncertainty.

</details>


### [28] [Sugar-Beet Stress Detection using Satellite Image Time Series](https://arxiv.org/abs/2507.13514)
*Bhumika Laxman Sadbhave,Philipp Vaeth,Denise Dejon,Gunther Schorcht,Magda Gregorová*

Main category: cs.CV

TL;DR: 提出了一种基于3D卷积自编码器的无监督方法，用于从Sentinel-2卫星图像时间序列中检测甜菜田的压力状态。


<details>
  <summary>Details</summary>
Motivation: 利用卫星图像时间序列（SITS）的丰富光谱和时间信息，解决甜菜田压力检测问题。

Method: 采用3D卷积自编码器提取特征，并结合特定采集日期的时间编码，以捕捉甜菜生长动态。

Result: 模型能够区分压力田和健康田，并可跨年份直接应用。

Conclusion: 该方法为甜菜田压力检测提供了一种实用且可扩展的工具。

Abstract: Satellite Image Time Series (SITS) data has proven effective for agricultural
tasks due to its rich spectral and temporal nature. In this study, we tackle
the task of stress detection in sugar-beet fields using a fully unsupervised
approach. We propose a 3D convolutional autoencoder model to extract meaningful
features from Sentinel-2 image sequences, combined with
acquisition-date-specific temporal encodings to better capture the growth
dynamics of sugar-beets. The learned representations are used in a downstream
clustering task to separate stressed from healthy fields. The resulting stress
detection system can be directly applied to data from different years, offering
a practical and accessible tool for stress detection in sugar-beets.

</details>


### [29] [SparseC-AFM: a deep learning method for fast and accurate characterization of MoS$_2$ with C-AFM](https://arxiv.org/abs/2507.13527)
*Levi Harris,Md Jayed Hossain,Mufan Qiu,Ruichen Zhang,Pingchuan Ma,Tianlong Chen,Jiaqi Gu,Seth Ariel Tongay,Umberto Celano*

Main category: cs.CV

TL;DR: SparseC-AFM是一种基于深度学习的模型，用于快速重建2D材料的导电性图，显著减少数据采集时间。


<details>
  <summary>Details</summary>
Motivation: 解决传统C-AFM技术因扫描速度慢而无法满足大规模生产需求的问题。

Method: 利用深度学习模型从稀疏的C-AFM扫描数据中重建高分辨率导电性图。

Result: SparseC-AFM将采集时间减少11倍，同时保持与高分辨率数据相似的电气特性。

Conclusion: 该技术为AI辅助2D材料表征从实验室研究向工业应用的转化迈出了重要一步。

Abstract: The increasing use of two-dimensional (2D) materials in nanoelectronics
demands robust metrology techniques for electrical characterization, especially
for large-scale production. While atomic force microscopy (AFM) techniques like
conductive AFM (C-AFM) offer high accuracy, they suffer from slow data
acquisition speeds due to the raster scanning process. To address this, we
introduce SparseC-AFM, a deep learning model that rapidly and accurately
reconstructs conductivity maps of 2D materials like MoS$_2$ from sparse C-AFM
scans. Our approach is robust across various scanning modes, substrates, and
experimental conditions. We report a comparison between (a) classic flow
implementation, where a high pixel density C-AFM image (e.g., 15 minutes to
collect) is manually parsed to extract relevant material parameters, and (b)
our SparseC-AFM method, which achieves the same operation using data that
requires substantially less acquisition time (e.g., under 5 minutes).
SparseC-AFM enables efficient extraction of critical material parameters in
MoS$_2$, including film coverage, defect density, and identification of
crystalline island boundaries, edges, and cracks. We achieve over 11x reduction
in acquisition time compared to manual extraction from a full-resolution C-AFM
image. Moreover, we demonstrate that our model-predicted samples exhibit
remarkably similar electrical properties to full-resolution data gathered using
classic-flow scanning. This work represents a significant step toward
translating AI-assisted 2D material characterization from laboratory research
to industrial fabrication. Code and model weights are available at
github.com/UNITES-Lab/sparse-cafm.

</details>


### [30] [Total Generalized Variation of the Normal Vector Field and Applications to Mesh Denoising](https://arxiv.org/abs/2507.13530)
*Lukas Baumgärtner,Ronny Bergmann,Roland Herzog,Stephan Schmidt,Manuel Weiß*

Main category: cs.CV

TL;DR: 提出了一种新的二阶总广义变分（TGV）公式，用于处理嵌入在三维空间中的三角形网格上的法向量。


<details>
  <summary>Details</summary>
Motivation: 扩展离散TGV模型，使其适用于流形值数据（如单位球面上的法向量）。

Method: 构建了一个定制的切向Raviart-Thomas型有限元空间，以适应流形设置。

Result: 新正则化器在网格去噪实验中与现有方法进行了比较。

Conclusion: 新方法为流形值数据的TGV正则化提供了有效工具。

Abstract: We propose a novel formulation for the second-order total generalized
variation (TGV) of the normal vector on an oriented, triangular mesh embedded
in $\mathbb{R}^3$. The normal vector is considered as a manifold-valued
function, taking values on the unit sphere. Our formulation extends previous
discrete TGV models for piecewise constant scalar data that utilize a
Raviart-Thomas function space. To exctend this formulation to the manifold
setting, a tailor-made tangential Raviart-Thomas type finite element space is
constructed in this work. The new regularizer is compared to existing methods
in mesh denoising experiments.

</details>


### [31] [$\nabla$NABLA: Neighborhood Adaptive Block-Level Attention](https://arxiv.org/abs/2507.13546)
*Dmitrii Mikhailov,Aleksey Letunovskiy,Maria Kovaleva,Vladimir Arkhipkin,Vladimir Korviakov,Vladimir Polovnikov,Viacheslav Vasilev,Evelina Sidorova,Denis Dimitrov*

Main category: cs.CV

TL;DR: NABLA提出了一种新型的邻域自适应块级注意力机制，用于降低视频扩散变换器中注意力计算的复杂度，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 全注意力机制的二次复杂度是视频生成任务中的瓶颈，尤其是高分辨率和长视频序列。

Method: 采用块级注意力机制和自适应稀疏阈值，动态适应视频扩散变换器中的稀疏模式。

Result: NABLA在训练和推理速度上提升了2.7倍，且几乎不影响生成质量和定量指标。

Conclusion: NABLA是一种高效且无需定制低层操作设计的注意力机制，适用于视频生成任务。

Abstract: Recent progress in transformer-based architectures has demonstrated
remarkable success in video generation tasks. However, the quadratic complexity
of full attention mechanisms remains a critical bottleneck, particularly for
high-resolution and long-duration video sequences. In this paper, we propose
NABLA, a novel Neighborhood Adaptive Block-Level Attention mechanism that
dynamically adapts to sparsity patterns in video diffusion transformers (DiTs).
By leveraging block-wise attention with adaptive sparsity-driven threshold,
NABLA reduces computational overhead while preserving generative quality. Our
method does not require custom low-level operator design and can be seamlessly
integrated with PyTorch's Flex Attention operator. Experiments demonstrate that
NABLA achieves up to 2.7x faster training and inference compared to baseline
almost without compromising quantitative metrics (CLIP score, VBench score,
human evaluation score) and visual quality drop. The code and model weights are
available here: https://github.com/gen-ai-team/Wan2.1-NABLA

</details>


### [32] [LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning](https://arxiv.org/abs/2507.13568)
*Kaihong Wang,Donghyun Kim,Margrit Betke*

Main category: cs.CV

TL;DR: 提出了一种基于LoRA增强的合成重放框架，通过任务特定的低秩适配器改进Stable Diffusion模型，提升视觉语言模型的持续学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有合成重放方法生成的样本可能因未捕捉领域细节和细粒度语义而误导微调，影响知识保留。

Method: 采用LoRA增强的合成重放框架，分两阶段基于置信度选择样本：先筛选真实任务数据，再生成并筛选合成样本。

Result: 在MTIL基准测试中表现优于现有方法，平衡了可塑性、稳定性和零样本能力。

Conclusion: 通过LoRA适配生成器，实现了视觉语言模型在持续学习中的鲁棒性。

Abstract: Continual learning for vision-language models has achieved remarkable
performance through synthetic replay, where samples are generated using Stable
Diffusion to regularize during finetuning and retain knowledge. However,
real-world downstream applications often exhibit domain-specific nuances and
fine-grained semantics not captured by generators, causing synthetic-replay
methods to produce misaligned samples that misguide finetuning and undermine
retention of prior knowledge. In this work, we propose a LoRA-enhanced
synthetic-replay framework that injects task-specific low-rank adapters into a
frozen Stable Diffusion model, efficiently capturing each new task's unique
visual and semantic patterns. Specifically, we introduce a two-stage,
confidence-based sample selection: we first rank real task data by
post-finetuning VLM confidence to focus LoRA finetuning on the most
representative examples, then generate synthetic samples and again select them
by confidence for distillation. Our approach integrates seamlessly with
existing replay pipelines-simply swap in the adapted generator to boost replay
fidelity. Extensive experiments on the Multi-domain Task Incremental Learning
(MTIL) benchmark show that our method outperforms previous synthetic-replay
techniques, achieving an optimal balance among plasticity, stability, and
zero-shot capability. These results demonstrate the effectiveness of generator
adaptation via LoRA for robust continual learning in VLMs.

</details>


### [33] [NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision](https://arxiv.org/abs/2507.13595)
*Tengkai Wang,Weihao Li,Ruikai Cui,Shi Qiu,Nick Barnes*

Main category: cs.CV

TL;DR: 论文提出NoiseSDF2NoiseSDF方法，通过噪声监督学习干净的神经SDF，直接从噪声点云中重建精确的隐式表面表示。


<details>
  <summary>Details</summary>
Motivation: 低质量扫描设备获取的点云通常包含大量噪声，导致表面重建不准确。受Noise2Noise范式启发，旨在将其扩展到3D神经场。

Method: 通过最小化噪声SDF表示之间的MSE损失，网络能够隐式去噪并优化表面估计。

Result: 在ShapeNet、ABC、Famous和Real数据集上的实验表明，该方法显著提高了噪声输入下的表面重建质量。

Conclusion: NoiseSDF2NoiseSDF为从噪声点云中学习干净神经SDF提供了一种有效方法。

Abstract: Reconstructing accurate implicit surface representations from point clouds
remains a challenging task, particularly when data is captured using
low-quality scanning devices. These point clouds often contain substantial
noise, leading to inaccurate surface reconstructions. Inspired by the
Noise2Noise paradigm for 2D images, we introduce NoiseSDF2NoiseSDF, a novel
method designed to extend this concept to 3D neural fields. Our approach
enables learning clean neural SDFs directly from noisy point clouds through
noisy supervision by minimizing the MSE loss between noisy SDF representations,
allowing the network to implicitly denoise and refine surface estimations. We
evaluate the effectiveness of NoiseSDF2NoiseSDF on benchmarks, including the
ShapeNet, ABC, Famous, and Real datasets. Experimental results demonstrate that
our framework significantly improves surface reconstruction quality from noisy
inputs.

</details>


### [34] [Learning Deblurring Texture Prior from Unpaired Data with Diffusion Model](https://arxiv.org/abs/2507.13599)
*Chengxu Liu,Lu Qi,Jinshan Pan,Xueming Qian,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型（DM）的无监督图像去模糊框架，通过从非配对数据中学习空间变化的纹理先验，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于获取大量真实的模糊-清晰图像对困难且昂贵，从非配对数据中学习去模糊更具实用性和前景。现有方法依赖对抗学习，忽略了真实世界模糊模式的复杂性。

Method: 提出DM框架，利用纹理先验编码器（TPE）和纹理转移变换器层（TTformer），结合自适应滤波和对抗损失，恢复模糊图像的纹理。

Result: 在广泛使用的基准测试中，该方法优于现有技术。

Conclusion: 该框架为无监督去模糊提供了有前景的解决方案，并在性能上超越了现有方法。

Abstract: Since acquiring large amounts of realistic blurry-sharp image pairs is
difficult and expensive, learning blind image deblurring from unpaired data is
a more practical and promising solution. Unfortunately, dominant approaches
rely heavily on adversarial learning to bridge the gap from blurry domains to
sharp domains, ignoring the complex and unpredictable nature of real-world blur
patterns. In this paper, we propose a novel diffusion model (DM)-based
framework, dubbed \ours, for image deblurring by learning spatially varying
texture prior from unpaired data. In particular, \ours performs DM to generate
the prior knowledge that aids in recovering the textures of blurry images. To
implement this, we propose a Texture Prior Encoder (TPE) that introduces a
memory mechanism to represent the image textures and provides supervision for
DM training. To fully exploit the generated texture priors, we present the
Texture Transfer Transformer layer (TTformer), in which a novel
Filter-Modulated Multi-head Self-Attention (FM-MSA) efficiently removes
spatially varying blurring through adaptive filtering. Furthermore, we
implement a wavelet-based adversarial loss to preserve high-frequency texture
details. Extensive evaluations show that \ours provides a promising
unsupervised deblurring solution and outperforms SOTA methods in widely-used
benchmarks.

</details>


### [35] [Efficient Burst Super-Resolution with One-step Diffusion](https://arxiv.org/abs/2507.13607)
*Kento Kawai,Takeru Oba,Kyotaro Tokoro,Kazutoshi Akita,Norimichi Ukita*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的随机采样方法，用于从低分辨率（LR）图像序列中生成高质量的超分辨率（SR）图像，显著减少了运行时间并保持了图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有的确定性方法生成的SR图像模糊且感知质量差，因此需要一种能生成清晰且高保真SR图像的方法。

Method: 采用扩散模型，结合随机采样器（基于高阶ODE）和一步扩散（通过知识蒸馏），以提高效率。

Result: 实验表明，该方法将运行时间降至基线的1.6%，同时保持基于图像失真和感知质量的SR质量。

Conclusion: 该方法在效率和图像质量之间取得了平衡，为SR任务提供了一种有效的解决方案。

Abstract: While burst Low-Resolution (LR) images are useful for improving their Super
Resolution (SR) image compared to a single LR image, prior burst SR methods are
trained in a deterministic manner, which produces a blurry SR image. Since such
blurry images are perceptually degraded, we aim to reconstruct sharp and
high-fidelity SR images by a diffusion model. Our method improves the
efficiency of the diffusion model with a stochastic sampler with a high-order
ODE as well as one-step diffusion using knowledge distillation. Our
experimental results demonstrate that our method can reduce the runtime to 1.6
% of its baseline while maintaining the SR quality measured based on image
distortion and perceptual quality.

</details>


### [36] [CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks](https://arxiv.org/abs/2507.13609)
*Yanan Wang,Julio Vizcarra,Zhi Li,Hao Niu,Mori Kurokawa*

Main category: cs.CV

TL;DR: 论文提出CoTasks框架，通过分解视频问题为四个实体级任务，提升视频大语言模型的链式推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型缺乏细粒度对象级理解的链式推理能力，需要结构化标注支持逐步推理。

Method: 将复杂视频问题分解为帧定位、实体跟踪、时空关系提取等四个基础任务，嵌入中间推理步骤。

Result: 在NeXT-QA基准测试中，LLaVA-video-7B和Qwen2.5-VL-3B的性能分别提升3.3和17.4分。

Conclusion: CoTasks作为结构化监督框架，显著提升了视频组合推理能力。

Abstract: Despite recent progress in video large language models (VideoLLMs), a key
open challenge remains: how to equip models with chain-of-thought (CoT)
reasoning abilities grounded in fine-grained object-level video understanding.
Existing instruction-tuned models, such as the Qwen and LLaVA series, are
trained on high-level video-text pairs, often lacking structured annotations
necessary for compositional, step-by-step reasoning. We propose CoTasks:
Chain-of-Thought based Video Instruction Tuning Tasks, a new framework that
decomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)
into four entity-level foundational tasks: frame localization, entity tracking,
spatial and temporal relation extraction. By embedding these intermediate
CoT-style reasoning steps into the input, CoTasks enables models to explicitly
perform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA
benchmark show that CoTasks significantly enhance inference performance:
LLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and
Qwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal
(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the
effectiveness of CoTasks as a structured CoT-style supervision framework for
improving compositional video reasoning.

</details>


### [37] [Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation](https://arxiv.org/abs/2507.13628)
*Masahiro Ogawa,Qi An,Atsushi Yamashita*

Main category: cs.CV

TL;DR: FoELS方法结合光流和纹理信息，有效分离动态和静态物体，适用于复杂场景和相机运动。


<details>
  <summary>Details</summary>
Motivation: 从移动相机视角分离动态和静态物体对3D重建、自主导航和场景理解至关重要，现有方法依赖光流但效果有限。

Method: FoELS通过计算光流的扩展焦点（FoE）并结合纹理信息，生成初始运动似然，再与分割先验融合估计最终运动概率。

Result: 在DAVIS 2016数据集和真实交通视频中表现优异，达到先进水平。

Conclusion: FoELS能有效处理复杂场景、旋转相机运动和平行动态，性能优越。

Abstract: Separating moving and static objects from a moving camera viewpoint is
essential for 3D reconstruction, autonomous navigation, and scene understanding
in robotics. Existing approaches often rely primarily on optical flow, which
struggles to detect moving objects in complex, structured scenes involving
camera motion. To address this limitation, we propose Focus of Expansion
Likelihood and Segmentation (FoELS), a method based on the core idea of
integrating both optical flow and texture information. FoELS computes the focus
of expansion (FoE) from optical flow and derives an initial motion likelihood
from the outliers of the FoE computation. This likelihood is then fused with a
segmentation-based prior to estimate the final moving probability. The method
effectively handles challenges including complex structured scenes, rotational
camera motion, and parallel motion. Comprehensive evaluations on the DAVIS 2016
dataset and real-world traffic videos demonstrate its effectiveness and
state-of-the-art performance.

</details>


### [38] [EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation](https://arxiv.org/abs/2507.13648)
*Seungjun Moon,Sangjoon Yu,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: EPSilon提出了一种高效的混合3D头像生成方法，通过空射线省略（ERO）和空区间省略（EIO）策略减少计算成本，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于NeRF和SMPL的混合模型因变形计算成本高导致推理速度慢，EPSilon旨在通过优化采样策略解决这一问题。

Method: EPSilon采用ERO和EIO两种策略，分别省略空射线和空区间，减少无效采样点。

Result: EPSilon仅需3.9%的采样点，推理速度提升约20倍，训练收敛速度提升4倍。

Conclusion: EPSilon在保持生成质量的同时显著提升了效率，为3D头像生成提供了更实用的解决方案。

Abstract: The rapid advancement of neural radiance fields (NeRF) has paved the way to
generate animatable human avatars from a monocular video. However, the sole
usage of NeRF suffers from a lack of details, which results in the emergence of
hybrid representation that utilizes SMPL-based mesh together with NeRF
representation. While hybrid-based models show photo-realistic human avatar
generation qualities, they suffer from extremely slow inference due to their
deformation scheme: to be aligned with the mesh, hybrid-based models use the
deformation based on SMPL skinning weights, which needs high computational
costs on each sampled point. We observe that since most of the sampled points
are located in empty space, they do not affect the generation quality but
result in inference latency with deformation. In light of this observation, we
propose EPSilon, a hybrid-based 3D avatar generation scheme with novel
efficient point sampling strategies that boost both training and inference. In
EPSilon, we propose two methods to omit empty points at rendering; empty ray
omission (ERO) and empty interval omission (EIO). In ERO, we wipe out rays that
progress through the empty space. Then, EIO narrows down the sampling interval
on the ray, which wipes out the region not occupied by either clothes or mesh.
The delicate sampling scheme of EPSilon enables not only great computational
cost reduction during deformation but also the designation of the important
regions to be sampled, which enables a single-stage NeRF structure without
hierarchical sampling. Compared to existing methods, EPSilon maintains the
generation quality while using only 3.9% of sampled points and achieves around
20 times faster inference, together with 4 times faster training convergence.
We provide video results on https://github.com/seungjun-moon/epsilon.

</details>


### [39] [When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework](https://arxiv.org/abs/2507.13659)
*Xiao Wang,Qian Zhu,Shujuan Wu,Bo Jiang,Shiliang Zhang,Yaowei Wang,Yonghong Tian,Bin Luo*

Main category: cs.CV

TL;DR: 论文提出了一个大规模RGB-事件行人重识别数据集EvReID，并基于此提出了一种属性引导的对比学习框架TriPro-ReID。


<details>
  <summary>Details</summary>
Motivation: 解决现有事件相机行人重识别方法因数据稀缺而难以评估真实性能和泛化能力的问题。

Method: 构建EvReID数据集，并提出TriPro-ReID框架，结合RGB和事件流数据，利用行人属性增强特征学习。

Result: 在EvReID和MARS数据集上的实验验证了框架的有效性。

Conclusion: 提出的数据集和框架为未来研究提供了数据和基准支持。

Abstract: Recent researchers have proposed using event cameras for person
re-identification (ReID) due to their promising performance and better balance
in terms of privacy protection, event camera-based person ReID has attracted
significant attention. Currently, mainstream event-based person ReID algorithms
primarily focus on fusing visible light and event stream, as well as preserving
privacy. Although significant progress has been made, these methods are
typically trained and evaluated on small-scale or simulated event camera
datasets, making it difficult to assess their real identification performance
and generalization ability. To address the issue of data scarcity, this paper
introduces a large-scale RGB-event based person ReID dataset, called EvReID.
The dataset contains 118,988 image pairs and covers 1200 pedestrian identities,
with data collected across multiple seasons, scenes, and lighting conditions.
We also evaluate 15 state-of-the-art person ReID algorithms, laying a solid
foundation for future research in terms of both data and benchmarking. Based on
our newly constructed dataset, this paper further proposes a pedestrian
attribute-guided contrastive learning framework to enhance feature learning for
person re-identification, termed TriPro-ReID. This framework not only
effectively explores the visual features from both RGB frames and event
streams, but also fully utilizes pedestrian attributes as mid-level semantic
features. Extensive experiments on the EvReID dataset and MARS datasets fully
validated the effectiveness of our proposed RGB-Event person ReID framework.
The benchmark dataset and source code will be released on
https://github.com/Event-AHU/Neuromorphic_ReID

</details>


### [40] [Global Modeling Matters: A Fast, Lightweight and Effective Baseline for Efficient Image Restoration](https://arxiv.org/abs/2507.13663)
*Xingyu Jiang,Ning Gao,Hongkun Dou,Xiuhui Zhang,Xiaoqing Zhong,Yue Deng,Hongjue Li*

Main category: cs.CV

TL;DR: 论文提出了一种基于金字塔小波-傅里叶迭代管道的高效图像修复基线方法PW-FNet，通过多尺度分解和傅里叶变换替代自注意力机制，显著提升了修复质量和效率。


<details>
  <summary>Details</summary>
Motivation: 恶劣天气条件会显著降低自然图像质量，影响下游任务性能。现有基于Transformer的方法虽有效但复杂度高，难以实时处理。

Method: PW-FNet采用金字塔小波多输入多输出结构实现多尺度分解，并在块内用傅里叶变换替代自注意力机制，降低计算复杂度。

Result: 在多种修复任务中，PW-FNet在修复质量和效率上均优于现有方法，参数规模、计算成本和推理时间显著减少。

Conclusion: PW-FNet展示了小波-傅里叶处理在图像修复中的潜力，为高效修复提供了新思路。

Abstract: Natural image quality is often degraded by adverse weather conditions,
significantly impairing the performance of downstream tasks. Image restoration
has emerged as a core solution to this challenge and has been widely discussed
in the literature. Although recent transformer-based approaches have made
remarkable progress in image restoration, their increasing system complexity
poses significant challenges for real-time processing, particularly in
real-world deployment scenarios. To this end, most existing methods attempt to
simplify the self-attention mechanism, such as by channel self-attention or
state space model. However, these methods primarily focus on network
architecture while neglecting the inherent characteristics of image restoration
itself. In this context, we explore a pyramid Wavelet-Fourier iterative
pipeline to demonstrate the potential of Wavelet-Fourier processing for image
restoration. Inspired by the above findings, we propose a novel and efficient
restoration baseline, named Pyramid Wavelet-Fourier Network (PW-FNet).
Specifically, PW-FNet features two key design principles: 1) at the inter-block
level, integrates a pyramid wavelet-based multi-input multi-output structure to
achieve multi-scale and multi-frequency bands decomposition; and 2) at the
intra-block level, incorporates Fourier transforms as an efficient alternative
to self-attention mechanisms, effectively reducing computational complexity
while preserving global modeling capability. Extensive experiments on tasks
such as image deraining, raindrop removal, image super-resolution, motion
deblurring, image dehazing, image desnowing and underwater/low-light
enhancement demonstrate that PW-FNet not only surpasses state-of-the-art
methods in restoration quality but also achieves superior efficiency, with
significantly reduced parameter size, computational cost and inference time.

</details>


### [41] [MaskHOI: Robust 3D Hand-Object Interaction Estimation via Masked Pre-training](https://arxiv.org/abs/2507.13673)
*Yuechen Xie,Haobo Jiang,Jian Yang,Yigong Zhang,Jin Xie*

Main category: cs.CV

TL;DR: MaskHOI是一种基于掩码自编码器（MAE）的预训练框架，用于提升3D手-物交互（HOI）姿态估计的精度，通过区域特定掩码分配和掩码符号距离场（SDF）学习机制解决几何模糊和遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 解决单目RGB输入在3D手-物交互任务中因几何模糊和严重遮挡导致的姿态估计困难。

Method: 提出MaskHOI框架，包括区域特定掩码分配（区分手和刚性物体的掩码比例）和骨架驱动的手部掩码引导，以及掩码SDF驱动的多模态学习机制。

Result: 实验表明，MaskHOI显著优于现有最先进方法。

Conclusion: MaskHOI通过掩码重建和几何感知学习，有效提升了3D手-物交互姿态估计的精度和鲁棒性。

Abstract: In 3D hand-object interaction (HOI) tasks, estimating precise joint poses of
hands and objects from monocular RGB input remains highly challenging due to
the inherent geometric ambiguity of RGB images and the severe mutual occlusions
that occur during interaction.To address these challenges, we propose MaskHOI,
a novel Masked Autoencoder (MAE)-driven pretraining framework for enhanced HOI
pose estimation. Our core idea is to leverage the masking-then-reconstruction
strategy of MAE to encourage the feature encoder to infer missing spatial and
structural information, thereby facilitating geometric-aware and
occlusion-robust representation learning. Specifically, based on our
observation that human hands exhibit far greater geometric complexity than
rigid objects, conventional uniform masking fails to effectively guide the
reconstruction of fine-grained hand structures. To overcome this limitation, we
introduce a Region-specific Mask Ratio Allocation, primarily comprising the
region-specific masking assignment and the skeleton-driven hand masking
guidance. The former adaptively assigns lower masking ratios to hand regions
than to rigid objects, balancing their feature learning difficulty, while the
latter prioritizes masking critical hand parts (e.g., fingertips or entire
fingers) to realistically simulate occlusion patterns in real-world
interactions. Furthermore, to enhance the geometric awareness of the pretrained
encoder, we introduce a novel Masked Signed Distance Field (SDF)-driven
multimodal learning mechanism. Through the self-masking 3D SDF prediction, the
learned encoder is able to perceive the global geometric structure of hands and
objects beyond the 2D image plane, overcoming the inherent limitations of
monocular input and alleviating self-occlusion issues. Extensive experiments
demonstrate that our method significantly outperforms existing state-of-the-art
approaches.

</details>


### [42] [Gaussian kernel-based motion measurement](https://arxiv.org/abs/2507.13693)
*Hongyi Liu,Haifeng Wang*

Main category: cs.CV

TL;DR: 提出了一种基于高斯核的运动测量方法，用于高精度结构健康监测，无需手动参数调整。


<details>
  <summary>Details</summary>
Motivation: 结构健康监测需求增长，现有视觉方法在亚像素级运动测量中精度不足或需大量手动调参。

Method: 开发了基于高斯核的运动测量方法，引入运动一致性和超分辨率约束以提高精度和鲁棒性。

Result: 数值和实验验证表明，该方法无需定制参数即可达到高精度。

Conclusion: 新方法在结构健康监测中具有高精度和鲁棒性，适用于实际应用。

Abstract: The growing demand for structural health monitoring has driven increasing
interest in high-precision motion measurement, as structural information
derived from extracted motions can effectively reflect the current condition of
the structure. Among various motion measurement techniques, vision-based
methods stand out due to their low cost, easy installation, and large-scale
measurement. However, when it comes to sub-pixel-level motion measurement,
current vision-based methods either lack sufficient accuracy or require
extensive manual parameter tuning (e.g., pyramid layers, target pixels, and
filter parameters) to reach good precision. To address this issue, we developed
a novel Gaussian kernel-based motion measurement method, which can extract the
motion between different frames via tracking the location of Gaussian kernels.
The motion consistency, which fits practical structural conditions, and a
super-resolution constraint, are introduced to increase accuracy and robustness
of our method. Numerical and experimental validations show that it can
consistently reach high accuracy without customized parameter setup for
different test samples.

</details>


### [43] [GOSPA and T-GOSPA quasi-metrics for evaluation of multi-object tracking algorithms](https://arxiv.org/abs/2507.13706)
*Ángel F. García-Fernández,Jinhao Gu,Lennart Svensson,Yuxuan Xia,Jan Krejčí,Oliver Kost,Ondřej Straka*

Main category: cs.CV

TL;DR: 本文提出了两种用于多目标跟踪（MOT）算法性能评估的准度量，分别基于GOSPA和T-GOSPA的扩展，具有灵活的成本分配和非对称定位误差惩罚特性。


<details>
  <summary>Details</summary>
Motivation: 现有的GOSPA和T-GOSPA度量在多目标跟踪评估中缺乏灵活性，无法根据应用需求调整不同错误的惩罚成本。

Method: 扩展GOSPA和T-GOSPA度量，引入非对称定位误差惩罚和灵活的成本分配，并应用于贝叶斯MOT算法的仿真评估。

Result: 提出的准度量能够灵活调整对不同错误的惩罚成本，并在仿真中验证了其有效性。

Conclusion: 新准度量为MOT评估提供了更灵活的工具，适用于特定应用场景。

Abstract: This paper introduces two quasi-metrics for performance assessment of
multi-object tracking (MOT) algorithms. In particular, one quasi-metric is an
extension of the generalised optimal subpattern assignment (GOSPA) metric and
measures the discrepancy between sets of objects. The other quasi-metric is an
extension of the trajectory GOSPA (T-GOSPA) metric and measures the discrepancy
between sets of trajectories. Similar to the GOSPA-based metrics, these
quasi-metrics include costs for localisation error for properly detected
objects, the number of false objects and the number of missed objects. The
T-GOSPA quasi-metric also includes a track switching cost. Differently from the
GOSPA and T-GOSPA metrics, the proposed quasi-metrics have the flexibility of
penalising missed and false objects with different costs, and the localisation
costs are not required to be symmetric. These properties can be useful in MOT
evaluation in certain applications. The performance of several Bayesian MOT
algorithms is assessed with the T-GOSPA quasi-metric via simulations.

</details>


### [44] [PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement](https://arxiv.org/abs/2507.13708)
*Sofia Jamil,Bollampalli Areen Reddy,Raghvendra Kumar,Sriparna Saha,Koustava Goswami,K. J. Joseph*

Main category: cs.CV

TL;DR: 提出了一种无需训练的新方法PoemTale Diffusion，通过多阶段提示优化和自注意力机制改进，提升诗歌文本到图像生成的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在处理复杂、抽象的诗歌语言时表现不佳，导致信息丢失。

Method: 结合多阶段提示优化循环和自注意力机制改进，生成多张一致图像以传达诗歌含义。

Result: 通过人类和定量评估验证了方法的有效性，并发布了P4I诗歌数据集。

Conclusion: PoemTale Diffusion为诗歌到图像生成提供了新视角，增强了生成图像的信息捕捉能力。

Abstract: Recent advancements in text-to-image diffusion models have achieved
remarkable success in generating realistic and diverse visual content. A
critical factor in this process is the model's ability to accurately interpret
textual prompts. However, these models often struggle with creative
expressions, particularly those involving complex, abstract, or highly
descriptive language. In this work, we introduce a novel training-free approach
tailored to improve image generation for a unique form of creative language:
poetic verse, which frequently features layered, abstract, and dual meanings.
Our proposed PoemTale Diffusion approach aims to minimise the information that
is lost during poetic text-to-image conversion by integrating a multi stage
prompt refinement loop into Language Models to enhance the interpretability of
poetic texts. To support this, we adapt existing state-of-the-art diffusion
models by modifying their self-attention mechanisms with a consistent
self-attention technique to generate multiple consistent images, which are then
collectively used to convey the poem's meaning. Moreover, to encourage research
in the field of poetry, we introduce the P4I (PoemForImage) dataset, consisting
of 1111 poems sourced from multiple online and offline resources. We engaged a
panel of poetry experts for qualitative assessments. The results from both
human and quantitative evaluations validate the efficacy of our method and
contribute a novel perspective to poem-to-image generation with enhanced
information capture in the generated images.

</details>


### [45] [Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction](https://arxiv.org/abs/2507.13719)
*Daniele Pannone,Alessia Castronovo,Maurizio Mancini,Gian Luca Foresti,Claudio Piciarelli,Rossana Gabrieli,Muhammad Yasir Bilal,Danilo Avola*

Main category: cs.CV

TL;DR: 本文提出了一种创新的增强现实流程，专为博物馆环境设计，旨在从单张图像中识别艺术品并生成精确的3D模型。


<details>
  <summary>Details</summary>
Motivation: 通过结合两种互补的预训练深度估计模型，解决艺术品不规则轮廓和可变纹理带来的挑战，以提升博物馆的互动数字体验。

Method: 整合GLPN和Depth-Anything模型，生成优化的深度图，并转换为高质量点云和网格，结合先进的神经网络和计算机视觉技术。

Result: 实验结果显示重建精度和视觉真实感显著提升，系统成为博物馆增强访客互动体验的强有力工具。

Conclusion: 该方法为博物馆提供了一种高效且稳健的解决方案，通过沉浸式AR体验提升访客参与度。

Abstract: This paper presents an innovative augmented reality pipeline tailored for
museum environments, aimed at recognizing artworks and generating accurate 3D
models from single images. By integrating two complementary pre-trained depth
estimation models, i.e., GLPN for capturing global scene structure and
Depth-Anything for detailed local reconstruction, the proposed approach
produces optimized depth maps that effectively represent complex artistic
features. These maps are then converted into high-quality point clouds and
meshes, enabling the creation of immersive AR experiences. The methodology
leverages state-of-the-art neural network architectures and advanced computer
vision techniques to overcome challenges posed by irregular contours and
variable textures in artworks. Experimental results demonstrate significant
improvements in reconstruction accuracy and visual realism, making the system a
highly robust tool for museums seeking to enhance visitor engagement through
interactive digital content.

</details>


### [46] [Tackling fake images in cybersecurity -- Interpretation of a StyleGAN and lifting its black-box](https://arxiv.org/abs/2507.13722)
*Julia Laubmann,Johannes Reschke*

Main category: cs.CV

TL;DR: 论文分析了StyleGAN生成器的内部机制，探讨了其关键技术和潜在伦理风险。


<details>
  <summary>Details</summary>
Motivation: 研究旨在深入理解StyleGAN生成器的工作原理，揭示其高效生成逼真图像的机制。

Method: 通过PyTorch框架训练StyleGAN模型，分析权重剪枝和潜在向量的作用。

Result: 发现大量权重可被剪枝而不显著影响输出，且潜在向量能精确控制生成图像的特征。

Conclusion: 研究揭示了StyleGAN的高效性和可操控性，同时强调了其潜在的伦理风险。

Abstract: In today's digital age, concerns about the dangers of AI-generated images are
increasingly common. One powerful tool in this domain is StyleGAN (style-based
generative adversarial networks), a generative adversarial network capable of
producing highly realistic synthetic faces. To gain a deeper understanding of
how such a model operates, this work focuses on analyzing the inner workings of
StyleGAN's generator component. Key architectural elements and techniques, such
as the Equalized Learning Rate, are explored in detail to shed light on the
model's behavior. A StyleGAN model is trained using the PyTorch framework,
enabling direct inspection of its learned weights. Through pruning, it is
revealed that a significant number of these weights can be removed without
drastically affecting the output, leading to reduced computational
requirements. Moreover, the role of the latent vector -- which heavily
influences the appearance of the generated faces -- is closely examined. Global
alterations to this vector primarily affect aspects like color tones, while
targeted changes to individual dimensions allow for precise manipulation of
specific facial features. This ability to finetune visual traits is not only of
academic interest but also highlights a serious ethical concern: the potential
misuse of such technology. Malicious actors could exploit this capability to
fabricate convincing fake identities, posing significant risks in the context
of digital deception and cybercrime.

</details>


### [47] [Can Synthetic Images Conquer Forgetting? Beyond Unexplored Doubts in Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2507.13739)
*Junsu Kim,Yunhoe Ku,Seungryul Baek*

Main category: cs.CV

TL;DR: Diffusion-FSCIL利用冻结的文本到图像扩散模型解决少样本类增量学习问题，通过多尺度特征提取和潜在重放提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决少样本类增量学习中数据稀缺和灾难性遗忘的挑战。

Method: 采用冻结的扩散模型作为主干，提取多尺度特征并辅以特征蒸馏，减少生成偏差。

Result: 在CUB-200、miniImageNet和CIFAR-100上超越现有方法，保持旧类性能并适应新类。

Conclusion: Diffusion-FSCIL通过生成模型的能力和高效设计，有效解决了FSCIL问题。

Abstract: Few-shot class-incremental learning (FSCIL) is challenging due to extremely
limited training data; while aiming to reduce catastrophic forgetting and learn
new information. We propose Diffusion-FSCIL, a novel approach that employs a
text-to-image diffusion model as a frozen backbone. Our conjecture is that
FSCIL can be tackled using a large generative model's capabilities benefiting
from 1) generation ability via large-scale pre-training; 2) multi-scale
representation; 3) representational flexibility through the text encoder. To
maximize the representation capability, we propose to extract multiple
complementary diffusion features to play roles as latent replay with slight
support from feature distillation for preventing generative biases. Our
framework realizes efficiency through 1) using a frozen backbone; 2) minimal
trainable components; 3) batch processing of multiple feature extractions.
Extensive experiments on CUB-200, \emph{mini}ImageNet, and CIFAR-100 show that
Diffusion-FSCIL surpasses state-of-the-art methods, preserving performance on
previously learned classes and adapting effectively to new ones.

</details>


### [48] [Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis](https://arxiv.org/abs/2507.13753)
*Tongtong Su,Chengyu Wang,Bingyan Liu,Jun Huang,Dongming Lu*

Main category: cs.CV

TL;DR: EVS是一种无需训练的封装视频合成器，结合T2I和T2V模型，提升生成视频的视觉保真度和运动平滑性。


<details>
  <summary>Details</summary>
Motivation: 现有T2V模型在生成高质量视频时存在画面闪烁和伪影问题，需改进视觉和运动表现。

Method: 利用预训练的T2I模型优化低质量视频帧，结合T2V模型确保运动一致性，通过噪声和去噪步骤优化。

Result: 实验证明EVS在视觉和运动质量上优于现有方法，推理速度提升1.6-4.5倍。

Conclusion: EVS通过结合T2I和T2V模型的优势，显著提升了视频生成的质量和效率。

Abstract: In recent years, large text-to-video (T2V) synthesis models have garnered
considerable attention for their abilities to generate videos from textual
descriptions. However, achieving both high imaging quality and effective motion
representation remains a significant challenge for these T2V models. Existing
approaches often adapt pre-trained text-to-image (T2I) models to refine video
frames, leading to issues such as flickering and artifacts due to
inconsistencies across frames. In this paper, we introduce EVS, a training-free
Encapsulated Video Synthesizer that composes T2I and T2V models to enhance both
visual fidelity and motion smoothness of generated videos. Our approach
utilizes a well-trained diffusion-based T2I model to refine low-quality video
frames by treating them as out-of-distribution samples, effectively optimizing
them with noising and denoising steps. Meanwhile, we employ T2V backbones to
ensure consistent motion dynamics. By encapsulating the T2V temporal-only prior
into the T2I generation process, EVS successfully leverages the strengths of
both types of models, resulting in videos of improved imaging and motion
quality. Experimental results validate the effectiveness of our approach
compared to previous approaches. Our composition process also leads to a
significant improvement of 1.6x-4.5x speedup in inference time. Source codes:
https://github.com/Tonniia/EVS.

</details>


### [49] [Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction](https://arxiv.org/abs/2507.13769)
*Mingyang Yu,Zhijian Wu,Dingjiang Huang*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的光谱扩散先验（SDP）和光谱先验注入模块（SPIM），用于提升高光谱图像（HSI）重建的高频细节捕捉能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在高光谱图像重建中难以准确捕捉高频细节，需要一种更有效的方法。

Method: 通过扩散模型隐式学习光谱扩散先验（SDP），并结合动态指导的光谱先验注入模块（SPIM）提升重建效果。

Result: 在MST和BISRNet两种代表性HSI方法上，性能提升约0.5 dB。

Conclusion: SDP和SPIM显著提升了HSI重建的细节恢复能力。

Abstract: Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its
degraded 2D measurements. Recently great progress has been made in deep
learning-based methods, however, these methods often struggle to accurately
capture high-frequency details of the HSI. To address this issue, this paper
proposes a Spectral Diffusion Prior (SDP) that is implicitly learned from
hyperspectral images using a diffusion model. Leveraging the powerful ability
of the diffusion model to reconstruct details, this learned prior can
significantly improve the performance when injected into the HSI model. To
further improve the effectiveness of the learned prior, we also propose the
Spectral Prior Injector Module (SPIM) to dynamically guide the model to recover
the HSI details. We evaluate our method on two representative HSI methods: MST
and BISRNet. Experimental results show that our method outperforms existing
networks by about 0.5 dB, effectively improving the performance of HSI
reconstruction.

</details>


### [50] [Feature Engineering is Not Dead: Reviving Classical Machine Learning with Entropy, HOG, and LBP Feature Fusion for Image Classification](https://arxiv.org/abs/2507.13772)
*Abhijit Sen,Giridas Maiti,Bikram K. Parida,Bhanu P. Mishra,Mahima Arya,Denys I. Bondar*

Main category: cs.CV

TL;DR: 论文提出了一种基于排列熵（PE）的图像分类方法，结合HOG和LBP特征，通过SVM分类器在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 在图像分类中，当需要解释性和计算效率时，传统机器学习方法仍具优势。本文探索PE在图像中的应用，结合经典特征提取方法，提供轻量级且可解释的解决方案。

Method: 将PE扩展到二维图像，结合HOG和LBP提取多尺度、多方向特征，训练SVM分类器。

Result: 在Fashion-MNIST等数据集上表现优异，证明了PE与HOG、LBP结合的有效性。

Conclusion: PE结合经典特征提取方法为图像分类提供了轻量、可解释的替代方案，展示了熵描述符的潜力。

Abstract: Feature engineering continues to play a critical role in image
classification, particularly when interpretability and computational efficiency
are prioritized over deep learning models with millions of parameters. In this
study, we revisit classical machine learning based image classification through
a novel approach centered on Permutation Entropy (PE), a robust and
computationally lightweight measure traditionally used in time series analysis
but rarely applied to image data. We extend PE to two-dimensional images and
propose a multiscale, multi-orientation entropy-based feature extraction
approach that characterizes spatial order and complexity along rows, columns,
diagonals, anti-diagonals, and local patches of the image. To enhance the
discriminatory power of the entropy features, we integrate two classic image
descriptors: the Histogram of Oriented Gradients (HOG) to capture shape and
edge structure, and Local Binary Patterns (LBP) to encode micro-texture of an
image. The resulting hand-crafted feature set, comprising of 780 dimensions, is
used to train Support Vector Machine (SVM) classifiers optimized through grid
search. The proposed approach is evaluated on multiple benchmark datasets,
including Fashion-MNIST, KMNIST, EMNIST, and CIFAR-10, where it delivers
competitive classification performance without relying on deep architectures.
Our results demonstrate that the fusion of PE with HOG and LBP provides a
compact, interpretable, and effective alternative to computationally expensive
and limited interpretable deep learning models. This shows a potential of
entropy-based descriptors in image classification and contributes a lightweight
and generalizable solution to interpretable machine learning in image
classification and computer vision.

</details>


### [51] [Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions](https://arxiv.org/abs/2507.13773)
*Pu Jian,Donglei Yu,Wen Yang,Shuo Ren,Jiajun Zhang*

Main category: cs.CV

TL;DR: 论文提出了ClearVQA基准，用于评估视觉语言模型（VLM）通过交互解决模糊问题的能力，填补了现有研究的空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要通过重述问题解决模糊性，忽略了用户反馈的交互性。缺乏评估VLM交互能力的基准，且VLM倾向于回答而非提问。

Method: 引入ClearVQA基准，针对VQA中三类常见模糊问题，覆盖多种VQA场景。

Result: ClearVQA为评估VLM交互解决模糊问题的能力提供了标准化工具。

Conclusion: ClearVQA填补了交互式模糊问题解决的评估空白，为未来研究提供了方向。

Abstract: In visual question answering (VQA) context, users often pose ambiguous
questions to visual language models (VLMs) due to varying expression habits.
Existing research addresses such ambiguities primarily by rephrasing questions.
These approaches neglect the inherently interactive nature of user interactions
with VLMs, where ambiguities can be clarified through user feedback. However,
research on interactive clarification faces two major challenges: (1)
Benchmarks are absent to assess VLMs' capacity for resolving ambiguities
through interaction; (2) VLMs are trained to prefer answering rather than
asking, preventing them from seeking clarification. To overcome these
challenges, we introduce \textbf{ClearVQA} benchmark, which targets three
common categories of ambiguity in VQA context, and encompasses various VQA
scenarios.

</details>


### [52] [SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering](https://arxiv.org/abs/2507.13779)
*Durgesh Singh,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 论文提出了一种显式可微分聚类模块，用于半监督学习和无监督域适应，通过利用监督数据计算聚类中心，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 半监督学习和无监督域适应通过利用标记和未标记数据提升模型性能，但现有方法通常隐式地利用聚类假设。本文旨在显式地引入可微分聚类模块，以更直接地利用监督数据。

Method: 提出了一种端到端的训练策略，显式地引入可微分聚类模块，并利用监督数据计算聚类中心。

Result: 实验表明，该方法在半监督学习和无监督域适应任务中表现优异，尤其在低监督条件下，既可作为独立模型，也可作为现有方法的正则化器。

Conclusion: 显式引入可微分聚类模块是一种有效的策略，能够显著提升半监督学习和无监督域适应的性能，尤其在低监督条件下表现突出。

Abstract: Semi-Supervised Learning (SSL) and Unsupervised Domain Adaptation (UDA)
enhance the model performance by exploiting information from labeled and
unlabeled data. The clustering assumption has proven advantageous for learning
with limited supervision and states that data points belonging to the same
cluster in a high-dimensional space should be assigned to the same category.
Recent works have utilized different training mechanisms to implicitly enforce
this assumption for the SSL and UDA. In this work, we take a different approach
by explicitly involving a differentiable clustering module which is extended to
leverage the supervised data to compute its centroids. We demonstrate the
effectiveness of our straightforward end-to-end training strategy for SSL and
UDA over extensive experiments and highlight its benefits, especially in low
supervision regimes, both as a standalone model and as a regularizer for
existing approaches.

</details>


### [53] [Localized FNO for Spatiotemporal Hemodynamic Upsampling in Aneurysm MRI](https://arxiv.org/abs/2507.13789)
*Kyriakos Flouris,Moritz Halter,Yolanne Y. R. Lee,Samuel Castonguay,Luuk Jacobs,Pietro Dirix,Jonathan Nestmann,Sebastian Kozerke,Ender Konukoglu*

Main category: cs.CV

TL;DR: 提出了一种名为LoFNO的新型3D架构，通过结合几何先验和神经算子框架，提升血流数据的时空分辨率，直接预测壁面剪切应力（WSS），优于传统方法和深度学习替代方案。


<details>
  <summary>Details</summary>
Motivation: 磁共振血流成像的低时空分辨率和信噪比限制了其诊断价值，因此需要一种方法提升分辨率并直接预测WSS。

Method: 提出LoFNO架构，整合拉普拉斯特征向量作为几何先验，结合EDSR层进行稳健上采样，直接从临床影像数据预测WSS。

Result: LoFNO在去噪和时空上采样方面表现优异，速度和WSS预测优于插值和其他深度学习方法。

Conclusion: LoFNO为脑血管诊断提供了更精确的工具，提升了血流分析的时空分辨率。

Abstract: Hemodynamic analysis is essential for predicting aneurysm rupture and guiding
treatment. While magnetic resonance flow imaging enables time-resolved
volumetric blood velocity measurements, its low spatiotemporal resolution and
signal-to-noise ratio limit its diagnostic utility. To address this, we propose
the Localized Fourier Neural Operator (LoFNO), a novel 3D architecture that
enhances both spatial and temporal resolution with the ability to predict wall
shear stress (WSS) directly from clinical imaging data. LoFNO integrates
Laplacian eigenvectors as geometric priors for improved structural awareness on
irregular, unseen geometries and employs an Enhanced Deep Super-Resolution
Network (EDSR) layer for robust upsampling. By combining geometric priors with
neural operator frameworks, LoFNO de-noises and spatiotemporally upsamples flow
data, achieving superior velocity and WSS predictions compared to interpolation
and alternative deep learning methods, enabling more precise cerebrovascular
diagnostics.

</details>


### [54] [DynFaceRestore: Balancing Fidelity and Quality in Diffusion-Guided Blind Face Restoration with Dynamic Blur-Level Mapping and Guidance](https://arxiv.org/abs/2507.13797)
*Huu-Phu Do,Yu-Wei Chen,Yi-Cheng Liao,Chi-Wei Hsiao,Han-Yang Wang,Wei-Chen Chiu,Ching-Chun Huang*

Main category: cs.CV

TL;DR: DynFaceRestore提出了一种动态盲脸修复方法，通过动态选择扩散起始时间步和局部调整引导强度，平衡了保真度和细节生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法因固定扩散采样时间步和全局引导尺度，导致保真度与质量不平衡。

Method: 利用模糊图像和高斯核动态选择扩散起始时间步，并引入动态引导缩放调整器。

Result: 在定量和定性评估中达到最先进性能。

Conclusion: DynFaceRestore在盲脸修复中表现出鲁棒性和高效性。

Abstract: Blind Face Restoration aims to recover high-fidelity, detail-rich facial
images from unknown degraded inputs, presenting significant challenges in
preserving both identity and detail. Pre-trained diffusion models have been
increasingly used as image priors to generate fine details. Still, existing
methods often use fixed diffusion sampling timesteps and a global guidance
scale, assuming uniform degradation. This limitation and potentially imperfect
degradation kernel estimation frequently lead to under- or over-diffusion,
resulting in an imbalance between fidelity and quality. We propose
DynFaceRestore, a novel blind face restoration approach that learns to map any
blindly degraded input to Gaussian blurry images. By leveraging these blurry
images and their respective Gaussian kernels, we dynamically select the
starting timesteps for each blurry image and apply closed-form guidance during
the diffusion sampling process to maintain fidelity. Additionally, we introduce
a dynamic guidance scaling adjuster that modulates the guidance strength across
local regions, enhancing detail generation in complex areas while preserving
structural fidelity in contours. This strategy effectively balances the
trade-off between fidelity and quality. DynFaceRestore achieves
state-of-the-art performance in both quantitative and qualitative evaluations,
demonstrating robustness and effectiveness in blind face restoration.

</details>


### [55] [One Step Closer: Creating the Future to Boost Monocular Semantic Scene Completion](https://arxiv.org/abs/2507.13801)
*Haoang Lu,Yuanqi Su,Xiaoning Zhang,Hao Hu*

Main category: cs.CV

TL;DR: 论文提出了一种新的时序3D语义场景补全框架CF-SSC，通过预测伪未来帧扩展感知范围，提升遮挡推理和场景补全精度。


<details>
  <summary>Details</summary>
Motivation: 现有单目SSC方法在真实交通场景中难以处理遮挡和视野外区域，限制了其实际应用。

Method: 结合位姿和深度建立3D对应关系，通过3D感知架构显式建模时空关系，融合过去、当前和预测的未来帧。

Result: 在SemanticKITTI和SSCBench-KITTI-360基准测试中达到最先进性能。

Conclusion: CF-SSC通过时序信息显著提升了遮挡推理和3D场景补全的准确性。

Abstract: In recent years, visual 3D Semantic Scene Completion (SSC) has emerged as a
critical perception task for autonomous driving due to its ability to infer
complete 3D scene layouts and semantics from single 2D images. However, in
real-world traffic scenarios, a significant portion of the scene remains
occluded or outside the camera's field of view -- a fundamental challenge that
existing monocular SSC methods fail to address adequately. To overcome these
limitations, we propose Creating the Future SSC (CF-SSC), a novel temporal SSC
framework that leverages pseudo-future frame prediction to expand the model's
effective perceptual range. Our approach combines poses and depths to establish
accurate 3D correspondences, enabling geometrically-consistent fusion of past,
present, and predicted future frames in 3D space. Unlike conventional methods
that rely on simple feature stacking, our 3D-aware architecture achieves more
robust scene completion by explicitly modeling spatial-temporal relationships.
Comprehensive experiments on SemanticKITTI and SSCBench-KITTI-360 benchmarks
demonstrate state-of-the-art performance, validating the effectiveness of our
approach, highlighting our method's ability to improve occlusion reasoning and
3D scene completion accuracy.

</details>


### [56] [GRAM-MAMBA: Holistic Feature Alignment for Wireless Perception with Adaptive Low-Rank Compensation](https://arxiv.org/abs/2507.13803)
*Weiqi Yang,Xu Zhou,Jingfu Guan,Hao Du,Tianyu Bai*

Main category: cs.CV

TL;DR: GRAM-MAMBA框架通过线性复杂度的Mamba模型和优化的GRAM矩阵策略，解决了多模态融合中的效率、模态对齐和鲁棒性问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有IoT多模态感知系统存在模型复杂度高、模态对齐不充分和鲁棒性差的问题，亟需高效且稳健的解决方案。

Method: 结合线性复杂度的Mamba模型和GRAM矩阵策略进行模态对齐，引入低秩自适应层补偿策略处理缺失模态。

Result: 在SPAWC2021和USC-HAD数据集上，GRAM-MAMBA显著优于基线方法，性能提升显著且参数训练量极低。

Conclusion: GRAM-MAMBA为资源受限环境下的高效鲁棒多模态感知提供了有效解决方案。

Abstract: Multi-modal fusion is crucial for Internet of Things (IoT) perception, widely
deployed in smart homes, intelligent transport, industrial automation, and
healthcare. However, existing systems often face challenges: high model
complexity hinders deployment in resource-constrained environments,
unidirectional modal alignment neglects inter-modal relationships, and
robustness suffers when sensor data is missing. These issues impede efficient
and robust multimodal perception in real-world IoT settings. To overcome these
limitations, we propose GRAM-MAMBA. This framework utilizes the
linear-complexity Mamba model for efficient sensor time-series processing,
combined with an optimized GRAM matrix strategy for pairwise alignment among
modalities, addressing the shortcomings of traditional single-modality
alignment. Inspired by Low-Rank Adaptation (LoRA), we introduce an adaptive
low-rank layer compensation strategy to handle missing modalities
post-training. This strategy freezes the pre-trained model core and irrelevant
adaptive layers, fine-tuning only those related to available modalities and the
fusion process. Extensive experiments validate GRAM-MAMBA's effectiveness. On
the SPAWC2021 indoor positioning dataset, the pre-trained model shows lower
error than baselines; adapting to missing modalities yields a 24.5% performance
boost by training less than 0.2% of parameters. On the USC-HAD human activity
recognition dataset, it achieves 93.55% F1 and 93.81% Overall Accuracy (OA),
outperforming prior work; the update strategy increases F1 by 23% while
training less than 0.3% of parameters. These results highlight GRAM-MAMBA's
potential for achieving efficient and robust multimodal perception in
resource-constrained environments.

</details>


### [57] [SkySense V2: A Unified Foundation Model for Multi-modal Remote Sensing](https://arxiv.org/abs/2507.13812)
*Yingying Zhang,Lixiang Ru,Kang Wu,Lei Yu,Lei Liang,Yansheng Li,Jingdong Chen*

Main category: cs.CV

TL;DR: SkySense V2是一个统一的多模态遥感基础模型，通过单一Transformer主干处理多模态数据，采用自适应SSL策略和MoE模块，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要为每种数据模态训练单独的主干网络，导致冗余和低效，且预训练方法未充分考虑遥感图像的特性。

Method: SkySense V2使用单一Transformer主干，结合自适应SSL策略、自适应补丁合并模块、可学习模态提示令牌和MoE模块。

Result: 在7个任务的16个数据集上评估，平均性能比SkySense提升1.8分。

Conclusion: SkySense V2通过统一架构和针对性优化，显著提升了多模态遥感任务的性能。

Abstract: The multi-modal remote sensing foundation model (MM-RSFM) has significantly
advanced various Earth observation tasks, such as urban planning, environmental
monitoring, and natural disaster management. However, most existing approaches
generally require the training of separate backbone networks for each data
modality, leading to redundancy and inefficient parameter utilization.
Moreover, prevalent pre-training methods typically apply self-supervised
learning (SSL) techniques from natural images without adequately accommodating
the characteristics of remote sensing (RS) images, such as the complicated
semantic distribution within a single RS image. In this work, we present
SkySense V2, a unified MM-RSFM that employs a single transformer backbone to
handle multiple modalities. This backbone is pre-trained with a novel SSL
strategy tailored to the distinct traits of RS data. In particular, SkySense V2
incorporates an innovative adaptive patch merging module and learnable modality
prompt tokens to address challenges related to varying resolutions and limited
feature diversity across modalities. In additional, we incorporate the mixture
of experts (MoE) module to further enhance the performance of the foundation
model. SkySense V2 demonstrates impressive generalization abilities through an
extensive evaluation involving 16 datasets over 7 tasks, outperforming SkySense
by an average of 1.8 points.

</details>


### [58] [Team of One: Cracking Complex Video QA with Model Synergy](https://arxiv.org/abs/2507.13820)
*Jun Xie,Zhaoran Zhao,Xiongjun Guan,Yingjian Zhu,Hongzhu Yi,Xinming Wang,Feng Chen,Zhepeng Wang*

Main category: cs.CV

TL;DR: 提出了一种新颖的开放视频问答框架，通过多模型协同和结构化思维链提升推理深度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视频-语言大模型（Video-LMMs）在复杂场景中表现不足，如上下文理解有限、时序建模弱、泛化能力差。

Method: 引入提示-响应集成机制，协调多个异构视频-语言模型（VLMs），结合外部大语言模型（LLM）作为评估和集成器。

Result: 在CVRR-ES数据集上显著优于现有基线，表现出更强的泛化能力和鲁棒性。

Conclusion: 提供了一种轻量级、可扩展的多模态推理策略，无需重新训练模型，为未来Video-LMM发展奠定基础。

Abstract: We propose a novel framework for open-ended video question answering that
enhances reasoning depth and robustness in complex real-world scenarios, as
benchmarked on the CVRR-ES dataset. Existing Video-Large Multimodal Models
(Video-LMMs) often exhibit limited contextual understanding, weak temporal
modeling, and poor generalization to ambiguous or compositional queries. To
address these challenges, we introduce a prompting-and-response integration
mechanism that coordinates multiple heterogeneous Video-Language Models (VLMs)
via structured chains of thought, each tailored to distinct reasoning pathways.
An external Large Language Model (LLM) serves as an evaluator and integrator,
selecting and fusing the most reliable responses. Extensive experiments
demonstrate that our method significantly outperforms existing baselines across
all evaluation metrics, showcasing superior generalization and robustness. Our
approach offers a lightweight, extensible strategy for advancing multimodal
reasoning without requiring model retraining, setting a strong foundation for
future Video-LMM development.

</details>


### [59] [A Quantum-assisted Attention U-Net for Building Segmentation over Tunis using Sentinel-1 Data](https://arxiv.org/abs/2507.13852)
*Luigi Russo,Francesco Mauro,Babak Memar,Alessandro Sebastianelli,Silvia Liberata Ullo,Paolo Gamba*

Main category: cs.CV

TL;DR: 论文研究了在突尼斯城市景观中，利用Quanvolution预处理增强Attention U-Net模型进行建筑物分割的效果，结果表明该方法在保持精度的同时减少了网络参数。


<details>
  <summary>Details</summary>
Motivation: 城市规划和灾害响应等领域需要精确的建筑物分割，但高分辨率卫星图像的处理存在挑战。

Method: 采用Quanvolution预处理提取SAR图像中的特征，结合Attention U-Net模型进行建筑物分割。

Result: 方法在测试精度上与标准模型相当，同时显著减少了网络参数，提高了计算效率。

Conclusion: 量子辅助深度学习框架在大规模城市建筑物分割中具有潜力。

Abstract: Building segmentation in urban areas is essential in fields such as urban
planning, disaster response, and population mapping. Yet accurately segmenting
buildings in dense urban regions presents challenges due to the large size and
high resolution of satellite images. This study investigates the use of a
Quanvolutional pre-processing to enhance the capability of the Attention U-Net
model in the building segmentation. Specifically, this paper focuses on the
urban landscape of Tunis, utilizing Sentinel-1 Synthetic Aperture Radar (SAR)
imagery. In this work, Quanvolution was used to extract more informative
feature maps that capture essential structural details in radar imagery,
proving beneficial for accurate building segmentation. Preliminary results
indicate that proposed methodology achieves comparable test accuracy to the
standard Attention U-Net model while significantly reducing network parameters.
This result aligns with findings from previous works, confirming that
Quanvolution not only maintains model accuracy but also increases computational
efficiency. These promising outcomes highlight the potential of
quantum-assisted Deep Learning frameworks for large-scale building segmentation
in urban environments.

</details>


### [60] [Depth3DLane: Fusing Monocular 3D Lane Detection with Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2507.13857)
*Max van den Hoven,Kishaan Jeeveswaran,Pieter Piscaer,Thijs Wensveen,Elahe Arani,Bahram Zonooz*

Main category: cs.CV

TL;DR: Depth3DLane提出了一种双路径框架，结合自监督深度估计，无需昂贵传感器或额外深度数据，实现了单目3D车道检测。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵的深度传感器或难以大规模获取的深度数据，且假设相机参数已知，限制了在无标定场景中的应用。

Method: 通过自监督深度网络生成点云，结合鸟瞰图和前视图路径提取空间和语义信息，使用3D车道锚点采样特征，并预测相机参数。

Result: 在OpenLane基准测试中表现优异，且无需标定相机参数即可应用。

Conclusion: Depth3DLane解决了现有方法的局限性，适用于无标定场景，具有广泛的应用潜力。

Abstract: Monocular 3D lane detection is essential for autonomous driving, but
challenging due to the inherent lack of explicit spatial information.
Multi-modal approaches rely on expensive depth sensors, while methods
incorporating fully-supervised depth networks rely on ground-truth depth data
that is impractical to collect at scale. Additionally, existing methods assume
that camera parameters are available, limiting their applicability in scenarios
like crowdsourced high-definition (HD) lane mapping. To address these
limitations, we propose Depth3DLane, a novel dual-pathway framework that
integrates self-supervised monocular depth estimation to provide explicit
structural information, without the need for expensive sensors or additional
ground-truth depth data. Leveraging a self-supervised depth network to obtain a
point cloud representation of the scene, our bird's-eye view pathway extracts
explicit spatial information, while our front view pathway simultaneously
extracts rich semantic information. Depth3DLane then uses 3D lane anchors to
sample features from both pathways and infer accurate 3D lane geometry.
Furthermore, we extend the framework to predict camera parameters on a
per-frame basis and introduce a theoretically motivated fitting procedure to
enhance stability on a per-segment basis. Extensive experiments demonstrate
that Depth3DLane achieves competitive performance on the OpenLane benchmark
dataset. Furthermore, experimental results show that using learned parameters
instead of ground-truth parameters allows Depth3DLane to be applied in
scenarios where camera calibration is infeasible, unlike previous methods.

</details>


### [61] [PositionIC: Unified Position and Identity Consistency for Image Customization](https://arxiv.org/abs/2507.13861)
*Junjie Hu,Tianyang Han,Kai Ma,Jialin Gao,Hao Dou,Song Yang,Xianhua He,Jianhui Zhang,Junfeng Luo,Xiaoming Wei,Wenqiang Zhang*

Main category: cs.CV

TL;DR: PositionIC是一个统一框架，通过位置和身份一致性实现多主题图像定制，解决了现有方法在细粒度空间控制上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有图像定制方法在实体级空间控制上存在不足，缺乏绑定身份与精确位置的可扩展数据集。

Method: 构建双向生成范式的可扩展合成管道，设计轻量级位置调制层解耦空间嵌入。

Result: 实验表明，PositionIC能实现精确空间控制并保持高一致性。

Conclusion: PositionIC为开放世界多实体场景的可控高保真图像定制提供了新方向。

Abstract: Recent subject-driven image customization has achieved significant
advancements in fidelity, yet fine-grained entity-level spatial control remains
elusive, hindering the broader real-world application. This limitation is
mainly attributed to scalable datasets that bind identity with precise
positional cues are absent. To this end, we introduce PositionIC, a unified
framework that enforces position and identity consistency for multi-subject
customization. We construct a scalable synthesis pipeline that employs a
bidirectional generation paradigm to eliminate subject drift and maintain
semantic coherence. On top of these data, we design a lightweight positional
modulation layer that decouples spatial embeddings among subjects, enabling
independent, accurate placement while preserving visual fidelity. Extensive
experiments demonstrate that our approach can achieve precise spatial control
while maintaining high consistency in image customization task. PositionIC
paves the way for controllable, high-fidelity image customization in
open-world, multi-entity scenarios and will be released to foster further
research.

</details>


### [62] [When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models](https://arxiv.org/abs/2507.13868)
*Francesco Ortu,Zhijing Jin,Diego Doimo,Alberto Cazzaniga*

Main category: cs.CV

TL;DR: 论文研究了视觉语言模型（VLMs）在内部参数知识与外部信息冲突时的机制，通过引入多模态反事实查询数据集，定位了控制冲突的关键头部，并展示了如何通过修改这些头部来引导模型行为。


<details>
  <summary>Details</summary>
Motivation: 解决VLMs在处理内部知识与外部信息冲突时的机制不明问题，以减少幻觉和不可靠响应。

Method: 引入多模态反事实查询数据集，通过logit检查定位关键头部，并修改这些头部以引导模型行为。

Result: 发现少量头部控制冲突，修改后可引导模型偏向内部知识或视觉输入；这些头部的注意力定位能力优于基于梯度的归因方法。

Conclusion: 研究揭示了VLMs处理知识冲突的机制，为模型优化提供了新方向。

Abstract: Vision-language models (VLMs) increasingly leverage diverse knowledge sources
to address complex tasks, often encountering conflicts between their internal
parametric knowledge and external information. Knowledge conflicts can result
in hallucinations and unreliable responses, but the mechanisms governing such
interactions remain unknown. To address this gap, we analyze the mechanisms
that VLMs use to resolve cross-modal conflicts by introducing a dataset of
multimodal counterfactual queries that deliberately contradict internal
commonsense knowledge. We localize with logit inspection a small set of heads
that control the conflict. Moreover, by modifying these heads, we can steer the
model towards its internal knowledge or the visual inputs. Finally, we show
that attention from such heads pinpoints localized image regions driving visual
overrides, outperforming gradient-based attribution in precision.

</details>


### [63] [Real-Time Fusion of Visual and Chart Data for Enhanced Maritime Vision](https://arxiv.org/abs/2507.13880)
*Marten Kreis,Benjamin Kiefer*

Main category: cs.CV

TL;DR: 提出了一种通过融合实时视觉数据和海图信息来增强海洋视觉的新方法，利用基于transformer的端到端神经网络实现浮标检测与海图标记的匹配。


<details>
  <summary>Details</summary>
Motivation: 提升动态和挑战性环境中的物体定位和关联准确性。

Method: 提出了一种基于transformer的端到端神经网络，用于预测浮标的边界框和置信度分数，直接匹配图像域检测与世界空间海图标记。

Result: 实验结果表明，该方法在真实海洋场景数据集中显著优于基线方法。

Conclusion: 该方法在动态和挑战性环境中显著提高了物体定位和关联的准确性。

Abstract: This paper presents a novel approach to enhancing marine vision by fusing
real-time visual data with chart information. Our system overlays nautical
chart data onto live video feeds by accurately matching detected navigational
aids, such as buoys, with their corresponding representations in chart data. To
achieve robust association, we introduce a transformer-based end-to-end neural
network that predicts bounding boxes and confidence scores for buoy queries,
enabling the direct matching of image-domain detections with world-space chart
markers. The proposed method is compared against baseline approaches, including
a ray-casting model that estimates buoy positions via camera projection and a
YOLOv7-based network extended with a distance estimation module. Experimental
results on a dataset of real-world maritime scenes demonstrate that our
approach significantly improves object localization and association accuracy in
dynamic and challenging environments.

</details>


### [64] [PCR-GS: COLMAP-Free 3D Gaussian Splatting via Pose Co-Regularizations](https://arxiv.org/abs/2507.13891)
*Yu Wei,Jiahui Zhang,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: PCR-GS是一种无需COLMAP的3D高斯泼溅技术，通过相机姿态共正则化提升复杂场景下的3D建模和相机姿态估计。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂相机轨迹场景中表现不佳，导致相机姿态估计和3D高斯泼溅联合优化陷入局部最优。

Method: 提出两种正则化方法：特征重投影正则化和基于小波的高频细节正则化，分别从语义对齐和高频差异优化相机姿态。

Result: 实验表明PCR-GS在剧烈变化的相机轨迹下实现了优越的无姿态3D高斯泼溅场景建模。

Conclusion: PCR-GS通过共正则化显著提升了复杂场景下的3D建模和相机姿态估计性能。

Abstract: COLMAP-free 3D Gaussian Splatting (3D-GS) has recently attracted increasing
attention due to its remarkable performance in reconstructing high-quality 3D
scenes from unposed images or videos. However, it often struggles to handle
scenes with complex camera trajectories as featured by drastic rotation and
translation across adjacent camera views, leading to degraded estimation of
camera poses and further local minima in joint optimization of camera poses and
3D-GS. We propose PCR-GS, an innovative COLMAP-free 3DGS technique that
achieves superior 3D scene modeling and camera pose estimation via camera pose
co-regularization. PCR-GS achieves regularization from two perspectives. The
first is feature reprojection regularization which extracts view-robust DINO
features from adjacent camera views and aligns their semantic information for
camera pose regularization. The second is wavelet-based frequency
regularization which exploits discrepancy in high-frequency details to further
optimize the rotation matrix in camera poses. Extensive experiments over
multiple real-world scenes show that the proposed PCR-GS achieves superior
pose-free 3D-GS scene modeling under dramatic changes of camera trajectories.

</details>


### [65] [Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection](https://arxiv.org/abs/2507.13899)
*Yujian Mo,Yan Wu,Junqiao Zhao,Jijun Wang,Yinghao Hu,Jun Yan*

Main category: cs.CV

TL;DR: 论文提出了一种利用DepthAnything生成的深度先验增强LiDAR点云特征的方法，通过双路径RoI特征提取和双向门控融合模块，显著提升了3D目标检测的精度。


<details>
  <summary>Details</summary>
Motivation: LiDAR点云特征表达能力有限，尤其是反射率属性的区分能力较弱，而DepthAnything提供的密集几何先验未被充分利用。

Method: 将DepthAnything预测的深度先验与LiDAR原始属性融合，提出点级特征提取模块和双路径RoI特征提取框架（体素分支和点分支），并通过双向门控RoI特征融合模块整合全局和局部信息。

Result: 在KITTI基准测试中，检测精度显著提升。

Conclusion: 视觉基础模型先验可以有效增强LiDAR点云特征，提升3D目标检测性能。

Abstract: Recent advances in foundation models have opened up new possibilities for
enhancing 3D perception. In particular, DepthAnything offers dense and reliable
geometric priors from monocular RGB images, which can complement sparse LiDAR
data in autonomous driving scenarios. However, such priors remain underutilized
in LiDAR-based 3D object detection. In this paper, we address the limited
expressiveness of raw LiDAR point features, especially the weak discriminative
capability of the reflectance attribute, by introducing depth priors predicted
by DepthAnything. These priors are fused with the original LiDAR attributes to
enrich each point's representation. To leverage the enhanced point features, we
propose a point-wise feature extraction module. Then, a Dual-Path RoI feature
extraction framework is employed, comprising a voxel-based branch for global
semantic context and a point-based branch for fine-grained structural details.
To effectively integrate the complementary RoI features, we introduce a
bidirectional gated RoI feature fusion module that balances global and local
cues. Extensive experiments on the KITTI benchmark show that our method
consistently improves detection accuracy, demonstrating the value of
incorporating visual foundation model priors into LiDAR-based 3D object
detection.

</details>


### [66] [Generalist Forecasting with Frozen Video Models via Latent Diffusion](https://arxiv.org/abs/2507.13942)
*Jacob C Walker,Pedro Vélez,Luisa Polania Cabrera,Guangyao Zhou,Rishabh Kabra,Carl Doersch,Maks Ovsjanikov,João Carreira,Shiry Ginosar*

Main category: cs.CV

TL;DR: 研究发现视觉模型的感知能力与其短期预测性能强相关，提出了一种通用预测框架，通过潜在扩散模型预测未来特征，并在多个任务中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索视觉模型的感知能力与预测性能之间的关系，以提升通用系统在不同抽象层次上的预测能力。

Method: 提出一种通用预测框架，利用潜在扩散模型在冻结的视觉骨干网络中预测未来特征，并通过轻量级任务特定解码器解码。

Result: 在九个模型和四个任务中验证了框架的有效性，发现感知能力与预测性能强相关。

Conclusion: 结合表征学习和生成模型对视频理解具有重要意义。

Abstract: Forecasting what will happen next is a critical skill for general-purpose
systems that plan or act in the world at different levels of abstraction. In
this paper, we identify a strong correlation between a vision model's
perceptual ability and its generalist forecasting performance over short time
horizons. This trend holds across a diverse set of pretrained models-including
those trained generatively-and across multiple levels of abstraction, from raw
pixels to depth, point tracks, and object motion. The result is made possible
by a novel generalist forecasting framework that operates on any frozen vision
backbone: we train latent diffusion models to forecast future features in the
frozen representation space, which are then decoded via lightweight,
task-specific readouts. To enable consistent evaluation across tasks, we
introduce distributional metrics that compare distributional properties
directly in the space of downstream tasks and apply this framework to nine
models and four tasks. Our results highlight the value of bridging
representation learning and generative modeling for temporally grounded video
understanding.

</details>


### [67] [DiViD: Disentangled Video Diffusion for Static-Dynamic Factorization](https://arxiv.org/abs/2507.13934)
*Marzieh Gheisari,Auguste Genovesio*

Main category: cs.CV

TL;DR: DiViD是一种端到端视频扩散框架，用于显式分离静态外观和动态运动，通过全局静态令牌和帧特定动态令牌实现，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于VAE和GAN的方法在视频中分离静态和动态内容时存在信息泄漏和模糊重建问题，需要更有效的解决方案。

Method: DiViD采用序列编码器提取全局静态令牌和帧特定动态令牌，结合条件DDPM解码器，引入共享噪声计划、时变KL瓶颈和交叉注意力等归纳偏置。

Result: DiViD在真实世界基准测试中表现优异，实现了最高的交换联合准确率，同时保持静态保真度和动态传递能力，减少交叉泄漏。

Conclusion: DiViD通过显式静态-动态分解和关键归纳偏置，显著提升了视频中静态与动态内容的分离效果。

Abstract: Unsupervised disentanglement of static appearance and dynamic motion in video
remains a fundamental challenge, often hindered by information leakage and
blurry reconstructions in existing VAE- and GAN-based approaches. We introduce
DiViD, the first end-to-end video diffusion framework for explicit
static-dynamic factorization. DiViD's sequence encoder extracts a global static
token from the first frame and per-frame dynamic tokens, explicitly removing
static content from the motion code. Its conditional DDPM decoder incorporates
three key inductive biases: a shared-noise schedule for temporal consistency, a
time-varying KL-based bottleneck that tightens at early timesteps (compressing
static information) and relaxes later (enriching dynamics), and cross-attention
that routes the global static token to all frames while keeping dynamic tokens
frame-specific. An orthogonality regularizer further prevents residual
static-dynamic leakage. We evaluate DiViD on real-world benchmarks using
swap-based accuracy and cross-leakage metrics. DiViD outperforms
state-of-the-art sequential disentanglement methods: it achieves the highest
swap-based joint accuracy, preserves static fidelity while improving dynamic
transfer, and reduces average cross-leakage.

</details>


### [68] [CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models](https://arxiv.org/abs/2507.13984)
*Quang-Binh Nguyen,Minh Luu,Quang Nguyen,Anh Tran,Khoi Nguyen*

Main category: cs.CV

TL;DR: 论文提出了一种基于视觉自回归模型（VAR）的内容-风格分解方法CSD-VAR，通过尺度感知优化、SVD校正和增强键值记忆提升分解效果，并在新数据集CSD-100上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对扩散模型，而VAR作为一种新兴生成框架，其逐尺度生成特性可能更适合内容-风格分解任务。

Method: 提出CSD-VAR方法，包括尺度感知交替优化、SVD校正和增强键值记忆三项创新。

Result: 实验表明CSD-VAR在内容保留和风格化保真度上优于现有方法。

Conclusion: CSD-VAR为内容-风格分解任务提供了一种高效且性能优越的解决方案。

Abstract: Disentangling content and style from a single image, known as content-style
decomposition (CSD), enables recontextualization of extracted content and
stylization of extracted styles, offering greater creative flexibility in
visual synthesis. While recent personalization methods have explored the
decomposition of explicit content style, they remain tailored for diffusion
models. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a
promising alternative with a next-scale prediction paradigm, achieving
performance comparable to that of diffusion models. In this paper, we explore
VAR as a generative framework for CSD, leveraging its scale-wise generation
process for improved disentanglement. To this end, we propose CSD-VAR, a novel
method that introduces three key innovations: (1) a scale-aware alternating
optimization strategy that aligns content and style representation with their
respective scales to enhance separation, (2) an SVD-based rectification method
to mitigate content leakage into style representations, and (3) an Augmented
Key-Value (K-V) memory enhancing content identity preservation. To benchmark
this task, we introduce CSD-100, a dataset specifically designed for
content-style decomposition, featuring diverse subjects rendered in various
artistic styles. Experiments demonstrate that CSD-VAR outperforms prior
approaches, achieving superior content preservation and stylization fidelity.

</details>


### [69] [Evaluation of Human Visual Privacy Protection: A Three-Dimensional Framework and Benchmark Dataset](https://arxiv.org/abs/2507.13981)
*Sara Abdulaziz,Giacomo D'Amicantonio,Egor Bondarev*

Main category: cs.CV

TL;DR: 本文提出了一种评估视觉隐私保护方法的框架，并发布了HR-VISPR数据集，用于训练可解释的隐私度量。


<details>
  <summary>Details</summary>
Motivation: AI驱动的监控技术引发了个人敏感数据处理的隐私担忧，需要客观的隐私保护评估方法。

Method: 提出一个三维（隐私、效用、实用性）评估框架，并引入HR-VISPR数据集，评估了11种隐私保护方法。

Result: 框架能够区分隐私级别，并揭示隐私、效用和实用性之间的权衡。

Conclusion: 该研究和数据集为隐私保护提供了结构化评估工具，适用于多种场景。

Abstract: Recent advances in AI-powered surveillance have intensified concerns over the
collection and processing of sensitive personal data. In response, research has
increasingly focused on privacy-by-design solutions, raising the need for
objective techniques to evaluate privacy protection. This paper presents a
comprehensive framework for evaluating visual privacy-protection methods across
three dimensions: privacy, utility, and practicality. In addition, it
introduces HR-VISPR, a publicly available human-centric dataset with biometric,
soft-biometric, and non-biometric labels to train an interpretable privacy
metric. We evaluate 11 privacy protection methods, ranging from conventional
techniques to advanced deep-learning methods, through the proposed framework.
The framework differentiates privacy levels in alignment with human visual
perception, while highlighting trade-offs between privacy, utility, and
practicality. This study, along with the HR-VISPR dataset, serves as an
insightful tool and offers a structured evaluation framework applicable across
diverse contexts.

</details>


### [70] [VLA-Mark: A cross modal watermark for large vision-language alignment model](https://arxiv.org/abs/2507.14067)
*Shuliang Liu,Qi Zheng,Jesse Jiaxi Xu,Yibo Yan,He Geng,Aiwei Liu,Peijie Jiang,Jia Liu,Yik-Cheung Tam,Xuming Hu*

Main category: cs.CV

TL;DR: VLA-Mark是一种视觉对齐的水印框架，通过跨模态协调嵌入可检测水印，同时保持语义保真度。


<details>
  <summary>Details</summary>
Motivation: 现有文本水印方法会破坏视觉-文本对齐，影响语义关键概念的保护，需要一种不损害多模态一致性的水印解决方案。

Method: 结合多尺度视觉-文本对齐指标（局部补丁亲和性、全局语义一致性和上下文注意力模式），动态平衡水印强度与语义保留。

Result: 实验显示，PPL降低7.4%，BLEU提高26.6%，检测准确率接近完美（98.8% AUC），抗攻击能力达96.1%。

Conclusion: VLA-Mark为质量保持的多模态水印设定了新标准。

Abstract: Vision-language models demand watermarking solutions that protect
intellectual property without compromising multimodal coherence. Existing text
watermarking methods disrupt visual-textual alignment through biased token
selection and static strategies, leaving semantic-critical concepts vulnerable.
We propose VLA-Mark, a vision-aligned framework that embeds detectable
watermarks while preserving semantic fidelity through cross-modal coordination.
Our approach integrates multiscale visual-textual alignment metrics, combining
localized patch affinity, global semantic coherence, and contextual attention
patterns, to guide watermark injection without model retraining. An
entropy-sensitive mechanism dynamically balances watermark strength and
semantic preservation, prioritizing visual grounding during low-uncertainty
generation phases. Experiments show 7.4% lower PPL and 26.6% higher BLEU than
conventional methods, with near-perfect detection (98.8% AUC). The framework
demonstrates 96.1\% attack resilience against attacks such as paraphrasing and
synonym substitution, while maintaining text-visual consistency, establishing
new standards for quality-preserving multimodal watermarking

</details>


### [71] [DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation](https://arxiv.org/abs/2507.13985)
*Haoran Li,Yuli Tian,Kun Lan,Yong Liao,Lin Wang,Pan Hui,Peng Yuan Zhou*

Main category: cs.CV

TL;DR: DreamScene是一个端到端框架，通过文本或对话生成高质量、可编辑的3D场景，解决了自动化、3D一致性和细粒度控制的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法在自动化、3D一致性和细粒度控制方面表现不佳，限制了3D场景生成的实用性。

Method: DreamScene结合场景规划模块、图布局算法、几何生成技术和渐进式相机采样策略，实现高质量和可编辑的3D场景生成。

Result: 实验表明，DreamScene在质量、一致性和灵活性上优于现有方法。

Conclusion: DreamScene为开放领域的3D内容创作提供了实用解决方案。

Abstract: Generating 3D scenes from natural language holds great promise for
applications in gaming, film, and design. However, existing methods struggle
with automation, 3D consistency, and fine-grained control. We present
DreamScene, an end-to-end framework for high-quality and editable 3D scene
generation from text or dialogue. DreamScene begins with a scene planning
module, where a GPT-4 agent infers object semantics and spatial constraints to
construct a hybrid graph. A graph-based placement algorithm then produces a
structured, collision-free layout. Based on this layout, Formation Pattern
Sampling (FPS) generates object geometry using multi-timestep sampling and
reconstructive optimization, enabling fast and realistic synthesis. To ensure
global consistent, DreamScene employs a progressive camera sampling strategy
tailored to both indoor and outdoor settings. Finally, the system supports
fine-grained scene editing, including object movement, appearance changes, and
4D dynamic motion. Experiments demonstrate that DreamScene surpasses prior
methods in quality, consistency, and flexibility, offering a practical solution
for open-domain 3D content creation. Code and demos are available at
https://dreamscene-project.github.io.

</details>


### [72] [Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment](https://arxiv.org/abs/2507.14093)
*Šimon Kubov,Simon Klíčník,Jakub Dandár,Zdeněk Straka,Karolína Kvaková,Daniel Kvak*

Main category: cs.CV

TL;DR: 论文评估了一种基于深度学习的自动化软件（Carebot AI Bones）用于测量脊柱侧弯的Cobb角，结果显示其与放射科医生的测量结果具有高度一致性，可用于临床工作流程。


<details>
  <summary>Details</summary>
Motivation: 脊柱侧弯影响2-4%的青少年，传统手动测量Cobb角耗时且存在观察者间差异，需要一种更高效、准确的方法。

Method: 研究回顾性评估了103张脊柱X光片，使用Carebot AI Bones软件进行自动测量，并与两位放射科医生的独立测量结果进行比较。

Result: AI与放射科医生的测量结果高度相关（Pearson相关系数0.906和0.880），平均绝对误差（MAE）约为3.9度，Cohen kappa显示分类一致性中等（0.51和0.64）。

Conclusion: 该软件能够复现专家水平的Cobb角测量和分类，可用于优化脊柱侧弯的临床报告和分诊流程。

Abstract: Scoliosis affects roughly 2 to 4 percent of adolescents, and treatment
decisions depend on precise Cobb angle measurement. Manual assessment is time
consuming and subject to inter observer variation. We conducted a
retrospective, multi centre evaluation of a fully automated deep learning
software (Carebot AI Bones, Spine Measurement functionality; Carebot s.r.o.) on
103 standing anteroposterior whole spine radiographs collected from ten
hospitals. Two musculoskeletal radiologists independently measured each study
and served as reference readers. Agreement between the AI and each radiologist
was assessed with Bland Altman analysis, mean absolute error (MAE), root mean
squared error (RMSE), Pearson correlation coefficient, and Cohen kappa for four
grade severity classification. Against Radiologist 1 the AI achieved an MAE of
3.89 degrees (RMSE 4.77 degrees) with a bias of 0.70 degrees and limits of
agreement from minus 8.59 to plus 9.99 degrees. Against Radiologist 2 the AI
achieved an MAE of 3.90 degrees (RMSE 5.68 degrees) with a bias of 2.14 degrees
and limits from minus 8.23 to plus 12.50 degrees. Pearson correlations were r
equals 0.906 and r equals 0.880 (inter reader r equals 0.928), while Cohen
kappa for severity grading reached 0.51 and 0.64 (inter reader kappa 0.59).
These results demonstrate that the proposed software reproduces expert level
Cobb angle measurements and categorical grading across multiple centres,
suggesting its utility for streamlining scoliosis reporting and triage in
clinical workflows.

</details>


### [73] [Automatic Classification and Segmentation of Tunnel Cracks Based on Deep Learning and Visual Explanations](https://arxiv.org/abs/2507.14010)
*Yong Feng,Xiaolei Zhang,Shijin Feng,Yong Zhao,Yihan Chen*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的两步法，用于隧道裂缝的分类和分割，提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 隧道裂缝是隧道安全状态的重要指标，需要一种更准确和高效的方法进行分类和分割。

Method: 第一步使用DenseNet-169进行隧道图像分类；第二步基于DeepLabV3+进行裂缝分割，并通过可视化技术评估模型内部逻辑。

Result: 分类模型准确率92.23%，FPS 39.80；分割模型IoU 57.01%，F1分数67.44%，均优于其他模型。

Conclusion: 该方法结合分类和分割，并通过可视化解释，为隧道健康状态的快速准确评估提供了基础。

Abstract: Tunnel lining crack is a crucial indicator of tunnels' safety status. Aiming
to classify and segment tunnel cracks with enhanced accuracy and efficiency,
this study proposes a two-step deep learning-based method. An automatic tunnel
image classification model is developed using the DenseNet-169 in the first
step. The proposed crack segmentation model in the second step is based on the
DeepLabV3+, whose internal logic is evaluated via a score-weighted visual
explanation technique. Proposed method combines tunnel image classification and
segmentation together, so that the selected images containing cracks from the
first step are segmented in the second step to improve the detection accuracy
and efficiency. The superior performances of the two-step method are validated
by experiments. The results show that the accuracy and frames per second (FPS)
of the tunnel crack classification model are 92.23% and 39.80, respectively,
which are higher than other convolutional neural networks (CNN) based and
Transformer based models. Also, the intersection over union (IoU) and F1 score
of the tunnel crack segmentation model are 57.01% and 67.44%, respectively,
outperforming other state-of-the-art models. Moreover, the provided visual
explanations in this study are conducive to understanding the "black box" of
deep learning-based models. The developed two-stage deep learning-based method
integrating visual explanations provides a basis for fast and accurate
quantitative assessment of tunnel health status.

</details>


### [74] [NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining](https://arxiv.org/abs/2507.14119)
*Maksim Kuprashevich,Grigorii Alekseenko,Irina Tolstykh,Georgii Fedorov,Bulat Suleimanov,Vladimir Dokholyan,Aleksandr Gordeev*

Main category: cs.CV

TL;DR: 提出了一种自动化、模块化的流程，用于生成高质量的训练数据三元组（原始图像、指令、编辑图像），无需人工干预，并发布了开源数据集和模型。


<details>
  <summary>Details</summary>
Motivation: 生成模型需要大量高质量的训练数据，但手动标注成本高且难以自动化。

Method: 利用公共生成模型和任务调优的验证器自动评分，通过反转和组合扩展数据集。

Result: 生成了35.8万高质量三元组数据集NHR-Edit，并在实验中表现优于其他公开数据集。

Conclusion: 该方法实现了大规模高质量数据自动化生成，推动了生成模型研究的发展。

Abstract: Recent advances in generative modeling enable image editing assistants that
follow natural language instructions without additional user input. Their
supervised training requires millions of triplets: original image, instruction,
edited image. Yet mining pixel-accurate examples is hard. Each edit must affect
only prompt-specified regions, preserve stylistic coherence, respect physical
plausibility, and retain visual appeal. The lack of robust automated
edit-quality metrics hinders reliable automation at scale. We present an
automated, modular pipeline that mines high-fidelity triplets across domains,
resolutions, instruction complexities, and styles. Built on public generative
models and running without human intervention, our system uses a task-tuned
Gemini validator to score instruction adherence and aesthetics directly,
removing any need for segmentation or grounding models. Inversion and
compositional bootstrapping enlarge the mined set by approximately 2.2x,
enabling large-scale high-fidelity training data. By automating the most
repetitive annotation steps, the approach allows a new scale of training
without human labeling effort. To democratize research in this
resource-intensive area, we release NHR-Edit: an open dataset of 358k
high-quality triplets. In the largest cross-dataset evaluation, it surpasses
all public alternatives. We also release Bagel-NHR-Edit, an open-source
fine-tuned Bagel model, which achieves state-of-the-art metrics in our
experiments.

</details>


### [75] [QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography](https://arxiv.org/abs/2507.14031)
*Hao Fang,Sihao Teng,Hao Yu,Siyi Yuan,Huaiwu He,Zhe Liu,Yunjie Yang*

Main category: cs.CV

TL;DR: 提出了一种基于量子辅助网络的超轻量级EIT图像重建框架QuantEIT，显著降低了模型复杂度，并在无监督、无需训练数据的情况下实现了高精度重建。


<details>
  <summary>Details</summary>
Motivation: EIT作为一种低成本、高时间分辨率的床边成像技术，其逆问题的不适定性限制了图像重建的准确性。现有深度学习方法虽有效但模型复杂，参数多，效率低。

Method: QuantEIT采用量子辅助网络（QA-Net），结合并行2量子比特电路生成隐式非线性先验，再通过单层线性网络重建电导率，大幅减少参数数量。

Result: 在模拟和真实2D/3D肺部EIT数据上，QuantEIT优于传统方法，仅用0.2%的参数实现了相当或更高的重建精度，且对噪声更鲁棒。

Conclusion: QuantEIT首次将量子电路引入EIT图像重建，提供了一种高效、轻量级的解决方案，具有潜在临床应用价值。

Abstract: Electrical Impedance Tomography (EIT) is a non-invasive, low-cost bedside
imaging modality with high temporal resolution, making it suitable for bedside
monitoring. However, its inherently ill-posed inverse problem poses significant
challenges for accurate image reconstruction. Deep learning (DL)-based
approaches have shown promise but often rely on complex network architectures
with a large number of parameters, limiting efficiency and scalability. Here,
we propose an Ultra-Lightweight Quantum-Assisted Inference (QuantEIT) framework
for EIT image reconstruction. QuantEIT leverages a Quantum-Assisted Network
(QA-Net), combining parallel 2-qubit quantum circuits to generate expressive
latent representations that serve as implicit nonlinear priors, followed by a
single linear layer for conductivity reconstruction. This design drastically
reduces model complexity and parameter number. Uniquely, QuantEIT operates in
an unsupervised, training-data-free manner and represents the first integration
of quantum circuits into EIT image reconstruction. Extensive experiments on
simulated and real-world 2D and 3D EIT lung imaging data demonstrate that
QuantEIT outperforms conventional methods, achieving comparable or superior
reconstruction accuracy using only 0.2% of the parameters, with enhanced
robustness to noise.

</details>


### [76] [Analysis of Plant Nutrient Deficiencies Using Multi-Spectral Imaging and Optimized Segmentation Model](https://arxiv.org/abs/2507.14013)
*Ji-Yan Wu,Zheng Yong Poh,Anoop C. Patil,Bongsoo Park,Giovanni Volpe,Daisuke Urano*

Main category: cs.CV

TL;DR: 该研究提出了一种结合多光谱成像和改进YOLOv5模型的深度学习框架，用于植物叶片异常分割，显著提升了检测精度。


<details>
  <summary>Details</summary>
Motivation: 精准农业需要早期检测植物叶片营养缺乏，以实现及时的施肥和疾病管理。

Method: 使用多光谱成像和增强的YOLOv5模型，结合基于变压器的注意力机制，处理九通道多光谱输入。

Result: 模型在Dice分数和IoU上比基线YOLOv5提高了约12%，尤其在检测叶绿素缺乏和色素积累方面表现优异。

Conclusion: 结合多光谱成像和光谱-空间特征学习，有望推动植物表型和精准农业的发展。

Abstract: Accurate detection of nutrient deficiency in plant leaves is essential for
precision agriculture, enabling early intervention in fertilization, disease,
and stress management. This study presents a deep learning framework for leaf
anomaly segmentation using multispectral imaging and an enhanced YOLOv5 model
with a transformer-based attention head. The model is tailored for processing
nine-channel multispectral input and uses self-attention mechanisms to better
capture subtle, spatially-distributed symptoms. The plants in the experiments
were grown under controlled nutrient stress conditions for evaluation. We carry
out extensive experiments to benchmark the proposed model against the baseline
YOLOv5. Extensive experiments show that the proposed model significantly
outperforms the baseline YOLOv5, with an average Dice score and IoU
(Intersection over Union) improvement of about 12%. In particular, this model
is effective in detecting challenging symptoms like chlorosis and pigment
accumulation. These results highlight the promise of combining multi-spectral
imaging with spectral-spatial feature learning for advancing plant phenotyping
and precision agriculture.

</details>


### [77] [Moodifier: MLLM-Enhanced Emotion-Driven Image Editing](https://arxiv.org/abs/2507.14024)
*Jiarong Ye,Sharon X. Huang*

Main category: cs.CV

TL;DR: 提出了一种结合情感与视觉内容的图像编辑方法，包括数据集MoodArchive、模型MoodifyCLIP和编辑工具Moodifier，实现了高精度的情感驱动编辑。


<details>
  <summary>Details</summary>
Motivation: 情感驱动的图像编辑在创意产业中潜力巨大，但因情感的抽象性和多样性而难以精确操控。

Method: 1. 构建MoodArchive数据集（8M+图像，带层级情感标注）；2. 开发MoodifyCLIP模型，将情感映射为视觉属性；3. 提出无需训练的编辑模型Moodifier，结合MLLMs实现精确情感转换。

Result: Moodifier在情感准确性和内容保留上优于现有方法，适用于多种领域（如时尚、家居）。

Conclusion: 通过将抽象情感与具体视觉变化关联，为实际应用中的情感内容创作提供了新可能。

Abstract: Bridging emotions and visual content for emotion-driven image editing holds
great potential in creative industries, yet precise manipulation remains
challenging due to the abstract nature of emotions and their varied
manifestations across different contexts. We tackle this challenge with an
integrated approach consisting of three complementary components. First, we
introduce MoodArchive, an 8M+ image dataset with detailed hierarchical
emotional annotations generated by LLaVA and partially validated by human
evaluators. Second, we develop MoodifyCLIP, a vision-language model fine-tuned
on MoodArchive to translate abstract emotions into specific visual attributes.
Third, we propose Moodifier, a training-free editing model leveraging
MoodifyCLIP and multimodal large language models (MLLMs) to enable precise
emotional transformations while preserving content integrity. Our system works
across diverse domains such as character expressions, fashion design, jewelry,
and home d\'ecor, enabling creators to quickly visualize emotional variations
while preserving identity and structure. Extensive experimental evaluations
show that Moodifier outperforms existing methods in both emotional accuracy and
content preservation, providing contextually appropriate edits. By linking
abstract emotions to concrete visual changes, our solution unlocks new
possibilities for emotional content creation in real-world applications. We
will release the MoodArchive dataset, MoodifyCLIP model, and make the Moodifier
code and demo publicly available upon acceptance.

</details>


### [78] [Training-free Token Reduction for Vision Mamba](https://arxiv.org/abs/2507.14042)
*Qiankun Ma,Ziyao Zhang,Chi Su,Jie Chen,Zhen Song,Hairong Zheng,Wen Gao*

Main category: cs.CV

TL;DR: Vision Mamba的MTR框架通过结构感知重要性评分实现无训练令牌压缩，显著降低计算量且性能损失小。


<details>
  <summary>Details</summary>
Motivation: 探索Vision Mamba的效率，解决现有ViT令牌压缩技术直接应用于Mamba时性能下降的问题。

Method: 提出MTR框架，基于Mamba结构感知重要性评分，无需训练即可实现令牌压缩。

Result: 在Vim-B骨干上减少40% FLOPs，ImageNet性能仅下降1.6%。

Conclusion: MTR是一种高效、即插即用的令牌压缩方法，适用于多种Mamba模型。

Abstract: Vision Mamba has emerged as a strong competitor to Vision Transformers (ViTs)
due to its ability to efficiently capture long-range dependencies with linear
computational complexity. While token reduction, an effective compression
technique in ViTs, has rarely been explored in Vision Mamba. Exploring Vision
Mamba's efficiency is essential for enabling broader applications. However, we
find that directly applying existing token reduction techniques for ViTs to
Vision Mamba leads to significant performance degradation. This is primarily
because Mamba is a sequence model without attention mechanisms, whereas most
token reduction techniques for ViTs rely on attention mechanisms for importance
measurement and overlook the order of compressed tokens. In this paper, we
investigate a Mamba structure-aware importance score to evaluate token
importance in a simple and effective manner. Building on this score, we further
propose MTR, a training-free \textbf{M}amba \textbf{T}oken \textbf{R}eduction
framework. Without the need for training or additional tuning parameters, our
method can be seamlessly integrated as a plug-and-play component across various
Mamba models. Extensive experiments demonstrate that our approach significantly
reduces computational workload while minimizing performance impact across
various tasks and multiple backbones. Notably, MTR reduces FLOPs by
approximately 40\% on the Vim-B backbone, with only a 1.6\% drop in ImageNet
performance without retraining.

</details>


### [79] [Foundation Models as Class-Incremental Learners for Dermatological Image Classification](https://arxiv.org/abs/2507.14050)
*Mohamed Elkhayat,Mohamed Mahmoud,Jamil Fayyad,Nourhan Bayasi*

Main category: cs.CV

TL;DR: 论文研究了在皮肤病分类中利用预训练基础模型进行类增量学习的方法，提出了一种简单有效的轻量级MLP增量训练策略，并探索了零训练场景的原型分类方法。


<details>
  <summary>Details</summary>
Motivation: 探索预训练基础模型在皮肤病分类的类增量学习中的潜力，解决传统方法中的遗忘问题。

Method: 冻结预训练模型的主干，为每个任务训练轻量级MLP；同时探索零训练场景下的原型分类方法。

Result: 提出的方法在性能上优于正则化、回放和基于架构的方法，原型分类方法也取得了竞争性结果。

Conclusion: 冻结预训练基础模型在皮肤病分类的持续学习中表现优异，支持其在现实医疗应用中的广泛采用。

Abstract: Class-Incremental Learning (CIL) aims to learn new classes over time without
forgetting previously acquired knowledge. The emergence of foundation models
(FM) pretrained on large datasets presents new opportunities for CIL by
offering rich, transferable representations. However, their potential for
enabling incremental learning in dermatology remains largely unexplored. In
this paper, we systematically evaluate frozen FMs pretrained on large-scale
skin lesion datasets for CIL in dermatological disease classification. We
propose a simple yet effective approach where the backbone remains frozen, and
a lightweight MLP is trained incrementally for each task. This setup achieves
state-of-the-art performance without forgetting, outperforming regularization,
replay, and architecture based methods. To further explore the capabilities of
frozen FMs, we examine zero training scenarios using nearest mean classifiers
with prototypes derived from their embeddings. Through extensive ablation
studies, we demonstrate that this prototype based variant can also achieve
competitive results. Our findings highlight the strength of frozen FMs for
continual learning in dermatology and support their broader adoption in real
world medical applications. Our code and datasets are available here.

</details>


### [80] [Unmasking Performance Gaps: A Comparative Study of Human Anonymization and Its Effects on Video Anomaly Detection](https://arxiv.org/abs/2507.14083)
*Sara Abdulaziz,Egor Bondarev*

Main category: cs.CV

TL;DR: 论文分析了四种匿名化技术对异常检测性能的影响，发现匿名化数据仍能有效检测异常，且性能与算法设计相关。


<details>
  <summary>Details</summary>
Motivation: 深度学习在监控视频异常检测中提升了性能，但收集敏感数据引发隐私问题，需研究匿名化技术对检测的影响。

Method: 在UCF-Crime数据集上应用四种匿名化技术（模糊、掩码、加密、虚拟人替换），评估四种异常检测方法（MGFN、UR-DMU、BN-WVAD、PEL4VAD）。

Result: 匿名化数据下异常检测仍可行，某些匿名化模式（如加密和掩码）甚至能提升部分模型的AUC性能。

Conclusion: 匿名化技术与算法设计之间存在权衡，隐私保护与检测效用需平衡，为未来研究提供了基准和见解。

Abstract: Advancements in deep learning have improved anomaly detection in surveillance
videos, yet they raise urgent privacy concerns due to the collection of
sensitive human data. In this paper, we present a comprehensive analysis of
anomaly detection performance under four human anonymization techniques,
including blurring, masking, encryption, and avatar replacement, applied to the
UCF-Crime dataset. We evaluate four anomaly detection methods, MGFN, UR-DMU,
BN-WVAD, and PEL4VAD, on the anonymized UCF-Crime to reveal how each method
responds to different obfuscation techniques. Experimental results demonstrate
that anomaly detection remains viable under anonymized data and is dependent on
the algorithmic design and the learning strategy. For instance, under certain
anonymization patterns, such as encryption and masking, some models
inadvertently achieve higher AUC performance compared to raw data, due to the
strong responsiveness of their algorithmic components to these noise patterns.
These results highlight the algorithm-specific sensitivities to anonymization
and emphasize the trade-off between preserving privacy and maintaining
detection utility. Furthermore, we compare these conventional anonymization
techniques with the emerging privacy-by-design solutions, highlighting an often
overlooked trade-off between robust privacy protection and utility flexibility.
Through comprehensive experiments and analyses, this study provides a
compelling benchmark and insights into balancing human privacy with the demands
of anomaly detection.

</details>


### [81] [C-DOG: Training-Free Multi-View Multi-Object Association in Dense Scenes Without Visual Feature via Connected δ-Overlap Graphs](https://arxiv.org/abs/2507.14095)
*Yung-Hong Sun,Ting-Hung Lin,Jiangang Chen,Hongrui Jiang,Yu Hen Hu*

Main category: cs.CV

TL;DR: C-DOG是一种无需训练的多视角多目标关联框架，通过结合连接增量重叠图建模和极几何，在噪声和视觉不可区分的情况下实现鲁棒关联。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在目标视觉不可区分或观测噪声时失效的问题。

Method: 使用连接增量重叠图建模和极几何，结合IQR过滤和3D反投影误差标准。

Result: 在合成基准测试中优于几何基线，在高目标密度和无视觉特征等挑战下仍保持鲁棒性。

Conclusion: C-DOG适用于现实场景中可扩展的3D重建。

Abstract: Multi-view multi-object association is a fundamental step in 3D
reconstruction pipelines, enabling consistent grouping of object instances
across multiple camera views. Existing methods often rely on appearance
features or geometric constraints such as epipolar consistency. However, these
approaches can fail when objects are visually indistinguishable or observations
are corrupted by noise. We propose C-DOG, a training-free framework that serves
as an intermediate module bridging object detection (or pose estimation) and 3D
reconstruction, without relying on visual features. It combines connected
delta-overlap graph modeling with epipolar geometry to robustly associate
detections across views. Each 2D observation is represented as a graph node,
with edges weighted by epipolar consistency. A delta-neighbor-overlap
clustering step identifies strongly consistent groups while tolerating noise
and partial connectivity. To further improve robustness, we incorporate
Interquartile Range (IQR)-based filtering and a 3D back-projection error
criterion to eliminate inconsistent observations. Extensive experiments on
synthetic benchmarks demonstrate that C-DOG outperforms geometry-based
baselines and remains robust under challenging conditions, including high
object density, without visual features, and limited camera overlap, making it
well-suited for scalable 3D reconstruction in real-world scenarios.

</details>


### [82] [Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning](https://arxiv.org/abs/2507.14137)
*Shashanka Venkataramanan,Valentinos Pariza,Mohammadreza Salehi,Lukas Knobel,Spyros Gidaris,Elias Ramzi,Andrei Bursuc,Yuki M. Asano*

Main category: cs.CV

TL;DR: Franca是首个完全开源的视觉基础模型，性能媲美甚至超越现有专有模型，如DINOv2和CLIP。其透明训练流程和公开数据支持，解决了SSL聚类方法的局限性，并引入了多头聚类投影器和位置解耦策略。


<details>
  <summary>Details</summary>
Motivation: 解决专有模型闭源和数据不透明的问题，同时改进SSL聚类方法的语义模糊性。

Method: 基于Web-SSL的透明训练流程，使用公开数据（ImageNet-21K和ReLAION-2B子集），引入多头聚类投影器和位置解耦策略。

Result: 在多个下游任务中表现优异，性能与专有模型相当或更好。

Conclusion: Franca为透明、高性能的视觉模型设定了新标准，推动了可复现和通用基础模型的发展。

Abstract: We present Franca (pronounced Fran-ka): free one; the first fully open-source
(data, code, weights) vision foundation model that matches and in many cases
surpasses the performance of state-of-the-art proprietary models, e.g., DINOv2,
CLIP, SigLIPv2, etc. Our approach is grounded in a transparent training
pipeline inspired by Web-SSL and uses publicly available data: ImageNet-21K and
a subset of ReLAION-2B. Beyond model release, we tackle critical limitations in
SSL clustering methods. While modern models rely on assigning image features to
large codebooks via clustering algorithms like Sinkhorn-Knopp, they fail to
account for the inherent ambiguity in clustering semantics. To address this, we
introduce a parameter-efficient, multi-head clustering projector based on
nested Matryoshka representations. This design progressively refines features
into increasingly fine-grained clusters without increasing the model size,
enabling both performance and memory efficiency. Additionally, we propose a
novel positional disentanglement strategy that explicitly removes positional
biases from dense representations, thereby improving the encoding of semantic
content. This leads to consistent gains on several downstream benchmarks,
demonstrating the utility of cleaner feature spaces. Our contributions
establish a new standard for transparent, high-performance vision models and
open a path toward more reproducible and generalizable foundation models for
the broader AI community. The code and model checkpoints are available at
https://github.com/valeoai/Franca.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [83] [GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination](https://arxiv.org/abs/2507.13511)
*Nabil Abdelaziz Ferhat Taleb,Abdolazim Rezaei,Raj Atulkumar Patel,Mehdi Sookhak*

Main category: cs.AI

TL;DR: GraphTrafficGPT是一种基于图的架构，通过并行执行和动态资源分配优化LLM驱动的交通管理任务，显著降低令牌消耗和响应延迟。


<details>
  <summary>Details</summary>
Motivation: 现有链式系统（如TrafficGPT）存在顺序任务执行、高令牌使用和可扩展性差的问题，无法满足复杂交通管理需求。

Method: 提出GraphTrafficGPT，将任务及其依赖关系表示为有向图中的节点和边，引入Brain Agent分解查询并协调多个专业代理。

Result: 实验显示，GraphTrafficGPT令牌消耗减少50.2%，响应延迟降低19.0%，多查询执行效率提升23.0%。

Conclusion: GraphTrafficGPT显著提升了LLM在交通管理中的效率和可扩展性。

Abstract: Large Language Models (LLMs) offer significant promise for intelligent
traffic management; however, current chain-based systems like TrafficGPT are
hindered by sequential task execution, high token usage, and poor scalability,
making them inefficient for complex, real-world scenarios. To address these
limitations, we propose GraphTrafficGPT, a novel graph-based architecture,
which fundamentally redesigns the task coordination process for LLM-driven
traffic applications. GraphTrafficGPT represents tasks and their dependencies
as nodes and edges in a directed graph, enabling efficient parallel execution
and dynamic resource allocation. The main idea behind the proposed model is a
Brain Agent that decomposes user queries, constructs optimized dependency
graphs, and coordinates a network of specialized agents for data retrieval,
analysis, visualization, and simulation. By introducing advanced context-aware
token management and supporting concurrent multi-query processing, the proposed
architecture handles interdependent tasks typical of modern urban mobility
environments. Experimental results demonstrate that GraphTrafficGPT reduces
token consumption by 50.2% and average response latency by 19.0% compared to
TrafficGPT, while supporting simultaneous multi-query execution with up to
23.0% improvement in efficiency.

</details>


### [84] [PrefPalette: Personalized Preference Modeling with Latent Attributes](https://arxiv.org/abs/2507.13541)
*Shuyue Stella Li,Melanie Sclar,Hunter Lang,Ansong Ni,Jacqueline He,Puxin Xu,Andrew Cohen,Chan Young Park,Yulia Tsvetkov,Asli Celikyilmaz*

Main category: cs.AI

TL;DR: PrefPalette框架通过分解用户偏好的属性维度，结合多属性决策原则，显著提升了偏好预测的准确性，并提供了可解释的社区特定偏好分析。


<details>
  <summary>Details</summary>
Motivation: 当前偏好模型将人类判断视为黑箱，无法理解偏好背后的原因。PrefPalette旨在通过分解偏好属性，捕捉不同社会社区的动态权重，实现更透明和个性化的AI系统。

Method: PrefPalette采用两步方法：(1) 可扩展的反事实属性合成，生成合成训练数据以隔离个体属性效应；(2) 基于注意力的偏好建模，学习不同社区如何动态加权这些属性。

Result: 在Reddit的45个社区中，PrefPalette的平均预测准确率比GPT-4o高出46.6%，并揭示了社区特定的偏好特征（如学术社区重视冗长和刺激，冲突社区偏好讽刺和直接）。

Conclusion: PrefPalette不仅提升了偏好预测性能，还提供了透明和可解释的洞察，为更可信、价值感知的个性化应用奠定了基础。

Abstract: Personalizing AI systems requires understanding not just what users prefer,
but the reasons that underlie those preferences - yet current preference models
typically treat human judgment as a black box. We introduce PrefPalette, a
framework that decomposes preferences into attribute dimensions and tailors its
preference prediction to distinct social community values in a
human-interpretable manner. PrefPalette operationalizes a cognitive science
principle known as multi-attribute decision making in two ways: (1) a scalable
counterfactual attribute synthesis step that involves generating synthetic
training data to isolate for individual attribute effects (e.g., formality,
humor, cultural values), and (2) attention-based preference modeling that
learns how different social communities dynamically weight these attributes.
This approach moves beyond aggregate preference modeling to capture the diverse
evaluation frameworks that drive human judgment. When evaluated on 45 social
communities from the online platform Reddit, PrefPalette outperforms GPT-4o by
46.6% in average prediction accuracy. Beyond raw predictive improvements,
PrefPalette also shed light on intuitive, community-specific profiles:
scholarly communities prioritize verbosity and stimulation, conflict-oriented
communities value sarcasm and directness, and support-based communities
emphasize empathy. By modeling the attribute-mediated structure of human
judgment, PrefPalette delivers both superior preference modeling and
transparent, interpretable insights, and serves as a first step toward more
trustworthy, value-aware personalized applications.

</details>


### [85] [DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs](https://arxiv.org/abs/2507.13737)
*Ye Tian,Xiaoyuan Ren,Zihao Wang,Onat Gungor,Xiaofan Yu,Tajana Rosing*

Main category: cs.AI

TL;DR: DailyLLM是一个基于轻量级LLM的框架，通过整合位置、运动、环境和生理四个维度的上下文信息，显著提升了活动日志生成的准确性、效率和语义丰富性。


<details>
  <summary>Details</summary>
Motivation: 现有活动日志生成方法在准确性、效率和语义丰富性方面存在不足，而LLM的语义理解和生成能力为解决这些问题提供了新机会。

Method: DailyLLM采用轻量级LLM框架，结合结构化提示和高效特征提取，实现高级活动理解。

Result: 实验表明，DailyLLM在BERTScore精度上比70B参数的SOTA基线提升17%，推理速度提升近10倍，且能在个人电脑和树莓派上高效部署。

Conclusion: DailyLLM为活动日志生成提供了高效、准确的解决方案，展示了轻量级LLM在实际应用中的潜力。

Abstract: Rich and context-aware activity logs facilitate user behavior analysis and
health monitoring, making them a key research focus in ubiquitous computing.
The remarkable semantic understanding and generation capabilities of Large
Language Models (LLMs) have recently created new opportunities for activity log
generation. However, existing methods continue to exhibit notable limitations
in terms of accuracy, efficiency, and semantic richness. To address these
challenges, we propose DailyLLM. To the best of our knowledge, this is the
first log generation and summarization system that comprehensively integrates
contextual activity information across four dimensions: location, motion,
environment, and physiology, using only sensors commonly available on
smartphones and smartwatches. To achieve this, DailyLLM introduces a
lightweight LLM-based framework that integrates structured prompting with
efficient feature extraction to enable high-level activity understanding.
Extensive experiments demonstrate that DailyLLM outperforms state-of-the-art
(SOTA) log generation methods and can be efficiently deployed on personal
computers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM
achieves a 17% improvement in log generation BERTScore precision compared to
the 70B-parameter SOTA baseline, while delivering nearly 10x faster inference
speed.

</details>


### [86] [GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models](https://arxiv.org/abs/2507.13550)
*Eduardo C. Garrido-Merchán,Cristina Puente*

Main category: cs.AI

TL;DR: 论文提出了一种结合大型语言模型（LLMs）和符号系统的新方法，以可控透明的方式开发专家系统，解决了LLMs的幻觉和不可验证事实问题。


<details>
  <summary>Details</summary>
Motivation: LLMs在知识系统中存在幻觉和生成不可验证事实的问题，需要一种可控透明的方法来开发可靠的专家系统。

Method: 通过限制领域并使用结构化提示提取方法，将知识表示为Prolog符号形式，并由人类专家验证和修正。

Result: 实验显示，该方法在事实准确性和语义连贯性上表现优异，结合了LLMs的召回能力和符号系统的精确性。

Conclusion: 该方法为敏感领域提供了可靠、可解释且可扩展的AI应用基础。

Abstract: The development of large language models (LLMs) has successfully transformed
knowledge-based systems such as open domain question nswering, which can
automatically produce vast amounts of seemingly coherent information. Yet,
those models have several disadvantages like hallucinations or confident
generation of incorrect or unverifiable facts. In this paper, we introduce a
new approach to the development of expert systems using LLMs in a controlled
and transparent way. By limiting the domain and employing a well-structured
prompt-based extraction approach, we produce a symbolic representation of
knowledge in Prolog, which can be validated and corrected by human experts.
This approach also guarantees interpretability, scalability and reliability of
the developed expert systems. Via quantitative and qualitative experiments with
Claude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic
coherence on our generated knowledge bases. We present a transparent hybrid
solution that combines the recall capacity of LLMs with the precision of
symbolic systems, thereby laying the foundation for dependable AI applications
in sensitive domains.

</details>


### [87] [Why Isn't Relational Learning Taking Over the World?](https://arxiv.org/abs/2507.13558)
*David Poole*

Main category: cs.AI

TL;DR: 论文探讨了当前AI主要关注像素和单词建模的局限性，提出应更关注实体及其关系的建模，并分析了关系学习未普及的原因及其未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统主要建模像素和单词，而世界由实体及其关系构成，应直接建模这些实体而非其感知或描述。

Method: 通过分析关系学习（如统计关系AI）的现状，探讨其未普及的原因。

Result: 关系学习仅在有限案例中应用，需进一步研究以提升其重要性。

Conclusion: 关系学习应成为AI的核心方向，需更多研究以解决其普及的障碍。

Abstract: AI seems to be taking over the world with systems that model pixels, words,
and phonemes. The world is arguably made up, not of pixels, words, and phonemes
but of entities (objects, things, including events) with properties and
relations among them. Surely we should model these, not the perception or
description of them. You might suspect that concentrating on modeling words and
pixels is because all of the (valuable) data in the world is in terms of text
and images. If you look into almost any company you will find their most
valuable data is in spreadsheets, databases and other relational formats. These
are not the form that are studied in introductory machine learning, but are
full of product numbers, student numbers, transaction numbers and other
identifiers that can't be interpreted naively as numbers. The field that
studies this sort of data has various names including relational learning,
statistical relational AI, and many others. This paper explains why relational
learning is not taking over the world -- except in a few cases with restricted
relations -- and what needs to be done to bring it to it's rightful prominence.

</details>


### [88] [Cross-modal Causal Intervention for Alzheimer's Disease Prediction](https://arxiv.org/abs/2507.13956)
*Yutao Jin,Haowen Xiao,Jielei Chu,Fengmao Lv,Yuxiao Li,Tianrui Li*

Main category: cs.AI

TL;DR: 论文提出了一种名为ADPC的视觉-语言因果干预框架，用于辅助诊断阿尔茨海默病（AD），通过消除混杂因素提升分类准确性。


<details>
  <summary>Details</summary>
Motivation: 早期识别轻度认知障碍（MCI）和AD对延缓痴呆进展至关重要，但现有方法因数据选择偏差和变量复杂关系面临挑战。

Method: ADPC结合MRI、fMRI图像和LLM生成的文本数据，通过因果干预消除混杂因素，分类CN/MCI/AD。

Result: 实验表明ADPC在CN/MCI/AD分类中表现优异，达到SOTA水平。

Conclusion: 研究展示了因果推理与多模态学习结合在神经疾病诊断中的潜力。

Abstract: Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's
Disease (AD), where early identification and intervention can effectively slow
the progression to dementia. However, diagnosing AD remains a significant
challenge in neurology due to the confounders caused mainly by the selection
bias of multimodal data and the complex relationships between variables. To
address these issues, we propose a novel visual-language causal intervention
framework named Alzheimer's Disease Prediction with Cross-modal Causal
Intervention (ADPC) for diagnostic assistance. Our ADPC employs large language
model (LLM) to summarize clinical data under strict templates, maintaining
structured text outputs even with incomplete or unevenly distributed datasets.
The ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)
images and textual data generated by LLM to classify participants into
Cognitively Normal (CN), MCI, and AD categories. Because of the presence of
confounders, such as neuroimaging artifacts and age-related biomarkers,
non-causal models are likely to capture spurious input-output correlations,
generating less reliable results. Our framework implicitly eliminates
confounders through causal intervention. Experimental results demonstrate the
outstanding performance of our method in distinguishing CN/MCI/AD cases,
achieving state-of-the-art (SOTA) metrics across most evaluation metrics. The
study showcases the potential of integrating causal reasoning with multi-modal
learning for neurological disease diagnosis.

</details>


### [89] [BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety](https://arxiv.org/abs/2507.13625)
*Yuxin Zhang,Xi Wang,Mo Hu,Zhenyu Zhang*

Main category: cs.AI

TL;DR: BifrostRAG是一种双图RAG系统，通过结合语言关系和文档结构，显著提升多跳问题的检索和回答性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统RAG系统在处理复杂法规文本和多跳查询时的局限性。

Method: 引入双图架构（实体网络图和文档导航图），结合图遍历和向量语义搜索。

Result: 在多项指标上显著优于单模态RAG基线，F1分数达87.3%。

Conclusion: BifrostRAG为复杂技术文档的检索提供了可推广的解决方案。

Abstract: Information retrieval and question answering from safety regulations are
essential for automated construction compliance checking but are hindered by
the linguistic and structural complexity of regulatory text. Many
compliance-related queries are multi-hop, requiring synthesis of information
across interlinked clauses. This poses a challenge for traditional
retrieval-augmented generation (RAG) systems. To overcome this, we introduce
BifrostRAG: a dual-graph RAG-integrated system that explicitly models both
linguistic relationships (via an Entity Network Graph) and document structure
(via a Document Navigator Graph). This architecture powers a hybrid retrieval
mechanism that combines graph traversal with vector-based semantic search,
enabling large language models to reason over both the meaning and the
structure of the text. Evaluation on a multi-hop question dataset shows that
BifrostRAG achieves 92.8 percent precision, 85.5 percent recall, and an F1
score of 87.3 percent. These results significantly outperform vector-only and
graph-only RAG baselines that represent current leading approaches. Error
analysis further highlights the comparative advantages of our hybrid method
over single-modality RAGs. These findings establish BifrostRAG as a robust
knowledge engine for LLM-driven compliance checking. Its dual-graph, hybrid
retrieval mechanism offers a transferable blueprint for navigating complex
technical documents across knowledge-intensive engineering domains.

</details>


### [90] [Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks](https://arxiv.org/abs/2507.13651)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 论文探讨了基于最终答案的自动错误诊断方法，用于解决学生在智能辅导系统中组合多步骤任务时的错误诊断问题。


<details>
  <summary>Details</summary>
Motivation: 智能辅导系统中，学生将多个步骤组合为一步时，可能的路径组合爆炸导致错误诊断困难。利用最终答案进行诊断可以缓解这一问题。

Method: 设计了一种基于最终答案的错误诊断服务，并通过现有数据集（n=1939）验证其有效性。

Result: 结果显示，该方法能诊断29.4%的未诊断步骤，且与教师诊断结果的一致性达到97%。

Conclusion: 该方法为未来进一步探索提供了基础。

Abstract: Many intelligent tutoring systems can support a student in solving a stepwise
task. When a student combines several steps in one step, the number of possible
paths connecting consecutive inputs may be very large. This combinatorial
explosion makes error diagnosis hard. Using a final answer to diagnose a
combination of steps can mitigate the combinatorial explosion, because there
are generally fewer possible (erroneous) final answers than (erroneous)
solution paths. An intermediate input for a task can be diagnosed by
automatically completing it according to the task solution strategy and
diagnosing this solution. This study explores the potential of automated error
diagnosis based on a final answer. We investigate the design of a service that
provides a buggy rule diagnosis when a student combines several steps. To
validate the approach, we apply the service to an existing dataset (n=1939) of
unique student steps when solving quadratic equations, which could not be
diagnosed by a buggy rule service that tries to connect consecutive inputs with
a single rule. Results show that final answer evaluation can diagnose 29,4% of
these steps. Moreover, a comparison of the generated diagnoses with teacher
diagnoses on a subset (n=115) shows that the diagnoses align in 97% of the
cases. These results can be considered a basis for further exploration of the
approach.

</details>


### [91] [Combining model tracing and constraint-based modeling for multistep strategy diagnoses](https://arxiv.org/abs/2507.13652)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 提出了一种结合模型追踪和约束建模的方法，用于诊断学生在多步任务中的输入，并在实际数据中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决模型追踪和约束建模各自在多步任务诊断中的局限性，提出一种综合方法。

Method: 将约束定义为学生输入与策略步骤的共同属性，支持对偏离策略的多步输入进行诊断。

Result: 系统诊断与教师编码在140个学生步骤中完全一致。

Conclusion: 该方法在多步策略诊断中具有可行性，且与人工诊断结果高度一致。

Abstract: Model tracing and constraint-based modeling are two approaches to diagnose
student input in stepwise tasks. Model tracing supports identifying consecutive
problem-solving steps taken by a student, whereas constraint-based modeling
supports student input diagnosis even when several steps are combined into one
step. We propose an approach that merges both paradigms. By defining
constraints as properties that a student input has in common with a step of a
strategy, it is possible to provide a diagnosis when a student deviates from a
strategy even when the student combines several steps. In this study we explore
the design of a system for multistep strategy diagnoses, and evaluate these
diagnoses. As a proof of concept, we generate diagnoses for an existing dataset
containing steps students take when solving quadratic equations (n=2136). To
compare with human diagnoses, two teachers coded a random sample of deviations
(n=70) and applications of the strategy (n=70). Results show that that the
system diagnosis aligned with the teacher coding in all of the 140 student
steps.

</details>


### [92] [OntView: What you See is What you Meant](https://arxiv.org/abs/2507.13759)
*Carlos Bobed,Carlota Quintana,Eduardo Mena,Jorge Bobed,Fernando Bobillo*

Main category: cs.AI

TL;DR: OntView是一款开源的本体查看器，旨在通过直观的可视化界面展示本体结构和推理知识，解决了现有工具在图形化表示上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有本体编辑器和查看器在图形化表示本体结构时效果不佳，限制了用户对大型本体框架的理解。

Method: OntView基于DL推理器，采用“所见即所意”范式，支持可视化通用概念包含（GCI），并提供简化视图功能（如本体摘要、聚焦TBox元素、动态隐藏/显示分支）。

Result: OntView能够直观展示本体概念及其关系，避免信息过载，并通过开源方式提供给社区。

Conclusion: OntView填补了现有可视化工具的空白，提升了用户对本体的理解和操作效率。

Abstract: In the field of knowledge management and computer science, ontologies provide
a structured framework for modeling domain-specific knowledge by defining
concepts and their relationships. However, the lack of tools that provide
effective visualization is still a significant challenge. While numerous
ontology editors and viewers exist, most of them fail to graphically represent
ontology structures in a meaningful and non-overwhelming way, limiting users'
ability to comprehend dependencies and properties within large ontological
frameworks.
  In this paper, we present OntView, an ontology viewer that is designed to
provide users with an intuitive visual representation of ontology concepts and
their formal definitions through a user-friendly interface. Building on the use
of a DL reasoner, OntView follows a "What you see is what you meant" paradigm,
showing the actual inferred knowledge. One key aspect for this is its ability
to visualize General Concept Inclusions (GCI), a feature absent in existing
visualization tools. Moreover, to avoid a possible information overload,
OntView also offers different ways to show a simplified view of the ontology
by: 1) creating ontology summaries by assessing the importance of the concepts
(according to different available algorithms), 2) focusing the visualization on
the existing TBox elements between two given classes and 3) allowing to
hide/show different branches in a dynamic way without losing the semantics.
OntView has been released with an open-source license for the whole community.

</details>


### [93] [From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning](https://arxiv.org/abs/2507.13768)
*Renato Ghisellini,Remo Pareschi,Marco Pedroni,Giovanni Battista Raggi*

Main category: cs.AI

TL;DR: 提出了一种结合启发式提取、语义激活和组合合成的混合架构，用于增强代理的战略推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统决策引擎通常选择最佳规则，而该研究旨在通过语义交互建模和修辞框架，将冲突的启发式融合为连贯且上下文敏感的叙述。

Method: 结合启发式提取、语义激活和组合合成，利用量子认知研究的语义相互依赖性激活和组合多个启发式。

Result: 通过Meta vs. FTC案例研究展示了框架，并通过语义指标进行了初步验证。

Conclusion: 讨论了动态干扰调优等局限性和扩展方向。

Abstract: We present a hybrid architecture for agent-augmented strategic reasoning,
combining heuristic extraction, semantic activation, and compositional
synthesis. Drawing on sources ranging from classical military theory to
contemporary corporate strategy, our model activates and composes multiple
heuristics through a process of semantic interdependence inspired by research
in quantum cognition. Unlike traditional decision engines that select the best
rule, our system fuses conflicting heuristics into coherent and
context-sensitive narratives, guided by semantic interaction modeling and
rhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,
with preliminary validation through semantic metrics. Limitations and
extensions (e.g., dynamic interference tuning) are discussed.

</details>


### [94] [Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment](https://arxiv.org/abs/2507.14107)
*Viraj Nishesh Darji,Callie C. Liao,Duoduo Liao*

Main category: cs.AI

TL;DR: 该研究探讨了大型语言模型（LLMs）在桥梁无损评估（NDE）数据分析中的应用，展示了LLMs在提高效率和准确性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 桥梁维护和安全至关重要，但NDE数据分析耗时且需要专业知识，LLMs为自动化分析提供了新途径。

Method: 研究设计了特定提示词，利用多种LLMs分析NDE等高线图，评估其描述能力、缺陷识别和推荐准确性。

Result: 九种模型中四种表现更优，其中ChatGPT-4和Claude 3.5 Sonnet生成的总结更有效。

Conclusion: LLMs可显著提升桥梁维护决策效率，为基础设施管理提供创新解决方案。

Abstract: Bridge maintenance and safety are essential for transportation authorities,
and Non-Destructive Evaluation (NDE) techniques are critical to assessing
structural integrity. However, interpreting NDE data can be time-consuming and
requires expertise, potentially delaying decision-making. Recent advancements
in Large Language Models (LLMs) offer new ways to automate and improve this
analysis. This pilot study introduces a holistic assessment of LLM capabilities
for interpreting NDE contour maps and demonstrates the effectiveness of LLMs in
providing detailed bridge condition analyses. It establishes a framework for
integrating LLMs into bridge inspection workflows, indicating that LLM-assisted
analysis can enhance efficiency without compromising accuracy. In this study,
several LLMs are explored with prompts specifically designed to enhance the
quality of image descriptions, which are applied to interpret five different
NDE contour maps obtained through technologies for assessing bridge conditions.
Each LLM model is evaluated based on its ability to produce detailed
descriptions, identify defects, provide actionable recommendations, and
demonstrate overall accuracy. The research indicates that four of the nine
models provide better image descriptions, effectively covering a wide range of
topics related to the bridge's condition. The outputs from these four models
are summarized using five different LLMs to form a comprehensive overview of
the bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more
effective summaries. The findings suggest that LLMs have the potential to
significantly improve efficiency and accuracy. This pilot study presents an
innovative approach that leverages LLMs for image captioning in parallel and
summarization, enabling faster decision-making in bridge maintenance and
enhancing infrastructure management and safety assessments.

</details>


### [95] [When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction](https://arxiv.org/abs/2507.13825)
*Haoyang Li,Yuming Xu,Yiming Li,Hanmo Liu,Darian Li,Chen Jason Zhang,Lei Chen,Qing Li*

Main category: cs.AI

TL;DR: EAGLE是一个轻量级框架，用于动态图中的时间链接预测，通过结合短期时间新近性和长期全局结构模式，显著提高了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有T-GNNs在建模时间和结构依赖时计算开销大，存在可扩展性和效率问题。

Method: EAGLE包含时间感知模块和结构感知模块，采用自适应权重机制平衡两者，避免复杂计算。

Result: 在七个真实世界动态图上，EAGLE在性能和效率上均优于现有T-GNNs，速度提升50倍以上。

Conclusion: EAGLE通过轻量级设计，解决了T-GNNs的计算效率问题，同时保持了高性能。

Abstract: Temporal link prediction in dynamic graphs is a critical task with
applications in diverse domains such as social networks, recommendation
systems, and e-commerce platforms. While existing Temporal Graph Neural
Networks (T-GNNs) have achieved notable success by leveraging complex
architectures to model temporal and structural dependencies, they often suffer
from scalability and efficiency challenges due to high computational overhead.
In this paper, we propose EAGLE, a lightweight framework that integrates
short-term temporal recency and long-term global structural patterns. EAGLE
consists of a time-aware module that aggregates information from a node's most
recent neighbors to reflect its immediate preferences, and a structure-aware
module that leverages temporal personalized PageRank to capture the influence
of globally important nodes. To balance these attributes, EAGLE employs an
adaptive weighting mechanism to dynamically adjust their contributions based on
data characteristics. Also, EAGLE eliminates the need for complex multi-hop
message passing or memory-intensive mechanisms, enabling significant
improvements in efficiency. Extensive experiments on seven real-world temporal
graphs demonstrate that EAGLE consistently achieves superior performance
against state-of-the-art T-GNNs in both effectiveness and efficiency,
delivering more than a 50x speedup over effective transformer-based T-GNNs.

</details>


### [96] [Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments](https://arxiv.org/abs/2507.13846)
*Kathrin Korte,Christian Medeiros Adriano,Sona Ghahremani,Holger Giese*

Main category: cs.AI

TL;DR: 论文提出了一种基于因果知识转移的多智能体强化学习框架，用于非静态环境中智能体间的知识共享与适应。


<details>
  <summary>Details</summary>
Motivation: 解决传统知识转移方法在多智能体强化学习中难以泛化的问题，减少智能体在环境变化时的重新训练成本。

Method: 引入因果知识转移框架，通过建模碰撞为因果干预，生成恢复动作宏并在线转移给其他智能体，实现零样本适应。

Result: 实验表明，智能体在新环境中能填补随机探索与完全重新训练策略之间约一半的差距，且因果知识转移效果受环境复杂性和智能体目标异质性影响。

Conclusion: 因果知识转移框架为多智能体强化学习在非静态环境中的知识共享提供了有效解决方案。

Abstract: [Context] Multi-agent reinforcement learning (MARL) has achieved notable
success in environments where agents must learn coordinated behaviors. However,
transferring knowledge across agents remains challenging in non-stationary
environments with changing goals. [Problem] Traditional knowledge transfer
methods in MARL struggle to generalize, and agents often require costly
retraining to adapt. [Approach] This paper introduces a causal knowledge
transfer framework that enables RL agents to learn and share compact causal
representations of paths within a non-stationary environment. As the
environment changes (new obstacles), agents' collisions require adaptive
recovery strategies. We model each collision as a causal intervention
instantiated as a sequence of recovery actions (a macro) whose effect
corresponds to a causal knowledge of how to circumvent the obstacle while
increasing the chances of achieving the agent's goal (maximizing cumulative
reward). This recovery action macro is transferred online from a second agent
and is applied in a zero-shot fashion, i.e., without retraining, just by
querying a lookup model with local context information (collisions). [Results]
Our findings reveal two key insights: (1) agents with heterogeneous goals were
able to bridge about half of the gap between random exploration and a fully
retrained policy when adapting to new environments, and (2) the impact of
causal knowledge transfer depends on the interplay between environment
complexity and agents' heterogeneous goals.

</details>


### [97] [Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery](https://arxiv.org/abs/2507.13874)
*Mateusz Bystroński,Mikołaj Hołysz,Grzegorz Piotrowski,Nitesh V. Chawla,Tomasz Kajdanowicz*

Main category: cs.AI

TL;DR: 论文提出了一种模型无关的潜在空间创意框架，旨在解决LLMs在生成新颖且相关创意时的局限性，无需手工规则，适应性强。


<details>
  <summary>Details</summary>
Motivation: LLMs在生成新颖且相关的创意时表现不佳，通常依赖训练数据的模式，缺乏创造性发散能力。现有方法依赖领域特定启发式规则，难以推广。

Method: 提出了一种模型无关的潜在空间创意框架，通过导航连续嵌入空间实现可控、可扩展的创意生成。

Result: 初步结果显示该框架具有潜力，可作为通用的人机协作创意工具。

Conclusion: 该框架为LLMs的创造性应用提供了新方向，有望成为通用的人机协作创意工具。

Abstract: Innovative idea generation remains a core challenge in AI, as large language
models (LLMs) often struggle to produce outputs that are both novel and
relevant. Despite their fluency, LLMs tend to replicate patterns seen during
training, limiting their ability to diverge creatively without extensive prompt
engineering. Prior work has addressed this through domain-specific heuristics
and structured prompting pipelines, but such solutions are brittle and
difficult to generalize. In this paper, we propose a model-agnostic
latent-space ideation framework that enables controlled, scalable creativity by
navigating the continuous embedding space of ideas. Unlike prior methods, our
framework requires no handcrafted rules and adapts easily to different domains,
input formats, and creative tasks. This paper introduces an early-stage
prototype of our method, outlining the conceptual framework and preliminary
results highlighting its potential as a general-purpose co-ideator for human-AI
collaboration.

</details>


### [98] [Towards Constraint Temporal Answer Set Programming](https://arxiv.org/abs/2507.13958)
*Pedro Cabalar,Martín Diéguez,François Olivier,Torsten Schaub,Igor Stéphan*

Main category: cs.AI

TL;DR: 提出了一种新的基于时间和约束的逻辑扩展方法，用于解决动态系统中的高分辨率时序和数值推理问题。


<details>
  <summary>Details</summary>
Motivation: 针对动态系统中高分辨率时序和数值推理的挑战，传统逻辑方法（如ASP）表现不足。

Method: 结合线性时间逻辑和非单调约束逻辑，提出了一种新的时序和约束扩展方法。

Result: 建立了一个适用于ASP范式的逻辑框架，能够处理复杂动态系统的高分辨率问题。

Conclusion: 该方法为动态系统的高分辨率推理提供了新的理论基础。

Abstract: Reasoning about dynamic systems with a fine-grained temporal and numeric
resolution presents significant challenges for logic-based approaches like
Answer Set Programming (ASP). To address this, we introduce and elaborate upon
a novel temporal and constraint-based extension of the logic of Here-and-There
and its nonmonotonic equilibrium extension, representing, to the best of our
knowledge, the first approach to nonmonotonic temporal reasoning with
constraints specifically tailored for ASP. This expressive system is achieved
by a synergistic combination of two foundational ASP extensions: the
linear-time logic of Here-and-There, providing robust nonmonotonic temporal
reasoning capabilities, and the logic of Here-and-There with constraints,
enabling the direct integration and manipulation of numeric constraints, among
others. This work establishes the foundational logical framework for tackling
complex dynamic systems with high resolution within the ASP paradigm.

</details>


### [99] [KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models](https://arxiv.org/abs/2507.14032)
*Lam Nguyen,Erika Barcelos,Roger French,Yinghui Wu*

Main category: cs.AI

TL;DR: KROMA是一个基于大型语言模型（LLM）和检索增强生成（RAG）的新型本体匹配框架，通过动态丰富语义上下文，显著提升了本体匹配性能。


<details>
  <summary>Details</summary>
Motivation: 现有本体匹配系统依赖手工规则或专用模型，适应性有限，需要更灵活高效的解决方案。

Method: KROMA结合了双相似度概念匹配和轻量级本体优化步骤，减少LLM调用开销，并通过RAG管道动态整合结构、词汇和定义知识。

Result: 实验表明，KROMA在多个基准数据集上优于传统系统和前沿LLM方法，同时保持较低通信开销。

Conclusion: 研究证实了知识检索、提示增强和本体优化等技术在大规模本体匹配中的可行性和优势。

Abstract: Ontology Matching (OM) is a cornerstone task of semantic interoperability,
yet existing systems often rely on handcrafted rules or specialized models with
limited adaptability. We present KROMA, a novel OM framework that harnesses
Large Language Models (LLMs) within a Retrieval-Augmented Generation (RAG)
pipeline to dynamically enrich the semantic context of OM tasks with
structural, lexical, and definitional knowledge. To optimize both performance
and efficiency, KROMA integrates a bisimilarity-based concept matching and a
lightweight ontology refinement step, which prune candidate concepts and
substantially reduce the communication overhead from invoking LLMs. Through
experiments on multiple benchmark datasets, we show that integrating knowledge
retrieval with context-augmented LLMs significantly enhances ontology matching,
outperforming both classic OM systems and cutting-edge LLM-based approaches
while keeping communication overhead comparable. Our study highlights the
feasibility and benefit of the proposed optimization techniques (targeted
knowledge retrieval, prompt enrichment, and ontology refinement) for ontology
matching at scale.

</details>


### [100] [Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions](https://arxiv.org/abs/2507.14077)
*Temiloluwa Prioleau,Baiying Lu,Yanjun Cui*

Main category: cs.AI

TL;DR: Glucose-ML是一个包含10个公开糖尿病数据集的集合，旨在加速透明、可重复和稳健的AI解决方案开发，并提供数据选择和血糖预测的基准。


<details>
  <summary>Details</summary>
Motivation: 高质量糖尿病数据集的获取困难阻碍了稳健AI解决方案的开发，因此需要公开数据集以促进研究。

Method: 收集并分析了10个公开糖尿病数据集（Glucose-ML），包含38百万个血糖样本，并进行了血糖预测的案例研究。

Result: 同一算法在不同数据集上的预测结果差异显著，研究结果为开发稳健AI解决方案提供了建议。

Conclusion: Glucose-ML数据集和代码的公开为糖尿病和其他健康领域的AI研究提供了重要资源。

Abstract: Artificial intelligence (AI) algorithms are a critical part of
state-of-the-art digital health technology for diabetes management. Yet, access
to large high-quality datasets is creating barriers that impede development of
robust AI solutions. To accelerate development of transparent, reproducible,
and robust AI solutions, we present Glucose-ML, a collection of 10 publicly
available diabetes datasets, released within the last 7 years (i.e., 2018 -
2025). The Glucose-ML collection comprises over 300,000 days of continuous
glucose monitor (CGM) data with a total of 38 million glucose samples collected
from 2500+ people across 4 countries. Participants include persons living with
type 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support
researchers and innovators with using this rich collection of diabetes
datasets, we present a comparative analysis to guide algorithm developers with
data selection. Additionally, we conduct a case study for the task of blood
glucose prediction - one of the most common AI tasks within the field. Through
this case study, we provide a benchmark for short-term blood glucose prediction
across all 10 publicly available diabetes datasets within the Glucose-ML
collection. We show that the same algorithm can have significantly different
prediction results when developed/evaluated with different datasets. Findings
from this study are then used to inform recommendations for developing robust
AI solutions within the diabetes or broader health domain. We provide direct
links to each longitudinal diabetes dataset in the Glucose-ML collection and
openly provide our code.

</details>


### [101] [Generative AI-Driven High-Fidelity Human Motion Simulation](https://arxiv.org/abs/2507.14097)
*Hari Iyer,Neel Macwan,Atharva Jitendra Hude,Heejin Jeong,Shenghan Guo*

Main category: cs.AI

TL;DR: 该研究提出了一种基于生成式AI的人体运动模拟方法（G-AI-HMS），通过结合文本到文本和文本到运动模型，提高了工业任务中运动模拟的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的人体运动模拟方法在运动保真度上表现不佳，影响了工人行为、安全和生产效率的评估。

Method: G-AI-HMS利用大型语言模型将任务描述转化为运动感知语言，并通过计算机视觉验证AI生成的运动与真实人类动作的一致性。

Result: 在八项任务的案例研究中，AI生成的运动在大多数场景中表现出更低的误差，且在空间准确性、姿态对齐和时间相似性上优于人工描述。

Conclusion: AI增强的提示显著减少了关节误差和时间错位，同时保持了姿态准确性，为工业任务中的运动模拟提供了更高效的解决方案。

Abstract: Human motion simulation (HMS) supports cost-effective evaluation of worker
behavior, safety, and productivity in industrial tasks. However, existing
methods often suffer from low motion fidelity. This study introduces
Generative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and
text-to-motion models to enhance simulation quality for physical tasks.
G-AI-HMS tackles two key challenges: (1) translating task descriptions into
motion-aware language using Large Language Models aligned with MotionGPT's
training vocabulary, and (2) validating AI-enhanced motions against real human
movements using computer vision. Posture estimation algorithms are applied to
real-time videos to extract joint landmarks, and motion similarity metrics are
used to compare them with AI-enhanced sequences. In a case study involving
eight tasks, the AI-enhanced motions showed lower error than human created
descriptions in most scenarios, performing better in six tasks based on spatial
accuracy, four tasks based on alignment after pose normalization, and seven
tasks based on overall temporal similarity. Statistical analysis showed that
AI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and
temporal misalignment while retaining comparable posture accuracy.

</details>


### [102] [CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.14111)
*Xiaoya Li,Xiaofei Sun,Albert Wang,Jiwei Li,Chris Shum*

Main category: cs.AI

TL;DR: CUDA-L1是一种基于强化学习的自动化CUDA优化框架，显著提升CUDA内核性能，并具有跨GPU架构的移植性。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型对GPU计算资源的需求激增，亟需自动化CUDA优化方法。现有模型在CUDA优化上成功率低，因此提出CUDA-L1。

Method: 采用强化学习框架，通过速度提升奖励信号训练模型，无需人工干预或领域知识。

Result: 在NVIDIA A100上平均加速17.7倍，峰值达449倍，且在其他GPU架构上表现优异。

Conclusion: CUDA-L1证明强化学习可有效优化CUDA性能，为自动化GPU优化开辟新途径。

Abstract: The exponential growth in demand for GPU computing resources, driven by the
rapid advancement of Large Language Models, has created an urgent need for
automated CUDA optimization strategies. While recent advances in LLMs show
promise for code generation, current SOTA models (e.g. R1, o1) achieve low
success rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an
automated reinforcement learning framework for CUDA optimization.
  CUDA-L1 achieves performance improvements on the CUDA optimization task:
trained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250
CUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the
model also demonstrates excellent portability across GPU architectures,
achieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,
x14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.
Beyond these benchmark results, CUDA-L1 demonstrates several remarkable
properties: 1) Discovers a variety of CUDA optimization techniques and learns
to combine them strategically to achieve optimal performance; 2) Uncovers
fundamental principles of CUDA optimization; 3) Identifies non-obvious
performance bottlenecks and rejects seemingly beneficial optimizations that
harm performance.
  The capabilities of CUDA-L1 demonstrate that reinforcement learning can
transform an initially poor-performing LLM into an effective CUDA optimizer
through speedup-based reward signals alone, without human expertise or domain
knowledge. More importantly, the trained RL model extend the acquired reasoning
abilities to new kernels. This paradigm opens possibilities for automated
optimization of CUDA operations, and holds promise to substantially promote GPU
efficiency and alleviate the rising pressure on GPU computing resources.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [103] [Physical models realizing the transformer architecture of large language models](https://arxiv.org/abs/2507.13354)
*Zeqian Chen*

Main category: cs.LG

TL;DR: 本文从物理角度分析了Transformer架构，提出了一种基于开放量子系统的物理模型，以解释其工作原理。


<details>
  <summary>Details</summary>
Motivation: 填补对Transformer架构理论理解的空白，从物理角度解释其工作原理。

Method: 在Fock空间上构建物理模型，将大型语言模型视为开放量子系统。

Result: 提出了支持Transformer架构的物理模型。

Conclusion: 物理模型为Transformer架构提供了理论基础，解释了其有效性。

Abstract: The introduction of the transformer architecture in 2017 (cf.\cite{VSP2017})
marked the most striking advancement in natural language processing. The
transformer is a model architecture relying entirely on an attention mechanism
to draw global dependencies between input and output. However, we believe there
is a gap in our theoretical understanding of what the transformer is, and why
it works physically. In this paper, from a physical perspective on modern
chips, we construct physical models in the Fock space over the Hilbert space of
tokens realizing large language models based on a transformer architecture as
open quantum systems. Our physical models underlie the transformer architecture
for large language models.

</details>


### [104] [Whose View of Safety? A Deep DIVE Dataset for Pluralistic Alignment of Text-to-Image Models](https://arxiv.org/abs/2507.13383)
*Charvi Rastogi,Tian Huey Teh,Pushkar Mishra,Roma Patel,Ding Wang,Mark Díaz,Alicia Parrish,Aida Mostafazadeh Davani,Zoe Ashwood,Michela Paganini,Vinodkumar Prabhakaran,Verena Rieser,Lora Aroyo*

Main category: cs.LG

TL;DR: 该论文提出了一种多元对齐方法，通过引入DIVE数据集和实证研究，改进文本到图像（T2I）模型以更好地反映多样的人类价值观。


<details>
  <summary>Details</summary>
Motivation: 当前T2I模型未能充分考虑多样的人类体验，导致系统与人类价值观不一致。研究旨在实现多元对齐，使AI能够理解和适应多样且可能冲突的人类价值观。

Method: 1. 引入DIVE数据集，支持多元对齐的多模态数据集；2. 实证研究确认人口统计学特征作为多样观点的关键代理；3. 探讨构建对齐T2I模型的策略。

Result: 研究发现人口统计学特征在危害感知中存在显著差异，与传统评估不同。DIVE数据集为多元对齐提供了基础工具。

Conclusion: 该研究为构建更公平和对齐的T2I系统提供了基础工具，包括高效数据收集策略和模型可操控性。

Abstract: Current text-to-image (T2I) models often fail to account for diverse human
experiences, leading to misaligned systems. We advocate for pluralistic
alignment, where an AI understands and is steerable towards diverse, and often
conflicting, human values. Our work provides three core contributions to
achieve this in T2I models. First, we introduce a novel dataset for Diverse
Intersectional Visual Evaluation (DIVE) -- the first multimodal dataset for
pluralistic alignment. It enable deep alignment to diverse safety perspectives
through a large pool of demographically intersectional human raters who
provided extensive feedback across 1000 prompts, with high replication,
capturing nuanced safety perceptions. Second, we empirically confirm
demographics as a crucial proxy for diverse viewpoints in this domain,
revealing significant, context-dependent differences in harm perception that
diverge from conventional evaluations. Finally, we discuss implications for
building aligned T2I models, including efficient data collection strategies,
LLM judgment capabilities, and model steerability towards diverse perspectives.
This research offers foundational tools for more equitable and aligned T2I
systems. Content Warning: The paper includes sensitive content that may be
harmful.

</details>


### [105] [Improving KAN with CDF normalization to quantiles](https://arxiv.org/abs/2507.13393)
*Jakub Strawa,Jarek Duda*

Main category: cs.LG

TL;DR: 论文探讨了在机器学习中使用CDF归一化的优势，特别是在KANs中的应用，展示了其优于传统归一化方法的效果。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习中常用的归一化方法（如均值标准差或固定范围缩放）在金融领域的copula理论中并不常见，而CDF归一化能减少过拟合并提供更简单的表示。

Method: 通过将数据转换为CDF(x)实现归一化，应用于Kolmogorov-Arnold Networks (KANs)，并与Legendre-KAN进行比较。

Result: CDF归一化显著提升了KANs的预测性能，同时神经元权重可解释为混合矩，支持概率分布传播和方向调整。

Conclusion: CDF归一化在机器学习中具有潜力，尤其在KANs中表现优异，值得进一步研究和应用。

Abstract: Data normalization is crucial in machine learning, usually performed by
subtracting the mean and dividing by standard deviation, or by rescaling to a
fixed range. In copula theory, popular in finance, there is used normalization
to approximately quantiles by transforming x to CDF(x) with estimated CDF
(cumulative distribution function) to nearly uniform distribution in [0,1],
allowing for simpler representations which are less likely to overfit. It seems
nearly unknown in machine learning, therefore, we would like to present some
its advantages on example of recently popular Kolmogorov-Arnold Networks
(KANs), improving predictions from Legendre-KAN by just switching rescaling to
CDF normalization. Additionally, in HCR interpretation, weights of such neurons
are mixed moments providing local joint distribution models, allow to propagate
also probability distributions, and change propagation direction.

</details>


### [106] [Selective Embedding for Deep Learning](https://arxiv.org/abs/2507.13399)
*Mert Sehri,Zehui Hua,Francisco de Assis Boldt,Patrick Dumond*

Main category: cs.LG

TL;DR: 本文提出了一种名为选择性嵌入的新数据加载策略，通过交替加载多源数据的短片段来提升深度学习模型的泛化能力和计算效率。


<details>
  <summary>Details</summary>
Motivation: 深度学习对输入数据敏感，性能在非稳态条件和跨域数据中下降，传统数据加载策略限制了泛化或增加了计算成本。

Method: 选择性嵌入策略，模仿人类信息处理方式，交替加载多源数据的短片段于单一输入通道。

Result: 在六个时域数据集上验证，该方法显著提高了分类准确性并减少了训练时间。

Conclusion: 该方法适用于多源数据的复杂系统，为医疗、重工业、海洋、铁路和农业等领域提供了高效解决方案。

Abstract: Deep learning has revolutionized many industries by enabling models to
automatically learn complex patterns from raw data, reducing dependence on
manual feature engineering. However, deep learning algorithms are sensitive to
input data, and performance often deteriorates under nonstationary conditions
and across dissimilar domains, especially when using time-domain data.
Conventional single-channel or parallel multi-source data loading strategies
either limit generalization or increase computational costs. This study
introduces selective embedding, a novel data loading strategy, which alternates
short segments of data from multiple sources within a single input channel.
Drawing inspiration from cognitive psychology, selective embedding mimics
human-like information processing to reduce model overfitting, enhance
generalization, and improve computational efficiency. Validation is conducted
using six time-domain datasets, demonstrating that the proposed method
consistently achieves high classification accuracy across various deep learning
architectures while significantly reducing training times. The approach proves
particularly effective for complex systems with multiple data sources, offering
a scalable and resource-efficient solution for real-world applications in
healthcare, heavy machinery, marine, railway, and agriculture, where robustness
and adaptability are critical.

</details>


### [107] [LightAutoDS-Tab: Multi-AutoML Agentic System for Tabular Data](https://arxiv.org/abs/2507.13413)
*Aleksey Lapin,Igor Hromov,Stanislav Chumakov,Mile Mitrovic,Dmitry Simakov,Nikolay O. Nikitin,Andrey V. Savchenko*

Main category: cs.LG

TL;DR: LightAutoDS-Tab是一个结合LLM代码生成和多个AutoML工具的多代理系统，用于处理表格数据任务，提高了灵活性和鲁棒性，并在Kaggle任务中表现优于现有开源方案。


<details>
  <summary>Details</summary>
Motivation: 当前AutoML的效率受限于对特定底层工具的依赖，因此需要一种更灵活和鲁棒的方法来处理表格数据任务。

Method: 结合LLM代码生成和多个AutoML工具，构建多代理系统LightAutoDS-Tab。

Result: 在多个Kaggle数据科学任务中表现优于现有开源解决方案。

Conclusion: LightAutoDS-Tab通过多代理系统设计提升了AutoML的灵活性和鲁棒性，为表格数据任务提供了高效解决方案。

Abstract: AutoML has advanced in handling complex tasks using the integration of LLMs,
yet its efficiency remains limited by dependence on specific underlying tools.
In this paper, we introduce LightAutoDS-Tab, a multi-AutoML agentic system for
tasks with tabular data, which combines an LLM-based code generation with
several AutoML tools. Our approach improves the flexibility and robustness of
pipeline design, outperforming state-of-the-art open-source solutions on
several data science tasks from Kaggle. The code of LightAutoDS-Tab is
available in the open repository https://github.com/sb-ai-lab/LADS

</details>


### [108] [Gauge Flow Models](https://arxiv.org/abs/2507.13414)
*Alexander Strunk,Roland Assam*

Main category: cs.LG

TL;DR: Gauge Flow Models是一种新型生成流模型，通过引入可学习的Gauge Field提升性能，实验显示其在高斯混合模型上表现优于传统流模型。


<details>
  <summary>Details</summary>
Motivation: 传统流模型在某些任务上性能有限，Gauge Flow Models通过引入Gauge Field改进流ODE，旨在提升生成任务的性能。

Method: 在流ODE中引入可学习的Gauge Field，构建数学框架并实验验证其在高斯混合模型上的性能。

Result: 实验表明，Gauge Flow Models在相同或更大规模下性能显著优于传统流模型。

Conclusion: Gauge Flow Models具有潜力在更广泛的生成任务中提升性能，未来研究值得期待。

Abstract: This paper introduces Gauge Flow Models, a novel class of Generative Flow
Models. These models incorporate a learnable Gauge Field within the Flow
Ordinary Differential Equation (ODE). A comprehensive mathematical framework
for these models, detailing their construction and properties, is provided.
Experiments using Flow Matching on Gaussian Mixture Models demonstrate that
Gauge Flow Models yields significantly better performance than traditional Flow
Models of comparable or even larger size. Additionally, unpublished research
indicates a potential for enhanced performance across a broader range of
generative tasks.

</details>


### [109] [Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement: application to data-driven constitutive modeling](https://arxiv.org/abs/2507.13416)
*Jiaxiang Yi,Bernardo P. Ferreira,Miguel A. Bessa*

Main category: cs.LG

TL;DR: 该论文提出了一种层次化的数据驱动学习方法，能够处理多保真度数据并量化认知不确定性，同时区分数据噪声。


<details>
  <summary>Details</summary>
Motivation: 解决多保真度数据驱动学习中的认知不确定性和数据噪声问题，以提升模型的准确性和适用性。

Method: 采用层次化方法，从单保真度确定性神经网络扩展到多保真度贝叶斯循环神经网络，支持方差估计。

Result: 方法能够准确预测响应、量化模型误差，并发现噪声分布（如果存在）。

Conclusion: 该方法为科学和工程领域中的不确定性设计和分析提供了新的可能性。

Abstract: Data-driven learning is generalized to consider history-dependent
multi-fidelity data, while quantifying epistemic uncertainty and disentangling
it from data noise (aleatoric uncertainty). This generalization is hierarchical
and adapts to different learning scenarios: from training the simplest
single-fidelity deterministic neural networks up to the proposed multi-fidelity
variance estimation Bayesian recurrent neural networks. The versatility and
generality of the proposed methodology are demonstrated by applying it to
different data-driven constitutive modeling scenarios that include multiple
fidelities with and without aleatoric uncertainty (noise). The method
accurately predicts the response and quantifies model error while also
discovering the noise distribution (when present). This opens opportunities for
future real-world applications in diverse scientific and engineering domains;
especially, the most challenging cases involving design and analysis under
uncertainty.

</details>


### [110] [Soft-ECM: An extension of Evidential C-Means for complex data](https://arxiv.org/abs/2507.13417)
*Armel Soubeiga,Thomas Guyet,Violaine Antoine*

Main category: cs.LG

TL;DR: 提出了一种新的基于信念函数的聚类算法Soft-ECM，用于处理复杂数据（如混合数据和时间序列），无需依赖欧几里得空间性质。


<details>
  <summary>Details</summary>
Motivation: 现有基于信念函数的聚类算法无法处理复杂数据（如混合数据或非表格数据），限制了其应用范围。

Method: 重新定义Evidential C-Means问题，提出Soft-ECM算法，仅需半度量即可定位模糊聚类中心。

Result: 实验表明，Soft-ECM在数值数据上与常规模糊聚类方法效果相当，并能有效处理混合数据和时间序列数据。

Conclusion: Soft-ECM扩展了信念函数聚类的适用性，为复杂数据提供了一种有效的解决方案。

Abstract: Clustering based on belief functions has been gaining increasing attention in
the machine learning community due to its ability to effectively represent
uncertainty and/or imprecision. However, none of the existing algorithms can be
applied to complex data, such as mixed data (numerical and categorical) or
non-tabular data like time series. Indeed, these types of data are, in general,
not represented in a Euclidean space and the aforementioned algorithms make use
of the properties of such spaces, in particular for the construction of
barycenters. In this paper, we reformulate the Evidential C-Means (ECM) problem
for clustering complex data. We propose a new algorithm, Soft-ECM, which
consistently positions the centroids of imprecise clusters requiring only a
semi-metric. Our experiments show that Soft-ECM present results comparable to
conventional fuzzy clustering approaches on numerical data, and we demonstrate
its ability to handle mixed data and its benefits when combining fuzzy
clustering with semi-metrics such as DTW for time series data.

</details>


### [111] [Air Traffic Controller Task Demand via Graph Neural Networks: An Interpretable Approach to Airspace Complexity](https://arxiv.org/abs/2507.13423)
*Edward Henderson,Dewi Gould,Richard Everson,George De Ath,Nick Pepper*

Main category: cs.LG

TL;DR: 本文提出了一种基于图神经网络（GNN）的框架，用于实时评估空中交通管制员（ATCO）的任务需求，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有复杂性指标无法捕捉空中交通操作中的细微驱动因素，需要一种更可靠的方法来评估任务需求。

Method: 采用注意力机制的GNN模型，通过静态交通场景中的交互预测即将发布的指令数量，并通过系统性地移除飞机来推导可解释的任务需求评分。

Result: 该框架显著优于启发式方法，并能更可靠地评估场景复杂性，还能将任务需求归因于特定飞机。

Conclusion: 该工具为控制器培训和空域重新设计提供了新的复杂性分析方法。

Abstract: Real-time assessment of near-term Air Traffic Controller (ATCO) task demand
is a critical challenge in an increasingly crowded airspace, as existing
complexity metrics often fail to capture nuanced operational drivers beyond
simple aircraft counts. This work introduces an interpretable Graph Neural
Network (GNN) framework to address this gap. Our attention-based model predicts
the number of upcoming clearances, the instructions issued to aircraft by
ATCOs, from interactions within static traffic scenarios. Crucially, we derive
an interpretable, per-aircraft task demand score by systematically ablating
aircraft and measuring the impact on the model's predictions. Our framework
significantly outperforms an ATCO-inspired heuristic and is a more reliable
estimator of scenario complexity than established baselines. The resulting tool
can attribute task demand to specific aircraft, offering a new way to analyse
and understand the drivers of complexity for applications in controller
training and airspace redesign.

</details>


### [112] [Off-Policy Evaluation and Learning for Matching Markets](https://arxiv.org/abs/2507.13608)
*Yudai Hayashi,Shuhei Goda,Yuta Saito*

Main category: cs.LG

TL;DR: 论文提出两种新的离线策略评估方法（DiPS和DPR），针对匹配市场的双向性和大规模特性，优化了偏差-方差控制，并在理论和实验中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 匹配市场（如求职和约会平台）中，双向推荐系统的策略评估成本高且不实用，现有离线策略评估方法因方差问题和奖励稀疏性不可靠。

Method: 结合直接法（DM）、逆倾向得分（IPS）和双重稳健（DR）估计器，并引入中间标签（如初始参与信号），设计了DiPS和DPR方法。

Result: 理论分析表明新方法在偏差和方差上优于传统方法，实验验证了其在合成数据和真实求职平台数据中的优越性。

Conclusion: DiPS和DPR为匹配市场的离线策略评估和学习提供了高效可靠的解决方案。

Abstract: Matching users based on mutual preferences is a fundamental aspect of
services driven by reciprocal recommendations, such as job search and dating
applications. Although A/B tests remain the gold standard for evaluating new
policies in recommender systems for matching markets, it is costly and
impractical for frequent policy updates. Off-Policy Evaluation (OPE) thus plays
a crucial role by enabling the evaluation of recommendation policies using only
offline logged data naturally collected on the platform. However, unlike
conventional recommendation settings, the large scale and bidirectional nature
of user interactions in matching platforms introduce variance issues and
exacerbate reward sparsity, making standard OPE methods unreliable. To address
these challenges and facilitate effective offline evaluation, we propose novel
OPE estimators, \textit{DiPS} and \textit{DPR}, specifically designed for
matching markets. Our methods combine elements of the Direct Method (DM),
Inverse Propensity Score (IPS), and Doubly Robust (DR) estimators while
incorporating intermediate labels, such as initial engagement signals, to
achieve better bias-variance control in matching markets. Theoretically, we
derive the bias and variance of the proposed estimators and demonstrate their
advantages over conventional methods. Furthermore, we show that these
estimators can be seamlessly extended to offline policy learning methods for
improving recommendation policies for making more matches. We empirically
evaluate our methods through experiments on both synthetic data and A/B testing
logs from a real job-matching platform. The empirical results highlight the
superiority of our approach over existing methods in off-policy evaluation and
learning tasks for a variety of configurations.

</details>


### [113] [Improving Out-of-distribution Human Activity Recognition via IMU-Video Cross-modal Representation Learning](https://arxiv.org/abs/2507.13482)
*Seyyed Saeid Cheshmi,Buyao Lyu,Thomas Lisko,Rajesh Rajamani,Robert A. McGovern,Yogatheesan Varatharajah*

Main category: cs.LG

TL;DR: 提出了一种跨模态自监督预训练方法，用于从大规模未标记的IMU-视频数据中学习表示，提高了在分布外IMU数据集上的HAR任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有HAR方法依赖特定应用标签、泛化能力不足的问题，特别是在不同环境或人群中的数据。

Method: 采用跨模态自监督预训练方法，利用IMU-视频数据学习通用表示。

Result: 在零样本和少样本评估中，该方法优于现有IMU-视频预训练和仅IMU预训练方法。

Conclusion: 跨模态预训练是学习动态数据模态（如IMU信号）通用表示的有效工具。

Abstract: Human Activity Recognition (HAR) based on wearable inertial sensors plays a
critical role in remote health monitoring. In patients with movement disorders,
the ability to detect abnormal patient movements in their home environments can
enable continuous optimization of treatments and help alert caretakers as
needed. Machine learning approaches have been proposed for HAR tasks using
Inertial Measurement Unit (IMU) data; however, most rely on
application-specific labels and lack generalizability to data collected in
different environments or populations. To address this limitation, we propose a
new cross-modal self-supervised pretraining approach to learn representations
from large-sale unlabeled IMU-video data and demonstrate improved
generalizability in HAR tasks on out of distribution (OOD) IMU datasets,
including a dataset collected from patients with Parkinson's disease.
Specifically, our results indicate that the proposed cross-modal pretraining
approach outperforms the current state-of-the-art IMU-video pretraining
approach and IMU-only pretraining under zero-shot and few-shot evaluations.
Broadly, our study provides evidence that in highly dynamic data modalities,
such as IMU signals, cross-modal pretraining may be a useful tool to learn
generalizable data representations. Our software is available at
https://github.com/scheshmi/IMU-Video-OOD-HAR.

</details>


### [114] [Model-free Reinforcement Learning for Model-based Control: Towards Safe, Interpretable and Sample-efficient Agents](https://arxiv.org/abs/2507.13491)
*Thomas Banker,Ali Mesbah*

Main category: cs.LG

TL;DR: 论文提出模型驱动的智能体作为无模型强化学习的替代方案，以提高样本效率、安全性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 无模型强化学习（RL）在复杂系统中存在样本效率低、学习不安全及可解释性差的问题，需要更优的解决方案。

Method: 引入基于模型的智能体，利用系统动态、成本和约束的可适应模型进行安全策略学习，并结合无模型RL弥补模型失配。

Result: 模型驱动的智能体能够通过编码先验知识提高决策的安全性和可解释性，同时结合无模型RL优化性能。

Conclusion: 模型驱动与无模型RL的结合为高效、安全和可解释的决策智能体提供了新方向。

Abstract: Training sophisticated agents for optimal decision-making under uncertainty
has been key to the rapid development of modern autonomous systems across
fields. Notably, model-free reinforcement learning (RL) has enabled
decision-making agents to improve their performance directly through system
interactions, with minimal prior knowledge about the system. Yet, model-free RL
has generally relied on agents equipped with deep neural network function
approximators, appealing to the networks' expressivity to capture the agent's
policy and value function for complex systems. However, neural networks amplify
the issues of sample inefficiency, unsafe learning, and limited
interpretability in model-free RL. To this end, this work introduces
model-based agents as a compelling alternative for control policy
approximation, leveraging adaptable models of system dynamics, cost, and
constraints for safe policy learning. These models can encode prior system
knowledge to inform, constrain, and aid in explaining the agent's decisions,
while deficiencies due to model mismatch can be remedied with model-free RL. We
outline the benefits and challenges of learning model-based agents --
exemplified by model predictive control -- and detail the primary learning
approaches: Bayesian optimization, policy search RL, and offline strategies,
along with their respective strengths. While model-free RL has long been
established, its interplay with model-based agents remains largely unexplored,
motivating our perspective on their combined potentials for sample-efficient
learning of safe and interpretable decision-making agents.

</details>


### [115] [Fake or Real: The Impostor Hunt in Texts for Space Operations](https://arxiv.org/abs/2507.13508)
*Agata Kaczmarek,Dawid Płudowski,Piotr Wilczyński,Przemysław Biecek,Krzysztof Kotowski,Ramez Shendy,Jakub Nalepa,Artur Janicki,Evridiki Ntagiou*

Main category: cs.LG

TL;DR: Kaggle竞赛“Fake or Real”聚焦于识别恶意修改的LLM输出，涉及数据投毒和过度依赖LLM的安全威胁。


<details>
  <summary>Details</summary>
Motivation: 解决AI安全中的两大威胁：数据投毒和过度依赖大型语言模型（LLM），填补相关研究空白。

Method: 参与者需开发新技术或调整现有方法，以区分正常和恶意修改的LLM输出。

Result: 竞赛旨在推动针对LLM安全威胁的新解决方案。

Conclusion: 该竞赛为AI安全领域提供了研究平台，促进对抗恶意LLM输出的技术发展。

Abstract: The "Fake or Real" competition hosted on Kaggle
(\href{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt}{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt})
is the second part of a series of follow-up competitions and hackathons related
to the "Assurance for Space Domain AI Applications" project funded by the
European Space Agency
(\href{https://assurance-ai.space-codev.org/}{https://assurance-ai.space-codev.org/}).
The competition idea is based on two real-life AI security threats identified
within the project -- data poisoning and overreliance in Large Language Models.
The task is to distinguish between the proper output from LLM and the output
generated under malicious modification of the LLM. As this problem was not
extensively researched, participants are required to develop new techniques to
address this issue or adjust already existing ones to this problem's statement.

</details>


### [116] [Provable Low-Frequency Bias of In-Context Learning of Representations](https://arxiv.org/abs/2507.13540)
*Yongyi Yang,Hidenori Tanaka,Wei Hu*

Main category: cs.LG

TL;DR: 论文提出了一种双收敛框架，解释了大型语言模型（LLM）如何通过上下文学习（ICL）从输入序列中学习新行为，而无需参数更新。


<details>
  <summary>Details</summary>
Motivation: 探索LLM通过ICL学习新行为的机制，填补现有研究的空白。

Method: 引入双收敛框架，分析隐藏表示在上下文和层间的收敛过程，证明其对低频表示的隐式偏好。

Result: 理论解释了ICL的鲁棒性、表示几何结构及能量衰减现象，并通过实验验证。

Conclusion: 研究为ICL的机制提供了理论支持，并有望扩展到更广泛的数据分布和设置。

Abstract: In-context learning (ICL) enables large language models (LLMs) to acquire new
behaviors from the input sequence alone without any parameter updates. Recent
studies have shown that ICL can surpass the original meaning learned in
pretraining stage through internalizing the structure the data-generating
process (DGP) of the prompt into the hidden representations. However, the
mechanisms by which LLMs achieve this ability is left open. In this paper, we
present the first rigorous explanation of such phenomena by introducing a
unified framework of double convergence, where hidden representations converge
both over context and across layers. This double convergence process leads to
an implicit bias towards smooth (low-frequency) representations, which we prove
analytically and verify empirically. Our theory explains several open empirical
observations, including why learned representations exhibit globally structured
but locally distorted geometry, and why their total energy decays without
vanishing. Moreover, our theory predicts that ICL has an intrinsic robustness
towards high-frequency noise, which we empirically confirm. These results
provide new insights into the underlying mechanisms of ICL, and a theoretical
foundation to study it that hopefully extends to more general data
distributions and settings.

</details>


### [117] [Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk Stratification Using Echocardiography](https://arxiv.org/abs/2507.13542)
*Beka Begiashvili,Carlos J. Fernandez-Candel,Matías Pérez Paredes*

Main category: cs.LG

TL;DR: 提出了一种名为Acoustic Index的新型AI衍生超声心动图参数，用于量化心脏功能障碍，结合了EDMD和混合神经网络，临床验证显示其性能优越。


<details>
  <summary>Details</summary>
Motivation: 传统超声心动图参数（如EF和GLS）在早期检测心脏功能障碍时存在局限性，需要一种可重复、可解释且操作独立的参数。

Method: 结合基于Koopman算子理论的EDMD和混合神经网络，提取超声心动图序列的时空动态特征，并通过注意力机制和流形学习融合临床数据。

Result: 在736名患者的队列中，Acoustic Index的AUC为0.89，交叉验证显示敏感性和特异性均超过0.8。

Conclusion: Acoustic Index是一种物理驱动的可解释AI生物标志物，有望用于早期检测和监测，未来需进一步验证和优化。

Abstract: Traditional echocardiographic parameters such as ejection fraction (EF) and
global longitudinal strain (GLS) have limitations in the early detection of
cardiac dysfunction. EF often remains normal despite underlying pathology, and
GLS is influenced by load conditions and vendor variability. There is a growing
need for reproducible, interpretable, and operator-independent parameters that
capture subtle and global cardiac functional alterations.
  We introduce the Acoustic Index, a novel AI-derived echocardiographic
parameter designed to quantify cardiac dysfunction from standard ultrasound
views. The model combines Extended Dynamic Mode Decomposition (EDMD) based on
Koopman operator theory with a hybrid neural network that incorporates clinical
metadata. Spatiotemporal dynamics are extracted from echocardiographic
sequences to identify coherent motion patterns. These are weighted via
attention mechanisms and fused with clinical data using manifold learning,
resulting in a continuous score from 0 (low risk) to 1 (high risk).
  In a prospective cohort of 736 patients, encompassing various cardiac
pathologies and normal controls, the Acoustic Index achieved an area under the
curve (AUC) of 0.89 in an independent test set. Cross-validation across five
folds confirmed the robustness of the model, showing that both sensitivity and
specificity exceeded 0.8 when evaluated on independent data. Threshold-based
analysis demonstrated stable trade-offs between sensitivity and specificity,
with optimal discrimination near this threshold.
  The Acoustic Index represents a physics-informed, interpretable AI biomarker
for cardiac function. It shows promise as a scalable, vendor-independent tool
for early detection, triage, and longitudinal monitoring. Future directions
include external validation, longitudinal studies, and adaptation to
disease-specific classifiers.

</details>


### [118] [Time Series Forecastability Measures](https://arxiv.org/abs/2507.13556)
*Rui Wang,Steven Klee,Alexis Roos*

Main category: cs.LG

TL;DR: 提出两种指标（谱可预测性评分和最大Lyapunov指数）来量化时间序列的预测性，避免传统模型评估的滞后性。


<details>
  <summary>Details</summary>
Motivation: 在模型开发前评估时间序列的固有预测性，帮助实践者更高效地规划资源。

Method: 使用谱可预测性评分评估频率成分的强度和规律性，Lyapunov指数量化系统的混沌和稳定性。

Result: 两种指标能准确反映时间序列的固有预测性，与实际模型预测性能强相关。

Conclusion: 提前了解时间序列的预测性有助于优化资源分配和设定合理预期。

Abstract: This paper proposes using two metrics to quantify the forecastability of time
series prior to model development: the spectral predictability score and the
largest Lyapunov exponent. Unlike traditional model evaluation metrics, these
measures assess the inherent forecastability characteristics of the data before
any forecast attempts. The spectral predictability score evaluates the strength
and regularity of frequency components in the time series, whereas the Lyapunov
exponents quantify the chaos and stability of the system generating the data.
We evaluated the effectiveness of these metrics on both synthetic and
real-world time series from the M5 forecast competition dataset. Our results
demonstrate that these two metrics can correctly reflect the inherent
forecastability of a time series and have a strong correlation with the actual
forecast performance of various models. By understanding the inherent
forecastability of time series before model training, practitioners can focus
their planning efforts on products and supply chain levels that are more
forecastable, while setting appropriate expectations or seeking alternative
strategies for products with limited forecastability.

</details>


### [119] [Change of Thought: Adaptive Test-Time Computation](https://arxiv.org/abs/2507.13569)
*Mrinal Mathur,Mike Doan,Barak Pearlmutter,Sergey Plis*

Main category: cs.LG

TL;DR: SELF-Transformer通过内部迭代更新注意力权重，提升编码器Transformer的表达能力，无需依赖自回归机制，实验显示性能提升20%。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在固定深度下表达能力受限，而自回归机制依赖外部化中间状态。SELF-Transformer旨在通过内部迭代提升表达能力，避免自回归的复杂性。

Method: 引入SELF-Transformer，通过迭代更新注意力权重至固定点，动态调整计算复杂度以适应输入难度。

Result: 在编码器基准测试中，性能提升高达20%，且不增加参数量。

Conclusion: SELF-Transformer通过内部迭代实现了接近自回归的表达能力，同时保持了编码器的简洁性。

Abstract: Transformers evaluated in a single, fixed-depth pass are provably limited in
expressive power to the constant-depth circuit class TC0. Running a Transformer
autoregressively removes that ceiling -- first in next-token prediction and,
more recently, in chain-of-thought reasoning. Both regimes rely on feedback
loops that decode internal states into tokens only to re-encode them in
subsequent steps. While this "thinking aloud" mirrors human reasoning,
biological brains iterate without externalising intermediate states as
language. To boost the expressive power of encoder Transformers without
resorting to token-level autoregression, we introduce the SELF-Transformer: an
encoder layer that iteratively refines its own attention weights to a fixed
point. Instead of producing -- in one pass -- the alignment matrix that remixes
the input sequence, the SELF-Transformer iteratively updates that matrix
internally, scaling test-time computation with input difficulty. This
adaptivity yields up to 20\% accuracy gains on encoder-style benchmarks without
increasing parameter count, demonstrating that input-adaptive alignment at test
time offers substantial benefits for only a modest extra compute budget.
Self-Transformers thus recover much of the expressive power of iterative
reasoning while preserving the simplicity of pure encoder architectures.

</details>


### [120] [Apple Intelligence Foundation Language Models: Tech Report 2025](https://arxiv.org/abs/2507.13575)
*Hanzhi Zhou,Erik Hornberger,Pengsheng Guo,Xiyou Zhou,Saiwen Wang,Xin Wang,Yifei He,Xuankai Chang,Rene Rauch,Louis D'hauwe,John Peebles,Alec Doane,Kohen Chia,Jenna Thibodeau,Zi-Yi Dou,Yuanyang Zhang,Ruoming Pang,Reed Li,Zhifeng Chen,Jeremy Warner,Zhaoyang Xu,Sophy Lee,David Mizrahi,Ramsey Tantawi,Chris Chaney,Kelsey Peterson,Jun Qin,Alex Dombrowski,Mira Chiang,Aiswarya Raghavan,Gerard Casamayor,Qibin Chen,Aonan Zhang,Nathalie Tran,Jianyu Wang,Hang Su,Thomas Voice,Alessandro Pappalardo,Brycen Wershing,Prasanth Yadla,Rui Li,Priyal Chhatrapati,Ismael Fernandez,Yusuf Goren,Xin Zheng,Forrest Huang,Tao Lei,Eray Yildiz,Alper Kokmen,Gokul Santhanam,Areeba Kamal,Kaan Elgin,Dian Ang Yap,Jeremy Liu,Peter Gray,Howard Xing,Kieran Liu,Matteo Ronchi,Moritz Schwarzer-Becker,Yun Zhu,Mandana Saebi,Jeremy Snow,David Griffiths,Guillaume Tartavel,Erin Feldman,Simon Lehnerer,Fernando Bermúdez-Medina,Hans Han,Joe Zhou,Xiaoyi Ren,Sujeeth Reddy,Zirui Wang,Tom Gunter,Albert Antony,Yuanzhi Li,John Dennison,Tony Sun,Yena Han,Yi Qin,Sam Davarnia,Jeffrey Bigham,Wayne Shan,Hannah Gillis Coleman,Guillaume Klein,Peng Liu,Muyang Yu,Jack Cackler,Yuan Gao,Crystal Xiao,Binazir Karimzadeh,Zhengdong Zhang,Felix Bai,Albin Madappally Jose,Feng Nan,Nazir Kamaldin,Dong Yin,Hans Hao,Yanchao Sun,Yi Hua,Charles Maalouf,Alex Guillen Garcia,Guoli Yin,Lezhi Li,Mohana Prasad Sathya Moorthy,Hongbin Gao,Jay Tang,Joanna Arreaza-Taylor,Faye Lao,Carina Peng,Josh Shaffer,Dan Masi,Sushma Rao,Tommi Vehvilainen,Senyu Tong,Dongcai Shen,Yang Zhao,Chris Bartels,Peter Fu,Qingqing Cao,Christopher Neubauer,Ethan Li,Mingfei Gao,Rebecca Callahan,Richard Wei,Patrick Dong,Alex Braunstein,Sachin Ravi,Adolfo Lopez Mendez,Kaiwei Huang,Kun Duan,Haoshuo Huang,Rui Qian,Stefano Ligas,Jordan Huffaker,Dongxu Li,Bailin Wang,Nanzhu Wang,Anuva Agarwal,Tait Madsen,Josh Newnham,Abhishek Sharma,Zhile Ren,Deepak Gopinath,Erik Daxberger,Saptarshi Guha,Oron Levy,Jing Lu,Nan Dun,Marc Kirchner,Yinfei Yang,Manjot Bilkhu,Dave Nelson,Anthony Spalvieri-Kruse,Juan Lao Tebar,Yang Xu,Phani Mutyala,Gabriel Jacoby-Cooper,Yingbo Wang,Karla Vega,Vishaal Mahtani,Darren Botten,Eric Wang,Hanli Li,Matthias Paulik,Haoran Yan,Navid Shiee,Yihao Qian,Bugu Wu,Qi Zhu,Ob Adaranijo,Bhuwan Dhingra,Zhe Gan,Nicholas Seidl,Grace Duanmu,Rong Situ,Yiping Ma,Yin Xia,David Riazati,Vasileios Saveris,Anh Nguyen,Michael,Lee,Patrick Sonnenberg,Chinguun Erdenebileg,Yanghao Li,Vivian Ma,James Chou,Isha Garg,Mark Lee,Keen You,Yuhong Li,Ransen Niu,Nandhitha Raghuram,Pulkit Agrawal,Henry Mason,Sumeet Singh,Keyu He,Hong-You Chen,Lucas Guibert,Shiyu Li,Varsha Paidi,Narendran Raghavan,Mingze Xu,Yuli Yang,Sergiu Sima,Irina Belousova,Sprite Chu,Afshin Dehghan,Philipp Dufter,David Haldimann,Zhen Yang,Margit Bowler,Chang Liu,Ying-Chang Cheng,Vivek Rathod,Syd Evans,Wilson Tsao,Dustin Withers,Haitian Sun,Biyao Wang,Peter Grasch,Walker Cheng,Yihao Feng,Vivek Kumar,Frank Chu,Victoria MönchJuan Haladjian,Doug Kang,Jiarui Lu,Ciro Sannino,Max Lam,Floris Weers,Bowen Pan,Kenneth Jung,Dhaval Doshi,Fangping Shi,Olli Saarikivi,Alp Aygar,Josh Elman,Cheng Leong,Eshan Verma,Matthew Lei,Jeff Nichols,Jiulong Shan,Donald Zhang,Lawrence Zhou,Stephen Murphy,Xianzhi Du,Chang Lan,Ankur Jain,Elmira Amirloo,Marcin Eichner,Naomy Sabo,Anupama Mann Anupama,David Qiu,Zhao Meng,Michael FitzMaurice,Peng Zhang,Simon Yeung,Chen Chen,Marco Zuliani,Andrew Hansen,Yang Lu,Brent Ramerth,Ziyi Zhong,Parsa Mazaheri,Matthew Hopkins,Mengyu Li,Simon Wang,David Chen,Farzin Rasteh,Chong Wang,Josh Gardner,Asaf Liberman,Haoxuan You,Andrew Walkingshaw,Xingyu Zhou,Jinhao Lei,Yan Meng,Quentin Keunebroek,Sam Wiseman,Anders Boesen Lindbo Larsen,Yi Zhang,Zaid Ahmed,Haiming Gang,Aaron Franklin,Kelvin Zou,Guillaume Seguin,Jonathan Janke,Rachel Burger,Co Giang,Cheng Shen,Jen Liu,Sanskruti Shah,Xiang Kong,Yiran Fei,TJ Collins,Chen Zhang,Zhiyun Lu,Michael Booker,Qin Ba,Yasutaka Tanaka,Andres Romero Mier Y Teran,Federico Scozzafava,Regan Poston,Jane Li,Eduardo Jimenez,Bas Straathof,Karanjeet Singh,Lindsay Hislop,Rajat Arora,Deepa Seshadri,Boyue Li,Colorado Reed,Zhen Li,TJ Lu,Yi Wang,Kaelen Haag,Nicholas Lusskin,Raunak Sinha,Rahul Nair,Eldon Schoop,Mary Beth Kery,Mehrdad Farajtbar,Brenda Yang,George Horrell,Shiwen Zhao,Dhruti Shah,Cha Chen,Bowen Zhang,Chang Gao,Devi Krishna,Jennifer Mallalieu,Javier Movellan,Di Feng,Emily Zhang,Sam Xu,Junting Pan,Dominik Moritz,Suma Jayaram,Kevin Smith,Dongseong Hwang,Daniel Parilla,Jiaming Hu,You-Cyuan Jhang,Emad Soroush,Fred Hohman,Nan Du,Emma Wang,Sam Dodge,Pragnya Sridhar,Joris Pelemans,Wei Fang,Nina Wenzel,Joseph Yitan Cheng,Hadas Kotek,Chung-Cheng Chiu,Meng Cao,Haijing Fu,Ruixuan Hou,Ke Ye,Diane Zhu,Nikhil Bhendawade,Joseph Astrauskas,Jian Liu,Sai Aitharaju,Wentao Wu,Artsiom Peshko,Hyunjik Kim,Nilesh Shahdadpuri,Andy De Wang,Qi Shan,Piotr Maj,Raul Rea Menacho,Justin Lazarow,Eric Liang Yang,Arsalan Farooq,Donghan Yu,David Güera,Minsik Cho,Kavya Nerella,Yongqiang Wang,Tao Jia,John Park,Jeff Lai,Haotian Zhang,Futang Peng,Daniele Molinari,Aparna Rajamani,Tyler Johnson,Lauren Gardiner,Chao Jia,Violet Yao,Wojciech Kryscinski,Xiujun Li,Shang-Chen Wu*

Main category: cs.LG

TL;DR: 苹果推出两款多语言、多模态基础语言模型，支持设备端和服务器端，通过创新架构和训练方法实现高性能，并在隐私保护方面有所突破。


<details>
  <summary>Details</summary>
Motivation: 为苹果设备和服务提供智能功能，同时兼顾性能、成本效率和用户隐私保护。

Method: 1. 设备端模型：3B参数，采用KV缓存共享和2位量化感知训练；2. 服务器模型：基于PT-MoE变压器，结合并行计算和稀疏计算。训练数据来自多语言、多模态数据集，并通过监督微调和强化学习优化。

Result: 模型在多语言理解和多模态任务上表现优异，在公开基准测试和人工评估中超越同类开源基线。

Conclusion: 苹果通过创新模型架构和训练方法，实现了高性能和隐私保护的平衡，同时为开发者提供了易于集成的工具框架。

Abstract: We introduce two multilingual, multimodal foundation language models that
power Apple Intelligence features across Apple devices and services: i a
3B-parameter on-device model optimized for Apple silicon through architectural
innovations such as KV-cache sharing and 2-bit quantization-aware training; and
ii a scalable server model built on a novel Parallel-Track Mixture-of-Experts
PT-MoE transformer that combines track parallelism, mixture-of-experts sparse
computation, and interleaved global-local attention to deliver high quality
with competitive cost on Apple's Private Cloud Compute platform. Both models
are trained on large-scale multilingual and multimodal datasets sourced via
responsible web crawling, licensed corpora, and high-quality synthetic data,
then further refined with supervised fine-tuning and reinforcement learning on
a new asynchronous platform. The resulting models support several additional
languages while understanding images and executing tool calls. In public
benchmarks and human evaluations, both the server model and the on-device model
match or surpass comparably sized open baselines.
  A new Swift-centric Foundation Models framework exposes guided generation,
constrained tool calling, and LoRA adapter fine-tuning, allowing developers to
integrate these capabilities with a few lines of code. The latest advancements
in Apple Intelligence models are grounded in our Responsible AI approach with
safeguards like content filtering and locale-specific evaluation, as well as
our commitment to protecting our users' privacy with innovations like Private
Cloud Compute.

</details>


### [121] [Learning Pluralistic User Preferences through Reinforcement Learning Fine-tuned Summaries](https://arxiv.org/abs/2507.13579)
*Hyunji Nam,Yanming Wan,Mickel Liu,Jianxun Lian,Natasha Jaques*

Main category: cs.LG

TL;DR: PLUS框架通过生成用户偏好摘要，实现个性化奖励模型，提升LLM对不同用户的响应质量。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF方法无法区分用户差异，需个性化响应以满足不同用户需求。

Method: 提出PLUS框架，利用强化学习生成用户偏好摘要，并动态更新奖励模型。

Result: PLUS生成的摘要能有效捕捉用户偏好，适应新用户和多样话题，且可迁移至GPT-4等模型。

Conclusion: PLUS提供透明、可控的个性化LLM对齐方法，用户可理解并修改摘要。

Abstract: As everyday use cases of large language model (LLM) AI assistants have
expanded, it is becoming increasingly important to personalize responses to
align to different users' preferences and goals. While reinforcement learning
from human feedback (RLHF) is effective at improving LLMs to be generally more
helpful and fluent, it does not account for variability across users, as it
models the entire user population with a single reward model. We present a
novel framework, Preference Learning Using Summarization (PLUS), that learns
text-based summaries of each user's preferences, characteristics, and past
conversations. These summaries condition the reward model, enabling it to make
personalized predictions about the types of responses valued by each user. We
train the user-summarization model with reinforcement learning, and update the
reward model simultaneously, creating an online co-adaptation loop. We show
that in contrast with prior personalized RLHF techniques or with in-context
learning of user information, summaries produced by PLUS capture meaningful
aspects of a user's preferences. Across different pluralistic user datasets, we
show that our method is robust to new users and diverse conversation topics.
Additionally, we demonstrate that the textual summaries generated about users
can be transferred for zero-shot personalization of stronger, proprietary
models like GPT-4. The resulting user summaries are not only concise and
portable, they are easy for users to interpret and modify, allowing for more
transparency and user control in LLM alignment.

</details>


### [122] [Tri-Learn Graph Fusion Network for Attributed Graph Clustering](https://arxiv.org/abs/2507.13620)
*Binxiong Li,Yuefei Wang,Xu Xiang,Xue Li,Binyu Zhao,Heyang Gao,Qinyu Zhao,Xi Yu*

Main category: cs.LG

TL;DR: 论文提出了一种结合GCN、AE和Graph Transformer的Tri-GFN框架，通过三学习机制和特征融合策略提升图聚类性能，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决GCN在大规模复杂图数据中存在的过平滑和过压缩问题，以及Graph Transformer在异构图数据上的性能限制。

Method: 提出Tri-GFN框架，整合GCN、AE和Graph Transformer，通过三学习机制和特征融合策略增强全局与局部信息的区分性和一致性。

Result: 在ACM、Reuters和USPS数据集上分别提升0.87%、14.14%和7.58%的准确率，尤其在Reuters数据集表现突出。

Conclusion: Tri-GFN框架显著提升了图聚类性能，适用于新闻自动分类和主题检索等领域。

Abstract: In recent years, models based on Graph Convolutional Networks (GCN) have made
significant strides in the field of graph data analysis. However, challenges
such as over-smoothing and over-compression remain when handling large-scale
and complex graph datasets, leading to a decline in clustering quality.
Although the Graph Transformer architecture has mitigated some of these issues,
its performance is still limited when processing heterogeneous graph data. To
address these challenges, this study proposes a novel deep clustering framework
that comprising GCN, Autoencoder (AE), and Graph Transformer, termed the
Tri-Learn Graph Fusion Network (Tri-GFN). This framework enhances the
differentiation and consistency of global and local information through a
unique tri-learning mechanism and feature fusion enhancement strategy. The
framework integrates GCN, AE, and Graph Transformer modules. These components
are meticulously fused by a triple-channel enhancement module, which maximizes
the use of both node attributes and topological structures, ensuring robust
clustering representation. The tri-learning mechanism allows mutual learning
among these modules, while the feature fusion strategy enables the model to
capture complex relationships, yielding highly discriminative representations
for graph clustering. It surpasses many state-of-the-art methods, achieving an
accuracy improvement of approximately 0.87% on the ACM dataset, 14.14 % on the
Reuters dataset, and 7.58 % on the USPS dataset. Due to its outstanding
performance on the Reuters dataset, Tri-GFN can be applied to automatic news
classification, topic retrieval, and related fields.

</details>


### [123] [Generalist Bimanual Manipulation via Foundation Video Diffusion Models](https://arxiv.org/abs/2507.12898)
*Yao Feng,Hengkai Tan,Xinyi Mao,Guodong Liu,Shuhe Huang,Chendong Xiang,Hang Su,Jun Zhu*

Main category: cs.LG

TL;DR: VIDAR是一个两阶段框架，通过扩散模型预训练和掩码逆向动力学模型解决双臂机器人操作中的数据稀缺和异构性问题，仅需少量演示即可泛化到新任务和背景。


<details>
  <summary>Details</summary>
Motivation: 双臂机器人操作中的数据稀缺和异构性是主要挑战，需要一种能够高效利用有限数据并泛化到新场景的方法。

Method: VIDAR结合大规模视频扩散预训练和掩码逆向动力学模型，利用多视角视频数据和无标签像素信息提取动作相关信息。

Result: 仅需20分钟人类演示（1%的典型数据需求），VIDAR在新机器人平台上表现出色，超越现有方法。

Conclusion: 视频基础模型与掩码动作预测结合，有望实现多样化现实场景中可扩展和泛化的机器人操作。

Abstract: Bimanual robotic manipulation, which involves the coordinated control of two
robotic arms, is foundational for solving challenging tasks. Despite recent
progress in general-purpose manipulation, data scarcity and embodiment
heterogeneity remain serious obstacles to further scaling up in bimanual
settings. In this paper, we introduce VIdeo Diffusion for Action Reasoning
(VIDAR), a two-stage framework that leverages large-scale, diffusion-based
video pre-training and a novel masked inverse dynamics model for action
prediction. We pre-train the video diffusion model on 750K multi-view videos
from three real-world bimanual robot platforms, utilizing a unified observation
space that encodes robot, camera, task, and scene contexts. Our masked inverse
dynamics model learns masks to extract action-relevant information from
generated trajectories without requiring pixel-level labels, and the masks can
effectively generalize to unseen backgrounds. Our experiments demonstrate that
with only 20 minutes of human demonstrations on an unseen robot platform (only
1% of typical data requirements), VIDAR generalizes to unseen tasks and
backgrounds with strong semantic understanding, surpassing state-of-the-art
methods. Our findings highlight the potential of video foundation models,
coupled with masked action prediction, to enable scalable and generalizable
robotic manipulation in diverse real-world settings.

</details>


### [124] [FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning](https://arxiv.org/abs/2507.13624)
*Daniel Commey,Kamel Abbad,Garth V. Crosby,Lyes Khoukhi*

Main category: cs.LG

TL;DR: FedSkipTwin是一种基于服务器端数字孪生的客户端跳过算法，通过预测梯度更新的幅度和不确定性来减少通信开销，在非IID数据下节省带宽并提升模型精度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的通信开销是主要瓶颈，尤其是移动和物联网设备带宽受限的情况下。

Method: 使用轻量级LSTM数字孪生预测客户端梯度更新的幅度和不确定性，仅在预测值超过阈值时请求通信，否则跳过轮次。

Result: 在UCI-HAR和MNIST数据集上，FedSkipTwin减少12-15.5%的通信量，同时模型精度提升0.5个百分点。

Conclusion: 预测引导的跳过策略是带宽受限边缘环境中资源感知联邦学习的实用有效方法。

Abstract: Communication overhead remains a primary bottleneck in federated learning
(FL), particularly for applications involving mobile and IoT devices with
constrained bandwidth. This work introduces FedSkipTwin, a novel
client-skipping algorithm driven by lightweight, server-side digital twins.
Each twin, implemented as a simple LSTM, observes a client's historical
sequence of gradient norms to forecast both the magnitude and the epistemic
uncertainty of its next update. The server leverages these predictions,
requesting communication only when either value exceeds a predefined threshold;
otherwise, it instructs the client to skip the round, thereby saving bandwidth.
Experiments are conducted on the UCI-HAR and MNIST datasets with 10 clients
under a non-IID data distribution. The results demonstrate that FedSkipTwin
reduces total communication by 12-15.5% across 20 rounds while simultaneously
improving final model accuracy by up to 0.5 percentage points compared to the
standard FedAvg algorithm. These findings establish that prediction-guided
skipping is a practical and effective strategy for resource-aware FL in
bandwidth-constrained edge environments.

</details>


### [125] [A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design](https://arxiv.org/abs/2507.13646)
*Nimisha Ghosh,Daniele Santoni,Debaleena Nawn,Eleonora Ottaviani,Giovanni Felici*

Main category: cs.LG

TL;DR: 综述了基于Transformer的语言模型在蛋白质序列分析与设计中的应用，总结了现有研究的优缺点，并探讨了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在NLP领域取得成功后，被引入生物信息学领域，尤其是蛋白质序列分析与设计。本文旨在综述相关研究进展，为研究者提供全面参考。

Method: 回顾并分析了大量关于Transformer模型在基因本体、蛋白质功能与结构识别、蛋白质生成及结合等方面的应用研究。

Result: 总结了现有研究的优缺点，为读者提供了全面的见解，并指出了当前研究的不足。

Conclusion: 本文为研究者提供了该领域的最新进展，并提出了未来研究的潜在方向。

Abstract: The impact of Transformer-based language models has been unprecedented in
Natural Language Processing (NLP). The success of such models has also led to
their adoption in other fields including bioinformatics. Taking this into
account, this paper discusses recent advances in Transformer-based models for
protein sequence analysis and design. In this review, we have discussed and
analysed a significant number of works pertaining to such applications. These
applications encompass gene ontology, functional and structural protein
identification, generation of de novo proteins and binding of proteins. We
attempt to shed light on the strength and weaknesses of the discussed works to
provide a comprehensive insight to readers. Finally, we highlight shortcomings
in existing research and explore potential avenues for future developments. We
believe that this review will help researchers working in this field to have an
overall idea of the state of the art in this field, and to orient their future
studies.

</details>


### [126] [Kolmogorov-Arnold Networks-based GRU and LSTM for Loan Default Early Prediction](https://arxiv.org/abs/2507.13685)
*Yue Yang,Zihan Su,Ying Zhang,Chang Chuan Goh,Yuxiang Lin,Anthony Graham Bellotti,Boon Giin Lee*

Main category: cs.LG

TL;DR: 论文提出GRU-KAN和LSTM-KAN两种新架构，用于提前预测贷款违约，显著优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有贷款违约预测模型在提前预测时准确性不足且依赖特定时间框架的问题，帮助金融机构提前采取预防措施。

Method: 结合Kolmogorov-Arnold Networks (KAN)与GRU和LSTM网络，提出GRU-KAN和LSTM-KAN模型。

Result: 新模型在提前3个月和8个月的预测中分别达到92%和88%的准确率，显著优于基线模型。

Conclusion: GRU-KAN和LSTM-KAN在贷款违约早期预测中表现出色，具有实际应用潜力。

Abstract: This study addresses a critical challenge in time series anomaly detection:
enhancing the predictive capability of loan default models more than three
months in advance to enable early identification of default events, helping
financial institutions implement preventive measures before risk events
materialize. Existing methods have significant drawbacks, such as their lack of
accuracy in early predictions and their dependence on training and testing
within the same year and specific time frames. These issues limit their
practical use, particularly with out-of-time data. To address these, the study
introduces two innovative architectures, GRU-KAN and LSTM-KAN, which merge
Kolmogorov-Arnold Networks (KAN) with Gated Recurrent Units (GRU) and Long
Short-Term Memory (LSTM) networks. The proposed models were evaluated against
the baseline models (LSTM, GRU, LSTM-Attention, and LSTM-Transformer) in terms
of accuracy, precision, recall, F1 and AUC in different lengths of feature
window, sample sizes, and early prediction intervals. The results demonstrate
that the proposed model achieves a prediction accuracy of over 92% three months
in advance and over 88% eight months in advance, significantly outperforming
existing baselines.

</details>


### [127] [Binarizing Physics-Inspired GNNs for Combinatorial Optimization](https://arxiv.org/abs/2507.13703)
*Martin Krutský,Gustav Šír,Vyacheslav Kungurtsev,Georgios Korpas*

Main category: cs.LG

TL;DR: PI-GNNs在组合优化问题中表现良好，但随着问题图密度增加，性能下降。研究发现训练动态中存在相变，并提出基于模糊逻辑和二值化神经网络的方法改进性能。


<details>
  <summary>Details</summary>
Motivation: 解决PI-GNNs在处理高密度组合优化图时性能下降的问题。

Method: 提出基于模糊逻辑和二值化神经网络的替代策略。

Result: 实验表明新方法显著提升了PI-GNNs在高密度场景下的性能。

Conclusion: 通过改进策略，PI-GNNs在高密度组合优化问题中的性能得到显著提升。

Abstract: Physics-inspired graph neural networks (PI-GNNs) have been utilized as an
efficient unsupervised framework for relaxing combinatorial optimization
problems encoded through a specific graph structure and loss, reflecting
dependencies between the problem's variables. While the framework has yielded
promising results in various combinatorial problems, we show that the
performance of PI-GNNs systematically plummets with an increasing density of
the combinatorial problem graphs. Our analysis reveals an interesting phase
transition in the PI-GNNs' training dynamics, associated with degenerate
solutions for the denser problems, highlighting a discrepancy between the
relaxed, real-valued model outputs and the binary-valued problem solutions. To
address the discrepancy, we propose principled alternatives to the naive
strategy used in PI-GNNs by building on insights from fuzzy logic and binarized
neural networks. Our experiments demonstrate that the portfolio of proposed
methods significantly improves the performance of PI-GNNs in increasingly dense
settings.

</details>


### [128] [Bayesian Optimization for Molecules Should Be Pareto-Aware](https://arxiv.org/abs/2507.13704)
*Anabel Yong,Austin Tripp,Layla Hosseini-Gerami,Brooks Paige*

Main category: cs.LG

TL;DR: 多目标贝叶斯优化（MOBO）在分子设计中优于标量化方法，特别是在低数据量和复杂权衡情况下。


<details>
  <summary>Details</summary>
Motivation: 探索MOBO在分子设计中的实际优势，尤其是与标量化方法相比。

Method: 使用基于帕累托的MOBO策略（EHVI）与固定权重的标量化基线（EI）进行对比实验。

Result: EHVI在帕累托前沿覆盖、收敛速度和化学多样性方面均优于EI。

Conclusion: Pareto感知的获取策略在分子优化中具有实际优势，尤其是在预算有限和权衡复杂的情况下。

Abstract: Multi-objective Bayesian optimization (MOBO) provides a principled framework
for navigating trade-offs in molecular design. However, its empirical
advantages over scalarized alternatives remain underexplored. We benchmark a
simple Pareto-based MOBO strategy -- Expected Hypervolume Improvement (EHVI) --
against a simple fixed-weight scalarized baseline using Expected Improvement
(EI), under a tightly controlled setup with identical Gaussian Process
surrogates and molecular representations. Across three molecular optimization
tasks, EHVI consistently outperforms scalarized EI in terms of Pareto front
coverage, convergence speed, and chemical diversity. While scalarization
encompasses flexible variants -- including random or adaptive schemes -- our
results show that even strong deterministic instantiations can underperform in
low-data regimes. These findings offer concrete evidence for the practical
advantages of Pareto-aware acquisition in de novo molecular optimization,
especially when evaluation budgets are limited and trade-offs are nontrivial.

</details>


### [129] [Learning Deformable Body Interactions With Adaptive Spatial Tokenization](https://arxiv.org/abs/2507.13707)
*Hao Wang,Yu Liu,Daniel Biggs,Haoru Wang,Jiandong Yu,Ping Huang*

Main category: cs.LG

TL;DR: 提出了一种自适应空间标记化（AST）方法，通过网格划分和注意力机制，高效模拟可变形体交互，解决了现有方法的计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 模拟可变形体交互在材料科学和机器人学中很重要，但现有基于图神经网络的方法在建模大规模网格时存在计算效率问题。

Method: 将模拟空间划分为网格单元，映射非结构化网格到结构化网格，并通过交叉注意力模块生成紧凑的固定长度嵌入，利用自注意力模块预测下一状态。

Result: 实验表明，该方法在大规模网格（超过10万个节点）上显著优于现有方法，并贡献了一个新的大规模数据集。

Conclusion: AST方法通过结合标记化和注意力机制，实现了高效且可扩展的可变形体交互模拟。

Abstract: Simulating interactions between deformable bodies is vital in fields like
material science, mechanical design, and robotics. While learning-based methods
with Graph Neural Networks (GNNs) are effective at solving complex physical
systems, they encounter scalability issues when modeling deformable body
interactions. To model interactions between objects, pairwise global edges have
to be created dynamically, which is computationally intensive and impractical
for large-scale meshes. To overcome these challenges, drawing on insights from
geometric representations, we propose an Adaptive Spatial Tokenization (AST)
method for efficient representation of physical states. By dividing the
simulation space into a grid of cells and mapping unstructured meshes onto this
structured grid, our approach naturally groups adjacent mesh nodes. We then
apply a cross-attention module to map the sparse cells into a compact,
fixed-length embedding, serving as tokens for the entire physical state.
Self-attention modules are employed to predict the next state over these tokens
in latent space. This framework leverages the efficiency of tokenization and
the expressive power of attention mechanisms to achieve accurate and scalable
simulation results. Extensive experiments demonstrate that our method
significantly outperforms state-of-the-art approaches in modeling deformable
body interactions. Notably, it remains effective on large-scale simulations
with meshes exceeding 100,000 nodes, where existing methods are hindered by
computational limitations. Additionally, we contribute a novel large-scale
dataset encompassing a wide range of deformable body interactions to support
future research in this area.

</details>


### [130] [Benchmarking of EEG Analysis Techniques for Parkinson's Disease Diagnosis: A Comparison between Traditional ML Methods and Foundation DL Methods](https://arxiv.org/abs/2507.13716)
*Danilo Avola,Andrea Bernardini,Giancarlo Crocetti,Andrea Ladogana,Mario Lezoche,Maurizio Mancini,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 本文系统比较了传统机器学习和深度学习模型在帕金森病（PD）分类中的表现，旨在为开发有效的学习系统奠定基础。


<details>
  <summary>Details</summary>
Motivation: 早期诊断帕金森病对临床干预至关重要，但开发可靠的自动化诊断模型仍具挑战性。脑电图（EEG）提供了一种非侵入性且经济高效的检测手段。

Method: 采用统一的七步预处理流程，应用一致的主题交叉验证和评估标准，比较传统机器学习（如XGBoost）和深度学习（如CNN-LSTM）模型。

Result: 结果表明，CNN-LSTM模型表现最佳，但传统分类器如XGBoost也表现出较强的预测准确性。

Conclusion: 本研究为未来开发更复杂或专用架构提供了基准框架，强调了科学严谨性和可重复性。

Abstract: Parkinson's Disease PD is a progressive neurodegenerative disorder that
affects motor and cognitive functions with early diagnosis being critical for
effective clinical intervention Electroencephalography EEG offers a noninvasive
and costeffective means of detecting PDrelated neural alterations yet the
development of reliable automated diagnostic models remains a challenge In this
study we conduct a systematic benchmark of traditional machine learning ML and
deep learning DL models for classifying PD using a publicly available oddball
task dataset Our aim is to lay the groundwork for developing an effective
learning system and to determine which approach produces the best results We
implement a unified sevenstep preprocessing pipeline and apply consistent
subjectwise crossvalidation and evaluation criteria to ensure comparability
across models Our results demonstrate that while baseline deep learning
architectures particularly CNNLSTM models achieve the best performance compared
to other deep learning architectures underlining the importance of capturing
longrange temporal dependencies several traditional classifiers such as XGBoost
also offer strong predictive accuracy and calibrated decision boundaries By
rigorously comparing these baselines our work provides a solid reference
framework for future studies aiming to develop and evaluate more complex or
specialized architectures Establishing a reliable set of baseline results is
essential to contextualize improvements introduced by novel methods ensuring
scientific rigor and reproducibility in the evolving field of EEGbased
neurodiagnostics

</details>


### [131] [Bi-GRU Based Deception Detection using EEG Signals](https://arxiv.org/abs/2507.13718)
*Danilo Avola,Muhammad Yasir Bilal,Emad Emam,Cristina Lakasz,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 该研究提出了一种基于双向门控循环单元（Bi-GRU）的深度学习模型，利用脑电图（EEG）信号检测欺骗行为，测试准确率达到97%。


<details>
  <summary>Details</summary>
Motivation: 欺骗检测在安全、心理学和法医学等领域具有重要意义，但传统方法存在局限性，因此探索基于EEG信号的深度学习方法是必要的。

Method: 使用Bag-of-Lies数据集中的EEG信号，训练双向门控循环单元（Bi-GRU）神经网络进行二分类任务。

Result: 模型在测试集上达到97%的准确率，并且在精确率、召回率和F1分数上表现优异。

Conclusion: 研究表明双向时间建模在基于EEG的欺骗检测中非常有效，具有实时应用潜力，并建议未来探索更先进的神经网络架构。

Abstract: Deception detection is a significant challenge in fields such as security,
psychology, and forensics. This study presents a deep learning approach for
classifying deceptive and truthful behavior using ElectroEncephaloGram (EEG)
signals from the Bag-of-Lies dataset, a multimodal corpus designed for
naturalistic, casual deception scenarios. A Bidirectional Gated Recurrent Unit
(Bi-GRU) neural network was trained to perform binary classification of EEG
samples. The model achieved a test accuracy of 97\%, along with high precision,
recall, and F1-scores across both classes. These results demonstrate the
effectiveness of using bidirectional temporal modeling for EEG-based deception
detection and suggest potential for real-time applications and future
exploration of advanced neural architectures.

</details>


### [132] [Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion](https://arxiv.org/abs/2507.13721)
*Zizhao Zhang,Tianxiang Zhao,Yu Sun,Liping Sun,Jichuan Kang*

Main category: cs.LG

TL;DR: 本文提出了一种混合特征融合框架，用于构建自主货船故障模式的图结构数据集，显著提高了文献检索效率，并在分类和预测任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决自主货船组件故障引发的级联反应和应急决策中的不确定性。

Method: 使用改进的布谷鸟搜索算法（HN-CSA）提升文献检索效率，构建分层特征融合框架，结合Word2Vec、BERT-KPCA和Sentence-BERT处理特征。

Result: 数据集覆盖12个系统、1,262种故障模式和6,150条传播路径；GATE-GNN模型分类准确率为0.735，预测F1分数达0.93。

Conclusion: 为自主货船的故障分析、风险评估和智能决策系统提供了可靠支持。

Abstract: To address the challenges posed by cascading reactions caused by component
failures in autonomous cargo ships (ACS) and the uncertainties in emergency
decision-making, this paper proposes a novel hybrid feature fusion framework
for constructing a graph-structured dataset of failure modes. By employing an
improved cuckoo search algorithm (HN-CSA), the literature retrieval efficiency
is significantly enhanced, achieving improvements of 7.1% and 3.4% compared to
the NSGA-II and CSA search algorithms, respectively. A hierarchical feature
fusion framework is constructed, using Word2Vec encoding to encode
subsystem/component features, BERT-KPCA to process failure modes/reasons, and
Sentence-BERT to quantify the semantic association between failure impact and
emergency decision-making. The dataset covers 12 systems, 1,262 failure modes,
and 6,150 propagation paths. Validation results show that the GATE-GNN model
achieves a classification accuracy of 0.735, comparable to existing benchmarks.
Additionally, a silhouette coefficient of 0.641 indicates that the features are
highly distinguishable. In the label prediction results, the Shore-based
Meteorological Service System achieved an F1 score of 0.93, demonstrating high
prediction accuracy. This paper not only provides a solid foundation for
failure analysis in autonomous cargo ships but also offers reliable support for
fault diagnosis, risk assessment, and intelligent decision-making systems. The
link to the dataset is
https://github.com/wojiufukele/Graph-Structured-about-CSA.

</details>


### [133] [Adversarial Training Improves Generalization Under Distribution Shifts in Bioacoustics](https://arxiv.org/abs/2507.13727)
*René Heinrich,Lukas Rauch,Bernhard Sick,Christoph Scholz*

Main category: cs.LG

TL;DR: 研究探讨了对抗训练在音频分类中对泛化性能和对抗鲁棒性的影响，发现输出空间攻击策略显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 对抗训练对数据分布显著变化的音频分类的泛化影响尚未充分研究。

Method: 采用两种对抗训练策略（输出空间和嵌入空间攻击），评估两种模型架构（ConvNeXt和AudioProtoPNet）在鸟类声音分类任务中的表现。

Result: 输出空间攻击策略平均提升干净测试数据性能10.5%，并增强模型对抗鲁棒性。

Conclusion: 对抗训练在音频分类中具有提升分布变化和对抗攻击鲁棒性的潜力。

Abstract: Adversarial training is a promising strategy for enhancing model robustness
against adversarial attacks. However, its impact on generalization under
substantial data distribution shifts in audio classification remains largely
unexplored. To address this gap, this work investigates how different
adversarial training strategies improve generalization performance and
adversarial robustness in audio classification. The study focuses on two model
architectures: a conventional convolutional neural network (ConvNeXt) and an
inherently interpretable prototype-based model (AudioProtoPNet). The approach
is evaluated using a challenging bird sound classification benchmark. This
benchmark is characterized by pronounced distribution shifts between training
and test data due to varying environmental conditions and recording methods, a
common real-world challenge. The investigation explores two adversarial
training strategies: one based on output-space attacks that maximize the
classification loss function, and another based on embedding-space attacks
designed to maximize embedding dissimilarity. These attack types are also used
for robustness evaluation. Additionally, for AudioProtoPNet, the study assesses
the stability of its learned prototypes under targeted embedding-space attacks.
Results show that adversarial training, particularly using output-space
attacks, improves clean test data performance by an average of 10.5% relative
and simultaneously strengthens the adversarial robustness of the models. These
findings, although derived from the bird sound domain, suggest that adversarial
training holds potential to enhance robustness against both strong distribution
shifts and adversarial attacks in challenging audio classification settings.

</details>


### [134] [An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC](https://arxiv.org/abs/2507.13736)
*Matthias Jobst,Tim Langer,Chen Liu,Mehmet Alici,Hector A. Gonzalez,Christian Mayr*

Main category: cs.LG

TL;DR: 提出了一种基于OctopuScheduler的多层DNN调度框架，支持从PyTorch模型到SpiNNaker2芯片的端到端推理流程。


<details>
  <summary>Details</summary>
Motivation: 为了在神经形态平台SpiNNaker2上实现大型复杂DNN（如Transformer）的边缘执行。

Method: 结合量化和降阶步骤的前端，扩展OctopuScheduler为多层DNN调度框架。

Result: 实现了在SpiNNaker2芯片上高效运行复杂DNN的能力。

Conclusion: 该框架为神经形态硬件上的DNN推理提供了可行的解决方案。

Abstract: This work presents a multi-layer DNN scheduling framework as an extension of
OctopuScheduler, providing an end-to-end flow from PyTorch models to inference
on a single SpiNNaker2 chip. Together with a front-end comprised of
quantization and lowering steps, the proposed framework enables the edge-based
execution of large and complex DNNs up to transformer scale using the
neuromorphic platform SpiNNaker2.

</details>


### [135] [SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification](https://arxiv.org/abs/2507.13741)
*Shangyou Wang,Zezhong Ding,Xike Xie*

Main category: cs.LG

TL;DR: SamGoG框架通过采样机制解决图分类任务中的类别和大小不平衡问题，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现实图中的类别和大小不平衡会偏置学习过程并降低模型性能，现有方法通常只解决一种不平衡或计算成本高。

Method: SamGoG通过重要性采样构建多个图之图（GoG），结合可学习的相似性和自适应节点度增强边同质性。

Result: 在基准数据集上，SamGoG实现了15.66%的准确率提升和6.7倍的训练加速。

Conclusion: SamGoG能有效解决图分类中的不平衡问题，并与多种GNN无缝集成，性能优越。

Abstract: Graph Neural Networks (GNNs) have shown remarkable success in graph
classification tasks by capturing both structural and feature-based
representations. However, real-world graphs often exhibit two critical forms of
imbalance: class imbalance and graph size imbalance. These imbalances can bias
the learning process and degrade model performance. Existing methods typically
address only one type of imbalance or incur high computational costs. In this
work, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learning
framework that effectively mitigates both class and graph size imbalance.
SamGoG constructs multiple GoGs through an efficient importance-based sampling
mechanism and trains on them sequentially. This sampling mechanism incorporates
the learnable pairwise similarity and adaptive GoG node degree to enhance edge
homophily, thus improving downstream model quality. SamGoG can seamlessly
integrate with various downstream GNNs, enabling their efficient adaptation for
graph classification tasks. Extensive experiments on benchmark datasets
demonstrate that SamGoG achieves state-of-the-art performance with up to a
15.66% accuracy improvement with 6.7$\times$ training acceleration.

</details>


### [136] [Search-Optimized Quantization in Biomedical Ontology Alignment](https://arxiv.org/abs/2507.13742)
*Oussama Bouaggad,Natalia Grabar*

Main category: cs.LG

TL;DR: 论文提出了一种基于监督学习的变压器模型优化方法，用于生物医学本体对齐，显著提升了推理速度和内存效率。


<details>
  <summary>Details</summary>
Motivation: 解决AI模型在资源受限环境中的部署问题，如能耗、内存和延迟。

Method: 使用Microsoft Olive搜索优化目标，结合动态量化和Intel工具进行模型优化。

Result: 在DEFT 2020任务中达到新SOTA，推理速度提升20倍，内存减少70%。

Conclusion: 该方法有效优化了模型性能，适用于资源受限场景。

Abstract: In the fast-moving world of AI, as organizations and researchers develop more
advanced models, they face challenges due to their sheer size and computational
demands. Deploying such models on edge devices or in resource-constrained
environments adds further challenges related to energy consumption, memory
usage and latency. To address these challenges, emerging trends are shaping the
future of efficient model optimization techniques. From this premise, by
employing supervised state-of-the-art transformer-based models, this research
introduces a systematic method for ontology alignment, grounded in cosine-based
semantic similarity between a biomedical layman vocabulary and the Unified
Medical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to
search for target optimizations among different Execution Providers (EPs) using
the ONNX Runtime backend, followed by an assembled process of dynamic
quantization employing Intel Neural Compressor and IPEX (Intel Extension for
PyTorch). Through our optimization process, we conduct extensive assessments on
the two tasks from the DEFT 2020 Evaluation Campaign, achieving a new
state-of-the-art in both. We retain performance metrics intact, while attaining
an average inference speed-up of 20x and reducing memory usage by approximately
70%.

</details>


### [137] [MolPIF: A Parameter Interpolation Flow Model for Molecule Generation](https://arxiv.org/abs/2507.13762)
*Yaowei Jin,Junjie Wang,Wenkai Xiang,Duanhua Cao,Dan Teng,Zhehuan Fan,Jiacheng Xiong,Xia Sheng,Chuanlong Zeng,Mingyue Zheng,Qian Shi*

Main category: cs.LG

TL;DR: 提出了一种新的参数插值流模型（PIF），用于分子生成，在药物设计中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 尽管贝叶斯流网络（BFNs）在化学任务中表现优异，但其基于贝叶斯推断的策略限制了分布变换路径的灵活性，难以适应多样化的数据分布和任务需求。

Method: 提出了参数插值流模型（PIF），并详细阐述了其理论基础、训练和推理过程。开发了MolPIF用于基于结构的药物设计。

Result: MolPIF在多种指标上优于基线方法。

Conclusion: 验证了基于参数空间的生成建模范式在分子生成中的有效性，并为模型设计提供了新视角。

Abstract: Advances in deep learning for molecular generation show promise in
accelerating drug discovery. Bayesian Flow Networks (BFNs) have recently shown
impressive performance across diverse chemical tasks, with their success often
ascribed to the paradigm of modeling in a low-variance parameter space.
However, the Bayesian inference-based strategy imposes limitations on designing
more flexible distribution transformation pathways, making it challenging to
adapt to diverse data distributions and varied task requirements. Furthermore,
the potential for simpler, more efficient parameter-space-based models is
unexplored. To address this, we propose a novel Parameter Interpolation Flow
model (named PIF) with detailed theoretical foundation, training, and inference
procedures. We then develop MolPIF for structure-based drug design,
demonstrating its superior performance across diverse metrics compared to
baselines. This work validates the effectiveness of parameter-space-based
generative modeling paradigm for molecules and offers new perspectives for
model design.

</details>


### [138] [Dual-Center Graph Clustering with Neighbor Distribution](https://arxiv.org/abs/2507.13765)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Li Jin,Liqiang Nie*

Main category: cs.LG

TL;DR: 提出了一种基于邻居分布特性的双中心图聚类方法（DCGC），通过邻居分布作为监督信号提升对比学习效果，并引入双中心优化。


<details>
  <summary>Details</summary>
Motivation: 现有目标导向聚类方法仅利用特征构建单目标分布，导致指导不完整且不可靠。

Method: 利用邻居分布作为监督信号挖掘难负样本，并引入邻居分布中心与特征中心共同构建双目标分布进行优化。

Result: 实验证明该方法性能优越且有效。

Conclusion: DCGC通过邻居分布和双中心优化显著提升了图聚类的效果。

Abstract: Graph clustering is crucial for unraveling intricate data structures, yet it
presents significant challenges due to its unsupervised nature. Recently,
goal-directed clustering techniques have yielded impressive results, with
contrastive learning methods leveraging pseudo-label garnering considerable
attention. Nonetheless, pseudo-label as a supervision signal is unreliable and
existing goal-directed approaches utilize only features to construct a
single-target distribution for single-center optimization, which lead to
incomplete and less dependable guidance. In our work, we propose a novel
Dual-Center Graph Clustering (DCGC) approach based on neighbor distribution
properties, which includes representation learning with neighbor distribution
and dual-center optimization. Specifically, we utilize neighbor distribution as
a supervision signal to mine hard negative samples in contrastive learning,
which is reliable and enhances the effectiveness of representation learning.
Furthermore, neighbor distribution center is introduced alongside feature
center to jointly construct a dual-target distribution for dual-center
optimization. Extensive experiments and analysis demonstrate superior
performance and effectiveness of our proposed method.

</details>


### [139] [On-the-Fly Fine-Tuning of Foundational Neural Network Potentials: A Bayesian Neural Network Approach](https://arxiv.org/abs/2507.13805)
*Tim Rensmeyer,Denis Kramer,Oliver Niggemann*

Main category: cs.LG

TL;DR: 论文提出了一种基于贝叶斯神经网络的方法，用于微调预训练的基础模型，并通过实时学习自动优化模型，同时检测稀有事件。


<details>
  <summary>Details</summary>
Motivation: 由于从头计算原子间力的计算复杂度高，机器学习力场的研究变得活跃，但生成足够多样化的训练数据集仍具有挑战性，尤其是在稀有事件或大配置空间系统中。

Method: 采用贝叶斯神经网络方法微调预训练的基础模型，结合实时学习工作流，自动优化模型并检测稀有事件。

Result: 该方法能够在保持预设精度的同时自动微调模型，并提高对稀有事件（如过渡态）的采样率。

Conclusion: 提出的方法有效解决了基础模型微调中的不确定性量化问题，并实现了对稀有事件的高效检测和采样。

Abstract: Due to the computational complexity of evaluating interatomic forces from
first principles, the creation of interatomic machine learning force fields has
become a highly active field of research. However, the generation of training
datasets of sufficient size and sample diversity itself comes with a
computational burden that can make this approach impractical for modeling rare
events or systems with a large configuration space. Fine-tuning foundation
models that have been pre-trained on large-scale material or molecular
databases offers a promising opportunity to reduce the amount of training data
necessary to reach a desired level of accuracy. However, even if this approach
requires less training data overall, creating a suitable training dataset can
still be a very challenging problem, especially for systems with rare events
and for end-users who don't have an extensive background in machine learning.
In on-the-fly learning, the creation of a training dataset can be largely
automated by using model uncertainty during the simulation to decide if the
model is accurate enough or if a structure should be recalculated with
classical methods and used to update the model. A key challenge for applying
this form of active learning to the fine-tuning of foundation models is how to
assess the uncertainty of those models during the fine-tuning process, even
though most foundation models lack any form of uncertainty quantification. In
this paper, we overcome this challenge by introducing a fine-tuning approach
based on Bayesian neural network methods and a subsequent on-the-fly workflow
that automatically fine-tunes the model while maintaining a pre-specified
accuracy and can detect rare events such as transition states and sample them
at an increased rate relative to their occurrence.

</details>


### [140] [Scalable Submodular Policy Optimization via Pruned Submodularity Graph](https://arxiv.org/abs/2507.13834)
*Aditi Anand,Suman Banerjee,Dildar Ali*

Main category: cs.LG

TL;DR: 本文研究了强化学习中奖励函数为次模函数的问题，提出了一种基于修剪次模性图的方法，以在可行计算时间内提供近似最优解。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习中奖励函数通常为加法形式，但现实中许多问题（如路径规划、覆盖控制等）的奖励函数表现为递减回报，可用次模函数建模。本文旨在解决此类问题。

Method: 提出了一种基于修剪次模性图的方法，分析了其时间和空间复杂度，并提供了性能保证。

Result: 在基准测试中，所提方法获得的策略比基线方法产生更高的奖励。

Conclusion: 该方法在次模奖励函数的强化学习问题中表现优于传统方法，具有实际应用潜力。

Abstract: In Reinforcement Learning (abbreviated as RL), an agent interacts with the
environment via a set of possible actions, and a reward is generated from some
unknown distribution. The task here is to find an optimal set of actions such
that the reward after a certain time step gets maximized. In a traditional
setup, the reward function in an RL Problem is considered additive. However, in
reality, there exist many problems, including path planning, coverage control,
etc., the reward function follows the diminishing return, which can be modeled
as a submodular function. In this paper, we study a variant of the RL Problem
where the reward function is submodular, and our objective is to find an
optimal policy such that this reward function gets maximized. We have proposed
a pruned submodularity graph-based approach that provides a provably
approximate solution in a feasible computation time. The proposed approach has
been analyzed to understand its time and space requirements as well as a
performance guarantee. We have experimented with a benchmark agent-environment
setup, which has been used for similar previous studies, and the results are
reported. From the results, we observe that the policy obtained by our proposed
approach leads to more reward than the baseline methods.

</details>


### [141] [Self-supervised learning on gene expression data](https://arxiv.org/abs/2507.13912)
*Kevin Dradjat,Massinissa Hamidi,Pierre Bartet,Blaise Hanczar*

Main category: cs.LG

TL;DR: 研究探讨了自监督学习方法在基因表达数据表型预测中的应用，证明其优于传统监督学习，减少对标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 基因表达数据的标注成本高且耗时，传统监督学习方法受限，自监督学习能直接从无标注数据中提取信息。

Method: 选择了三种自监督学习方法，评估其在基因表达数据中的表现，并用于下游预测任务。

Result: 自监督学习方法能有效捕捉复杂信息，提高表型预测准确性，优于传统监督模型。

Conclusion: 自监督学习在基因表达数据分析中具有潜力，未来研究可进一步优化其应用。

Abstract: Predicting phenotypes from gene expression data is a crucial task in
biomedical research, enabling insights into disease mechanisms, drug responses,
and personalized medicine. Traditional machine learning and deep learning rely
on supervised learning, which requires large quantities of labeled data that
are costly and time-consuming to obtain in the case of gene expression data.
Self-supervised learning has recently emerged as a promising approach to
overcome these limitations by extracting information directly from the
structure of unlabeled data. In this study, we investigate the application of
state-of-the-art self-supervised learning methods to bulk gene expression data
for phenotype prediction. We selected three self-supervised methods, based on
different approaches, to assess their ability to exploit the inherent structure
of the data and to generate qualitative representations which can be used for
downstream predictive tasks. By using several publicly available gene
expression datasets, we demonstrate how the selected methods can effectively
capture complex information and improve phenotype prediction accuracy. The
results obtained show that self-supervised learning methods can outperform
traditional supervised models besides offering significant advantage by
reducing the dependency on annotated data. We provide a comprehensive analysis
of the performance of each method by highlighting their strengths and
limitations. We also provide recommendations for using these methods depending
on the case under study. Finally, we outline future research directions to
enhance the application of self-supervised learning in the field of gene
expression data analysis. This study is the first work that deals with bulk
RNA-Seq data and self-supervised learning.

</details>


### [142] [Reframing attention as a reinforcement learning problem for causal discovery](https://arxiv.org/abs/2507.13920)
*Turan Orujlu,Christian Gumbsch,Martin V. Butz,Charley M Wu*

Main category: cs.LG

TL;DR: 论文提出了一种动态因果结构的表示理论（Causal Process框架）及其实现（Causal Process Model），将Transformer的注意力机制与强化学习结合，以推断可解释的因果过程。


<details>
  <summary>Details</summary>
Motivation: 现有神经因果模型多假设静态因果图，忽视了因果交互的动态性，因此需要一种新的理论和方法来动态表示因果结构。

Method: 引入Causal Process框架，提出Causal Process Model，将Transformer的注意力机制嵌入强化学习，通过RL代理构建动态因果图假设。

Result: 在强化学习环境中，该方法在因果表示学习和代理性能上优于现有方法，并能恢复动态因果过程图。

Conclusion: Causal Process框架为动态因果结构提供了新的理论和实践工具，推动了因果表示与深度强化学习的结合。

Abstract: Formal frameworks of causality have operated largely parallel to modern
trends in deep reinforcement learning (RL). However, there has been a revival
of interest in formally grounding the representations learned by neural
networks in causal concepts. Yet, most attempts at neural models of causality
assume static causal graphs and ignore the dynamic nature of causal
interactions. In this work, we introduce Causal Process framework as a novel
theory for representing dynamic hypotheses about causal structure. Furthermore,
we present Causal Process Model as an implementation of this framework. This
allows us to reformulate the attention mechanism popularized by Transformer
networks within an RL setting with the goal to infer interpretable causal
processes from visual observations. Here, causal inference corresponds to
constructing a causal graph hypothesis which itself becomes an RL task nested
within the original RL problem. To create an instance of such hypothesis, we
employ RL agents. These agents establish links between units similar to the
original Transformer attention mechanism. We demonstrate the effectiveness of
our approach in an RL environment where we outperform current alternatives in
causal representation learning and agent performance, and uniquely recover
graphs of dynamic causal processes.

</details>


### [143] [MoDyGAN: Combining Molecular Dynamics With GANs to Investigate Protein Conformational Space](https://arxiv.org/abs/2507.13950)
*Jingbo Liang,Bruna Jacobson*

Main category: cs.LG

TL;DR: MoDyGAN是一种结合分子动力学模拟和生成对抗网络的新方法，用于高效探索蛋白质构象空间。


<details>
  <summary>Details</summary>
Motivation: 由于基于物理的动态模拟计算成本高，探索蛋白质构象空间仍具挑战性。

Method: MoDyGAN利用GAN将高斯分布映射到MD模拟轨迹，并通过双判别器和集成学习优化生成构象。创新性地将3D蛋白质结构转换为2D矩阵，以利用图像GAN架构。

Result: MoDyGAN成功生成了新的合理构象，并在隐空间插值中与SMD模拟轨迹一致。

Conclusion: 将蛋白质表示为类图像数据为生物分子模拟提供了新的深度学习应用可能，且框架可扩展到其他复杂3D结构。

Abstract: Extensively exploring protein conformational landscapes remains a major
challenge in computational biology due to the high computational cost involved
in dynamic physics-based simulations. In this work, we propose a novel
pipeline, MoDyGAN, that leverages molecular dynamics (MD) simulations and
generative adversarial networks (GANs) to explore protein conformational
spaces. MoDyGAN contains a generator that maps Gaussian distributions into
MD-derived protein trajectories, and a refinement module that combines ensemble
learning with a dual-discriminator to further improve the plausibility of
generated conformations. Central to our approach is an innovative
representation technique that reversibly transforms 3D protein structures into
2D matrices, enabling the use of advanced image-based GAN architectures. We use
three rigid proteins to demonstrate that MoDyGAN can generate plausible new
conformations. We also use deca-alanine as a case study to show that
interpolations within the latent space closely align with trajectories obtained
from steered molecular dynamics (SMD) simulations. Our results suggest that
representing proteins as image-like data unlocks new possibilities for applying
advanced deep learning techniques to biomolecular simulation, leading to an
efficient sampling of conformational states. Additionally, the proposed
framework holds strong potential for extension to other complex 3D structures.

</details>


### [144] [Robust Anomaly Detection with Graph Neural Networks using Controllability](https://arxiv.org/abs/2507.13954)
*Yifan Wei,Anwar Said,Waseem Abbas,Xenofon Koutsoukos*

Main category: cs.LG

TL;DR: 论文提出两种新方法，通过平均可控性改进图机器学习模型的异常检测性能，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 复杂领域中的异常检测面临标记数据不足和样本不平衡的挑战，图机器学习模型需要创新策略以提升性能。

Method: 提出两种方法：将平均可控性作为边权重或编码为一热边属性向量，以增强图模型的异常检测能力。

Result: 在真实和合成网络上验证，新方法优于六种基线模型，显著提升了异常检测性能。

Conclusion: 平均可控性可作为额外指标，有效解决稀疏和不平衡数据集中的异常检测问题。

Abstract: Anomaly detection in complex domains poses significant challenges due to the
need for extensive labeled data and the inherently imbalanced nature of
anomalous versus benign samples. Graph-based machine learning models have
emerged as a promising solution that combines attribute and relational data to
uncover intricate patterns. However, the scarcity of anomalous data exacerbates
the challenge, which requires innovative strategies to enhance model learning
with limited information. In this paper, we hypothesize that the incorporation
of the influence of the nodes, quantified through average controllability, can
significantly improve the performance of anomaly detection. We propose two
novel approaches to integrate average controllability into graph-based
frameworks: (1) using average controllability as an edge weight and (2)
encoding it as a one-hot edge attribute vector. Through rigorous evaluation on
real-world and synthetic networks with six state-of-the-art baselines, our
proposed methods demonstrate improved performance in identifying anomalies,
highlighting the critical role of controllability measures in enhancing the
performance of graph machine learning models. This work underscores the
potential of integrating average controllability as additional metrics to
address the challenges of anomaly detection in sparse and imbalanced datasets.

</details>


### [145] [Signs of the Past, Patterns of the Present: On the Automatic Classification of Old Babylonian Cuneiform Signs](https://arxiv.org/abs/2507.13959)
*Eli Verwimp,Gustav Ryberg Smidt,Hendrik Hameeuw,Katrien De Graef*

Main category: cs.LG

TL;DR: 本文研究了机器学习在楔形文字分类中的应用，分析了数据差异对模型性能的影响，并提出了未来数据采集标准的建议。


<details>
  <summary>Details</summary>
Motivation: 楔形文字的多样性（来源、用途、书写者和数字化方式）导致模型在不同数据集上表现不佳，本文旨在研究这种差异对性能的影响。

Method: 使用ResNet50模型，基于三个美索不达米亚城市（尼普尔、杜尔-阿比舒和西帕尔）的手写古巴比伦文本进行训练和测试。

Result: 模型在至少20个实例的楔形文字上取得了87.1%的top-1准确率和96.5%的top-5准确率。

Conclusion: 研究为未来楔形文字分类任务提供了基础，并建议改进数据采集标准以提高模型泛化能力。

Abstract: The work in this paper describes the training and evaluation of machine
learning (ML) techniques for the classification of cuneiform signs. There is a
lot of variability in cuneiform signs, depending on where they come from, for
what and by whom they were written, but also how they were digitized. This
variability makes it unlikely that an ML model trained on one dataset will
perform successfully on another dataset. This contribution studies how such
differences impact that performance. Based on our results and insights, we aim
to influence future data acquisition standards and provide a solid foundation
for future cuneiform sign classification tasks. The ML model has been trained
and tested on handwritten Old Babylonian (c. 2000-1600 B.C.E.) documentary
texts inscribed on clay tablets originating from three Mesopotamian cities
(Nippur, D\=ur-Abie\v{s}uh and Sippar). The presented and analysed model is
ResNet50, which achieves a top-1 score of 87.1% and a top-5 score of 96.5% for
signs with at least 20 instances. As these automatic classification results are
the first on Old Babylonian texts, there are currently no comparable results.

</details>


### [146] [Structural Connectome Harmonization Using Deep Learning: The Strength of Graph Neural Networks](https://arxiv.org/abs/2507.13992)
*Jagruti Patel,Thomas A. W. Bolton,Mikkel Schöttner,Anjali Tarun,Sebastien Tourbier,Yasser Alemàn-Gòmez,Jonas Richiardi,Patric Hagmann*

Main category: cs.LG

TL;DR: 论文提出了一种基于深度学习的框架，用于跨多站点结构连接组（SC）数据的协调，解决了现有方法依赖元数据或忽略图拓扑的问题。


<details>
  <summary>Details</summary>
Motivation: 神经影像学中小样本量限制了可靠生物标志物的开发，多站点研究存在扫描仪异质性导致的偏差，现有协调方法依赖元数据或忽略图结构。

Method: 提出了一种站点条件深度协调框架，测试了三种深度架构（全连接自编码器、卷积自编码器和图卷积自编码器）与线性回归基线的性能。

Result: 非图模型在边权重预测和边存在检测上表现优异，图自编码器在拓扑结构和个体特征保留上更优，线性回归基线性能最高但依赖元数据。

Conclusion: 图架构在结构感知和泛化性方面表现突出，适合大规模多站点SC研究。

Abstract: Small sample sizes in neuroimaging in general, and in structural connectome
(SC) studies in particular limit the development of reliable biomarkers for
neurological and psychiatric disorders - such as Alzheimer's disease and
schizophrenia - by reducing statistical power, reliability, and
generalizability. Large-scale multi-site studies have exist, but they have
acquisition-related biases due to scanner heterogeneity, compromising imaging
consistency and downstream analyses. While existing SC harmonization methods -
such as linear regression (LR), ComBat, and deep learning techniques - mitigate
these biases, they often rely on detailed metadata, traveling subjects (TS), or
overlook the graph-topology of SCs. To address these limitations, we propose a
site-conditioned deep harmonization framework that harmonizes SCs across
diverse acquisition sites without requiring metadata or TS that we test in a
simulated scenario based on the Human Connectome Dataset. Within this
framework, we benchmark three deep architectures - a fully connected
autoencoder (AE), a convolutional AE, and a graph convolutional AE - against a
top-performing LR baseline. While non-graph models excel in edge-weight
prediction and edge existence detection, the graph AE demonstrates superior
preservation of topological structure and subject-level individuality, as
reflected by graph metrics and fingerprinting accuracy, respectively. Although
the LR baseline achieves the highest numerical performance by explicitly
modeling acquisition parameters, it lacks applicability to real-world
multi-site use cases as detailed acquisition metadata is often unavailable. Our
results highlight the critical role of model architecture in SC harmonization
performance and demonstrate that graph-based approaches are particularly
well-suited for structure-aware, domain-generalizable SC harmonization in
large-scale multi-site SC studies.

</details>


### [147] [ParallelTime: Dynamically Weighting the Balance of Short- and Long-Term Temporal Dependencies](https://arxiv.org/abs/2507.13998)
*Itay Katav,Aryeh Kontorovich*

Main category: cs.LG

TL;DR: 论文提出了一种动态加权机制ParallelTime Weighter和ParallelTime架构，用于优化时间序列预测中长短期依赖的权重分配，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在时间序列预测中对长短期依赖赋予相同权重，但研究发现这种分配并不最优。

Method: 提出动态加权机制ParallelTime Weighter，根据输入和模型知识为每个token计算长短期依赖的权重，并引入ParallelTime架构。

Result: ParallelTime在多个基准测试中表现优异，具有鲁棒性、低计算量、少参数需求，并能扩展到更长预测范围。

Conclusion: ParallelTime为时间序列预测中的并行Attention-Mamba架构提供了新的发展方向。

Abstract: Modern multivariate time series forecasting primarily relies on two
architectures: the Transformer with attention mechanism and Mamba. In natural
language processing, an approach has been used that combines local window
attention for capturing short-term dependencies and Mamba for capturing
long-term dependencies, with their outputs averaged to assign equal weight to
both. We find that for time-series forecasting tasks, assigning equal weight to
long-term and short-term dependencies is not optimal. To mitigate this, we
propose a dynamic weighting mechanism, ParallelTime Weighter, which calculates
interdependent weights for long-term and short-term dependencies for each token
based on the input and the model's knowledge. Furthermore, we introduce the
ParallelTime architecture, which incorporates the ParallelTime Weighter
mechanism to deliver state-of-the-art performance across diverse benchmarks.
Our architecture demonstrates robustness, achieves lower FLOPs, requires fewer
parameters, scales effectively to longer prediction horizons, and significantly
outperforms existing methods. These advances highlight a promising path for
future developments of parallel Attention-Mamba in time series forecasting. The
implementation is readily available at:
\href{https://github.com/itay1551/ParallelTime}{ParallelTime GitHub

</details>


### [148] [On the Fundamental Limitations of Dual Static CVaR Decompositions in Markov Decision Processes](https://arxiv.org/abs/2507.14005)
*Mathieu Godbout,Audrey Durand*

Main category: cs.LG

TL;DR: 论文分析了动态规划方法在MDP中寻找静态CVaR最优策略时失败的原因，提出风险分配一致性约束的概念，并证明双CVaR分解方法在寻找全局最优策略时的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究动态规划方法在静态CVaR优化中的失败原因，并探索其根本问题。

Method: 通过策略评估任务，提出风险分配一致性约束，并量化CVaR评估误差。

Result: 发现双CVaR分解方法在某些MDP中无法找到全局最优策略。

Conclusion: 双CVaR分解方法在寻找全局最优策略时存在根本性限制。

Abstract: Recent work has shown that dynamic programming (DP) methods for finding
static CVaR-optimal policies in Markov Decision Processes (MDPs) can fail when
based on the dual formulation, yet the root cause for the failure has remained
unclear. We expand on these findings by shifting focus from policy optimization
to the seemingly simpler task of policy evaluation. We show that evaluating the
static CVaR of a given policy can be framed as two distinct minimization
problems. For their solutions to match, a set of ``risk-assignment consistency
constraints'' must be satisfied, and we demonstrate that the intersection of
the constraints being empty is the source of previously observed evaluation
errors. Quantifying the evaluation error as the CVaR evaluation gap, we then
demonstrate that the issues observed when optimizing over the dual-based CVaR
DP are explained by the returned policy having a non-zero CVaR evaluation gap.
We then leverage our proposed risk-assignment perspective to prove that the
search for a single, uniformly optimal policy via on the dual CVaR
decomposition is fundamentally limited, identifying an MDP where no single
policy can be optimal across all initial risk levels.

</details>


### [149] [Byzantine-resilient federated online learning for Gaussian process regression](https://arxiv.org/abs/2507.14021)
*Xu Zhang,Zhenyuan Yuan,Minghui Zhu*

Main category: cs.LG

TL;DR: 提出了一种拜占庭容错的联邦高斯过程回归算法，用于在部分代理存在拜占庭故障时提升学习性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何在代理存在拜占庭故障（任意或敌对行为）的情况下，通过联邦学习提升高斯过程回归的性能。

Method: 开发了一种拜占庭容错的联邦GPR算法，通过代理本地GPR发送预测到云端，云端使用拜占庭容错的专家乘积聚合规则计算全局模型，并广播回代理。代理通过融合全局模型和本地模型优化预测。

Result: 量化了代理融合GPR相对于本地GPR的学习精度提升，并在玩具示例和两个真实数据集上验证了算法性能。

Conclusion: 提出的算法在拜占庭故障存在的情况下，有效提升了联邦高斯过程回归的学习性能。

Abstract: In this paper, we study Byzantine-resilient federated online learning for
Gaussian process regression (GPR). We develop a Byzantine-resilient federated
GPR algorithm that allows a cloud and a group of agents to collaboratively
learn a latent function and improve the learning performances where some agents
exhibit Byzantine failures, i.e., arbitrary and potentially adversarial
behavior. Each agent-based local GPR sends potentially compromised local
predictions to the cloud, and the cloud-based aggregated GPR computes a global
model by a Byzantine-resilient product of experts aggregation rule. Then the
cloud broadcasts the current global model to all the agents. Agent-based fused
GPR refines local predictions by fusing the received global model with that of
the agent-based local GPR. Moreover, we quantify the learning accuracy
improvements of the agent-based fused GPR over the agent-based local GPR.
Experiments on a toy example and two medium-scale real-world datasets are
conducted to demonstrate the performances of the proposed algorithm.

</details>


### [150] [DONUT: Physics-aware Machine Learning for Real-time X-ray Nanodiffraction Analysis](https://arxiv.org/abs/2507.14038)
*Aileen Luo,Tao Zhou,Ming Du,Martin V. Holt,Andrej Singer,Mathew J. Cherukara*

Main category: cs.LG

TL;DR: DONUT是一种基于物理感知的神经网络，用于快速自动分析纳米束衍射数据，无需标记数据集或预训练，显著提高了实时分析效率。


<details>
  <summary>Details</summary>
Motivation: 实时分析纳米束衍射数据的瓶颈在于计算复杂性和伪影问题，传统方法效率低下。

Method: DONUT结合可微几何衍射模型，通过无监督训练预测晶体晶格应变和取向。

Result: 实验表明，DONUT比传统拟合方法效率高200倍以上，能准确提取数据特征。

Conclusion: DONUT为X射线科学中的实时分析提供了一种高效且无需监督学习的解决方案。

Abstract: Coherent X-ray scattering techniques are critical for investigating the
fundamental structural properties of materials at the nanoscale. While
advancements have made these experiments more accessible, real-time analysis
remains a significant bottleneck, often hindered by artifacts and computational
demands. In scanning X-ray nanodiffraction microscopy, which is widely used to
spatially resolve structural heterogeneities, this challenge is compounded by
the convolution of the divergent beam with the sample's local structure. To
address this, we introduce DONUT (Diffraction with Optics for Nanobeam by
Unsupervised Training), a physics-aware neural network designed for the rapid
and automated analysis of nanobeam diffraction data. By incorporating a
differentiable geometric diffraction model directly into its architecture,
DONUT learns to predict crystal lattice strain and orientation in real-time.
Crucially, this is achieved without reliance on labeled datasets or
pre-training, overcoming a fundamental limitation for supervised machine
learning in X-ray science. We demonstrate experimentally that DONUT accurately
extracts all features within the data over 200 times more efficiently than
conventional fitting methods.

</details>


### [151] [Noradrenergic-inspired gain modulation attenuates the stability gap in joint training](https://arxiv.org/abs/2507.14056)
*Alejandro Rodriguez-Garcia,Anindya Ghosh,Srikanth Ramaswamy*

Main category: cs.LG

TL;DR: 论文研究了持续学习中的稳定性间隙问题，提出了一种基于不确定性调制增益的动态机制来平衡知识整合与干扰。


<details>
  <summary>Details</summary>
Motivation: 持续学习中的稳定性间隙揭示了现有方法在适应新任务时对已掌握任务性能的下降，需要一种机制来平衡可塑性与稳定性。

Method: 受生物大脑多时间尺度动态启发，提出不确定性调制增益动态机制，模拟两时间尺度优化器。

Result: 在MNIST和CIFAR基准测试中，该机制有效减少了稳定性间隙。

Conclusion: 不确定性调制增益动态不仅减少了稳定性间隙，还提供了对持续学习任务性能提升的机制性见解。

Abstract: Recent studies in continual learning have identified a transient drop in
performance on mastered tasks when assimilating new ones, known as the
stability gap. Such dynamics contradict the objectives of continual learning,
revealing a lack of robustness in mitigating forgetting, and notably,
persisting even under an ideal joint-loss regime. Examining this gap within
this idealized joint training context is critical to isolate it from other
sources of forgetting. We argue that it reflects an imbalance between rapid
adaptation and robust retention at task boundaries, underscoring the need to
investigate mechanisms that reconcile plasticity and stability within continual
learning frameworks. Biological brains navigate a similar dilemma by operating
concurrently on multiple timescales, leveraging neuromodulatory signals to
modulate synaptic plasticity. However, artificial networks lack native
multitimescale dynamics, and although optimizers like momentum-SGD and Adam
introduce implicit timescale regularization, they still exhibit stability gaps.
Inspired by locus coeruleus mediated noradrenergic bursts, which transiently
enhance neuronal gain under uncertainty to facilitate sensory assimilation, we
propose uncertainty-modulated gain dynamics - an adaptive mechanism that
approximates a two-timescale optimizer and dynamically balances integration of
knowledge with minimal interference on previously consolidated information. We
evaluate our mechanism on domain-incremental and class-incremental variants of
the MNIST and CIFAR benchmarks under joint training, demonstrating that
uncertainty-modulated gain dynamics effectively attenuate the stability gap.
Finally, our analysis elucidates how gain modulation replicates noradrenergic
functions in cortical circuits, offering mechanistic insights into reducing
stability gaps and enhance performance in continual learning tasks.

</details>


### [152] [Preference-based Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2507.14066)
*Ni Mu,Yao Luan,Qing-Shan Jia*

Main category: cs.LG

TL;DR: 论文提出了一种基于偏好的多目标强化学习方法（Pb-MORL），通过偏好指导策略优化，避免了复杂的奖励设计，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 多目标强化学习（MORL）通常依赖预定义的奖励函数，难以平衡冲突目标且易简化问题。偏好作为更灵活的决策指导，可以解决这一问题。

Method: 提出Pb-MORL，将偏好整合到MORL框架中，构建与偏好对齐的多目标奖励模型，并证明优化该模型等价于训练帕累托最优策略。

Result: 在多个基准任务、能源管理任务和自动驾驶任务中，Pb-MORL表现优异，甚至超越使用真实奖励函数的方法。

Conclusion: Pb-MORL展示了在复杂现实系统中应用的潜力，为多目标优化提供了更灵活的解决方案。

Abstract: Multi-objective reinforcement learning (MORL) is a structured approach for
optimizing tasks with multiple objectives. However, it often relies on
pre-defined reward functions, which can be hard to design for balancing
conflicting goals and may lead to oversimplification. Preferences can serve as
more flexible and intuitive decision-making guidance, eliminating the need for
complicated reward design. This paper introduces preference-based MORL
(Pb-MORL), which formalizes the integration of preferences into the MORL
framework. We theoretically prove that preferences can derive policies across
the entire Pareto frontier. To guide policy optimization using preferences, our
method constructs a multi-objective reward model that aligns with the given
preferences. We further provide theoretical proof to show that optimizing this
reward model is equivalent to training the Pareto optimal policy. Extensive
experiments in benchmark multi-objective tasks, a multi-energy management task,
and an autonomous driving task on a multi-line highway show that our method
performs competitively, surpassing the oracle method, which uses the ground
truth reward function. This highlights its potential for practical applications
in complex real-world systems.

</details>


### [153] [DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration](https://arxiv.org/abs/2507.14088)
*Xiyun Li,Yining Ding,Yuhua Jiang,Yunlong Zhao,Runpeng Xie,Shuang Xu,Yuanhua Ni,Yiqin Yang,Bo Xu*

Main category: cs.LG

TL;DR: 提出了一种新的双过程多尺度心智理论（DPMT）框架，通过多尺度心智理论模块增强人机协作。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLM）代理难以准确建模复杂的人类心理特征（如领域意图），特别是在缺乏直接沟通的情况下。

Method: 提出DPMT框架，结合多尺度心智理论（ToM）模块，通过心理特征推理实现稳健的人类伙伴建模。

Result: 实验表明DPMT显著提升了人机协作效果，消融研究验证了多尺度ToM在慢系统中的贡献。

Conclusion: DPMT框架通过多尺度ToM模块有效解决了动态场景中人类行为建模的挑战。

Abstract: Real-time human-artificial intelligence (AI) collaboration is crucial yet
challenging, especially when AI agents must adapt to diverse and unseen human
behaviors in dynamic scenarios. Existing large language model (LLM) agents
often fail to accurately model the complex human mental characteristics such as
domain intentions, especially in the absence of direct communication. To
address this limitation, we propose a novel dual process multi-scale theory of
mind (DPMT) framework, drawing inspiration from cognitive science dual process
theory. Our DPMT framework incorporates a multi-scale theory of mind (ToM)
module to facilitate robust human partner modeling through mental
characteristic reasoning. Experimental results demonstrate that DPMT
significantly enhances human-AI collaboration, and ablation studies further
validate the contributions of our multi-scale ToM in the slow system.

</details>


### [154] [Kolmogorov Arnold Networks (KANs) for Imbalanced Data -- An Empirical Perspective](https://arxiv.org/abs/2507.14121)
*Pankaj Yadav,Vivek Vijay*

Main category: cs.LG

TL;DR: Kolmogorov Arnold Networks (KANs) 在类别不平衡分类中表现优于标准神经网络（MLPs），但传统不平衡策略与KANs冲突，且其计算成本高。MLPs结合不平衡技术可达到与KANs相当的效果，但资源消耗更低。


<details>
  <summary>Details</summary>
Motivation: 研究KANs在类别不平衡分类中的表现，探索其与传统不平衡策略的兼容性及计算效率。

Method: 在十个基准数据集上对KANs和MLPs进行实证评估，比较其在原始不平衡数据及结合不平衡策略时的表现。

Result: KANs在原始不平衡数据上表现优于MLPs，但传统不平衡策略显著降低其性能。MLPs结合不平衡技术可达到与KANs相当的效果，且资源消耗更低。

Conclusion: KANs适用于资源充足的原始不平衡数据场景，但其性能与资源消耗的权衡及与传统策略的冲突限制了实际应用。未来需优化KANs的架构和计算效率。

Abstract: Kolmogorov Arnold Networks (KANs) are recent architectural advancement in
neural computation that offer a mathematically grounded alternative to standard
neural networks. This study presents an empirical evaluation of KANs in context
of class imbalanced classification, using ten benchmark datasets. We observe
that KANs can inherently perform well on raw imbalanced data more effectively
than Multi-Layer Perceptrons (MLPs) without any resampling strategy. However,
conventional imbalance strategies fundamentally conflict with KANs mathematical
structure as resampling and focal loss implementations significantly degrade
KANs performance, while marginally benefiting MLPs. Crucially, KANs suffer from
prohibitive computational costs without proportional performance gains.
Statistical validation confirms that MLPs with imbalance techniques achieve
equivalence with KANs (|d| < 0.08 across metrics) at minimal resource costs.
These findings reveal that KANs represent a specialized solution for raw
imbalanced data where resources permit. But their severe performance-resource
tradeoffs and incompatibility with standard resampling techniques currently
limits practical deployment. We identify critical research priorities as
developing KAN specific architectural modifications for imbalance learning,
optimizing computational efficiency, and theoretical reconciling their conflict
with data augmentation. This work establishes foundational insights for next
generation KAN architectures in imbalanced classification scenarios.

</details>


### [155] [Toward Temporal Causal Representation Learning with Tensor Decomposition](https://arxiv.org/abs/2507.14126)
*Jianhong Chen,Meng Zhao,Mostafa Reisi Gahrooei,Xubo Yue*

Main category: cs.LG

TL;DR: 提出了一种结合时间因果表示学习与非规则张量分解的框架CaRTeD，用于高维变长数据，理论证明其收敛性，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 高维非规则张量数据在现实应用中常见，但现有方法难以有效提取因果表示和聚类信息。

Method: 提出CaRTeD框架，结合时间因果表示学习与非规则张量分解，提供灵活的正则化设计。

Result: 理论证明算法收敛，实验在合成和真实数据（如MIMIC-III）上表现优于现有方法。

Conclusion: CaRTeD填补了非规则张量分解的理论空白，提升了因果表示的可解释性和下游任务性能。

Abstract: Temporal causal representation learning is a powerful tool for uncovering
complex patterns in observational studies, which are often represented as
low-dimensional time series. However, in many real-world applications, data are
high-dimensional with varying input lengths and naturally take the form of
irregular tensors. To analyze such data, irregular tensor decomposition is
critical for extracting meaningful clusters that capture essential information.
In this paper, we focus on modeling causal representation learning based on the
transformed information. First, we present a novel causal formulation for a set
of latent clusters. We then propose CaRTeD, a joint learning framework that
integrates temporal causal representation learning with irregular tensor
decomposition. Notably, our framework provides a blueprint for downstream tasks
using the learned tensor factors, such as modeling latent structures and
extracting causal information, and offers a more flexible regularization design
to enhance tensor decomposition. Theoretically, we show that our algorithm
converges to a stationary point. More importantly, our results fill the gap in
theoretical guarantees for the convergence of state-of-the-art irregular tensor
decomposition. Experimental results on synthetic and real-world electronic
health record (EHR) datasets (MIMIC-III), with extensive benchmarks from both
phenotyping and network recovery perspectives, demonstrate that our proposed
method outperforms state-of-the-art techniques and enhances the explainability
of causal representations.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [156] [CogniQ-H: A Soft Hierarchical Reinforcement Learning Paradigm for Automated Data Preparation](https://arxiv.org/abs/2507.13710)
*Jing Chang,Chang Liu,Jinbin Huang,Rui Mao,Jianbin Qin*

Main category: cs.DB

TL;DR: CogniQ-H是一种基于软层次强化学习（HRL）的数据准备框架，结合了LLM的战略先验、LTR模型的细粒度评分和Q函数的长远价值估计，显著提升了管道质量和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 数据准备是机器学习生命周期中基础但极具挑战性的环节，现有强化学习方法效率低下，未能捕捉问题的结构化层次性。

Method: 提出CogniQ-H框架，通过贝叶斯推断实现动作选择，结合LLM的战略先验、LTR模型的评分和Q函数的长远价值估计。

Result: 在18个多样化数据集上，CogniQ-H实现了管道质量提升13.9%和收敛速度加快2.8倍。

Conclusion: CogniQ-H通过软层次强化学习框架，有效平衡了战略指导和自适应决策，显著优于现有方法。

Abstract: Data preparation is a foundational yet notoriously challenging component of
the machine learning lifecycle, characterized by a vast combinatorial search
space of potential operator sequences. While reinforcement learning (RL) offers
a promising direction, existing approaches are inefficient as they fail to
capture the structured, hierarchical nature of the problem. We argue that
Hierarchical Reinforcement Learning (HRL), a paradigm that has been successful
in other domains, provides a conceptually ideal yet previously unexplored
framework for this task. However, a naive HRL implementation with a `hard
hierarchy' is prone to suboptimal, irreversible decisions. To address this, we
introduce CogniQ-H, the first framework to implement a soft hierarchical
paradigm for robust, end-to-end automated data preparation. CogniQ-H formulates
action selection as a Bayesian inference problem. A high-level strategic prior,
generated by a Large Language Model (LLM), guides exploration
probabilistically. This prior is synergistically combined with a fine-grained
operator quality score from a supervised Learning-to-Rank (LTR) model and a
long-term value estimate from the agent's own Q-function. This hybrid
architecture allows CogniQ-H to balance strategic guidance with adaptive,
evidence-based decision-making. Through extensive experiments on 18 diverse
datasets spanning multiple domains, we demonstrate that CogniQ-H achieves up to
13.9\% improvement in pipeline quality and 2.8$\times$ faster convergence
compared to state-of-the-art RL-based methods.

</details>


### [157] [LLaPipe: LLM-Guided Reinforcement Learning for Automated Data Preparation Pipeline Construction](https://arxiv.org/abs/2507.13712)
*Jing Chang,Chang Liu,Jinbin Huang,Rui Mao,Jianbin Qin*

Main category: cs.DB

TL;DR: LLaPipe是一个结合大型语言模型（LLMs）的智能策略顾问框架，用于优化数据预处理管道的探索效率，相比传统方法在质量和速度上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习（RL）的数据预处理方法在探索庞大的预处理管道空间时效率低下，限制了机器学习的普及。

Method: LLaPipe通过LLM Policy Advisor分析数据集语义和管道历史，提供探索建议；Experience Distillation挖掘成功模式；Adaptive Advisor Triggering动态决定LLM干预时机。

Result: 在18个数据集上的实验显示，LLaPipe在管道质量上提升22.4%，收敛速度提高2.3倍，且计算效率高（LLM仅占19.0%的探索步骤）。

Conclusion: LLaPipe通过智能LLM干预显著提升了数据预处理管道的探索效率和质量，为自动化机器学习提供了新思路。

Abstract: Automated data preparation is crucial for democratizing machine learning, yet
existing reinforcement learning (RL) based approaches suffer from inefficient
exploration in the vast space of possible preprocessing pipelines. We present
LLaPipe, a novel framework that addresses this exploration bottleneck by
integrating Large Language Models (LLMs) as intelligent policy advisors. Unlike
traditional methods that rely solely on statistical features and blind
trial-and-error, LLaPipe leverages the semantic understanding capabilities of
LLMs to provide contextually relevant exploration guidance. Our framework
introduces three key innovations: (1) an LLM Policy Advisor that analyzes
dataset semantics and pipeline history to suggest promising preprocessing
operations, (2) an Experience Distillation mechanism that mines successful
patterns from past pipelines and transfers this knowledge to guide future
exploration, and (3) an Adaptive Advisor Triggering strategy
(Advisor\textsuperscript{+}) that dynamically determines when LLM intervention
is most beneficial, balancing exploration effectiveness with computational
cost. Through extensive experiments on 18 diverse datasets spanning multiple
domains, we demonstrate that LLaPipe achieves up to 22.4\% improvement in
pipeline quality and 2.3$\times$ faster convergence compared to
state-of-the-art RL-based methods, while maintaining computational efficiency
through selective LLM usage (averaging only 19.0\% of total exploration steps).

</details>


### [158] [Efficient and Scalable Self-Healing Databases Using Meta-Learning and Dependency-Driven Recovery](https://arxiv.org/abs/2507.13757)
*Joydeep Chandra,Prabal Manhas*

Main category: cs.DB

TL;DR: 提出了一种结合元学习和强化学习的自愈数据库框架，解决动态工作负载环境中的实时适应性和最小化再训练问题。


<details>
  <summary>Details</summary>
Motivation: 解决数据库在动态工作负载环境中的实时适应性和最小化再训练挑战。

Method: 整合MAML与强化学习，结合多目标优化、GNN、合成任务增强、自监督学习和可解释AI技术。

Result: 框架显著提升了适应性、效率和可靠性。

Conclusion: 该框架在数据库管理和自愈系统方面取得了重要进展。

Abstract: This study explored the development of a novel self-healing framework for
databases using meta-learning and reinforcement learning techniques. The
primary objective was to address the challenges of real-time adaptability and
minimal retraining in dynamic workload environments. The proposed approach
integrated Model-Agnostic Meta-Learning (MAML) with reinforcement learning to
enable anomaly detection and corrective actions that adapted swiftly to
evolving database conditions. Multi-objective optimization was employed to
balance performance, resource utilization, and cost efficiency during the
healing process. Graph Neural Networks (GNNs) were incorporated to model
interdependencies within database components, ensuring holistic recovery
strategies. Data efficiency was enhanced through synthetic task augmentation
and self-supervised learning, enabling effective training in sparse data
regimes. To promote trust and transparency, explainable AI techniques were
integrated to provide interpretable insights into anomaly detection and healing
actions. Federated meta-learning further enabled privacy-preserving
adaptability in distributed database environments. The framework demonstrated
significant improvements in adaptability, efficiency, and reliability,
contributing to advancements in database management and self-healing systems.

</details>


### [159] [Towards Next Generation Data Engineering Pipelines](https://arxiv.org/abs/2507.13892)
*Kevin M. Kramer,Valerie Restat,Sebastian Strasser,Uta Störl,Meike Klettke*

Main category: cs.DB

TL;DR: 论文提出下一代数据工程管道的三个层次：优化、自感知和自适应，以解决现有管道在数据质量和反应性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有数据工程管道在数据质量和应对变化方面存在不足，可能导致崩溃或输出不理想结果。

Method: 提出三个层次的改进：优化管道组成与参数化、自感知管道的状态监控、自适应管道的自动反应。

Result: 通过优化、自感知和自适应方法，提升数据工程管道的质量和反应能力。

Conclusion: 下一代数据工程管道应具备优化、自感知和自适应能力，以应对数据质量和变化挑战。

Abstract: Data engineering pipelines are a widespread way to provide high-quality data
for all kinds of data science applications. However, numerous challenges still
remain in the composition and operation of such pipelines. Data engineering
pipelines do not always deliver high-quality data. By default, they are also
not reactive to changes. When new data is coming in which deviates from prior
data, the pipeline could crash or output undesired results. We therefore
envision three levels of next generation data engineering pipelines: optimized
data pipelines, self-aware data pipelines, and self-adapting data pipelines.
Pipeline optimization addresses the composition of operators and their
parametrization in order to achieve the highest possible data quality.
Self-aware data engineering pipelines enable a continuous monitoring of its
current state, notifying data engineers on significant changes. Self-adapting
data engineering pipelines are then even able to automatically react to those
changes. We propose approaches to achieve each of these levels.

</details>


### [160] [Project-connex Decompositions and Tractability of Aggregate Group-by Conjunctive Queries](https://arxiv.org/abs/2507.14101)
*Diego Figueira,Cibele Freire*

Main category: cs.DB

TL;DR: 论文提出了一种名为'project-connex'树宽的新度量，用于衡量半环聚合查询的易处理性，并统一了多种查询类型的复杂性分析。


<details>
  <summary>Details</summary>
Motivation: 现有方法针对不同类型的查询（如聚合查询、枚举查询、计数查询）分别设计了不同的结构条件，缺乏统一的度量标准。

Method: 通过扩展'free-connex'分解的概念，定义了'project-connex'树分解，并展示了其算法操作的一致性和直观性。

Result: 证明了'project-connex'树宽能够统一解释现有查询类型的易处理性结果，并展示了如何通过经典树分解算法获得此类分解。

Conclusion: 'project-connex'树宽为半环聚合查询提供了一种统一的易处理性度量，简化了复杂性分析并扩展了应用范围。

Abstract: We introduce 'project-connex' tree-width as a measure of tractability for
counting and aggregate conjunctive queries over semirings with 'group-by'
projection (also known as 'AJAR' or 'FAQ' queries). This elementary measure
allows to obtain comparable complexity bounds to the ones obtained by previous
structural conditions tailored for efficient evaluation of semiring aggregate
queries, enumeration algorithms of conjunctive queries, and tractability of
counting answers to conjunctive queries.
  Project-connex tree decompositions are defined as the natural extension of
the known notion of 'free-connex' decompositions. They allow for a unified,
simple and intuitive algorithmic manipulation for evaluation of aggregate
queries and explain some existing tractability results on conjunctive query
enumeration, counting conjunctive query evaluation, and evaluation of semiring
aggregate queries. Using this measure we also recover results relating
tractable classes of counting conjunctive queries and bounded free-connex
tree-width, or the constant-time delay enumeration of semiring aggregate
queries over bounded project-connex classes. We further show that
project-connex tree decompositions can be obtained via algorithms for computing
classical tree decompositions.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [161] [SEER: Semantic Enhancement and Emotional Reasoning Network for Multimodal Fake News Detection](https://arxiv.org/abs/2507.13415)
*Peican Zhu,Yubo Jing,Le Cheng,Bin Chen,Xiaodong Cui,Lianwei Wu,Keke Tang*

Main category: cs.MM

TL;DR: 提出了一种结合语义增强和情感推理的多模态假新闻检测网络SEER，通过生成图像摘要和利用大模型增强语义，同时优化情感特征以提高检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了大模型的语义增强效果和新闻的情感特征，而假新闻更倾向于包含负面情绪。

Method: 提出SEER网络，包括生成图像摘要进行语义理解、利用大模型增强语义，以及设计情感推理模块优化情感特征。

Result: 在两个真实数据集上的实验表明，SEER优于现有基线方法。

Conclusion: SEER通过语义增强和情感推理显著提升了多模态假新闻检测的性能。

Abstract: Previous studies on multimodal fake news detection mainly focus on the
alignment and integration of cross-modal features, as well as the application
of text-image consistency. However, they overlook the semantic enhancement
effects of large multimodal models and pay little attention to the emotional
features of news. In addition, people find that fake news is more inclined to
contain negative emotions than real ones. Therefore, we propose a novel
Semantic Enhancement and Emotional Reasoning (SEER) Network for multimodal fake
news detection. We generate summarized captions for image semantic
understanding and utilize the products of large multimodal models for semantic
enhancement. Inspired by the perceived relationship between news authenticity
and emotional tendencies, we propose an expert emotional reasoning module that
simulates real-life scenarios to optimize emotional features and infer the
authenticity of news. Extensive experiments on two real-world datasets
demonstrate the superiority of our SEER over state-of-the-art baselines.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [162] [Faster Multi-Source Reachability and Approximate Distances via Shortcuts, Hopsets and Matrix Multiplication](https://arxiv.org/abs/2507.13470)
*Michael Elkin,Chhaya Trehan*

Main category: cs.DS

TL;DR: 论文提出了一种改进的集中式和并行算法，用于解决有向图中的$S \times V$可达性问题，并扩展到近似距离计算。


<details>
  <summary>Details</summary>
Motivation: 解决现有算法在计算$S \times V$可达性问题时的时间复杂度较高的问题，尤其是在特定参数范围内。

Method: 利用Kogan和Parter的快捷构造，提出了一种新的集中式算法，并改进了Cohen的并行算法，适用于具有小递归分隔符或树宽限制的图。

Result: 新算法在特定参数范围内优于现有算法，时间复杂度和工作复杂度均有所降低。

Conclusion: 论文提出的算法在理论和实际应用中均具有显著优势，并扩展到了近似距离计算。

Abstract: Given an $n$-vertex $m$-edge digraph $G = (V,E)$ and a subset $S \subseteq V$
of $|S| = n^{\sigma}$ (for some $0 \le \sigma \le 1$) designated sources, the
$S \times V$ reachability problem is to compute the sets $\mathcal V_s$ of
vertices reachable from $s$, for every $s \in S$. Naive centralized algorithms
run BFS/DFS from each source in $O(m \cdot n^{\sigma})$ time or compute $G$'s
transitive closure in $\hat O(n^{\omega})$ time, where $\omega \le
2.371552\ldots$ is the matrix multiplication exponent. Thus, the best known
bound is $\hat O(n^{\min \{ 2 + \sigma, \omega\}})$. Leveraging shortcut
constructions by Kogan and Parter [SODA 2022, ICALP 2022], we develop a
centralized algorithm with running time $\hat O(n^{1 + \frac{2}{3}
\omega(\sigma)})$, where $\omega(\sigma)$ is the rectangular matrix
multiplication exponent. Using current estimates on $\omega(\sigma)$, our
exponent improves upon $\min \{2 + \sigma, \omega \}$ for $\tilde \sigma \leq
\sigma \leq 0.53$, where $1/3 < \tilde \sigma < 0.3336$ is a universal
constant.
  In a classical result, Cohen [Journal of Algorithms, 1996] devised parallel
algorithms for $S \times V$ reachability on graphs admitting balanced recursive
separators of size $n^{\rho}$ for $\rho < 1$, requiring polylogarithmic time
and work $n^{\max \{\omega \rho, 2\rho + \sigma \} + o(1)}$. We significantly
improve, extend, and generalize Cohen's result. First, our parallel algorithm
for graphs with small recursive separators has lower work complexity than
Cohen's in boraod paramater ranges. Second, we generalize our algorithm to
graphs of treewidth at most $n^{\rho}$ ($\rho < 1$) and provide a centralized
algorithm that outperforms existing bounds for $S \times V$ reachability on
such graphs. We also do this for some other graph familes with small
separators. Finally, we extend these results to $(1 + \epsilon)$-approximate
distance computation.

</details>


### [163] [Strassen $2\times2$ Matrix Multiplication from a 3-dimensional Volume Form](https://arxiv.org/abs/2507.13510)
*Benoit Jacob*

Main category: cs.DS

TL;DR: Strassen的2×2矩阵乘法算法源于2×2矩阵除以恒等矩阵倍数的3维商空间上的体积形式。


<details>
  <summary>Details</summary>
Motivation: 探索矩阵乘法的高效算法，利用代数几何中的体积形式简化计算。

Method: 通过分析2×2矩阵除以恒等矩阵倍数的3维商空间，推导出Strassen算法。

Result: 提出了一种高效的2×2矩阵乘法算法。

Conclusion: Strassen算法展示了代数几何在优化计算问题中的潜力。

Abstract: The Strassen $2\times2$ matrix multiplication algorithm arises from the
volume form on the 3-dimensional quotient space of the $2\times 2$ matrices by
the multiples of identity.

</details>


### [164] [Combinatorics of Palindromes](https://arxiv.org/abs/2507.13671)
*Michael Itzhaki*

Main category: cs.DS

TL;DR: 研究了Manacher数组的结构和重建复杂性，提出了组合下界、图论框架，并分析了重建算法，解决了开放问题。


<details>
  <summary>Details</summary>
Motivation: 深入理解Manacher数组的组合性质及其在字符串重建中的应用。

Method: 1. 建立组合下界；2. 引入图论框架；3. 分析重建算法。

Result: 证明了组合下界，提出了图论框架，算法实现了最小字母表大小。

Conclusion: 推进了对Manacher数组的理解，为字符串重建提供了新方向。

Abstract: We investigate the structure and reconstruction complexity of Manacher
arrays. First, we establish a combinatorial lower bound, proving that the
number of rooted tandem repeat trees with $n+1$ genes exceeds the number of
distinct Manacher arrays of length $n$. Second, we introduce a graph-theoretic
framework that associates a graph to each Manacher array, where every proper
vertex coloring yields a string consistent with the array. Finally, we analyze
a reconstruction algorithm by I et al. (SPIRE 2010), showing that it
simultaneously achieves a globally minimal alphabet size, uses at most
$\log_2(n{-}1) + 2$ distinct symbols, and can be adapted to produce
reconstructions over arbitrary alphabets when possible. Our results also
resolve an open problem posed by the original authors. Together, these findings
advance the combinatorial understanding of Manacher arrays and open new
directions for string reconstruction under structural constraints.

</details>


### [165] [Tight Bounds for Answering Adaptively Chosen Concentrated Queries](https://arxiv.org/abs/2507.13700)
*Emma Rapoport,Edith Cohen,Uri Stemmer*

Main category: cs.DS

TL;DR: 论文分析了在自适应数据分析中，当数据集样本存在相关性时，集中查询框架的局限性，并证明了在当前框架下效用差距的必然性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在样本相关情况下自适应数据分析的挑战，尤其是集中查询框架的局限性。

Method: 通过理论证明和简化已知算法，验证了集中查询框架在自适应设置中的效用差距。

Result: 证明了在当前框架下，效用差距是必然的，并提出了匹配不可能性结果的简化算法。

Conclusion: 结论指出集中查询框架在自适应设置中支持查询数量的限制是固有的，并提供了简化算法作为解决方案。

Abstract: Most work on adaptive data analysis assumes that samples in the dataset are
independent. When correlations are allowed, even the non-adaptive setting can
become intractable, unless some structural constraints are imposed. To address
this, Bassily and Freund [2016] introduced the elegant framework of
concentrated queries, which requires the analyst to restrict itself to queries
that are concentrated around their expected value. While this assumption makes
the problem trivial in the non-adaptive setting, in the adaptive setting it
remains quite challenging. In fact, all known algorithms in this framework
support significantly fewer queries than in the independent case: At most
$O(n)$ queries for a sample of size $n$, compared to $O(n^2)$ in the
independent setting.
  In this work, we prove that this utility gap is inherent under the current
formulation of the concentrated queries framework, assuming some natural
conditions on the algorithm. Additionally, we present a simplified version of
the best-known algorithms that match our impossibility result.

</details>


### [166] [Improved girth approximation in weighted undirected graphs](https://arxiv.org/abs/2507.13869)
*Avi Kadria,Liam Roditty,Aaron Sidford,Virginia Vassilevska Williams,Uri Zwick*

Main category: cs.DS

TL;DR: 提出了一种在加权无向图中快速找到长度不超过$\frac{4k}{3}g$的循环的算法，时间复杂度和性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决加权无向图中高效寻找短循环的问题，改进现有算法的性能和适用范围。

Method: 设计了一种时间复杂度为$O(kn^{1+1/k}\log{n} + m(k+\log{n}))$的算法，适用于任意输入整数$k \\geq 1$。

Result: 算法在加权图中找到长度不超过$\frac{4k}{3}g$的循环，性能优于现有方法。

Conclusion: 该算法在加权图中显著提升了寻找短循环的效率，为相关领域提供了新的工具。

Abstract: Let $G = (V,E,\ell)$ be a $n$-node $m$-edge weighted undirected graph, where
$\ell: E \rightarrow (0,\infty)$ is a real \emph{length} function defined on
its edges, and let $g$ denote the girth of $G$, i.e., the length of its
shortest cycle. We present an algorithm that, for any input, integer $k \geq
1$, in $O(kn^{1+1/k}\log{n} + m(k+\log{n}))$ expected time finds a cycle of
length at most $\frac{4k}{3}g$. This algorithm nearly matches a
$O(n^{1+1/k}\log{n})$-time algorithm of \cite{KadriaRSWZ22} which applied to
unweighted graphs of girth $3$. For weighted graphs, this result also improves
upon the previous state-of-the-art algorithm that in $O((n^{1+1/k}\log n+m)\log
(nM))$ time, where $\ell: E \rightarrow [1, M]$ is an integral length function,
finds a cycle of length at most $2kg$~\cite{KadriaRSWZ22}. For $k=1$ this
result improves upon the result of Roditty and Tov~\cite{RodittyT13}.

</details>


### [167] [Quantum Pattern Matching with Wildcards](https://arxiv.org/abs/2507.13885)
*Masoud Seddighin,Saeed Seddighin*

Main category: cs.DS

TL;DR: 本文提出了一种量子算法，用于解决带有通配符的模式匹配问题，时间复杂度为$\tilde O(\sqrt{n}\sqrt{k})$，当通配符数量$k$满足$k \\geq \\sqrt{n}$时，算法能在亚线性时间内运行。


<details>
  <summary>Details</summary>
Motivation: 经典的模式匹配问题及其通配符变体已有高效算法，但量子计算领域是否能在亚线性时间内解决通配符问题仍是一个开放性问题。本文旨在填补这一空白。

Method: 利用量子算法，结合通配符数量$k$的限制，设计了一种时间复杂度为$\tilde O(\sqrt{n}\sqrt{k})$的解决方案。

Result: 当通配符数量$k$满足$k \\geq \\sqrt{n}$时，算法能在亚线性时间内运行。

Conclusion: 本文证明了在量子计算框架下，带有通配符的模式匹配问题可以在亚线性时间内解决，前提是通配符数量为亚线性。

Abstract: Pattern matching is one of the fundamental problems in Computer Science. Both
the classic version of the problem as well as the more sophisticated version
where wildcards can also appear in the input can be solved in almost linear
time $\tilde O(n)$ using the KMP algorithm and Fast Fourier Transform,
respectively. In 2000, Ramesh and Vinay~\cite{ramesh2003string} give a quantum
algorithm that solves classic pattern matching in sublinear time and asked
whether the wildcard problem can also be solved in sublinear time? In this
work, we give a quantum algorithm for pattern matching with wildcards that runs
in time $\tilde O(\sqrt{n}\sqrt{k})$ when the number of wildcards is bounded by
$k$ for $k \geq \sqrt{n}$. This leads to an algorithm that runs in sublinear
time as long as the number of wildcards is sublinear.

</details>


### [168] [Optimal antimatroid sorting](https://arxiv.org/abs/2507.13994)
*Benjamin Aram Berendsohn*

Main category: cs.DS

TL;DR: 论文研究了受限排序问题，其中可能的全序集合T以某种压缩形式给出。通过推广拓扑堆排序算法，适用于更广泛的受限排序问题，特别是当T对应于给定的反拟阵时。


<details>
  <summary>Details</summary>
Motivation: 经典比较排序问题要求通过比较找到元素的全序，而受限版本中，给定一个可能的全序集合T作为提示。研究目的是扩展拓扑堆排序算法，以解决更广泛的受限排序问题。

Method: 推广拓扑堆排序算法，使其适用于T对应于给定反拟阵的情况。

Result: 获得了针对多种受限排序问题的最优算法，包括单调优先公式、弦图的完美消除序以及连通有根图的顶点搜索序。

Conclusion: 通过推广拓扑堆排序算法，成功解决了更广泛的受限排序问题，为多种具体场景提供了最优算法。

Abstract: The classical comparison-based sorting problem asks us to find the underlying
total order of a given set of elements, where we can only access the elements
via comparisons. In this paper, we study a restricted version, where, as a
hint, a set $T$ of possible total orders is given, usually in some compressed
form.
  Recently, an algorithm called topological heapsort with optimal running time
was found for the case where $T$ is the set of topological orderings of a given
directed acyclic graph, or, equivalently, $T$ is the set of linear extensions
of a given partial order [Haeupler et al. 2024]. We show that a simple
generalization of topological heapsort is applicable to a much broader class of
restricted sorting problems, where $T$ corresponds to a given antimatroid.
  As a consequence, we obtain optimal algorithms for the following restricted
sorting problems, where the allowed total orders are restricted by: a given set
of monotone precedence formulas; the perfect elimination orders of a given
chordal graph; or the possible vertex search orders of a given connected rooted
graph.

</details>


### [169] [Sparse Navigable Graphs for Nearest Neighbor Search: Algorithms and Hardness](https://arxiv.org/abs/2507.14060)
*Sanjeev Khanna,Ashwin Padaki,Erik Waingarten*

Main category: cs.DS

TL;DR: 研究了稀疏α-导航图的近似算法和计算障碍，提出了基于Set Cover问题的近似算法，并证明了其NP难度。


<details>
  <summary>Details</summary>
Motivation: 解决图基最近邻搜索中稀疏α-导航图的高效构建问题，优化稀疏性目标（最大出度和总大小）。

Method: 通过等价于Set Cover问题，设计了O(ln n)-近似算法，包括基于快速矩阵乘法的双准则算法。

Result: 证明了DiskANN方法在某些情况下稀疏性可能极差，并提出了更高效的近似算法。

Conclusion: 在OPT为O(n)时，提出的算法接近最优，且任何o(n)-近似算法需要Ω(n²)距离计算。

Abstract: We initiate the study of approximation algorithms and computational barriers
for constructing sparse $\alpha$-navigable graphs [IX23, DGM+24], a core
primitive underlying recent advances in graph-based nearest neighbor search.
Given an $n$-point dataset $P$ with an associated metric $\mathsf{d}$ and a
parameter $\alpha \geq 1$, the goal is to efficiently build the sparsest graph
$G=(P, E)$ that is $\alpha$-navigable: for every distinct $s, t \in P$, there
exists an edge $(s, u) \in E$ with $\mathsf{d}(u, t) < \mathsf{d}(s,
t)/\alpha$. We consider two natural sparsity objectives: minimizing the maximum
out-degree and minimizing the total size.
  We first show a strong negative result: the slow-preprocessing version of
DiskANN (analyzed in [IX23] for low-doubling metrics) can yield solutions whose
sparsity is $\widetilde{\Omega}(n)$ times larger than optimal, even on
Euclidean instances. We then show a tight approximation-preserving equivalence
between the Sparsest Navigable Graph problem and the classic Set Cover problem,
obtaining an $O(n^3)$-time $(\ln n + 1)$-approximation algorithm, as well as
establishing NP-hardness of achieving an $o(\ln n)$-approximation. Building on
this equivalence, we develop faster $O(\ln n)$-approximation algorithms. The
first runs in $\widetilde{O}(n \cdot \mathrm{OPT})$ time and is thus much
faster when the optimal solution is sparse. The second, based on fast matrix
multiplication, is a bicriteria algorithm that computes an $O(\ln
n)$-approximation to the sparsest $2\alpha$-navigable graph, running in
$\widetilde{O}(n^{\omega})$ time.
  Finally, we complement our upper bounds with a query complexity lower bound,
showing that any $o(n)$-approximation requires examining $\Omega(n^2)$
distances. This result shows that in the regime where $\mathrm{OPT} =
\widetilde{O}(n)$, our $\widetilde{O}(n \cdot \mathrm{OPT})$-time algorithm is
essentially best possible.

</details>


### [170] [An Efficient Massively Parallel Constant-Factor Approximation Algorithm for the $k$-Means Problem](https://arxiv.org/abs/2507.14089)
*Vincent Cohen-Addad,Fabian Kuhn,Zahra Parsaeian*

Main category: cs.DS

TL;DR: 本文提出了一种高效的并行近似算法，用于解决$k$-means问题，在MPC模型中实现了$o(\log n)$轮次的常数因子近似。


<details>
  <summary>Details</summary>
Motivation: 解决$k$-means问题在大规模并行计算（MPC）模型中的高效近似需求，填补现有方法在轮次复杂度上的不足。

Method: 基于Jain和Vazirani的框架，通过改进设施选址问题的近似算法，并利用LMP性质将其转化为$k$-means近似。

Result: 算法在$O(\log\log n \cdot \log\log\log n)$轮次内实现常数因子近似，内存使用接近线性。

Conclusion: 该算法是首个在MPC模型中实现$o(\log n)$轮次的$k$-means常数因子近似，具有理论和实际意义。

Abstract: In this paper, we present an efficient massively parallel approximation
algorithm for the $k$-means problem. Specifically, we provide an MPC algorithm
that computes a constant-factor approximation to an arbitrary $k$-means
instance in $O(\log\log n \cdot \log\log\log n)$ rounds. The algorithm uses
$O(n^\sigma)$ bits of memory per machine, where $\sigma > 0$ is a constant that
can be made arbitrarily small. The global memory usage is
$O(n^{1+\varepsilon})$ bits for an arbitrarily small constant $\varepsilon >
0$, and is thus only slightly superlinear. Recently, Czumaj, Gao, Jiang,
Krauthgamer, and Vesel\'{y} showed that a constant-factor bicriteria
approximation can be computed in $O(1)$ rounds in the MPC model. However, our
algorithm is the first constant-factor approximation for the general $k$-means
problem that runs in $o(\log n)$ rounds in the MPC model.
  Our approach builds upon the foundational framework of Jain and Vazirani. The
core component of our algorithm is a constant-factor approximation for the
related facility location problem. While such an approximation was already
achieved in constant time in the work of Czumaj et al.\ mentioned above, our
version additionally satisfies the so-called Lagrangian Multiplier Preserving
(LMP) property. This property enables the transformation of a facility location
approximation into a comparably good $k$-means approximation.

</details>


### [171] [Weighted Matching in a Poly-Streaming Model](https://arxiv.org/abs/2507.14114)
*Ahammed Ullah,S. M. Ferdous,Alex Pothen*

Main category: cs.DS

TL;DR: 论文提出了一种多流并行计算模型（poly-streaming model），设计了一种单遍算法用于近似最大权重匹配问题，并在共享内存并行环境中验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 传统流式计算模型在处理大规模数据时存在性能瓶颈，需要一种更高效的并行计算模型来提升处理速度和资源利用率。

Method: 提出多流并行计算模型，设计单遍算法近似最大权重匹配问题，支持共享内存并行计算和分层架构。

Result: 算法在共享内存系统中表现出色，处理万亿级边图时显著提升速度和内存效率，匹配权重远超理论保证。

Conclusion: 多流并行计算模型及其算法在大规模数据处理中具有显著优势，适用于高效并行计算场景。

Abstract: We introduce the poly-streaming model, a generalization of streaming models
of computation in which $k$ processors process $k$ data streams containing a
total of $N$ items. The algorithm is allowed $O\left(f(k)\cdot M_1\right)$
space, where $M_1$ is either $o\left(N\right)$ or the space bound for a
sequential streaming algorithm. Processors may communicate as needed.
Algorithms are assessed by the number of passes, per-item processing time,
total runtime, space usage, communication cost, and solution quality.
  We design a single-pass algorithm in this model for approximating the maximum
weight matching (MWM) problem. Given $k$ edge streams and a parameter
$\varepsilon > 0$, the algorithm computes a
$\left(2+\epsilon\right)$-approximate MWM. We analyze its performance in a
shared-memory parallel setting: for any constant $\varepsilon > 0$, it runs in
time $\widetilde{O}\left(L_{\max}+n\right)$, where $n$ is the number of
vertices and $L_{\max}$ is the maximum stream length. It supports
$O\left(1\right)$ per-edge processing time using $\widetilde{O}\left(k\cdot
n\right)$ space. We further generalize the design to hierarchical
architectures, in which $k$ processors are partitioned into $r$ groups, each
with its own shared local memory. The total intergroup communication is
$\widetilde{O}\left(r \cdot n\right)$ bits, while all other performance
guarantees are preserved.
  We evaluate the algorithm on a shared-memory system using graphs with
trillions of edges. It achieves substantial speedups as $k$ increases and
produces matchings with weights significantly exceeding the theoretical
guarantee. On our largest test graph, it reduces runtime by nearly two orders
of magnitude and memory usage by five orders of magnitude compared to an
offline algorithm.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [172] [Round-Preserving Asymptotic Compression of Prior-Free Interactive Protocols](https://arxiv.org/abs/2507.13464)
*Gurleen Padda,Dave Touchette*

Main category: cs.IT

TL;DR: 本文研究了无先验交互式通信中通信复杂度与信息复杂度的关系，改进了Braverman的结果，实现了轮次保留和有限共享随机性。


<details>
  <summary>Details</summary>
Motivation: 探索通信复杂度与信息复杂度的关系，并提供更自然的证明方法。

Method: 通过估计输入的联合类型或经验分布，改进无先验反向香农定理协议。

Result: 实现了轮次保留和有限共享随机性，改进了现有结果。

Conclusion: 研究为交互式通信中的复杂度关系提供了更优的解决方案。

Abstract: There is a close relationship between the communication complexity and
information complexity of communication problems, as demonstrated by results
such as Shannon's noiseless source coding theorem, and the Slepian-Wolf
theorem. Here, we study this relationship in the prior-free and interactive
setting, where we provide an alternate proof for the result of Braverman [SIAM
Review, vol. 59, no. 4, 2017], that the amortized communication complexity of
simulating a prior-free interactive communication protocol, is equal to its
prior-free information cost. While this is a known result, our approach
addresses the need for a more natural proof of it. We also improve on the
result by achieving round preservation, and using a bounded quantity of shared
randomness. We do this by showing that the communicating parties can produce a
reliable estimate of the joint type, or empirical distribution, of their
inputs. This estimate is then used in our protocol for the prior-free reverse
Shannon theorem with side information at the receiver. These results are then
generalized to the interactive setting to obtain our main result.

</details>


### [173] [Loss-Complexity Landscape and Model Structure Functions](https://arxiv.org/abs/2507.13543)
*Alexander Kolpakov*

Main category: cs.IT

TL;DR: 本文提出了一个框架，用于对偶化Kolmogorov结构函数，并引入统计力学的类比，证明了Legendre-Fenchel对偶性，并通过实验验证了理论预测。


<details>
  <summary>Details</summary>
Motivation: 研究信息论构造与统计力学之间的数学类比，以更好地理解模型复杂度与泛化能力的关系。

Method: 开发了对偶化Kolmogorov结构函数的框架，引入分区函数和自由能泛函，证明了Legendre-Fenchel对偶性，并通过线性与树回归模型进行实验验证。

Result: 理论预测得到验证，模型复杂度与泛化能力的关系在实验中明确展现。

Conclusion: 该框架为理解模型复杂度与泛化能力的关系提供了新的视角，并验证了信息论与统计力学的类比。

Abstract: We develop a framework for dualizing the Kolmogorov structure function
$h_x(\alpha)$, which then allows using computable complexity proxies. We
establish a mathematical analogy between information-theoretic constructs and
statistical mechanics, introducing a suitable partition function and free
energy functional. We explicitly prove the Legendre-Fenchel duality between the
structure function and free energy, showing detailed balance of the Metropolis
kernel, and interpret acceptance probabilities as information-theoretic
scattering amplitudes. A susceptibility-like variance of model complexity is
shown to peak precisely at loss-complexity trade-offs interpreted as phase
transitions. Practical experiments with linear and tree-based regression models
verify these theoretical predictions, explicitly demonstrating the interplay
between the model complexity, generalization, and overfitting threshold.

</details>


### [174] [Efficient Decoding of Double-circulant and Wozencraft Codes from Square-root Errors](https://arxiv.org/abs/2507.13548)
*Oren Dubin,Noam Oz,Noga Ron-Zewi*

Main category: cs.IT

TL;DR: 提出了两种双循环码的高效解码算法，并讨论了其与Wozencraft码的转换关系。


<details>
  <summary>Details</summary>
Motivation: 研究双循环码的解码效率及其与Wozencraft码的转换，以提升纠错码的实用性。

Method: 基于Sidon集和循环码的双循环码解码算法，并分析其与Wozencraft码的转换。

Result: 成功构造了可高效解码的Wozencraft码，并指出了基于循环码的转换限制。

Conclusion: 双循环码的解码算法和转换关系为纠错码设计提供了新的思路，但部分方法存在局限性。

Abstract: We present efficient decoding algorithms from square-root errors for two
known families of double-circulant codes: A construction based on Sidon sets
(Bhargava, Taveres, and Shiva, \emph{IEEE IT 74}; Calderbank, \emph{IEEE IT
83}; Guruswami and Li, \emph{IEEE IT 2025}), and a construction based on cyclic
codes (Chen, Peterson, and Weldon, \emph{Information and Control 1969}). We
further observe that the work of Guruswami and Li implicitly gives a
transformation from double-circulant codes of certain block lengths to
Wozencraft codes which preserves that distance of the codes, and we show that
this transformation also preserves efficiency of decoding. By instantiating
this transformation with the first family of double-circulant codes based on
Sidon sets, we obtain an explicit construction of a Wozencraft code that is
efficiently decodable from square-root errors. We also discuss limitations on
instantiating this transformation with the second family of double-circulant
codes based on cyclic codes.

</details>


### [175] [Density Evolution Analysis of Sparse-Block IDMA](https://arxiv.org/abs/2507.13689)
*Jean-Francois Chamberland,Gianluigi Liva,Krishna Narayanan*

Main category: cs.IT

TL;DR: SB-IDMA是一种新的无源多址协议，旨在提升5G新无线电标准的性能，本文通过密度进化分析其接收器性能。


<details>
  <summary>Details</summary>
Motivation: 改进3GPP 5G新无线电标准中的无授权两步随机接入传输协议性能。

Method: 采用密度进化分析SB-IDMA的连续干扰消除接收器。

Result: 提供了SB-IDMA性能的理论特征。

Conclusion: SB-IDMA及其接收器分析为5G标准提供了理论支持。

Abstract: Sparse block interleaver division multiple access (SB-IDMA) is a recently
introduced unsourced multiple access protocol that aims to improve the
performance of the grant-free two-step random access transmission protocol of
the 3GPP 5G New Radio standard. We introduced a density evolution analysis of
the successive interference cancellation receiver of SB-IDMA, providing a
theoretical characterization of its performance.

</details>


### [176] [Asymptotically Optimal Codes Correcting One Substring Edit](https://arxiv.org/abs/2507.13808)
*Yuting Li,Yuanyuan Tang,Hao Lou,Ryan Gabrys,Farzad Farnoud*

Main category: cs.IT

TL;DR: 本文研究了子串编辑错误的纠正问题，提出了一种冗余度为log n + O(log log n)的编码方法，实现了渐近最优。


<details>
  <summary>Details</summary>
Motivation: 子串编辑错误（如插入、删除和替换）在局部窗口内发生，现有方法的冗余度至少为log n + k。本文旨在降低冗余度，提高效率。

Method: 构建了一种新的编码方法，通过优化设计，将冗余度从log n + k降低到log n + O(log log n)。

Result: 提出的编码方法实现了渐近最优的冗余度，显著优于现有方法。

Conclusion: 本文的方法在纠正子串编辑错误方面具有高效性和最优性，为相关领域提供了新的解决方案。

Abstract: The substring edit error is the operation of replacing a substring $u$ of $x$
with another string $v$, where the lengths of $u$ and $v$ are bounded by a
given constant $k$. It encompasses localized insertions, deletions, and
substitutions within a window. Codes correcting one substring edit have
redundancy at least $\log n+k$. In this paper, we construct codes correcting
one substring edit with redundancy $\log n+O(\log \log n)$, which is
asymptotically optimal.

</details>


### [177] [Secretive Hotplug Coded Caching](https://arxiv.org/abs/2507.13961)
*Mallikharjuna Chinnapadamala,Charul Rajput,B. Sundar Rajan*

Main category: cs.IT

TL;DR: 本文研究了热插拔编码缓存模型中的保密性问题，提出了两种针对已知HpPDA类的保密方案，并在某些内存区域中优于基线方案。


<details>
  <summary>Details</summary>
Motivation: 在热插拔编码缓存系统中，用户可能在交付阶段离线，且需要确保用户无法从缓存内容中获取任何文件信息，同时活跃用户不应从缓存或服务器传输中获取非需求文件的信息。

Method: 提出了两种针对已知HpPDA类的保密方案，并与基线方案（基于经典编码缓存PDA的保密方案）进行了比较。

Result: 数值结果表明，在某些内存区域中，提出的方案优于基线方案。

Conclusion: 本文提出的保密方案在热插拔编码缓存系统中表现更优，特别是在特定内存条件下。

Abstract: In this work, we consider a coded caching model called \textit{hotplug coded
caching}, in which some users are offline during the delivery phase. The
concept of Hotplug Placement Delivery Arrays (HpPDAs) for hotplug coded caching
systems has been introduced in the literature, and two classes of HpPDAs are
known. In this paper, we consider a secrecy constraint in hotplug coded caching
setup, where users should not learn anything about any file from their cache
content, and active users should not gain any information about files other
than their demanded file from either their cache content or the server
transmissions. We propose two secretive schemes for the two classes of HpPDAs
and compare them with a baseline scheme, which is a secretive scheme using PDAs
for the classical coded caching setup and can be trivially adapted for the
hotplug coded caching setup. We numerically show that our schemes outperform
the baseline scheme in certain memory regions.

</details>


### [178] [Bounds and Constructions of High-Memory Spatially-Coupled Codes](https://arxiv.org/abs/2507.14064)
*Lei Huang*

Main category: cs.IT

TL;DR: 本文应用Clique Lovász局部引理，为去除空间耦合（SC）码中影响解码性能的有害组合结构提供了内存和提升度的充分条件，并提出了一种基于Moser-Tardos算法的构造性方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在消除SC码中的有害组合结构，以提升解码性能。

Method: 应用Clique Lovász局部引理，提出基于Moser-Tardos算法的构造性方法，并分析有害结构间的依赖关系。

Result: 给出了去除有害结构后剩余结构概率变化的上界，例如去除4-cycles会使6-cycles活跃概率最多增加e^(8/3)倍。

Conclusion: 通过理论分析和构造性方法，有效减少了SC码中的有害结构，提升了其解码性能。

Abstract: In this paper, we apply the Clique Lov\'asz Local Lemma to provide sufficient
conditions on memory and lifting degree for removing certain harmful
combinatorial structures in spatially-coupled (SC) codes that negatively impact
decoding performance. Additionally, we present, for the first time, a
constructive algorithm based on the Moser-Tardos algorithm that ensures
predictable performance. Furthermore, leveraging the properties of
LLL-distribution and M-T-distribution, we establish the dependencies among the
harmful structures during the construction process. We provide upper bounds on
the probability change of remaining harmful structures after eliminating some
of them. In particular, the elimination of 4-cycles increases the probability
of 6-cycles becoming active by at most a factor of $e^{8/3}$.

</details>


### [179] [Error Correcting Codes for Segmented Burst-Deletion Channels](https://arxiv.org/abs/2507.14070)
*Yajuan Liu,Tolga M. Duman*

Main category: cs.IT

TL;DR: 研究了分段突发删除信道，开发了针对任意字母表的纠错码，冗余度为O(log b)。


<details>
  <summary>Details</summary>
Motivation: 现实中的同步错误通常以突发形式出现，因此需要研究分段突发删除信道。

Method: 利用现有的一突发删除码对每个分段进行编码，并添加约束以帮助解码器识别分段边界。

Result: 实现了冗余度为O(log b)的纠错码。

Conclusion: 该方法有效解决了分段突发删除信道的纠错问题。

Abstract: We study segmented burst-deletion channels motivated by the observation that
synchronization errors commonly occur in a bursty manner in real-world
settings. In this channel model, transmitted sequences are implicitly divided
into non-overlapping segments, each of which may experience at most one burst
of deletions. In this paper, we develop error correction codes for segmented
burst-deletion channels over arbitrary alphabets under the assumption that each
segment may contain only one burst of t-deletions. The main idea is to encode
the input subsequence corresponding to each segment using existing one-burst
deletion codes, with additional constraints that enable the decoder to identify
segment boundaries during the decoding process from the received sequence. The
resulting codes achieve redundancy that scales as O(log b), where b is the
length of each segment.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [180] [Resource-Splitting Games with Tullock-Based Lossy Contests](https://arxiv.org/abs/2507.13853)
*Marko Maljkovic,Gustav Nilsson,Nikolas Geroliminis*

Main category: cs.GT

TL;DR: 本文提出了一种新颖的多阶段资源分配博弈框架，用于模拟现实世界中供需平衡和资源投入回报的场景，并研究了均衡策略及其计算方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中，资源分配的盈利性取决于供需平衡，且高投入带来高回报。本文旨在建模此类场景，并解决均衡策略的存在性和计算问题。

Method: 提出了一个结合利润损失的多阶段博弈框架，采用加权公平比例分配，研究了集中式和纳什均衡策略，并提出了一种半分散式迭代方法计算均衡。

Result: 证明了均衡的存在性和唯一性条件，框架可推广至现有模型（如Receding Horizon和Blotto博弈），并提供了Blotto博弈中均衡的半解析计算方法。

Conclusion: 通过智能交通的数值案例验证了模型的实用性和适用性，展示了其在现实问题中的潜力。

Abstract: This paper introduces a novel class of multi-stage resource allocation games
that model real-world scenarios in which profitability depends on the balance
between supply and demand, and where higher resource investment leads to
greater returns. Our proposed framework, which incorporates the notion of
profit loss due to insufficient player participation, gives rise to a
Tullock-like functional form of the stage payoff structure when weighted fair
proportional resource allocation is applied. We explore both centralized and
Nash equilibrium strategies, establish sufficient conditions for their
existence and uniqueness, and provide an iterative, semi-decentralized method
to compute the Nash equilibrium in games with arbitrarily many players.
Additionally, we demonstrate that the framework generalizes instances of
several existing models, including Receding Horizon and Blotto games, and
present a semi-analytical method for computing the unique Nash equilibrium
within the Blotto setup. Our findings are validated through a numerical case
study in smart mobility, highlighting the practical relevance and applicability
of the proposed model.

</details>


### [181] [Online MMS Allocation for Chores](https://arxiv.org/abs/2507.14039)
*Jiaxin Song,Biaoshuai Tao,Wenqian Wang,Yuhao Zhang*

Main category: cs.GT

TL;DR: 论文研究了在线不可分割杂务的公平分配问题，填补了现有研究的理论空白，提出了负面和正面的结果。


<details>
  <summary>Details</summary>
Motivation: 现有研究在在线分配不可分割杂务时存在理论空白，尤其是在一般情况下的公平性保证不足。

Method: 通过理论证明和算法设计，研究了在线分配问题，提出了负面结果（不可能性定理）和正面结果（新算法）。

Result: 证明了对于任何固定的n和ε，无法保证(n-ε)-MMS分配；同时提出了一个适用于一般情况的在线算法，提供合理的公平性保证。

Conclusion: 论文填补了理论空白，提出了负面和正面的结果，为在线公平分配问题提供了新的见解。

Abstract: We study the problem of fair division of indivisible chores among $n$ agents
in an online setting, where items arrive sequentially and must be allocated
irrevocably upon arrival. The goal is to produce an $\alpha$-MMS allocation at
the end. Several recent works have investigated this model, but have only
succeeded in obtaining non-trivial algorithms under restrictive assumptions,
such as the two-agent bi-valued special case (Wang and Wei, 2025), or by
assuming knowledge of the total disutility of each agent (Zhou, Bai, and Wu,
2023). For the general case, the trivial $n$-MMS guarantee remains the best
known, while the strongest lower bound is still only $2$.
  We close this gap on the negative side by proving that for any fixed $n$ and
$\varepsilon$, no algorithm can guarantee an $(n - \varepsilon)$-MMS
allocation. Notably, this lower bound holds precisely for every $n$, without
hiding constants in big-$O$ notation, thereby exactly matching the trivial
upper bound.
  Despite this strong impossibility result, we also present positive results.
We provide an online algorithm that applies in the general case, guaranteeing a
$\min\{n, O(k), O(\log D)\}$-MMS allocation, where $k$ is the maximum number of
distinct disutilities across all agents and $D$ is the maximum ratio between
the largest and smallest disutilities for any agent. This bound is reasonable
across a broad range of scenarios and, for example, implies that we can achieve
an $O(1)$-MMS allocation whenever $k$ is constant. Moreover, to optimize the
constant in the important personalized bi-valued case, we show that if each
agent has at most two distinct disutilities, our algorithm guarantees a $(2 +
\sqrt{3}) \approx 3.7$-MMS allocation.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [182] [DyG-RAG: Dynamic Graph Retrieval-Augmented Generation with Event-Centric Reasoning](https://arxiv.org/abs/2507.13396)
*Qingyun Sun,Jiaqi Yuan,Shan He,Xiao Guan,Haonan Yuan,Xingcheng Fu,Jianxin Li,Philip S. Yu*

Main category: cs.IR

TL;DR: DyG-RAG是一种动态图检索增强生成框架，专注于解决传统Graph RAG在时间推理上的不足，通过动态事件单元和事件图实现时间敏感的检索与生成。


<details>
  <summary>Details</summary>
Motivation: 传统Graph RAG方法难以建模现实世界事件的时间演变和顺序，导致时间推理能力不足。

Method: DyG-RAG提出动态事件单元（DEUs）编码语义和时间信息，构建事件图以捕捉时间与因果依赖，并通过时间感知检索和时间链式思维策略生成答案。

Result: 实验表明，DyG-RAG显著提升了时间敏感问题的准确率和召回率。

Conclusion: DyG-RAG为时间感知的生成提供了更可靠的解决方案，适用于复杂时间敏感查询。

Abstract: Graph Retrieval-Augmented Generation has emerged as a powerful paradigm for
grounding large language models with external structured knowledge. However,
existing Graph RAG methods struggle with temporal reasoning, due to their
inability to model the evolving structure and order of real-world events. In
this work, we introduce DyG-RAG, a novel event-centric dynamic graph
retrieval-augmented generation framework designed to capture and reason over
temporal knowledge embedded in unstructured text. To eliminate temporal
ambiguity in traditional retrieval units, DyG-RAG proposes Dynamic Event Units
(DEUs) that explicitly encode both semantic content and precise temporal
anchors, enabling accurate and interpretable time-aware retrieval. To capture
temporal and causal dependencies across events, DyG-RAG constructs an event
graph by linking DEUs that share entities and occur close in time, supporting
efficient and meaningful multi-hop reasoning. To ensure temporally consistent
generation, DyG-RAG introduces an event timeline retrieval pipeline that
retrieves event sequences via time-aware traversal, and proposes a Time
Chain-of-Thought strategy for temporally grounded answer generation. This
unified pipeline enables DyG-RAG to retrieve coherent, temporally ordered event
sequences and to answer complex, time-sensitive queries that standard RAG
systems cannot resolve. Extensive experiments on temporal QA benchmarks
demonstrate that DyG-RAG significantly improves the accuracy and recall of
three typical types of temporal reasoning questions, paving the way for more
faithful and temporal-aware generation. DyG-RAG is available at
https://github.com/RingBDStack/DyG-RAG.

</details>


### [183] [Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based Personalized Recommendation](https://arxiv.org/abs/2507.13525)
*Genki Kusano,Kosuke Akimoto,Kunihiro Takeoka*

Main category: cs.IR

TL;DR: 论文研究了在单用户设置下，利用提示工程优化大语言模型（LLMs）的推荐任务表现，比较了23种提示类型在8个数据集和12个LLMs上的效果，发现简单提示在高性能LLMs中表现更优。


<details>
  <summary>Details</summary>
Motivation: 探索在隐私敏感或数据有限的应用中，如何通过提示工程优化LLMs的推荐任务表现，尤其是在单用户设置下。

Method: 通过大规模实验比较23种提示类型在8个公共数据集和12种LLMs上的表现，使用统计测试和线性混合效应模型评估准确性和推理成本。

Result: 对于成本效益高的LLMs，三种提示类型效果显著：指令重述、背景知识考虑和简化推理过程；高性能LLMs中简单提示表现更优且成本更低。

Conclusion: 根据准确性和成本的平衡需求，提供了选择提示和LLMs的实用建议。

Abstract: Large language models (LLMs) can perform recommendation tasks by taking
prompts written in natural language as input. Compared to traditional methods
such as collaborative filtering, LLM-based recommendation offers advantages in
handling cold-start, cross-domain, and zero-shot scenarios, as well as
supporting flexible input formats and generating explanations of user behavior.
In this paper, we focus on a single-user setting, where no information from
other users is used. This setting is practical for privacy-sensitive or
data-limited applications. In such cases, prompt engineering becomes especially
important for controlling the output generated by the LLM. We conduct a
large-scale comparison of 23 prompt types across 8 public datasets and 12 LLMs.
We use statistical tests and linear mixed-effects models to evaluate both
accuracy and inference cost. Our results show that for cost-efficient LLMs,
three types of prompts are especially effective: those that rephrase
instructions, consider background knowledge, and make the reasoning process
easier to follow. For high-performance LLMs, simple prompts often outperform
more complex ones while reducing cost. In contrast, commonly used prompting
styles in natural language processing, such as step-by-step reasoning, or the
use of reasoning models often lead to lower accuracy. Based on these findings,
we provide practical suggestions for selecting prompts and LLMs depending on
the required balance between accuracy and cost.

</details>


### [184] [IP2: Entity-Guided Interest Probing for Personalized News Recommendation](https://arxiv.org/abs/2507.13622)
*Youlin Wu,Yuanyuan Sun,Xiaokun Zhang,Haoxi Zhan,Bo Xu,Liang Yang,Hongfei Lin*

Main category: cs.IR

TL;DR: IP2方法通过分析新闻实体在扫描和标题阅读阶段的作用，提出了一种基于Transformer的新闻推荐系统，显著提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有新闻推荐方法忽视了实体在用户阅读行为中的独特作用，尤其是在扫描和标题阅读阶段。

Method: IP2方法包括：1）使用Transformer编码器聚合新闻标题中的实体；2）通过对比预训练初始化实体含义；3）双塔用户编码器捕捉标题和实体层面的兴趣；4）跨塔注意力校准标题阅读兴趣。

Result: 在两个真实数据集上的实验表明，IP2在新闻推荐任务中达到了最先进的性能。

Conclusion: IP2通过显式建模实体在阅读行为中的作用，显著提升了新闻推荐的准确性和实用性。

Abstract: News recommender systems aim to provide personalized news reading experiences
for users based on their reading history. Behavioral science studies suggest
that screen-based news reading contains three successive steps: scanning, title
reading, and then clicking. Adhering to these steps, we find that intra-news
entity interest dominates the scanning stage, while the inter-news entity
interest guides title reading and influences click decisions. Unfortunately,
current methods overlook the unique utility of entities in news recommendation.
To this end, we propose a novel method called IP2 to probe entity-guided
reading interest at both intra- and inter-news levels. At the intra-news level,
a Transformer-based entity encoder is devised to aggregate mentioned entities
in the news title into one signature entity. Then, a signature entity-title
contrastive pre-training is adopted to initialize entities with proper meanings
using the news story context, which in the meantime facilitates us to probe for
intra-news entity interest. As for the inter-news level, a dual tower user
encoder is presented to capture inter-news reading interest from both the title
meaning and entity sides. In addition to highlighting the contribution of
inter-news entity guidance, a cross-tower attention link is adopted to
calibrate title reading interest using inter-news entity interest, thus further
aligning with real-world behavior. Extensive experiments on two real-world
datasets demonstrate that our IP2 achieves state-of-the-art performance in news
recommendation.

</details>


### [185] [Point of Interest Recommendation: Pitfalls and Viable Solutions](https://arxiv.org/abs/2507.13725)
*Alejandro Bellogín,Linus W. Dietz,Francesco Ricci,Pablo Sánchez*

Main category: cs.IR

TL;DR: 本文讨论了POI推荐问题的现状和主要挑战，批判性评估了当前研究的不足，并提出了未来研究的方向。


<details>
  <summary>Details</summary>
Motivation: POI推荐对提升游客体验至关重要，但现有研究存在诸多未解决的问题，限制了其实际应用。

Method: 通过批判性评估当前研究的不足，提出改进方向，重点关注数据集、算法和评估方法。

Result: 指出了当前POI推荐研究中的关键问题，如缺乏标准化数据集、模型设计中的假设缺陷等。

Conclusion: 提出了一个结构化研究议程，为未来研究指明了方向，包括多利益相关者设计、上下文感知等。

Abstract: Point of interest (POI) recommendation can play a pivotal role in enriching
tourists' experiences by suggesting context-dependent and preference-matching
locations and activities, such as restaurants, landmarks, itineraries, and
cultural attractions. Unlike some more common recommendation domains (e.g.,
music and video), POI recommendation is inherently high-stakes: users invest
significant time, money, and effort to search, choose, and consume these
suggested POIs. Despite the numerous research works in the area, several
fundamental issues remain unresolved, hindering the real-world applicability of
the proposed approaches. In this paper, we discuss the current status of the
POI recommendation problem and the main challenges we have identified. The
first contribution of this paper is a critical assessment of the current state
of POI recommendation research and the identification of key shortcomings
across three main dimensions: datasets, algorithms, and evaluation
methodologies. We highlight persistent issues such as the lack of standardized
benchmark datasets, flawed assumptions in the problem definition and model
design, and inadequate treatment of biases in the user behavior and system
performance. The second contribution is a structured research agenda that,
starting from the identified issues, introduces important directions for future
work related to multistakeholder design, context awareness, data collection,
trustworthiness, novel interactions, and real-world evaluation.

</details>


### [186] [RAG-based Architectures for Drug Side Effect Retrieval in LLMs](https://arxiv.org/abs/2507.13822)
*Shad Nygren,Pinar Avci,Andre Daniels,Reza Rassol,Afshin Beheshti,Diego Galeano*

Main category: cs.IR

TL;DR: 论文提出两种架构（RAG和GraphRAG），将药物副作用知识整合到Llama 3 8B模型中，显著提升了药物副作用检索的准确性。


<details>
  <summary>Details</summary>
Motivation: 药物副作用是全球健康问题，现有大语言模型（LLMs）在专业领域（如药物警戒）中存在局限性，如依赖黑盒数据、易产生幻觉和缺乏领域知识。

Method: 提出Retrieval-Augmented Generation (RAG)和GraphRAG两种架构，整合药物副作用知识到Llama 3 8B模型中。

Result: 在19,520个药物副作用关联的评估中，GraphRAG实现了近乎完美的检索准确性。

Conclusion: GraphRAG为药物警戒提供了高精度、可扩展的解决方案，是LLMs在关键领域应用的重要进展。

Abstract: Drug side effects are a major global health concern, necessitating advanced
methods for their accurate detection and analysis. While Large Language Models
(LLMs) offer promising conversational interfaces, their inherent limitations,
including reliance on black-box training data, susceptibility to
hallucinations, and lack of domain-specific knowledge, hinder their reliability
in specialized fields like pharmacovigilance. To address this gap, we propose
two architectures: Retrieval-Augmented Generation (RAG) and GraphRAG, which
integrate comprehensive drug side effect knowledge into a Llama 3 8B language
model. Through extensive evaluations on 19,520 drug side effect associations
(covering 976 drugs and 3,851 side effect terms), our results demonstrate that
GraphRAG achieves near-perfect accuracy in drug side effect retrieval. This
framework offers a highly accurate and scalable solution, signifying a
significant advancement in leveraging LLMs for critical pharmacovigilance
applications.

</details>


### [187] [SPARQL Query Generation with LLMs: Measuring the Impact of Training Data Memorization and Knowledge Injection](https://arxiv.org/abs/2507.13859)
*Aleksandr Gashkov,Aleksandr Perevalov,Maria Eltsova,Andreas Both*

Main category: cs.IR

TL;DR: 论文提出了一种新方法，通过在不同条件下生成SPARQL查询来评估大型语言模型（LLMs）的质量，以分析训练数据对问答系统性能的影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索LLMs在知识图谱问答（KGQA）中的表现，尤其是训练数据对模型性能的影响，以提升问答系统的质量和可信度。

Method: 方法包括三种条件下的SPARQL查询生成：零样本生成、知识注入和匿名知识注入，以评估LLMs的实际能力。

Result: 结果表明，该方法能够有效评估LLMs的性能，并揭示训练数据对模型表现的影响，从而帮助判断方法的可移植性。

Conclusion: 结论指出，该方法具有可移植性和鲁棒性，适用于任何知识图谱和LLM，为评估LLMs的实际能力提供了新视角。

Abstract: Nowadays, the importance of software with natural-language user interfaces
cannot be underestimated. In particular, in Question Answering (QA) systems,
generating a SPARQL query for a given natural-language question (often named
Query Building) from the information retrieved from the same question is the
central task of QA systems working over Knowledge Graphs (KGQA). Due to the
rise of Large Language Models (LLMs), they are considered a well-suited method
to increase the quality of the question-answering functionality, as there is
still a lot of room for improvement, aiming for enhanced quality and
trustworthiness. However, LLMs are trained on web data, where researchers have
no control over whether the benchmark or the knowledge graph was already
included in the training data. In this paper, we introduce a novel method that
evaluates the quality of LLMs by generating a SPARQL query from a
natural-language question under various conditions: (1) zero-shot SPARQL
generation, (2) with knowledge injection, and (3) with "anonymized" knowledge
injection. This enables us, for the first time, to estimate the influence of
the training data on the QA quality improved by LLMs. Ultimately, this will
help to identify how portable a method is or whether good results might mostly
be achieved because a benchmark was already included in the training data (cf.
LLM memorization). The developed method is portable, robust, and supports any
knowledge graph; therefore, it could be easily applied to any KGQA or LLM,
s.t., generating consistent insights into the actual LLM capabilities is
possible.

</details>


### [188] [PARK: Personalized academic retrieval with knowledge-graphs](https://arxiv.org/abs/2507.13910)
*Pranav Kasela,Gabriella Pasi,Raffaele Perego*

Main category: cs.IR

TL;DR: 论文提出了一种结合神经语言模型和知识图谱嵌入的两步方法，用于个性化学术搜索，显著提升了检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有个性化学术搜索模型难以全面捕捉用户的学术兴趣，且未充分利用引文图的信息。

Method: 1. 训练神经语言模型用于检索；2. 将学术图转换为知识图谱，并通过平移嵌入技术将其嵌入到与语言模型共享的语义空间中。

Result: 在四个学术搜索领域中，该方法在三个领域优于传统图基和个性化模型，MAP@100提升高达10%。

Conclusion: 基于知识图谱的用户模型能有效提升检索效果，展示了其在学术搜索中的潜力。

Abstract: Academic Search is a search task aimed to manage and retrieve scientific
documents like journal articles and conference papers. Personalization in this
context meets individual researchers' needs by leveraging, through user
profiles, the user related information (e.g. documents authored by a
researcher), to improve search effectiveness and to reduce the information
overload. While citation graphs are a valuable means to support the outcome of
recommender systems, their use in personalized academic search (with, e.g.
nodes as papers and edges as citations) is still under-explored.
  Existing personalized models for academic search often struggle to fully
capture users' academic interests. To address this, we propose a two-step
approach: first, training a neural language model for retrieval, then
converting the academic graph into a knowledge graph and embedding it into a
shared semantic space with the language model using translational embedding
techniques. This allows user models to capture both explicit relationships and
hidden structures in citation graphs and paper content. We evaluate our
approach in four academic search domains, outperforming traditional graph-based
and personalized models in three out of four, with up to a 10\% improvement in
MAP@100 over the second-best model. This highlights the potential of knowledge
graph-based user models to enhance retrieval effectiveness.

</details>


### [189] [DUALRec: A Hybrid Sequential and Language Model Framework for Context-Aware Movie Recommendation](https://arxiv.org/abs/2507.13957)
*Yitong Li,Raoul Grasman*

Main category: cs.IR

TL;DR: 论文提出了一种结合LSTM和LLM优势的新型推荐系统DUALRec，用于动态建模用户偏好，并在MovieLens-1M数据集上表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统难以捕捉动态和上下文丰富的用户偏好，传统方法在时间模式和语义理解上存在不足。

Method: 结合LSTM的时间建模能力和LLM的语义推理能力，设计DUALRec模型。

Result: 在MovieLens-1M数据集上，DUALRec在HR@k、NDCG@k和类型相似性指标上优于基线模型。

Conclusion: DUALRec填补了时间序列建模与语义推理之间的空白，为智能推荐系统提供了新方向。

Abstract: The modern recommender systems are facing an increasing challenge of
modelling and predicting the dynamic and context-rich user preferences.
Traditional collaborative filtering and content-based methods often struggle to
capture the temporal patternings and evolving user intentions. While Large
Language Models (LLMs) have gained gradual attention in recent years, by their
strong semantic understanding and reasoning abilities, they are not inherently
designed to model chronologically evolving user preference and intentions. On
the other hand, for sequential models like LSTM (Long-Short-Term-Memory) which
is good at capturing the temporal dynamics of user behaviour and evolving user
preference over time, but still lacks a rich semantic understanding for
comprehensive recommendation generation. In this study, we propose DUALRec
(Dynamic User-Aware Language-based Recommender), a novel recommender that
leverages the complementary strength of both models, which combines the
temporal modelling abilities of LSTM networks with semantic reasoning power of
the fine-tuned Large Language Models. The LSTM component will capture users
evolving preference through their viewing history, while the fine-tuned LLM
variants will leverage these temporal user insights to generate next movies
that users might enjoy. Experimental results on MovieLens-1M dataset shows that
the DUALRec model outperforms a wide range of baseline models, with
comprehensive evaluation matrices of Hit Rate (HR@k), Normalized Discounted
Cumulative Gain (NDCG@k), and genre similarity metrics. This research proposes
a novel architecture that bridges the gap between temporal sequence modeling
and semantic reasoning, and offers a promising direction for developing more
intelligent and context-aware recommenders.

</details>
