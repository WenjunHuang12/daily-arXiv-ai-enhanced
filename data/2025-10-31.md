<div id=toc></div>

# Table of Contents

- [cs.GT](#cs.GT) [Total: 2]
- [cs.IR](#cs.IR) [Total: 8]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.IT](#cs.IT) [Total: 6]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.DS](#cs.DS) [Total: 2]


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [1] [Engineering Social Optimality via Utility Shaping in Non-Cooperative Games under Incomplete Information and Imperfect Monitoring](https://arxiv.org/abs/2510.26033)
*David Smith,Jie Dong,Yizhou Yang*

Main category: cs.GT

TL;DR: 本文提出了一种通过效用塑造和公共指数实现去中心化决策的方法，在非合作环境下使个体最优与社会最优一致，无需复杂通信机制。


<details>
  <summary>Details</summary>
Motivation: 解决去中心化系统中个体优化与社会最优之间的冲突，在信息不完全和公共监控不完善的条件下实现约束社会最优。

Method: 通过嵌入影子价格或KKT对齐惩罚来塑造效用函数，使阶段博弈成为精确势博弈；使用随机变分不等式分析贝叶斯均衡；提供阻尼梯度和带滞后最佳响应更新的跟踪界限。

Result: 相对于仅使用价格的基准方法，效用塑造实现了接近集中化的社会福利，消除了稳态约束/容量违规，加速了收敛；在量化情况下，离散均衡在网格内跟踪连续均衡。

Conclusion: 效用塑造加公共指数可在噪声和漂移下实现约束社会最优和稳定均衡，是操作研究友好的替代方案，适用于需求响应、云计算调度、交通定价和生物安全等领域。

Abstract: In this paper, we study decentralized decision-making where agents optimize
private objectives under incomplete information and imperfect public
monitoring, in a non-cooperative setting. By shaping utilities-embedding shadow
prices or Karush-Kuhn-Tucker(KKT)-aligned penalties-we make the stage game an
exact-potential game whose unique equilibrium equals the (possibly constrained)
social optimum. We characterize the Bayesian equilibrium as a stochastic
variational inequality; strong monotonicity follows from a single-inflection
compressed/stretched-exponential response combined with convex pricing. We give
tracking bounds for damped-gradient and best-response-with-hysteresis updates
under a noisy public index, and corresponding steady-state error. The framework
accommodates discrete and continuous action sets and composes with slower
discrete assignment. Deployable rules include: embed prices/penalties; publish
a single public index; tune steps, damping, and dual rates for contraction.
Computational experiments cover (i) a multi-tier supply chain and (ii) a
non-cooperative agentic-AI compute market of bidding bots. Relative to
price-only baselines, utility shaping attains near-centralized welfare,
eliminates steady-state constraint/capacity violations when feasible, and
accelerates convergence; with quantization, discrete equilibria track
continuous ones within the mesh. The blueprint is portable to demand response,
cloud/edge scheduling, and transportation pricing and biosecurity/agriculture.
Overall, utility shaping plus a public index implements the constrained social
optimum with stable equilibria under noise and drift-an
operations-research-friendly alternative to heavy messaging or full mechanism
design.

</details>


### [2] [NP-Hardness of Approximating Nash Social Welfare with Supermodular Valuations](https://arxiv.org/abs/2510.26055)
*Alon Bebchuk*

Main category: cs.GT

TL;DR: 该论文研究了在超模效用下分配不可分割物品以最大化纳什社会福利的问题，证明了该问题在任何近似比下都是NP难的


<details>
  <summary>Details</summary>
Motivation: 研究在超模效用函数下分配不可分割物品的优化问题，特别是关注纳什社会福利最大化这一重要目标

Method: 通过理论分析证明该优化问题的计算复杂性

Result: 证明了在超模效用下最大化纳什社会福利的问题对于任何近似比都是NP难的

Conclusion: 该问题在计算上非常困难，不存在有效的近似算法

Abstract: We study the problem of allocating a set of indivisible items to agents with
supermodular utilities to maximize the Nash social welfare. We show that the
problem is NP-hard for any approximation factor.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [3] [ORBIT -- Open Recommendation Benchmark for Reproducible Research with Hidden Tests](https://arxiv.org/abs/2510.26095)
*Jingyuan He,Jiongnan Liu,Vishan Vishesh Oberoi,Bolin Wu,Mahima Jagadeesh Patel,Kangrui Mao,Chuning Shi,I-Ta Lee,Arnold Overwijk,Chenyan Xiong*

Main category: cs.IR

TL;DR: ORBIT是一个统一的推荐系统基准测试平台，包含公开数据集和隐藏测试集ClueWeb-Reco，旨在提供一致且现实的模型评估环境。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统研究受到数据集不真实和评估设置不一致的限制，导致结论模糊，需要标准化的评估框架。

Method: 构建ORBIT基准测试，包含标准化评估框架、可复现的数据分割和透明的公开排行榜设置，并引入基于真实浏览数据的ClueWeb-Reco隐藏测试数据集。

Result: 在公开数据集上评估了12个代表性推荐模型，结果显示系统整体改进但个体性能差异大；隐藏测试揭示了现有方法在大规模网页推荐中的局限性，LLM集成显示出改进潜力。

Conclusion: ORBIT为推荐系统研究提供了标准化评估环境，隐藏测试挑战了模型的泛化能力，LLM集成是未来改进的重要方向。

Abstract: Recommender systems are among the most impactful AI applications, interacting
with billions of users every day, guiding them to relevant products, services,
or information tailored to their preferences. However, the research and
development of recommender systems are hindered by existing datasets that fail
to capture realistic user behaviors and inconsistent evaluation settings that
lead to ambiguous conclusions. This paper introduces the Open Recommendation
Benchmark for Reproducible Research with HIdden Tests (ORBIT), a unified
benchmark for consistent and realistic evaluation of recommendation models.
ORBIT offers a standardized evaluation framework of public datasets with
reproducible splits and transparent settings for its public leaderboard.
Additionally, ORBIT introduces a new webpage recommendation task, ClueWeb-Reco,
featuring web browsing sequences from 87 million public, high-quality webpages.
ClueWeb-Reco is a synthetic dataset derived from real, user-consented, and
privacy-guaranteed browsing data. It aligns with modern recommendation
scenarios and is reserved as the hidden test part of our leaderboard to
challenge recommendation models' generalization ability. ORBIT measures 12
representative recommendation models on its public benchmark and introduces a
prompted LLM baseline on the ClueWeb-Reco hidden test. Our benchmark results
reflect general improvements of recommender systems on the public datasets,
with variable individual performances. The results on the hidden test reveal
the limitations of existing approaches in large-scale webpage recommendation
and highlight the potential for improvements with LLM integrations. ORBIT
benchmark, leaderboard, and codebase are available at
https://www.open-reco-bench.ai.

</details>


### [4] [OneTrans: Unified Feature Interaction and Sequence Modeling with One Transformer in Industrial Recommender](https://arxiv.org/abs/2510.26104)
*Zhaoqi Zhang,Haolei Pei,Jun Guo,Tianyu Wang,Yufei Feng,Hui Sun,Shaowei Liu,Aixin Sun*

Main category: cs.IR

TL;DR: OneTrans是一个统一的Transformer骨干网络，同时执行用户行为序列建模和特征交互，通过统一的tokenizer和参数共享机制实现高效扩展。


<details>
  <summary>Details</summary>
Motivation: 推荐系统中特征交互模块和用户行为序列模块通常分开开发，阻碍了双向信息交换和统一优化扩展。

Method: 使用统一tokenizer将序列和非序列属性转换为单一token序列，通过因果注意力和跨请求KV缓存实现预计算和缓存。

Result: 在工业规模数据集上，OneTrans随参数增加高效扩展，持续优于强基线，在线A/B测试中用户GMV提升5.68%。

Conclusion: OneTrans提供了一个统一的Transformer框架，成功整合了序列建模和特征交互，实现了更好的性能和效率。

Abstract: In recommendation systems, scaling up feature-interaction modules (e.g.,
Wukong, RankMixer) or user-behavior sequence modules (e.g., LONGER) has
achieved notable success. However, these efforts typically proceed on separate
tracks, which not only hinders bidirectional information exchange but also
prevents unified optimization and scaling. In this paper, we propose OneTrans,
a unified Transformer backbone that simultaneously performs user-behavior
sequence modeling and feature interaction. OneTrans employs a unified tokenizer
to convert both sequential and non-sequential attributes into a single token
sequence. The stacked OneTrans blocks share parameters across similar
sequential tokens while assigning token-specific parameters to non-sequential
tokens. Through causal attention and cross-request KV caching, OneTrans enables
precomputation and caching of intermediate representations, significantly
reducing computational costs during both training and inference. Experimental
results on industrial-scale datasets demonstrate that OneTrans scales
efficiently with increasing parameters, consistently outperforms strong
baselines, and yields a 5.68% lift in per-user GMV in online A/B tests.

</details>


### [5] [ReaKase-8B: Legal Case Retrieval via Knowledge and Reasoning Representations with LLMs](https://arxiv.org/abs/2510.26178)
*Yanran Tang,Ruihong Qiu,Xue Li,Zi Huang*

Main category: cs.IR

TL;DR: 提出了ReaKase-8B框架，通过提取法律事实、法律问题、法律关系三元组和法律推理来增强法律案例检索效果，在COLIEE基准数据集上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有法律案例检索方法主要依赖传统词汇模型和预训练语言模型，但忽略了法律实体间的关系以及法律推理过程，这些信息能够反映案例的独特性并提高检索精度。

Method: 设计了上下文法律案例表示学习范式，使用微调的大型语言模型，整合法律事实、法律问题、法律关系三元组和法律推理信息来生成精确的案例嵌入。

Result: 在COLIEE 2022和2023基准数据集上的广泛实验表明，知识和推理增强的嵌入显著提高了检索性能，优于基线模型。

Conclusion: 将法律推理整合到法律案例检索系统中具有巨大潜力，ReaKase-8B框架为法律案例检索提供了新的有效方法。

Abstract: Legal case retrieval (LCR) is a cornerstone of real-world legal decision
making, as it enables practitioners to identify precedents for a given query
case. Existing approaches mainly rely on traditional lexical models and
pretrained language models to encode the texts of legal cases. Yet there are
rich information in the relations among different legal entities as well as the
crucial reasoning process that uncovers how legal facts and legal issues can
lead to judicial decisions. Such relational reasoning process reflects the
distinctive characteristics of each case that can distinguish one from another,
mirroring the real-world judicial process. Naturally, incorporating such
information into the precise case embedding could further enhance the accuracy
of case retrieval. In this paper, a novel ReaKase-8B framework is proposed to
leverage extracted legal facts, legal issues, legal relation triplets and legal
reasoning for effective legal case retrieval. ReaKase-8B designs an in-context
legal case representation learning paradigm with a fine-tuned large language
model. Extensive experiments on two benchmark datasets from COLIEE 2022 and
COLIEE 2023 demonstrate that our knowledge and reasoning augmented embeddings
substantially improve retrieval performance over baseline models, highlighting
the potential of integrating legal reasoning into legal case retrieval systems.
The code has been released on https://github.com/yanran-tang/ReaKase-8B.

</details>


### [6] [DiSE: A diffusion probabilistic model for automatic structure elucidation of organic compounds](https://arxiv.org/abs/2510.26231)
*Haochen Chen,Qi Huang,Anan Wu,Wenhao Zhang,Jianliang Ye,Jianming Wu,Kai Tan,Xin Lu,Xin Xu*

Main category: cs.IR

TL;DR: DiSE是一个基于扩散模型的端到端生成模型，整合多种光谱模态实现有机化合物的自动化结构解析


<details>
  <summary>Details</summary>
Motivation: 实现自动结构解析对于自驱动实验室至关重要，能够闭合实验反馈回路，为机器学习模型提供可靠的结构信息以进行实时决策和优化

Method: 使用扩散生成模型，整合多种光谱模态（MS、13C和1H化学位移、HSQC、COSY），通过数据驱动方法学习光谱间的内在相关性

Result: DiSE实现了卓越的准确性，在化学多样性数据集上表现出强大的泛化能力，并且对实验数据具有鲁棒性，尽管仅在计算光谱上训练

Conclusion: DiSE代表了向完全自动化结构解析的重要进展，在天然产物研究、药物发现和自驱动实验室中具有广泛潜力

Abstract: Automatic structure elucidation is essential for self-driving laboratories as
it enables the system to achieve truly autonomous. This capability closes the
experimental feedback loop, ensuring that machine learning models receive
reliable structure information for real-time decision-making and optimization.
Herein, we present DiSE, an end-to-end diffusion-based generative model that
integrates multiple spectroscopic modalities, including MS, 13C and 1H chemical
shifts, HSQC, and COSY, to achieve automated yet accurate structure elucidation
of organic compounds. By learning inherent correlations among spectra through
data-driven approaches, DiSE achieves superior accuracy, strong generalization
across chemically diverse datasets, and robustness to experimental data despite
being trained on calculated spectra. DiSE thus represents a significant advance
toward fully automated structure elucidation, with broad potential in natural
product research, drug discovery, and self-driving laboratories.

</details>


### [7] [Barlow Twins for Sequential Recommendation](https://arxiv.org/abs/2510.26407)
*Ivan Razvorotnev,Marina Munkhoeva,Evgeny Frolov*

Main category: cs.IR

TL;DR: BT-SR是一个新颖的非对比自监督学习框架，将Barlow Twins冗余减少原则集成到基于Transformer的下一个物品推荐器中，无需负采样或人工扰动即可提高推荐准确性和多样性。


<details>
  <summary>Details</summary>
Motivation: 解决序列推荐中的稀疏交互数据、流行度偏差以及准确性与多样性之间的冲突目标，同时避免传统对比学习方法的大批量要求、手工增强和负采样问题。

Method: 集成Barlow Twins冗余减少原则到Transformer推荐器中，学习对齐相似短期行为的用户嵌入，同时保持长期区别，无需负采样或人工扰动。

Result: 在五个公共基准测试中，BT-SR持续提高下一个物品预测准确性，显著增强长尾物品覆盖率和推荐校准，单个超参数可控制准确性与多样性权衡。

Conclusion: BT-SR通过结构敏感对齐有效识别新兴用户意图并减轻噪声历史背景影响，使从业者能够根据特定应用需求调整推荐系统。

Abstract: Sequential recommendation models must navigate sparse interaction data
popularity bias and conflicting objectives like accuracy versus diversity While
recent contrastive selfsupervised learning SSL methods offer improved accuracy
they come with tradeoffs large batch requirements reliance on handcrafted
augmentations and negative sampling that can reinforce popularity bias In this
paper we introduce BT-SR a novel noncontrastive SSL framework that integrates
the Barlow Twins redundancyreduction principle into a Transformerbased nextitem
recommender BTSR learns embeddings that align users with similar shortterm
behaviors while preserving longterm distinctionswithout requiring negative
sampling or artificial perturbations This structuresensitive alignment allows
BT-SR to more effectively recognize emerging user intent and mitigate the
influence of noisy historical context Our experiments on five public benchmarks
demonstrate that BTSR consistently improves nextitem prediction accuracy and
significantly enhances longtail item coverage and recommendation calibration
Crucially we show that a single hyperparameter can control the
accuracydiversity tradeoff enabling practitioners to adapt recommendations to
specific application needs

</details>


### [8] [Vectorized Context-Aware Embeddings for GAT-Based Collaborative Filtering](https://arxiv.org/abs/2510.26461)
*Danial Ebrat,Sepideh Ahmadian,Luis Rueda*

Main category: cs.IR

TL;DR: 提出基于图注意力网络和LLM增强的协同过滤框架，通过文本嵌入解决数据稀疏和冷启动问题，在MovieLens数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 推荐系统面临数据稀疏和冷启动问题，难以为新用户或交互较少的用户提供准确推荐。

Method: 使用图注意力网络，结合LLM生成的用户简档和物品元数据文本嵌入作为图节点特征，采用混合损失函数（BPR+余弦相似度）和负采样策略。

Result: 在MovieLens 100k和1M数据集上，Precision、NDCG和MAP指标均优于现有基线方法，对交互历史有限的用户表现出鲁棒性。

Conclusion: 通过将LLM衍生的上下文理解整合到图架构中，有效缓解了稀疏性和冷启动限制，未来将关注推荐准确性、覆盖率、多样性、公平性和可解释性的平衡。

Abstract: Recommender systems often struggle with data sparsity and cold-start
scenarios, limiting their ability to provide accurate suggestions for new or
infrequent users. This paper presents a Graph Attention Network (GAT) based
Collaborative Filtering (CF) framework enhanced with Large Language Model (LLM)
driven context aware embeddings. Specifically, we generate concise textual user
profiles and unify item metadata (titles, genres, overviews) into rich textual
embeddings, injecting these as initial node features in a bipartite user item
graph. To further optimize ranking performance, we introduce a hybrid loss
function that combines Bayesian Personalized Ranking (BPR) with a cosine
similarity term and robust negative sampling, ensuring explicit negative
feedback is distinguished from unobserved data. Experiments on the MovieLens
100k and 1M datasets show consistent improvements over state-of-the-art
baselines in Precision, NDCG, and MAP while demonstrating robustness for users
with limited interaction history. Ablation studies confirm the critical role of
LLM-augmented embeddings and the cosine similarity term in capturing nuanced
semantic relationships. Our approach effectively mitigates sparsity and
cold-start limitations by integrating LLM-derived contextual understanding into
graph-based architectures. Future directions include balancing recommendation
accuracy with coverage and diversity, and introducing fairness-aware
constraints and interpretability features to enhance system performance
further.

</details>


### [9] [WeaveRec: An LLM-Based Cross-Domain Sequential Recommendation Framework with Model Merging](https://arxiv.org/abs/2510.26546)
*Min Hou,Xin Liu,Le Wu,Chenyi He,Hao Liu,Zhi Li,Xin Li,Si Wei*

Main category: cs.IR

TL;DR: 提出了WeaveRec方法，通过交叉训练多个LoRA模块并融合，解决了基于LLM的跨域推荐中性能下降的问题，无需重叠用户/物品且不增加推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有跨域推荐方法依赖重叠用户/物品，这在现实中很少见。虽然LLM和模型融合技术可以统一多域数据，但简单训练或合并LLM会导致性能下降。

Method: WeaveRec方法交叉训练多个LoRA模块，使用源域和目标域数据进行编织式训练，然后通过模型融合合并这些模块。

Result: 在单源、多源和跨平台跨域推荐场景中的广泛实验表明，WeaveRec有效缓解了性能下降，在真实推荐任务中持续优于基线方法。

Conclusion: WeaveRec通过编织式LoRA训练和模型融合，成功解决了LLM跨域推荐的性能下降问题，提供了理论保证，并在实际场景中表现优异。

Abstract: Cross-Domain Sequential Recommendation (CDSR) seeks to improve user
preference modeling by transferring knowledge from multiple domains. Despite
the progress made in CDSR, most existing methods rely on overlapping users or
items to establish cross-domain correlations-a requirement that rarely holds in
real-world settings. The advent of large language models (LLM) and
model-merging techniques appears to overcome this limitation by unifying
multi-domain data without explicit overlaps. Yet, our empirical study shows
that naively training an LLM on combined domains-or simply merging several
domain-specific LLMs-often degrades performance relative to a model trained
solely on the target domain. To address these challenges, we first
experimentally investigate the cause of suboptimal performance in LLM-based
cross-domain recommendation and model merging. Building on these insights, we
introduce WeaveRec, which cross-trains multiple LoRA modules with source and
target domain data in a weaving fashion, and fuses them via model merging.
WeaveRec can be extended to multi-source domain scenarios and notably does not
introduce additional inference-time cost in terms of latency or memory.
Furthermore, we provide a theoretical guarantee that WeaveRec can reduce the
upper bound of the expected error in the target domain. Extensive experiments
on single-source, multi-source, and cross-platform cross-domain recommendation
scenarios validate that WeaveRec effectively mitigates performance degradation
and consistently outperforms baseline approaches in real-world recommendation
tasks.

</details>


### [10] [ProfOlaf: Semi-Automated Tool for Systematic Literature Reviews](https://arxiv.org/abs/2510.26750)
*Martim Afonso,Nuno Saavedra,Bruno Lourenço,Alexandra Mendes,João Ferreira*

Main category: cs.IR

TL;DR: ProfOlaf是一个半自动化工具，通过结合迭代滚雪球式文献收集、人机协同过滤和大型语言模型分析，提高系统综述的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 系统综述和映射研究对于综合研究、识别研究空白和指导未来工作至关重要，但传统方法通常劳动密集且耗时。现有工具仅支持特定步骤，大部分过程仍需手动操作且容易出错。

Method: ProfOlaf采用半自动化方法，支持迭代滚雪球式文献收集，结合人工在环过滤机制，并利用大型语言模型辅助分析文章、提取关键主题和回答关于论文内容的查询。

Result: 通过将自动化与指导性人工努力相结合，ProfOlaf提高了系统综述的效率、质量和可重复性，适用于各个研究领域。

Conclusion: ProfOlaf通过智能自动化与人工监督的平衡，为系统综述提供了更高效、更可靠的解决方案，同时保持了方法学的严谨性。

Abstract: Systematic reviews and mapping studies are critical for synthesizing
research, identifying gaps, and guiding future work, but they are often
labor-intensive and time-consuming. Existing tools provide partial support for
specific steps, leaving much of the process manual and error-prone. We present
ProfOlaf, a semi-automated tool designed to streamline systematic reviews while
maintaining methodological rigor. ProfOlaf supports iterative snowballing for
article collection with human-in-the-loop filtering and uses large language
models to assist in analyzing articles, extracting key topics, and answering
queries about the content of papers. By combining automation with guided manual
effort, ProfOlaf enhances the efficiency, quality, and reproducibility of
systematic reviews across research fields. A video describing and demonstrating
ProfOlaf is available at: https://youtu.be/4noUXfcmxsE

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [11] [Rethinking Text-to-SQL: Dynamic Multi-turn SQL Interaction for Real-world Database Exploration](https://arxiv.org/abs/2510.26495)
*Linzhuang Sun,Tianyu Guo,Hao Liang,Yuying Li,Qifeng Cai,Jingxuan Wei,Bihui Yu,Wentao Zhang,Bin Cui*

Main category: cs.DB

TL;DR: DySQL-Bench是一个评估动态多轮Text-to-SQL能力的基准测试，通过自动化流程生成包含1072个任务的交互式SQL查询数据集，模拟真实世界用户意图演变的场景。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL系统在静态单轮任务表现良好，但在真实交互场景中用户意图会随时间演变，需要模型能够适应多轮查询调整，特别是在金融和商业分析等应用中。

Method: 采用两阶段自动化流程：基于数据库表结构树表示进行LLM任务生成，然后进行交互导向的过滤和专家验证。同时提出多轮评估框架，模拟LLM用户、被测模型和可执行数据库之间的真实交互。

Result: 构建了覆盖13个领域、1072个任务的基准测试，人工验证确认合成数据100%正确。GPT-4o在该基准上仅达到58.34%总体准确率和23.81%的Pass@5指标，显示基准的高难度。

Conclusion: DySQL-Bench填补了动态多轮Text-to-SQL评估的空白，揭示了现有模型在真实交互场景中的局限性，为未来研究提供了重要基准。

Abstract: Recent advances in Text-to-SQL have achieved strong results in static,
single-turn tasks, where models generate SQL queries from natural language
questions. However, these systems fall short in real-world interactive
scenarios, where user intents evolve and queries must be refined over multiple
turns. In applications such as finance and business analytics, users
iteratively adjust query constraints or dimensions based on intermediate
results. To evaluate such dynamic capabilities, we introduce DySQL-Bench, a
benchmark assessing model performance under evolving user interactions. Unlike
previous manually curated datasets, DySQL-Bench is built through an automated
two-stage pipeline of task synthesis and verification. Structured tree
representations derived from raw database tables guide LLM-based task
generation, followed by interaction-oriented filtering and expert validation.
Human evaluation confirms 100% correctness of the synthesized data. We further
propose a multi-turn evaluation framework simulating realistic interactions
among an LLM-simulated user, the model under test, and an executable database.
The model must adapt its reasoning and SQL generation as user intents change.
DySQL-Bench covers 13 domains across BIRD and Spider 2 databases, totaling
1,072 tasks. Even GPT-4o attains only 58.34% overall accuracy and 23.81% on the
Pass@5 metric, underscoring the benchmark's difficulty. All code and data are
released at https://github.com/Aurora-slz/Real-World-SQL-Bench .

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [12] [Coherence-Aware Distributed Learning under Heterogeneous Downlink Impairments](https://arxiv.org/abs/2510.25917)
*Mehdi Karbalayghareh,David J. Love,Christopher G. Brinton*

Main category: cs.IT

TL;DR: 提出了一种针对无线联邦学习的感知相干性通信效率框架，通过资源复用策略在异构衰落动态下联合进行信道训练和模型更新。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习方案忽略了设备间相干时间差异，导致通信效率低下和训练开销严重。实际中边缘设备由于移动性和散射环境不同，具有不相等的相干时间，对导频信号和信道估计资源需求不同。

Method: 针对下行链路损伤，引入基于乘积叠加的资源复用策略，使参数服务器能够通过将静态设备的全局模型更新嵌入到移动设备的导频传输中，有效调度静态和动态设备。

Result: 理论分析了所提方案的收敛行为，量化了其在预期通信效率和训练准确性方面的增益。实验证明了该框架在移动性诱导动态下的有效性。

Conclusion: 该框架为无线信道上联邦学习的实际部署提供了有用见解，能够有效处理异构衰落动态下的通信效率问题。

Abstract: The performance of federated learning (FL) over wireless networks critically
depends on accurate and timely channel state information (CSI) across
distributed devices. This requirement is tightly linked to how rapidly the
channel gains vary, i.e., the coherence intervals. In practice, edge devices
often exhibit unequal coherence times due to differences in mobility and
scattering environments, leading to unequal demands for pilot signaling and
channel estimation resources. Conventional FL schemes that overlook this
coherence disparity can suffer from severe communication inefficiencies and
training overhead. This paper proposes a coherence-aware,
communication-efficient framework for joint channel training and model updating
in practical wireless FL systems operating under heterogeneous fading dynamics.
Focusing on downlink impairments, we introduce a resource-reuse strategy based
on product superposition, enabling the parameter server to efficiently schedule
both static and dynamic devices by embedding global model updates for static
devices within pilot transmissions intended for mobile devices. We
theoretically analyze the convergence behavior of the proposed scheme and
quantify its gains in expected communication efficiency and training accuracy.
Experiments demonstrate the effectiveness of the proposed framework under
mobility-induced dynamics and offer useful insights for the practical
deployment of FL over wireless channels.

</details>


### [13] [Duality-Based Fixed Point Iteration Algorithm for Beamforming Design in ISAC Systems](https://arxiv.org/abs/2510.26147)
*Xilai Fan,Ya-Feng Liu*

Main category: cs.IT

TL;DR: 本文研究集成感知与通信系统中的波束成形设计问题，提出了一种基于对偶固定点迭代的高效算法，在保证通信用户SINR和雷达感知MSE约束的同时最小化总发射功率。


<details>
  <summary>Details</summary>
Motivation: 在集成感知与通信系统中，通信用户的SINR要求和雷达感知性能指标之间存在复杂耦合关系，这给波束成形设计带来了挑战，需要开发高效算法来解决这一联合优化问题。

Method: 首先建立原始ISAC波束成形问题与其半定松弛的等价性，推导拉格朗日对偶形式，并将其重构为具有不定权重矩阵的广义下行链路波束成形问题。然后提出定制的固定点迭代算法和基于对偶的固定点迭代算法。

Result: 仿真结果表明，所提出的Dual-FPI算法能够获得全局最优解，同时与现有基线方法相比显著降低了计算复杂度。

Conclusion: 本文成功解决了ISAC系统中的波束成形设计问题，提出的Dual-FPI算法在保证性能的同时实现了计算效率的提升，为实际系统部署提供了可行的解决方案。

Abstract: In this paper, we investigate the beamforming design problem in an integrated
sensing and communication (ISAC) system, where a multi-antenna base station
simultaneously serves multiple communication users while performing radar
sensing. We formulate the problem as the minimization of the total transmit
power, subject to signal-to-interference-plus-noise ratio (SINR) constraints
for communication users and mean-squared-error (MSE) constraints for radar
sensing. The core challenge arises from the complex coupling between
communication SINR requirements and sensing performance metrics. To efficiently
address this challenge, we first establish the equivalence between the original
ISAC beamforming problem and its semidefinite relaxation (SDR), derive its
Lagrangian dual formulation, and further reformulate it as a generalized
downlink beamforming (GDB) problem with potentially indefinite weighting
matrices. Compared to the classical DB problem, the presence of indefinite
weighting matrices in the GDB problem introduces substantial analytical and
computational challenges. Our key technical contributions include (i) a
necessary and sufficient condition for the boundedness of the GDB problem, and
(ii) a tailored efficient fixed point iteration (FPI) algorithm with a provable
convergence guarantee for solving the GDB problem. Building upon these results,
we develop a duality-based fixed point iteration (Dual-FPI) algorithm, which
integrates an outer subgradient ascent loop with an inner FPI loop. Simulation
results demonstrate that the proposed Dual-FPI algorithm achieves globally
optimal solutions while significantly reducing computational complexity
compared with existing baseline approaches.

</details>


### [14] [Efficient Spectral Efficiency Maximization Design for IRS-aided MIMO Systems](https://arxiv.org/abs/2510.26279)
*Fuying Li,Yajun Wang,Zhuxian Lian,Wen Chen*

Main category: cs.IT

TL;DR: 提出ADMM-APG算法解决IRS辅助MIMO系统中的频谱效率最大化问题，该算法结合ADMM和APG方法，在频谱效率和计算复杂度方面优于现有基准方法。


<details>
  <summary>Details</summary>
Motivation: 无线通信对频谱效率的需求日益增长，智能反射表面(IRS)能够动态重构传播环境，但在IRS辅助MIMO系统中联合优化发射预编码矩阵和IRS相位配置具有挑战性。

Method: 提出ADMM-APG算法，将交替方向乘子法(ADMM)与加速投影梯度(APG)方法相结合，将原问题分解为可处理的子问题，每个子问题都有闭式解且保持低计算复杂度。

Result: 仿真结果表明，ADMM-APG算法在频谱效率和计算复杂度方面持续超越现有基准方法，在各种系统配置下实现显著性能增益。

Conclusion: ADMM-APG算法为IRS辅助MIMO系统中的频谱效率最大化问题提供了一种计算高效的解决方案，具有优越的性能和实际应用价值。

Abstract: Driven by the growing demand for higher spectral efficiency in wireless
communications, intelligent reflecting surfaces (IRS) have attracted
considerable attention for their ability to dynamically reconfigure the
propagation environment. This work addresses the spectral efficiency
maximization problem in IRS-assisted multiple-input multiple-output (MIMO)
systems, which involves the joint optimization of the transmit precoding matrix
and the IRS phase shift configuration. This problem is inherently challenging
due to its non-convex nature. To tackle it effectively, we introduce a
computationally efficient algorithm, termed ADMM-APG, which integrates the
alternating direction method of multipliers (ADMM) with the accelerated
projected gradient (APG) method. The proposed framework decomposes the original
problem into tractable subproblems, each admitting a closed-form solution while
maintaining low computational complexity. Simulation results demonstrate that
the ADMM-APG algorithm consistently surpasses existing benchmark methods in
terms of spectral efficiency and computational complexity, achieving
significant performance gains across a range of system configurations.

</details>


### [15] [Diffusion-Aided Bandwidth-Efficient Semantic Communication with Adaptive Requests](https://arxiv.org/abs/2510.26442)
*Xuesong Wang,Xinyan Xie,Mo Li,Zhaoqian Liu*

Main category: cs.IT

TL;DR: 提出了一种基于扩散模型的语义通信框架，通过传输简洁文本描述和少量关键视觉特征，结合自适应重传机制来减少语义冗余，在保持高语义准确性的同时显著降低带宽使用。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信方法存在两个问题：仅传输文本描述无法精确捕捉空间布局和细节；传输文本加密集视觉特征会引入语义冗余。需要减少冗余同时保持语义理解和视觉保真度。

Method: 传输简洁文本描述和少量关键潜在视觉特征，使用扩散修复模型重建图像。接收端设计语义一致性机制评估重建图像与文本的对齐度，检测到语义差异时触发重传请求额外潜在块来优化重建。

Result: 该方法显著降低了带宽使用，同时保持了高语义准确性，在重建质量和传输开销之间实现了高效平衡。

Conclusion: 扩散基语义通信框架通过自适应重传机制有效解决了语义冗余问题，为视觉内容的语义通信提供了一种高效解决方案。

Abstract: Semantic communication focuses on conveying the intrinsic meaning of data
rather than its raw symbolic representation. For visual content, this paradigm
shifts from traditional pixel-level transmission toward leveraging the semantic
structure of images to communicate visual meaning. Existing approaches
generally follow one of two paths: transmitting only text descriptions, which
often fail to capture precise spatial layouts and fine-grained appearance
details; or transmitting text alongside dense latent visual features, which
tends to introduce substantial semantic redundancy. A key challenge, therefore,
is to reduce semantic redundancy while preserving semantic understanding and
visual fidelity, thereby improving overall transmission efficiency. This paper
introduces a diffusion-based semantic communication framework with adaptive
retransmission. The system transmits concise text descriptions together with a
limited set of key latent visual features, and employs a diffusion-based
inpainting model to reconstruct the image. A receiver-side semantic consistency
mechanism is designed to evaluate the alignment between the reconstructed image
and the original text description. When a semantic discrepancy is detected, the
receiver triggers a retransmission to request a small set of additional latent
blocks and refine the image reconstruction. This approach significantly reduces
bandwidth usage while preserving high semantic accuracy, achieving an efficient
balance between reconstruction quality and transmission overhead.

</details>


### [16] [PolarZero: A Reinforcement Learning Approach for Low-Complexity Polarization Kernel Design](https://arxiv.org/abs/2510.26452)
*Yi-Ting Hong,Stefano Rini,Luca Barletta*

Main category: cs.IT

TL;DR: 使用基于Gumbel AlphaZero算法的强化学习框架，通过递归最大似然解码(RMLD)构建大核极化码，在满足错误指数要求的同时最小化解码复杂度。


<details>
  <summary>Details</summary>
Motivation: 大核极化码能改善错误指数，但设计低解码复杂度的核具有挑战性。需要一种能高效探索设计空间并找到平衡错误指数和解码复杂度的核构造方法。

Method: 采用基于Gumbel AlphaZero算法的强化学习框架，在递归最大似然解码(RMLD)下进行核构造。该方法能有效探索设计空间，识别满足给定错误指数要求的大尺寸核。

Result: 对于尺寸16的核，该方法比手工设计降低17%的解码复杂度，达到0.5183的错误指数，优于Arikan核的0.5。

Conclusion: 基于学习的方法在实用极化码构造中具有有效性，能够找到在错误指数和解码复杂度之间达到更好平衡的核设计。

Abstract: Polar codes with large kernels can achieve improved error exponents but are
challenging to design with low decoding complexity. This work investigates
kernel construction under recursive maximum likelihood decoding (RMLD) using a
reinforcement learning framework based on the Gumbel AlphaZero algorithm. The
proposed method efficiently explores the design space and identifies large-size
kernels that satisfy a given error exponent while minimizing decoding
complexity. For a size-16 kernel, it achieves 17% lower decoding complexity
than handcrafted designs while reaching an error exponent of 0.5183 compared to
0.5 for Arikan's kernel, demonstrating the effectiveness of the learning-based
approach for practical polar code construction.

</details>


### [17] [Entropy Functions on Two-Dimensional Faces of Polymatroidal Region of Degree Four: Part II: Information Theoretic Constraints Breed New Combinatorial Structures](https://arxiv.org/abs/2510.26552)
*Shaocheng Liu,Qi Chen,Minquan Cheng*

Main category: cs.IT

TL;DR: 本文是系列论文的第二部分，旨在表征四维多拟阵区域Γ4中2维面上的熵函数，完成了对剩余10种类型面的分析，其中8种完全表征，2种部分表征。


<details>
  <summary>Details</summary>
Motivation: 信息论中熵函数的表征具有基础重要性。通过在多拟阵区域（Shannon外界的多拟阵区域）上施加约束，可以得到该区域的各个面以及具有特殊结构的熵函数。

Method: 通过算法枚举了Γ4的所有59种2维面类型，在本文中针对剩余的10种类型，引入了新的组合设计结构来进行熵函数表征。

Result: 在第一部分已完全表征了49种类型的基础上，本文对剩余的10种类型进行了分析，其中8种类型完全表征，2种类型部分表征。

Conclusion: 通过引入新的组合设计结构，成功表征了Γ4中2维面上的大部分熵函数，为信息论中熵函数的完整表征提供了重要进展。

Abstract: Characterization of entropy functions is of fundamental importance in
information theory. By imposing constraints on their Shannon outer bound, i.e.,
the polymatroidal region, one obtains the faces of the region and entropy
functions on them with special structures. In this series of two papers, we
characterize entropy functions on the $2$-dimensional faces of the
polymatroidal region $\Gamma_4$. In Part I, we formulated the problem,
enumerated all $59$ types of $2$-dimensional faces of $\Gamma_4$ by a
algorithm, and fully characterized entropy functions on $49$ types of them. In
this paper, i.e., Part II, we will characterize entropy functions on the
remaining $10$ types of faces, among which $8$ types are fully characterized
and $2$ types are partially characterized. To characterize these types of
faces, we introduce some new combinatorial design structures which are
interesting themself.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [18] [Contribution-Guided Asymmetric Learning for Robust Multimodal Fusion under Imbalance and Noise](https://arxiv.org/abs/2510.26289)
*Zijing Xu,Yunfeng Kou,Kunming Wu,Hong Liu*

Main category: cs.MM

TL;DR: 提出CAL方法解决多模态学习中的模态不平衡和数据噪声问题，通过贡献度引导的不对称学习增强高贡献模态，压缩弱模态以提升融合性能


<details>
  <summary>Details</summary>
Motivation: 现有方法通过抑制主导模态实现平衡，但忽略了模态间信息价值的固有差异，可能导致收敛到次优解

Method: 基于模态贡献度度量W^m，设计不对称梯度加速机制和贡献感知的不对称信息瓶颈压缩机制，动态压缩低贡献模态的噪声

Result: 在CREMA-D、KS和AVE数据集上分别达到79.30%、74.82%和74.21%的准确率，显著优于现有最优模型ARL；在高噪声鲁棒性测试中也表现领先

Conclusion: CAL在模态不平衡和噪声干扰方面具有显著优势，作为灵活高效的框架易于迁移到其他任务，具有广泛适应性和应用前景

Abstract: Multimodal learning faces two major challenges: modality imbalance and data
noise, which significantly affect the robustness and generalization ability of
models. Existing methods achieve modality balance by suppressing dominant
modalities, but they neglect the inherent differences in the information value
between modalities, potentially leading to convergence to suboptimal solutions.
This paper proposes an innovative modality compression paradigm,
Contribution-Guided Asymmetric Learning (CAL), which aims to enhance the
contribution of high-contribution modalities while compressing weak modalities
to increase their contribution, allowing both to improve the performance of
multimodal information fusion. CAL is based on a modality contribution metric
W^m combining the information quantity I(m) and confidence D(m), and it designs
an asymmetric gradient acceleration mechanism and a contribution-aware
Asymmetric Information Bottleneck (AIB) compression mechanism. The former
accelerates the gradient update of modalities, while the latter dynamically
compresses the noise of low-contribution modalities.
  On five benchmark datasets, including emotion recognition, scene recognition,
and event localization tasks, CAL has shown outstanding performance in
imbalanced fusion tasks and noise robustness tests. On CREMA-D, KS, and AVE,
CAL achieves 79.30%, 74.82%, and 74.21% accuracy, significantly outperforming
the existing state-of-the-art model ARL. In high-noise robustness tests, CAL
also achieved leading performance under various attack strategies on the
MVSA-Single and NYUD2 datasets. These results validate the significant
advantages of CAL in modality imbalance and noise interference. CAL, as a
flexible and efficient framework, is easy to transfer to other tasks and has
broad adaptability and potential application prospects.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [19] [Online 3-Taxi on General Metrics](https://arxiv.org/abs/2510.25861)
*Christian Coester,Tze-Yang Poon*

Main category: cs.DS

TL;DR: 提出了一个针对3-taxi问题的O(1)竞争比算法，解决了该问题在一般度量空间上是否存在有限竞争比的长期开放性问题。


<details>
  <summary>Details</summary>
Motivation: 在线k-taxi问题是k-server问题的泛化，其中k辆出租车需要在度量空间中服务乘客请求。该问题的'困难'版本（成本为无乘客行驶距离）比k-server问题困难得多，此前即使在k=3的情况下，也未知在一般度量空间上是否能实现有限竞争比。

Method: 提出了一个新的算法来解决3-taxi问题，该算法在一般度量空间上具有常数竞争比。

Result: 证明了3-taxi问题在一般度量空间上存在O(1)竞争比的在线算法，这是该问题的一个重要突破。

Conclusion: 这项工作首次证明了3-taxi问题在一般度量空间上可以实现有限竞争比，为这一长期开放性问题提供了解决方案。

Abstract: The online $k$-taxi problem, introduced in 1990 by Fiat, Rabani and Ravid, is
a generalization of the $k$-server problem where $k$ taxis must serve a
sequence of requests in a metric space. Each request is a pair of two points,
representing the pick-up and drop-off location of a passenger. In the
interesting ''hard'' version of the problem, the cost is the total distance
that the taxis travel without a passenger. The problem is known to be
substantially harder than the $k$-server problem, and prior to this work even
for $k=3$ taxis it has been unknown whether a finite competitive ratio is
achievable on general metric spaces. We present an $O(1)$-competitive algorithm
for the $3$-taxi problem.

</details>


### [20] [Space-Efficient k-Mismatch Text Indexes](https://arxiv.org/abs/2510.26264)
*Tomasz Kociumaka,Jakub Radoszewski*

Main category: cs.DS

TL;DR: 本文提出了改进的k-不匹配索引，将空间复杂度从O(nlog^k n)降低到O(nlog^{k-1} n)，同时保持相同的查询时间，这是20年来首次改进Cole等人的原始k-错误树的时间-空间权衡。


<details>
  <summary>Details</summary>
Motivation: k-错误树自2004年提出以来，虽然被广泛采用，但其原始的时间-空间权衡在一般情况下从未被改进。本文旨在打破这一僵局，提供更优的k-不匹配索引。

Method: 开发了新的k-不匹配索引方法，在保持查询时间不变的情况下减少空间使用。对于常数大小字母表，进一步将空间复杂度降低到O(nlog^{k-1.5+ε} n)。同时为短模式开发了改进的索引。

Result: 实现了第一个在一般情况下改进k-错误树时间-空间权衡的索引：空间复杂度O(nlog^{k-1} n)，查询时间O(log^k n log log n + m + occ)。对于常数字母表，空间复杂度进一步降至O(nlog^{k-1.5+ε} n)。

Conclusion: 本文成功改进了20年来未被优化的k-不匹配索引问题，提供了更优的空间效率，同时保持了查询性能，为字符串处理中的近似模式匹配提供了更高效的解决方案。

Abstract: A central task in string processing is text indexing, where the goal is to
preprocess a text (a string of length $n$) into an efficient index (a data
structure) supporting queries about the text. Cole, Gottlieb, and Lewenstein
(STOC 2004) proposed $k$-errata trees, a family of text indexes supporting
approximate pattern matching queries of several types. In particular,
$k$-errata trees yield an elegant solution to $k$-mismatch queries, where we
are to report all substrings of the text with Hamming distance at most $k$ to
the query pattern. The resulting $k$-mismatch index uses $O(n\log^k n)$ space
and answers a query for a length-$m$ pattern in $O(\log^k n \log \log n + m +
occ)$ time, where $occ$ is the number of approximate occurrences.
  In retrospect, $k$-errata trees appear very well optimized: even though a
large body of work has adapted $k$-errata trees to various settings throughout
the past two decades, the original time-space trade-off for $k$-mismatch
indexing has not been improved in the general case. We present the first such
improvement, a $k$-mismatch index with $O(n\log^{k-1} n)$ space and the same
query time as $k$-errata trees.
  Previously, due to a result of Chan, Lam, Sung, Tam, and Wong (Algorithmica
2010), such an $O(n\log^{k-1} n)$-size index has been known only for texts over
alphabets of constant size. In this setting, however, we obtain an even smaller
$k$-mismatch index of size only $O(n \log^{k-2+\varepsilon+\frac{2}{k+2-(k
\bmod 2)}} n)\subseteq O(n\log^{k-1.5+\varepsilon} n)$ for $2\le k\le O(1)$ and
any constant $\varepsilon>0$. Along the way, we also develop improved indexes
for short patterns, offering better trade-offs in this practically relevant
special case.

</details>
