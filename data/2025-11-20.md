<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 5]
- [cs.IR](#cs.IR) [Total: 14]
- [cs.DS](#cs.DS) [Total: 5]
- [cs.IT](#cs.IT) [Total: 9]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.MM](#cs.MM) [Total: 1]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Castle: Causal Cascade Updates in Relational Databases with Large Language Models](https://arxiv.org/abs/2511.14762)
*Yongye Su,Yucheng Zhang,Zeru Shi,Bruno Ribeiro,Elisa Bertino*

Main category: cs.DB

TL;DR: Castle是首个使用大语言模型进行仅模式级联更新生成的框架，解决了传统静态CASCADE UPDATE约束在现代非规范化数据库中的不足，通过自然语言指令生成多列、因果一致的SQL UPDATE语句。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法主要关注SELECT查询生成，忽视了SQL更新操作及其连锁效应的挑战。传统CASCADE UPDATE约束是静态的，不适合需要动态、上下文感知更新的现代非规范化数据库。

Method: 将UPDATE SQL生成构建为分治任务，利用LLM的推理能力确定哪些列需要直接更新，以及这些更新如何通过模式传播，通过嵌套查询和子结构确保数据机密性。

Result: 在真实世界因果更新场景中评估，证明Castle能够生成准确的SQL更新语句，展示了LLM在自动化DBMS中的推理能力。

Conclusion: Castle框架成功展示了LLM在数据库管理系统中的推理能力，能够处理复杂的级联更新场景，同时保护数据机密性。

Abstract: This work introduces Castle, the first framework for schema-only cascade update generation using large language models (LLMs). Despite recent advances in LLMs for Text2SQL code generation, existing approaches focus primarily on SELECT queries, neglecting the challenges of SQL update operations and their ripple effects. Traditional CASCADE UPDATE constraints are static and unsuitable for modern, denormalized databases, which demand dynamic, context-aware updates. Castle enables natural language instructions to trigger multi-column, causally consistent SQL UPDATE statements, without revealing table content to the model. By framing UPDATE SQL generation as a divide-and-conquer task with LLMs' reasoning capacity, Castle can determine not only which columns must be directly updated, but also how those updates propagate through the schema, causing cascading updates -- all via nested queries and substructures that ensure data confidentiality. We evaluate it on real-world causal update scenarios, demonstrating its ability to produce accurate SQL updates, and thereby highlighting the reasoning ability of LLMs in automated DBMS.

</details>


### [2] [BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning in Document Visual Question Answer](https://arxiv.org/abs/2511.15090)
*Wenhan Yu,Wang Chen,Guanqiang Qi,Weikang Li,Yang Li,Lei Sha,Deguo Xia,Jizhou Huang*

Main category: cs.DB

TL;DR: BBox DocVQA是一个大规模、基于边界框的文档视觉问答数据集，旨在增强视觉文档中的空间推理和证据定位能力。


<details>
  <summary>Details</summary>
Motivation: 现有DocVQA数据集大多局限于页面级别，缺乏细粒度的空间定位，限制了视觉语言模型的解释性和推理能力。

Method: 提出了自动化构建流水线Segment Judge and Generate，结合区域分割模型、语义判断VLM和问答生成VLM，并通过人工验证保证质量。

Result: 构建了包含3.6K个多样化文档和32K个QA对的数据集，涵盖单区域/多区域和单页/多页场景。基准测试显示现有VLMs在空间定位和推理准确性方面仍面临挑战。

Conclusion: 在BBox DocVQA上微调显著改善了边界框定位和答案生成，验证了该数据集对增强VLMs推理能力的有效性。

Abstract: Document Visual Question Answering (DocVQA) is a fundamental task for multimodal document understanding and a key testbed for vision language reasoning. However, most existing DocVQA datasets are limited to the page level and lack fine grained spatial grounding, constraining the interpretability and reasoning capability of Vision Language Models (VLMs). To address this gap, we introduce BBox DocVQA a large scale, bounding box grounded dataset designed to enhance spatial reasoning and evidence localization in visual documents. We further present an automated construction pipeline, Segment Judge and Generate, which integrates a segment model for region segmentation, a VLM for semantic judgment, and another advanced VLM for question answer generation, followed by human verification for quality assurance. The resulting dataset contains 3.6 K diverse documents and 32 K QA pairs, encompassing single and multi region as well as single and multi page scenarios. Each QA instance is grounded on explicit bounding boxes, enabling fine grained evaluation of spatial semantic alignment. Benchmarking multiple state of the art VLMs (e.g., GPT 5, Qwen2.5 VL, and InternVL) on BBox DocVQA reveals persistent challenges in spatial grounding and reasoning accuracy. Furthermore, fine tuning on BBox DocVQA substantially improves both bounding box localization and answer generation, validating its effectiveness for enhancing the reasoning ability of VLMs. Our dataset and code will be publicly released to advance research on interpretable and spatially grounded vision language reasoning.

</details>


### [3] [B+ANN: A Fast Billion-Scale Disk-based Nearest-Neighbor Index](https://arxiv.org/abs/2511.15557)
*Selim Furkan Tekin,Rajesh Bordawekar*

Main category: cs.DB

TL;DR: 提出了一种基于磁盘的近似最近邻索引B+ANN，解决了HNSW算法的内存设计、随机内存访问、缓存行为差等问题，通过数据分区和B+树变体实现混合遍历，在召回率和查询性能上优于HNSW。


<details>
  <summary>Details</summary>
Motivation: 当前向量数据库主要使用基于图的HNSW算法，但存在内存设计、随机内存访问导致缓存性能下降、细粒度计算限制加速范围、仅支持语义相似性查询等问题。

Method: 首先将输入数据分区为包含语义相似项的块，然后构建B+树变体在内存和磁盘上存储块，最后启用基于边和块的混合内存遍历。

Result: B+ANN在质量（召回率）和执行性能（QPS）上优于HNSW，改善了空间和时间局部性，减少了19.23%的缓存未命中，内存消耗和磁盘构建时间比DiskANN算法减少24倍。

Conclusion: B+ANN是一种有效的磁盘ANN索引，不仅提升了相似性查询性能，还支持HNSW不支持的相异性查询。

Abstract: Storing and processing of embedding vectors by specialized Vector databases (VDBs) has become the linchpin in building modern AI pipelines. Most current VDBs employ variants of a graph-based ap- proximate nearest-neighbor (ANN) index algorithm, HNSW, to an- swer semantic queries over stored vectors. Inspite of its wide-spread use, the HNSW algorithm suffers from several issues: in-memory design and implementation, random memory accesses leading to degradation in cache behavior, limited acceleration scope due to fine-grained pairwise computations, and support of only semantic similarity queries. In this paper, we present a novel disk-based ANN index, B+ANN, to address these issues: it first partitions input data into blocks containing semantically similar items, then builds an B+ tree variant to store blocks both in-memory and on disks, and finally, enables hybrid edge- and block-based in-memory traversals. As demonstrated by our experimantal evaluation, the proposed B+ANN disk-based index improves both quality (Recall value), and execution performance (Queries per second/QPS) over HNSW, by improving spatial and temporal locality for semantic operations, reducing cache misses (19.23% relative gain), and decreasing the memory consumption and disk-based build time by 24x over the DiskANN algorithm. Finally, it enables dissimilarity queries, which are not supported by similarity-oriented ANN indices.

</details>


### [4] [A Decade of Systems for Human Data Interaction](https://arxiv.org/abs/2511.15585)
*Eugene Wu,Yiru Chen,Haneen Mohammed,Zezhou Huang*

Main category: cs.DB

TL;DR: HDI系统与传统数据管理不同，需满足基于可用性而非查询语义的延迟、正确性和一致性需求。界面与系统紧密耦合，需要协同设计，这为系统创新和数据库理论启发新交互设计提供了机会。


<details>
  <summary>Details</summary>
Motivation: HDI面临与传统数据管理不同的挑战，需要满足基于用户体验的延迟、正确性和一致性需求，界面与系统的紧密耦合要求协同设计。

Method: 通过调查实验室十年工作，采用界面与系统协同设计的方法，将系统创新和数据库理论应用于交互和可视化设计。

Result: HDI系统成为可靠、交互式、AI驱动应用的基础，系统创新能够启发新的交互设计。

Conclusion: HDI系统是可靠交互式AI应用的基础，界面与系统的协同设计至关重要，系统创新可以反过来启发新的交互范式。

Abstract: Human-data interaction (HDI) presents fundamentally different challenges from traditional data management. HDI systems must meet latency, correctness, and consistency needs that stem from usability rather than query semantics; failing to meet these expectations breaks the user experience. Moreover, interfaces and systems are tightly coupled; neither can easily be optimized in isolation, and effective solutions demand their co-design. This dependence also presents a research opportunity: rather than adapt systems to interface demands, systems innovations and database theory can also inspire new interaction and visualization designs. We survey a decade of our lab's work that embraces this coupling and argue that HDI systems are the foundation for reliable, interactive, AI-driven applications.

</details>


### [5] [Sufficient Explanations in Databases and their Connections to Necessary Explanations and Repairs](https://arxiv.org/abs/2511.15623)
*Leopoldo Bertossi,Nina Pardal*

Main category: cs.DB

TL;DR: 本文探讨了充分解释概念在关系数据库中的应用，及其与数据库修复和因果解释的联系。


<details>
  <summary>Details</summary>
Motivation: 将Halpern和Pearl形式化的因果概念应用于关系数据库，以表征和计算查询答案的因果解释。

Method: 研究充分解释与数据库修复（用于处理不一致数据库）以及基于因果的必要解释之间的联系。

Result: 获得了一些计算性结果。

Conclusion: 充分解释为数据库查询答案提供了一种替代的因果解释框架，并与现有方法建立了理论联系。

Abstract: The notion of cause, as formalized by Halpern and Pearl, has been recently applied to relational databases, to characterize and compute causal explanations for query answers. In this work we consider the alternative notion of sufficient explanation. We investigate its connections with database repairs as used for dealing with inconsistent databases, and with causality-based necessary explanations. We also obtain some computational results.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [6] [Membership Inference Attack against Large Language Model-based Recommendation Systems: A New Distillation-based Paradigm](https://arxiv.org/abs/2511.14763)
*Li Cuihong,Huang Xiaowen,Yin Chuanhuan,Sang Jitao*

Main category: cs.IR

TL;DR: 提出了一种基于知识蒸馏的成员推理攻击范式，用于提升对LLM推荐系统的攻击性能，通过知识蒸馏获得参考模型来增强区分成员和非成员数据的能力。


<details>
  <summary>Details</summary>
Motivation: 传统MIA通过影子模型获取目标模型特征，但LLM推荐系统的训练数据规模和复杂性使得影子模型难以构建，知识蒸馏有助于构建更强的参考模型。

Method: 引入知识蒸馏获得参考模型，在蒸馏过程中分别对成员和非成员数据进行蒸馏，增强模型区分能力，从参考模型获取个体特征并用融合特征训练攻击模型。

Result: 相比基于影子模型的攻击，该范式提高了MIA的攻击性能。

Conclusion: 基于知识蒸馏的MIA范式能够有效提升对LLM推荐系统的成员推理攻击效果。

Abstract: Membership Inference Attack (MIA) aims to determine if a data sample is used in the training dataset of a target model. Traditional MIA obtains feature of target model via shadow models and uses the feature to train attack model, but the scale and complexity of training or fine-tuning data for large language model (LLM)-based recommendation systems make shadow models difficult to construct. Knowledge distillation as a method for extracting knowledge contributes to construct a stronger reference model. Knowledge distillation enables separate distillation for member and non-member data during the distillation process, enhancing the model's discriminative capability between the two in MIA. This paper propose a knowledge distillation-based MIA paradigm to improve the performance of membership inference attacks on LLM-based recommendation systems. Our paradigm introduces knowledge distillation to obtain a reference model, which enhances the reference model's ability to distinguish between member and non-member data. We obtain individual features from the reference model and train our attack model with fused feature. Our paradigm improves the attack performance of MIA compared to shadow model-based attack.

</details>


### [7] [Image-Seeking Intent Prediction for Cross-Device Product Search](https://arxiv.org/abs/2511.14764)
*Mariya Hendriksen,Svitlana Vakulenko,Jordan Massiah,Gabriella Kazai,Emine Yilmaz*

Main category: cs.IR

TL;DR: 提出图像搜索意图预测任务，使用LLM预测何时语音查询需要视觉增强并触发跨设备切换，通过结合查询语义和产品数据提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 解决多设备购物场景中，预测何时语音查询需要视觉增强并主动切换到屏幕设备的问题，以提升用户体验并减少不必要的干扰。

Method: 开发IRP模型，利用90万条语音查询、相关产品检索和图像轮播参与度等行为信号，结合查询语义和产品元数据进行视觉意图预测，采用轻量级摘要和可微分精度导向损失函数。

Result: 实验表明，结合查询语义和产品数据（特别是通过轻量级摘要改进后）能持续提高预测准确性，可微分精度导向损失进一步减少误报。

Conclusion: LLM有潜力驱动智能跨设备购物助手，预测并适应用户需求，实现更无缝和个性化的电商体验。

Abstract: Large Language Models (LLMs) are transforming personalized search, recommendations, and customer interaction in e-commerce. Customers increasingly shop across multiple devices, from voice-only assistants to multimodal displays, each offering different input and output capabilities. A proactive suggestion to switch devices can greatly improve the user experience, but it must be offered with high precision to avoid unnecessary friction. We address the challenge of predicting when a query requires visual augmentation and a cross-device switch to improve product discovery. We introduce Image-Seeking Intent Prediction, a novel task for LLM-driven e-commerce assistants that anticipates when a spoken product query should proactively trigger a visual on a screen-enabled device. Using large-scale production data from a multi-device retail assistant, including 900K voice queries, associated product retrievals, and behavioral signals such as image carousel engagement, we train IRP (Image Request Predictor), a model that leverages user input query and corresponding retrieved product metadata to anticipate visual intent. Our experiments show that combining query semantics with product data, particularly when improved through lightweight summarization, consistently improves prediction accuracy. Incorporating a differentiable precision-oriented loss further reduces false positives. These results highlight the potential of LLMs to power intelligent, cross-device shopping assistants that anticipate and adapt to user needs, enabling more seamless and personalized e-commerce experiences.

</details>


### [8] [Optimizing Agricultural Research: A RAG-Based Approach to Mycorrhizal Fungi Information](https://arxiv.org/abs/2511.14765)
*Mohammad Usman Altam,Md Imtiaz Habib,Tuan Hoang*

Main category: cs.IR

TL;DR: 本文开发了一个针对Mycophyto的检索增强生成(RAG)系统，专注于丛枝菌根真菌(AMF)的农业应用，通过动态整合领域知识来提升回答的准确性和事实可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型受限于静态训练语料，无法处理时效性和专业领域知识。RAG系统能够动态整合外部知识源，克服时间和学科限制，为可持续农业中的AMF应用提供准确支持。

Method: 采用双层策略：(1)使用向量嵌入从农学和生物技术语料库中进行语义检索和增强；(2)结构化数据提取，捕获预定义的实验元数据(如接种方法、孢子密度、土壤参数等)。嵌入存储在高效向量数据库中，支持近实时检索。

Result: 实证评估表明，该管道能够检索和合成关于AMF与作物系统(如番茄)相互作用的高度相关信息，生成的回答不仅语义对齐，还得到结构化实验证据的支持。

Conclusion: 该框架强调了AI驱动知识发现在加速农业生态创新和增强可持续农业系统决策方面的潜力，为农业应用提供了可扩展的知识发现解决方案。

Abstract: Retrieval-Augmented Generation (RAG) represents a transformative approach within natural language processing (NLP), combining neural information retrieval with generative language modeling to enhance both contextual accuracy and factual reliability of responses. Unlike conventional Large Language Models (LLMs), which are constrained by static training corpora, RAG-powered systems dynamically integrate domain-specific external knowledge sources, thereby overcoming temporal and disciplinary limitations. In this study, we present the design and evaluation of a RAG-enabled system tailored for Mycophyto, with a focus on advancing agricultural applications related to arbuscular mycorrhizal fungi (AMF). These fungi play a critical role in sustainable agriculture by enhancing nutrient acquisition, improving plant resilience under abiotic and biotic stresses, and contributing to soil health. Our system operationalizes a dual-layered strategy: (i) semantic retrieval and augmentation of domain-specific content from agronomy and biotechnology corpora using vector embeddings, and (ii) structured data extraction to capture predefined experimental metadata such as inoculation methods, spore densities, soil parameters, and yield outcomes. This hybrid approach ensures that generated responses are not only semantically aligned but also supported by structured experimental evidence. To support scalability, embeddings are stored in a high-performance vector database, allowing near real-time retrieval from an evolving literature base. Empirical evaluation demonstrates that the proposed pipeline retrieves and synthesizes highly relevant information regarding AMF interactions with crop systems, such as tomato (Solanum lycopersicum). The framework underscores the potential of AI-driven knowledge discovery to accelerate agroecological innovation and enhance decision-making in sustainable farming systems.

</details>


### [9] [OTCR: Optimal Transmission, Compression and Representation for Multimodal Information Extraction](https://arxiv.org/abs/2511.14766)
*Yang Li,Yajiao Wang,Wenhao Hu,Zhixiong Zhang,Mengting Zhang*

Main category: cs.IR

TL;DR: OTCR是一个两阶段多模态信息提取框架，通过跨模态最优传输实现文本主导的视觉选择性支持，并使用变分信息瓶颈压缩特征以减少任务无关噪声。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设模态等价或统一处理多模态信息，导致多模态信号的无差别融合和任务无关冗余，限制了泛化能力。需要从任务中心视角重新审视多模态信息提取。

Method: 1. 跨模态最优传输：生成文本标记与视觉补丁之间的稀疏概率对齐，通过上下文感知门控制视觉注入；2. 变分信息瓶颈：压缩融合特征，过滤任务无关噪声，生成紧凑的任务自适应表示。

Result: 在FUNSD数据集上达到91.95% SER和91.13% RE，在XFUND(ZH)数据集上达到91.09% SER和94.20% RE，表现出跨数据集的竞争性能。特征分析证实减少了模态冗余并增强了任务信号。

Conclusion: 这项工作为文档AI中的可控多模态融合提供了一个可解释的、信息论驱动的范式，强调文本主导、视觉选择性支持的原则。

Abstract: Multimodal Information Extraction (MIE) requires fusing text and visual cues from visually rich documents. While recent methods have advanced multimodal representation learning, most implicitly assume modality equivalence or treat modalities in a largely uniform manner, still relying on generic fusion paradigms. This often results in indiscriminate incorporation of multimodal signals and insufficient control over task-irrelevant redundancy, which may in turn limit generalization. We revisit MIE from a task-centric view: text should dominate, vision should selectively support. We present OTCR, a two-stage framework. First, Cross-modal Optimal Transport (OT) yields sparse, probabilistic alignments between text tokens and visual patches, with a context-aware gate controlling visual injection. Second, a Variational Information Bottleneck (VIB) compresses fused features, filtering task-irrelevant noise to produce compact, task-adaptive representations. On FUNSD, OTCR achieves 91.95% SER and 91.13% RE, while on XFUND (ZH), it reaches 91.09% SER and 94.20% RE, demonstrating competitive performance across datasets. Feature-level analyses further confirm reduced modality redundancy and strengthened task signals. This work offers an interpretable, information-theoretic paradigm for controllable multimodal fusion in document AI.

</details>


### [10] [An LLM-Powered Agent for Real-Time Analysis of the Vietnamese IT Job Market](https://arxiv.org/abs/2511.14767)
*Minh-Thuan Nguyen,Thien Vo-Thanh,Thai-Duy Dinh,Xuan-Quang Phan,Tan-Ha Mai,Lam-Son Lê*

Main category: cs.IR

TL;DR: 开发了一个基于AI的越南IT就业市场咨询系统，通过自动化爬取和分析数千个职位信息，为求职者提供实时、数据驱动的职业指导。


<details>
  <summary>Details</summary>
Motivation: 解决越南IT就业市场缺乏可靠职业指导的问题，现有市场报告过时且手动分析大量职位信息不切实际。

Method: 构建自动化数据采集管道，使用Playwright爬取职位门户网站，利用LLM结构化非结构化数据，基于ReAct代理框架开发工具增强的AI代理系统，支持SQL查询、语义搜索和数据可视化。

Result: 成功收集和分析3,745个职位信息，系统能够回答复杂多步骤查询、生成按需可视化图表，并提供基于真实数据的个性化职业建议。

Conclusion: 该工作引入了劳动力市场分析的新范式，展示了专业化的AI代理系统如何为新一代专业人士提供及时、可信的职业智能服务。

Abstract: Individuals entering Vietnam's dynamic Information Technology (IT) job market face a critical gap in reliable career guidance. Existing market reports are often outdated, while the manual analysis of thousands of job postings is impractical for most. To address this challenge, we present the AI Job Market Consultant, a novel conversational agent that delivers deep, data-driven insights directly from the labor market in real-time. The foundation of our system is a custom-built dataset created via an automated pipeline that crawls job portals using Playwright and leverages the Large Language Model (LLM) to intelligently structure unstructured posting data. The core of our system is a tool-augmented AI agent, based on the ReAct agentic framework, which enables the ability of autonomously reasoning, planning, and executing actions through a specialized toolbox for SQL queries, semantic search, and data visualization. Our prototype successfully collected and analyzed 3,745 job postings, demonstrating its ability to answer complex, multi-step queries, generate on-demand visualizations, and provide personalized career advice grounded in real-world data. This work introduces a new paradigm for labor market analysis, showcasing how specialized agentic AI systems can democratize access to timely, trustworthy career intelligence for the next generation of professionals.

</details>


### [11] [Causally-Informed Reinforcement Learning for Adaptive Emotion-Aware Social Media Recommendation](https://arxiv.org/abs/2511.14768)
*Bhavika Jain,Robert Pitsko,Ananya Drishti,Mahfuza Farooque*

Main category: cs.IR

TL;DR: 提出了ESMR框架，通过Transformer预测用户情绪轨迹，结合LightGBM和强化学习实现情感感知的社交媒体推荐，在保持参与度的同时改善用户情绪恢复。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统仅优化参与度指标，忽略用户情绪状态，长期接触情绪化内容会对用户情感健康产生负面影响。

Method: 使用Transformer预测用户情绪轨迹，结合LightGBM处理稳定期推荐和基于因果推理奖励的强化学习处理负面情绪持续期。

Result: 在30天交互轨迹评估中，ESMR显示出改善的情绪恢复、减少的情绪波动和强大的参与度保持能力。

Conclusion: ESMR提供了一条在不影响参与度性能的前提下实现情感感知推荐的路径。

Abstract: Social media recommendation systems play a central role in shaping users' emotional experiences. However, most systems are optimized solely for engagement metrics, such as click rate, viewing time, or scrolling, without accounting for users' emotional states. Repeated exposure to emotionally charged content has been shown to negatively affect users' emotional well-being over time. We propose an Emotion-aware Social Media Recommendation (ESMR) framework that personalizes content based on users' evolving emotional trajectories. ESMR integrates a Transformer-based emotion predictor with a hybrid recommendation policy: a LightGBM model for engagement during stable periods and a reinforcement learning agent with causally informed rewards when negative emotional states persist. Through behaviorally grounded evaluation over 30-day interaction traces, ESMR demonstrates improved emotional recovery, reduced volatility, and strong engagement retention. ESMR offers a path toward emotionally aware recommendations without compromising engagement performance.

</details>


### [12] [Cluster-based Adaptive Retrieval: Dynamic Context Selection for RAG Applications](https://arxiv.org/abs/2511.14769)
*Yifan Xu,Vipul Gupta,Rohit Aggarwal,Varsha Mahadevan,Bhaskar Krishnamachari*

Main category: cs.IR

TL;DR: CAR算法通过分析查询-文档相似度距离的聚类模式，动态确定最佳检索文档数量，显著提升RAG系统性能。


<details>
  <summary>Details</summary>
Motivation: 传统的静态top-k检索方法无法适应不同查询特性：窄范围查询需要少量高相关文档，而宽泛查询需要更多支持信息。静态方法导致要么上下文不足，要么信息冗余。

Method: 提出基于聚类的自适应检索(CAR)算法，通过分析有序查询-文档相似度距离中的聚类模式，检测高相关文档向低相关文档的过渡点，建立自适应截断机制。

Result: 在Coinbase CDP语料库和MultiHop-RAG基准测试中，CAR始终选择最优检索深度，获得最高TES分数，优于所有固定top-k基线。下游RAG评估显示：LLM令牌使用减少60%，端到端延迟降低22%，幻觉减少10%，同时完全保持答案相关性。

Conclusion: CAR算法能有效适应查询复杂性，显著提升RAG系统效率和准确性。在Coinbase虚拟助手中集成CAR后，用户参与度提升了200%。

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by pulling in external material, document, code, manuals, from vast and ever-growing corpora, to effectively answer user queries. The effectiveness of RAG depends significantly on aligning the number of retrieved documents with query characteristics: narrowly focused queries typically require fewer, highly relevant documents, whereas broader or ambiguous queries benefit from retrieving more extensive supporting information. However, the common static top-k retrieval approach fails to adapt to this variability, resulting in either insufficient context from too few documents or redundant information from too many. Motivated by these challenges, we introduce Cluster-based Adaptive Retrieval (CAR), an algorithm that dynamically determines the optimal number of documents by analyzing the clustering patterns of ordered query-document similarity distances. CAR detects the transition point within similarity distances, where tightly clustered, highly relevant documents shift toward less pertinent candidates, establishing an adaptive cut-off that scales with query complexity. On Coinbase's CDP corpus and the public MultiHop-RAG benchmark, CAR consistently picks the optimal retrieval depth and achieves the highest TES score, outperforming every fixed top-k baseline. In downstream RAG evaluations, CAR cuts LLM token usage by 60%, trims end-to-end latency by 22%, and reduces hallucinations by 10% while fully preserving answer relevance. Since integrating CAR into Coinbase's virtual assistant, we've seen user engagement jump by 200%.

</details>


### [13] [ExplainRec: Towards Explainable Multi-Modal Zero-Shot Recommendation with Preference Attribution and Large Language Models](https://arxiv.org/abs/2511.14770)
*Bo Ma,LuYao Liu,ZeHua Hu,Simon Lau*

Main category: cs.IR

TL;DR: ExplainRec是一个基于大语言模型的推荐框架，通过偏好归因、多模态融合和零样本迁移学习提升推荐系统的可解释性和冷启动处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐方法如TALLRec在可解释性和冷启动场景面临挑战，需要开发能够生成解释性推荐并有效处理冷启动问题的框架。

Method: 提出偏好归因调优、零样本偏好迁移、多模态增强和多任务协同优化四个技术贡献，融合视觉和文本内容。

Result: 在MovieLens-25M和Amazon数据集上实验表明，ExplainRec在电影推荐任务上AUC提升0.7%，跨域任务提升0.9%，能生成可解释推荐并有效处理冷启动场景。

Conclusion: ExplainRec框架通过整合多种技术显著提升了LLM推荐系统的性能、可解释性和冷启动处理能力。

Abstract: Recent advances in Large Language Models (LLMs) have opened new possibilities for recommendation systems, though current approaches such as TALLRec face challenges in explainability and cold-start scenarios. We present ExplainRec, a framework that extends LLM-based recommendation capabilities through preference attribution, multi-modal fusion, and zero-shot transfer learning. The framework incorporates four technical contributions: preference attribution tuning for explainable recommendations, zero-shot preference transfer for cold-start users and items, multi-modal enhancement leveraging visual and textual content, and multi-task collaborative optimization. Experimental evaluation on MovieLens-25M and Amazon datasets shows that ExplainRec outperforms existing methods, achieving AUC improvements of 0.7\% on movie recommendation and 0.9\% on cross-domain tasks, while generating interpretable explanations and handling cold-start scenarios effectively.

</details>


### [14] [SilverTorch: A Unified Model-based System to Democratize Large-Scale Recommendation on GPUs](https://arxiv.org/abs/2511.14881)
*Bi Xue,Hong Wu,Lei Chen,Chao Yang,Yiming Ma,Fei Ding,Zhen Wang,Liang Wang,Xiaoheng Mao,Ke Huang,Xialu Li,Peng Xia,Rui Jian,Yanli Zhao,Yanzun Huang,Yijie Deng,Harry Tran,Ryan Chang,Min Yu,Eric Dong,Jiazhou Wang,Qianqian Zhang,Keke Zhai,Hongzhang Yin,Pawel Garbacki,Zheng Fang,Yiyi Pan,Min Ni,Yang Liu*

Main category: cs.IR

TL;DR: SilverTorch是一个基于GPU的推荐模型服务系统，通过统一模型服务、GPU上的Bloom索引算法和Int8 ANN内核，显著提升了推荐服务的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于CPU的ANN索引和过滤服务存在显著成本问题，且无法支持更复杂的模型架构，如学习相似性和多任务检索。

Method: 提出SilverTorch系统，用模型层替代独立的索引和过滤服务，包括GPU上的Bloom索引算法、Int8 ANN内核，以及共同设计ANN搜索索引和过滤索引以减少GPU内存使用。

Result: 在工业规模数据集上，SilverTorch实现了比现有方法低5.6倍的延迟和高23.7倍的吞吐量，成本效率比基于CPU的解决方案高13.35倍。

Conclusion: SilverTorch通过GPU统一服务范式，提高了检索准确性，并为服务更复杂模型提供了基础，已在主要产品中服务数百个模型，为数十亿日活用户推荐内容。

Abstract: Serving deep learning based recommendation models (DLRM) at scale is challenging. Existing systems rely on CPU-based ANN indexing and filtering services, suffering from non-negligible costs and forgoing joint optimization opportunities. Such inefficiency makes them difficult to support more complex model architectures, such as learned similarities and multi-task retrieval.
  In this paper, we propose SilverTorch, a model-based system for serving recommendation models on GPUs. SilverTorch unifies model serving by replacing standalone indexing and filtering services with layers of served models. We propose a Bloom index algorithm on GPUs for feature filtering and a tensor-native fused Int8 ANN kernel on GPUs for nearest neighbor search. We further co-design the ANN search index and filtering index to reduce GPU memory utilization and eliminate unnecessary computation. Benefit from SilverTorch's serving paradigm, we introduce a OverArch scoring layer and a Value Model to aggregate results across multi-tasks. These advancements improve the accuracy for retrieval and enable future studies for serving more complex models. For ranking, SilverTorch's design accelerates item embedding calculation by caching the pre-calculated embeddings inside the serving model.
  Our evaluation on the industry-scale datasets show that SilverTorch achieves up to 5.6x lower latency and 23.7x higher throughput compared to the state-of-the-art approaches. We also demonstrate that SilverTorch's solution is 13.35x more cost-efficient than CPU-based solution while improving accuracy via serving more complex models. SilverTorch serves over hundreds of models online across major products and recommends contents for billions of daily active users.

</details>


### [15] [Multi-Aspect Cross-modal Quantization for Generative Recommendation](https://arxiv.org/abs/2511.15122)
*Fuwei Zhang,Xiaoyu Liu,Dongbo Xi,Jishen Yin,Huan Chen,Peng Yan,Fuzhen Zhuang,Zhao Zhang*

Main category: cs.IR

TL;DR: 提出MACRec方法，通过多模态交叉量化改进生成式推荐系统，降低冲突率并增强生成能力


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐方法在利用多模态信息和捕捉深度跨模态交互方面存在局限，影响语义ID质量和模型训练效果

Method: 引入跨模态量化减少冲突率，结合隐式和显式多模态对齐增强生成能力

Result: 在三个知名推荐数据集上的实验验证了方法的有效性

Conclusion: MACRec通过多模态交叉量化和多角度对齐，显著提升了生成式推荐的性能

Abstract: Generative Recommendation (GR) has emerged as a new paradigm in recommender systems. This approach relies on quantized representations to discretize item features, modeling users' historical interactions as sequences of discrete tokens. Based on these tokenized sequences, GR predicts the next item by employing next-token prediction methods. The challenges of GR lie in constructing high-quality semantic identifiers (IDs) that are hierarchically organized, minimally conflicting, and conducive to effective generative model training. However, current approaches remain limited in their ability to harness multimodal information and to capture the deep and intricate interactions among diverse modalities, both of which are essential for learning high-quality semantic IDs and for effectively training GR models. To address this, we propose Multi-Aspect Cross-modal quantization for generative Recommendation (MACRec), which introduces multimodal information and incorporates it into both semantic ID learning and generative model training from different aspects. Specifically, we first introduce cross-modal quantization during the ID learning process, which effectively reduces conflict rates and thus improves codebook usability through the complementary integration of multimodal information. In addition, to further enhance the generative ability of our GR model, we incorporate multi-aspect cross-modal alignments, including the implicit and explicit alignments. Finally, we conduct extensive experiments on three well-known recommendation datasets to demonstrate the effectiveness of our proposed method.

</details>


### [16] [ItemRAG: Item-Based Retrieval-Augmented Generation for LLM-Based Recommendation](https://arxiv.org/abs/2511.15141)
*Sunwoo Kim,Geon Lee,Kyungho Kim,Jaemin Yoo,Kijung Shin*

Main category: cs.IR

TL;DR: 提出ItemRAG方法，基于物品-物品共同购买历史检索相关物品来增强LLM推荐系统，相比基于用户的RAG方法在标准推荐和冷启动物品推荐中表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法主要基于用户相似性检索，而物品间的共同购买模式对推荐系统也很重要，特别是对于冷启动物品的处理。

Method: 开发ItemRAG方法，从物品-物品共同购买历史中检索相关物品，结合语义相似性和共同购买频率来改进检索质量。

Result: 实验显示ItemRAG将零样本LLM推荐器的Hit-Ratio-1提升高达43%，在标准推荐和冷启动物品推荐中都优于基于用户的RAG基线方法。

Conclusion: 基于物品的RAG方法能有效捕捉物品间的共同购买模式，显著提升LLM推荐系统的性能，特别是在处理冷启动物品方面具有优势。

Abstract: Recently, large language models (LLMs) have been widely used as recommender systems, owing to their strong reasoning capability and their effectiveness in handling cold-start items. To better adapt LLMs for recommendation, retrieval-augmented generation (RAG) has been incorporated. Most existing RAG methods are user-based, retrieving purchase patterns of users similar to the target user and providing them to the LLM. In this work, we propose ItemRAG, an item-based RAG method for LLM-based recommendation that retrieves relevant items (rather than users) from item-item co-purchase histories. ItemRAG helps LLMs capture co-purchase patterns among items, which are beneficial for recommendations. Especially, our retrieval strategy incorporates semantically similar items to better handle cold-start items and uses co-purchase frequencies to improve the relevance of the retrieved items. Through extensive experiments, we demonstrate that ItemRAG consistently (1) improves the zero-shot LLM-based recommender by up to 43% in Hit-Ratio-1 and (2) outperforms user-based RAG baselines under both standard and cold-start item recommendation settings.

</details>


### [17] [Selective Mixup for Debiasing Question Selection in Computerized Adaptive Testing](https://arxiv.org/abs/2511.15241)
*Mi Tian,Kun Zhang,Fei Liu,Jinglong Li,Yuxin Liao,Chenxi Bai,Zhengtao Tan,Le Wu,Richang Hong*

Main category: cs.IR

TL;DR: 本文提出了一个用于计算机自适应测试(CAT)的去偏框架，通过交叉属性考生检索和选择性Mixup正则化来解决自适应过程中的选择偏差问题，显著提升了诊断模型的泛化能力和公平性。


<details>
  <summary>Details</summary>
Motivation: 现有的CAT方法主要关注提高诊断准确性，但忽略了自适应过程中的选择偏差问题。这种偏差源于问题选择强烈依赖于估计的熟练度，导致偏差在迭代更新中传播和放大，造成预测偏差和对齐错误。此外，学习者历史交互的不平衡性进一步加剧了诊断模型的偏差。

Method: 提出的去偏框架包含两个关键模块：1) 交叉属性考生检索 - 检索具有相对均匀的正确和错误回答分布的平衡考生，作为有偏考生的中性参考；2) 选择性Mixup正则化 - 在每个有偏考生与其匹配的平衡对应者之间应用mixup，在标签一致性下进行数据增强，丰富偏差冲突样本的多样性并平滑选择边界。

Result: 在两个基准数据集上使用多个先进诊断模型进行的广泛实验表明，该方法显著提高了CAT中问题选择的泛化能力和公平性。

Conclusion: 该研究成功解决了CAT中的选择偏差问题，提出的去偏框架通过平衡参考和mixup正则化有效缓解了偏差传播，为在线教育平台提供了更公平和准确的个性化学习者建模方法。

Abstract: Computerized Adaptive Testing (CAT) is a widely used technology for evaluating learners' proficiency in online education platforms. By leveraging prior estimates of proficiency to select questions and updating the estimates iteratively based on responses, CAT enables personalized learner modeling and has attracted substantial attention. Despite this progress, most existing works focus primarily on improving diagnostic accuracy, while overlooking the selection bias inherent in the adaptive process. Selection Bias arises because the question selection is strongly influenced by the estimated proficiency, such as assigning easier questions to learners with lower proficiency and harder ones to learners with higher proficiency. Since the selection depends on prior estimation, this bias propagates into the diagnosis model, which is further amplified during iterative updates, leading to misalignment and biased predictions. Moreover, the imbalanced nature of learners' historical interactions often exacerbates the bias in diagnosis models. To address this issue, we propose a debiasing framework consisting of two key modules: Cross-Attribute Examinee Retrieval and Selective Mixup-based Regularization. First, we retrieve balanced examinees with relatively even distributions of correct and incorrect responses and use them as neutral references for biased examinees. Then, mixup is applied between each biased examinee and its matched balanced counterpart under label consistency. This augmentation enriches the diversity of bias-conflicting samples and smooths selection boundaries. Finally, extensive experiments on two benchmark datasets with multiple advanced diagnosis models demonstrate that our method substantially improves both the generalization ability and fairness of question selection in CAT.

</details>


### [18] [Unveiling Inference Scaling for Difference-Aware User Modeling in LLM Personalization](https://arxiv.org/abs/2511.15389)
*Suyu Chen,Yimeng Bai,Yulong Huang,Xiaoyan Zhao,Yang Zhang*

Main category: cs.IR

TL;DR: 提出了DRP框架，通过推理扩展重构差异提取机制，利用系统2思维进行用户差异推理，在个性化评论生成任务中优于基线方法


<details>
  <summary>Details</summary>
Motivation: 现有个性化方法主要依赖用户自身历史，忽略了用户间差异，且特征提取过程通常基于固定维度和快速直觉推理，限制了用户差异的覆盖范围和粒度

Method: DRP框架自主识别相关差异特征维度，生成结构化定义和描述，利用系统2思维对用户差异进行缓慢、深思熟虑的推理

Result: 在个性化评论生成任务上的实验表明，DRP在多个指标上持续优于基线方法

Conclusion: DRP通过重构差异提取机制，利用推理扩展增强LLM个性化能力，在建模用户差异方面取得显著改进

Abstract: Large Language Models (LLMs) are increasingly integrated into users' daily lives, driving a growing demand for personalized outputs. Prior work has primarily leveraged a user's own history, often overlooking inter-user differences that are critical for effective personalization. While recent methods have attempted to model such differences, their feature extraction processes typically rely on fixed dimensions and quick, intuitive inference (System-1 thinking), limiting both the coverage and granularity of captured user differences. To address these limitations, we propose Difference-aware Reasoning Personalization (DRP), a framework that reconstructs the difference extraction mechanism by leveraging inference scaling to enhance LLM personalization. DRP autonomously identifies relevant difference feature dimensions and generates structured definitions and descriptions, enabling slow, deliberate reasoning (System-2 thinking) over user differences. Experiments on personalized review generation demonstrate that DRP consistently outperforms baseline methods across multiple metrics.

</details>


### [19] [CroPS: Improving Dense Retrieval with Cross-Perspective Positive Samples in Short-Video Search](https://arxiv.org/abs/2511.15443)
*Ao Xie,Jiahui Chen,Quanzhi Zhu,Xiaoze Jiang,Zhiheng Qin,Enyun Yu,Han Li*

Main category: cs.IR

TL;DR: CroPS是一个新颖的检索数据引擎，通过引入多视角的多样化正样本来缓解传统训练中的过滤气泡效应，在快手搜索平台上显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 传统工业检索系统采用自增强训练范式，依赖历史用户交互数据进行监督，这会导致过滤气泡效应，排除潜在相关但未见过的内容，使模型偏向狭隘和保守的检索。

Method: CroPS从三个层面引入多样化正样本：用户查询重构行为（查询级）、推荐流中的互动数据（系统级）、以及大语言模型合成的世界知识（知识级）。采用分层标签分配策略和相应的H-InfoNCE损失函数进行细粒度优化。

Result: 在快手搜索平台上的大量实验表明，CroPS在线下和线上A/B测试中都显著优于强基线，实现了更优的检索性能并降低了查询重构率。目前已在快手搜索全面部署，每日服务数亿用户。

Conclusion: CroPS通过多视角正样本增强训练，有效缓解了过滤气泡问题，显著提升了密集检索系统的性能，证明了多样化训练信号在工业搜索系统中的重要性。

Abstract: Dense retrieval has become a foundational paradigm in modern search systems, especially on short-video platforms. However, most industrial systems adopt a self-reinforcing training pipeline that relies on historically exposed user interactions for supervision. This paradigm inevitably leads to a filter bubble effect, where potentially relevant but previously unseen content is excluded from the training signal, biasing the model toward narrow and conservative retrieval. In this paper, we present CroPS (Cross-Perspective Positive Samples), a novel retrieval data engine designed to alleviate this problem by introducing diverse and semantically meaningful positive examples from multiple perspectives. CroPS enhances training with positive signals derived from user query reformulation behavior (query-level), engagement data in recommendation streams (system-level), and world knowledge synthesized by large language models (knowledge-level). To effectively utilize these heterogeneous signals, we introduce a Hierarchical Label Assignment (HLA) strategy and a corresponding H-InfoNCE loss that together enable fine-grained, relevance-aware optimization. Extensive experiments conducted on Kuaishou Search, a large-scale commercial short-video search platform, demonstrate that CroPS significantly outperforms strong baselines both offline and in live A/B tests, achieving superior retrieval performance and reducing query reformulation rates. CroPS is now fully deployed in Kuaishou Search, serving hundreds of millions of users daily.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [20] [Exact Learning of Weighted Graphs Using Composite Queries](https://arxiv.org/abs/2511.14882)
*Michael T. Goodrich,Songyu Liu,Ioannis Panageas*

Main category: cs.DS

TL;DR: 研究加权图的精确学习问题，通过组合查询以亚二次方查询次数重建图结构


<details>
  <summary>Details</summary>
Motivation: 单纯使用最短路径长度查询不足以学习加权图，需要探索更高效的查询方法

Method: 使用组合查询（结合2-3个简单查询）来学习图结构，避免使用二次方数量的简单查询

Result: 在多个场景下能够以亚二次方数量的组合查询成功学习加权图

Conclusion: 组合查询方法可以有效解决加权图重建问题，相比简单查询具有更好的效率

Abstract: In this paper, we study the exact learning problem for weighted graphs, where we are given the vertex set, $V$, of a weighted graph, $G=(V,E,w)$, but we are not given $E$. The problem, which is also known as graph reconstruction, is to determine all the edges of $E$, including their weights, by asking queries about $G$ from an oracle. As we observe, using simple shortest-path length queries is not sufficient, in general, to learn a weighted graph. So we study a number of scenarios where it is possible to learn $G$ using a subquadratic number of composite queries, which combine two or three simple queries.

</details>


### [21] [Intermediate N-Gramming: Deterministic and Fast N-Grams For Large N and Large Datasets](https://arxiv.org/abs/2511.14955)
*Ryan R. Curtin,Fred Lu,Edward Raff,Priyanka Ranade*

Main category: cs.DS

TL;DR: 提出了一种名为Intergrams的多遍算法，用于快速、准确地恢复前k个最频繁的n-gram，相比现有最快算法实现了高达33倍的加速。


<details>
  <summary>Details</summary>
Motivation: 基于生产机器学习系统中n-gram特征的实际需求，解决n-gram特征数量随n指数增长带来的计算挑战，特别是当n小至3时计算最频繁n-gram的计算需求。

Method: 设计了一个多遍算法Intergrams，从前面的(n-1)-gram构建候选n-gram，并针对硬件特性进行优化设计。

Result: 相比已知最快算法实现了超过一个数量级的加速（最高达33倍），即使对其他算法应用类似优化也是如此。

Conclusion: 通过利用n-gram的经验幂律分布，为多遍方法的有效性提供了理论依据，证明该方法能够高效解决大规模n-gram频率计算问题。

Abstract: The number of n-gram features grows exponentially in n, making it computationally demanding to compute the most frequent n-grams even for n as small as 3. Motivated by our production machine learning system built on n-gram features, we ask: is it possible to accurately, deterministically, and quickly recover the top-k most frequent n-grams? We devise a multi-pass algorithm called Intergrams that constructs candidate n-grams from the preceding (n - 1)-grams. By designing this algorithm with hardware in mind, our approach yields more than an order of magnitude speedup (up to 33x!) over the next known fastest algorithm, even when similar optimizations are applied to the other algorithm. Using the empirical power-law distribution over n-grams, we also provide theory to inform the efficacy of our multi-pass approach. Our code is available at https://github.com/rcurtin/Intergrams.

</details>


### [22] [A Dichotomy for 1-Planarity with Restricted Crossing Types Parameterized by Treewidth](https://arxiv.org/abs/2511.14975)
*Sergio Cabello,Alexander Dobler,Gašper Fijavž,Thekla Hamm,Mirko H. Wagner*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A drawing of a graph is 1-planar if each edge participates in at most one crossing and adjacent edges do not cross. Up to symmetry, each crossing in a 1-planar drawing belongs to one out of six possible crossing types, where a type characterizes the subgraph induced by the four vertices of the crossing edges. Each of the 63 possible nonempty subsets $\mathcal{S}$ of crossing types gives a recognition problem: does a given graph admit an $\mathcal{S}$-restricted drawing, that is, a 1-planar drawing where the crossing type of each crossing is in $\mathcal{S}$?
  We show that there is a set $\mathcal{S}_{\rm bad}$ with three crossing types and the following properties: If $\mathcal{S}$ contains no crossing type from $\mathcal{S}_{\rm bad}$, then the recognition of graphs that admit an $\mathcal{S}$-restricted drawing is fixed-parameter tractable with respect to the treewidth of the input graph. If $\mathcal{S}$ contains any crossing type from $\mathcal{S}_{\rm bad}$, then it is NP-hard to decide whether a graph has an $\mathcal{S}$-restricted drawing, even when considering graphs of constant pathwidth.
  We also extend this characterization of crossing types to 1-planar straight-line drawings and show the same complexity behaviour parameterized by treewidth.

</details>


### [23] [Combinatorial Optimization using Comparison Oracles](https://arxiv.org/abs/2511.15142)
*Vincent Cohen-Addad,Tommaso d'Orsi,Anupam Gupta,Guru Guruganesh,Euiwoong Lee,Debmalya Panigrahi,Madhusudhan Reddy Pittu,Jon Schneider,David P. Woodruff*

Main category: cs.DS

TL;DR: 本文研究了在线性组合优化问题中使用比较查询模型（而非传统权重向量或值查询）的查询复杂度和算法效率，提出了三个主要贡献：一般查询复杂度界限、基于全局子空间学习的高效算法，以及多个经典组合优化问题的多项式时间低查询算法。


<details>
  <summary>Details</summary>
Motivation: 传统线性组合优化问题依赖权重向量或值查询，本文研究更弱但更鲁棒的比较查询模型，旨在理解计算模型的理论基础，并应对实际应用中常见的成对比较场景。

Method: 采用推理维度框架分析一般查询复杂度，提出全局子空间学习（GSL）框架处理离散整数权重，使用代数技术处理线性拟阵问题，并设计多项式时间算法解决经典组合优化问题。

Result: 证明了任意集合系统的查询复杂度为O(n²)，当权重有界时改进为O(nB log(nB))，并为最小割、最小生成树、二分匹配、最短路径等经典问题提供了首个多项式时间低查询算法。

Conclusion: 该工作为比较查询模型提供了首个一般性查询复杂度界限和高效算法，开辟了基于比较的优化新方向，揭示了信息复杂度和计算复杂度之间的分离。

Abstract: In a linear combinatorial optimization problem, we are given a family $\mathcal{F} \subseteq 2^U$ of feasible subsets of a ground set $U$ of $n$ elements, and aim to find $S^* = \arg\min_{S \in \mathcal{F}} \langle w, \mathbbm{1}_S \rangle$. Traditionally, the weight vector is given, or a value oracle allows evaluating $w(S) := \langle w, \mathbbm{1}_S \rangle$. Motivated by practical interest in pairwise comparisons, and by the theoretical quest to understand computational models, we study a weaker, more robust comparison oracle that for any $S, T \in \mathcal{F}$ reveals only whether $w(S) <, =, > w(T)$. We ask: when can we find $S^*$ using few comparison queries, and when can this be done efficiently?
  We present three contributions: (1) We establish that the query complexity over any set system $\mathcal{F} \subseteq 2^U$ is $\tilde O(n^2)$, using the inference dimension framework, highlighting a separation between information and computational complexity (runtime may still be exponential for NP-hard problems under ETH). (2) We introduce a Global Subspace Learning (GSL) framework for objective functions with discrete integer weights bounded by $B$, giving an algorithm to sort all feasible sets using $O(nB \log(nB))$ queries, improving the $\tilde O(n^2)$ bound when $B = o(n)$. For linear matroids, algebraic techniques yield efficient algorithms for problems including $k$-SUM, SUBSET-SUM, and $A{+}B$ sorting. (3) We give the first polynomial-time, low-query algorithms for classic combinatorial problems: minimum cuts, minimum weight spanning trees (and matroid bases), bipartite matching (and matroid intersection), and shortest $s$-$t$ paths.
  Our work provides the first general query complexity bounds and efficient algorithms for this model, opening new directions for comparison-based optimization.

</details>


### [24] [Dynamic Matroids: Base Packing and Covering](https://arxiv.org/abs/2511.15460)
*Tijn de Vos,Mara Grilnberger*

Main category: cs.DS

TL;DR: 本文研究了动态拟阵问题，提出了维护基、基打包和基覆盖的高效动态算法，包括(1±ε)近似算法，查询复杂度分别为O(Φ·poly(log n, ε⁻¹))和O(β·poly(log n, ε⁻¹))。


<details>
  <summary>Details</summary>
Motivation: 拟阵是组合优化问题的核心结构，研究动态拟阵可以推广多个动态图问题，如树性和最大二分匹配等。

Method: 通过探索基集合（树打包的推广）与基打包和基覆盖之间的关系，提供结构定理来形式化这些连接，并设计简单的动态算法。

Result: 提出了确定性算法：维护基打包数Φ的(1±ε)近似需O(Φ·poly(log n, ε⁻¹))查询；维护基覆盖数β的(1±ε)近似需O(β·poly(log n, ε⁻¹))查询；针对遗忘对手的基覆盖数β近似需O(poly(log n, ε⁻¹))查询。

Conclusion: 这些结果为动态拟阵研究提供了基础构建块，展示了基集合与基打包/覆盖之间的结构联系可以带来高效的动态算法。

Abstract: In this paper, we consider dynamic matroids, where elements can be inserted to or deleted from the ground set over time. The independent sets change to reflect the current ground set. As matroids are central to the study of many combinatorial optimization problems, it is a natural next step to also consider them in a dynamic setting. The study of dynamic matroids has the potential to generalize several dynamic graph problems, including, but not limited to, arboricity and maximum bipartite matching. We contribute by providing efficient algorithms for some fundamental matroid questions.
  In particular, we study the most basic question of maintaining a base dynamically, providing an essential building block for future algorithms. We further utilize this result and consider the elementary problems of base packing and base covering. We provide a deterministic algorithm that maintains a $(1\pm \varepsilon)$-approximation of the base packing number $Φ$ in $O(Φ\cdot \text{poly}(\log n, \varepsilon^{-1}))$ queries per update. Similarly, we provide a deterministic algorithm that maintains a $(1\pm \varepsilon)$-approximation of the base covering number $β$ in $O(β\cdot \text{poly}(\log n, \varepsilon^{-1}))$ queries per update. Moreover, we give an algorithm that maintains a $(1\pm \varepsilon)$-approximation of the base covering number $β$ in $O(\text{poly}(\log n, \varepsilon^{-1}))$ queries per update against an oblivious adversary.
  These results are obtained by exploring the relationship between base collections, a generalization of tree-packings, and base packing and covering respectively. We provide structural theorems to formalize these connections, and show how they lead to simple dynamic algorithms.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [25] [Channel Coding for Gaussian Channels with Multifaceted Power Constraints](https://arxiv.org/abs/2511.14849)
*Adeel Mahmood,Aaron B. Wagner*

Main category: cs.IT

TL;DR: 基于正态近似的渐近结果，研究了高阶编码性能如何依赖于平均功率Γ以及输入功率的精细统计特性。提出了一个多方面的功率模型，约束了归一化平均功率任意函数的期望。该框架推广了现有模型，恢复了标准的最大和期望功率约束以及最近的均值和方差约束作为特例。


<details>
  <summary>Details</summary>
Motivation: 受基于正态近似的精炼渐近结果启发，研究高阶编码性能对平均功率Γ和输入功率精细统计特性的依赖性。

Method: 引入多方面的功率模型，约束归一化平均功率任意函数的期望。该框架推广了现有模型，在特定增长和连续性假设下，主要定理给出了高斯信道最小平均错误概率作为一阶和二阶编码率函数的精确表征。逆证明将码设计问题简化为在概率分布紧集上的最小化，刻画了该集合的极值点并应用了Bauer最大化原理。

Result: 主要定理给出了高斯信道最小平均错误概率作为一阶和二阶编码率函数的精确表征。

Conclusion: 提出的多方面功率模型框架能够统一现有功率约束模型，并在特定条件下给出高斯信道编码性能的精确表征。

Abstract: Motivated by refined asymptotic results based on the normal approximation, we study how higher-order coding performance depends on the mean power $Γ$ as well as on finer statistics of the input power. We introduce a multifaceted power model in which the expectation of an arbitrary number of arbitrary functions of the normalized average power is constrained. The framework generalizes existing models, recovering the standard maximal and expected power constraints and the recent mean and variance constraint as special cases. Under certain growth and continuity assumptions on the functions, our main theorem gives an exact characterization of the minimum average error probability for Gaussian channels as a function of the first- and second-order coding rates. The converse proof reduces the code design problem to minimization over a compact (under the Prokhorov metric) set of probability distributions, characterizes the extreme points of this set and invokes the Bauer's maximization principle.

</details>


### [26] [Beyond the "G" Frontier: A Time Traveler's Century-Long Vision for Wireless Intelligence](https://arxiv.org/abs/2511.14906)
*Yasser Al Eryani*

Main category: cs.IT

TL;DR: 本文通过信息-曲率效率定律分析，预测2125年的无线通信将不是通过6G或7G等渐进式发展，而是通过电磁学、生物学、热力学和认知的曲率管理集成，形成具有自我意识信息流的全球生态基础设施。


<details>
  <summary>Details</summary>
Motivation: 探索未来100年无线通信的发展轨迹，挑战传统渐进式代际发展模式，提出基于信息-曲率效率定律的新范式。

Method: 应用信息-曲率效率定律作为分析框架，预测无线通信从2025到2125年的演变路径。

Result: 预测无线通信将发展为几何与通信融合的全球生态基础设施，支持技术和生物生命的信息流动。

Conclusion: 无线通信的未来在于多学科曲率管理的集成，而非传统的代际升级，最终形成自我意识的信息流生态。

Abstract: This article travels one century into the future--from 2025 to 2125--through the analytical lens of the Information--Curvature Efficiency Law (ICEL). It contends that wireless evolution will not proceed through incremental generations such as 6G or 7G, but through a curvature-managed integration of electromagnetics, biology, thermodynamics, and cognition. The resulting infrastructure will constitute a global ecology of self-aware information flow, where geometry and communication converge to sustain both technological and biological life.

</details>


### [27] [Hyper-VIB: A Hypernetwork-Enhanced Information Bottleneck Approach for Task-Oriented Communications](https://arxiv.org/abs/2511.15041)
*Jingchen Peng,Chaowen Deng,Yili Deng,Boxiang Ren,Lu Yang*

Main category: cs.IT

TL;DR: Hyper-VIB是一种基于超网络增强的信息瓶颈方法，用于6G协作智能系统中的高效任务导向通信，通过单次训练生成不同超参数下的近似最优DNN参数。


<details>
  <summary>Details</summary>
Motivation: 解决传统信息瓶颈方法在6G协作智能系统中计算复杂度高、需要多次训练的问题，实现高效的任务导向通信。

Method: 结合信息瓶颈理论和超网络，推导出可处理的变分上界近似，通过超网络在单次训练中为不同超参数值生成近似最优的DNN参数。

Result: 在线性情况下的理论分析验证了超网络设计，实验结果表明在分类和回归任务中，Hyper-VIB在准确性和训练效率上均优于传统VIB方法。

Conclusion: Hyper-VIB提供了一种计算高效的解决方案，能够在单次训练中优化设备与网络模型的端到端联合训练，实现任务执行精度最大化和通信开销最小化。

Abstract: This paper presents Hyper-VIB, a hypernetwork-enhanced information bottleneck (IB) approach designed to enable efficient task-oriented communications in 6G collaborative intelligent systems. Leveraging IB theory, our approach enables an optimal end-to-end joint training of device and network models, in terms of the maximal task execution accuracy as well as the minimal communication overhead, through optimizing the trade-off hyperparameter. To address computational intractability in high-dimensional IB optimization, a tractable variational upper-bound approximation is derived. Unlike conventional grid or random search methods that require multiple training rounds with substantial computational costs, Hyper-VIB introduces a hypernetwork that generates approximately optimal DNN parameters for different values of the hyperparameter within a single training phase. Theoretical analysis in the linear case validates the hypernetwork design. Experimental results demonstrate our Hyper-VIB's superior accuracy and training efficiency over conventional VIB approaches in both classification and regression tasks.

</details>


### [28] [Mutual Information Bounds in the Shuffle Model](https://arxiv.org/abs/2511.15051)
*Pengcheng Su,Haibo Cheng,Ping Wang*

Main category: cs.IT

TL;DR: 本文从信息论角度系统研究了单消息洗牌模型，分析了洗牌专用设置和洗牌差分隐私设置，推导了互信息量的渐近表达式和上界，连接了洗牌差分隐私与基于互信息的隐私保护。


<details>
  <summary>Details</summary>
Motivation: 洗牌模型通过随机排列匿名化用户报告来增强隐私，但缺乏从信息论角度的系统性研究。本文旨在填补这一空白，深入分析洗牌模型的信息泄露特性。

Method: 研究两种设置：洗牌专用设置（用户直接提交消息）和洗牌差分隐私设置（用户先应用本地差分隐私机制再洗牌）。推导互信息量I(Y₁;Z)和I(K;Z)的渐近表达式，建立信息泄露上界。

Result: 在洗牌专用设置中，推导了互信息量的渐近表达式；在洗牌差分隐私设置中，建立了信息泄露上界：I(K;Z) ≤ 2ε₀ 和 I(X₁;Z|(Xᵢ)ᵢ₌₂ⁿ) ≤ (e^{ε₀}-1)/(2n) + O(n^{-3/2})。

Conclusion: 本文建立了洗牌差分隐私与基于互信息的隐私保护之间的桥梁，为理解洗牌模型的隐私保护能力提供了信息论基础，并展示了分析框架可扩展到异构用户分布场景。

Abstract: The shuffle model enhances privacy by anonymizing users' reports through random permutation. This paper presents the first systematic study of the single-message shuffle model from an information-theoretic perspective. We analyze two regimes: the shuffle-only setting, where each user directly submits its message ($Y_i=X_i$), and the shuffle-DP setting, where each user first applies a local $\varepsilon_0$-differentially private mechanism before shuffling ($Y_i=\mathcal{R}(X_i)$). Let $\boldsymbol{Z} = (Y_{σ(i)})_i$ denote the shuffled sequence produced by a uniformly random permutation $σ$, and let $K = σ^{-1}(1)$ represent the position of user 1's message after shuffling.
  For the shuffle-only setting, we focus on a tractable yet expressive \emph{basic configuration}, where the target user's message follows $Y_1 \sim P$ and the remaining users' messages are i.i.d.\ samples from $Q$, i.e., $Y_2,\dots,Y_n \sim Q$. We derive asymptotic expressions for the mutual information quantities $I(Y_1;\boldsymbol{Z})$ and $I(K;\boldsymbol{Z})$ as $n \to \infty$, and demonstrate how this analytical framework naturally extends to settings with heterogeneous user distributions.
  For the shuffle-DP setting, we establish information-theoretic upper bounds on total information leakage. When each user applies an $\varepsilon_0$-DP mechanism, the overall leakage satisfies $I(K; \boldsymbol{Z}) \le 2\varepsilon_0$ and $I(X_1; \boldsymbol{Z}\mid (X_i)_{i=2}^n) \le (e^{\varepsilon_0}-1)/(2n) + O(n^{-3/2})$. These results bridge shuffle differential privacy and mutual-information-based privacy.

</details>


### [29] [Generalized Repetition Codes and Their Application to HARQ](https://arxiv.org/abs/2511.15207)
*Chaofeng Guan,Gaojun Luo,Lan Luo,Yangyang Fei,Hong Wang*

Main category: cs.IT

TL;DR: 提出两类广义重复码（GRC），对应两种重传通信模型，通过多度量误差校正实现比传统纠错码更强的纠错能力


<details>
  <summary>Details</summary>
Motivation: 通信信道的不确定性使得任何编码方案都有非零的失败概率，需要重传机制确保消息可靠性。传统方法在有限传输轮次内最大化正确解码概率面临挑战

Method: 将GRC视为多度量下的纠错码，具有多个最小距离，可在不同度量下进行多轮纠错。分别研究Type-I和Type-II GRC的边界和构造方法

Result: 获得了大量最优的Type-I和Type-II GRC，这些GRC具有比传统纠错码更强的纠错能力

Conclusion: 广义重复码通过多度量误差校正机制，在有限传输轮次内显著提升了消息正确解码的概率，为可靠通信提供了有效解决方案

Abstract: The inherent uncertainty of communication channels implies that any coding scheme has a non-zero probability of failing to correct errors, making retransmission mechanisms essential. To ensure message reliability and integrity, a dual-layer redundancy framework is typically employed: error correction codes mitigate noise-induced impairments at the physical layer, while cyclic redundancy checks verify message integrity after decoding. Retransmission is initiated if verification fails. This operational model can be categorized into two types of repeated communication models: Type-I systems repeatedly transmit identical codewords, whereas Type-II systems transmit distinct coded representations of the same message. The core challenge lies in maximizing the probability of correct message decoding within a limited number of transmission rounds through verification-based feedback mechanisms.
  In this paper, we consider a scenario where the same error-correcting code is used for repeated transmissions, and we specifically propose two classes of generalized repetition codes (GRCs), corresponding to the two repeated communication models. In contrast to classical theory, we regard GRCs as error-correcting codes under multiple metrics--that is, GRCs possess multiple minimum distances. This design enables GRCs to perform multi-round error correction under different metrics, achieving stronger error-correction capabilities than classical error-correcting codes. However, the special structure of GRCs makes their construction more challenging, as it requires simultaneously optimizing multiple minimum distances. To address this, we separately investigate the bounds and constructions for Type-I and Type-II GRCs, and obtain numerous optimal Type-I and Type-II GRCs.

</details>


### [30] [The Rate-Distortion-Perception Trade-Off with Algorithmic Realism](https://arxiv.org/abs/2511.15255)
*Yassine Hamdi,Aaron B. Wagner,Deniz Gündüz*

Main category: cs.IT

TL;DR: 该论文解释了在图像压缩中理论预测需要大量公共随机性来实现真实感约束，但实践中并未观察到这一现象的原因。通过考虑需要满足通用批评者的真实感约束，作者证明了在没有公共随机性的情况下也能渐近达到最优率失真权衡，除非批处理大小不切实际地大。


<details>
  <summary>Details</summary>
Motivation: 解释理论研究中预测需要高率公共随机性来实现真实感约束，但实践中并未观察到这一现象的原因，弥合理论与实践的差距。

Method: 考虑需要满足通用批评者的真实感约束，该批评者检查单个压缩重建或其批处理的实现。表征在此类真实感约束下的最优率失真权衡。

Result: 证明了在没有公共随机性的情况下也能渐近达到最优率失真权衡，除非批处理大小不切实际地大。

Conclusion: 公共随机性在实现真实感约束方面并非必要资源，除非在极端情况下，这解释了理论与实践中观察到的差异。

Abstract: Realism constraints (or constraints on perceptual quality) have received considerable recent attention within the context of lossy compression, particularly of images. Theoretical studies of lossy compression indicate that high-rate common randomness between the compressor and the decompressor is a valuable resource for achieving realism. On the other hand, the utility of significant amounts of common randomness has not been noted in practice. We offer an explanation for this discrepancy by considering a realism constraint that requires satisfying a universal critic that inspects realizations of individual compressed reconstructions, or batches thereof. We characterize the optimal rate-distortion trade-off under such a realism constraint, and show that it is asymptotically achievable without any common randomness, unless the batch size is impractically large.

</details>


### [31] [Communication-Pipelined Split Federated Learning for Foundation Model Fine-Tuning in UAV Networks](https://arxiv.org/abs/2511.15404)
*Zizhen Zhou,Ying-Chang Liang,Yanyu Cheng,Wei Yang Bryan Lim*

Main category: cs.IT

TL;DR: 提出了一种通信流水线化的分割联邦学习（CPSFL）方法，用于在无人机网络上对基础模型进行LoRA微调，通过顺序梯度传输和异步训练来减少延迟和能耗。


<details>
  <summary>Details</summary>
Motivation: 在无人机网络上部署基础模型具有广阔应用前景，但现有并行梯度传输方法在无人机网络中通信延迟远大于计算延迟，导致资源闲置和训练延迟问题。

Method: 提出顺序梯度传输范式，服务器为当前梯度传输分配所有下行资源；设计CPSFL方法，具有下行梯度传输优先级调度和轮内异步训练特性；使用基于注意力的深度强化学习框架优化分割点选择和资源分配。

Result: 仿真结果表明，提出的基于DRL的CPSFL方案在训练延迟和能耗方面优于并行梯度传输基准、消融变体、固定资源分配方案，并接近最佳固定分割点方案。

Conclusion: CPSFL方法有效解决了无人机网络中基础模型微调的延迟和能耗问题，为低空经济应用提供了可行的解决方案。

Abstract: Deploying foundation models (FMs) on uncrewed aerial vehicles (UAVs) promises broad ``low-altitude economy'' applications. Split federated learning (SFL)-based fine-tuning leverages distributed data while keeping raw data local and reduces client-side burden by partitioning the model between client and server. However, the per-round training latency is dominated by stragglers. Training paradigms featuring parallel gradient transmission (GT) allocate dedicated portions of downlink communication resources to each client. They may leave resources idle and suffer from prolonged GT latency, especially in UAV networks, where the communication latency typically far exceeds the computation latency. To address this, we propose a sequential GT paradigm, where the server dedicates all downlink resources for the current GT. We further propose communication-pipelined SFL (CPSFL), characterized by downlink GT priority scheduling and intra-round asynchronous training. We investigate CPSFL-based LoRA fine-tuning of FMs in UAV networks and formulate an optimization problem to minimize a weighted sum of per-round training latency and worst-case client energy consumption by optimizing the split point selection (SPS) and the computing and communication resource allocation (CCRA) (the uplink bandwidth allocation and the server computing frequency allocation). To solve this problem, we develop an attention-based deep reinforcement learning (DRL) framework, where the base station agent decides the split point and the CCRA in each round by leveraging previous round information, including UAV trajectories. Simulation results show that the proposed DRL-based CPSFL scheme outperforms the parallel GT benchmarks, the ablation variants, the fixed CCRA scheme, while approaching the best fixed-SPS scheme.

</details>


### [32] [RIS-Enabled UAV Communications and Sensing: Opportunities, Challenges, and Key Technologies](https://arxiv.org/abs/2511.15555)
*Yajun Zhao,Mengnan Jian,Yifei Yuan*

Main category: cs.IT

TL;DR: 本文深入研究了无人机通信网络的特征与挑战，提出了可重构智能表面(RIS)辅助网络作为增强无人机信号覆盖的解决方案，并探讨了网络架构设计和未来技术趋势。


<details>
  <summary>Details</summary>
Motivation: 无人机在低空经济中发挥关键作用，但在传输操作中面临网络覆盖可靠性挑战，传统有源相控阵天线网络存在成本高、复杂度大和站点部署限制等问题。

Method: 采用双层异构网络拓扑实现三维连续覆盖，引入RIS技术增强信号覆盖，包括设计原理、天线倾角配置、新波束类型和波束跟踪机制等技术特征。

Result: 现场试验结果验证了RIS在改善无人机覆盖方面的有效性，展示了其在增强信号覆盖和网络共存方面的潜力。

Conclusion: RIS辅助网络是优化无人机通信系统的有前景解决方案，未来需要加强工程实施和标准化工作，以推动RIS增强的无人机集成感知与通信网络发展。

Abstract: Unmanned Aerial Vehicles (UAVs) play a pivotal role in the emerging low-altitude economy. However, they face significant challenges in achieving reliable network coverage during transit operations. This paper provides an in-depth investigation into the characteristics and challenges of communication networks tailored for UAVs. First, we outline typical operational scenarios, traffic patterns, and a dual-layer heterogeneous network topology. This topology is essential for enabling three-dimensional continuous coverage and ensuring seamless network coexistence between UAVs and other network entities. Moreover, the paper delves into the channel characteristics and specific challenges faced by UAV Integrated Sensing and Communication (ISAC) networks. It highlights the limitations of traditional Active Phased Array Antenna (APAA)-based networks, particularly regarding cost, complexity, and site deployment constraints. We then introduce Reconfigurable Intelligent Surface (RIS)-assisted networks as a promising solution for enhancing UAV signal coverage. The key technical features of RIS are discussed, including design principles, antenna tilt configurations, new beam types, and beam tracking mechanisms. In addition, we examine the impact of highfrequency bands and their absorption peaks on signal attenuation. The paper further explores network architecture designs aimed at improving UAV signal coverage, facilitating network coexistence, and supporting RIS-enhanced UAV sensing. Field trial results evaluating the effectiveness of RIS in improving UAV coverage are presented. Finally, we outline future technological trends and highlight potential advancements to further optimize UAV communication systems. We also emphasize the importance of engineering implementation and standardization efforts in RIS-based UAV-ISAC networks.

</details>


### [33] [Information Efficiency of Scientific Automation](https://arxiv.org/abs/2511.15671)
*Mihir Rao*

Main category: cs.IT

TL;DR: 该论文将科学发现建模为热力学过程，在有限工作预算下推导了顺序贝叶斯学习的信息增益界限，并提出了信息-工作效率指标来比较不同学习策略。


<details>
  <summary>Details</summary>
Motivation: 将科学发现框架化为热力学过程，研究在有限工作预算下如何优化信息获取效率，为科学自动化提供理论指导。

Method: 利用计算热力学的已有结果，推导顺序贝叶斯学习在有限预算下的信息增益界限，提出信息-工作效率指标，比较未分区和联邦学习策略。

Result: 得出了有限预算下的信息增益界限，并提供了比较不同学习策略效率的指标。

Conclusion: 研究结果为大规模科学自动化工作提供了界限指导和信息效率度量标准。

Abstract: Scientific discovery can be framed as a thermodynamic process in which an agent invests physical work to acquire information about an environment under a finite work budget. Using established results about the thermodynamics of computing, we derive finite-budget bounds on information gain over rounds of sequential Bayesian learning. We also propose a metric of information-work efficiency, and compare unpartitioned and federated learning strategies under matched work budgets. The presented results offer guidance in the form of bounds and an information efficiency metric for efforts in scientific automation at large.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [34] [Computing Power Indices in Weighted Majority Games with Formal Power Series](https://arxiv.org/abs/2511.14995)
*Naonori Kakimura,Yoshihiko Terai*

Main category: cs.GT

TL;DR: 本文提出了计算加权多数博弈中权力指数的快速伪多项式时间算法，包括Banzhaf指数和Shapley-Shubik指数的高效计算方法。


<details>
  <summary>Details</summary>
Motivation: 现有算法在处理加权多数博弈中的权力指数计算时效率较低，特别是在配额q较小时。本文旨在开发更快的算法来解决这一问题。

Method: 利用形式幂级数的高效计算技术，设计了时间复杂度分别为O(n+q log(q))和O(nq log(q))的算法来计算Banzhaf指数和Shapley-Shubik指数。

Result: 当q=2^{o(n)}时，新算法比现有算法更快。Banzhaf指数可在O(n+q log(q))时间内计算所有玩家，Shapley-Shubik指数可在O(nq log(q))时间内计算所有玩家。

Conclusion: 本文提出的基于形式幂级数计算的算法显著提高了加权多数博弈中权力指数的计算效率，为相关应用提供了更快的计算工具。

Abstract: In this paper, we propose fast pseudo-polynomial-time algorithms for computing power indices in weighted majority games. We show that we can compute the Banzhaf index for all players in $O(n+q\log (q))$ time, where $n$ is the number of players and $q$ is a given quota. Moreover, we prove that the Shapley--Shubik index for all players can be computed in $O(nq\log (q))$ time. Our algorithms are faster than existing algorithms when $q=2^{o(n)}$. Our algorithms exploit efficient computation techniques for formal power series.

</details>


### [35] [Coopetitive Index: a measure of cooperation and competition in coalition formation](https://arxiv.org/abs/2511.15441)
*Michele Aleandri,Marco Dall'Aglio*

Main category: cs.GT

TL;DR: 将合作竞争指数从简单博弈扩展到单调TU博弈和所有非空联盟，定义了范围在[-1,1]的绝对合作竞争指数，研究了Banzhaf、Uniform Shapley和Shapley-Owen等版本，并提供了后两者的公理化特征。


<details>
  <summary>Details</summary>
Motivation: 扩展合作竞争指数的适用范围，使其能够在更广泛的博弈类型和所有联盟中量化合作与竞争倾向，便于跨联盟比较。

Method: 将合作竞争指数推广到单调TU博弈，定义绝对合作竞争指数，研究不同版本（Banzhaf、Uniform Shapley、Shapley-Owen），推导与经典半值的关系，并提供公理化特征。

Result: 成功定义了具有通用范围[-1,1]的绝对合作竞争指数，建立了与经典半值的显式公式联系，并完成了Uniform Shapley和Shapley-Owen版本的唯一性公理化特征。

Conclusion: 合作竞争指数成为量化TU博弈中联盟合作与竞争倾向的通用工具，通过公理化特征确立了其理论基础。

Abstract: We extend the coopetition index introduced by Aleandri and Dall'Aglio (2025) for simple games to the broader class of monotone transferable utility (TU) games and to all non-empty coalitions, including singletons. The new formulation allows us to define an absolute coopetition index with a universal range in [-1,1], facilitating meaningful comparisons across coalitions.
  We study several notable instances of the index, including the Banzhaf, Uniform Shapley, and Shapley-Owen coopetition indices, and we derive explicit formulas that connect coopetition to classical semivalues. Finally, we provide axiomatic characterizations of the Uniform Shapley and Shaple--Owen versions, showing that each is uniquely determined by linearity, symmetry over pure bargaining games, external null player neutrality, and a contraction axiom reflecting its internal distribution. These results position the coopetition index as a versatile tool for quantifying the cooperative and competitive tendencies of coalitions in TU-games.

</details>


### [36] [A Scenario Approach to the Robustness of Nonconvex-Nonconcave Minimax Problems](https://arxiv.org/abs/2511.15606)
*Huan Peng,Guanpu Chen,Karl Henrik Johansson*

Main category: cs.GT

TL;DR: 本文通过情景方法研究非凸非凹极小极大问题的概率鲁棒性，为关键均衡点提供鲁棒性保证，克服了对非退化假设的依赖。


<details>
  <summary>Details</summary>
Motivation: 传统极小极大问题的鲁棒性分析依赖于非退化假设，本文旨在克服这一限制，为非凸非凹极小极大问题建立概率鲁棒性理论框架。

Method: 采用情景优化方法，在凸策略集下通过证明平稳残差的单调性建立ε-平稳点的概率鲁棒性保证；在非凸策略集下通过极值定理和Berge极大值定理建立全局极小极大点的鲁棒性保证。

Result: 在凸策略集下获得了ε-平稳点的概率鲁棒性保证，在非凸策略集下获得了全局极小极大点的鲁棒性保证，并通过机组组合问题的数值实验验证了理论结果。

Conclusion: 本文为非凸非凹极小极大问题提供了概率鲁棒性分析的理论框架，在不同策略集条件下均能获得有效的鲁棒性保证，具有重要的理论和应用价值。

Abstract: This paper investigates probabilistic robustness of nonconvex-nonconcave minimax problems via the scenario approach. Inspired by recent advances in scenario optimization (Garatti and Campi, 2025), we obtain robustness results for key equilibria with nonconvex-nonconcave payoffs, overcoming the dependence on the non-degeneracy assumption. Specifically, under convex strategy sets for all players, we first establish a probabilistic robustness guarantee for an epsilon-stationary point by proving the monotonicity of the stationary residual in the number of scenarios. Moreover, under nonconvex strategy sets for all players, we derive a probabilistic robustness guarantee for a global minimax point by invoking the extreme value theorem and Berge's maximum theorem. A numerical experiment on a unit commitment problem corroborates our theoretical findings.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [37] [ChartEditor: A Reinforcement Learning Framework for Robust Chart Editing](https://arxiv.org/abs/2511.15266)
*Liangyu Chen,Yichen Xu,Jianzhe Ma,Yuqi Liu,Donglu Yang,Liang Zhang,Wenxuan Wang,Qin Jin*

Main category: cs.MM

TL;DR: 提出了ChartEditVista基准测试集和ChartEditor模型，用于评估和改进基于自然语言指令的图表编辑任务，无需原始图表代码。


<details>
  <summary>Details</summary>
Motivation: 现有图表编辑基准测试数据多样性不足，且假设能获取完整图表代码，这与现实场景不符。需要开发更贴近实际应用的图表编辑评估框架。

Method: 创建ChartEditVista基准测试集（7,964个样本，31个图表类别），使用全自动流水线生成、编辑和验证图表。提出基于规则的细粒度评估指标：布局指标和文本指标。开发ChartEditor模型，采用强化学习框架并引入渲染奖励机制。

Result: ChartEditVista提供了稳健的评估基准，ChartEditor在图表编辑任务中持续优于相似规模和更大规模的模型。

Conclusion: ChartEditVista填补了图表编辑评估的空白，ChartEditor通过强化学习和渲染奖励机制有效提升了图表编辑的性能和可靠性。

Abstract: Chart editing reduces manual effort in visualization design. Typical benchmarks limited in data diversity and assume access to complete chart code, which is seldom in real-world scenarios. To address this gap, we present ChartEditVista, a comprehensive benchmark consisting of 7,964 samples spanning 31 chart categories. It encompasses diverse editing instructions and covers nearly all editable chart elements. The inputs in ChartEditVista include only the original chart image and natural language editing instructions, without the original chart codes. ChartEditVista is generated through a fully automated pipeline that produces, edits, and verifies charts, ensuring high-quality chart editing data. Besides, we introduce two novel fine-grained, rule-based evaluation metrics: the layout metric, which evaluates the position, size and color of graphical components; and the text metric, which jointly assesses textual content and font styling. Building on top of ChartEditVista, we present ChartEditor, a model trained using a reinforcement learning framework that incorporates a novel rendering reward to simultaneously enforce code executability and visual fidelity. Through extensive experiments and human evaluations, we demonstrate that ChartEditVista provides a robust evaluation, while ChartEditor consistently outperforms models with similar-scale and larger-scale on chart editing tasks.

</details>
