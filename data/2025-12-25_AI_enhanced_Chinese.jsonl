{"id": "2512.20883", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.20883", "abs": "https://arxiv.org/abs/2512.20883", "authors": ["Xinyi Guo", "Li You", "Qiong Liu", "Xiqi Gao", "Xiang-Gen Xia"], "title": "Uplink RSMA Performance Analysis with Rate Adaptation: A Stochastic Geometry Approach", "comment": "15 pages, 13 figures, submitted for possible publication", "summary": "Rate-splitting multiple access (RSMA) has emerged as a promising technique for efficient interference management in next-generation wireless networks. While most existing studies focus on downlink and single-cell designs, the modeling and analysis of uplink RSMA under large-scale deployments remain largely unexplored. On the basis of stochastic geometry (SG), this paper introduces a unified analytical framework that integrates finite modulation and coding scheme (MCS)-based rate adaptation. This framework jointly captures spatial interference coupling and discrete rate behavior to bridge theoretical tractability and practical realism. Within this framework, we derive tractable expressions for the conditional received rate (CRR), its spatial average, and higher-order statistics via the meta distribution, thereby quantifying both the mean and user-specific rate performance. Results show that the proposed unified framework not only generalizes existing non-orthogonal multiple access (NOMA) and orthogonal multiple access (OMA) analyses but also provides new insights into how discrete rate adaptation reshapes interference dynamics and fairness in dense RSMA-enabled networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u51e0\u4f55\u7684\u7edf\u4e00\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u4e0a\u884c\u94fe\u8def\u901f\u7387\u5206\u5272\u591a\u5740\u63a5\u5165\u7f51\u7edc\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u6709\u9650\u8c03\u5236\u7f16\u7801\u65b9\u6848\u901f\u7387\u9002\u914d\uff0c\u80fd\u591f\u8054\u5408\u6355\u83b7\u7a7a\u95f4\u5e72\u6270\u8026\u5408\u548c\u79bb\u6563\u901f\u7387\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4e0b\u884c\u94fe\u8def\u548c\u5355\u5c0f\u533a\u8bbe\u8ba1\uff0c\u800c\u5927\u89c4\u6a21\u90e8\u7f72\u4e0b\u7684\u4e0a\u884c\u94fe\u8defRSMA\u5efa\u6a21\u548c\u5206\u6790\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8fde\u63a5\u7406\u8bba\u53ef\u5904\u7406\u6027\u548c\u5b9e\u9645\u73b0\u5b9e\u6027\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u968f\u673a\u51e0\u4f55\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5206\u6790\u6846\u67b6\uff0c\u96c6\u6210\u4e86\u6709\u9650MCS\u901f\u7387\u9002\u914d\u3002\u8be5\u6846\u67b6\u8054\u5408\u6355\u83b7\u7a7a\u95f4\u5e72\u6270\u8026\u5408\u548c\u79bb\u6563\u901f\u7387\u884c\u4e3a\uff0c\u63a8\u5bfc\u4e86\u6761\u4ef6\u63a5\u6536\u901f\u7387\u3001\u5176\u7a7a\u95f4\u5e73\u5747\u503c\u4ee5\u53ca\u901a\u8fc7\u5143\u5206\u5e03\u7684\u9ad8\u9636\u7edf\u8ba1\u91cf\u7684\u53ef\u5904\u7406\u8868\u8fbe\u5f0f\u3002", "result": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63a8\u5e7f\u4e86\u73b0\u6709\u7684NOMA\u548cOMA\u5206\u6790\uff0c\u8fd8\u63d0\u4f9b\u4e86\u5173\u4e8e\u79bb\u6563\u901f\u7387\u9002\u914d\u5982\u4f55\u91cd\u5851\u5bc6\u96c6RSMA\u7f51\u7edc\u4e2d\u7684\u5e72\u6270\u52a8\u6001\u548c\u516c\u5e73\u6027\u7684\u65b0\u89c1\u89e3\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u5206\u6790\u6846\u67b6\u4e3a\u5927\u89c4\u6a21\u4e0a\u884c\u94fe\u8defRSMA\u7f51\u7edc\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u5de5\u5177\uff0c\u80fd\u591f\u91cf\u5316\u5e73\u5747\u548c\u7528\u6237\u7279\u5b9a\u901f\u7387\u6027\u80fd\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2512.20984", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.20984", "abs": "https://arxiv.org/abs/2512.20984", "authors": ["Wei Wu", "Lingyi Wang", "Fuhui Zhou", "Zhaohui Yang", "Qihui Wu"], "title": "Knowledge-Driven 3D Semantic Spectrum Map: KE-VQ-Transformer Based UAV Semantic Communication and Map Completion", "comment": null, "summary": "Artificial intelligence (AI)-native three-dimensional (3D) spectrum maps are crucial in spectrum monitoring for intelligent communication networks. However, it is challenging to obtain and transmit 3D spectrum maps in a spectrum-efficient, computation-efficient, and AI-driven manner, especially under complex communication environments and sparse sampling data. In this paper, we consider practical air-to-ground semantic communications for spectrum map completion, where the unmanned aerial vehicle (UAV) measures the spectrum at spatial points and extracts the spectrum semantics, which are then utilized to complete spectrum maps at the ground device. Since statistical machine learning can easily be misled by superficial data correlations with the lack of interpretability, we propose a novel knowledge-enhanced semantic spectrum map completion framework with two expert knowledge-driven constraints from physical signal propagation models. This framework can capture the real-world physics and avoid getting stuck in the mindset of superficial data distributions. Furthermore, a knowledge-enhanced vector-quantized Transformer (KE-VQ-Transformer) based multi-scale low-complex intelligent completion approach is proposed, where the sparse window is applied to avoid ultra-large 3D attention computation, and the multi-scale design improves the completion performance. The knowledge-enhanced mean square error (KMSE) and root KMSE (RKMSE) are introduced as novel metrics for semantic spectrum map completion that jointly consider the numerical precision and physical consistency with the signal propagation model, based on which a joint offline and online training method is developed with supervised and unsupervised knowledge loss. The simulation demonstrates that our proposed scheme outperforms the state-of-the-art benchmark schemes in terms of RKMSE.", "AI": {"tldr": "\u63d0\u51fa\u77e5\u8bc6\u589e\u5f3a\u7684\u8bed\u4e49\u9891\u8c31\u5730\u56fe\u8865\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u7269\u7406\u4fe1\u53f7\u4f20\u64ad\u6a21\u578b\u7ea6\u675f\u63d0\u5347AI\u9a71\u52a8\u76843D\u9891\u8c31\u5730\u56fe\u91cd\u5efa\u6027\u80fd", "motivation": "\u5728\u590d\u6742\u901a\u4fe1\u73af\u5883\u548c\u7a00\u758f\u91c7\u6837\u6570\u636e\u4e0b\uff0c\u4f20\u7edf\u7edf\u8ba1\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5bb9\u6613\u88ab\u8868\u9762\u6570\u636e\u76f8\u5173\u6027\u8bef\u5bfc\u4e14\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u96be\u4ee5\u9ad8\u6548\u83b7\u53d6\u548c\u4f20\u8f933D\u9891\u8c31\u5730\u56fe", "method": "\u63d0\u51fa\u77e5\u8bc6\u589e\u5f3a\u7684\u8bed\u4e49\u9891\u8c31\u5730\u56fe\u8865\u5168\u6846\u67b6\uff0c\u5305\u542b\u57fa\u4e8e\u7269\u7406\u4fe1\u53f7\u4f20\u64ad\u6a21\u578b\u7684\u4e13\u5bb6\u77e5\u8bc6\u7ea6\u675f\uff1b\u8bbe\u8ba1KE-VQ-Transformer\u591a\u5c3a\u5ea6\u4f4e\u590d\u6742\u5ea6\u667a\u80fd\u8865\u5168\u65b9\u6cd5\uff0c\u91c7\u7528\u7a00\u758f\u7a97\u53e3\u907f\u514d\u8d85\u59273D\u6ce8\u610f\u529b\u8ba1\u7b97\uff1b\u5f15\u5165KMSE\u548cRKMSE\u65b0\u6307\u6807\uff0c\u5f00\u53d1\u8054\u5408\u79bb\u7ebf\u5728\u7ebf\u8bad\u7ec3\u65b9\u6cd5", "result": "\u4eff\u771f\u8868\u660e\u6240\u63d0\u65b9\u6848\u5728RKMSE\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u51c6\u65b9\u6848", "conclusion": "\u901a\u8fc7\u878d\u5165\u7269\u7406\u77e5\u8bc6\u7ea6\u675f\uff0c\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6355\u6349\u771f\u5b9e\u4e16\u754c\u7269\u7406\u7279\u6027\uff0c\u907f\u514d\u9677\u5165\u8868\u9762\u6570\u636e\u5206\u5e03\u601d\u7ef4\uff0c\u5b9e\u73b0\u66f4\u51c6\u786e\u3001\u7269\u7406\u4e00\u81f4\u7684\u9891\u8c31\u5730\u56fe\u8865\u5168"}}
{"id": "2512.21112", "categories": ["cs.IT", "math.LO"], "pdf": "https://arxiv.org/pdf/2512.21112", "abs": "https://arxiv.org/abs/2512.21112", "authors": ["Cheuk Ting Li"], "title": "Coding-Logic Correspondence: Turning Information and Communication Networks into Logical Formulae via Hypergraph Heyting Algebra", "comment": "28 pages, 3 figures", "summary": "We propose using confusion hypergraphs (hyperconfusions) as a model of information. In contrast to the conventional approach using random variables, we can now perform conjunction, disjunction and implication of information, forming a Heyting algebra. Using the connection between Heyting algebra and intuitionistic logic, we can express the requirements of a communication network (e.g., network coding, index coding, Slepian-Wolf coding) as a logical formula, allowing us to use the hypergraph Heyting algebra to directly compute the optimal coding scheme. The optimal communication cost is simply given by the entropy of the hypergraph (within a logarithmic gap). This gives a surprising correspondence between coding settings and logical formulae, similar to the Curry-Howard correspondence between proofs and computer programs.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u6df7\u6dc6\u8d85\u56fe\uff08\u8d85\u6df7\u6dc6\uff09\u4f5c\u4e3a\u4fe1\u606f\u6a21\u578b\uff0c\u66ff\u4ee3\u4f20\u7edf\u968f\u673a\u53d8\u91cf\u65b9\u6cd5\uff0c\u5f62\u6210Heyting\u4ee3\u6570\uff0c\u5c06\u901a\u4fe1\u7f51\u7edc\u9700\u6c42\u8868\u8fbe\u4e3a\u903b\u8f91\u516c\u5f0f\uff0c\u76f4\u63a5\u8ba1\u7b97\u6700\u4f18\u7f16\u7801\u65b9\u6848", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u968f\u673a\u53d8\u91cf\u7684\u4fe1\u606f\u7406\u8bba\u65b9\u6cd5\u65e0\u6cd5\u76f4\u63a5\u5904\u7406\u4fe1\u606f\u7684\u5408\u53d6\u3001\u6790\u53d6\u548c\u8574\u542b\u8fd0\u7b97\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u4fe1\u606f\u6a21\u578b\u6765\u7edf\u4e00\u8868\u8fbe\u901a\u4fe1\u7f51\u7edc\u7684\u5404\u79cd\u7f16\u7801\u9700\u6c42", "method": "\u4f7f\u7528\u6df7\u6dc6\u8d85\u56fe\u4f5c\u4e3a\u4fe1\u606f\u6a21\u578b\uff0c\u5efa\u7acbHeyting\u4ee3\u6570\u7ed3\u6784\uff0c\u5229\u7528\u76f4\u89c9\u4e3b\u4e49\u903b\u8f91\u4e0eHeyting\u4ee3\u6570\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u5c06\u7f51\u7edc\u7f16\u7801\u3001\u7d22\u5f15\u7f16\u7801\u3001Slepian-Wolf\u7f16\u7801\u7b49\u901a\u4fe1\u9700\u6c42\u8868\u8fbe\u4e3a\u903b\u8f91\u516c\u5f0f", "result": "\u901a\u8fc7\u8d85\u56feHeyting\u4ee3\u6570\u53ef\u4ee5\u76f4\u63a5\u8ba1\u7b97\u6700\u4f18\u7f16\u7801\u65b9\u6848\uff0c\u6700\u4f18\u901a\u4fe1\u6210\u672c\u7531\u8d85\u56fe\u7684\u71b5\u7ed9\u51fa\uff08\u5728\u5bf9\u6570\u5dee\u8ddd\u5185\uff09\uff0c\u5efa\u7acb\u4e86\u7f16\u7801\u573a\u666f\u4e0e\u903b\u8f91\u516c\u5f0f\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb", "conclusion": "\u6df7\u6dc6\u8d85\u56fe\u6a21\u578b\u4e3a\u4fe1\u606f\u7406\u8bba\u63d0\u4f9b\u4e86\u65b0\u7684\u4ee3\u6570\u6846\u67b6\uff0c\u5efa\u7acb\u4e86\u7c7b\u4f3cCurry-Howard\u5bf9\u5e94\u7684\u7f16\u7801\u4e0e\u903b\u8f91\u5bf9\u5e94\u5173\u7cfb\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u901a\u4fe1\u7f16\u7801\u95ee\u9898"}}
{"id": "2512.20688", "categories": ["cs.GT", "cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.20688", "abs": "https://arxiv.org/abs/2512.20688", "authors": ["Stefano Grassi"], "title": "Mechanism-Based Intelligence (MBI): Differentiable Incentives for Rational Coordination and Guaranteed Alignment in Multi-Agent Systems", "comment": null, "summary": "Autonomous multi-agent systems are fundamentally fragile: they struggle to solve the Hayekian Information problem (eliciting dispersed private knowledge) and the Hurwiczian Incentive problem (aligning local actions with global objectives), making coordination computationally intractable. I introduce Mechanism-Based Intelligence (MBI), a paradigm that reconceptualizes intelligence as emergent from the coordination of multiple \"brains\", rather than a single one. At its core, the Differentiable Price Mechanism (DPM) computes the exact loss gradient $$ \\mathbf{G}_i = - \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}_i} $$ as a dynamic, VCG-equivalent incentive signal, guaranteeing Dominant Strategy Incentive Compatibility (DSIC) and convergence to the global optimum. A Bayesian extension ensures incentive compatibility under asymmetric information (BIC). The framework scales linearly ($\\mathcal{O}(N)$) with the number of agents, bypassing the combinatorial complexity of Dec-POMDPs and is empirically 50x faster than Model-Free Reinforcement Learning. By structurally aligning agent self-interest with collective objectives, it provides a provably efficient, auditable and generalizable approach to coordinated, trustworthy and scalable multi-agent intelligence grounded in economic principles.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u673a\u5236\u57fa\u7840\u667a\u80fd(MBI)\u8303\u5f0f\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u4ef7\u683c\u673a\u5236(DPM)\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4fe1\u606f\u5206\u6563\u548c\u6fc0\u52b1\u5bf9\u9f50\u95ee\u9898\uff0c\u5b9e\u73b0\u7ebf\u6027\u53ef\u6269\u5c55\u7684\u534f\u8c03\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u81ea\u4e3b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b58\u5728\u6839\u672c\u6027\u8106\u5f31\uff1a\u96be\u4ee5\u89e3\u51b3\u54c8\u8036\u514b\u4fe1\u606f\u95ee\u9898\uff08\u83b7\u53d6\u5206\u6563\u7684\u79c1\u6709\u77e5\u8bc6\uff09\u548c\u8d6b\u7ef4\u8328\u6fc0\u52b1\u95ee\u9898\uff08\u4f7f\u5c40\u90e8\u884c\u52a8\u4e0e\u5168\u5c40\u76ee\u6807\u5bf9\u9f50\uff09\uff0c\u5bfc\u81f4\u534f\u8c03\u8ba1\u7b97\u4e0d\u53ef\u884c\u3002", "method": "\u63d0\u51fa\u673a\u5236\u57fa\u7840\u667a\u80fd(MBI)\u8303\u5f0f\uff0c\u5c06\u667a\u80fd\u91cd\u65b0\u6982\u5ff5\u5316\u4e3a\u591a\u4e2a\"\u5927\u8111\"\u534f\u8c03\u7684\u6d8c\u73b0\u73b0\u8c61\u3002\u6838\u5fc3\u662f\u53ef\u5fae\u5206\u4ef7\u683c\u673a\u5236(DPM)\uff0c\u8ba1\u7b97\u7cbe\u786e\u635f\u5931\u68af\u5ea6\u4f5c\u4e3a\u52a8\u6001\u7684VCG\u7b49\u4ef7\u6fc0\u52b1\u4fe1\u53f7\uff0c\u4fdd\u8bc1\u4e3b\u5bfc\u7b56\u7565\u6fc0\u52b1\u76f8\u5bb9(DSIC)\u5e76\u6536\u655b\u5230\u5168\u5c40\u6700\u4f18\u3002\u8d1d\u53f6\u65af\u6269\u5c55\u786e\u4fdd\u5728\u4fe1\u606f\u4e0d\u5bf9\u79f0\u4e0b\u7684\u6fc0\u52b1\u76f8\u5bb9(BIC)\u3002", "result": "\u6846\u67b6\u968f\u667a\u80fd\u4f53\u6570\u91cf\u7ebf\u6027\u6269\u5c55(O(N))\uff0c\u7ed5\u8fc7Dec-POMDP\u7684\u7ec4\u5408\u590d\u6742\u6027\uff0c\u7ecf\u9a8c\u4e0a\u6bd4\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u5feb50\u500d\u3002\u901a\u8fc7\u7ed3\u6784\u6027\u5730\u5c06\u667a\u80fd\u4f53\u81ea\u5229\u4e0e\u96c6\u4f53\u76ee\u6807\u5bf9\u9f50\uff0c\u63d0\u4f9b\u4e86\u53ef\u8bc1\u660e\u9ad8\u6548\u3001\u53ef\u5ba1\u8ba1\u4e14\u53ef\u6cdb\u5316\u7684\u534f\u8c03\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u7ecf\u6d4e\u539f\u5219\u7684\u673a\u5236\u57fa\u7840\u667a\u80fd\u4e3a\u53ef\u4fe1\u8d56\u3001\u53ef\u6269\u5c55\u7684\u591a\u667a\u80fd\u4f53\u667a\u80fd\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6839\u672c\u534f\u8c03\u95ee\u9898\u3002"}}
{"id": "2512.20781", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.20781", "abs": "https://arxiv.org/abs/2512.20781", "authors": ["Youjin Jung", "Seongwoo Cho", "Hyun-seok Min", "Sungchul Choi"], "title": "Soft Filtering: Guiding Zero-shot Composed Image Retrieval with Prescriptive and Proscriptive Constraints", "comment": "Accepted to AAAI 2026 Workshop on New Frontiers in Information Retrieval", "summary": "Composed Image Retrieval (CIR) aims to find a target image that aligns with user intent, expressed through a reference image and a modification text. While Zero-shot CIR (ZS-CIR) methods sidestep the need for labeled training data by leveraging pretrained vision-language models, they often rely on a single fused query that merges all descriptive cues of what the user wants, tending to dilute key information and failing to account for what they wish to avoid. Moreover, current CIR benchmarks assume a single correct target per query, overlooking the ambiguity in modification texts. To address these challenges, we propose Soft Filtering with Textual constraints (SoFT), a training-free, plug-and-play filtering module for ZS-CIR. SoFT leverages multimodal large language models (LLMs) to extract two complementary constraints from the reference-modification pair: prescriptive (must-have) and proscriptive (must-avoid) constraints. These serve as semantic filters that reward or penalize candidate images to re-rank results, without modifying the base retrieval model or adding supervision. In addition, we construct a two-stage dataset pipeline that refines CIR benchmarks. We first identify multiple plausible targets per query to construct multi-target triplets, capturing the open-ended nature of user intent. Then guide multimodal LLMs to rewrite the modification text to focus on one target, while referencing contrastive distractors to ensure precision. This enables more comprehensive and reliable evaluation under varying ambiguity levels. Applied on top of CIReVL, a ZS-CIR retriever, SoFT raises R@5 to 65.25 on CIRR (+12.94), mAP@50 to 27.93 on CIRCO (+6.13), and R@50 to 58.44 on FashionIQ (+4.59), demonstrating broad effectiveness.", "AI": {"tldr": "SoFT\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u5373\u63d2\u5373\u7528\u7684\u8fc7\u6ee4\u6a21\u5757\uff0c\u7528\u4e8e\u96f6\u6837\u672c\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\uff0c\u901a\u8fc7\u63d0\u53d6\u89c4\u5b9a\u6027\u548c\u7981\u6b62\u6027\u7ea6\u675f\u6765\u91cd\u65b0\u6392\u5e8f\u7ed3\u679c\uff0c\u5e76\u6784\u5efa\u4e86\u591a\u76ee\u6807\u6570\u636e\u96c6\u8fdb\u884c\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u96f6\u6837\u672c\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u5355\u4e00\u878d\u5408\u67e5\u8be2\uff0c\u5bb9\u6613\u7a00\u91ca\u5173\u952e\u4fe1\u606f\u4e14\u65e0\u6cd5\u5904\u7406\u7528\u6237\u60f3\u8981\u907f\u514d\u7684\u5185\u5bb9\u3002\u6b64\u5916\uff0c\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u5047\u8bbe\u6bcf\u4e2a\u67e5\u8be2\u53ea\u6709\u4e00\u4e2a\u6b63\u786e\u7b54\u6848\uff0c\u5ffd\u7565\u4e86\u4fee\u6539\u6587\u672c\u7684\u6a21\u7cca\u6027\u3002", "method": "SoFT\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u53c2\u8003\u56fe\u50cf-\u4fee\u6539\u6587\u672c\u5bf9\u4e2d\u63d0\u53d6\u4e24\u79cd\u4e92\u8865\u7ea6\u675f\uff1a\u89c4\u5b9a\u6027\uff08\u5fc5\u987b\u5305\u542b\uff09\u548c\u7981\u6b62\u6027\uff08\u5fc5\u987b\u907f\u514d\uff09\u7ea6\u675f\uff0c\u4f5c\u4e3a\u8bed\u4e49\u8fc7\u6ee4\u5668\u6765\u5956\u52b1\u6216\u60e9\u7f5a\u5019\u9009\u56fe\u50cf\u4ee5\u91cd\u65b0\u6392\u5e8f\u7ed3\u679c\u3002\u540c\u65f6\u6784\u5efa\u4e24\u9636\u6bb5\u6570\u636e\u96c6\u7ba1\u9053\uff0c\u521b\u5efa\u591a\u76ee\u6807\u4e09\u5143\u7ec4\u5e76\u91cd\u5199\u4fee\u6539\u6587\u672c\u4ee5\u63d0\u9ad8\u8bc4\u4f30\u7cbe\u5ea6\u3002", "result": "\u5728CIReVL\u68c0\u7d22\u5668\u57fa\u7840\u4e0a\u5e94\u7528SoFT\uff0c\u5728CIRR\u6570\u636e\u96c6\u4e0aR@5\u63d0\u5347\u81f365.25\uff08+12.94\uff09\uff0c\u5728CIRCO\u6570\u636e\u96c6\u4e0amAP@50\u63d0\u5347\u81f327.93\uff08+6.13\uff09\uff0c\u5728FashionIQ\u6570\u636e\u96c6\u4e0aR@50\u63d0\u5347\u81f358.44\uff08+4.59\uff09\uff0c\u663e\u793a\u51fa\u5e7f\u6cdb\u7684\u6709\u6548\u6027\u3002", "conclusion": "SoFT\u901a\u8fc7\u63d0\u53d6\u4e92\u8865\u7ea6\u675f\u548c\u6784\u5efa\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u96f6\u6837\u672c\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u4e2d\u7684\u4fe1\u606f\u7a00\u91ca\u548c\u6a21\u7cca\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u6027\u80fd\u3002"}}
{"id": "2512.20916", "categories": ["cs.IR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.20916", "abs": "https://arxiv.org/abs/2512.20916", "authors": ["Haoyu Wang", "Yitong Wang", "Jining Wang"], "title": "MMSRARec: Summarization and Retrieval Augumented Sequential Recommendation Based on Multimodal Large Language Model", "comment": "Under Review", "summary": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated significant potential in recommendation systems. However, the effective application of MLLMs to multimodal sequential recommendation remains unexplored: A) Existing methods primarily leverage the multimodal semantic understanding capabilities of pre-trained MLLMs to generate item embeddings or semantic IDs, thereby enhancing traditional recommendation models. These approaches generate item representations that exhibit limited interpretability, and pose challenges when transferring to language model-based recommendation systems. B) Other approaches convert user behavior sequence into image-text pairs and perform recommendation through multiple MLLM inference, incurring prohibitive computational and time costs. C) Current MLLM-based recommendation systems generally neglect the integration of collaborative signals. To address these limitations while balancing recommendation performance, interpretability, and computational cost, this paper proposes MultiModal Summarization-and-Retrieval-Augmented Sequential Recommendation. Specifically, we first employ MLLM to summarize items into concise keywords and fine-tune the model using rewards that incorporate summary length, information loss, and reconstruction difficulty, thereby enabling adaptive adjustment of the summarization policy. Inspired by retrieval-augmented generation, we then transform collaborative signals into corresponding keywords and integrate them as supplementary context. Finally, we apply supervised fine-tuning with multi-task learning to align the MLLM with the multimodal sequential recommendation. Extensive evaluations on common recommendation datasets demonstrate the effectiveness of MMSRARec, showcasing its capability to efficiently and interpretably understand user behavior histories and item information for accurate recommendations.", "AI": {"tldr": "\u63d0\u51faMMSRARec\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u603b\u7ed3\u7269\u54c1\u4e3a\u5173\u952e\u8bcd\uff0c\u7ed3\u5408\u534f\u540c\u4fe1\u53f7\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u5e8f\u5217\u63a8\u8350", "motivation": "\u5f53\u524dMLLM\u5728\u63a8\u8350\u7cfb\u7edf\u5e94\u7528\u4e2d\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u73b0\u6709\u65b9\u6cd5\u751f\u6210\u7684\u7269\u54c1\u8868\u793a\u53ef\u89e3\u91ca\u6027\u6709\u9650\uff0c\u96be\u4ee5\u8fc1\u79fb\u5230\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u8350\u7cfb\u7edf\uff1b2\uff09\u5c06\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u8f6c\u6362\u4e3a\u56fe\u50cf-\u6587\u672c\u5bf9\u8fdb\u884c\u591a\u6b21MLLM\u63a8\u7406\uff0c\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff1b3\uff09\u73b0\u6709MLLM\u63a8\u8350\u7cfb\u7edf\u901a\u5e38\u5ffd\u7565\u534f\u540c\u4fe1\u53f7\u7684\u6574\u5408", "method": "1\uff09\u4f7f\u7528MLLM\u5c06\u7269\u54c1\u603b\u7ed3\u4e3a\u7b80\u6d01\u5173\u952e\u8bcd\uff0c\u5e76\u901a\u8fc7\u5956\u52b1\u673a\u5236\uff08\u5305\u542b\u603b\u7ed3\u957f\u5ea6\u3001\u4fe1\u606f\u635f\u5931\u548c\u91cd\u6784\u96be\u5ea6\uff09\u5fae\u8c03\u6a21\u578b\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u603b\u7ed3\u7b56\u7565\uff1b2\uff09\u53d7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u542f\u53d1\uff0c\u5c06\u534f\u540c\u4fe1\u53f7\u8f6c\u6362\u4e3a\u76f8\u5e94\u5173\u952e\u8bcd\u4f5c\u4e3a\u8865\u5145\u4e0a\u4e0b\u6587\uff1b3\uff09\u901a\u8fc7\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u76d1\u7763\u5fae\u8c03\uff0c\u4f7fMLLM\u4e0e\u591a\u6a21\u6001\u5e8f\u5217\u63a8\u8350\u5bf9\u9f50", "result": "\u5728\u5e38\u89c1\u63a8\u8350\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8bc1\u660e\u4e86MMSRARec\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u80fd\u591f\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u5730\u7406\u89e3\u7528\u6237\u884c\u4e3a\u5386\u53f2\u548c\u7269\u54c1\u4fe1\u606f\uff0c\u5b9e\u73b0\u51c6\u786e\u63a8\u8350", "conclusion": "MMSRARec\u65b9\u6cd5\u5728\u63a8\u8350\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u89e3\u51b3\u4e86\u5f53\u524dMLLM\u63a8\u8350\u7cfb\u7edf\u7684\u4e3b\u8981\u5c40\u9650\u6027\uff0c\u4e3a\u591a\u6a21\u6001\u5e8f\u5217\u63a8\u8350\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.20869", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.20869", "abs": "https://arxiv.org/abs/2512.20869", "authors": ["Felipe A. Louza", "Arnaud Lefebvre"], "title": "In-Place BWT and Lyndon Array Construction in Constant Space", "comment": null, "summary": "We present an extension of the in-place BWT algorithm of Crochemore et al. [8] that enables the construction of the Lyndon array using O(1) extra space. Our approach incrementally maintains the lexicographic ranks of the suffixes during the right-to-left BWT construction and then derives the Lyndon array through a simple next-smaller-value procedure. Although not intended for practical use due to its quadratic running time, the method is conceptually simple and works for unbounded alphabets.", "AI": {"tldr": "\u6269\u5c55Crochemore\u7b49\u4eba\u7684\u539f\u5730BWT\u7b97\u6cd5\uff0c\u4f7f\u7528O(1)\u989d\u5916\u7a7a\u95f4\u6784\u5efaLyndon\u6570\u7ec4", "motivation": "\u73b0\u6709Lyndon\u6570\u7ec4\u6784\u5efa\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u989d\u5916\u7a7a\u95f4\uff0c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u4ec5\u9700O(1)\u989d\u5916\u7a7a\u95f4\u7684\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u65e0\u754c\u5b57\u6bcd\u8868", "method": "\u6269\u5c55Crochemore\u7b49\u4eba\u7684\u539f\u5730BWT\u7b97\u6cd5\uff0c\u5728\u4ece\u53f3\u5230\u5de6\u6784\u5efaBWT\u8fc7\u7a0b\u4e2d\u589e\u91cf\u7ef4\u62a4\u540e\u7f00\u7684\u5b57\u5178\u5e8f\u6392\u540d\uff0c\u7136\u540e\u901a\u8fc7next-smaller-value\u8fc7\u7a0b\u63a8\u5bfcLyndon\u6570\u7ec4", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u4ec5\u9700O(1)\u989d\u5916\u7a7a\u95f4\u7684Lyndon\u6570\u7ec4\u6784\u5efa\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u65e0\u754c\u5b57\u6bcd\u8868\uff0c\u4f46\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a\u4e8c\u6b21\u65b9", "conclusion": "\u8be5\u65b9\u6cd5\u6982\u5ff5\u7b80\u5355\uff0c\u867d\u7136\u4e8c\u6b21\u65f6\u95f4\u590d\u6742\u5ea6\u4e0d\u9002\u5408\u5b9e\u9645\u5e94\u7528\uff0c\u4f46\u5728\u7406\u8bba\u4e0a\u63d0\u4f9b\u4e86\u4ec5\u9700O(1)\u989d\u5916\u7a7a\u95f4\u7684Lyndon\u6570\u7ec4\u6784\u5efa\u65b9\u6848"}}
{"id": "2512.20864", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2512.20864", "abs": "https://arxiv.org/abs/2512.20864", "authors": ["Suhyeon Lee", "Dieu-Huyen Nguyen", "Donghwan Lee"], "title": "(Im)possibility of Incentive Design for Challenge-based Blockchain Protocols", "comment": null, "summary": "Blockchains offer a decentralized and secure execution environment strong enough to host cryptocurrencies, but the state-replication model makes on-chain computation expensive. To avoid heavy on-chain workloads, systems like Truebit and optimistic rollups use challenge-based protocols, performing computations off-chain and invoking the chain only when challenged. This keeps normal-case costs low and, if at least one honest challenger exists, can catch fraud. What has been less clear is whether honest challengers are actually incentivized and a dishonest proposer is properly damaged under the worst case environment. We build a model with a colluding minority, heterogeneous costs, and three ordering modes. We then ask whether two goals can be met together: honest non-loss and fraud deterrence. Our results are clear: in single-winner designs, the incentive design is impossible or limited in scale. By contrast, in multi-winner designs, we obtain simple, explicit conditions under which both goals hold.", "AI": {"tldr": "\u533a\u5757\u94fe\u6311\u6218\u534f\u8bae\u6fc0\u52b1\u5206\u6790\uff1a\u5355\u8d62\u5bb6\u8bbe\u8ba1\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u8bda\u5b9e\u65e0\u635f\u5931\u548c\u6b3a\u8bc8\u5a01\u6151\uff0c\u591a\u8d62\u5bb6\u8bbe\u8ba1\u53ef\u8fbe\u6210", "motivation": "\u73b0\u6709\u533a\u5757\u94fe\u6311\u6218\u534f\u8bae\uff08\u5982Truebit\u548c\u4e50\u89c2\u6c47\u603b\uff09\u4f9d\u8d56\u8bda\u5b9e\u6311\u6218\u8005\u6765\u68c0\u6d4b\u6b3a\u8bc8\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8bda\u5b9e\u6311\u6218\u8005\u6fc0\u52b1\u548c\u6b3a\u8bc8\u8005\u60e9\u7f5a\u7684\u4e25\u683c\u5206\u6790\uff0c\u7279\u522b\u662f\u5728\u6700\u574f\u60c5\u51b5\u4e0b", "method": "\u5efa\u7acb\u5305\u542b\u5408\u8c0b\u5c11\u6570\u6d3e\u3001\u5f02\u8d28\u6210\u672c\u548c\u4e09\u79cd\u6392\u5e8f\u6a21\u5f0f\u7684\u6a21\u578b\uff0c\u5206\u6790\u8bda\u5b9e\u65e0\u635f\u5931\u548c\u6b3a\u8bc8\u5a01\u6151\u4e24\u4e2a\u76ee\u6807\u80fd\u5426\u540c\u65f6\u5b9e\u73b0", "result": "\u5355\u8d62\u5bb6\u8bbe\u8ba1\u4e2d\u6fc0\u52b1\u8bbe\u8ba1\u4e0d\u53ef\u80fd\u6216\u89c4\u6a21\u53d7\u9650\uff1b\u591a\u8d62\u5bb6\u8bbe\u8ba1\u4e2d\u53ef\u83b7\u5f97\u7b80\u5355\u660e\u786e\u7684\u6761\u4ef6\u4f7f\u4e24\u4e2a\u76ee\u6807\u540c\u65f6\u6210\u7acb", "conclusion": "\u591a\u8d62\u5bb6\u8bbe\u8ba1\u6bd4\u5355\u8d62\u5bb6\u8bbe\u8ba1\u5728\u6fc0\u52b1\u8bda\u5b9e\u6311\u6218\u8005\u548c\u5a01\u6151\u6b3a\u8bc8\u65b9\u9762\u66f4\u5177\u4f18\u52bf\uff0c\u4e3a\u533a\u5757\u94fe\u6311\u6218\u534f\u8bae\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6fc0\u52b1\u4fdd\u969c"}}
{"id": "2512.20896", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.20896", "abs": "https://arxiv.org/abs/2512.20896", "authors": ["Kazuma Onishi", "Katsuhiko Hayashi", "Hidetaka Kamigaito"], "title": "Accurate and Diverse Recommendations via Propensity-Weighted Linear Autoencoders", "comment": "Published in the proceedings of SIGIR-AP'25", "summary": "In real-world recommender systems, user-item interactions are Missing Not At Random (MNAR), as interactions with popular items are more frequently observed than those with less popular ones. Missing observations shift recommendations toward frequently interacted items, which reduces the diversity of the recommendation list. To alleviate this problem, Inverse Propensity Scoring (IPS) is widely used and commonly models propensities based on a power-law function of item interaction frequency. However, we found that such power-law-based correction overly penalizes popular items and harms their recommendation performance. We address this issue by redefining the propensity score to allow broader item recommendation without excessively penalizing popular items. The proposed score is formulated by applying a sigmoid function to the logarithm of the item observation frequency, maintaining the simplicity of power-law scoring while allowing for more flexible adjustment. Furthermore, we incorporate the redefined propensity score into a linear autoencoder model, which tends to favor popular items, and evaluate its effectiveness. Experimental results revealed that our method substantially improves the diversity of items in the recommendation list without sacrificing recommendation accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8esigmoid\u51fd\u6570\u7684\u503e\u5411\u6027\u8bc4\u5206\u65b9\u6cd5\uff0c\u89e3\u51b3MNAR\u6570\u636e\u4e2d\u4f20\u7edf\u5e42\u5f8b\u503e\u5411\u6027\u8bc4\u5206\u8fc7\u5ea6\u60e9\u7f5a\u70ed\u95e8\u7269\u54c1\u7684\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u63a8\u8350\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u5347\u63a8\u8350\u591a\u6837\u6027\u3002", "motivation": "\u73b0\u5b9e\u63a8\u8350\u7cfb\u7edf\u4e2d\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\u5b58\u5728MNAR\u95ee\u9898\uff0c\u70ed\u95e8\u7269\u54c1\u7684\u4ea4\u4e92\u66f4\u9891\u7e41\u88ab\u89c2\u5bdf\u5230\u3002\u4f20\u7edf\u57fa\u4e8e\u5e42\u5f8b\u51fd\u6570\u7684\u9006\u503e\u5411\u6027\u8bc4\u5206(IPS)\u8fc7\u5ea6\u60e9\u7f5a\u70ed\u95e8\u7269\u54c1\uff0c\u635f\u5bb3\u5176\u63a8\u8350\u6027\u80fd\uff0c\u9700\u8981\u66f4\u5e73\u8861\u7684\u65b9\u6cd5\u3002", "method": "\u91cd\u65b0\u5b9a\u4e49\u503e\u5411\u6027\u8bc4\u5206\uff0c\u5c06\u7269\u54c1\u89c2\u5bdf\u9891\u7387\u7684\u5bf9\u6570\u901a\u8fc7sigmoid\u51fd\u6570\u8f6c\u6362\uff0c\u4fdd\u6301\u5e42\u5f8b\u8bc4\u5206\u7684\u7b80\u5355\u6027\u540c\u65f6\u5141\u8bb8\u66f4\u7075\u6d3b\u7684\u8c03\u6574\u3002\u5c06\u65b0\u8bc4\u5206\u6574\u5408\u5230\u503e\u5411\u4e8e\u63a8\u8350\u70ed\u95e8\u7269\u54c1\u7684\u7ebf\u6027\u81ea\u7f16\u7801\u5668\u6a21\u578b\u4e2d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u8350\u5217\u8868\u4e2d\u7269\u54c1\u7684\u591a\u6837\u6027\uff0c\u540c\u65f6\u6ca1\u6709\u727a\u7272\u63a8\u8350\u51c6\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684sigmoid\u503e\u5411\u6027\u8bc4\u5206\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfIPS\u8fc7\u5ea6\u60e9\u7f5a\u70ed\u95e8\u7269\u54c1\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u63a8\u8350\u591a\u6837\u6027\u548c\u51c6\u786e\u6027\u7684\u66f4\u597d\u5e73\u8861\u3002"}}
{"id": "2512.21076", "categories": ["cs.IR", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.21076", "abs": "https://arxiv.org/abs/2512.21076", "authors": ["Suraj Kumar", "Utsav Kumar Nareti", "Soumi Chattopadhyay", "Chandranath Adak", "Prolay Mallick"], "title": "Blurb-Refined Inference from Crowdsourced Book Reviews using Hierarchical Genre Mining with Dual-Path Graph Convolutions", "comment": "10 pages, 4 figures, 3 tables", "summary": "Accurate book genre classification is fundamental to digital library organization, content discovery, and personalized recommendation. Existing approaches typically model genre prediction as a flat, single-label task, ignoring hierarchical genre structure and relying heavily on noisy, subjective user reviews, which often degrade classification reliability. We propose HiGeMine, a two-phase hierarchical genre mining framework that robustly integrates user reviews with authoritative book blurbs. In the first phase, HiGeMine employs a zero-shot semantic alignment strategy to filter reviews, retaining only those semantically consistent with the corresponding blurb, thereby mitigating noise, bias, and irrelevance. In the second phase, we introduce a dual-path, two-level graph-based classification architecture: a coarse-grained Level-1 binary classifier distinguishes fiction from non-fiction, followed by Level-2 multi-label classifiers for fine-grained genre prediction. Inter-genre dependencies are explicitly modeled using a label co-occurrence graph, while contextual representations are derived from pretrained language models applied to the filtered textual content. To facilitate systematic evaluation, we curate a new hierarchical book genre dataset. Extensive experiments demonstrate that HiGeMine consistently outperformed strong baselines across hierarchical genre classification tasks. The proposed framework offers a principled and effective solution for leveraging both structured and unstructured textual data in hierarchical book genre analysis.", "AI": {"tldr": "HiGeMine\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u5206\u5c42\u56fe\u4e66\u4f53\u88c1\u6316\u6398\u6846\u67b6\uff0c\u901a\u8fc7\u96f6\u6837\u672c\u8bed\u4e49\u5bf9\u9f50\u8fc7\u6ee4\u7528\u6237\u8bc4\u8bba\u566a\u58f0\uff0c\u7ed3\u5408\u53cc\u8def\u5f84\u56fe\u5206\u7c7b\u67b6\u6784\uff0c\u5229\u7528\u6807\u7b7e\u5171\u73b0\u56fe\u5efa\u6a21\u4f53\u88c1\u4f9d\u8d56\u5173\u7cfb\uff0c\u663e\u8457\u63d0\u5347\u5206\u5c42\u4f53\u88c1\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u56fe\u4e66\u4f53\u88c1\u5206\u7c7b\u65b9\u6cd5\u901a\u5e38\u5c06\u5176\u5efa\u6a21\u4e3a\u6241\u5e73\u7684\u5355\u6807\u7b7e\u4efb\u52a1\uff0c\u5ffd\u7565\u4e86\u4f53\u88c1\u7684\u5c42\u6b21\u7ed3\u6784\uff0c\u5e76\u4e14\u8fc7\u5ea6\u4f9d\u8d56\u5608\u6742\u3001\u4e3b\u89c2\u7684\u7528\u6237\u8bc4\u8bba\uff0c\u8fd9\u964d\u4f4e\u4e86\u5206\u7c7b\u7684\u53ef\u9760\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u6574\u5408\u6743\u5a01\u4e66\u7c4d\u7b80\u4ecb\u548c\u7528\u6237\u8bc4\u8bba\uff0c\u540c\u65f6\u8003\u8651\u4f53\u88c1\u5c42\u6b21\u7ed3\u6784\u7684\u9c81\u68d2\u65b9\u6cd5\u3002", "method": "\u63d0\u51faHiGeMine\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u96f6\u6837\u672c\u8bed\u4e49\u5bf9\u9f50\u7b56\u7565\u8fc7\u6ee4\u7528\u6237\u8bc4\u8bba\uff0c\u4fdd\u7559\u4e0e\u4e66\u7c4d\u7b80\u4ecb\u8bed\u4e49\u4e00\u81f4\u7684\u5185\u5bb9\uff1b\u7b2c\u4e8c\u9636\u6bb5\u91c7\u7528\u53cc\u8def\u5f84\u3001\u4e24\u7ea7\u7684\u56fe\u5206\u7c7b\u67b6\u6784\uff1a\u7b2c\u4e00\u7ea7\u7c97\u7c92\u5ea6\u4e8c\u5143\u5206\u7c7b\u5668\u533a\u5206\u5c0f\u8bf4\u4e0e\u975e\u5c0f\u8bf4\uff0c\u7b2c\u4e8c\u7ea7\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4f53\u88c1\u9884\u6d4b\uff0c\u4f7f\u7528\u6807\u7b7e\u5171\u73b0\u56fe\u5efa\u6a21\u4f53\u88c1\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u83b7\u53d6\u4e0a\u4e0b\u6587\u8868\u793a\u3002", "result": "\u6784\u5efa\u4e86\u65b0\u7684\u5206\u5c42\u56fe\u4e66\u4f53\u88c1\u6570\u636e\u96c6\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5927\u91cf\u5b9e\u9a8c\u8868\u660eHiGeMine\u5728\u5206\u5c42\u4f53\u88c1\u5206\u7c7b\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u5229\u7528\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u6587\u672c\u6570\u636e\u8fdb\u884c\u5206\u5c42\u56fe\u4e66\u4f53\u88c1\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "HiGeMine\u6846\u67b6\u901a\u8fc7\u6574\u5408\u6743\u5a01\u4e66\u7c4d\u7b80\u4ecb\u548c\u8fc7\u6ee4\u540e\u7684\u7528\u6237\u8bc4\u8bba\uff0c\u7ed3\u5408\u5c42\u6b21\u5316\u5206\u7c7b\u67b6\u6784\u548c\u4f53\u88c1\u4f9d\u8d56\u5efa\u6a21\uff0c\u4e3a\u56fe\u4e66\u4f53\u88c1\u5206\u7c7b\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u548c\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u6027\u80fd\u3002"}}
{"id": "2512.20960", "categories": ["cs.DS", "cs.DM"], "pdf": "https://arxiv.org/pdf/2512.20960", "abs": "https://arxiv.org/abs/2512.20960", "authors": ["Mohammadreza Daneshvaramoli", "Helia Karisani", "Mohammad Hajiesmaili", "Shahin Kamali", "Cameron Musco"], "title": "Fairness in the k-Server Problem", "comment": "49 pages, 2 figures, Innovations in Theoretical Computer Science(ITCS) 2026", "summary": "We initiate a formal study of fairness for the $k$-server problem, where the objective is not only to minimize the total movement cost, but also to distribute the cost equitably among servers. We first define a general notion of $(\u03b1,\u03b2)$-fairness, where, for parameters $\u03b1\\ge 1$ and $\u03b2\\ge 0$, no server incurs more than an $\u03b1/k$-fraction of the total cost plus an additive term $\u03b2$. We then show that fairness can be achieved without a loss in competitiveness in both the offline and online settings. In the offline setting, we give a deterministic algorithm that, for any $\\varepsilon > 0$, transforms any optimal solution into an $(\u03b1,\u03b2)$-fair solution for $\u03b1= 1 + \\varepsilon$ and $\u03b2= O(\\mathrm{diam} \\cdot \\log k / \\varepsilon)$, while increasing the cost of the solution by just an additive $O(\\mathrm{diam} \\cdot k \\log k / \\varepsilon)$ term. Here $\\mathrm{diam}$ is the diameter of the underlying metric space. We give a similar result in the online setting, showing that any competitive algorithm can be transformed into a randomized online algorithm that is fair with high probability against an oblivious adversary and still competitive up to a small loss.\n  The above results leave open a significant question: can fairness be achieved in the online setting, either with a deterministic algorithm or a randomized algorithm, against a fully adaptive adversary? We make progress towards answering this question, showing that the classic deterministic Double Coverage Algorithm (DCA) is fair on line metrics and on tree metrics when $k = 2$. However, we also show a negative result: DCA fails to be fair for any non-vacuous parameters on general tree metrics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5f62\u5f0f\u5316\u7814\u7a76k-server\u95ee\u9898\u4e2d\u7684\u516c\u5e73\u6027\uff0c\u5728\u6700\u5c0f\u5316\u603b\u79fb\u52a8\u6210\u672c\u7684\u540c\u65f6\uff0c\u8981\u6c42\u6210\u672c\u5728\u670d\u52a1\u5668\u95f4\u516c\u5e73\u5206\u914d\u3002\u63d0\u51fa\u4e86(\u03b1,\u03b2)-\u516c\u5e73\u6027\u5b9a\u4e49\uff0c\u5e76\u8bc1\u660e\u5728\u7ebf\u548c\u79bb\u7ebf\u8bbe\u7f6e\u4e2d\u90fd\u80fd\u5728\u4e0d\u635f\u5931\u7ade\u4e89\u6027\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u516c\u5e73\u3002", "motivation": "\u4f20\u7edfk-server\u95ee\u9898\u53ea\u5173\u6ce8\u6700\u5c0f\u5316\u603b\u79fb\u52a8\u6210\u672c\uff0c\u5ffd\u7565\u4e86\u6210\u672c\u5728\u670d\u52a1\u5668\u95f4\u7684\u516c\u5e73\u5206\u914d\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u670d\u52a1\u5668\u53ef\u80fd\u5c5e\u4e8e\u4e0d\u540c\u5b9e\u4f53\u6216\u5177\u6709\u4e0d\u540c\u8d44\u6e90\u9650\u5236\uff0c\u9700\u8981\u786e\u4fdd\u6ca1\u6709\u670d\u52a1\u5668\u627f\u62c5\u4e0d\u6210\u6bd4\u4f8b\u7684\u6210\u672c\u8d1f\u62c5\u3002", "method": "\u63d0\u51fa(\u03b1,\u03b2)-\u516c\u5e73\u6027\u5f62\u5f0f\u5316\u5b9a\u4e49\uff1a\u4efb\u4f55\u670d\u52a1\u5668\u627f\u62c5\u7684\u6210\u672c\u4e0d\u8d85\u8fc7\u603b\u6210\u672c\u7684\u03b1/k\u52a0\u4e0a\u03b2\u3002\u5728\u79bb\u7ebf\u8bbe\u7f6e\u4e2d\uff0c\u8bbe\u8ba1\u786e\u5b9a\u6027\u7b97\u6cd5\u5c06\u6700\u4f18\u89e3\u8f6c\u6362\u4e3a\u516c\u5e73\u89e3\uff1b\u5728\u7ebf\u8bbe\u7f6e\u4e2d\uff0c\u5c06\u7ade\u4e89\u6027\u7b97\u6cd5\u8f6c\u6362\u4e3a\u516c\u5e73\u7684\u968f\u673a\u5728\u7ebf\u7b97\u6cd5\u3002\u8fd8\u5206\u6790\u4e86\u7ecf\u5178\u786e\u5b9a\u6027\u53cc\u8986\u76d6\u7b97\u6cd5(DCA)\u5728\u4e0d\u540c\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u7684\u516c\u5e73\u6027\u8868\u73b0\u3002", "result": "1) \u79bb\u7ebf\u8bbe\u7f6e\uff1a\u53ef\u5c06\u6700\u4f18\u89e3\u8f6c\u6362\u4e3a(1+\u03b5, O(diam\u00b7log k/\u03b5))-\u516c\u5e73\u89e3\uff0c\u4ec5\u589e\u52a0O(diam\u00b7k log k/\u03b5)\u6210\u672c\uff1b2) \u5728\u7ebf\u8bbe\u7f6e\uff1a\u53ef\u5c06\u7ade\u4e89\u6027\u7b97\u6cd5\u8f6c\u6362\u4e3a\u516c\u5e73\u7684\u968f\u673a\u5728\u7ebf\u7b97\u6cd5\uff1b3) DCA\u5728\u7ebf\u5ea6\u91cf\u548ck=2\u7684\u6811\u5ea6\u91cf\u4e0a\u662f\u516c\u5e73\u7684\uff0c\u4f46\u5728\u4e00\u822c\u6811\u5ea6\u91cf\u4e0a\u4e0d\u516c\u5e73\u3002", "conclusion": "\u516c\u5e73\u6027\u53ef\u4ee5\u5728k-server\u95ee\u9898\u4e2d\u5b9e\u73b0\u800c\u4e0d\u663e\u8457\u635f\u5931\u6027\u80fd\uff0c\u4f46\u5b8c\u5168\u81ea\u9002\u5e94\u5bf9\u624b\u4e0b\u7684\u5728\u7ebf\u516c\u5e73\u6027\u4ecd\u662f\u5f00\u653e\u95ee\u9898\u3002DCA\u5728\u67d0\u4e9b\u7279\u6b8a\u5ea6\u91cf\u7a7a\u95f4\u4e0a\u5177\u6709\u516c\u5e73\u6027\uff0c\u4f46\u5728\u4e00\u822c\u6811\u5ea6\u91cf\u4e0a\u4e0d\u6210\u7acb\u3002"}}
{"id": "2512.21024", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21024", "abs": "https://arxiv.org/abs/2512.21024", "authors": ["Yue Lin", "Shuhui Zhu", "Wenhao Li", "Ang Li", "Dan Qiao", "Pascal Poupart", "Hongyuan Zha", "Baoxiang Wang"], "title": "Policy-Conditioned Policies for Multi-Agent Task Solving", "comment": null, "summary": "In multi-agent tasks, the central challenge lies in the dynamic adaptation of strategies. However, directly conditioning on opponents' strategies is intractable in the prevalent deep reinforcement learning paradigm due to a fundamental ``representational bottleneck'': neural policies are opaque, high-dimensional parameter vectors that are incomprehensible to other agents. In this work, we propose a paradigm shift that bridges this gap by representing policies as human-interpretable source code and utilizing Large Language Models (LLMs) as approximate interpreters. This programmatic representation allows us to operationalize the game-theoretic concept of \\textit{Program Equilibrium}. We reformulate the learning problem by utilizing LLMs to perform optimization directly in the space of programmatic policies. The LLM functions as a point-wise best-response operator that iteratively synthesizes and refines the ego agent's policy code to respond to the opponent's strategy. We formalize this process as \\textit{Programmatic Iterated Best Response (PIBR)}, an algorithm where the policy code is optimized by textual gradients, using structured feedback derived from game utility and runtime unit tests. We demonstrate that this approach effectively solves several standard coordination matrix games and a cooperative Level-Based Foraging environment.", "AI": {"tldr": "\u63d0\u51fa\u7528\u53ef\u89e3\u91ca\u7684\u6e90\u4ee3\u7801\u8868\u793a\u7b56\u7565\uff0c\u5229\u7528LLM\u4f5c\u4e3a\u8fd1\u4f3c\u89e3\u91ca\u5668\uff0c\u5b9e\u73b0\u7a0b\u5e8f\u5747\u8861\uff0c\u901a\u8fc7\u6587\u672c\u68af\u5ea6\u4f18\u5316\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u534f\u8c03\u95ee\u9898\u3002", "motivation": "\u5728\u591a\u667a\u80fd\u4f53\u4efb\u52a1\u4e2d\uff0c\u76f4\u63a5\u57fa\u4e8e\u5bf9\u624b\u7b56\u7565\u8c03\u6574\u7b56\u7565\u5b58\u5728\"\u8868\u793a\u74f6\u9888\"\u95ee\u9898\uff1a\u795e\u7ecf\u7b56\u7565\u662f\u4e0d\u900f\u660e\u7684\u9ad8\u7ef4\u53c2\u6570\u5411\u91cf\uff0c\u5176\u4ed6\u667a\u80fd\u4f53\u65e0\u6cd5\u7406\u89e3\u3002\u9700\u8981\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u7b56\u7565\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u5c06\u7b56\u7565\u8868\u793a\u4e3a\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u6e90\u4ee3\u7801\uff0c\u5229\u7528LLM\u4f5c\u4e3a\u8fd1\u4f3c\u89e3\u91ca\u5668\uff0c\u5b9e\u73b0\u7a0b\u5e8f\u5747\u8861\u3002\u63d0\u51fa\u7a0b\u5e8f\u5316\u8fed\u4ee3\u6700\u4f18\u54cd\u5e94(PIBR)\u7b97\u6cd5\uff0c\u901a\u8fc7\u6587\u672c\u68af\u5ea6\u4f18\u5316\u7b56\u7565\u4ee3\u7801\uff0c\u4f7f\u7528\u6e38\u620f\u6548\u7528\u548c\u8fd0\u884c\u65f6\u5355\u5143\u6d4b\u8bd5\u7684\u7ed3\u6784\u5316\u53cd\u9988\u3002", "result": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u4e2a\u6807\u51c6\u534f\u8c03\u77e9\u9635\u6e38\u620f\u548c\u5408\u4f5c\u6027Level-Based Foraging\u73af\u5883\uff0c\u8bc1\u660e\u4e86\u7a0b\u5e8f\u5316\u7b56\u7565\u8868\u793a\u548cLLM\u4f18\u5316\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7b56\u7565\u8868\u793a\u4e3a\u6e90\u4ee3\u7801\u5e76\u5229\u7528LLM\u8fdb\u884c\u4f18\u5316\uff0c\u6210\u529f\u514b\u670d\u4e86\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u4e2d\u7684\u8868\u793a\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u53ef\u89e3\u91ca\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2512.20962", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.20962", "abs": "https://arxiv.org/abs/2512.20962", "authors": ["Shaun Scovil", "Bhargav Chickmagalur Nanjundappa"], "title": "Time-Bucketed Balance Records: Bounded-Storage Ephemeral Tokens for Resource-Constrained Systems", "comment": "14 pages, 1 figure, 1 Algorithm, 3 Theorems", "summary": "Fungible tokens with time-to-live (TTL) semantics require tracking individual expiration times for each deposited unit. A naive implementation creates a new balance record per deposit, leading to unbounded storage growth and vulnerability to denial-of-service attacks. We present time-bucketed balance records, a data structure that bounds storage to O(k) records per account while guaranteeing that tokens never expire before their configured TTL. Our approach discretizes time into k buckets, coalescing deposits within the same bucket to limit unique expiration timestamps. We prove three key properties: (1) storage is bounded by k+1 records regardless of deposit frequency, (2) actual expiration time is always at least the configured TTL, and (3) adversaries cannot increase a victim's operation cost beyond O(k)[amortized] worst case. We provide a reference implementation in Solidity with measured gas costs demonstrating practical efficiency.", "AI": {"tldr": "\u63d0\u51fa\u65f6\u95f4\u5206\u6876\u4f59\u989d\u8bb0\u5f55\u6570\u636e\u7ed3\u6784\uff0c\u89e3\u51b3\u53ef\u66ff\u4ee3\u4ee3\u5e01TTL\u8bed\u4e49\u4e2d\u7684\u5b58\u50a8\u7206\u70b8\u95ee\u9898\uff0c\u5c06\u5b58\u50a8\u9650\u5236\u5728O(k)\u8bb0\u5f55\u5185", "motivation": "\u53ef\u66ff\u4ee3\u4ee3\u5e01\u7684\u65f6\u95f4\u5230\u671f(TTL)\u8bed\u4e49\u9700\u8981\u8ddf\u8e2a\u6bcf\u4e2a\u5b58\u5165\u5355\u4f4d\u7684\u5355\u72ec\u8fc7\u671f\u65f6\u95f4\u3002\u4f20\u7edf\u5b9e\u73b0\u4e3a\u6bcf\u4e2a\u5b58\u6b3e\u521b\u5efa\u65b0\u4f59\u989d\u8bb0\u5f55\uff0c\u5bfc\u81f4\u5b58\u50a8\u65e0\u9650\u589e\u957f\u4e14\u6613\u53d7\u62d2\u7edd\u670d\u52a1\u653b\u51fb", "method": "\u91c7\u7528\u65f6\u95f4\u5206\u6876\u4f59\u989d\u8bb0\u5f55\u6570\u636e\u7ed3\u6784\uff0c\u5c06\u65f6\u95f4\u79bb\u6563\u5316\u4e3ak\u4e2a\u6876\uff0c\u5c06\u540c\u4e00\u6876\u5185\u7684\u5b58\u6b3e\u5408\u5e76\u4ee5\u9650\u5236\u552f\u4e00\u8fc7\u671f\u65f6\u95f4\u6233\u6570\u91cf", "result": "\u8bc1\u660e\u4e09\u4e2a\u5173\u952e\u5c5e\u6027\uff1a(1)\u5b58\u50a8\u9650\u5236\u5728k+1\u6761\u8bb0\u5f55\u5185\uff0c(2)\u5b9e\u9645\u8fc7\u671f\u65f6\u95f4\u81f3\u5c11\u7b49\u4e8e\u914d\u7f6e\u7684TTL\uff0c(3)\u653b\u51fb\u8005\u65e0\u6cd5\u5c06\u53d7\u5bb3\u8005\u64cd\u4f5c\u6210\u672c\u63d0\u9ad8\u5230O(k)\u644a\u9500\u6700\u574f\u60c5\u51b5\u4ee5\u4e0a\u3002\u63d0\u4f9bSolidity\u53c2\u8003\u5b9e\u73b0\u5e76\u6d4b\u91cf\u71c3\u6c14\u6210\u672c", "conclusion": "\u65f6\u95f4\u5206\u6876\u4f59\u989d\u8bb0\u5f55\u6570\u636e\u7ed3\u6784\u6709\u6548\u89e3\u51b3\u4e86TTL\u4ee3\u5e01\u7684\u5b58\u50a8\u7206\u70b8\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5b9e\u9645\u6548\u7387"}}
{"id": "2512.21021", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.21021", "abs": "https://arxiv.org/abs/2512.21021", "authors": ["Andre Rusli", "Miao Cao", "Shoma Ishimoto", "Sho Akiyama", "Max Frenzel"], "title": "Towards Better Search with Domain-Aware Text Embeddings for C2C Marketplaces", "comment": "5 pages, AAAI 2026 Workshop on New Frontiers in Information Retrieval", "summary": "Consumer-to-consumer (C2C) marketplaces pose distinct retrieval challenges: short, ambiguous queries; noisy, user-generated listings; and strict production constraints. This paper reports our experiment to build a domain-aware Japanese text-embedding approach to improve the quality of search at Mercari, Japan's largest C2C marketplace. We experimented with fine-tuning on purchase-driven query-title pairs, using role-specific prefixes to model query-item asymmetry. To meet production constraints, we apply Matryoshka Representation Learning to obtain compact, truncation-robust embeddings. Offline evaluation on historical search logs shows consistent gains over a strong generic encoder, with particularly large improvements when replacing PCA compression with Matryoshka truncation. A manual assessment further highlights better handling of proper nouns, marketplace-specific semantics, and term-importance alignment. Additionally, an initial online A/B test demonstrates statistically significant improvements in revenue per user and search-flow efficiency, with transaction frequency maintained. Results show that domain-aware embeddings improve relevance and efficiency at scale and form a practical foundation for richer LLM-era search experiences.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u65e5\u672cC2C\u5e02\u573a\u7684\u9886\u57df\u611f\u77e5\u6587\u672c\u5d4c\u5165\u65b9\u6cd5\uff0c\u901a\u8fc7\u5fae\u8c03\u8d2d\u4e70\u9a71\u52a8\u7684\u67e5\u8be2-\u6807\u9898\u5bf9\u3001\u4f7f\u7528\u89d2\u8272\u7279\u5b9a\u524d\u7f00\u5efa\u6a21\u67e5\u8be2-\u7269\u54c1\u4e0d\u5bf9\u79f0\u6027\uff0c\u5e76\u5e94\u7528Matryoshka\u8868\u793a\u5b66\u4e60\u83b7\u5f97\u7d27\u51d1\u7684\u622a\u65ad\u9c81\u68d2\u5d4c\u5165\uff0c\u663e\u8457\u63d0\u5347\u4e86\u641c\u7d22\u8d28\u91cf\u548c\u6548\u7387\u3002", "motivation": "C2C\u5e02\u573a\u9762\u4e34\u72ec\u7279\u7684\u68c0\u7d22\u6311\u6218\uff1a\u7b80\u77ed\u6a21\u7cca\u7684\u67e5\u8be2\u3001\u5608\u6742\u7684\u7528\u6237\u751f\u6210\u5217\u8868\u4ee5\u53ca\u4e25\u683c\u7684\u751f\u4ea7\u7ea6\u675f\u3002\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u65e5\u672cC2C\u5e02\u573a\uff08Mercari\uff09\u7684\u6587\u672c\u5d4c\u5165\u65b9\u6cd5\u6765\u63d0\u5347\u641c\u7d22\u8d28\u91cf\u3002", "method": "1. \u5728\u8d2d\u4e70\u9a71\u52a8\u7684\u67e5\u8be2-\u6807\u9898\u5bf9\u4e0a\u5fae\u8c03\u6587\u672c\u5d4c\u5165\u6a21\u578b\uff1b2. \u4f7f\u7528\u89d2\u8272\u7279\u5b9a\u524d\u7f00\u5efa\u6a21\u67e5\u8be2\u548c\u7269\u54c1\u4e4b\u95f4\u7684\u4e0d\u5bf9\u79f0\u6027\uff1b3. \u5e94\u7528Matryoshka\u8868\u793a\u5b66\u4e60\u83b7\u5f97\u7d27\u51d1\u4e14\u622a\u65ad\u9c81\u68d2\u7684\u5d4c\u5165\u8868\u793a\u3002", "result": "\u79bb\u7ebf\u8bc4\u4f30\u663e\u793a\u76f8\u6bd4\u901a\u7528\u7f16\u7801\u5668\u6709\u6301\u7eed\u63d0\u5347\uff0c\u7279\u522b\u662f\u7528Matryoshka\u622a\u65ad\u66ff\u4ee3PCA\u538b\u7f29\u65f6\u6539\u8fdb\u663e\u8457\u3002\u624b\u52a8\u8bc4\u4f30\u663e\u793a\u80fd\u66f4\u597d\u5904\u7406\u4e13\u6709\u540d\u8bcd\u3001\u5e02\u573a\u7279\u5b9a\u8bed\u4e49\u548c\u672f\u8bed\u91cd\u8981\u6027\u5bf9\u9f50\u3002\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\u7528\u6237\u6536\u5165\u548c\u641c\u7d22\u6d41\u7a0b\u6548\u7387\u6709\u7edf\u8ba1\u663e\u8457\u63d0\u5347\uff0c\u4ea4\u6613\u9891\u7387\u4fdd\u6301\u4e0d\u53d8\u3002", "conclusion": "\u9886\u57df\u611f\u77e5\u5d4c\u5165\u65b9\u6cd5\u80fd\u5728\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u63d0\u5347\u76f8\u5173\u6027\u548c\u6548\u7387\uff0c\u4e3a\u66f4\u4e30\u5bcc\u7684LLM\u65f6\u4ee3\u641c\u7d22\u4f53\u9a8c\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u3002"}}
{"id": "2512.21128", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.21128", "abs": "https://arxiv.org/abs/2512.21128", "authors": ["Meike Neuwohner", "Vera Traub", "Rico Zenklusen"], "title": "Approximation Schemes for Planar Graph Connectivity Problems", "comment": null, "summary": "Finding a smallest subgraph that is k-edge-connected, or augmenting a k-edge-connected graph with a smallest subset of given candidate edges to become (k+1)-edge-connected, are among the most fundamental Network Design problems. They are both APX-hard in general graphs. However, this hardness does not carry over to the planar setting, which is not well understood, except for very small values of k. One main obstacle in using standard decomposition techniques for planar graphs, like Baker's technique and extensions thereof, is that connectivity requirements are global (rather than local) properties that are not captured by existing frameworks.\n  We present a novel, and arguably clean, decomposition technique for such classical connectivity problems on planar graphs. This technique immediately implies PTASs for the problems of finding a smallest k-edge-connected or k-vertex-connected spanning subgraph of a planar graph for arbitrary k. By leveraging structural results for minimally k-edge-connected graphs, we further obtain a PTAS for planar k-connectivity augmentation for any constant k. We complement this with an NP-hardness result, showing that our results are essentially optimal.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5e73\u9762\u56fe\u5206\u89e3\u6280\u672f\uff0c\u89e3\u51b3\u4e86k\u8fb9\u8fde\u901a\u548ck\u9876\u70b9\u8fde\u901a\u5b50\u56fe\u7684\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u4ee5\u53ca\u5e73\u9762\u56fek\u8fde\u901a\u6027\u589e\u5f3a\u95ee\u9898\uff0c\u4e3a\u8fd9\u4e9b\u7ecf\u5178\u7f51\u7edc\u8bbe\u8ba1\u95ee\u9898\u63d0\u4f9b\u4e86PTAS\uff08\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u65b9\u6848\uff09\u3002", "motivation": "\u5728\u5e73\u9762\u56fe\u4e2d\u5bfb\u627e\u6700\u5c0f\u7684k\u8fb9\u8fde\u901a\u5b50\u56fe\u6216\u901a\u8fc7\u6dfb\u52a0\u6700\u5c0f\u8fb9\u96c6\u5c06k\u8fb9\u8fde\u901a\u56fe\u589e\u5f3a\u4e3a(k+1)\u8fb9\u8fde\u901a\u56fe\u662f\u7f51\u7edc\u8bbe\u8ba1\u4e2d\u7684\u57fa\u672c\u95ee\u9898\u3002\u8fd9\u4e9b\u95ee\u9898\u5728\u4e00\u822c\u56fe\u4e2d\u662fAPX\u96be\u7684\uff0c\u4f46\u5728\u5e73\u9762\u56fe\u8bbe\u7f6e\u4e2d\u60c5\u51b5\u5c1a\u4e0d\u6e05\u695a\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u8f83\u5927\u7684k\u503c\u3002\u73b0\u6709\u5206\u89e3\u6280\u672f\uff08\u5982Baker\u6280\u672f\uff09\u96be\u4ee5\u5904\u7406\u8fde\u901a\u6027\u8fd9\u79cd\u5168\u5c40\u6027\u8d28\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u4e14\u7b80\u6d01\u7684\u5e73\u9762\u56fe\u5206\u89e3\u6280\u672f\uff0c\u4e13\u95e8\u9488\u5bf9\u8fde\u901a\u6027\u95ee\u9898\u8bbe\u8ba1\u3002\u8be5\u6280\u672f\u5229\u7528\u4e86\u6700\u5c0fk\u8fb9\u8fde\u901a\u56fe\u7684\u7ed3\u6784\u7279\u6027\uff0c\u80fd\u591f\u5904\u7406\u8fde\u901a\u6027\u8fd9\u79cd\u5168\u5c40\u6027\u8d28\u3002", "result": "\u8be5\u6280\u672f\u4e3a\u4efb\u610fk\u503c\u7684\u5e73\u9762\u56fe\u6700\u5c0fk\u8fb9\u8fde\u901a\u6216k\u9876\u70b9\u8fde\u901a\u751f\u6210\u5b50\u56fe\u95ee\u9898\u63d0\u4f9b\u4e86PTAS\u3002\u8fdb\u4e00\u6b65\u5730\uff0c\u5bf9\u4e8e\u4efb\u610f\u5e38\u6570k\u7684\u5e73\u9762k\u8fde\u901a\u6027\u589e\u5f3a\u95ee\u9898\u4e5f\u83b7\u5f97\u4e86PTAS\u3002\u540c\u65f6\u8bc1\u660e\u4e86NP\u96be\u6027\u7ed3\u679c\uff0c\u8868\u660e\u8fd9\u4e9b\u7ed3\u679c\u5728\u672c\u8d28\u4e0a\u662f\u6700\u4f18\u7684\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u5206\u89e3\u6280\u672f\u6210\u529f\u89e3\u51b3\u4e86\u5e73\u9762\u56fe\u4e2d\u7ecf\u5178\u8fde\u901a\u6027\u95ee\u9898\u7684\u8fd1\u4f3c\u7b97\u6cd5\u8bbe\u8ba1\u96be\u9898\uff0c\u4e3a\u8fd9\u4e9b\u7f51\u7edc\u8bbe\u8ba1\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8fd1\u4f3c\u65b9\u6848\uff0c\u5e76\u901a\u8fc7NP\u96be\u6027\u8bc1\u660e\u786e\u7acb\u4e86\u7ed3\u679c\u7684\u7d27\u81f4\u6027\u3002"}}
{"id": "2512.21039", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.21039", "abs": "https://arxiv.org/abs/2512.21039", "authors": ["Roopa Bukke", "Soumya Pandey", "Suraj Kumar", "Soumi Chattopadhyay", "Chandranath Adak"], "title": "Agentic Multi-Persona Framework for Evidence-Aware Fake News Detection", "comment": "12 pages, 8 tables, 2 figures", "summary": "The rapid proliferation of online misinformation poses significant risks to public trust, policy, and safety, necessitating reliable automated fake news detection. Existing methods often struggle with multimodal content, domain generalization, and explainability. We propose AMPEND-LS, an agentic multi-persona evidence-grounded framework with LLM-SLM synergy for multimodal fake news detection. AMPEND-LS integrates textual, visual, and contextual signals through a structured reasoning pipeline powered by LLMs, augmented with reverse image search, knowledge graph paths, and persuasion strategy analysis. To improve reliability, we introduce a credibility fusion mechanism combining semantic similarity, domain trustworthiness, and temporal context, and a complementary SLM classifier to mitigate LLM uncertainty and hallucinations. Extensive experiments across three benchmark datasets demonstrate that AMPEND-LS consistently outperformed state-of-the-art baselines in accuracy, F1 score, and robustness. Qualitative case studies further highlight its transparent reasoning and resilience against evolving misinformation. This work advances the development of adaptive, explainable, and evidence-aware systems for safeguarding online information integrity.", "AI": {"tldr": "AMPEND-LS\uff1a\u57fa\u4e8eLLM-SLM\u534f\u540c\u7684\u591a\u6a21\u6001\u5047\u65b0\u95fb\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u89d2\u8272\u8bc1\u636e\u63a8\u7406\u548c\u53ef\u4fe1\u5ea6\u878d\u5408\u673a\u5236\uff0c\u5728\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u7ebf\u865a\u5047\u4fe1\u606f\u7684\u5feb\u901f\u4f20\u64ad\u5bf9\u516c\u4f17\u4fe1\u4efb\u3001\u653f\u7b56\u548c\u5b89\u5168\u6784\u6210\u91cd\u5927\u98ce\u9669\uff0c\u9700\u8981\u53ef\u9760\u7684\u81ea\u52a8\u5316\u5047\u65b0\u95fb\u68c0\u6d4b\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u5185\u5bb9\u5904\u7406\u3001\u9886\u57df\u6cdb\u5316\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51faAMPEND-LS\u6846\u67b6\uff0c\u6574\u5408\u6587\u672c\u3001\u89c6\u89c9\u548c\u4e0a\u4e0b\u6587\u4fe1\u53f7\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u7684\u7ed3\u6784\u5316\u63a8\u7406\u6d41\u7a0b\uff0c\u7ed3\u5408\u53cd\u5411\u56fe\u50cf\u641c\u7d22\u3001\u77e5\u8bc6\u56fe\u8c31\u8def\u5f84\u548c\u8bf4\u670d\u7b56\u7565\u5206\u6790\u3002\u5f15\u5165\u53ef\u4fe1\u5ea6\u878d\u5408\u673a\u5236\uff08\u8bed\u4e49\u76f8\u4f3c\u6027\u3001\u9886\u57df\u53ef\u4fe1\u5ea6\u3001\u65f6\u95f4\u4e0a\u4e0b\u6587\uff09\u548c\u8865\u5145\u7684SLM\u5206\u7c7b\u5668\u6765\u51cf\u8f7bLLM\u4e0d\u786e\u5b9a\u6027\u548c\u5e7b\u89c9\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cAMPEND-LS\u5728\u51c6\u786e\u6027\u3001F1\u5206\u6570\u548c\u9c81\u68d2\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u5b9a\u6027\u6848\u4f8b\u7814\u7a76\u8fdb\u4e00\u6b65\u7a81\u51fa\u4e86\u5176\u900f\u660e\u63a8\u7406\u80fd\u529b\u548c\u5bf9\u6f14\u5316\u865a\u5047\u4fe1\u606f\u7684\u97e7\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63a8\u52a8\u4e86\u81ea\u9002\u5e94\u3001\u53ef\u89e3\u91ca\u548c\u8bc1\u636e\u611f\u77e5\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u7528\u4e8e\u4fdd\u62a4\u5728\u7ebf\u4fe1\u606f\u5b8c\u6574\u6027\uff0c\u4e3a\u5e94\u5bf9\u4e0d\u65ad\u6f14\u53d8\u7684\u865a\u5047\u4fe1\u606f\u5a01\u80c1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.21195", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.21195", "abs": "https://arxiv.org/abs/2512.21195", "authors": ["Nick Dawes"], "title": "An O($nlogn$) approximate knapsack algorithm", "comment": "8 pages", "summary": "A modified dynamic programming algorithm rapidly and accurately solves large 0/1 knapsack problems. It has computational O($nlogn$), space O($nlogn$) and predictable maximum error. Experimentally it's accuracy increases faster than linearly with the solution size $k$. Problems with $k=10^3$ are solved with an average maximum fractional error of $10^{-4}$ and problems with $k=10^5$ with an average maximum fractional error of $10^{-7}$. The algorithm runs in constant time for all problems with a given $n$. On a common desktop computer the algorithm processes $n=10^3$ problems in $10^{-3}$ seconds and $n=10^6$ problems in 2 seconds.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6539\u8fdb\u7684\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\uff0c\u80fd\u5feb\u901f\u51c6\u786e\u89e3\u51b3\u5927\u89c4\u6a210/1\u80cc\u5305\u95ee\u9898\uff0c\u5177\u6709O(nlogn)\u65f6\u95f4/\u7a7a\u95f4\u590d\u6742\u5ea6\uff0c\u8bef\u5dee\u53ef\u9884\u6d4b\uff0c\u4e14\u7cbe\u5ea6\u968f\u89e3\u89c4\u6a21k\u589e\u957f\u800c\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u89e3\u51b3\u5927\u89c4\u6a210/1\u80cc\u5305\u95ee\u9898\u65f6\u9762\u4e34\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u8fd1\u4f3c\u7b97\u6cd5\u6765\u5904\u7406\u5927\u89c4\u6a21\u5b9e\u4f8b\u3002", "method": "\u91c7\u7528\u6539\u8fdb\u7684\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u6570\u636e\u7ed3\u6784\uff08\u53ef\u80fd\u4f7f\u7528\u8fd1\u4f3c\u6280\u672f\u6216\u526a\u679d\u7b56\u7565\uff09\u6765\u964d\u4f4e\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u9884\u6d4b\u7684\u8bef\u5dee\u754c\u9650\u3002", "result": "\u7b97\u6cd5\u5728k=10\u00b3\u65f6\u5e73\u5747\u6700\u5927\u5206\u6570\u8bef\u5dee\u4e3a10\u207b\u2074\uff0ck=10\u2075\u65f6\u8bef\u5dee\u964d\u81f310\u207b\u2077\uff1b\u5728\u666e\u901a\u684c\u9762\u8ba1\u7b97\u673a\u4e0a\uff0cn=10\u00b3\u95ee\u9898\u5904\u7406\u65f6\u95f4\u4e3a10\u207b\u00b3\u79d2\uff0cn=10\u2076\u95ee\u9898\u4ec5\u97002\u79d2\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u4e3a\u5927\u89c4\u6a210/1\u80cc\u5305\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u53ef\u63a5\u53d7\u7684\u8bef\u5dee\u8303\u56f4\u5185\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2512.21257", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21257", "abs": "https://arxiv.org/abs/2512.21257", "authors": ["Chuan Wang", "Gaoming Yang", "Han Wu", "Jiakai Tang", "Jiahao Yu", "Jian Wu", "Jianwu Hu", "Junjun Zheng", "Shuwen Xiao", "Yeqiu Yang", "Yuning Jiang", "Ahjol Nurlanbek", "Binbin Cao", "Bo Zheng", "Fangmei Zhu", "Gaoming Zhou", "Huimin Yi", "Huiping Chu", "Jin Huang", "Jinzhe Shan", "Kenan Cui", "Longbin Li", "Silu Zhou", "Wen Chen", "Xia Ming", "Xiang Gao", "Xin Yao", "Xingyu Wen", "Yan Zhang", "Yiwen Hu", "Yulin Wang", "Ziheng Bao", "Zongyuan Wu"], "title": "ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling", "comment": null, "summary": "Industrial recommender systems face two fundamental limitations under the log-driven paradigm: (1) knowledge poverty in ID-based item representations that causes brittle interest modeling under data sparsity, and (2) systemic blindness to beyond-log user interests that constrains model performance within platform boundaries. These limitations stem from an over-reliance on shallow interaction statistics and close-looped feedback while neglecting the rich world knowledge about product semantics and cross-domain behavioral patterns that Large Language Models have learned from vast corpora.\n  To address these challenges, we introduce ReaSeq, a reasoning-enhanced framework that leverages world knowledge in Large Language Models to address both limitations through explicit and implicit reasoning. Specifically, ReaSeq employs explicit Chain-of-Thought reasoning via multi-agent collaboration to distill structured product knowledge into semantically enriched item representations, and latent reasoning via Diffusion Large Language Models to infer plausible beyond-log behaviors. Deployed on Taobao's ranking system serving hundreds of millions of users, ReaSeq achieves substantial gains: >6.0% in IPV and CTR, >2.9% in Orders, and >2.5% in GMV, validating the effectiveness of world-knowledge-enhanced reasoning over purely log-driven approaches.", "AI": {"tldr": "ReaSeq\u662f\u4e00\u4e2a\u63a8\u7406\u589e\u5f3a\u7684\u63a8\u8350\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e16\u754c\u77e5\u8bc6\u89e3\u51b3\u4f20\u7edf\u65e5\u5fd7\u9a71\u52a8\u63a8\u8350\u7cfb\u7edf\u7684\u77e5\u8bc6\u8d2b\u4e4f\u548c\u7cfb\u7edf\u76f2\u533a\u95ee\u9898\uff0c\u5728\u6dd8\u5b9d\u6392\u540d\u7cfb\u7edf\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u5404\u9879\u6307\u6807\u3002", "motivation": "\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u5728\u65e5\u5fd7\u9a71\u52a8\u8303\u5f0f\u4e0b\u5b58\u5728\u4e24\u4e2a\u6839\u672c\u9650\u5236\uff1a(1)\u57fa\u4e8eID\u7684\u7269\u54c1\u8868\u793a\u77e5\u8bc6\u8d2b\u4e4f\uff0c\u5bfc\u81f4\u6570\u636e\u7a00\u758f\u4e0b\u5174\u8da3\u5efa\u6a21\u8106\u5f31\uff1b(2)\u7cfb\u7edf\u5bf9\u65e5\u5fd7\u5916\u7528\u6237\u5174\u8da3\u5b58\u5728\u76f2\u533a\uff0c\u9650\u5236\u4e86\u5e73\u53f0\u8fb9\u754c\u5185\u7684\u6a21\u578b\u6027\u80fd\u3002\u8fd9\u4e9b\u95ee\u9898\u6e90\u4e8e\u8fc7\u5ea6\u4f9d\u8d56\u6d45\u5c42\u4ea4\u4e92\u7edf\u8ba1\u548c\u95ed\u73af\u53cd\u9988\uff0c\u800c\u5ffd\u89c6\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u6d77\u91cf\u8bed\u6599\u4e2d\u5b66\u5230\u7684\u4ea7\u54c1\u8bed\u4e49\u548c\u8de8\u57df\u884c\u4e3a\u6a21\u5f0f\u7684\u4e16\u754c\u77e5\u8bc6\u3002", "method": "ReaSeq\u901a\u8fc7\u663e\u5f0f\u548c\u9690\u5f0f\u63a8\u7406\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e16\u754c\u77e5\u8bc6\u3002\u5177\u4f53\u91c7\u7528\uff1a1) \u663e\u5f0f\u601d\u7ef4\u94fe\u63a8\u7406\uff1a\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5c06\u7ed3\u6784\u5316\u4ea7\u54c1\u77e5\u8bc6\u63d0\u70bc\u6210\u8bed\u4e49\u4e30\u5bcc\u7684\u7269\u54c1\u8868\u793a\uff1b2) \u9690\u5f0f\u63a8\u7406\uff1a\u901a\u8fc7\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u65ad\u5408\u7406\u7684\u65e5\u5fd7\u5916\u884c\u4e3a\u3002", "result": "\u5728\u6dd8\u5b9d\u6392\u540d\u7cfb\u7edf\uff08\u670d\u52a1\u6570\u4ebf\u7528\u6237\uff09\u4e2d\u90e8\u7f72ReaSeq\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\uff1aIPV\u548cCTR\u63d0\u5347\u8d85\u8fc76.0%\uff0c\u8ba2\u5355\u91cf\u63d0\u5347\u8d85\u8fc72.9%\uff0cGMV\u63d0\u5347\u8d85\u8fc72.5%\u3002", "conclusion": "ReaSeq\u9a8c\u8bc1\u4e86\u4e16\u754c\u77e5\u8bc6\u589e\u5f3a\u63a8\u7406\u76f8\u5bf9\u4e8e\u7eaf\u65e5\u5fd7\u9a71\u52a8\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e3a\u89e3\u51b3\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u7684\u6839\u672c\u9650\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
