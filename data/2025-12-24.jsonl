{"id": "2512.20261", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2512.20261", "abs": "https://arxiv.org/abs/2512.20261", "authors": ["Edith Elkind", "Michele Flammini", "Giovanna Varricchio"], "title": "Maximizing the Egalitarian Welfare in Friends and Enemies Games", "comment": "Accepted paper at AAMAS'26", "summary": "We consider the complexity of maximizing egalitarian welfare in Friends and Enemies Games -- a subclass of hedonic games in which every agent partitions other agents into friends and enemies. We investigate two classic scenarios proposed in the literature, namely, Friends Appreciation ($\\mathsf{FA}$) and Enemies Aversion ($\\mathsf{EA}$): in the former, each agent primarily cares about the number of friends in her coalition, breaking ties based on the number of enemies, while in the latter, the opposite is true. For $\\mathsf{EA}$, we show that our objective is hard to approximate within $O(n^{1-ε})$, for any fixed $ε>0$, and provide a polynomial-time $(n-1)$-approximation. For $\\mathsf{FA}$, we obtain an NP-hardness result and a polynomial-time approximation algorithm. Our algorithm achieves a ratio of $2-Θ(\\frac{1}{n})$ when every agent has at least two friends; however, if some agent has at most one friend, its approximation ratio deteriorates to $n/2$. We recover the $2-Θ(\\frac{1}{n})$ approximation ratio for two important variants: when randomization is allowed and when the friendship relationship is symmetric. Additionally, for both $\\mathsf{EA}$ and $\\mathsf{FA}$ we identify special cases where the optimal egalitarian partition can be computed in polynomial time."}
{"id": "2512.20180", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.20180", "abs": "https://arxiv.org/abs/2512.20180", "authors": ["Zeev Nutov", "Anael Vaknin"], "title": "Approximation and parameterized algorithms for covering disjointness-compliable set families", "comment": null, "summary": "A set-family ${\\cal F}$ is disjointness-compliable if $A' \\subseteq A \\in {\\cal F}$ implies $A' \\in {\\cal F}$ or $A \\setminus A' \\in {\\cal F}$; if ${\\cal F}$ is also symmetric then ${\\cal F}$ is proper. A classic result of Goemans and Williamson [SODA 92:307-316] states that the problem of covering a proper set-family by a min-cost edge set admits approximation ratio $2$, by a classic primal-dual algorithm. However, there are several famous algorithmic problems whose set-family ${\\cal F}$ is disjointness-compliable but not symmetric -- among them $k$-Minimum Spanning Tree ($k$-MST), Generalized Point-to-Point Connection (G-P2P), Group Steiner, Covering Steiner, multiroot versions of these problems, and others. We will show that any such problem admits approximation ratio $O(α\\log τ)$, where $τ$ is the number of inclusion-minimal sets in the family ${\\cal F}$ that models the problem and $α$ is the best known approximation ratio for the case when $τ=1$. This immediately implies several results, among them the following two. (i) The first deterministic polynomial time $O(\\log n)$-approximation algorithm for the G-P2P problem. Here the $τ=1$ case is the $k$-MST problem. (ii) Approximation ratio $O(\\log^4 n)$ for the multiroot version of the Covering Steiner problem, where each root has its own set of groups. Here the $τ=1$ case is the Covering Steiner problem.\n  We also discuss the parameterized complexity of covering a disjointness-compliable family ${\\cal F}$, when parametrized by $τ$. We will show that if ${\\cal F}$ is proper then the problem is fixed parameter tractable and can be solved in time $O^*(3^τ)$. For the non-symmetric case we will show that the problem admits approximation ratio between $α$ and $α+1$ in time $O^*(3^τ)$, which is essentially the best possible."}
{"id": "2512.20059", "categories": ["cs.MM", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.20059", "abs": "https://arxiv.org/abs/2512.20059", "authors": ["Ziyang Fan", "Li Tao", "Yi Wang", "Jingwei Qu", "Ying Wang", "Fei Jiang"], "title": "DS-HGCN: A Dual-Stream Hypergraph Convolutional Network for Predicting Student Engagement via Social Contagion", "comment": "14pages,Accepted by MMM2026", "summary": "Student engagement is a critical factor influencing academic success and learning outcomes. Accurately predicting student engagement is essential for optimizing teaching strategies and providing personalized interventions. However, most approaches focus on single-dimensional feature analysis and assessing engagement based on individual student factors. In this work, we propose a dual-stream multi-feature fusion model based on hypergraph convolutional networks (DS-HGCN), incorporating social contagion of student engagement. DS-HGCN enables accurate prediction of student engagement states by modeling multi-dimensional features and their propagation mechanisms between students. The framework constructs a hypergraph structure to encode engagement contagion among students and captures the emotional and behavioral differences and commonalities by multi-frequency signals. Furthermore, we introduce a hypergraph attention mechanism to dynamically weigh the influence of each student, accounting for individual differences in the propagation process. Extensive experiments on public benchmark datasets demonstrate that our proposed method achieves superior performance and significantly outperforms existing state-of-the-art approaches."}
{"id": "2512.19750", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.19750", "abs": "https://arxiv.org/abs/2512.19750", "authors": ["Ilsun Chang"], "title": "Risk-Aware GPU-Assisted Cardinality Estimation for Cost-Based Query Optimizers", "comment": "6 pages, 9 figures", "summary": "Cardinality estimation is a cornerstone of cost-based optimizers (CBOs), yet real-world workloads often violate the assumptions behind static statistics, degrading decision stability and increasing plan flip rates. We empirically characterize failures caused by stale statistics, skew, join correlations, hidden distributions in bind variables, and sampling bias, and quantify the overhead and break-even points of hardware-accelerated measurement.\n  We propose GACE (GPU-Assisted Cardinality Estimation), a hybrid auxiliary architecture that augments rather than replaces the optimizer. GACE selectively invokes GPU-based measurement only in risky intervals via a Risky Gate that detects estimation uncertainty, and a GPU Measurement Engine that performs high-speed probing with explicit cost accounting for the measurement itself. This design preserves low overhead in stable regions while improving plan stability and reducing tail latency (P99) in problematic scenarios."}
{"id": "2512.19958", "categories": ["cs.IR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.19958", "abs": "https://arxiv.org/abs/2512.19958", "authors": ["Sneha Oommen", "Gabby Sanchez", "Cassandra T. Britto", "Di Wang", "Jordan Chiou", "Maria Spichkova"], "title": "Towards Analysing Invoices and Receipts with Amazon Textract", "comment": null, "summary": "This paper presents an evaluation of the AWS Textract in the context of extracting data from receipts. We analyse Textract functionalities using a dataset that includes receipts of varied formats and conditions. Our analysis provided a qualitative view of Textract strengths and limitations. While the receipts totals were consistently detected, we also observed typical issues and irregularities that were often influenced by image quality and layout. Based on the analysis of the observations, we propose mitigation strategies."}
{"id": "2512.19764", "categories": ["cs.IT", "eess.SP", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2512.19764", "abs": "https://arxiv.org/abs/2512.19764", "authors": ["Chathuranga M. Wijerathna Basnayaka", "Haeyoung Lee", "Pandelis Kourtessis", "John M. Senior", "Vishalya P. Sooriarachchi", "Dushantha Nalin K. Jayakody", "Marko Beko", "Seokjoo Shin"], "title": "Visual Event Detection over AI-Edge LEO Satellites with AoI Awareness", "comment": null, "summary": "Non terrestrial networks (NTNs), particularly low Earth orbit (LEO) satellite systems, play a vital role in supporting future mission critical applications such as disaster relief. Recent advances in artificial intelligence (AI)-native communications enable LEO satellites to act as intelligent edge nodes capable of on board learning and task oriented inference. However, the limited link budget, coupled with severe path loss and fading, significantly constrains reliable downlink transmission. This paper proposes a deep joint source-channel coding (DJSCC)-based downlink scheme for AI-native LEO networks, optimized for goal-oriented visual inference. In the DJSCC approach, only semantically meaningful features are extracted and transmitted, whereas conventional separate source-channel coding (SSCC) transmits the original image data. To evaluate information freshness and visual event detection performance, this work introduces the age of misclassified information (AoMI) metric and a threshold based AoI analysis that measures the proportion of users meeting application specific timeliness requirements. Simulation results show that the proposed DJSCC scheme provides higher inference accuracy, lower average AoMI, and greater threshold compliance than the conventional SSCC baseline, enabling semantic communication in AI native LEO satellite networks for 6G and beyond."}
{"id": "2512.20598", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.20598", "abs": "https://arxiv.org/abs/2512.20598", "authors": ["Vinicius T. V. Date", "Leandro M. Zatesko"], "title": "On the near-tightness of $χ\\leq 2r$: a general $σ$-ary construction and a binary case via LFSRs", "comment": "Accepted to LATIN 2026. 16 pages, 0 figures", "summary": "In the field of compressed string indexes, recent work has introduced suffixient sets and their corresponding repetitiveness measure $χ$. In particular, researchers have explored its relationship to other repetitiveness measures, notably $r$, the number of runs in the Burrows--Wheeler Transform (BWT) of a string. Navarro et al. (2025) proved that $χ\\leq 2r$, although empirical results by Cenzato et al. (2024) suggest that this bound is loose, with real data bounding $χ$ by around $1.13r$ to $1.33r$ when the size of the alphabet is $σ= 4$. To better understand this gap, we present two cases for the asymptotic tightness of the $χ\\leq 2r$ bound: a general construction for arbitrary $σ$ values, and a binary alphabet case, consisting of de Bruijn sequences constructed by linear-feedback shift registers (LFSRs) from primitive polynomials over $\\mathbb{F}_2$. The second is a novel characterization of which de Bruijn sequences achieve the literature run-minimal pattern for the cyclic BWT. Moreover, we show that de Bruijn sequences fail to close the gap for $σ\\geq 3$."}
{"id": "2512.20271", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.20271", "abs": "https://arxiv.org/abs/2512.20271", "authors": ["Angjela Davitkova", "Sebastian Michel"], "title": "Automated Training of Learned Database Components with Generative AI", "comment": "5 pages, 2 tables, NOVAS Workshop at SIGMOD 2025", "summary": "The use of deep learning for database optimization has gained significant traction, offering improvements in indexing, cardinality estimation, and query optimization. However, acquiring high-quality training data remains a significant challenge. This paper explores the possibility of using generative models, such as GPT, to synthesize training data for learned database components. We present an initial feasibility study investigating their ability to produce realistic query distributions and execution plans for database workloads. Additionally, we discuss key challenges, such as data scalability and labeling, along with potential solutions. The initial results suggest that generative models can effectively augment training datasets, improving the adaptability of learned database techniques."}
{"id": "2512.19983", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.19983", "abs": "https://arxiv.org/abs/2512.19983", "authors": ["Ziyuan Guo", "Jie Guo", "Zhenghao Chen", "Bin Song", "Fei Richard Yu"], "title": "IGDMRec: Behavior Conditioned Item Graph Diffusion for Multimodal Recommendation", "comment": "12 pages, 6 figures. This paper has been accepted for publication in IEEE Transactions on Multimedia. The final published version will be available via IEEE Xplore", "summary": "Multimodal recommender systems (MRSs) are critical for various online platforms, offering users more accurate personalized recommendations by incorporating multimodal information of items. Structure-based MRSs have achieved state-of-the-art performance by constructing semantic item graphs, which explicitly model relationships between items based on modality feature similarity. However, such semantic item graphs are often noisy due to 1) inherent noise in multimodal information and 2) misalignment between item semantics and user-item co-occurrence relationships, which introduces false links and leads to suboptimal recommendations. To address this challenge, we propose Item Graph Diffusion for Multimodal Recommendation (IGDMRec), a novel method that leverages a diffusion model with classifier-free guidance to denoise the semantic item graph by integrating user behavioral information. Specifically, IGDMRec introduces a Behavior-conditioned Graph Diffusion (BGD) module, incorporating interaction data as conditioning information to guide the denoising of the semantic item graph. Additionally, a Conditional Denoising Network (CD-Net) is designed to implement the denoising process with manageable complexity. Finally, we propose a contrastive representation augmentation scheme that leverages both the denoised item graph and the original item graph to enhance item representations. \\LL{Extensive experiments on four real-world datasets demonstrate the superiority of IGDMRec over competitive baselines, with robustness analysis validating its denoising capability and ablation studies verifying the effectiveness of its key components."}
{"id": "2512.19777", "categories": ["cs.IT", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.19777", "abs": "https://arxiv.org/abs/2512.19777", "authors": ["Antonio Tarizzo", "Mohammad Kazemi", "Deniz Gündüz"], "title": "Learned Digital Codes for Over-the-Air Computation in Federated Edge Learning", "comment": null, "summary": "Federated edge learning (FEEL) enables wireless devices to collaboratively train a centralised model without sharing raw data, but repeated uplink transmission of model updates makes communication the dominant bottleneck. Over-the-air (OTA) aggregation alleviates this by exploiting the superposition property of the wireless channel, enabling simultaneous transmission and merging communication with computation. Digital OTA schemes extend this principle by incorporating the robustness of conventional digital communication, but current designs remain limited in low signal-to-noise ratio (SNR) regimes. This work proposes a learned digital OTA framework that improves recovery accuracy, convergence behaviour, and robustness to challenging SNR conditions while maintaining the same uplink overhead as state-of-the-art methods. The design integrates an unsourced random access (URA) codebook with vector quantisation and AMP-DA-Net, an unrolled approximate message passing (AMP)-style decoder trained end-to-end with the digital codebook and parameter server local training statistics. The proposed design extends OTA aggregation beyond averaging to a broad class of symmetric functions, including trimmed means and majority-based rules. Experiments on highly heterogeneous device datasets and varying numbers of active devices show that the proposed design extends reliable digital OTA operation by more than 10 dB into low SNR regimes while matching or improving performance across the full SNR range. The learned decoder remains effective under message corruption and nonlinear aggregation, highlighting the broader potential of end-to-end learned design for digital OTA communication in FEEL."}
{"id": "2512.20022", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.20022", "abs": "https://arxiv.org/abs/2512.20022", "authors": ["Kian Godhwani", "David Benrimoh"], "title": "LLM-Assisted Abstract Screening with OLIVER: Evaluating Calibration and Single-Model vs. Actor-Critic Configurations in Literature Reviews", "comment": null, "summary": "Introduction: Recent work suggests large language models (LLMs) can accelerate screening, but prior evaluations focus on earlier LLMs, standardized Cochrane reviews, single-model setups, and accuracy as the primary metric, leaving generalizability, configuration effects, and calibration largely unexamined.\n  Methods: We developed OLIVER (Optimized LLM-based Inclusion and Vetting Engine for Reviews), an open-source pipeline for LLM-assisted abstract screening. We evaluated multiple contemporary LLMs across two non-Cochrane systematic reviews and performance was assessed at both the full-text screening and final inclusion stages using accuracy, AUC, and calibration metrics. We further tested an actor-critic screening framework combining two lightweight models under three aggregation rules.\n  Results: Across individual models, performance varied widely. In the smaller Review 1 (821 abstracts, 63 final includes), several models achieved high sensitivity for final includes but at the cost of substantial false positives and poor calibration. In the larger Review 2 (7741 abstracts, 71 final includes), most models were highly specific but struggled to recover true includes, with prompt design influencing recall. Calibration was consistently weak across single-model configurations despite high overall accuracy. Actor-critic screening improved discrimination and markedly reduced calibration error in both reviews, yielding higher AUCs.\n  Discussion: LLMs may eventually accelerate abstract screening, but single-model performance is highly sensitive to review characteristics, prompting, and calibration is limited. An actor-critic framework improves classification quality and confidence reliability while remaining computationally efficient, enabling large-scale screening at low cost."}
{"id": "2512.20108", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.20108", "abs": "https://arxiv.org/abs/2512.20108", "authors": ["Yuntong Gu", "Xiangming meng", "Zhiyuan Lin", "Sheng Wu", "Linling Kuang"], "title": "Generative Bayesian Spectrum Cartography: Unified Reconstruction and Active Sensing via Diffusion Models", "comment": null, "summary": "High-fidelity spectrum cartography is pivotal for spectrum management and wireless situational awareness, yet it remains a challenging ill-posed inverse problem due to the sparsity and irregularity of observations. Furthermore, existing approaches often decouple reconstruction from sensing, lacking a principled mechanism for informative sampling. To address these limitations, this paper proposes a unified diffusion-based Bayesian framework that jointly addresses spectrum reconstruction and active sensing. We formulate the reconstruction task as a conditional generation process driven by a learned diffusion prior. Specifically, we derive tractable, closed-form posterior transition kernels for the reverse diffusion process, which enforce consistency with both linear Gaussian and non-linear quantized measurements. Leveraging the intrinsic probabilistic nature of diffusion models, we further develop an uncertainty-aware active sampling strategy. This strategy quantifies reconstruction uncertainty to adaptively guide sensing agents toward the most informative locations, thereby maximizing spectral efficiency. Extensive experiments demonstrate that the proposed framework significantly outperforms state-of-the-art interpolation, sparsity-based, and deep learning baselines in terms of reconstruction accuracy, sampling efficiency, and robustness to low-bit quantization."}
{"id": "2512.20034", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.20034", "abs": "https://arxiv.org/abs/2512.20034", "authors": ["Xian Wu", "Ming Zhang", "Zhiyu Fang", "Fei Li", "Bin Wang", "Yong Jiang", "Hao Zhou"], "title": "VSA:Visual-Structural Alignment for UI-to-Code", "comment": null, "summary": "The automation of user interface development has the potential to accelerate software delivery by mitigating intensive manual implementation. Despite the advancements in Large Multimodal Models for design-to-code translation, existing methodologies predominantly yield unstructured, flat codebases that lack compatibility with component-oriented libraries such as React or Angular. Such outputs typically exhibit low cohesion and high coupling, complicating long-term maintenance. In this paper, we propose \\textbf{VSA (VSA)}, a multi-stage paradigm designed to synthesize organized frontend assets through visual-structural alignment. Our approach first employs a spatial-aware transformer to reconstruct the visual input into a hierarchical tree representation. Moving beyond basic layout extraction, we integrate an algorithmic pattern-matching layer to identify recurring UI motifs and encapsulate them into modular templates. These templates are then processed via a schema-driven synthesis engine, ensuring the Large Language Model generates type-safe, prop-drilled components suitable for production environments. Experimental results indicate that our framework yields a substantial improvement in code modularity and architectural consistency over state-of-the-art benchmarks, effectively bridging the gap between raw pixels and scalable software engineering."}
{"id": "2512.20332", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.20332", "abs": "https://arxiv.org/abs/2512.20332", "authors": ["Chaorong Zhang", "Benjamin K. Ng", "Hui Xu", "Chan-Tong Lam", "Halim Yanikomeroglu"], "title": "RIS-Empowered OTFS Modulation With Faster-than-Nyquist Signaling in High-Mobility Wireless Communications", "comment": "Submitted to IEEE Journal", "summary": "High-mobility wireless communication systems suffer from severe Doppler spread and multi-path delay, which degrade the reliability and spectral efficiency of conventional modulation schemes. Orthogonal time frequency space (OTFS) modulation offers strong robustness in such environments by representing symbols in the delay-Doppler (DD) domain, while faster-than-Nyquist (FTN) signaling can further enhance spectral efficiency through intentional symbol packing. Meanwhile, reconfigurable intelligent surfaces (RIS) provide a promising means to improve link quality via passive beamforming. Motivated by these advantages, we propose a novel RIS-empowered OTFS modulation with FTN signaling (RIS-OTFS-FTN) scheme. First, we establish a unified DD-domain input-output relationship that jointly accounts for RIS passive beamforming, FTN-induced inter-symbol interference, and DD-domain channel characteristics. Based on this model, we provide comprehensive analytical performance for the frame error rate, spectral efficiency, and peak-to-average power ratio (PAPR), etc. Furthermore, a practical RIS phase adjustment strategy with quantized phase selection is designed to maximize the effective channel gain. Extensive Monte Carlo simulations under a standardized extended vehicular A (EVA) channel model validate the theoretical results and provide key insights into the trade-offs among spectral efficiency, PAPR, input back-off (IBO), and error performance, with some interesting insights.The proposed RIS-OTFS-FTN scheme demonstrates notable performance gains in both reliability and spectral efficiency, offering a viable solution for future high-mobility and spectrum-constrained wireless systems."}
{"id": "2512.20172", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.20172", "abs": "https://arxiv.org/abs/2512.20172", "authors": ["Yan Zhang", "Li Deng", "Lixin Duan", "Ivor W. Tsang", "Guowu Yang"], "title": "Collaborative Group-Aware Hashing for Fast Recommender Systems", "comment": null, "summary": "The fast online recommendation is critical for applications with large-scale databases; meanwhile, it is challenging to provide accurate recommendations in sparse scenarios. Hash technique has shown its superiority for speeding up the online recommendation by bit operations on Hamming distance computations. However, existing hashing-based recommendations suffer from low accuracy, especially with sparse settings, due to the limited representation capability of each bit and neglected inherent relations among users and items. To this end, this paper lodges a Collaborative Group-Aware Hashing (CGAH) method for both collaborative filtering (namely CGAH-CF) and content-aware recommendations (namely CGAH) by integrating the inherent group information to alleviate the sparse issue. Firstly, we extract inherent group affinities of users and items by classifying their latent vectors into different groups. Then, the preference is formulated as the inner product of the group affinity and the similarity of hash codes. By learning hash codes with the inherent group information, CGAH obtains more effective hash codes than other discrete methods with sparse interactive data. Extensive experiments on three public datasets show the superior performance of our proposed CGAH and CGAH-CF over the state-of-the-art discrete collaborative filtering methods and discrete content-aware recommendations under different sparse settings."}
{"id": "2512.20389", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.20389", "abs": "https://arxiv.org/abs/2512.20389", "authors": ["Victoria E. Galanopoulou", "Thrassos K. Oikonomou", "Odysseas G. Karagiannidis", "Sotiris A. Tegos", "Panagiotis D. Diamantoulakis"], "title": "Viterbi State Selection for Discrete Pinching Antenna Systems", "comment": null, "summary": "Pinching antennas enable dynamic control of electromagnetic wave propagation through reconfigurable radiating structures, but selecting an optimal subset of antennas remains a combinatorial problem with exponential complexity. This letter considers antenna subset selection for a waveguide-fed pinching antenna array serving ground users under a time-division access scheme. The achievable rate depends on the coherent superposition of the effective complex channel gains and is therefore highly sensitive to the relative phase alignment of the activated antennas. To address the prohibitive complexity of exhaustive search, we propose a Viterbi state selection (VSS) algorithm that exploits the phase structure of the combined received signal. The trellis state is defined by a quantized representation of the phase of the accumulated complex gain, and a Viterbi-based survivor rule is used to prune dominated antenna subsets across stages. Numerical results demonstrate that the proposed method achieves the same antenna selection and rate as exhaustive search, while reducing the computational complexity from exponential to polynomial in the number of available antennas."}
{"id": "2512.20458", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.20458", "abs": "https://arxiv.org/abs/2512.20458", "authors": ["Shuting Wang", "Qiaolin Xia", "Hao Wang", "Yu Lu", "Bobsimons", "Zhicheng Dou"], "title": "Laser: Governing Long-Horizon Agentic Search via Structured Protocol and Context Register", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) and Large Reasoning Models (LRMs) have enabled agentic search systems that interleave multi-step reasoning with external tool use. However, existing frameworks largely rely on unstructured natural-language reasoning and accumulate raw intermediate traces in the context, which often leads to unstable reasoning trajectories, context overflow, and degraded performance on complex multi-hop queries. In this study, we introduce Laser, a general framework for stabilizing and scaling agentic search. Laser defines a symbolic action protocol that organizes agent behaviors into three spaces: planning, task-solving, and retrospection. Each action is specified with explicit semantics and a deterministic execution format, enabling structured and logical reasoning processes and reliable action parsing. This design makes intermediate decisions interpretable and traceable, enhancing explicit retrospection and fine-grained control over reasoning trajectories. In coordination with parsable actions, Laser further maintains a compact context register that stores only essential states of the reasoning process, allowing the agent to reason over long horizons without uncontrolled context expansion. Experiments on Qwen2.5/3-series models across challenging multi-hop QA datasets show that Laser consistently outperforms existing agentic search baselines under both prompting-only and fine-tuning settings, demonstrating that Laser provides a principled and effective foundation for robust, scalable agentic search."}
{"id": "2512.20552", "categories": ["cs.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.20552", "abs": "https://arxiv.org/abs/2512.20552", "authors": ["Sung En Chiang", "Zhaolu Liu", "Robert L. Peach", "Mauricio Barahona"], "title": "Information-theoretic signatures of causality in Bayesian networks and hypergraphs", "comment": "20 pages, 3 figures", "summary": "Analyzing causality in multivariate systems involves establishing how information is generated, distributed and combined, and thus requires tools that capture interactions beyond pairwise relations. Higher-order information theory provides such tools. In particular, Partial Information Decomposition (PID) allows the decomposition of the information that a set of sources provides about a target into redundant, unique, and synergistic components. Yet the mathematical connection between such higher-order information-theoretic measures and causal structure remains undeveloped. Here we establish the first theoretical correspondence between PID components and causal structure in both Bayesian networks and hypergraphs. We first show that in Bayesian networks unique information precisely characterizes direct causal neighbors, while synergy identifies collider relationships. This establishes a localist causal discovery paradigm in which the structure surrounding each variable can be recovered from its immediate informational footprint, eliminating the need for global search over graph space. Extending these results to higher-order systems, we prove that PID signatures in Bayesian hypergraphs differentiate parents, children, co-heads, and co-tails, revealing a higher-order collider effect unique to multi-tail hyperedges. We also present procedures by which our results can be used to characterize systematically the causal structure of Bayesian networks and hypergraphs. Our results position PID as a rigorous, model-agnostic foundation for inferring both pairwise and higher-order causal structure, and introduce a fundamentally local information-theoretic viewpoint on causal discovery."}
{"id": "2512.20612", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.20612", "abs": "https://arxiv.org/abs/2512.20612", "authors": ["Yibin Lei", "Shwai He", "Ang Li", "Andrew Yates"], "title": "Making Large Language Models Efficient Dense Retrievers", "comment": null, "summary": "Recent work has shown that directly fine-tuning large language models (LLMs) for dense retrieval yields strong performance, but their substantial parameter counts make them computationally inefficient. While prior studies have revealed significant layer redundancy in LLMs for generative tasks, it remains unclear whether similar redundancy exists when these models are adapted for retrieval tasks, which require encoding entire sequences into fixed representations rather than generating tokens iteratively. To this end, we conduct a comprehensive analysis of layer redundancy in LLM-based dense retrievers. We find that, in contrast to generative settings, MLP layers are substantially more prunable, while attention layers remain critical for semantic aggregation. Building on this insight, we propose EffiR, a framework for developing efficient retrievers that performs large-scale MLP compression through a coarse-to-fine strategy (coarse-grained depth reduction followed by fine-grained width reduction), combined with retrieval-specific fine-tuning. Across diverse BEIR datasets and LLM backbones, EffiR achieves substantial reductions in model size and inference cost while preserving the performance of full-size models."}
