<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 7]
- [cs.IR](#cs.IR) [Total: 5]
- [cs.DB](#cs.DB) [Total: 4]
- [cs.DS](#cs.DS) [Total: 13]
- [cs.GT](#cs.GT) [Total: 2]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [List Decoding and New Bicycle Code Constructions for Quantum LDPC Codes](https://arxiv.org/abs/2511.02951)
*Sheida Rabeti,Hessam Mahdavifar*

Main category: cs.IT

TL;DR: 提出了一种新的解码器MBBP-LD，用于量子低密度奇偶校验码，在保持线性时间复杂度的同时显著降低逻辑错误率。


<details>
  <summary>Details</summary>
Motivation: 现有QLDPC码解码器在性能和复杂度之间存在权衡，需要一种既能保持线性复杂度又能提高解码性能的方法。

Method: 扩展了经典循环LDPC码的多基信念传播框架，并引入了新的后处理列表解码器决策规则。

Result: 对于[[144,12,12]]双变量自行车码，MBBP-LD解码器比最先进的BP-OSD解码器降低了40%的逻辑错误率。

Conclusion: MBBP-LD解码器在保持线性时间复杂度的同时显著提升了QLDPC码的解码性能，同时探索的单变量自行车码也显示出良好潜力。

Abstract: In this paper, we propose a new decoder, called the Multiple-Bases
Belief-Propagation List Decoder (MBBP-LD), for Quantum Low-Density Parity-Check
(QLDPC) codes. It extends the Multiple-Bases Belief-Propagation (MBBP)
framework, originally developed for classical cyclic LDPC codes. The proposed
method preserves the linear-time complexity of standard BP decoder while
improving the logical error rate. To further reduce the logical error rate, a
new decision rule is introduced for the post-processing list decoder,
outperforming the conventional least-metric selector (LMS) criterion. For the
recently developed and implemented bivariate bicycle (BB) code with parameters
\([[144,12,12]]\), our proposed MBBP-LD decoder achieves up to 40\% lower
logical error rate compared to the state-of-the-art decoder for short QLDPC
codes, i.e., BP with ordered-statistics decoding (BP-OSD), while retaining the
linear-time complexity of the plain BP decoder. In addition, we explore a new
subclass of BB codes, that we refer to as the univariate bicycle (UB) codes,
specifically with lower-weight parity checks (\(w=6,8\)). This reduces the
polynomial search space for the code compared to general BB codes, i.e., by
reducing the search space over two polynomial components in BB codes to just a
single polynomial component in UB codes. Simulations demonstrate the promising
performance of these codes under various types of BP decoders.

</details>


### [2] [A Tsallis-Entropy Lens on Genetic Variation](https://arxiv.org/abs/2511.03063)
*Margarita Geleta,Daniel Mas Montserrat,Alexander G. Ioannidis*

Main category: cs.IT

TL;DR: 本文提出了Tsallis q阶F统计量F_q，作为经典F_ST统计量的信息论推广，通过调节q值可以精细分析群体遗传分化，特别适用于等位基因频率分布偏斜的情况。


<details>
  <summary>Details</summary>
Motivation: 经典F_ST统计量基于方差分析，在等位基因频率分布偏斜时可能无法全面反映群体分化模式。需要一种更灵活的统计量来捕捉不同频率等位基因的贡献差异。

Method: 引入Tsallis q熵概念，构建F_q统计量家族。当q=2时还原为经典F_ST，q=1时对应香农熵形式。通过调节q值可以分别强调稀有等位基因(q<1)或常见等位基因(q>1)。

Result: 在865个大洋洲基因组和受控系谱模拟中，F_q在One-vs-Rest和Leave-One-Out模式下能清晰识别驱动区域结构的亚群体，并能敏感地时间标记隔离迁移事件和奠基者效应。

Conclusion: F_q统计量作为F_ST的精细分辨率补充，为模拟验证和群体结构总结提供了更强大的分析工具，特别适用于等位基因频率谱偏斜的情况。

Abstract: We introduce an information-theoretic generalization of the fixation
statistic, the Tsallis-order $q$ F-statistic, $F_q$, which measures the
fraction of Tsallis $q$-entropy lost within subpopulations relative to the
pooled population. The family nests the classical variance-based fixation index
$F_{\textbf{ST}}$ at $q{=}2$ and a Shannon-entropy analogue at $q{=}1$, whose
absolute form equals the mutual information between alleles and population
labels. By varying $q$, $F_q$ acts as a spectral differentiator that up-weights
rare variants at low $q$, while $q{>}1$ increasingly emphasizes common
variants, providing a more fine-grained view of differentiation than
$F_{\textbf{ST}}$ when allele-frequency spectra are skewed. On real data (865
Oceanian genomes with 1,823,000 sites) and controlled genealogical simulations
(seeded from 1,432 founders from HGDP and 1000 Genomes panels, with 322,216
sites), we show that $F_q$ in One-vs-Rest (OVR) and Leave-One-Out (LOO) modes
provides clear attribution of which subpopulations drive regional structure,
and sensitively timestamps isolation-migration events and founder effects.
$F_q$ serves as finer-resolution complement for simulation audits and
population-structure summaries.

</details>


### [3] [DRL-Based Robust Multi-Timescale Anti-Jamming Approaches under State Uncertainty](https://arxiv.org/abs/2511.03305)
*Haoqin Zhao,Zan Li,Jiangbo Si,Rui Huang,Hang Hu,Tony Q. S. Quek,Naofal Al-Dhahir*

Main category: cs.IT

TL;DR: 提出两种鲁棒抗干扰方案：PGD-DDQN和NQC-DDQN，在多时间尺度决策模型中考虑状态不确定性，在感知误差下保持抗干扰性能。


<details>
  <summary>Details</summary>
Motivation: 现有抗干扰方法假设精确感知且忽视异构动作执行延迟不匹配和传感器误差问题，DRL方法对输入扰动敏感，可能导致选择次优动作。

Method: 建立多时间尺度决策模型，提出PGD-DDQN算法（使用投影梯度下降进行鲁棒优化）和NQC-DDQN算法（引入非线性压缩机制消除动作混淆）。

Result: 仿真结果表明，相比完美感知基线，所提算法在抗干扰性能上仅有轻微下降，在各种扰动下保持鲁棒性。

Conclusion: 所提算法在非完美感知条件下具有实用性，验证了其鲁棒性和有效性。

Abstract: Owing to the openness of wireless channels, wireless communication systems
are highly susceptible to malicious jamming. Most existing anti-jamming methods
rely on the assumption of accurate sensing and optimize parameters on a single
timescale. However, such methods overlook two practical issues: mismatched
execution latencies across heterogeneous actions and measurement errors caused
by sensor imperfections. Especially for deep reinforcement learning (DRL)-based
methods, the inherent sensitivity of neural networks implies that even minor
perturbations in the input can mislead the agent into choosing suboptimal
actions, with potentially severe consequences. To ensure reliable wireless
transmission, we establish a multi-timescale decision model that incorporates
state uncertainty. Subsequently, we propose two robust schemes that sustain
performance under bounded sensing errors. First, a Projected Gradient
Descent-assisted Double Deep Q-Network (PGD-DDQN) algorithm is designed, which
derives worst-case perturbations under a norm-bounded error model and applies
PGD during training for robust optimization. Second, a Nonlinear Q-Compression
DDQN (NQC-DDQN) algorithm introduces a nonlinear compression mechanism that
adaptively contracts Q-value ranges to eliminate action aliasing. Simulation
results indicate that, compared with the perfect-sensing baseline, the proposed
algorithms show only minor degradation in anti-jamming performance while
maintaining robustness under various perturbations, thereby validating their
practicality in imperfect sensing conditions.

</details>


### [4] [Constacyclic codes with best-known parameters](https://arxiv.org/abs/2511.03323)
*Zekai Chen,Min Sha*

Main category: cs.IT

TL;DR: 构建了多个无限族的q元常循环码，这些码具有长度n、维度约n/2、最小距离至少为cn/log_q n的参数特性，包含许多最优或接近最优的码。


<details>
  <summary>Details</summary>
Motivation: 研究具有良好参数特性的常循环码构造，特别是寻找具有最优或接近最优参数的实际可用码。

Method: 通过构造多个无限族的q元常循环码，考虑不同长度n的形式，确保码的维度约n/2且最小距离有下界保证。

Result: 成功构造了多个无限族的常循环码，这些码包含许多具有最优、几乎最优或已知最佳参数的码实例。

Conclusion: 提出的构造方法能够系统地生成具有良好参数特性的常循环码，为编码理论提供了实用的码构造方案。

Abstract: In this paper, we construct several infinite families of $q$-ary constacyclic
codes over a finite field $\mathbb{F}_q$ with length $n$, dimension around
$n/2$, and minimum distance at least $cn/\log_q n$ for some positive constant
$c$. They contain many constacyclic codes with optimal, or almost-optimal, or
best-known parameters. We also consider various forms of the length $n$.

</details>


### [5] [The (+)-(L, P)-TGRS code](https://arxiv.org/abs/2511.03398)
*Zhonghao Liang,Chenlu Jia,Qunying Liao*

Main category: cs.IT

TL;DR: 本文研究了(L,P)-TGRS码的NMDS条件、非RS性质以及自正交性，部分解决了Hu等人在2025年提出的两个开放问题，并改进了相关结果。


<details>
  <summary>Details</summary>
Motivation: 非RS型线性码的构造是近年研究热点，Hu等人在2025年通过定义(L,P)-TGRS码构造了非RS MDS码，本文在此基础上进一步研究其性质。

Method: 首先给出了(L,P)-TGRS码的校验矩阵，然后研究了其NMDS条件、非RS性质以及自正交性，并通过构造示例验证理论结果。

Result: 给出了C是NMDS的充要条件，证明了当2k>n时C是非RS码，给出了C不自对偶或不自正交的充分条件，并构造了两类自正交码。

Conclusion: 本文部分解决了Hu等人提出的开放问题，改进了相关结果，为(L,P)-TGRS码的理论研究提供了新的进展。

Abstract: The construction of the non-Reed-Solomon (in short, non-RS) type linear code
has been one of the research hotspots in recent years. In 2025, Hu et al.
constructed some non-RS MDS codes by defining the (L, P)-twisted generalized
Reed-Solomon code (in short, (L, P)-TGRS). In this paper, we focus on the
(+)-(L, P)-TGRS code C. We firstly present a parity-check matrix. Secondly, we
give a sufficient and necessary condition for C to be NMDS which partially
answers two open problems proposed by Hu et al. in 2025, and prove that C is
non-RS for 2k > n which partially improves the corresponding result given by Hu
et al. in 2025,. Thirdly, we give a sufficient condition for C not to be
self-dual or self-orthogonal, respectively, furthermore, we construct two
classes of self-orthogonal codes which is a promotion of the corresponding
result given by Ding et al. in 2025. Finally, some examples are given.

</details>


### [6] [On the Fundamental Scaling Laws of Fluid Antenna Systems](https://arxiv.org/abs/2511.03415)
*Xusheng Zhu,Farshad Rostami Ghadi,Tuo Wu,Kaitao Meng,Chao Wang,Gui Zhou*

Main category: cs.IT

TL;DR: 本文建立了流体天线系统(FAS)在空间相关信道中的符号错误率(SER)基本缩放定律，揭示了SER与信道空间相关结构的基本关系。


<details>
  <summary>Details</summary>
Motivation: 流体天线系统通过利用空间分集来增强无线通信性能，但此前缺乏对其错误概率的严格分析框架。

Method: 推导了适用于一般调制方案的紧致闭式渐近SER表达式，基于此框架完整表征了分集增益和编码增益。

Result: 建立了SER与信道空间相关结构的基本缩放定律，发现扩大天线移动空间可提高分集增益，而在受限空间内仅增加端口密度收益递减。

Conclusion: SER的根本改进需要扩大天线移动空间以增加分集，而仅在受限空间内增加端口密度效果有限。

Abstract: Fluid antenna systems (FAS) offer a promising paradigm for enhancing wireless
communication by exploiting spatial diversity, yet a rigorous analytical
framework for their error probability has been notably absent. To this end,
this paper addresses this critical gap by unveiling the \textbf{fundamental
scaling laws} that govern the symbol error rate (SER) of FAS in realistic,
spatially correlated channels. To establish these laws, we derive a tight,
closed-form asymptotic expression for the SER applicable to a general class of
modulation schemes. This result is pivotal as it establishes the fundamental
scaling law governing the relationship between SER and the channel's spatial
correlation structure. Based on this framework, we provide a complete
characterization of the diversity and coding gains. The analysis culminates in
a definitive design directive: SER can be fundamentally improved by expanding
the antenna's movement space to increase diversity, while merely increasing
port density within a constrained space yields diminishing returns.

</details>


### [7] [Neural Beamforming with Doppler-Aware Sparse Attention for High Mobility Environments](https://arxiv.org/abs/2511.03632)
*Cemil Vahapoglu,Timothy J. O'Shea,Wan Liu,Sennur Ulukus*

Main category: cs.IT

TL;DR: 提出了一种基于多普勒感知的稀疏神经网络波束成形模型，通过通道自适应稀疏注意力机制在MU-SIMO系统中提升高移动场景下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 传统波束成形技术在恶劣信道条件下性能下降，而现有Transformer模型在大型OFDM网格中面临二次复杂度问题，且现有稀疏注意力机制未充分考虑无线通信场景中的信道动态特性。

Method: 开发了Doppler-aware Sparse NNBF模型，采用通道自适应稀疏注意力机制，在2D时频轴上根据信道动态配置稀疏结构，理论证明可在p个注意力头内确保完全连接性。

Result: 在UMa信道条件下的仿真结果显示，该模型在高移动场景中显著优于固定模式基线(Standard Sparse NNBF)和传统波束成形技术(ZFBF和MMSE)，同时保持结构化稀疏性和可控的注意力键数量。

Conclusion: 所提出的多普勒感知稀疏神经网络波束成形模型能够有效应对高移动场景下的信道动态，在保持计算效率的同时显著提升性能表现。

Abstract: Beamforming has significance for enhancing spectral efficiency and mitigating
interference in multi-antenna wireless systems, facilitating spatial
multiplexing and diversity in dense and high mobility scenarios. Traditional
beamforming techniques such as zero-forcing beamforming (ZFBF) and minimum mean
square error (MMSE) beamforming experience performance deterioration under
adverse channel conditions. Deep learning-based beamforming offers an
alternative with nonlinear mappings from channel state information (CSI) to
beamforming weights by improving robustness against dynamic channel
environments. Transformer-based models are particularly effective due to their
ability to model long-range dependencies across time and frequency. However,
their quadratic attention complexity limits scalability in large OFDM grids.
Recent studies address this issue through sparse attention mechanisms that
reduce complexity while maintaining expressiveness, yet often employ patterns
that disregard channel dynamics, as they are not specifically designed for
wireless communication scenarios. In this work, we propose a Doppler-aware
Sparse Neural Network Beamforming (Doppler-aware Sparse NNBF) model that
incorporates a channel-adaptive sparse attention mechanism in a multi-user
single-input multiple-output (MU-SIMO) setting. The proposed sparsity structure
is configurable along 2D time-frequency axes based on channel dynamics and is
theoretically proven to ensure full connectivity within p hops, where p is the
number of attention heads. Simulation results under urban macro (UMa) channel
conditions show that Doppler-aware Sparse NNBF significantly outperforms both a
fixed-pattern baseline, referred to as Standard Sparse NNBF, and conventional
beamforming techniques ZFBF and MMSE beamforming in high mobility scenarios,
while maintaining structured sparsity with a controlled number of attended keys
per query.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [8] [Generative Sequential Recommendation via Hierarchical Behavior Modeling](https://arxiv.org/abs/2511.03155)
*Zhefan Wang,Guokai Yan,Jinbei Yu,Siyu Gu,Jingyan Chen,Peng Jiang,Zhiqiang Guo,Min Zhang*

Main category: cs.IR

TL;DR: 提出了GAMER框架，通过生成式方法解决多行为推荐中的序列建模不足和数据集缺乏问题，并在短视频广告数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多行为推荐系统需要处理稀疏的高价值转化行为，现有生成式方法在序列建模和数据集方面存在不足，限制了在其他领域的应用验证。

Method: 基于解码器架构的GAMER框架，引入跨层级交互层捕捉行为间的层次依赖关系，以及序列增强策略提升训练鲁棒性，并发布了短视频广告数据集ShortVideoAD。

Result: 在多个指标上，GAMER始终优于判别式和生成式基线方法，证明了其有效性。

Conclusion: GAMER框架通过改进的序列建模和新数据集，为多行为生成式推荐提供了有效的解决方案，并在短视频广告领域展现了优越性能。

Abstract: Recommender systems in multi-behavior domains, such as advertising and
e-commerce, aim to guide users toward high-value but inherently sparse
conversions. Leveraging auxiliary behaviors (e.g., clicks, likes, shares) is
therefore essential. Recent progress on generative recommendations has brought
new possibilities for multi-behavior sequential recommendation. However,
existing generative approaches face two significant challenges: 1) Inadequate
Sequence Modeling: capture the complex, cross-level dependencies within user
behavior sequences, and 2) Lack of Suitable Datasets: publicly available
multi-behavior recommendation datasets are almost exclusively derived from
e-commerce platforms, limiting the validation of feasibility in other domains,
while also lacking sufficient side information for semantic ID generation. To
address these issues, we propose a novel generative framework, GAMER
(Generative Augmentation and Multi-lEvel behavior modeling for Recommendation),
built upon a decoder-only backbone. GAMER introduces a cross-level interaction
layer to capture hierarchical dependencies among behaviors and a sequential
augmentation strategy that enhances robustness in training. To further advance
this direction, we collect and release ShortVideoAD, a large-scale
multi-behavior dataset from a mainstream short-video platform, which differs
fundamentally from existing e-commerce datasets and provides pretrained
semantic IDs for research on generative methods. Extensive experiments show
that GAMER consistently outperforms both discriminative and generative
baselines across multiple metrics.

</details>


### [9] [KScaNN: Scalable Approximate Nearest Neighbor Search on Kunpeng](https://arxiv.org/abs/2511.03298)
*Oleg Senkevich,Siyang Xu,Tianyi Jiang,Alexander Radionov,Jan Tabaszewski,Dmitriy Malyshev,Zijian Li,Daihao Xue,Licheng Yu,Weidi Zeng,Meiling Wang,Xin Yao,Siyu Huang,Gleb Neshchetkin,Qiuling Pan,Yaoyao Fu*

Main category: cs.IR

TL;DR: KScaNN是针对ARM架构优化的近似最近邻搜索算法，在Kunpeng 920平台上实现了比x86解决方案1.63倍的加速


<details>
  <summary>Details</summary>
Motivation: 随着ARM服务器在工业界的普及，需要专门为ARM架构优化的ANNS解决方案，现有x86算法的简单移植无法充分利用ARM硬件能力

Method: 采用整体协同设计方法：1)混合集群内搜索策略和改进的PQ残差计算；2)ML驱动的自适应搜索模块实现查询级参数调优；3)高度优化的ARM SIMD内核

Result: KScaNN不仅弥补了性能差距，还建立了新标准，比最快的x86解决方案快1.63倍

Conclusion: 该工作为在现代ARM架构上实现领先的向量搜索性能提供了明确蓝图

Abstract: Approximate Nearest Neighbor Search (ANNS) is a cornerstone algorithm for
information retrieval, recommendation systems, and machine learning
applications. While x86-based architectures have historically dominated this
domain, the increasing adoption of ARM-based servers in industry presents a
critical need for ANNS solutions optimized on ARM architectures. A naive port
of existing x86 ANNS algorithms to ARM platforms results in a substantial
performance deficit, failing to leverage the unique capabilities of the
underlying hardware. To address this challenge, we introduce KScaNN, a novel
ANNS algorithm co-designed for the Kunpeng 920 ARM architecture. KScaNN
embodies a holistic approach that synergizes sophisticated, data aware
algorithmic refinements with carefully-designed hardware specific
optimizations. Its core contributions include: 1) novel algorithmic techniques,
including a hybrid intra-cluster search strategy and an improved PQ residual
calculation method, which optimize the search process at a higher level; 2) an
ML-driven adaptive search module that provides adaptive, per-query tuning of
search parameters, eliminating the inefficiencies of static configurations; and
3) highly-optimized SIMD kernels for ARM that maximize hardware utilization for
the critical distance computation workloads. The experimental results
demonstrate that KScaNN not only closes the performance gap but establishes a
new standard, achieving up to a 1.63x speedup over the fastest x86-based
solution. This work provides a definitive blueprint for achieving
leadership-class performance for vector search on modern ARM architectures and
underscores

</details>


### [10] [Discourse-Aware Scientific Paper Recommendation via QA-Style Summarization and Multi-Level Contrastive Learning](https://arxiv.org/abs/2511.03330)
*Shenghua Wang,Zhen Yin*

Main category: cs.IR

TL;DR: OMRC-MR是一个用于学术论文推荐的分层框架，通过QA式OMRC摘要、多级对比学习和结构感知重排序，解决了现有模型忽略论文话语结构的问题，显著提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: 开放获取出版物的快速增长加剧了识别相关科学论文的挑战。由于隐私限制和用户交互数据有限，现有模型通常将论文视为非结构化文本，忽略了其话语组织，限制了语义完整性和可解释性。

Method: 提出OMRC-MR分层框架：1）QA式OMRC摘要模块将原始论文转换为结构化表示；2）多级对比学习目标在元数据、章节和文档级别对齐语义表示；3）结构感知重排序阶段通过上下文相似性校准提高检索精度。

Result: 在DBLP、S2ORC和新构建的Sci-OMRC数据集上的实验表明，OMRC-MR始终优于最先进的基线方法，在Precision@10和Recall@10上分别实现了高达7.2%和3.8%的改进。QA式摘要产生了更连贯和事实完整的表示。

Conclusion: OMRC-MR为基于内容的科学论文推荐提供了一个统一且可解释的范式，推进了可信赖和隐私感知的学术信息检索。

Abstract: The rapid growth of open-access (OA) publications has intensified the
challenge of identifying relevant scientific papers. Due to privacy constraints
and limited access to user interaction data, recent efforts have shifted toward
content-based recommendation, which relies solely on textual information.
However, existing models typically treat papers as unstructured text,
neglecting their discourse organization and thereby limiting semantic
completeness and interpretability. To address these limitations, we propose
OMRC-MR, a hierarchical framework that integrates QA-style OMRC (Objective,
Method, Result, Conclusion) summarization, multi-level contrastive learning,
and structure-aware re-ranking for scholarly recommendation. The QA-style
summarization module converts raw papers into structured and
discourse-consistent representations, while multi-level contrastive objectives
align semantic representations across metadata, section, and document levels.
The final re-ranking stage further refines retrieval precision through
contextual similarity calibration. Experiments on DBLP, S2ORC, and the newly
constructed Sci-OMRC dataset demonstrate that OMRC-MR consistently surpasses
state-of-the-art baselines, achieving up to 7.2% and 3.8% improvements in
Precision@10 and Recall@10, respectively. Additional evaluations confirm that
QA-style summarization produces more coherent and factually complete
representations. Overall, OMRC-MR provides a unified and interpretable
content-based paradigm for scientific paper recommendation, advancing
trustworthy and privacy-aware scholarly information retrieval.

</details>


### [11] [A Semantic Encoding of Object Centric Event Data](https://arxiv.org/abs/2511.03351)
*Saba Latif,Fajar J. Ekaputra,Maxim Vidgof,Sabrina Kirrane,Claudio Di Ciccio*

Main category: cs.IR

TL;DR: 提出了一种基于语义网技术的对象中心事件数据(OCED)元模型，旨在增强过程数据的推理能力、信息源互连和表达能力。


<details>
  <summary>Details</summary>
Motivation: 解决来自不同提供商的数据集成、多个过程组合以及知识推理增强等新挑战，促进互操作性和过程信息交换。

Method: 利用语义网技术创建机器可读的OCED描述，通过基于本体的关系和实体分类进行丰富。

Result: 开发了一种语义增强的OCED实现方法，能够加强过程数据推理、互连信息源并提升表达力。

Conclusion: 语义网技术为OCED元模型提供了有效的实现途径，能够显著提升过程数据的语义表达和推理能力。

Abstract: The Object-Centric Event Data (OCED) is a novel meta-model aimed at providing
a common ground for process data records centered around events and objects.
One of its objectives is to foster interoperability and process information
exchange. In this context, the integration of data from different providers,
the combination of multiple processes, and the enhancement of knowledge
inference are novel challenges. Semantic Web technologies can enable the
creation of a machine-readable OCED description enriched through ontology-based
relationships and entity categorization. In this paper, we introduce an
approach built upon Semantic Web technologies for the realization of
semantic-enhanced OCED, with the aim to strengthen process data reasoning,
interconnect information sources, and boost expressiveness.

</details>


### [12] [CLAX: Fast and Flexible Neural Click Models in JAX](https://arxiv.org/abs/2511.03620)
*Philipp Hager,Onno Zoeter,Maarten de Rijke*

Main category: cs.IR

TL;DR: CLAX是一个基于JAX的库，用现代梯度优化实现经典点击模型，解决了传统EM优化效率低的问题，支持模块化集成和端到端优化。


<details>
  <summary>Details</summary>
Motivation: 虽然神经点击模型在过去十年出现，但基于概率图模型的复杂点击模型尚未系统采用梯度优化，阻碍了从业者在保持经典模型可解释性的同时利用现代深度学习框架。

Method: 用直接梯度优化替代EM优化，采用数值稳定方式实现，模块化设计支持嵌入、深度网络和自定义模块集成到经典点击模型中。

Result: 在包含超过10亿用户会话的Baidu-ULTR数据集上，单GPU约2小时完成实验，比传统EM方法快几个数量级。实现了10个经典点击模型。

Conclusion: CLAX填补了梯度优化在经典点击模型中的应用空白，为行业从业者和研究人员提供了高效、可扩展的解决方案。

Abstract: CLAX is a JAX-based library that implements classic click models using modern
gradient-based optimization. While neural click models have emerged over the
past decade, complex click models based on probabilistic graphical models
(PGMs) have not systematically adopted gradient-based optimization, preventing
practitioners from leveraging modern deep learning frameworks while preserving
the interpretability of classic models. CLAX addresses this gap by replacing
EM-based optimization with direct gradient-based optimization in a numerically
stable manner. The framework's modular design enables the integration of any
component, from embeddings and deep networks to custom modules, into classic
click models for end-to-end optimization. We demonstrate CLAX's efficiency by
running experiments on the full Baidu-ULTR dataset comprising over a billion
user sessions in $\approx$ 2 hours on a single GPU, orders of magnitude faster
than traditional EM approaches. CLAX implements ten classic click models,
serving both industry practitioners seeking to understand user behavior and
improve ranking performance at scale and researchers developing new click
models. CLAX is available at: https://github.com/philipphager/clax

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [13] [Formalizing ETLT and ELTL Design Patterns and Proposing Enhanced Variants: A Systematic Framework for Modern Data Engineering](https://arxiv.org/abs/2511.03393)
*Chiara Rucco,Motaz Saad,Antonella Longo*

Main category: cs.DB

TL;DR: 本文正式化ETLT和ELTL作为可重用设计模式，并引入增强变体ETLT++和ELTL++来解决治理、质量保证和可观测性方面的持续差距。


<details>
  <summary>Details</summary>
Motivation: 传统ETL和ELT设计模式难以满足现代可扩展性、治理和实时数据处理的要求，而混合方法如ETLT和ELTL在实践中已使用但缺乏最佳实践和正式认可。

Method: 在模式框架内系统化定义ETLT和ELTL模式，并通过嵌入显式契约、版本控制、语义管理和持续监控来扩展为ETLT++和ELTL++。

Result: 提出了一个结构化路线图，用于构建可审计、可扩展且成本效益高的数据管道，在多云和实时环境中统一质量执行、数据血缘和可用性。

Conclusion: 通过正式化ETLT和ELTL并增强为ETLT++和ELTL++，这项工作弥合了临时实践与系统设计之间的差距，为现代可信数据工程提供了可重用基础。

Abstract: Traditional ETL and ELT design patterns struggle to meet modern requirements
of scalability, governance, and real-time data processing. Hybrid approaches
such as ETLT (Extract-Transform-Load-Transform) and ELTL
(Extract-Load-Transform-Load) are already used in practice, but the literature
lacks best practices and formal recognition of these approaches as design
patterns. This paper formalizes ETLT and ELTL as reusable design patterns by
codifying implicit best practices and introduces enhanced variants, ETLT++ and
ELTL++, to address persistent gaps in governance, quality assurance, and
observability. We define ETLT and ELTL patterns systematically within a design
pattern framework, outlining their structure, trade-offs, and use cases.
Building on this foundation, we extend them into ETLT++ and ELTL++ by embedding
explicit contracts, versioning, semantic curation, and continuous monitoring as
mandatory design obligations. The proposed framework offers practitioners a
structured roadmap to build auditable, scalable, and cost-efficient pipelines,
unifying quality enforcement, lineage, and usability across multi-cloud and
real-time contexts. By formalizing ETLT and ELTL, and enhancing them through
ETLT++ and ELTL++, this work bridges the gap between ad hoc practice and
systematic design, providing a reusable foundation for modern, trustworthy data
engineering.

</details>


### [14] [HERP: Hardware for Energy Efficient and Realtime DB Search and Cluster Expansion in Proteomics](https://arxiv.org/abs/2511.03437)
*Md Mizanur Rahaman Nayan,Zheyu Li,Flavio Ponzina,Sumukh Pinge,Tajana Rosing,Azad J. Naeemi*

Main category: cs.DB

TL;DR: 提出了一种轻量级增量聚类和高度并行化的数据库搜索平台，针对资源受限环境优化，在保持性能的同时降低能耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 传统蛋白质组学中的数据库搜索和聚类方法需要大量资源且延迟高，不适用于资源受限环境。

Method: 利用质谱分析见解，采用分桶并行化和查询调度策略；一次性硬件初始化预聚类数据，支持连续数据库搜索和本地重聚类；使用预聚类数据的启发式方法指导增量聚类。

Result: 增量聚类速度提升20倍，聚类误差仅增加0.3%；数据库搜索结果与最先进工具重叠率达96%；人类基因组数据集(131GB)的1000次查询搜索仅消耗1.1μJ能量；分桶并行化实现100倍加速。

Conclusion: 该方法为资源受限环境提供了实用高效的数据库搜索和聚类解决方案，在保持高质量的同时显著降低了资源需求和延迟。

Abstract: Database (DB) search and clustering are fundamental in proteomics but
conventional full clustering and search approaches demand high resources and
incur long latency. We propose a lightweight incremental clustering and highly
parallelizable DB search platform tailored for resource-constrained
environments, delivering low energy and latency without compromising
performance. By leveraging mass-spectrometry insights, we employ bucket-wise
parallelization and query scheduling to reduce latency. A one-time hardware
initialization with pre-clustered proteomics data enables continuous DB search
and local re-clustering, offering a more practical and efficient alternative to
clustering from scratch. Heuristics from pre-clustered data guide incremental
clustering, accelerating the process by 20x with only a 0.3% increase in
clustering error. DB search results overlap by 96% with state-of-the-art tools,
validating search quality. The hardware leverages a 3T 2M T J SOT-CAM at the
7nm node with a compute-in-memory design. For the human genome draft dataset
(131GB), setup requires 1.19mJ for 2M spectra, while a 1000 query search
consumes 1.1{\mu}J. Bucket-wise parallelization further achieves 100x speedup.

</details>


### [15] [In-Memory Indexing and Querying of Provenance in Data Preparation Pipelines](https://arxiv.org/abs/2511.03480)
*Khalid Belhajjame,Haroun Mezrioui,Yuyan Zhao*

Main category: cs.DB

TL;DR: 提出了一种基于张量的索引机制，用于高效捕获和查询数据准备流水线的细粒度溯源信息，结合回顾性和前瞻性溯源来支持属性级溯源查询。


<details>
  <summary>Details</summary>
Motivation: 数据溯源在数据准备流水线中有多种应用，如调试故障流水线、解释结果、验证公平性和识别数据质量问题。现有方法需要更高效的机制来捕获和查询细粒度溯源信息。

Method: 使用张量来捕获数据处理操作的细粒度溯源，占用内存最小。通过增强张量来结合回顾性溯源和前瞻性溯源信息，建立数据处理操作输入输出模式之间的连接，实现属性级溯源。

Result: 通过真实和合成数据的评估验证了该方法的有效性，能够高效回答广泛的溯源查询问题。

Conclusion: 提出的索引机制成功结合了两种溯源类型，为数据流水线提供了高效的细粒度溯源捕获和查询能力，在内存使用和查询效率方面表现良好。

Abstract: Data provenance has numerous applications in the context of data preparation
pipelines. It can be used for debugging faulty pipelines, interpreting results,
verifying fairness, and identifying data quality issues, which may affect the
sources feeding the pipeline execution. In this paper, we present an indexing
mechanism to efficiently capture and query pipeline provenance. Our solution
leverages tensors to capture fine-grained provenance of data processing
operations, using minimal memory. In addition to record-level lineage
relationships, we provide finer granularity at the attribute level. This is
achieved by augmenting tensors, which capture retrospective provenance, with
prospective provenance information, drawing connections between input and
output schemas of data processing operations. We demonstrate how these two
types of provenance (retrospective and prospective) can be combined to answer a
broad range of provenance queries efficiently, and show effectiveness through
evaluation exercises using both real and synthetic data.

</details>


### [16] [Analytical Queries for Unstructured Data](https://arxiv.org/abs/2511.03489)
*Daniel Kang*

Main category: cs.DB

TL;DR: 这篇论文讨论了使用机器学习分析非结构化数据（特别是视频分析）时面临的数据管理系统挑战，包括查询表达、计算成本和错误处理问题，并介绍了该领域的最新研究进展。


<details>
  <summary>Details</summary>
Motivation: 随着非结构化数据呈指数级增长和机器学习方法日益强大，迫切需要解决在部署这些技术时面临的三大挑战：高效执行昂贵的ML查询、在自定义数据形式上表达查询、以及处理ML方法中的错误。

Method: 论文综述了数据管理社区的最新工作，包括通过用户定义函数、结构化模式不透明查询和示例查询来表达用户意图；通过近似昂贵的"黄金"方法来优化查询；以及应用异常值和漂移检测来处理ML模型错误。

Result: 研究显示，当前的数据管理系统已经能够解决非结构化数据分析中的关键挑战，特别是在视频分析领域，通过创新的查询表达方式和优化技术，使得基于ML的数据分析变得更加可行和高效。

Conclusion: 尽管在非结构化数据分析领域仍面临挑战，但数据管理社区的最新进展为解决ML查询表达、计算成本和错误处理等问题提供了有效的解决方案，为更广泛地应用机器学习分析现实世界数据奠定了基础。

Abstract: Unstructured data, in the form of text, images, video, and audio, is produced
at exponentially higher rates. In tandem, machine learning (ML) methods have
become increasingly powerful at analyzing unstructured data. Modern ML methods
can now detect objects in images, understand actions in videos, and even
classify complex legal texts based on legal intent. Combined, these trends make
it increasingly feasible for analysts and researchers to automatically
understand the "real world." However, there are major challenges in deploying
these techniques: 1) executing queries efficiently given the expense of ML
methods, 2) expressing queries over bespoke forms of data, and 3) handling
errors in ML methods.
  In this monograph, we discuss challenges and advances in data management
systems for unstructured data using ML, with a particular focus on video
analytics. Using ML to answer queries introduces new challenges.First, even
turning user intent into queries can be challenging: it is not obvious how to
express a query of the form "select instances of cars turning left." Second, ML
models can be orders of magnitude more expensive compared to processing
traditional structured data. Third, ML models and the methods to accelerate
analytics with ML models can be error-prone.
  Recent work in the data management community has aimed to address all of
these challenges. Users can now express queries via user-defined functions,
opaquely through standard structured schemas, and even by providing examples.
Given a query, recent work focuses on optimizing queries by approximating
expensive "gold" methods with varying levels of guarantees. Finally, to handle
errors in ML models, recent work has focused on applying outlier and drift
detection to data analytics with ML.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [17] [Faster Weak Expander Decompositions and Approximate Max Flow](https://arxiv.org/abs/2511.02943)
*Henry Fleischmann,George Z. Li,Jason Li*

Main category: cs.DS

TL;DR: 本文提出了更快的弱扩展器分解和近似最大流算法，通过预热剪枝匹配游戏和优化非递归框架，显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有算法在计算弱扩展器分解时存在递归深度成本高的问题，且对流量子程序的要求过于严格，限制了算法效率。

Method: 1. 在计算弱扩展器分解时引入预热启动机制，避免递归深度成本；2. 优化Li等人的非递归近似最大流算法框架，适配新的弱扩展器分解原语。

Result: 获得了在扩展器分解方法极限范围内的近似最大流算法，计算效率显著提升，仅需几个对数因子。

Conclusion: 通过预热启动和框架优化，本文在弱扩展器分解和近似最大流问题上实现了更高效的算法，为相关研究提供了新的技术路径。

Abstract: We give faster algorithms for weak expander decompositions and approximate
max flow on undirected graphs. First, we show that it is possible to "warm
start" the cut-matching game when computing weak expander decompositions,
avoiding the cost of the recursion depth. Our algorithm is also flexible enough
to support weaker flow subroutines than previous algorithms.
  Our second contribution is to streamline the recent non-recursive approximate
max flow algorithm of Li, Rao, and Wang (SODA, 2025) and adapt their framework
to use our new weak expander decomposition primitive. Consequently, we give an
approximate max flow algorithm within a few logarithmic factors of the limit of
expander decomposition-based approaches.

</details>


### [18] [Tight Better-Than-Worst-Case Bounds for Element Distinctness and Set Intersection](https://arxiv.org/abs/2511.02954)
*Ivor van der Hoog,Eva Rotenberg,Daniel Rutschmann*

Main category: cs.DS

TL;DR: 本文研究了元素唯一性问题的实例敏感下界，通过构建重复元素的图结构，证明了确定性算法的最优竞争比为O(log log n)，并与集合交集问题进行了对比。


<details>
  <summary>Details</summary>
Motivation: 经典的元素唯一性问题有Ω(n log n)的比较下界，但这个下界在输入包含大量重复元素时不适用。作者希望找到对重复元素数量敏感的比较下界。

Method: 通过构建表示重复元素组合结构的图G(I)，研究算法在所有具有同构图结构的输入上的最坏情况运行时间。建立了对抗性下界和匹配的确定性算法。

Result: 证明了任何确定性算法都存在一个图G，使得存在算法在所有同构于G的输入上比该算法快O(log log n)倍。同时给出了O(log log n)竞争的确定性算法。

Conclusion: 元素唯一性问题的最优确定性竞争比为Θ(log log n)，而集合交集问题的最优竞争比为Θ(log n)，显示了这两个问题之间的分离。

Abstract: The element distinctness problem takes as input a list $I$ of $n$ values from
a totally ordered universe and the goal is to decide whether $I$ contains any
duplicates. It is a well-studied problem with a classical worst-case $\Omega(n
\log n)$ comparison-based lower bound by Fredman. At first glance, this lower
bound appears to rule out any algorithm more efficient than the naive approach
of sorting $I$ and comparing adjacent elements. However, upon closer
inspection, the $\Omega(n \log n)$ bound does not apply if the input has many
duplicates. We therefore ask: Are there comparison-based lower bounds for
element distinctness that are sensitive to the amount of duplicates in the
input?
  To address this question, we derive instance-specific lower bounds. For any
input instance $I$, we represent the combinatorial structure of the duplicates
in $I$ by an undirected graph $G(I)$ that connects identical elements. Each
such graph $G$ is a union of cliques, and we study algorithms by their
worst-case running time over all inputs $I'$ with $G(I') \cong G$. We establish
an adversarial lower bound showing that, for any deterministic algorithm
$\mathcal{A}$, there exists a graph $G$ and an algorithm $\mathcal{A}'$ that,
for all inputs $I$ with $G(I) \cong G$, is a factor $O(\log \log n)$ faster
than $\mathcal{A}$. Consequently, no deterministic algorithm can be $o(\log
\log n)$-competitive for all graphs $G$. We complement this with an $O(\log
\log n)$-competitive deterministic algorithm, thereby obtaining tight bounds
for element distinctness that go beyond classical worst-case analysis.
  We subsequently study the related problem of set intersection. We show that
no deterministic set intersection algorithm can be $o(\log n)$-competitive, and
provide an $O(\log n)$-competitive deterministic algorithm. This shows a
separation between element distinctness and the set intersection problem.

</details>


### [19] [Implementation and Brief Experimental Analysis of the Duan et al. (2025) Algorithm for Single-Source Shortest Paths](https://arxiv.org/abs/2511.03007)
*Lucas Castro,Thailsson Clementino,Rosiane de Freitas*

Main category: cs.DS

TL;DR: 实现了Duan等人(2025)提出的SSSP确定性算法，该算法在比较-加法模型中达到已知最佳渐近上界O(m log^{2/3} n)，但实验显示其常数因子较大，在稀疏图上Dijkstra算法更快。


<details>
  <summary>Details</summary>
Motivation: 验证具有最佳渐近复杂度的SSSP新算法在实际应用中的性能表现，比较其与经典Dijkstra算法的实际效率。

Method: 忠实实现Duan等人算法的C++版本，在合成稀疏随机图和真实道路网络(DIMACS基准)上进行实验，与使用二叉堆的Dijkstra算法对比。

Result: 新算法虽然渐近复杂度更优，但常数因子显著更大，在所有测试的稀疏图(包括数千万顶点实例)上Dijkstra算法更快。

Conclusion: 尽管新算法理论复杂度更好，但由于较大的常数因子，在实际稀疏图应用中经典Dijkstra算法仍然更优。

Abstract: We present an implementation and a brief experimental analysis of the
deterministic algorithm proposed by Duan et al. (2025) for the Single-Source
Shortest Path (SSSP) problem, which achieves the best known asymptotic upper
bound in the comparison-addition model, with running time $O(m \log^{2/3} n)$.
We provide a faithful C++ implementation of this algorithm, following all
structural details described in the original paper, and compare its empirical
performance with the classical Dijkstra's algorithm using binary heaps. The
experiments were conducted on both synthetic sparse random graphs and
real-world road network instances from the DIMACS benchmark. Our results show
that, despite its superior asymptotic complexity, the new algorithm presents
significantly larger constant factors, making Dijkstra's algorithm faster for
all tested sparse graph sizes, including instances with tens of millions of
vertices. Our implementation achieves $O(m \log^{2/3} n)$ expected time, due to
the use of hash tables, and some possibilities for making it worst-case are
being considered. (This is a ongoing work.)

</details>


### [20] [A Branch-and-Bound Approach for Maximum Low-Diameter Dense Subgraph Problems](https://arxiv.org/abs/2511.03157)
*Yi Zhoua,Chunyu Luoa,Zhengren Wangb,Zhang-Hua Fuc*

Main category: cs.DS

TL;DR: 本文研究在图中寻找直径不超过2的最大f(·)-稠密子图问题，提出了基于分解的分支定界算法，通过分解框架将图划分为n个子图进行独立搜索，在真实图数据集上表现优于MIP求解器和纯分支定界方法。


<details>
  <summary>Details</summary>
Motivation: f(·)-稠密图虽然能涵盖多种团模型，但可能存在不连通或弱连通的问题。为了解决这个问题，需要寻找具有良好连通性（直径不超过2）的最大稠密子图。

Method: 提出分解框架的分支定界算法，使用退化序和两跳退化序分解策略，结合基于排序的上界技术来求解每个子问题。

Result: 在139个真实图数据集上的实验表明，该算法在1小时内能解决近两倍于MIP求解器和纯分支定界方法的实例，性能显著提升。

Conclusion: 提出的分解框架分支定界算法能有效解决最大直径约束稠密子图问题，在真实图数据上表现出优越性能。

Abstract: A graph with $n$ vertices is an $f(\cdot)$-dense graph if it has at least
$f(n)$ edges, $f(\cdot)$ being a well-defined function. The notion
$f(\cdot)$-dense graph encompasses various clique models like $\gamma$-quasi
cliques, $k$-defective cliques, and dense cliques, arising in cohesive subgraph
extraction applications. However, the $f(\cdot)$-dense graph may be
disconnected or weakly connected. To conquer this, we study the problem of
finding the largest $f(\cdot)$-dense subgraph with a diameter of at most two in
the paper. Specifically, we present a decomposition-based branch-and-bound
algorithm to optimally solve this problem. The key feature of the algorithm is
a decomposition framework that breaks the graph into $n$ smaller subgraphs,
allowing independent searches in each subgraph. We also introduce decomposition
strategies including degeneracy and two-hop degeneracy orderings, alongside a
branch-and-bound algorithm with a novel sorting-based upper bound to solve each
subproblem. Worst-case complexity for each component is provided. Empirical
results on 139 real-world graphs under two $f(\cdot)$ functions show our
algorithm outperforms the MIP solver and pure branch-and-bound, solving nearly
twice as many instances optimally within one hour.

</details>


### [21] [Optimal Stopping with a Predicted Prior](https://arxiv.org/abs/2511.03289)
*Tian Bai,Zhiyi Huang,Chui Shan Lee,Dongchen Li*

Main category: cs.DS

TL;DR: 该论文提出了一个结合秘书问题和先知不等式的最优停止模型，使用预测先验来设计既一致又鲁棒的算法，改进了现有方法的权衡效果。


<details>
  <summary>Details</summary>
Motivation: 实际决策者通常依赖可能出错的机器学习先验，而现有的秘书模型（无先验知识）和先知不等式模型（完全信息）都无法很好地处理这种情况。

Method: 提出了基于预测先验的双准则算法族，在最大化期望接受值和最大化接受最大值的概率两个目标上，都能获得改进的一致性-鲁棒性权衡。

Result: 证明了该算法族在两种目标下都能实现比现有方法更好的权衡效果，但对于最大化接受最大值概率的目标，无法同时达到最佳先知不等式算法的一致性和最佳秘书算法的鲁棒性。

Conclusion: 该研究填补了最优停止理论中的空白，为实际应用中基于预测先验的决策提供了有效的算法框架。

Abstract: There are two major models of value uncertainty in the optimal stopping
literature: the secretary model, which assumes no prior knowledge, and the
prophet inequality model, which assumes full information about value
distributions. In practice, decision makers often rely on machine-learned
priors that may be erroneous. Motivated by this gap, we formulate the model of
optimal stopping with a predicted prior to design algorithms that are both
consistent, exploiting the prediction when accurate, and robust, retaining
worst-case guarantees when it is not.
  Existing secretary and prophet inequality algorithms are either pessimistic
in consistency or not robust to misprediction. A randomized combination only
interpolates their guarantees linearly. We show that a family of bi-criteria
algorithms achieves improved consistency-robustness trade-offs, both for
maximizing the expected accepted value and for maximizing the probability of
accepting the maximum value. We further prove that for the latter objective, no
algorithm can simultaneously match the best prophet inequality algorithm in
consistency, and the best secretary algorithm in robustness.

</details>


### [22] [Improved Online Load Balancing in the Two-Norm](https://arxiv.org/abs/2511.03345)
*Sander Borst,Danish Kashaev*

Main category: cs.DS

TL;DR: 本文提出了首个突破5竞争比的在线负载均衡算法，达到4.9843的竞争比，使用新的原始-对偶框架和相关的随机舍入方法。


<details>
  <summary>Details</summary>
Motivation: 在线负载均衡问题中，之前最好的随机算法竞争比为5，需要突破这一界限。

Method: 使用基于半定规划松弛的新原始-对偶框架，结合在线实现的关联随机舍入过程。

Result: 获得了4.9843的竞争比，突破了之前的5界限，并提供了多个算法的最优性证明。

Conclusion: 新框架不仅突破了竞争比界限，还统一了多个算法的分析，并证明了某些算法的最优性。

Abstract: We study the online load balancing problem on unrelated machines, with the
objective of minimizing the square of the $\ell_2$ norm of the loads on the
machines. The greedy algorithm of Awerbuch et al. (STOC'95) is optimal for
deterministic algorithms and achieves a competitive ratio of $3 + 2 \sqrt{2}
\approx 5.828$, and an improved $5$-competitive randomized algorithm based on
independent rounding has been shown by Caragiannis (SODA'08). In this work, we
present the first algorithm breaking the barrier of $5$ on the competitive
ratio, achieving a bound of $4.9843$. To obtain this result, we use a new
primal-dual framework to analyze this problem based on a natural semidefinite
programming relaxation, together with an online implementation of a correlated
randomized rounding procedure of Im and Shadloo (SODA'20). This novel
primal-dual framework also yields new, simple and unified proofs of the
competitive ratio of the $(3 + 2 \sqrt{2})$-competitive greedy algorithm, the
$5$-competitive randomized independent rounding algorithm, and that of a new
$4$-competitive optimal fractional algorithm. We also provide lower bounds
showing that the previous best randomized algorithm is optimal among
independent rounding algorithms, that our new fractional algorithm is optimal,
and that a simple greedy algorithm is optimal for the closely related online
scheduling problem $R || \sum w_j C_j$.

</details>


### [23] [Hesse's Redemption: Efficient Convex Polynomial Programming](https://arxiv.org/abs/2511.03440)
*Lucas Slot,David Steurer,Manuel Wiedmer*

Main category: cs.DS

TL;DR: 本文解决了凸多项式优化问题，证明了存在多项式位长的近似最优解，并基于此开发了第一个多项式时间算法，特别是解决了四阶及以上凸多项式无约束最小化的开放问题。


<details>
  <summary>Details</summary>
Motivation: 凸优化算法（如椭球法）需要先验的最优解边界。对于线性和凸二次规划，已有经典方法确定边界，但对于半定规划等，Khachiyan的例子表明最优解可能需要指数位长的系数。四阶及以上凸多项式最小化问题处于中间状态：既无线性特征化，又不受Khachiyan型例子影响，因此成为开放问题。

Method: 开发新技术证明在无线性特征化情况下的解边界。对于任意阶凸多项式在多面体上的最小化，证明若存在最优解，则也存在具有多项式位长的近似最优解。结合椭球法，得到多项式时间算法。

Result: 证明了凸多项式规划存在多项式位长的近似最优解，并基于此开发了第一个多项式时间算法，解决了Nesterov提出的问题。此前，即使是四阶凸多项式的无约束最小化也没有已知的多项式时间算法。

Conclusion: 本文通过新开发的解边界技术，首次为凸多项式规划提供了多项式时间算法，填补了线性/二次规划与半定规划之间的算法空白，解决了长期存在的开放问题。

Abstract: Efficient algorithms for convex optimization, such as the ellipsoid method,
require an a priori bound on the radius of a ball around the origin guaranteed
to contain an optimal solution if one exists. For linear and convex quadratic
programming, such solution bounds follow from classical characterizations of
optimal solutions by systems of linear equations. For other programs, e.g.,
semidefinite ones, examples due to Khachiyan show that optimal solutions may
require huge coefficients with an exponential number of bits, even if we allow
approximations. Correspondingly, semidefinite programming is not even known to
be in NP. The unconstrained minimization of convex polynomials of degree four
and higher has remained a fundamental open problem between these two extremes:
its optimal solutions do not admit a linear characterization and, at the same
time, Khachiyan-type examples do not apply. We resolve this problem by
developing new techniques to prove solution bounds when no linear
characterizations are available. Even for programs minimizing a convex
polynomial (of arbitrary degree) over a polyhedron, we prove that the existence
of an optimal solution implies that an approximately optimal one with
polynomial bit length also exists. These solution bounds, combined with the
ellipsoid method, yield the first polynomial-time algorithm for convex
polynomial programming, settling a question posed by Nesterov (Math. Program.,
2019). Before, no polynomial-time algorithm was known even for unconstrained
minimization of a convex polynomial of degree four.

</details>


### [24] [Dynamic Meta-Kernelization](https://arxiv.org/abs/2511.03461)
*Christian Bertram,Deborah Haun,Mads Vestergaard Jensen,Tuukka Korhonen*

Main category: cs.DS

TL;DR: 该论文将核化理论从静态设置扩展到动态设置，为平面图和拓扑次自由图类上的支配集等NP难问题提供了动态线性核。


<details>
  <summary>Details</summary>
Motivation: 传统核化理论主要研究静态图上的多项式时间预处理算法，已有20年历史。该研究旨在将这些经典结果推广到动态图设置，即支持边和顶点插入删除的动态图。

Method: 构建动态数据结构，维护近似最优的突起分解。该结构在O(n log n)时间内初始化，每次更新仅需O(log n)时间，保持核的大小为O(OPT(G))且保持平面性。

Result: 成功实现了动态核化算法，为支配集等NP难问题在平面图和拓扑次自由图类上提供动态线性核。同时获得了新的动态常数近似算法和改进的动态FPT算法。

Conclusion: 该工作将核化理论扩展到动态设置，为动态参数化算法提供了新的技术工具，特别是动态突起分解数据结构的开发是主要技术贡献。

Abstract: Kernelization studies polynomial-time preprocessing algorithms. Over the last
20 years, the most celebrated positive results of the field have been linear
kernels for classical NP-hard graph problems on sparse graph classes. In this
paper, we lift these results to the dynamic setting.
  As the canonical example, Alber, Fellows, and Niedermeier [J. ACM 2004] gave
a linear kernel for dominating set on planar graphs. We provide the following
dynamic version of their kernel: Our data structure is initialized with an
$n$-vertex planar graph $G$ in $O(n \log n)$ amortized time, and, at
initialization, outputs a planar graph $K$ with $\mathrm{OPT}(K) =
\mathrm{OPT}(G)$ and $|K| = O(\mathrm{OPT}(G))$, where $\mathrm{OPT}(\cdot)$
denotes the size of a minimum dominating set. The graph $G$ can be updated by
insertions and deletions of edges and isolated vertices in $O(\log n)$
amortized time per update, under the promise that it remains planar. After each
update to $G$, the data structure outputs $O(1)$ updates to $K$, maintaining
$\mathrm{OPT}(K) = \mathrm{OPT}(G)$, $|K| = O(\mathrm{OPT}(G))$, and planarity
of $K$.
  Furthermore, we obtain similar dynamic kernelization algorithms for all
problems satisfying certain conditions on (topological-)minor-free graph
classes. Besides kernelization, this directly implies new dynamic
constant-approximation algorithms and improvements to dynamic FPT algorithms
for such problems.
  Our main technical contribution is a dynamic data structure for maintaining
an approximately optimal protrusion decomposition of a dynamic
topological-minor-free graph. Protrusion decompositions were introduced by
Bodlaender, Fomin, Lokshtanov, Penninkx, Saurabh, and Thilikos [J. ACM 2016],
and have since developed into a part of the core toolbox in kernelization and
parameterized algorithms.

</details>


### [25] [Online Flow Time Minimization: Tight Bounds for Non-Preemptive Algorithms](https://arxiv.org/abs/2511.03485)
*Yutong Geng,Enze Sun,Zonghan Yang,Yuhao Zhang*

Main category: cs.DS

TL;DR: 本文研究了最小化总流时间的在线调度问题，提出了随机化算法和确定性算法的竞争比结果，并在kill-and-restart模型中揭示了确定性算法的尖锐转变。


<details>
  <summary>Details</summary>
Motivation: 先前工作通常引用Ω(n)下界来论证抢占或资源增强的必要性，但这个下界仅适用于单机情况下的确定性算法，留下了随机化是否能帮助非抢占调度以及多机情况下最优确定性算法等基本问题。

Method: 提出了多项式时间随机化算法，竞争比为Θ(√(n/m))，并证明了匹配的随机化下界；设计了非抢占确定性算法，竞争比为O(n/m²+√(n/m)log m)；将框架扩展到kill-and-restart模型。

Result: 随机化算法竞争比为Θ(√(n/m))，改进了离线近似比；确定性算法竞争比为O(n/m²+√(n/m)log m)；在kill-and-restart模型中，m≥2时竞争比为O(√(n/m))，m=1时下界为Ω(n/log n)。

Conclusion: 解决了非抢占在线调度的随机化和确定性算法的基本问题，揭示了kill-and-restart模型中的算法转变，并表明在未知n的情况下，kill-and-restart能突破O(n)障碍而随机化单独不足以实现o(n)竞争比。

Abstract: This paper studies the classical online scheduling problem of minimizing
total flow time for $n$ jobs on $m$ identical machines. Prior work often cites
the $\Omega(n)$ lower bound for non-preemptive algorithms to argue for the
necessity of preemption or resource augmentation, which shows the trivial
$O(n)$-competitive greedy algorithm is tight. However, this lower bound applies
only to \emph{deterministic} algorithms in the \emph{single-machine} case,
leaving several fundamental questions unanswered. Can randomness help in the
non-preemptive setting, and what is the optimal online deterministic algorithm
when $m \geq 2$? We resolve both questions. We present a polynomial-time
randomized algorithm with competitive ratio $\Theta(\sqrt{n/m})$ and prove a
matching randomized lower bound, settling the randomized non-preemptive setting
for every $m$. This also improves the best-known offline approximation ratio
from $O(\sqrt{n/m}\log(n/m))$ to $O(\sqrt{n/m})$. On the deterministic side, we
present a non-preemptive algorithm with competitive ratio
$O(n/m^{2}+\sqrt{n/m}\log m)$ and prove a nearly matching lower bound.
  Our framework also extends to the kill-and-restart model, where we reveal a
sharp transition of deterministic algorithms: we design an asymptotically
optimal algorithm with the competitive ratio $O(\sqrt{n/m})$ for $m\ge 2$, yet
establish a strong $\Omega(n/\log n)$ lower bound for $m=1$. Moreover, we show
that randomization provides no further advantage, as the lower bound coincides
with that of the non-preemptive setting.
  While our main results assume prior knowledge of $n$, we also investigate the
setting where $n$ is unknown. We show kill-and-restart is powerful enough to
break the $O(n)$ barrier for $m \geq 2$ even without knowing $n$. Conversely,
we prove randomization alone is insufficient, as no algorithm can achieve an
$o(n)$ competitive ratio in this setting.

</details>


### [26] [Randomized Rounding over Dynamic Programs](https://arxiv.org/abs/2511.03490)
*Etienne Bamas,Shi Li,Lars Rohwedder*

Main category: cs.DS

TL;DR: 该论文提出了一种方法，可以在满足动态规划递推关系的问题中，近似地处理大量额外的装箱约束，获得近似保证为$n^\epsilon \mathrm{polylog} n$，时间复杂度为$n^{O(1/\epsilon)}$。


<details>
  <summary>Details</summary>
Motivation: 传统动态规划方法难以处理大量额外的装箱约束，本文旨在扩展动态规划的应用范围，使其能够处理带有大量近似约束的问题。

Method: 将动态规划子问题重新解释为网络设计问题，构建强LP松弛，然后应用随机舍入技术。

Result: 获得了近似保证为$n^\epsilon \mathrm{polylog} n$，时间复杂度为$n^{O(1/\epsilon)}$的算法，适用于多种经典动态规划问题。

Conclusion: 该方法扩展了动态规划的应用范围，能够处理带有大量近似约束的问题，并可以间接应用于覆盖约束问题和匹配问题变体。

Abstract: We show that under mild assumptions for a problem whose solutions admit a
dynamic programming-like recurrence relation, we can still find a solution
under additional packing constraints, which need to be satisfied approximately.
The number of additional constraints can be very large, for example, polynomial
in the problem size. Technically, we reinterpret the dynamic programming
subproblems and their solutions as a network design problem. Inspired by
techniques from, for example, the Directed Steiner Tree problem, we construct a
strong LP relaxation, on which we then apply randomized rounding. Our
approximation guarantees on the packing constraints have roughly the form of a
$(n^{\epsilon} \mathrm{polylog}\ n)$-approximation in time $n^{O(1/\epsilon)}$,
for any $\epsilon > 0$. By setting $\epsilon=\log \log n/\log n$, we obtain a
polylogarithmic approximation in quasi-polynomial time, or by setting
$\epsilon$ as a constant, an $n^\epsilon$-approximation in polynomial time.
  While there are necessary assumptions on the form of the DP, it is general
enough to capture many textbook dynamic programs from Shortest Path to Longest
Common Subsequence. Our algorithm then implies that we can impose additional
constraints on the solutions to these problems. This allows us to model various
problems from the literature in approximation algorithms, many of which were
not thought to be connected to dynamic programming. In fact, our result can
even be applied indirectly to some problems that involve covering instead of
packing constraints, for example, the Directed Steiner Tree problem, or those
that do not directly follow a recurrence relation, for example, variants of the
Matching problem.

</details>


### [27] [Engineering Algorithms for $\ell$-Isolated Maximal Clique Enumeration](https://arxiv.org/abs/2511.03525)
*Marco D'Elia,Irene Finocchi,Maurizio Patrignani*

Main category: cs.DS

TL;DR: 提出四种剪枝启发式算法，用于高效枚举ℓ-孤立极大团，通过控制参数ℓ过滤掉与外部过度连接的团，在真实世界社交网络图上显著提升效率


<details>
  <summary>Details</summary>
Motivation: 极大团在众多应用领域发挥重要作用，但其数量庞大使得实际应用困难。ℓ-孤立极大团通过限制团内顶点与外部图的平均连接数来筛选出更实用的团

Method: 基于Tomita等人的递归极大团枚举算法，提出四种剪枝启发式方法，可单独或组合使用，丢弃保证不会产生ℓ-孤立极大团的递归搜索分支

Result: 实验研究表明，其中两种启发式方法在具有社交网络属性的真实世界图上提供了显著的效率提升，优于Tomita基线和最先进方法

Conclusion: 所提出的剪枝启发式方法能够有效提高ℓ-孤立极大团枚举的效率，特别适用于社交网络等真实世界图数据

Abstract: Maximal cliques play a fundamental role in numerous application domains,
where their enumeration can prove extremely useful. Yet their sheer number,
even in sparse real-world graphs, can make them impractical to be exploited
effectively. To address this issue, one approach is to enumerate
$\ell$-isolated maximal cliques, whose vertices have (on average) less than
$\ell$ edges toward the rest of the graph. By tuning parameter $\ell$, the
degree of isolation can be controlled, and cliques that are overly connected to
the outside are filtered out. Building on Tomita et al.'s very practical
recursive algorithm for maximal clique enumeration, we propose four pruning
heuristics, applicable individually or in combination, that discard recursive
search branches that are guaranteed not to yield $\ell$-isolated maximal
cliques. Besides proving correctness, we characterize both the pruning power
and the computational cost of these heuristics, and we conduct an extensive
experimental study comparing our methods with Tomita's baseline and with a
state-of-the-art approach. Results show that two of our heuristics offer
substantial efficiency improvements, especially on real-world graphs with
social network properties.

</details>


### [28] [Improved Bounds with a Simple Algorithm for Edge Estimation for Graphs of Unknown Size](https://arxiv.org/abs/2511.03650)
*Debarshi Chanda*

Main category: cs.DS

TL;DR: 提出了一种随机算法，使用Degree和Random Edge查询来估计图的平均度数，查询复杂度为Õ(α/ε²d)和Õ(1/ε²)，改进了之前的工作。


<details>
  <summary>Details</summary>
Motivation: 改进Beretta等人[SODA 2026]的算法，该算法需要Õ(√n/d)查询且需要Degree、Neighbour和Random Edge三种查询，目标是开发更简单、更实用的算法。

Method: 使用随机算法，仅需Degree和Random Edge查询，通过新的估计技术，无需任何图参数作为输入。

Result: 算法能获得满足(1±ε)d的估计值，查询复杂度显著优于先前工作。

Conclusion: 提出了更优的查询复杂度算法，并给出了相应的下界证明，解决了Beretta等人提出的问题。

Abstract: We propose a randomized algorithm with query access that given a graph $G$
with arboricity $\alpha$, and average degree $d$, makes
$\widetilde{O}\left(\frac{\alpha}{\varepsilon^2d}\right)$ \texttt{Degree} and
$\widetilde{O}\left(\frac{1}{\varepsilon^2}\right)$ \texttt{Random Edge}
queries to obtain an estimate $\widehat{d}$ satisfying $\widehat{d} \in
(1\pm\varepsilon)d$. This improves the $\widetilde{O}_{\varepsilon,\log
n}\left(\sqrt{\frac{n}{d}}\right)$ query algorithm of [Beretta et al., SODA
2026] that has access to \texttt{Degree}, \texttt{Neighbour}, and
\texttt{Random Edge} queries. Our algorithm does not require any graph
parameter as input, not even the size of the vertex set, and attains both
simplicity and practicality through a new estimation technique. We complement
our upper bounds with a lower bound that shows for all valid $n,d$, and
$\alpha$, any algorithm that has access to \texttt{Degree}, \texttt{Neighbour},
and \texttt{Random Edge} queries, must make at least
$\Omega\left(\min\left(d,\frac{\alpha}{d}\right)\right)$ queries to obtain a
$(1\pm\varepsilon)$-multiplicative estimate of $d$, even with the knowledge of
$n$ and $\alpha$. We also show that even with \texttt{Pair} and
\texttt{FullNbr} queries, an algorithm must make
$\Omega\left(\min\left(d,\frac{\alpha}{d}\right)\right)$ queries to obtain a
$(1\pm\varepsilon)$-multiplicative estimate of $d$. Our work addresses both the
questions raised by the work of [Beretta et al., SODA 2026].

</details>


### [29] [An Improved Quality Hierarchical Congestion Approximator in Near-Linear Time](https://arxiv.org/abs/2511.03716)
*Monika Henzinger,Robin Münk,Harald Räcke*

Main category: cs.DS

TL;DR: 提出了第一个近线性时间算法，构建层次化拥塞近似器，在O(log²n log log n)近似比下实现，改进了之前的最佳结果。


<details>
  <summary>Details</summary>
Motivation: 现有拥塞近似器在计算时间和近似质量之间存在权衡，需要开发更高效的算法来平衡这一关系。

Method: 使用新的分区例程避免在大子图上递归，引入边界可路由性概念，改进顶点权重的最稀疏割预言机。

Result: 算法在近线性时间内实现O(log²n log log n)近似比，使用O(n log n)个割，并行实现具有多对数跨度和近线性工作量。

Conclusion: 该工作显著改进了层次化拥塞近似器的近似质量，同时保持了近线性时间复杂度，并建立了Ω(log n)的下界。

Abstract: A congestion approximator for a graph is a compact data structure that
approximately predicts the edge congestion required to route any set of flow
demands in a network. A congestion approximator is hierarchical if it consists
of a laminar family of cuts in the graph. There is a tradeoff between the
running time for computing a congestion approximator and its approximation
quality. Currently, for an $n$-node graph there exists a polynomial time
algorithm that achieves a $O(\log^{1.5}n \log \log n)$ approximation and a
near-linear time algorithm that achieves w.h.p. a $O(\log^4 n)$ approximation.
In this paper we give the first near-linear time algorithm, that achieves
w.h.p. a $O(\log^2 n \log \log n)$ approximation, using an hierarchical
congestion approximator with $O(n \log n)$ cuts. Based on a reduction from
oblivious routing, we also present a lower bound of $\Omega(\log n)$ for the
approximation quality of hierarchical congestion approximators.
  Our algorithm can also be implemented in the parallel setting achieving the
same approximation quality, polylogarithmic span and near-linear work. This
improves upon the best prior parallel algorithm, which has a $O(\log^9n)$
approximation.
  Crucial for achieving a near linear running time is a new partitioning
routine that, unlike previous such routines, manages to avoid recursing on
large subgraphs. To achieve the improved approximation quality, we introduce
the new concept of border routability of a cut and give an improved sparsest
cut oracle for general vertex weights.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [30] [Branch-and-Cut for Computing Approximate Equilibria of Mixed-Integer Generalized Nash Games](https://arxiv.org/abs/2511.03340)
*Aloïs Duguet,Tobias Harks,Martin Schmidt,Julian Schwarz*

Main category: cs.GT

TL;DR: 本文研究了混合整数变量的广义纳什均衡问题，提出了一种分支切割方法来计算包含乘性和加性松弛的近似均衡，并证明了在某些条件下的有限终止性。


<details>
  <summary>Details</summary>
Motivation: 混合整数变量的广义纳什均衡问题通常不存在精确均衡，且假设所有玩家都能求解非凸问题到全局最优是不现实的，这促使了对近似均衡的研究。

Method: 提出分支切割方法，采用交集切割思想，在约束为线性且每个玩家的成本函数为凸或凹的条件下，计算近似均衡或证明其不存在。对于标准纳什均衡问题，引入替代类型的切割。

Result: 在特定条件下证明了交集切割的存在性，对于标准纳什均衡问题，方法在玩家仅有有限多个不同最佳响应集时有限终止。基于分支切割方法，提出了单树二分搜索方法来计算最佳近似均衡。

Conclusion: 本文为混合整数广义纳什均衡问题提供了有效的计算方法，通过分支切割和单树二分搜索方法能够计算近似均衡，并在数值实验中验证了方法的有效性。

Abstract: Generalized Nash equilibrium problems with mixed-integer variables constitute
an important class of games in which each player solves a mixed-integer
optimization problem, where both the objective and the feasible set is
parameterized by the rivals' strategies. However, such games are known for
failing to admit exact equilibria and also the assumption of all players being
able to solve nonconvex problems to global optimality is questionable. This
motivates the study of approximate equilibria. In this work, we consider an
approximation concept that incorporates both multiplicative and additive
relaxations of optimality. We propose a branch-and-cut (B&C) method that
computes such approximate equilibria or proves its non-existence. For this, we
adopt the idea of intersection cuts and show the existence of such cuts under
the condition that the constraints are linear and each player's cost function
is either convex in the entire strategy profile, or, concave in the entire
strategy profile and linear in the rivals' strategies. For the special case of
standard Nash equilibrium problems, we introduce an alternative type of cut and
show that the method terminates finitely, provided that each player has only
finitely many distinct best-response sets. Finally, on the basis of the B&C
method, we introduce a single-tree binary-search method to compute
best-approximate equilibria under some simplifying assumptions. We implemented
these methods and present numerical results for a class of mixed-integer flow
games.

</details>


### [31] [Non-Monotonicity in Fair Division of Graphs](https://arxiv.org/abs/2511.03629)
*Hadi Hosseini,Shraddha Pathak,Yu Zhou*

Main category: cs.GT

TL;DR: 该论文研究了在图顶点公平分配问题中，当估值由割值（bundle中恰好有一个端点的边数）决定时，EF1（无嫉妒到一件物品）与转移稳定性（TS）的兼容性。结果显示存在与代理人数n的非单调关系：n=2和n≥4时存在EF1+TS分配，但n=3时可能不存在。


<details>
  <summary>Details</summary>
Motivation: 解决团队形成和网络划分等应用中固有的非单调估值问题，其中边际价值可能为正、负或零，取决于bundle的组成。

Method: 使用图论和公平分配理论，分析EF1与转移稳定性（TS）的兼容性，开发高效算法来构造满足条件的分配。

Result: 发现EF1+TS分配的存在性与代理人数n呈非单调关系：n=2和n≥4时总是存在，n=3时可能不存在。通过弱化效率要求或限制图为森林，可以保证对所有n都存在。

Conclusion: 在非单调估值设置下，EF1与转移稳定性之间存在复杂的兼容性关系，但通过适当调整条件或图结构限制，可以获得可行的公平高效分配方案。

Abstract: We consider the problem of fairly allocating the vertices of a graph among
$n$ agents, where the value of a bundle is determined by its cut value -- the
number of edges with exactly one endpoint in the bundle. This model naturally
captures applications such as team formation and network partitioning, where
valuations are inherently non-monotonic: the marginal values may be positive,
negative, or zero depending on the composition of the bundle. We focus on the
fairness notion of envy-freeness up to one item (EF1) and explore its
compatibility with several efficiency concepts such as Transfer Stability (TS)
that prohibits single-item transfers that benefit one agent without making the
other worse-off. For general graphs, our results uncover a non-monotonic
relationship between the number of agents $n$ and the existence of allocations
satisfying EF1 and transfer stability (TS): such allocations always exist for
$n=2$, may fail to exist for $n=3$, but exist again for all $n\geq 4$. We
further show that existence can be guaranteed for any $n$ by slightly weakening
the efficiency requirement or by restricting the graph to forests. All of our
positive results are achieved via efficient algorithms.

</details>
