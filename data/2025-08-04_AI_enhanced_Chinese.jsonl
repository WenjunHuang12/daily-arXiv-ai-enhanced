{"id": "2508.00081", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00081", "abs": "https://arxiv.org/abs/2508.00081", "authors": ["Fred Mutisya", "Shikoh Gitau", "Nasubo Ongoma", "Keith Mbae", "Elizabeth Wamicha"], "title": "Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench", "comment": null, "summary": "HealthBench, a benchmark designed to measure the capabilities of AI systems\nfor health better (Arora et al., 2025), has advanced medical language model\nevaluation through physician-crafted dialogues and transparent rubrics.\nHowever, its reliance on expert opinion, rather than high-tier clinical\nevidence, risks codifying regional biases and individual clinician\nidiosyncrasies, further compounded by potential biases in automated grading\nsystems. These limitations are particularly magnified in low- and middle-income\nsettings, where issues like sparse neglected tropical disease coverage and\nregion-specific guideline mismatches are prevalent.\n  The unique challenges of the African context, including data scarcity,\ninadequate infrastructure, and nascent regulatory frameworks, underscore the\nurgent need for more globally relevant and equitable benchmarks. To address\nthese shortcomings, we propose anchoring reward functions in version-controlled\nClinical Practice Guidelines (CPGs) that incorporate systematic reviews and\nGRADE evidence ratings.\n  Our roadmap outlines \"evidence-robust\" reinforcement learning via\nrubric-to-guideline linkage, evidence-weighted scoring, and contextual override\nlogic, complemented by a focus on ethical considerations and the integration of\ndelayed outcome feedback. By re-grounding rewards in rigorously vetted CPGs,\nwhile preserving HealthBench's transparency and physician engagement, we aim to\nfoster medical language models that are not only linguistically polished but\nalso clinically trustworthy, ethically sound, and globally relevant.", "AI": {"tldr": "HealthBench\u662f\u4e00\u4e2a\u8bc4\u4f30AI\u533b\u7597\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u4f46\u4f9d\u8d56\u4e13\u5bb6\u610f\u89c1\u53ef\u80fd\u5f15\u5165\u504f\u89c1\u3002\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u4e34\u5e8a\u5b9e\u8df5\u6307\u5357\uff08CPGs\uff09\u7684\u6539\u8fdb\u65b9\u6848\uff0c\u4ee5\u589e\u5f3a\u5168\u7403\u9002\u7528\u6027\u548c\u516c\u5e73\u6027\u3002", "motivation": "HealthBench\u7684\u5c40\u9650\u6027\u5728\u4e8e\u4f9d\u8d56\u4e13\u5bb6\u610f\u89c1\uff0c\u53ef\u80fd\u5f15\u5165\u533a\u57df\u504f\u89c1\u548c\u4e34\u5e8a\u4e2a\u4f53\u5dee\u5f02\uff0c\u5c24\u5176\u5728\u4f4e\u6536\u5165\u5730\u533a\u95ee\u9898\u66f4\u7a81\u51fa\u3002\u9700\u8981\u66f4\u5168\u7403\u5316\u548c\u516c\u5e73\u7684\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7248\u672c\u63a7\u5236CPGs\u7684\u5956\u52b1\u51fd\u6570\uff0c\u7ed3\u5408\u7cfb\u7edf\u8bc4\u4ef7\u548cGRADE\u8bc1\u636e\u8bc4\u7ea7\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u8bc1\u636e\u7a33\u5065\u7684\u8bc4\u4f30\u3002", "result": "\u6539\u8fdb\u65b9\u6848\u65e8\u5728\u63d0\u5347\u533b\u7597\u8bed\u8a00\u6a21\u578b\u7684\u4e34\u5e8a\u53ef\u4fe1\u5ea6\u3001\u4f26\u7406\u6027\u548c\u5168\u7403\u9002\u7528\u6027\uff0c\u540c\u65f6\u4fdd\u7559\u900f\u660e\u5ea6\u548c\u533b\u751f\u53c2\u4e0e\u3002", "conclusion": "\u901a\u8fc7\u57fa\u4e8e\u4e25\u683c\u5ba1\u67e5\u7684CPGs\u91cd\u65b0\u8bbe\u8ba1\u5956\u52b1\u673a\u5236\uff0c\u53ef\u4ee5\u6784\u5efa\u66f4\u53ef\u9760\u3001\u516c\u5e73\u4e14\u5168\u7403\u9002\u7528\u7684\u533b\u7597AI\u8bc4\u4f30\u57fa\u51c6\u3002"}}
{"id": "2508.00106", "categories": ["cs.AI", "cs.LG", "cs.LO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.00106", "abs": "https://arxiv.org/abs/2508.00106", "authors": ["Ernest Bonnah", "Luan Viet Nguyen", "Khaza Anuarul Hoque"], "title": "Hyperproperty-Constrained Secure Reinforcement Learning", "comment": "Accepted in IEEE/ACM MEMOCODE 2025", "summary": "Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a\ndomain-specific formal specification language known for its effectiveness in\ncompactly representing security, opacity, and concurrency properties for\nrobotics applications. This paper focuses on HyperTWTL-constrained secure\nreinforcement learning (SecRL). Although temporal logic-constrained safe\nreinforcement learning (SRL) is an evolving research problem with several\nexisting literature, there is a significant research gap in exploring\nsecurity-aware reinforcement learning (RL) using hyperproperties. Given the\ndynamics of an agent as a Markov Decision Process (MDP) and opacity/security\nconstraints formalized as HyperTWTL, we propose an approach for learning\nsecurity-aware optimal policies using dynamic Boltzmann softmax RL while\nsatisfying the HyperTWTL constraints. The effectiveness and scalability of our\nproposed approach are demonstrated using a pick-up and delivery robotic mission\ncase study. We also compare our results with two other baseline RL algorithms,\nshowing that our proposed method outperforms them.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eHyperTWTL\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08SecRL\uff09\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u5b89\u5168\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u7684\u7a7a\u767d\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5728\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u4e2d\u672a\u5145\u5206\u63a2\u7d22\u57fa\u4e8e\u8d85\u5c5e\u6027\u7684\u5b89\u5168\u7ea6\u675f\uff0c\u5c24\u5176\u662f\u5728\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001Boltzmann softmax\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408HyperTWTL\u7ea6\u675f\uff0c\u7528\u4e8e\u5b66\u4e60\u5b89\u5168\u611f\u77e5\u7684\u6700\u4f18\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u673a\u5668\u4eba\u4efb\u52a1\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u4f18\u4e8e\u4e24\u79cd\u57fa\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002", "conclusion": "HyperTWTL\u7ea6\u675f\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.00116", "categories": ["cs.AI", "H.4.1; I.2.1"], "pdf": "https://arxiv.org/pdf/2508.00116", "abs": "https://arxiv.org/abs/2508.00116", "authors": ["Wil M. P. van der Aalst"], "title": "No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence", "comment": "10 pages, 4 figures, preprint keynote paper of the seventh\n  International Conference on Intelligent and Fuzzy Systems (INFUS 2025)", "summary": "The uptake of Artificial Intelligence (AI) impacts the way we work, interact,\ndo business, and conduct research. However, organizations struggle to apply AI\nsuccessfully in industrial settings where the focus is on end-to-end\noperational processes. Here, we consider generative, predictive, and\nprescriptive AI and elaborate on the challenges of diagnosing and improving\nsuch processes. We show that AI needs to be grounded using Object-Centric\nProcess Mining (OCPM). Process-related data are structured and\norganization-specific and, unlike text, processes are often highly dynamic.\nOCPM is the missing link connecting data and processes and enables different\nforms of AI. We use the term Process Intelligence (PI) to refer to the\namalgamation of process-centric data-driven techniques able to deal with a\nvariety of object and event types, enabling AI in an organizational context.\nThis paper explains why AI requires PI to improve operational processes and\nhighlights opportunities for successfully combining OCPM and generative,\npredictive, and prescriptive AI.", "AI": {"tldr": "AI\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u9700\u7ed3\u5408\u5bf9\u8c61\u4e2d\u5fc3\u8fc7\u7a0b\u6316\u6398\uff08OCPM\uff09\u5b9e\u73b0\u8fc7\u7a0b\u667a\u80fd\uff08PI\uff09\uff0c\u4ee5\u63d0\u5347\u7aef\u5230\u7aef\u64cd\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u63a2\u8ba8AI\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u6210\u529f\u5e94\u7528\u7684\u969c\u788d\uff0c\u63d0\u51fa\u7ed3\u5408OCPM\u7684\u5fc5\u8981\u6027\u3002", "method": "\u5206\u6790\u751f\u6210\u5f0f\u3001\u9884\u6d4b\u5f0f\u548c\u89c4\u5b9a\u5f0fAI\uff0c\u5f15\u5165OCPM\u4f5c\u4e3a\u6570\u636e\u4e0e\u8fc7\u7a0b\u7684\u6865\u6881\u3002", "result": "OCPM\u662f\u5b9e\u73b0\u8fc7\u7a0b\u667a\u80fd\uff08PI\uff09\u7684\u5173\u952e\uff0c\u80fd\u6709\u6548\u652f\u6301\u591a\u79cdAI\u5f62\u5f0f\u3002", "conclusion": "AI\u9700\u7ed3\u5408PI\u548cOCPM\uff0c\u4ee5\u4f18\u5316\u64cd\u4f5c\u6d41\u7a0b\u5e76\u63a8\u52a8\u5de5\u4e1a\u5e94\u7528\u6210\u529f\u3002"}}
{"id": "2508.00194", "categories": ["cs.IR", "eess.AS"], "pdf": "https://arxiv.org/pdf/2508.00194", "abs": "https://arxiv.org/abs/2508.00194", "authors": ["F\u0131rat \u00d6ncel", "Emiliano Penaloza", "Haolun Wu", "Shubham Gupta", "Mirco Ravanelli", "Laurent Charlin", "Cem Subakan"], "title": "Audio Prototypical Network For Controllable Music Recommendation", "comment": "Accepted to MLSP2025", "summary": "Traditional recommendation systems represent user preferences in dense\nrepresentations obtained through black-box encoder models. While these models\noften provide strong recommendation performance, they lack interpretability for\nusers, leaving users unable to understand or control the system's modeling of\ntheir preferences. This limitation is especially challenging in music\nrecommendation, where user preferences are highly personal and often evolve\nbased on nuanced qualities like mood, genre, tempo, or instrumentation. In this\npaper, we propose an audio prototypical network for controllable music\nrecommendation. This network expresses user preferences in terms of prototypes\nrepresentative of semantically meaningful features pertaining to musical\nqualities. We show that the model obtains competitive recommendation\nperformance compared to popular baseline models while also providing\ninterpretable and controllable user profiles.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u97f3\u9891\u539f\u578b\u7f51\u7edc\u7684\u53ef\u63a7\u97f3\u4e50\u63a8\u8350\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u63a7\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u4f7f\u7528\u9ed1\u76d2\u7f16\u7801\u6a21\u578b\u751f\u6210\u5bc6\u96c6\u8868\u793a\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u7528\u6237\u65e0\u6cd5\u7406\u89e3\u6216\u63a7\u5236\u7cfb\u7edf\u5bf9\u5176\u504f\u597d\u7684\u5efa\u6a21\u3002\u97f3\u4e50\u63a8\u8350\u4e2d\u8fd9\u4e00\u95ee\u9898\u5c24\u4e3a\u7a81\u51fa\uff0c\u56e0\u4e3a\u7528\u6237\u504f\u597d\u9ad8\u5ea6\u4e2a\u6027\u5316\u4e14\u57fa\u4e8e\u7ec6\u5fae\u7684\u97f3\u4e50\u54c1\u8d28\uff08\u5982\u60c5\u7eea\u3001\u6d41\u6d3e\u3001\u8282\u594f\u6216\u4e50\u5668\uff09\u53d8\u5316\u3002", "method": "\u63d0\u51fa\u97f3\u9891\u539f\u578b\u7f51\u7edc\uff0c\u901a\u8fc7\u4ee3\u8868\u97f3\u4e50\u54c1\u8d28\u8bed\u4e49\u7279\u5f81\u7684\u8868\u8fbe\u7528\u6237\u504f\u597d\u3002", "result": "\u6a21\u578b\u5728\u63a8\u8350\u6027\u80fd\u4e0a\u4e0e\u6d41\u884c\u57fa\u7ebf\u6a21\u578b\u76f8\u5f53\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u548c\u53ef\u63a7\u7684\u7528\u6237\u6863\u6848\u3002", "conclusion": "\u8be5\u6a21\u578b\u5728\u4fdd\u6301\u63a8\u8350\u6027\u80fd\u7684\u540c\u65f6\uff0c\u589e\u5f3a\u4e86\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u548c\u7528\u6237\u63a7\u5236\u80fd\u529b\u3002"}}
{"id": "2508.00579", "categories": ["cs.MM", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.00579", "abs": "https://arxiv.org/abs/2508.00579", "authors": ["Ziyu Gong", "Yihua Huang", "Chengcheng Mai"], "title": "MMRAG-DocQA: A Multi-Modal Retrieval-Augmented Generation Method for Document Question-Answering with Hierarchical Index and Multi-Granularity Retrieval", "comment": null, "summary": "The multi-modal long-context document question-answering task aims to locate\nand integrate multi-modal evidences (such as texts, tables, charts, images, and\nlayouts) distributed across multiple pages, for question understanding and\nanswer generation. The existing methods can be categorized into Large\nVision-Language Model (LVLM)-based and Retrieval-Augmented Generation\n(RAG)-based methods. However, the former were susceptible to hallucinations,\nwhile the latter struggled for inter-modal disconnection and cross-page\nfragmentation. To address these challenges, a novel multi-modal RAG model,\nnamed MMRAG-DocQA, was proposed, leveraging both textual and visual information\nacross long-range pages to facilitate accurate question answering. A\nhierarchical indexing method with the integration of flattened in-page chunks\nand topological cross-page chunks was designed to jointly establish in-page\nmulti-modal associations and long-distance cross-page dependencies. By means of\njoint similarity evaluation and large language model (LLM)-based re-ranking, a\nmulti-granularity semantic retrieval method, including the page-level parent\npage retrieval and document-level summary retrieval, was proposed to foster\nmulti-modal evidence connection and long-distance evidence integration and\nreasoning. Experimental results performed on public datasets, MMLongBench-Doc\nand LongDocURL, demonstrated the superiority of our MMRAG-DocQA method in\nunderstanding and answering modality-rich and multi-page documents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMMRAG-DocQA\u7684\u591a\u6a21\u6001RAG\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u6587\u672c\u548c\u89c6\u89c9\u4fe1\u606f\u89e3\u51b3\u591a\u6a21\u6001\u957f\u6587\u6863\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u5e7b\u89c9\u548c\u6a21\u6001\u65ad\u5f00\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08LVLM\u548cRAG\uff09\u5728\u591a\u6a21\u6001\u957f\u6587\u6863\u95ee\u7b54\u4e2d\u5b58\u5728\u5e7b\u89c9\u548c\u6a21\u6001\u65ad\u5f00\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u5206\u5c42\u7d22\u5f15\u65b9\u6cd5\uff0c\u7ed3\u5408\u6241\u5e73\u5316\u7684\u9875\u9762\u5185\u5757\u548c\u62d3\u6251\u7ed3\u6784\u7684\u8de8\u9875\u9762\u5757\uff0c\u63d0\u51fa\u591a\u7c92\u5ea6\u8bed\u4e49\u68c0\u7d22\u65b9\u6cd5\uff0c\u5305\u62ec\u9875\u9762\u7ea7\u548c\u6587\u6863\u7ea7\u68c0\u7d22\u3002", "result": "\u5728MMLongBench-Doc\u548cLongDocURL\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86MMRAG-DocQA\u5728\u7406\u89e3\u548c\u56de\u7b54\u591a\u6a21\u6001\u591a\u9875\u6587\u6863\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "MMRAG-DocQA\u901a\u8fc7\u591a\u6a21\u6001\u5173\u8054\u548c\u957f\u8ddd\u79bb\u4f9d\u8d56\u7684\u8054\u5408\u5efa\u6a21\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u957f\u6587\u6863\u95ee\u7b54\u7684\u6027\u80fd\u3002"}}
{"id": "2508.00129", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2508.00129", "abs": "https://arxiv.org/abs/2508.00129", "authors": ["Agust\u00edn Borda", "Juan Bautista Cabral", "Gonzalo Giarda", "Diego Nicol\u00e1s Gimenez Irusta", "Paula Pacheco", "Alvaro Roy Schachner"], "title": "Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis", "comment": null, "summary": "In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem\nthat can greatly affect the results of a Multi-Criteria Decision Method against\na particular set of alternatives. It is therefore useful to have a mechanism\nthat allows one to measure the performance of a method on a set of\nalternatives. This idea could be taken further to build a global ranking of the\neffectiveness of different methods to solve a problem. In this paper, we\npresent three tests that detect the presence of Rank Reversals, along with\ntheir implementation in the Scikit-Criteria library. We also address the\ncomplications that arise when implementing these tests for general scenarios\nand the design considerations we made to handle them. We close with a\ndiscussion about how these additions could play a major role in the judgment of\nmulti-criteria decision methods for problem solving.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e09\u79cd\u68c0\u6d4b\u591a\u51c6\u5219\u51b3\u7b56\u5206\u6790\u4e2d\u6392\u540d\u53cd\u8f6c\u95ee\u9898\u7684\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u5728Scikit-Criteria\u5e93\u4e2d\u7684\u5b9e\u73b0\u53ca\u5176\u5bf9\u65b9\u6cd5\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u6392\u540d\u53cd\u8f6c\u662f\u591a\u51c6\u5219\u51b3\u7b56\u5206\u6790\u4e2d\u7684\u4e25\u91cd\u95ee\u9898\uff0c\u5f71\u54cd\u51b3\u7b56\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u8861\u91cf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u68c0\u6d4b\u6392\u540d\u53cd\u8f6c\uff0c\u5e76\u5728Scikit-Criteria\u5e93\u4e2d\u5b9e\u73b0\uff0c\u540c\u65f6\u8ba8\u8bba\u4e86\u901a\u7528\u573a\u666f\u4e0b\u7684\u5b9e\u73b0\u6311\u6218\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u4e09\u79cd\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5e76\u89e3\u51b3\u4e86\u901a\u7528\u573a\u666f\u4e2d\u7684\u8bbe\u8ba1\u95ee\u9898\u3002", "conclusion": "\u8fd9\u4e9b\u6d4b\u8bd5\u65b9\u6cd5\u5728\u591a\u51c6\u5219\u51b3\u7b56\u65b9\u6cd5\u7684\u8bc4\u4f30\u4e2d\u53ef\u80fd\u53d1\u6325\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2508.00450", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00450", "abs": "https://arxiv.org/abs/2508.00450", "authors": ["Hongxiang Lin", "Hao Guo", "Zeshun Li", "Erpeng Xue", "Yongqian He", "Xiangyu Hou", "Zhaoyu Hu", "Lei Wang", "Sheng Chen"], "title": "When Relevance Meets Novelty: Dual-Stable Periodic Optimization for Exploratory Recommendation", "comment": null, "summary": "Traditional recommendation systems tend to trap users in strong feedback\nloops by excessively pushing content aligned with their historical preferences,\nthereby limiting exploration opportunities and causing content fatigue.\nAlthough large language models (LLMs) demonstrate potential with their diverse\ncontent generation capabilities, existing LLM-enhanced dual-model frameworks\nface two major limitations: first, they overlook long-term preferences driven\nby group identity, leading to biased interest modeling; second, they suffer\nfrom static optimization flaws, as a one-time alignment process fails to\nleverage incremental user data for closed-loop optimization. To address these\nchallenges, we propose the Co-Evolutionary Alignment (CoEA) method. For\ninterest modeling bias, we introduce Dual-Stable Interest Exploration (DSIE)\nmodule, jointly modeling long-term group identity and short-term individual\ninterests through parallel processing of behavioral sequences. For static\noptimization limitations, we design a Periodic Collaborative Optimization (PCO)\nmechanism. This mechanism regularly conducts preference verification on\nincremental data using the Relevance LLM, then guides the Novelty LLM to\nperform fine-tuning based on the verification results, and subsequently feeds\nback the output of the incrementally fine-tuned Novelty LLM to the Relevance\nLLM for re-evaluation, thereby achieving a dynamic closed-loop optimization.\nExtensive online and offline experiments verify the effectiveness of the CoEA\nmodel in exploratory recommendation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCo-Evolutionary Alignment (CoEA)\u65b9\u6cd5\uff0c\u901a\u8fc7Dual-Stable Interest Exploration (DSIE)\u6a21\u5757\u548cPeriodic Collaborative Optimization (PCO)\u673a\u5236\uff0c\u89e3\u51b3\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u53cd\u9988\u5faa\u73af\u548cLLM\u589e\u5f3a\u6846\u67b6\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u6613\u9677\u5165\u53cd\u9988\u5faa\u73af\uff0c\u9650\u5236\u7528\u6237\u63a2\u7d22\uff1b\u73b0\u6709LLM\u589e\u5f3a\u6846\u67b6\u5b58\u5728\u5174\u8da3\u5efa\u6a21\u504f\u5dee\u548c\u9759\u6001\u4f18\u5316\u7f3a\u9677\u3002", "method": "\u63d0\u51faCoEA\u65b9\u6cd5\uff0c\u5305\u62ecDSIE\u6a21\u5757\uff08\u5e76\u884c\u5efa\u6a21\u957f\u671f\u7fa4\u4f53\u8eab\u4efd\u548c\u77ed\u671f\u4e2a\u4f53\u5174\u8da3\uff09\u548cPCO\u673a\u5236\uff08\u5468\u671f\u6027\u534f\u540c\u4f18\u5316\uff09\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1CoEA\u5728\u63a2\u7d22\u6027\u63a8\u8350\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "CoEA\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u95ed\u73af\u4f18\u5316\u548c\u53cc\u5174\u8da3\u5efa\u6a21\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u63a2\u7d22\u80fd\u529b\u3002"}}
{"id": "2508.00632", "categories": ["cs.AI", "cs.MA", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.00632", "abs": "https://arxiv.org/abs/2508.00632", "authors": ["Alexia Jolicoeur-Martineau"], "title": "Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings", "comment": null, "summary": "While AI excels at generating text, audio, images, and videos, creating\ninteractive audio-visual content such as video games remains challenging.\nCurrent LLMs can generate JavaScript games and animations, but lack automated\nevaluation metrics and struggle with complex content that normally requires\nteams of humans working for many months (multi-shot, multi-agents) using assets\nmade by artists. To tackle these issues, we built a new metric and a\nmulti-agent system.\n  We propose AVR-Eval, a relative metric for multimedia content quality using\nAudio-Visual Recordings (AVRs). An omni-modal model (processing text, video,\nand audio) compares the AVRs of two contents, with a text model reviewing\nevaluations to determine superiority. We show that AVR-Eval properly identifies\ngood from broken or mismatched content.\n  We built AVR-Agent, a multi-agent system generating JavaScript code from a\nbank of multimedia assets (audio, images, 3D models). The coding agent selects\nrelevant assets, generates multiple initial codes, uses AVR-Eval to identify\nthe best version, and iteratively improves it through omni-modal agent feedback\nfrom the AVR.\n  We run experiments on games and animations with AVR-Eval (win rate of content\nA against B). We find that content generated by AVR-Agent has a significantly\nhigher win rate against content made through one-shot generation. However,\nmodels struggle to leverage custom assets and AVR feedback effectively, showing\nno higher win rate. This reveals a critical gap: while humans benefit from\nhigh-quality assets and audio-visual feedback, current coding models do not\nseem to utilize these resources as effectively, highlighting fundamental\ndifferences between human and machine content creation approaches.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86AVR-Eval\u548cAVR-Agent\uff0c\u5206\u522b\u7528\u4e8e\u8bc4\u4f30\u548c\u751f\u6210\u4ea4\u4e92\u5f0f\u591a\u5a92\u4f53\u5185\u5bb9\uff0c\u89e3\u51b3\u4e86\u5f53\u524dAI\u5728\u590d\u6742\u5185\u5bb9\u751f\u6210\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524dAI\u5728\u751f\u6210\u4ea4\u4e92\u5f0f\u591a\u5a92\u4f53\u5185\u5bb9\uff08\u5982\u89c6\u9891\u6e38\u620f\uff09\u65f6\u9762\u4e34\u6311\u6218\uff0c\u7f3a\u4e4f\u81ea\u52a8\u5316\u8bc4\u4f30\u6307\u6807\u4e14\u96be\u4ee5\u5904\u7406\u590d\u6742\u5185\u5bb9\u3002", "method": "\u63d0\u51faAVR-Eval\u4f5c\u4e3a\u591a\u5a92\u4f53\u5185\u5bb9\u8d28\u91cf\u7684\u76f8\u5bf9\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u5f00\u53d1AVR-Agent\u591a\u4ee3\u7406\u7cfb\u7edf\u751f\u6210JavaScript\u4ee3\u7801\u3002", "result": "AVR-Agent\u751f\u6210\u7684\u5185\u5bb9\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u5355\u6b21\u751f\u6210\u7684\u5185\u5bb9\uff0c\u4f46\u672a\u80fd\u6709\u6548\u5229\u7528\u81ea\u5b9a\u4e49\u8d44\u6e90\u548c\u53cd\u9988\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u4eba\u7c7b\u4e0e\u673a\u5668\u5728\u5185\u5bb9\u521b\u4f5c\u4e0a\u7684\u6839\u672c\u5dee\u5f02\uff0c\u5f3a\u8c03\u4e86\u9ad8\u8d28\u91cf\u8d44\u6e90\u548c\u53cd\u9988\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.00037", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00037", "abs": "https://arxiv.org/abs/2508.00037", "authors": ["Tong Nie", "Jian Sun", "Wei Ma"], "title": "Predicting Large-scale Urban Network Dynamics with Energy-informed Graph Neural Diffusion", "comment": "Accepted at IEEE Transactions on Industrial Informatics", "summary": "Networked urban systems facilitate the flow of people, resources, and\nservices, and are essential for economic and social interactions. These systems\noften involve complex processes with unknown governing rules, observed by\nsensor-based time series. To aid decision-making in industrial and engineering\ncontexts, data-driven predictive models are used to forecast spatiotemporal\ndynamics of urban systems. Current models such as graph neural networks have\nshown promise but face a trade-off between efficacy and efficiency due to\ncomputational demands. Hence, their applications in large-scale networks still\nrequire further efforts. This paper addresses this trade-off challenge by\ndrawing inspiration from physical laws to inform essential model designs that\nalign with fundamental principles and avoid architectural redundancy. By\nunderstanding both micro- and macro-processes, we present a principled\ninterpretable neural diffusion scheme based on Transformer-like structures\nwhose attention layers are induced by low-dimensional embeddings. The proposed\nscalable spatiotemporal Transformer (ScaleSTF), with linear complexity, is\nvalidated on large-scale urban systems including traffic flow, solar power, and\nsmart meters, showing state-of-the-art performance and remarkable scalability.\nOur results constitute a fresh perspective on the dynamics prediction in\nlarge-scale urban networks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u5b9a\u5f8b\u542f\u53d1\u7684\u53ef\u6269\u5c55\u65f6\u7a7aTransformer\uff08ScaleSTF\uff09\uff0c\u7528\u4e8e\u9884\u6d4b\u5927\u89c4\u6a21\u57ce\u5e02\u7f51\u7edc\u7684\u52a8\u6001\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u5728\u6548\u80fd\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u57ce\u5e02\u7cfb\u7edf\u4e2d\u7684\u590d\u6742\u8fc7\u7a0b\u901a\u5e38\u7f3a\u4e4f\u660e\u786e\u7684\u89c4\u5219\uff0c\u800c\u73b0\u6709\u9884\u6d4b\u6a21\u578b\uff08\u5982\u56fe\u795e\u7ecf\u7f51\u7edc\uff09\u5728\u8ba1\u7b97\u6548\u7387\u4e0e\u9884\u6d4b\u6548\u679c\u4e4b\u95f4\u5b58\u5728\u77db\u76fe\uff0c\u9650\u5236\u4e86\u5176\u5728\u5927\u89c4\u6a21\u7f51\u7edc\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u7269\u7406\u5b9a\u5f8b\u548cTransformer\u7ed3\u6784\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u4f4e\u7ef4\u5d4c\u5165\u8bf1\u5bfc\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u63d0\u51fa\u4e86\u7ebf\u6027\u590d\u6742\u5ea6\u7684ScaleSTF\u6a21\u578b\u3002", "result": "\u5728\u4ea4\u901a\u6d41\u91cf\u3001\u592a\u9633\u80fd\u53d1\u7535\u548c\u667a\u80fd\u7535\u8868\u7b49\u5927\u89c4\u6a21\u57ce\u5e02\u7cfb\u7edf\u4e2d\u9a8c\u8bc1\u4e86ScaleSTF\u7684\u5148\u8fdb\u6027\u80fd\u548c\u5353\u8d8a\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "ScaleSTF\u4e3a\u5927\u89c4\u6a21\u57ce\u5e02\u7f51\u7edc\u52a8\u6001\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u5c55\u793a\u4e86\u5176\u5728\u6548\u80fd\u4e0e\u6548\u7387\u4e0a\u7684\u5e73\u8861\u4f18\u52bf\u3002"}}
{"id": "2508.00776", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2508.00776", "abs": "https://arxiv.org/abs/2508.00776", "authors": ["Dieter van Melkebeek"], "title": "From Dynamic Programs to Greedy Algorithms", "comment": "14 pages, 2 figures", "summary": "We show for several computational problems how classical greedy algorithms\nfor special cases can be derived in a simple way from dynamic programs for the\ngeneral case: interval scheduling (restricted to unit weights), knapsack\n(restricted to unit values), and shortest paths (restricted to nonnegative edge\nlengths). Conceptually, we repeatedly expand the Bellman equations underlying\nthe dynamic program and use straightforward monotonicity properties to figure\nout which terms yield the optimal value under the respective restrictions. The\napproach offers an alternative for developing these greedy algorithms in\nundergraduate algorithms courses and/or for arguing their correctness. In the\nsetting of interval scheduling, it elucidates the change in order from earliest\nstart time first for the memoized dynamic program to earliest finish time first\nfor the greedy algorithm.", "AI": {"tldr": "\u8bba\u6587\u5c55\u793a\u4e86\u5982\u4f55\u4ece\u52a8\u6001\u89c4\u5212\u7684\u901a\u7528\u89e3\u6cd5\u4e2d\u7b80\u5355\u63a8\u5bfc\u51fa\u7ecf\u5178\u8d2a\u5fc3\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u533a\u95f4\u8c03\u5ea6\u3001\u80cc\u5305\u95ee\u9898\u548c\u6700\u77ed\u8def\u5f84\u95ee\u9898\u3002", "motivation": "\u4e3a\u672c\u79d1\u7b97\u6cd5\u8bfe\u7a0b\u63d0\u4f9b\u4e00\u79cd\u66ff\u4ee3\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u89c4\u5212\u7684\u6269\u5c55\u548c\u5355\u8c03\u6027\u63a8\u5bfc\u8d2a\u5fc3\u7b97\u6cd5\u7684\u6b63\u786e\u6027\u3002", "method": "\u901a\u8fc7\u6269\u5c55Bellman\u65b9\u7a0b\u5e76\u5229\u7528\u5355\u8c03\u6027\uff0c\u786e\u5b9a\u5728\u7279\u5b9a\u9650\u5236\u4e0b\u54ea\u4e9b\u9879\u80fd\u4ea7\u751f\u6700\u4f18\u89e3\u3002", "result": "\u6210\u529f\u63a8\u5bfc\u51fa\u533a\u95f4\u8c03\u5ea6\u3001\u80cc\u5305\u95ee\u9898\u548c\u6700\u77ed\u8def\u5f84\u95ee\u9898\u7684\u8d2a\u5fc3\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7406\u89e3\u8d2a\u5fc3\u7b97\u6cd5\u7684\u6b63\u786e\u6027\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5c24\u5176\u5728\u533a\u95f4\u8c03\u5ea6\u4e2d\u89e3\u91ca\u4e86\u6392\u5e8f\u89c4\u5219\u7684\u53d8\u5316\u3002"}}
{"id": "2508.00183", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.00183", "abs": "https://arxiv.org/abs/2508.00183", "authors": ["Ching-Fang Li", "Mary Wootters"], "title": "Improved Bounds on Access-Redundancy Tradeoffs in Quantized Linear Computations", "comment": "ISIT 2025", "summary": "Consider the problem of computing quantized linear functions with only a few\nqueries. Formally, given $\\mathbf{x}\\in \\mathbb{R}^k$, our goal is to encode\n$\\mathbf{x}$ as $\\mathbf{c} \\in \\mathbb{R}^n$, for $n > k$, so that for any\n$\\mathbf{w} \\in A^k$, $\\mathbf{w}^T \\mathbf{x}$ can be computed using at most\n$\\ell$ queries to $\\mathbf{c}$. Here, $A$ is some finite set; in this paper we\nfocus on the case where $|A| = 2$.\n  Prior work \\emph{(Ramkumar, Raviv, and Tamo, Trans. IT, 2024)} has given\nconstructions and established impossibility results for this problem. We give\nimproved impossibility results, both for the general problem, and for the\nspecific class of construction (block construction) presented in that work. The\nlatter establishes that the block constructions of prior work are optimal\nwithin that class.\n  We also initiate the study of \\emph{approximate} recovery for this problem,\nwhere the goal is not to recover $\\mathbf{w}^T \\mathbf{x}$ exactly but rather\nto approximate it up to a parameter $\\varepsilon > 0$. We give several\nconstructions, and give constructions for $\\varepsilon = 0.1$ that outperform\nour impossibility result for exact schemes.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u7528\u5c11\u91cf\u67e5\u8be2\u8ba1\u7b97\u91cf\u5316\u7ebf\u6027\u51fd\u6570\u7684\u95ee\u9898\uff0c\u6539\u8fdb\u4e86\u5148\u524d\u7684\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\uff0c\u5e76\u9996\u6b21\u63a2\u8ba8\u4e86\u8fd1\u4f3c\u6062\u590d\u7684\u6784\u9020\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5728\u6709\u9650\u67e5\u8be2\u6b21\u6570\u4e0b\u7cbe\u786e\u6216\u8fd1\u4f3c\u8ba1\u7b97\u91cf\u5316\u7ebf\u6027\u51fd\u6570\u7684\u6311\u6218\uff0c\u4f18\u5316\u73b0\u6709\u6784\u9020\u7684\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u6539\u8fdb\u5148\u524d\u7684\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\uff0c\u5e76\u5f15\u5165\u8fd1\u4f3c\u6062\u590d\u7684\u6784\u9020\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u9488\u5bf9\u03b5=0.1\u7684\u60c5\u51b5\u3002", "result": "\u8bc1\u660e\u4e86\u5148\u524d\u5757\u6784\u9020\u7684\u6700\u4f18\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u8fd1\u4f3c\u6784\u9020\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4f18\u4e8e\u7cbe\u786e\u6784\u9020\u3002", "conclusion": "\u8bba\u6587\u4e3a\u91cf\u5316\u7ebf\u6027\u51fd\u6570\u7684\u9ad8\u6548\u8ba1\u7b97\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u548c\u6784\u9020\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u8fd1\u4f3c\u6062\u590d\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2508.00130", "categories": ["cs.GT", "cs.DM"], "pdf": "https://arxiv.org/pdf/2508.00130", "abs": "https://arxiv.org/abs/2508.00130", "authors": ["Drew Gao", "Yihang Sun", "Jan Vondr\u00e1k"], "title": "Computation of Approximately Stable Committees in Approval-based Elections", "comment": "18 pages, 2 figures", "summary": "Approval-based committee selection is a model of significant interest in\nsocial choice theory. In this model, we have a set of voters $\\mathcal{V}$, a\nset of candidates $\\mathcal{C}$, and each voter has a set $A_v \\subset\n\\mathcal{C}$ of approved candidates. For any committee size $K$, the goal is to\nchoose $K$ candidates to represent the voters' preferences. We study a\ncriterion known as \\emph{approximate stability}, where a committee is\n$\\lambda$-approximately-stable if there is no other committee $T$ preferred by\nat least $\\frac{\\lambda|T|}{k} |\\mathcal{V}| $ voters. We prove that a\n$3.65$-approximately stable committee always exists and can be computed\nalgorithmically in this setting. Our approach is based on finding a Lindahl\nequilibrium and sampling from a strongly Rayleigh distribution associated with\nit.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u6279\u51c6\u7684\u59d4\u5458\u4f1a\u9009\u62e9\u6a21\u578b\u4e2d\u7684\u8fd1\u4f3c\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u8bc1\u660e\u4e863.65-\u8fd1\u4f3c\u7a33\u5b9a\u59d4\u5458\u4f1a\u7684\u5b58\u5728\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLindahl\u5747\u8861\u548c\u5f3a\u745e\u5229\u5206\u5e03\u7684\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76\u57fa\u4e8e\u6279\u51c6\u7684\u59d4\u5458\u4f1a\u9009\u62e9\u6a21\u578b\u4e2d\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u65e8\u5728\u627e\u5230\u80fd\u591f\u4ee3\u8868\u9009\u6c11\u504f\u597d\u7684\u59d4\u5458\u4f1a\u3002", "method": "\u901a\u8fc7\u5bfb\u627eLindahl\u5747\u8861\uff0c\u5e76\u5229\u7528\u5f3a\u745e\u5229\u5206\u5e03\u8fdb\u884c\u91c7\u6837\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e863.65-\u8fd1\u4f3c\u7a33\u5b9a\u59d4\u5458\u4f1a\u7684\u5b58\u5728\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u8ba1\u7b97\u8be5\u59d4\u5458\u4f1a\u7684\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u59d4\u5458\u4f1a\u9009\u62e9\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u4fdd\u8bc1\u548c\u8ba1\u7b97\u65b9\u6cd5\u3002"}}
{"id": "2508.00137", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00137", "abs": "https://arxiv.org/abs/2508.00137", "authors": ["Shqiponja Ahmetaj", "George Konstantinidis", "Magdalena Ortiz", "Paolo Pareti", "Mantas Simkus"], "title": "SHACL Validation under Graph Updates (Extended Paper)", "comment": "Accepted at the International Semantic Web Conference (ISWC 2025)", "summary": "SHACL (SHApe Constraint Language) is a W3C standardized constraint language\nfor RDF graphs. In this paper, we study SHACL validation in RDF graphs under\nupdates. We present a SHACL-based update language that can capture intuitive\nand realistic modifications on RDF graphs and study the problem of static\nvalidation under such updates. This problem asks to verify whether every graph\nthat validates a SHACL specification will still do so after applying a given\nupdate sequence. More importantly, it provides a basis for further services for\nreasoning about evolving RDF graphs. Using a regression technique that embeds\nthe update actions into SHACL constraints, we show that static validation under\nupdates can be reduced to (un)satisfiability of constraints in (a minor\nextension of) SHACL. We analyze the computational complexity of the static\nvalidation problem for SHACL and some key fragments. Finally, we present a\nprototype implementation that performs static validation and other static\nanalysis tasks on SHACL constraints and demonstrate its behavior through\npreliminary experiments.", "AI": {"tldr": "\u7814\u7a76\u4e86SHACL\u5728RDF\u56fe\u66f4\u65b0\u4e0b\u7684\u9a8c\u8bc1\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSHACL\u7684\u66f4\u65b0\u8bed\u8a00\uff0c\u5e76\u901a\u8fc7\u56de\u5f52\u6280\u672f\u5c06\u9759\u6001\u9a8c\u8bc1\u95ee\u9898\u8f6c\u5316\u4e3aSHACL\u7ea6\u675f\u7684\uff08\u4e0d\uff09\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u3002", "motivation": "\u7814\u7a76RDF\u56fe\u5728\u66f4\u65b0\u540e\u662f\u5426\u4ecd\u6ee1\u8db3SHACL\u89c4\u8303\uff0c\u4e3a\u52a8\u6001RDF\u56fe\u63d0\u4f9b\u9a8c\u8bc1\u57fa\u7840\u3002", "method": "\u63d0\u51faSHACL\u66f4\u65b0\u8bed\u8a00\uff0c\u4f7f\u7528\u56de\u5f52\u6280\u672f\u5c06\u66f4\u65b0\u52a8\u4f5c\u5d4c\u5165SHACL\u7ea6\u675f\uff0c\u5206\u6790\u8ba1\u7b97\u590d\u6742\u6027\u3002", "result": "\u8bc1\u660e\u9759\u6001\u9a8c\u8bc1\u95ee\u9898\u53ef\u8f6c\u5316\u4e3aSHACL\u7ea6\u675f\u7684\uff08\u4e0d\uff09\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u539f\u578b\u8fdb\u884c\u9a8c\u8bc1\u3002", "conclusion": "\u4e3a\u52a8\u6001RDF\u56fe\u7684SHACL\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2508.00452", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00452", "abs": "https://arxiv.org/abs/2508.00452", "authors": ["Chuan He", "Yongchao Liu", "Qiang Li", "Wenliang Zhong", "Chuntao Hong", "Xinwei Yao"], "title": "M^2VAE: Multi-Modal Multi-View Variational Autoencoder for Cold-start Item Recommendation", "comment": null, "summary": "Cold-start item recommendation is a significant challenge in recommendation\nsystems, particularly when new items are introduced without any historical\ninteraction data. While existing methods leverage multi-modal content to\nalleviate the cold-start issue, they often neglect the inherent multi-view\nstructure of modalities, the distinction between shared and modality-specific\nfeatures. In this paper, we propose Multi-Modal Multi-View Variational\nAutoEncoder (M^2VAE), a generative model that addresses the challenges of\nmodeling common and unique views in attribute and multi-modal features, as well\nas user preferences over single-typed item features. Specifically, we generate\ntype-specific latent variables for item IDs, categorical attributes, and image\nfeatures, and use Product-of-Experts (PoE) to derive a common representation. A\ndisentangled contrastive loss decouples the common view from unique views while\npreserving feature informativeness. To model user inclinations, we employ a\npreference-guided Mixture-of-Experts (MoE) to adaptively fuse representations.\nWe further incorporate co-occurrence signals via contrastive learning,\neliminating the need for pretraining. Extensive experiments on real-world\ndatasets validate the effectiveness of our approach.", "AI": {"tldr": "\u63d0\u51faM^2VAE\u6a21\u578b\uff0c\u89e3\u51b3\u51b7\u542f\u52a8\u63a8\u8350\u4e2d\u591a\u6a21\u6001\u591a\u89c6\u56fe\u7279\u5f81\u5efa\u6a21\u95ee\u9898\uff0c\u901a\u8fc7\u751f\u6210\u7c7b\u578b\u7279\u5b9a\u9690\u53d8\u91cf\u548c\u5bf9\u6bd4\u5b66\u4e60\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u51b7\u542f\u52a8\u7269\u54c1\u63a8\u8350\u7f3a\u4e4f\u5386\u53f2\u4ea4\u4e92\u6570\u636e\uff0c\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u591a\u6a21\u6001\u7684\u591a\u89c6\u56fe\u7ed3\u6784\u548c\u7279\u5f81\u533a\u5206\u3002", "method": "\u4f7f\u7528M^2VAE\u751f\u6210\u7c7b\u578b\u7279\u5b9a\u9690\u53d8\u91cf\uff0c\u7ed3\u5408PoE\u548cMoE\u5efa\u6a21\u5171\u540c\u4e0e\u72ec\u7279\u89c6\u56fe\uff0c\u5f15\u5165\u5bf9\u6bd4\u5b66\u4e60\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "conclusion": "M^2VAE\u80fd\u6709\u6548\u5efa\u6a21\u591a\u6a21\u6001\u591a\u89c6\u56fe\u7279\u5f81\uff0c\u63d0\u5347\u51b7\u542f\u52a8\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2508.00039", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00039", "abs": "https://arxiv.org/abs/2508.00039", "authors": ["Kaustav Chatterjee", "Joshua Q. Li", "Fatemeh Ansari", "Masud Rana Munna", "Kundan Parajulee", "Jared Schwennesen"], "title": "Hybrid LSTM-Transformer Models for Profiling Highway-Railway Grade Crossings", "comment": null, "summary": "Hump crossings, or high-profile Highway Railway Grade Crossings (HRGCs), pose\nsafety risks to highway vehicles due to potential hang-ups. These crossings\ntypically result from post-construction railway track maintenance activities or\nnon-compliance with design guidelines for HRGC vertical alignments.\nConventional methods for measuring HRGC profiles are costly, time-consuming,\ntraffic-disruptive, and present safety challenges. To address these issues,\nthis research employed advanced, cost-effective techniques and innovative\nmodeling approaches for HRGC profile measurement. A novel hybrid deep learning\nframework combining Long Short-Term Memory (LSTM) and Transformer architectures\nwas developed by utilizing instrumentation and ground truth data.\nInstrumentation data were gathered using a highway testing vehicle equipped\nwith Inertial Measurement Unit (IMU) and Global Positioning System (GPS)\nsensors, while ground truth data were obtained via an industrial-standard\nwalking profiler. Field data was collected at the Red Rock Railroad Corridor in\nOklahoma. Three advanced deep learning models Transformer-LSTM sequential\n(model 1), LSTM-Transformer sequential (model 2), and LSTM-Transformer parallel\n(model 3) were evaluated to identify the most efficient architecture. Models 2\nand 3 outperformed the others and were deployed to generate 2D/3D HRGC\nprofiles. The deep learning models demonstrated significant potential to\nenhance highway and railroad safety by enabling rapid and accurate assessment\nof HRGC hang-up susceptibility.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LSTM\u548cTransformer\u7684\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u6d4b\u91cfHRGC\u5256\u9762\uff0c\u63d0\u5347\u5b89\u5168\u6027\u3002", "motivation": "\u4f20\u7edfHRGC\u5256\u9762\u6d4b\u91cf\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u8017\u65f6\u957f\u4e14\u5b58\u5728\u5b89\u5168\u9690\u60a3\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5f00\u53d1\u4e86\u4e09\u79cd\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5229\u7528IMU\u548cGPS\u4f20\u611f\u5668\u6570\u636e\u4e0e\u5730\u9762\u771f\u5b9e\u6570\u636e\u5bf9\u6bd4\u3002", "result": "\u6a21\u578b2\u548c3\u8868\u73b0\u6700\u4f73\uff0c\u80fd\u5feb\u901f\u751f\u62102D/3D HRGC\u5256\u9762\uff0c\u663e\u8457\u63d0\u5347\u5b89\u5168\u6027\u8bc4\u4f30\u6548\u7387\u3002", "conclusion": "\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e3aHRGC\u5256\u9762\u6d4b\u91cf\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u6539\u5584\u516c\u8def\u548c\u94c1\u8def\u5b89\u5168\u3002"}}
{"id": "2508.00268", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.00268", "abs": "https://arxiv.org/abs/2508.00268", "authors": ["Jian Xiao", "Ji Wang", "Qimei Cui", "Yucang Yang", "Xingwang Li", "Dusit Niyato", "Chau Yuen"], "title": "Channel Estimation for Flexible Intelligent Metasurfaces: From Model-Based Approaches to Neural Operators", "comment": null, "summary": "Flexible intelligent metasurfaces (FIMs) offer a new solution for wireless\ncommunications by introducing morphological degrees of freedom, dynamically\nmorphing their three-dimensional shape to ensure multipath signals interfere\nconstructively. However, realizing the desired performance gains in FIM systems\nis critically dependent on acquiring accurate channel state information across\na continuous and high-dimensional deformation space. Therefore, this paper\ninvestigates this fundamental channel estimation problem for FIM assisted\nmillimeter-wave communication systems. First, we develop model-based frameworks\nthat structure the problem as either function approximation using interpolation\nand kernel methods or as a sparse signal recovery problem that leverages the\ninherent angular sparsity of millimeter-wave channels. To further advance the\nestimation capability beyond explicit assumptions in model-based channel\nestimation frameworks, we propose a deep learning-based framework using a\nFourier neural operator (FNO). By parameterizing a global convolution operator\nin the Fourier domain, we design an efficient FNO architecture to learn the\ncontinuous operator that maps FIM shapes to channel responses with\nmesh-independent properties. Furthermore, we exploit a hierarchical FNO (H-FNO)\narchitecture to efficiently capture the multi-scale features across a hierarchy\nof spatial resolutions. Numerical results demonstrate that the proposed H-FNO\nsignificantly outperforms the model-based benchmarks in estimation accuracy and\npilot efficiency. In particular, the interpretability analysis show that the\nproposed H-FNO learns an anisotropic spatial filter adapted to the physical\ngeometry of FIM and is capable of accurately reconstructing the non-linear\nchannel response across the continuous deformation space.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u67d4\u6027\u667a\u80fd\u8d85\u8868\u9762\uff08FIM\uff09\u8f85\u52a9\u6beb\u7c73\u6ce2\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u4fe1\u9053\u4f30\u8ba1\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6a21\u578b\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u5176\u4e2d\u5c42\u6b21\u5316\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\uff08H-FNO\uff09\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "FIM\u901a\u8fc7\u52a8\u6001\u53d8\u5f62\u5b9e\u73b0\u591a\u5f84\u4fe1\u53f7\u7684\u76f8\u957f\u5e72\u6d89\uff0c\u4f46\u5176\u6027\u80fd\u4f9d\u8d56\u4e8e\u9ad8\u7ef4\u53d8\u5f62\u7a7a\u95f4\u4e2d\u7684\u7cbe\u786e\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u83b7\u53d6\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u6846\u67b6\uff08\u63d2\u503c\u3001\u6838\u65b9\u6cd5\u548c\u7a00\u758f\u4fe1\u53f7\u6062\u590d\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff08FNO\u548cH-FNO\uff09\uff0c\u7528\u4e8e\u4fe1\u9053\u4f30\u8ba1\u3002", "result": "H-FNO\u5728\u4f30\u8ba1\u7cbe\u5ea6\u548c\u5bfc\u9891\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u6a21\u578b\u7684\u57fa\u51c6\u65b9\u6cd5\uff0c\u5e76\u80fd\u51c6\u786e\u91cd\u5efa\u975e\u7ebf\u6027\u4fe1\u9053\u54cd\u5e94\u3002", "conclusion": "H-FNO\u901a\u8fc7\u5b66\u4e60\u9002\u5e94FIM\u7269\u7406\u51e0\u4f55\u7684\u5404\u5411\u5f02\u6027\u7a7a\u95f4\u6ee4\u6ce2\u5668\uff0c\u4e3aFIM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u4fe1\u9053\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00349", "categories": ["cs.GT", "cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2508.00349", "abs": "https://arxiv.org/abs/2508.00349", "authors": ["Yuga Kanaya", "Kenjiro Takazawa"], "title": "On the Equivalence of the Graph-Structural and Optimization-Based Characterizations of Popular Matchings", "comment": null, "summary": "Popular matchings provide a model of matching under preferences in which a\nsolution corresponds to a Condorcet winner in voting systems. In a bipartite\ngraph in which the vertices have preferences over their neighbours, a matching\nis defined to be popular if it does not lose in a majority vote against any\nmatching. In this paper, we study the following three primary problems: only\nthe vertices on one side have preferences; a generalization of this problem\nallowing ties in the preferences; and the vertices on both sides have\npreferences. A principal issue in the algorithmic aspects of popular matchings\nis how to determine the popularity of a matching, because it requires\nexponential time if the definition is simply applied. In the literature, we\nhave the following two types of characterizations: a graph-structural\ncharacterization; and an optimization-based characterization described by\nmaximum-weight matchings. The graph-structural characterizations are\nspecifically designed for each problem and provide a combinatorial structure of\nthe popular matchings. The optimization-based characterizations work in the\nsame manner for all problems, while they do not reveal the structure of the\npopular matchings. A main contribution of this paper is to provide a direct\nconnection of the above two types of characterizations for all of the three\nproblems. Specifically, we prove that each characterization can be derived from\nthe other, without relying on the fact that they characterize popular\nmatchings. Our proofs offer a comprehensive understanding of the equivalence of\nthe two types of characterizations, and suggest a new interpretation of the\ngraph-structural characterization in terms of the dual optimal solution for the\nmaximum-weight matching problem.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e09\u79cd\u6d41\u884c\u5339\u914d\u95ee\u9898\uff0c\u901a\u8fc7\u8fde\u63a5\u56fe\u7ed3\u6784\u7279\u5f81\u548c\u4f18\u5316\u7279\u5f81\uff0c\u63d0\u4f9b\u4e86\u5bf9\u4e24\u8005\u7b49\u4ef7\u6027\u7684\u5168\u9762\u7406\u89e3\u3002", "motivation": "\u7814\u7a76\u6d41\u884c\u5339\u914d\u95ee\u9898\uff0c\u89e3\u51b3\u5982\u4f55\u9ad8\u6548\u786e\u5b9a\u5339\u914d\u7684\u6d41\u884c\u6027\uff0c\u907f\u514d\u76f4\u63a5\u5e94\u7528\u5b9a\u4e49\u6240\u9700\u7684\u6307\u6570\u65f6\u95f4\u3002", "method": "\u901a\u8fc7\u56fe\u7ed3\u6784\u7279\u5f81\u548c\u57fa\u4e8e\u4f18\u5316\u7684\u7279\u5f81\uff08\u6700\u5927\u6743\u91cd\u5339\u914d\uff09\u5bf9\u4e09\u79cd\u6d41\u884c\u5339\u914d\u95ee\u9898\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u8bc1\u660e\u4e24\u8005\u4e4b\u95f4\u7684\u76f4\u63a5\u8054\u7cfb\u3002", "result": "\u8bc1\u660e\u4e86\u4e24\u79cd\u7279\u5f81\u53ef\u4ee5\u76f8\u4e92\u63a8\u5bfc\uff0c\u63d0\u4f9b\u4e86\u5bf9\u6d41\u884c\u5339\u914d\u7ed3\u6784\u7684\u6df1\u5165\u7406\u89e3\uff0c\u5e76\u63ed\u793a\u4e86\u56fe\u7ed3\u6784\u7279\u5f81\u4e0e\u6700\u5927\u6743\u91cd\u5339\u914d\u5bf9\u5076\u89e3\u7684\u65b0\u89e3\u91ca\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u8fde\u63a5\u4e24\u79cd\u7279\u5f81\uff0c\u4e3a\u6d41\u884c\u5339\u914d\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u7406\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u89e3\u91ca\u89c6\u89d2\u3002"}}
{"id": "2508.00138", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00138", "abs": "https://arxiv.org/abs/2508.00138", "authors": ["Rashid Mushkani", "Hugo Berard", "Toumadher Ammar", "Cassandre Chatonnier", "Shin Koseki"], "title": "Co-Producing AI: Toward an Augmented, Participatory Lifecycle", "comment": "Eighth AAAI/ACM Conference on AI, Ethics, and Society 2025", "summary": "Despite efforts to mitigate the inherent risks and biases of artificial\nintelligence (AI) algorithms, these algorithms can disproportionately impact\nculturally marginalized groups. A range of approaches has been proposed to\naddress or reduce these risks, including the development of ethical guidelines\nand principles for responsible AI, as well as technical solutions that promote\nalgorithmic fairness. Drawing on design justice, expansive learning theory, and\nrecent empirical work on participatory AI, we argue that mitigating these harms\nrequires a fundamental re-architecture of the AI production pipeline. This\nre-design should center co-production, diversity, equity, inclusion (DEI), and\nmultidisciplinary collaboration. We introduce an augmented AI lifecycle\nconsisting of five interconnected phases: co-framing, co-design,\nco-implementation, co-deployment, and co-maintenance. The lifecycle is informed\nby four multidisciplinary workshops and grounded in themes of distributed\nauthority and iterative knowledge exchange. Finally, we relate the proposed\nlifecycle to several leading ethical frameworks and outline key research\nquestions that remain for scaling participatory governance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bbe\u8ba1\u6b63\u4e49\u548c\u53c2\u4e0e\u5f0fAI\u7684AI\u751f\u547d\u5468\u671f\u91cd\u6784\u65b9\u6cd5\uff0c\u5f3a\u8c03\u5171\u540c\u751f\u4ea7\u3001\u591a\u6837\u6027\u548c\u591a\u5b66\u79d1\u5408\u4f5c\uff0c\u4ee5\u51cf\u5c11AI\u5bf9\u8fb9\u7f18\u5316\u7fa4\u4f53\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "motivation": "AI\u7b97\u6cd5\u53ef\u80fd\u5bf9\u6587\u5316\u8fb9\u7f18\u5316\u7fa4\u4f53\u4ea7\u751f\u4e0d\u6210\u6bd4\u4f8b\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u4f26\u7406\u6307\u5357\u548c\u6280\u672f\u89e3\u51b3\u65b9\u6848\uff09\u672a\u80fd\u5b8c\u5168\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u589e\u5f3a\u7684AI\u751f\u547d\u5468\u671f\uff0c\u5305\u62ec\u4e94\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u9636\u6bb5\uff1a\u5171\u540c\u6846\u67b6\u3001\u5171\u540c\u8bbe\u8ba1\u3001\u5171\u540c\u5b9e\u65bd\u3001\u5171\u540c\u90e8\u7f72\u548c\u5171\u540c\u7ef4\u62a4\uff0c\u57fa\u4e8e\u591a\u5b66\u79d1\u7814\u8ba8\u4f1a\u548c\u5206\u5e03\u5f0f\u6743\u5a01\u7406\u5ff5\u3002", "result": "\u65b0\u751f\u547d\u5468\u671f\u7ed3\u5408\u4e86\u4f26\u7406\u6846\u67b6\uff0c\u5e76\u63d0\u51fa\u4e86\u6269\u5c55\u53c2\u4e0e\u5f0f\u6cbb\u7406\u7684\u5173\u952e\u7814\u7a76\u95ee\u9898\u3002", "conclusion": "\u91cd\u6784AI\u751f\u4ea7\u6d41\u7a0b\u4ee5\u4e2d\u5fc3\u5316\u5171\u540c\u751f\u4ea7\u548c\u591a\u6837\u6027\uff0c\u662f\u51cf\u5c11AI\u5bf9\u8fb9\u7f18\u5316\u7fa4\u4f53\u5371\u5bb3\u7684\u5173\u952e\u3002"}}
{"id": "2508.00570", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.00570", "abs": "https://arxiv.org/abs/2508.00570", "authors": ["Gyuseok Lee", "Yaokun Liu", "Yifan Liu", "Susik Yoon", "Dong Wang", "SeongKu Kang"], "title": "Session-Based Recommendation with Validated and Enriched LLM Intents", "comment": null, "summary": "Session-based recommendation (SBR) aims to predict the next item for an\nanonymous user in a timely manner. However, SBR suffers from data sparsity due\nto the short and anonymous nature of sessions. Recently, an emerging line of\nwork has explored inferring the underlying user intents of a session using\nlarge language models (LLMs), with the generated intents serving as auxiliary\ntraining signals to enhance SBR models. Despite its promise, this approach\nfaces three key challenges: validating intent quality, incorporating\nsession-level multi-intents, and complementing inevitable LLM failure cases. In\nthis paper, we propose VELI4SBR, a two-stage framework that leverages Validated\nand Enriched LLM-generated Intents for SBR. In the first stage, we generate\nhigh-quality intents using a predict-and-correct loop that validates the\ninformativeness of LLM-generated intents with a global intent pool to constrain\nthe LLM's output space and reduce hallucination. In the second stage, we\nenhance the SBR model using the generated intents through a lightweight\nmulti-intent prediction and fusion mechanism. Furthermore, we introduce a\ntraining strategy that compensates for LLM failures by inferring intents from\ninter-session behavioral similarities. Extensive experiments show that VELI4SBR\noutperforms state-of-the-art baselines while improving explainability.", "AI": {"tldr": "VELI4SBR\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u9a8c\u8bc1\u548c\u4e30\u5bccLLM\u751f\u6210\u7684\u610f\u56fe\u6765\u6539\u8fdb\u57fa\u4e8e\u4f1a\u8bdd\u7684\u63a8\u8350\uff08SBR\uff09\u3002", "motivation": "\u89e3\u51b3SBR\u4e2d\u6570\u636e\u7a00\u758f\u6027\u548cLLM\u751f\u6210\u610f\u56fe\u7684\u8d28\u91cf\u3001\u591a\u610f\u56fe\u6574\u5408\u53caLLM\u5931\u8d25\u8865\u507f\u95ee\u9898\u3002", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u901a\u8fc7\u9884\u6d4b-\u6821\u6b63\u5faa\u73af\u751f\u6210\u9ad8\u8d28\u91cf\u610f\u56fe\uff1b2) \u901a\u8fc7\u591a\u610f\u56fe\u9884\u6d4b\u548c\u878d\u5408\u673a\u5236\u589e\u5f3aSBR\u6a21\u578b\u3002", "result": "VELI4SBR\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5e76\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "VELI4SBR\u6709\u6548\u89e3\u51b3\u4e86SBR\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2508.00040", "categories": ["cs.LG", "math.PR", "stat.AP", "stat.ML", "60J20, 68T07"], "pdf": "https://arxiv.org/pdf/2508.00040", "abs": "https://arxiv.org/abs/2508.00040", "authors": ["Abhinav Das", "Stephan Schl\u00fcter"], "title": "Regime-Aware Conditional Neural Processes with Multi-Criteria Decision Support for Operational Electricity Price Forecasting", "comment": null, "summary": "This work integrates Bayesian regime detection with conditional neural\nprocesses for 24-hour electricity price prediction in the German market. Our\nmethodology integrates regime detection using a disentangled sticky\nhierarchical Dirichlet process hidden Markov model (DS-HDP-HMM) applied to\ndaily electricity prices. Each identified regime is subsequently modeled by an\nindependent conditional neural process (CNP), trained to learn localized\nmappings from input contexts to 24-dimensional hourly price trajectories, with\nfinal predictions computed as regime-weighted mixtures of these CNP outputs. We\nrigorously evaluate R-NP against deep neural networks (DNN) and Lasso estimated\nauto-regressive (LEAR) models by integrating their forecasts into diverse\nbattery storage optimization frameworks, including price arbitrage, risk\nmanagement, grid services, and cost minimization. This operational utility\nassessment revealed complex performance trade-offs: LEAR often yielded superior\nabsolute profits or lower costs, while DNN showed exceptional optimality in\nspecific cost-minimization contexts. Recognizing that raw prediction accuracy\ndoesn't always translate to optimal operational outcomes, we employed TOPSIS as\na comprehensive multi-criteria evaluation layer. Our TOPSIS analysis identified\nLEAR as the top-ranked model for 2021, but crucially, our proposed R-NP model\nemerged as the most balanced and preferred solution for 2021, 2022 and 2023.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7ed3\u5408\u8d1d\u53f6\u65af\u673a\u5236\u68c0\u6d4b\u4e0e\u6761\u4ef6\u795e\u7ecf\u8fc7\u7a0b\uff0c\u7528\u4e8e\u5fb7\u56fd\u5e02\u573a24\u5c0f\u65f6\u7535\u4ef7\u9884\u6d4b\uff0c\u63d0\u51faR-NP\u6a21\u578b\uff0c\u5e76\u5728\u591a\u573a\u666f\u4e0b\u8bc4\u4f30\u5176\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u7535\u4ef7\u9884\u6d4b\u4e2d\u56e0\u5e02\u573a\u673a\u5236\u53d8\u5316\u5bfc\u81f4\u7684\u9884\u6d4b\u4e0d\u51c6\u786e\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u9884\u6d4b\u6a21\u578b\u5728\u5b9e\u9645\u8fd0\u8425\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u4f7f\u7528DS-HDP-HMM\u8fdb\u884c\u673a\u5236\u68c0\u6d4b\uff0c\u6bcf\u4e2a\u673a\u5236\u7531\u72ec\u7acb\u7684CNP\u5efa\u6a21\uff0c\u6700\u7ec8\u9884\u6d4b\u4e3a\u673a\u5236\u52a0\u6743\u7684CNP\u8f93\u51fa\u3002", "result": "R-NP\u5728\u591a\u573a\u666f\u8bc4\u4f30\u4e2d\u8868\u73b0\u5747\u8861\uff0c\u4f18\u4e8eDNN\u548cLEAR\u6a21\u578b\uff0c\u5c24\u5176\u57282021-2023\u5e74\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "R-NP\u6a21\u578b\u5728\u7535\u4ef7\u9884\u6d4b\u4e2d\u5177\u6709\u5e73\u8861\u6027\u548c\u5b9e\u7528\u6027\uff0c\u662f\u7efc\u5408\u6027\u80fd\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00379", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.00379", "abs": "https://arxiv.org/abs/2508.00379", "authors": ["Yuan Fang", "Xianxin Song", "Huazhou Hou", "Ziguo Zhong", "Xianghao Yu", "Jie Xu", "Yongming Huang"], "title": "Active IRS-Enabled Integrated Sensing and Communications with Extended Targets", "comment": null, "summary": "This paper studies the active intelligent reflecting surface (IRS)-enabled\nintegrated sensing and communications (ISAC), in which an active IRS is\ndeployed to assist the base station (BS) in serving multiple communication\nusers (CUs) and simultaneously sensing an \\emph{extended} target at the\nnon-line-of-sight (NLoS) area of the BS. The active IRS has the capability of\namplifying the reflected signals so as to overcome significant reflection path\nloss in NLoS communication and sensing. In particular, we derive the sensing\nCram\\'{e}r-Rao bound (CRB) for estimating the target response matrix.\nAccordingly, we jointly optimize the transmit beamforming at the BS and the\nreflective beamforming at the active IRS to minimize the sensing CRB, subject\nto the signal-to-interference-plus-noise ratio (SINR) requirements at the CUs,\nthe transmit power budgets at the BS and active IRS, as well as the power\namplification gain constraints at the active IRS. The CRB minimization problem\nis highly non-convex and thus difficult to solve in general. To address this\nchallenge, we first focus on two specified conditions by considering the\nsensing-only scenario via ignoring the SINR constraints for communications, for\nwhich the closed-form optimal transmit beamforming is derived. Then, we propose\ntwo efficient alternating optimization (AO)-based algorithms to obtain\nhigh-quality solutions for the general ISAC scenarios. Next, we analyze the\ninherent relationship between the power scaling at the BS and the amplification\nscaling at the active IRS. It is shown that the active IRS always amplifies the\nsignal using the maximum amplification gain under practical system settings.\nFinally, numerical results are provided to verify the effectiveness of the\nproposed AO-based algorithms and the benefits of active IRS-enabled ISAC\ncompared to its passive IRSs counterparts.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e3b\u52a8\u667a\u80fd\u53cd\u5c04\u9762\uff08IRS\uff09\u652f\u6301\u7684\u96c6\u6210\u4f20\u611f\u4e0e\u901a\u4fe1\uff08ISAC\uff09\uff0c\u901a\u8fc7\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u6700\u5c0f\u5316\u4f20\u611fCRB\uff0c\u540c\u65f6\u6ee1\u8db3\u901a\u4fe1\u7528\u6237\u7684SINR\u9700\u6c42\u3002", "motivation": "\u89e3\u51b3\u975e\u89c6\u8ddd\uff08NLoS\uff09\u533a\u57df\u4e2d\u901a\u4fe1\u548c\u4f20\u611f\u7684\u8def\u5f84\u635f\u8017\u95ee\u9898\uff0c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u8054\u5408\u4f18\u5316\u57fa\u7ad9\uff08BS\uff09\u7684\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\u548c\u4e3b\u52a8IRS\u7684\u53cd\u5c04\u6ce2\u675f\u6210\u5f62\uff0c\u63d0\u51fa\u4ea4\u66ff\u4f18\u5316\uff08AO\uff09\u7b97\u6cd5\u3002", "result": "\u4e3b\u52a8IRS\u5728\u5b9e\u7528\u7cfb\u7edf\u8bbe\u7f6e\u4e0b\u603b\u662f\u4f7f\u7528\u6700\u5927\u653e\u5927\u589e\u76ca\uff0c\u9a8c\u8bc1\u4e86AO\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4e3b\u52a8IRS\u652f\u6301\u7684ISAC\u4f18\u4e8e\u88ab\u52a8IRS\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2508.00811", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2508.00811", "abs": "https://arxiv.org/abs/2508.00811", "authors": ["Matthew M. Casey", "Edith Elkind"], "title": "Justified Representation: From Hare to Droop", "comment": null, "summary": "The study of proportionality in multiwinner voting with approval ballots has\nreceived much attention in recent years. Typically, proportionality is captured\nby variants of the Justified Representation axiom, which say that cohesive\ngroups of at least $\\ell\\cdot\\frac{n}{k}$ voters (where $n$ is the total number\nof voters and $k$ is the desired number of winners) deserve $\\ell$\nrepresentatives. The quantity $\\frac{n}{k}$ is known as the Hare quota in the\nsocial choice literature. Another -- more demanding -- choice of quota is the\nDroop quota, defined as $\\lfloor\\frac{n}{k+1}\\rfloor+1$. This quota is often\nused in multiwinner voting with ranked ballots: in algorithms such as Single\nTransferable Voting, and in proportionality axioms, such as Droop's\nProportionality Criterion. A few authors have considered it in the context of\napproval ballots, but the existing analysis is far from comprehensive. The\ncontribution of our work is a systematic study of JR-style axioms (and voting\nrules that satisfy them) defined using the Droop quota instead of the Hare\nquota. For each of the standard JR axioms (namely, JR, PJR, EJR, FPJR, FJR,\nPJR+ and EJR+), we identify a voting rule that satisfies the Droop version of\nthis axiom. In some cases, it suffices to consider known rules (modifying the\ncorresponding Hare proof, sometimes quite substantially), and in other cases it\nis necessary to modify the rules from prior work. Each axiom is more difficult\nto satisfy when defined using the Droop quota, so our results expand the\nfrontier of satisfiable proportionality axioms. We complement our theoretical\nresults with an experimental study, showing that for many probabilistic models\nof voter approvals, Droop JR/EJR+ are considerably more demanding than standard\n(Hare) JR/EJR+.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u57fa\u4e8eDroop\u914d\u989d\u7684\u591a\u8d62\u5bb6\u6295\u7968\u4e2d\u7684\u6bd4\u4f8b\u6027\u516c\u7406\uff0c\u63d0\u51fa\u4e86\u6ee1\u8db3Droop\u7248\u672cJR\u516c\u7406\u7684\u6295\u7968\u89c4\u5219\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4e25\u683c\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8Hare\u914d\u989d\u4e0b\u7684\u6bd4\u4f8b\u6027\u516c\u7406\uff0c\u800c\u5bf9\u66f4\u4e25\u683c\u7684Droop\u914d\u989d\u5206\u6790\u4e0d\u8db3\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u4fee\u6539\u5df2\u77e5\u6295\u7968\u89c4\u5219\u6216\u8bbe\u8ba1\u65b0\u89c4\u5219\uff0c\u9a8c\u8bc1\u5176\u6ee1\u8db3Droop\u7248\u672c\u7684JR\u516c\u7406\uff08\u5982JR\u3001PJR\u3001EJR\u7b49\uff09\u3002", "result": "\u6210\u529f\u4e3a\u6bcf\u79cdDroop\u7248\u672cJR\u516c\u7406\u627e\u5230\u6ee1\u8db3\u7684\u6295\u7968\u89c4\u5219\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660eDroop\u914d\u989d\u6bd4Hare\u914d\u989d\u66f4\u4e25\u683c\u3002", "conclusion": "\u672c\u6587\u6269\u5c55\u4e86\u53ef\u6ee1\u8db3\u6bd4\u4f8b\u6027\u516c\u7406\u7684\u8303\u56f4\uff0c\u4e3a\u591a\u8d62\u5bb6\u6295\u7968\u63d0\u4f9b\u4e86\u66f4\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2508.00143", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.00143", "abs": "https://arxiv.org/abs/2508.00143", "authors": ["Danielle R. Thomas", "Conrad Borchers", "Kenneth R. Koedinger"], "title": "Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation", "comment": "Accepted for presentation at NCME AIME-Con 2025", "summary": "Humans can be notoriously imperfect evaluators. They are often biased,\nunreliable, and unfit to define \"ground truth.\" Yet, given the surging need to\nproduce large amounts of training data in educational applications using AI,\ntraditional inter-rater reliability (IRR) metrics like Cohen's kappa remain\ncentral to validating labeled data. IRR remains a cornerstone of many machine\nlearning pipelines for educational data. Take, for example, the classification\nof tutors' moves in dialogues or labeling open responses in machine-graded\nassessments. This position paper argues that overreliance on human IRR as a\ngatekeeper for annotation quality hampers progress in classifying data in ways\nthat are valid and predictive in relation to improving learning. To address\nthis issue, we highlight five examples of complementary evaluation methods,\nsuch as multi-label annotation schemes, expert-based approaches, and\nclose-the-loop validity. We argue that these approaches are in a better\nposition to produce training data and subsequent models that produce improved\nstudent learning and more actionable insights than IRR approaches alone. We\nalso emphasize the importance of external validity, for example, by\nestablishing a procedure of validating tutor moves and demonstrating that it\nworks across many categories of tutor actions (e.g., providing hints). We call\non the field to rethink annotation quality and ground truth--prioritizing\nvalidity and educational impact over consensus alone.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u8fc7\u5ea6\u4f9d\u8d56\u4eba\u7c7b\u8bc4\u4f30\u8005\u95f4\u4e00\u81f4\u6027\uff08IRR\uff09\u4f1a\u963b\u788d\u6559\u80b2\u6570\u636e\u5206\u7c7b\u7684\u8fdb\u5c55\uff0c\u63d0\u51fa\u4e94\u79cd\u8865\u5145\u8bc4\u4f30\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u6570\u636e\u8d28\u91cf\u548c\u6a21\u578b\u6548\u679c\u3002", "motivation": "\u4eba\u7c7b\u8bc4\u4f30\u8005\u5b58\u5728\u504f\u89c1\u548c\u4e0d\u53ef\u9760\u6027\uff0c\u4f20\u7edfIRR\u6307\u6807\u4e0d\u8db3\u4ee5\u786e\u4fdd\u6807\u6ce8\u6570\u636e\u7684\u6709\u6548\u6027\uff0c\u5c24\u5176\u662f\u5728\u6559\u80b2AI\u9886\u57df\u3002", "method": "\u63d0\u51fa\u4e94\u79cd\u8865\u5145\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5305\u62ec\u591a\u6807\u7b7e\u6807\u6ce8\u65b9\u6848\u3001\u4e13\u5bb6\u8bc4\u4f30\u548c\u95ed\u73af\u9a8c\u8bc1\u7b49\u3002", "result": "\u8fd9\u4e9b\u65b9\u6cd5\u80fd\u751f\u6210\u66f4\u6709\u6548\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u63d0\u5347\u6a21\u578b\u5bf9\u5b66\u751f\u5b66\u4e60\u7684\u4fc3\u8fdb\u4f5c\u7528\u3002", "conclusion": "\u547c\u5401\u91cd\u65b0\u5b9a\u4e49\u6807\u6ce8\u8d28\u91cf\u548c\u771f\u5b9e\u6807\u51c6\uff0c\u4f18\u5148\u8003\u8651\u6709\u6548\u6027\u548c\u6559\u80b2\u5f71\u54cd\uff0c\u800c\u975e\u4ec5\u4f9d\u8d56\u5171\u8bc6\u3002"}}
{"id": "2508.00710", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2508.00710", "abs": "https://arxiv.org/abs/2508.00710", "authors": ["Ngozichukwuka Onah", "Nadine Steinmetz", "Hani Al-Sayeh", "Kai-Uwe Sattler"], "title": "Experimental Evaluation of Dynamic Topic Modeling Algorithms", "comment": null, "summary": "The amount of text generated daily on social media is gigantic and analyzing\nthis text is useful for many purposes. To understand what lies beneath a huge\namount of text, we need dependable and effective computing techniques from\nself-powered topic models. Nevertheless, there are currently relatively few\nthorough quantitative comparisons between these models. In this study, we\ncompare these models and propose an assessment metric that documents how the\ntopics change in time.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u81ea\u9a71\u52a8\u4e3b\u9898\u6a21\u578b\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u6307\u6807\uff0c\u7528\u4e8e\u8bb0\u5f55\u4e3b\u9898\u968f\u65f6\u95f4\u7684\u53d8\u5316\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u6bcf\u5929\u751f\u6210\u7684\u6587\u672c\u91cf\u5de8\u5927\uff0c\u5206\u6790\u8fd9\u4e9b\u6587\u672c\u5bf9\u8bb8\u591a\u7528\u9014\u975e\u5e38\u6709\u7528\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u6a21\u578b\u7684\u5168\u9762\u5b9a\u91cf\u6bd4\u8f83\u3002", "method": "\u6bd4\u8f83\u4e86\u81ea\u9a71\u52a8\u4e3b\u9898\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u8bb0\u5f55\u4e3b\u9898\u968f\u65f6\u95f4\u53d8\u5316\u7684\u8bc4\u4f30\u6307\u6807\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u81ea\u9a71\u52a8\u4e3b\u9898\u6a21\u578b\u5b9a\u91cf\u6bd4\u8f83\u7684\u7a7a\u767d\uff0c\u5e76\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2508.00041", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.00041", "abs": "https://arxiv.org/abs/2508.00041", "authors": ["Yebo Wu", "Jingguang Li", "Zhijiang Guo", "Li Li"], "title": "Learning Like Humans: Resource-Efficient Federated Fine-Tuning through Cognitive Developmental Stages", "comment": null, "summary": "Federated fine-tuning enables Large Language Models (LLMs) to adapt to\ndownstream tasks while preserving data privacy, but its resource-intensive\nnature limits deployment on edge devices. In this paper, we introduce\nDevelopmental Federated Tuning (DevFT), a resource-efficient approach inspired\nby cognitive development that progressively builds a powerful LLM from a\ncompact foundation. DevFT decomposes the fine-tuning process into developmental\nstages, each optimizing submodels with increasing parameter capacity. Knowledge\nfrom earlier stages transfers to subsequent submodels, providing optimized\ninitialization parameters that prevent convergence to local minima and\naccelerate training. This paradigm mirrors human learning, gradually\nconstructing comprehensive knowledge structure while refining existing skills.\nTo efficiently build stage-specific submodels, DevFT introduces\ndeconfliction-guided layer grouping and differential-based layer fusion to\ndistill essential information and construct representative layers. Evaluations\nacross multiple benchmarks demonstrate that DevFT significantly outperforms\nstate-of-the-art methods, achieving up to 4.59$\\times$ faster convergence,\n10.67$\\times$ reduction in communication overhead, and 9.07% average\nperformance improvement, while maintaining compatibility with existing\napproaches.", "AI": {"tldr": "DevFT\u662f\u4e00\u79cd\u8d44\u6e90\u9ad8\u6548\u7684\u8054\u90a6\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u9636\u6bb5\u6784\u5efaLLM\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5fae\u8c03\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8d44\u6e90\u6d88\u8017\u9ad8\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u3002", "method": "\u5206\u9636\u6bb5\u5fae\u8c03\uff0c\u9010\u6b65\u589e\u52a0\u6a21\u578b\u53c2\u6570\u5bb9\u91cf\uff0c\u5e76\u901a\u8fc7\u77e5\u8bc6\u8f6c\u79fb\u4f18\u5316\u521d\u59cb\u5316\u53c2\u6570\u3002", "result": "DevFT\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u6536\u655b\u901f\u5ea6\u63d0\u53474.59\u500d\uff0c\u901a\u4fe1\u5f00\u9500\u51cf\u5c1110.67\u500d\uff0c\u6027\u80fd\u5e73\u5747\u63d0\u53479.07%\u3002", "conclusion": "DevFT\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u517c\u5bb9\u73b0\u6709\u65b9\u6cd5\u7684\u8054\u90a6\u5fae\u8c03\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00458", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.00458", "abs": "https://arxiv.org/abs/2508.00458", "authors": ["Jiuyu Liu", "Yi Ma", "Rahim Tafazolli"], "title": "LO-Aware Adaptive Modulation for Rydberg Atomic Receivers", "comment": "Accepted by IEEE GLOBECOM 2025", "summary": "Rydberg atomic (RA) receivers represent a revolutionary quantum technology\nfor wireless communications, offering unprecedented sensitivity beyond\nconventional radio frequency (RF) antennas. However, these receivers detect\nonly signal amplitude, losing critical phase information. While reference\nsignals generated by a local oscillator (LO) can assist in phase recovery,\nexisting modulation schemes designed for conventional systems perform poorly\nwith this quantum detection mechanism. This paper introduces a breakthrough\nLO-aware adaptive modulation (LOAM) scheme specifically developed for RA\nreceivers that dynamically adapts to complex fading channel coefficients. LOAM\nmaximizes the minimum amplitude difference between constellation points,\nensuring optimal detection performance. The innovation employs an adaptive\nco-linear constellation architecture aligned with the combined phase of\nreference signal and channel coefficient. For strong reference signals, LOAM\ngenerates symmetric constellation points centered at origin; for weak signals,\nit adopts non-symmetric distributions. The paper mathematically derives the\nthreshold governing these operational regimes. Simulation results reveal the\ntransformative impact of LOAM, demonstrating performance gains exceeding 45 dB\nover conventional modulation schemes, including quadrature amplitude modulation\n(QAM), phase-shift keying (PSK), and pulse-amplitude modulation (PAM).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9Rydberg\u539f\u5b50\u63a5\u6536\u5668\u7684LO\u611f\u77e5\u81ea\u9002\u5e94\u8c03\u5236\u65b9\u6848\uff08LOAM\uff09\uff0c\u901a\u8fc7\u52a8\u6001\u9002\u5e94\u590d\u6742\u8870\u843d\u4fe1\u9053\u7cfb\u6570\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "Rydberg\u539f\u5b50\u63a5\u6536\u5668\u5728\u65e0\u7ebf\u901a\u4fe1\u4e2d\u5177\u6709\u9769\u547d\u6027\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u8c03\u5236\u65b9\u6848\u65e0\u6cd5\u6709\u6548\u652f\u6301\u5176\u91cf\u5b50\u68c0\u6d4b\u673a\u5236\uff0c\u5bfc\u81f4\u6027\u80fd\u53d7\u9650\u3002", "method": "LOAM\u65b9\u6848\u901a\u8fc7\u81ea\u9002\u5e94\u5171\u7ebf\u661f\u5ea7\u67b6\u6784\uff0c\u6839\u636e\u53c2\u8003\u4fe1\u53f7\u548c\u4fe1\u9053\u7cfb\u6570\u7684\u76f8\u4f4d\u52a8\u6001\u8c03\u6574\u661f\u5ea7\u70b9\u5206\u5e03\uff0c\u6700\u5927\u5316\u6700\u5c0f\u632f\u5e45\u5dee\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0cLOAM\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u8c03\u5236\u65b9\u6848\uff08\u5982QAM\u3001PSK\u3001PAM\uff09\uff0c\u589e\u76ca\u8d85\u8fc745 dB\u3002", "conclusion": "LOAM\u4e3aRydberg\u539f\u5b50\u63a5\u6536\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u8c03\u5236\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u901a\u4fe1\u6027\u80fd\u3002"}}
{"id": "2508.00159", "categories": ["cs.AI", "cs.CY", "cs.LG", "econ.TH", "math.OC", "68Txx", "I.2"], "pdf": "https://arxiv.org/pdf/2508.00159", "abs": "https://arxiv.org/abs/2508.00159", "authors": ["Jobst Heitzig", "Ram Potham"], "title": "Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power", "comment": null, "summary": "Power is a key concept in AI safety: power-seeking as an instrumental goal,\nsudden or gradual disempowerment of humans, power balance in human-AI\ninteraction and international AI governance. At the same time, power as the\nability to pursue diverse goals is essential for wellbeing.\n  This paper explores the idea of promoting both safety and wellbeing by\nforcing AI agents explicitly to empower humans and to manage the power balance\nbetween humans and AI agents in a desirable way. Using a principled, partially\naxiomatic approach, we design a parametrizable and decomposable objective\nfunction that represents an inequality- and risk-averse long-term aggregate of\nhuman power. It takes into account humans' bounded rationality and social\nnorms, and, crucially, considers a wide variety of possible human goals.\n  We derive algorithms for computing that metric by backward induction or\napproximating it via a form of multi-agent reinforcement learning from a given\nworld model. We exemplify the consequences of (softly) maximizing this metric\nin a variety of paradigmatic situations and describe what instrumental\nsub-goals it will likely imply. Our cautious assessment is that softly\nmaximizing suitable aggregate metrics of human power might constitute a\nbeneficial objective for agentic AI systems that is safer than direct\nutility-based objectives.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u660e\u786e\u8981\u6c42AI\u8d4b\u80fd\u4eba\u7c7b\u5e76\u7ba1\u7406\u4eba\u673a\u6743\u529b\u5e73\u8861\uff0c\u4ee5\u4fc3\u8fdb\u5b89\u5168\u548c\u798f\u7949\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u53c2\u6570\u5316\u3001\u53ef\u5206\u89e3\u7684\u76ee\u6807\u51fd\u6570\uff0c\u5e76\u901a\u8fc7\u7b97\u6cd5\u8ba1\u7b97\u5176\u5ea6\u91cf\u3002", "motivation": "\u6743\u529b\u662fAI\u5b89\u5168\u4e2d\u7684\u5173\u952e\u6982\u5ff5\uff0c\u6d89\u53ca\u6743\u529b\u5bfb\u6c42\u3001\u4eba\u7c7b\u6743\u529b\u4e27\u5931\u53ca\u6743\u529b\u5e73\u8861\u95ee\u9898\u3002\u540c\u65f6\uff0c\u6743\u529b\u4f5c\u4e3a\u8ffd\u6c42\u591a\u6837\u76ee\u6807\u7684\u80fd\u529b\u5bf9\u798f\u7949\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u90e8\u5206\u516c\u7406\u5316\u65b9\u6cd5\u8bbe\u8ba1\u76ee\u6807\u51fd\u6570\uff0c\u8003\u8651\u4eba\u7c7b\u6709\u9650\u7406\u6027\u548c\u793e\u4f1a\u89c4\u8303\uff0c\u901a\u8fc7\u9006\u5411\u5f52\u7eb3\u6216\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8ba1\u7b97\u8be5\u5ea6\u91cf\u3002", "result": "\u5728\u591a\u79cd\u5178\u578b\u60c5\u5883\u4e2d\u5c55\u793a\u4e86\u6700\u5927\u5316\u8be5\u5ea6\u91cf\u7684\u540e\u679c\u53ca\u5176\u6f5c\u5728\u5b50\u76ee\u6807\uff0c\u8868\u660e\u5176\u53ef\u80fd\u6bd4\u76f4\u63a5\u57fa\u4e8e\u6548\u7528\u7684\u76ee\u6807\u66f4\u5b89\u5168\u3002", "conclusion": "\u8f6f\u6027\u6700\u5927\u5316\u4eba\u7c7b\u6743\u529b\u805a\u5408\u6307\u6807\u53ef\u80fd\u662fAI\u7cfb\u7edf\u7684\u6709\u76ca\u76ee\u6807\uff0c\u6bd4\u76f4\u63a5\u6548\u7528\u76ee\u6807\u66f4\u5b89\u5168\u3002"}}
{"id": "2508.00751", "categories": ["cs.IR", "cs.AI", "H.3; G.3"], "pdf": "https://arxiv.org/pdf/2508.00751", "abs": "https://arxiv.org/abs/2508.00751", "authors": ["Qing Zhang", "Alex Deng", "Michelle Du", "Huiji Gao", "Liwei He", "Sanjeev Katariya"], "title": "Harnessing the Power of Interleaving and Counterfactual Evaluation for Airbnb Search Ranking", "comment": "10 pages", "summary": "Evaluation plays a crucial role in the development of ranking algorithms on\nsearch and recommender systems. It enables online platforms to create\nuser-friendly features that drive commercial success in a steady and effective\nmanner. The online environment is particularly conducive to applying causal\ninference techniques, such as randomized controlled experiments (known as A/B\ntest), which are often more challenging to implement in fields like medicine\nand public policy. However, businesses face unique challenges when it comes to\neffective A/B test. Specifically, achieving sufficient statistical power for\nconversion-based metrics can be time-consuming, especially for significant\npurchases like booking accommodations. While offline evaluations are quicker\nand more cost-effective, they often lack accuracy and are inadequate for\nselecting candidates for A/B test. To address these challenges, we developed\ninterleaving and counterfactual evaluation methods to facilitate rapid online\nassessments for identifying the most promising candidates for A/B tests. Our\napproach not only increased the sensitivity of experiments by a factor of up to\n100 (depending on the approach and metrics) compared to traditional A/B testing\nbut also streamlined the experimental process. The practical insights gained\nfrom usage in production can also benefit organizations with similar interests.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4ea4\u9519\u548c\u53cd\u4e8b\u5b9e\u8bc4\u4f30\u7684\u65b9\u6cd5\uff0c\u4ee5\u5feb\u901f\u7b5b\u9009A/B\u6d4b\u8bd5\u5019\u9009\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u5b9e\u9a8c\u6548\u7387\u548c\u7075\u654f\u5ea6\u3002", "motivation": "\u5728\u7ebf\u5e73\u53f0\u5728\u8bc4\u4f30\u6392\u540d\u7b97\u6cd5\u65f6\u9762\u4e34\u7edf\u8ba1\u529f\u6548\u4e0d\u8db3\u548c\u8017\u65f6\u95ee\u9898\uff0c\u4f20\u7edf\u79bb\u7ebf\u8bc4\u4f30\u53c8\u7f3a\u4e4f\u51c6\u786e\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4ea4\u9519\u548c\u53cd\u4e8b\u5b9e\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7528\u4e8e\u5feb\u901f\u5728\u7ebf\u8bc4\u4f30\u548c\u7b5b\u9009A/B\u6d4b\u8bd5\u5019\u9009\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u7075\u654f\u5ea6\u63d0\u5347\u9ad8\u8fbe100\u500d\uff0c\u5e76\u4f18\u5316\u4e86\u5b9e\u9a8c\u6d41\u7a0b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7c7b\u4f3c\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bc4\u4f30\u6548\u7387\u548c\u6548\u679c\u3002"}}
{"id": "2508.00043", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00043", "abs": "https://arxiv.org/abs/2508.00043", "authors": ["Nhut Truong", "Uri Hasson"], "title": "Improved Robustness and Functional Localization in Topographic CNNs Through Weight Similarity", "comment": null, "summary": "Topographic neural networks are computational models that can simulate the\nspatial and functional organization of the brain. Topographic constraints in\nneural networks can be implemented in multiple ways, with potentially different\nimpacts on the representations learned by the network. The impact of such\ndifferent implementations has not been systematically examined. To this end,\nhere we compare topographic convolutional neural networks trained with two\nspatial constraints: Weight Similarity (WS), which pushes neighboring units to\ndevelop similar incoming weights, and Activation Similarity (AS), which\nenforces similarity in unit activations. We evaluate the resulting models on\nclassification accuracy, robustness to weight perturbations and input\ndegradation, and the spatial organization of learned representations. Compared\nto both AS and standard CNNs, WS provided three main advantages: i) improved\nrobustness to noise, also showing higher accuracy under weight corruption; ii)\ngreater input sensitivity, reflected in higher activation variance; and iii)\nstronger functional localization, with units showing similar activations\npositioned at closer distances. In addition, WS produced differences in\norientation tuning, symmetry sensitivity, and eccentricity profiles of units,\nindicating an influence of this spatial constraint on the representational\ngeometry of the network. Our findings suggest that during end-to-end training,\nWS constraints produce more robust representations than AS or non-topographic\nCNNs. These findings also suggest that weight-based spatial constraints can\nshape feature learning and functional organization in biophysical inspired\nmodels.", "AI": {"tldr": "\u6bd4\u8f83\u4e86\u4e24\u79cd\u5730\u5f62\u7ea6\u675f\uff08\u6743\u91cd\u76f8\u4f3c\u6027\u548c\u6fc0\u6d3b\u76f8\u4f3c\u6027\uff09\u5bf9\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6743\u91cd\u76f8\u4f3c\u6027\u5728\u9c81\u68d2\u6027\u3001\u8f93\u5165\u654f\u611f\u6027\u548c\u529f\u80fd\u5b9a\u4f4d\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u7814\u7a76\u4e0d\u540c\u5730\u5f62\u7ea6\u675f\u5bf9\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u8868\u793a\u7684\u5f71\u54cd\uff0c\u586b\u8865\u7cfb\u7edf\u6027\u6bd4\u8f83\u7684\u7a7a\u767d\u3002", "method": "\u8bad\u7ec3\u4e24\u79cd\u5730\u5f62\u7ea6\u675f\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08\u6743\u91cd\u76f8\u4f3c\u6027\u548c\u6fc0\u6d3b\u76f8\u4f3c\u6027\uff09\uff0c\u8bc4\u4f30\u5206\u7c7b\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u8868\u793a\u7a7a\u95f4\u7ec4\u7ec7\u3002", "result": "\u6743\u91cd\u76f8\u4f3c\u6027\u5728\u566a\u58f0\u9c81\u68d2\u6027\u3001\u8f93\u5165\u654f\u611f\u6027\u548c\u529f\u80fd\u5b9a\u4f4d\u65b9\u9762\u4f18\u4e8e\u6fc0\u6d3b\u76f8\u4f3c\u6027\u548c\u6807\u51c6CNN\u3002", "conclusion": "\u6743\u91cd\u76f8\u4f3c\u6027\u7ea6\u675f\u80fd\u4ea7\u751f\u66f4\u9c81\u68d2\u7684\u8868\u793a\uff0c\u5e76\u5f71\u54cd\u7f51\u7edc\u7684\u7279\u5f81\u5b66\u4e60\u548c\u529f\u80fd\u7ec4\u7ec7\u3002"}}
{"id": "2508.00525", "categories": ["cs.IT", "cs.AI", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.00525", "abs": "https://arxiv.org/abs/2508.00525", "authors": ["George M. Coghill"], "title": "Towards a Measure Theory of Semantic Information", "comment": "17 pages,3 figures", "summary": "A classic account of the quantification of semantic information is that of\nBar-Hiller and Carnap. Their account proposes an inverse relation between the\ninformativeness of a statement and its probability. However, their approach\nassigns the maximum informativeness to a contradiction: which Floridi refers to\nas the Bar-Hillel-Carnap paradox. He developed a novel theory founded on a\ndistance metric and parabolic relation, designed to remove this paradox.\nUnfortunately is approach does not succeed in that aim.\n  In this paper I critique Floridi's theory of strongly semantic information on\nits own terms and show where it succeeds and fails. I then present a new\napproach based on the unit circle (a relation that has been the basis of\ntheories from basic trigonometry to quantum theory). This is used, by analogy\nwith von Neumann's quantum probability to construct a measure space for\ninformativeness that meets all the requirements stipulated by Floridi and\nremoves the paradox. In addition, while contradictions and tautologies have\nzero informativeness, it is found that messages which are contradictory to each\nother are equally informative. The utility of this is explained by means of an\nexample.", "AI": {"tldr": "\u672c\u6587\u6279\u5224\u4e86Floridi\u7684\u5f3a\u8bed\u4e49\u4fe1\u606f\u7406\u8bba\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5355\u4f4d\u5706\u7684\u65b0\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86Bar-Hillel-Carnap\u6096\u8bba\u3002", "motivation": "Floridi\u7684\u7406\u8bba\u672a\u80fd\u5b8c\u5168\u89e3\u51b3Bar-Hillel-Carnap\u6096\u8bba\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u65b0\u65b9\u6cd5\u5f7b\u5e95\u6d88\u9664\u8fd9\u4e00\u77db\u76fe\u3002", "method": "\u91c7\u7528\u5355\u4f4d\u5706\u4f5c\u4e3a\u57fa\u7840\uff0c\u7c7b\u6bd4von Neumann\u7684\u91cf\u5b50\u6982\u7387\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u6ee1\u8db3Floridi\u8981\u6c42\u7684\u5ea6\u91cf\u7a7a\u95f4\u3002", "result": "\u65b0\u65b9\u6cd5\u4e0d\u4ec5\u89e3\u51b3\u4e86\u6096\u8bba\uff0c\u8fd8\u53d1\u73b0\u76f8\u4e92\u77db\u76fe\u7684\u4fe1\u606f\u5177\u6709\u76f8\u540c\u7684\u4fe1\u606f\u91cf\u3002", "conclusion": "\u57fa\u4e8e\u5355\u4f4d\u5706\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86Floridi\u7406\u8bba\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u9645\u5e94\u7528\u7684\u793a\u4f8b\u3002"}}
{"id": "2508.00222", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00222", "abs": "https://arxiv.org/abs/2508.00222", "authors": ["Yihong Dong", "Xue Jiang", "Yongding Tao", "Huanyu Liu", "Kechi Zhang", "Lili Mou", "Rongyu Cao", "Yingwei Ma", "Jue Chen", "Binhua Li", "Zhi Jin", "Fei Huang", "Yongbin Li", "Ge Li"], "title": "RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization", "comment": null, "summary": "Reinforcement Learning with Verifiable Reward (RLVR) has significantly\nadvanced the complex reasoning abilities of Large Language Models (LLMs).\nHowever, it struggles to break through the inherent capability boundaries of\nthe base LLM, due to its inherently on-policy strategy with LLM's immense\naction space and sparse reward. Further, RLVR can lead to the capability\nboundary collapse, narrowing the LLM's problem-solving scope. To address this\nproblem, we propose RL-PLUS, a novel approach that synergizes internal\nexploitation (i.e., Thinking) with external data (i.e., Learning) to achieve\nstronger reasoning capabilities and surpass the boundaries of base models.\nRL-PLUS integrates two core components: Multiple Importance Sampling to address\nfor distributional mismatch from external data, and an Exploration-Based\nAdvantage Function to guide the model towards high-value, unexplored reasoning\npaths. We provide both theoretical analysis and extensive experiments to\ndemonstrate the superiority and generalizability of our approach. The results\nshow that RL-PLUS achieves state-of-the-art performance compared with existing\nRLVR methods on six math reasoning benchmarks and exhibits superior performance\non six out-of-distribution reasoning tasks. It also achieves consistent and\nsignificant gains across diverse model families, with average relative\nimprovements ranging from 21.1\\% to 69.2\\%. Moreover, Pass@k curves across\nmultiple benchmarks indicate that RL-PLUS effectively resolves the capability\nboundary collapse problem.", "AI": {"tldr": "RL-PLUS\u901a\u8fc7\u7ed3\u5408\u5185\u90e8\u63a2\u7d22\u4e0e\u5916\u90e8\u6570\u636e\uff0c\u89e3\u51b3\u4e86RLVR\u7684\u80fd\u529b\u8fb9\u754c\u95ee\u9898\uff0c\u63d0\u5347\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "RLVR\u56e0\u7b56\u7565\u56fa\u6709\u6027\u548c\u7a00\u758f\u5956\u52b1\u9650\u5236\u4e86LLM\u7684\u80fd\u529b\u8fb9\u754c\uff0c\u751a\u81f3\u5bfc\u81f4\u80fd\u529b\u8fb9\u754c\u5d29\u6e83\u3002", "method": "RL-PLUS\u7ed3\u5408\u591a\u91cd\u91cd\u8981\u6027\u91c7\u6837\u548c\u63a2\u7d22\u4f18\u52bf\u51fd\u6570\uff0c\u4f18\u5316\u63a8\u7406\u8def\u5f84\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u548c\u5206\u5e03\u5916\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747\u63d0\u534721.1%\u81f369.2%\u3002", "conclusion": "RL-PLUS\u6709\u6548\u89e3\u51b3\u4e86\u80fd\u529b\u8fb9\u754c\u5d29\u6e83\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2508.00271", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.00271", "abs": "https://arxiv.org/abs/2508.00271", "authors": ["Hongjin Qian", "Zheng Liu"], "title": "MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning", "comment": "Technical Report, 14 pages", "summary": "In this work, we propose MetaAgent, an agentic paradigm inspired by the\nprinciple of learning-by-doing, where expertise is developed through hands-on\npractice and continual self-improvement. MetaAgent starts with a minimal\nworkflow, equipped only with basic reasoning and adaptive help-seeking\nabilities. When a knowledge gap is encountered, MetaAgent generates natural\nlanguage help requests, which are routed to the most suitable external tool by\na dedicated tool router. As MetaAgent solves tasks, it continually conducts\nself-reflection and answer verification, distilling actionable experience into\nconcise texts that are dynamically incorporated into future task contexts.\nBesides, MetaAgent autonomously builds in-house tools and a persistent\nknowledge base by organizing its tool-use history, further enhancing its\nability to retrieve and integrate relevant information We term this continual,\ndata-driven process as \\textit{meta tool learning}, through which MetaAgent\nincrementally refines its reasoning and tool-use strategies, without changing\nmodel parameters or requiring further post-training. Evaluated on challenging\nknowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,\nMetaAgent consistently outperforms workflow-based baselines and matches or\nexceeds end-to-end trained agents, demonstrating the promise of self-evolving\nagentic systems for robust, general-purpose knowledge discovery. We provide our\nsource codes in https://github.com/qhjqhj00/MetaAgent.", "AI": {"tldr": "MetaAgent\u662f\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u5b9e\u8df5\u539f\u5219\u7684\u667a\u80fd\u4ee3\u7406\uff0c\u901a\u8fc7\u4e0d\u65ad\u81ea\u6211\u6539\u8fdb\u548c\u5de5\u5177\u5b66\u4e60\u63d0\u5347\u4efb\u52a1\u89e3\u51b3\u80fd\u529b\u3002", "motivation": "\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u901a\u8fc7\u5b9e\u8df5\u548c\u81ea\u6211\u53cd\u601d\u6301\u7eed\u63d0\u5347\u80fd\u529b\u7684\u667a\u80fd\u4ee3\u7406\uff0c\u4ee5\u89e3\u51b3\u77e5\u8bc6\u53d1\u73b0\u4efb\u52a1\u4e2d\u7684\u6311\u6218\u3002", "method": "MetaAgent\u4ece\u57fa\u7840\u80fd\u529b\u51fa\u53d1\uff0c\u901a\u8fc7\u751f\u6210\u81ea\u7136\u8bed\u8a00\u8bf7\u6c42\u3001\u5de5\u5177\u8def\u7531\u3001\u81ea\u6211\u53cd\u601d\u548c\u77e5\u8bc6\u5e93\u6784\u5efa\uff0c\u5b9e\u73b0\u52a8\u6001\u5b66\u4e60\u548c\u5de5\u5177\u4f7f\u7528\u4f18\u5316\u3002", "result": "\u5728GAIA\u3001WebWalkerQA\u548cBrowseCamp\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMetaAgent\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5ab2\u7f8e\u7aef\u5230\u7aef\u8bad\u7ec3\u4ee3\u7406\u3002", "conclusion": "MetaAgent\u5c55\u793a\u4e86\u81ea\u8fdb\u5316\u4ee3\u7406\u7cfb\u7edf\u5728\u901a\u7528\u77e5\u8bc6\u53d1\u73b0\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u65e0\u9700\u8c03\u6574\u6a21\u578b\u53c2\u6570\u6216\u989d\u5916\u8bad\u7ec3\u3002"}}
{"id": "2508.00046", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00046", "abs": "https://arxiv.org/abs/2508.00046", "authors": ["Ruo Yu Tao", "Kaicheng Guo", "Cameron Allen", "George Konidaris"], "title": "Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains", "comment": "To appear at RLC 2025. 1 cover page, 10 pages, 3 reference pages + 13\n  pages for supplementary material", "summary": "Mitigating partial observability is a necessary but challenging task for\ngeneral reinforcement learning algorithms. To improve an algorithm's ability to\nmitigate partial observability, researchers need comprehensive benchmarks to\ngauge progress. Most algorithms tackling partial observability are only\nevaluated on benchmarks with simple forms of state aliasing, such as feature\nmasking and Gaussian noise. Such benchmarks do not represent the many forms of\npartial observability seen in real domains, like visual occlusion or unknown\nopponent intent. We argue that a partially observable benchmark should have two\nkey properties. The first is coverage in its forms of partial observability, to\nensure an algorithm's generalizability. The second is a large gap between the\nperformance of a agents with more or less state information, all other factors\nroughly equal. This gap implies that an environment is memory improvable: where\nperformance gains in a domain are from an algorithm's ability to cope with\npartial observability as opposed to other factors. We introduce best-practice\nguidelines for empirically benchmarking reinforcement learning under partial\nobservability, as well as the open-source library POBAX: Partially Observable\nBenchmarks in JAX. We characterize the types of partial observability present\nin various environments and select representative environments for our\nbenchmark. These environments include localization and mapping, visual control,\ngames, and more. Additionally, we show that these tasks are all memory\nimprovable and require hard-to-learn memory functions, providing a concrete\nsignal for partial observability research. This framework includes recommended\nhyperparameters as well as algorithm implementations for fast, out-of-the-box\nevaluation, as well as highly performant environments implemented in JAX for\nGPU-scalable experimentation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u4e0b\u6027\u80fd\u7684\u57fa\u51c6\u6846\u67b6POBAX\uff0c\u5f3a\u8c03\u57fa\u51c6\u9700\u8986\u76d6\u591a\u79cd\u90e8\u5206\u53ef\u89c2\u6d4b\u5f62\u5f0f\u4e14\u5177\u6709\u8bb0\u5fc6\u6539\u8fdb\u6027\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u7684\u57fa\u51c6\u8fc7\u4e8e\u7b80\u5355\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u590d\u6742\u6027\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u5168\u9762\u7684\u57fa\u51c6\u6765\u63a8\u52a8\u7b97\u6cd5\u7814\u7a76\u3002", "method": "\u63d0\u51faPOBAX\u5f00\u6e90\u5e93\uff0c\u5305\u542b\u591a\u79cd\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\uff08\u5982\u5b9a\u4f4d\u3001\u89c6\u89c9\u63a7\u5236\u3001\u6e38\u620f\u7b49\uff09\uff0c\u5e76\u63d0\u4f9b\u8d85\u53c2\u6570\u548c\u7b97\u6cd5\u5b9e\u73b0\u3002", "result": "POBAX\u4e2d\u7684\u4efb\u52a1\u5747\u5177\u6709\u8bb0\u5fc6\u6539\u8fdb\u6027\uff0c\u4e14\u9700\u8981\u96be\u4ee5\u5b66\u4e60\u7684\u8bb0\u5fc6\u529f\u80fd\uff0c\u4e3a\u7814\u7a76\u63d0\u4f9b\u4e86\u660e\u786e\u4fe1\u53f7\u3002", "conclusion": "POBAX\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u3001\u9ad8\u6548\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u7b97\u6cd5\u53d1\u5c55\u3002"}}
{"id": "2508.00540", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.00540", "abs": "https://arxiv.org/abs/2508.00540", "authors": ["Hequn Zhang", "Qu Luo", "Pei Xiao", "Yue Zhang", "Huiyu Zhou"], "title": "Appendices for \"Closed-Form BER Analysis for Uplink NOMA with Dynamic SIC Decoding\"", "comment": null, "summary": "This document provides the supplementary materials for the paper Closed-Form\nBER Analysis for Uplink NOMA with Dynamic SIC Decoding. The appendices present\ndetailed mathematical derivations and proofs that support the analytical\nframework of the main paper. Specifically, we include: (i) cumulative\ndistribution functions for ordered channel gains; (ii) probability density\nfunctions of normalized signal-plus-interference variances in NOMA dynamic SIC\ndecoding; (iii) closed-form expressions for pairwise error probability (PEP)\nwith two users; (iv) probability derivations for channel gain ordering in the\ntwo-UE case, specifically when UE 1 and UE 2 have the strongest or second\nstrongest channel gains; (v) BER analysis for M-QAM modulation schemes\nincluding BPSK, 4QAM, 16QAM and 64QAM; (vi) PDF derivations for channel gains\nunder various ordering conditions; and (vii) challenges of PDF derivations for\nreal part of channel gain under various ordering condition. These mathematical\nfoundations enable the closed-form BER analysis of uplink NOMA systems with\ndynamic SIC decoding under Rayleigh fading channels, supporting analytical\nexpressions for various modulation schemes and system configurations.", "AI": {"tldr": "\u672c\u6587\u8865\u5145\u6750\u6599\u63d0\u4f9b\u4e86\u4e0a\u884cNOMA\u52a8\u6001SIC\u89e3\u7801\u7684\u95ed\u5f0fBER\u5206\u6790\u8be6\u7ec6\u6570\u5b66\u63a8\u5bfc\uff0c\u5305\u62ec\u4fe1\u9053\u589e\u76ca\u6392\u5e8f\u3001\u8bef\u5dee\u6982\u7387\u548c\u8c03\u5236\u65b9\u6848\u7684PDF\u63a8\u5bfc\u3002", "motivation": "\u4e3a\u4e0a\u884cNOMA\u7cfb\u7edf\u5728\u745e\u5229\u8870\u843d\u4fe1\u9053\u4e0b\u7684\u52a8\u6001SIC\u89e3\u7801\u63d0\u4f9b\u6570\u5b66\u57fa\u7840\uff0c\u652f\u6301\u95ed\u5f0fBER\u5206\u6790\u3002", "method": "\u8be6\u7ec6\u6570\u5b66\u63a8\u5bfc\uff0c\u5305\u62ec\u4fe1\u9053\u589e\u76ca\u6392\u5e8f\u3001PDF\u63a8\u5bfc\u548c\u8bef\u5dee\u6982\u7387\u5206\u6790\u3002", "result": "\u63d0\u4f9b\u4e86\u591a\u79cd\u8c03\u5236\u65b9\u6848\u548c\u7cfb\u7edf\u914d\u7f6e\u4e0b\u7684\u95ed\u5f0fBER\u8868\u8fbe\u5f0f\u3002", "conclusion": "\u8865\u5145\u6750\u6599\u4e3a\u4e0a\u884cNOMA\u52a8\u6001SIC\u89e3\u7801\u7684\u95ed\u5f0fBER\u5206\u6790\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u6570\u5b66\u57fa\u7840\u3002"}}
{"id": "2508.00047", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00047", "abs": "https://arxiv.org/abs/2508.00047", "authors": ["Yuan-Cheng Yu", "Yen-Chieh Ouyang", "Chun-An Lin"], "title": "TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection", "comment": "11 pages, 2 figures", "summary": "Time-series anomaly detection plays a central role across a wide range of\napplication domains. With the increasing proliferation of the Internet of\nThings (IoT) and smart manufacturing, time-series data has dramatically\nincreased in both scale and dimensionality. This growth has exposed the\nlimitations of traditional statistical methods in handling the high\nheterogeneity and complexity of such data. Inspired by the recent success of\nlarge language models (LLMs) in multimodal tasks across language and vision\ndomains, we propose a novel unsupervised anomaly detection framework: A\nTri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly\nDetection (TriP-LLM). TriP-LLM integrates local and global temporal features\nthrough a tri-branch design-Patching, Selection, and Global-to encode the input\ntime series into patch-wise tokens, which are then processed by a frozen,\npretrained LLM. A lightweight patch-wise decoder reconstructs the input, from\nwhich anomaly scores are derived. We evaluate TriP-LLM on several public\nbenchmark datasets using PATE, a recently proposed threshold-free evaluation\nmetric, and conduct all comparisons within a unified open-source framework to\nensure fairness. Experimental results show that TriP-LLM consistently\noutperforms recent state-of-the-art methods across all datasets, demonstrating\nstrong detection capabilities. Furthermore, through extensive ablation studies,\nwe verify the substantial contribution of the LLM to the overall architecture.\nCompared to LLM-based approaches using Channel Independence (CI) patch\nprocessing, TriP-LLM achieves significantly lower memory consumption, making it\nmore suitable for GPU memory-constrained environments. All code and model\ncheckpoints are publicly available on https://github.com/YYZStart/TriP-LLM.git", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTriP-LLM\u7684\u65e0\u76d1\u7763\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u5206\u652f\u8bbe\u8ba1\u548c\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5904\u7406\u6570\u636e\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\u548c\u667a\u80fd\u5236\u9020\u7684\u666e\u53ca\uff0c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u89c4\u6a21\u548c\u7ef4\u5ea6\u6025\u5267\u589e\u52a0\uff0c\u4f20\u7edf\u7edf\u8ba1\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5176\u9ad8\u5f02\u8d28\u6027\u548c\u590d\u6742\u6027\u3002", "method": "TriP-LLM\u91c7\u7528\u4e09\u5206\u652f\u8bbe\u8ba1\uff08Patching\u3001Selection\u3001Global\uff09\u5c06\u65f6\u95f4\u5e8f\u5217\u7f16\u7801\u4e3a\u5206\u5757\u6807\u8bb0\uff0c\u7531\u51bb\u7ed3\u7684\u9884\u8bad\u7ec3LLM\u5904\u7406\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u89e3\u7801\u5668\u91cd\u6784\u8f93\u5165\u4ee5\u8ba1\u7b97\u5f02\u5e38\u5206\u6570\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cTriP-LLM\u8868\u73b0\u4f18\u4e8e\u6700\u65b0\u65b9\u6cd5\uff0c\u4e14\u5185\u5b58\u6d88\u8017\u663e\u8457\u4f4e\u4e8e\u57fa\u4e8e\u901a\u9053\u72ec\u7acb\u7684LLM\u65b9\u6cd5\u3002", "conclusion": "TriP-LLM\u5c55\u793a\u4e86LLM\u5728\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\uff0c\u9002\u5408\u5185\u5b58\u53d7\u9650\u7684\u73af\u5883\uff0c\u4ee3\u7801\u548c\u6a21\u578b\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.00596", "categories": ["cs.IT", "cs.CR", "cs.DC", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.00596", "abs": "https://arxiv.org/abs/2508.00596", "authors": ["Xiang Zhang", "Zhou Li", "Shuangyang Li", "Kai Wan", "Derrick Wing Kwan Ng", "Giuseppe Caire"], "title": "Information-Theoretic Decentralized Secure Aggregation with Collusion Resilience", "comment": "Submitted to IEEE for potential journal publication", "summary": "In decentralized federated learning (FL), multiple clients collaboratively\nlearn a shared machine learning (ML) model by leveraging their privately held\ndatasets distributed across the network, through interactive exchange of the\nintermediate model updates. To ensure data security, cryptographic techniques\nare commonly employed to protect model updates during aggregation. Despite\ngrowing interest in secure aggregation, existing works predominantly focus on\nprotocol design and computational guarantees, with limited understanding of the\nfundamental information-theoretic limits of such systems. Moreover, optimal\nbounds on communication and key usage remain unknown in decentralized settings,\nwhere no central aggregator is available. Motivated by these gaps, we study the\nproblem of decentralized secure aggregation (DSA) from an information-theoretic\nperspective. Specifically, we consider a network of $K$ fully-connected users,\neach holding a private input -- an abstraction of local training data -- who\naim to securely compute the sum of all inputs. The security constraint requires\nthat no user learns anything beyond the input sum, even when colluding with up\nto $T$ other users. We characterize the optimal rate region, which specifies\nthe minimum achievable communication and secret key rates for DSA. In\nparticular, we show that to securely compute one symbol of the desired input\nsum, each user must (i) transmit at least one symbol to others, (ii) hold at\nleast one symbol of secret key, and (iii) all users must collectively hold no\nfewer than $K - 1$ independent key symbols. Our results establish the\nfundamental performance limits of DSA, providing insights for the design of\nprovably secure and communication-efficient protocols in distributed learning\nsystems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5b89\u5168\u805a\u5408\u95ee\u9898\uff0c\u4ece\u4fe1\u606f\u8bba\u7684\u89d2\u5ea6\u5206\u6790\u4e86\u901a\u4fe1\u548c\u5bc6\u94a5\u4f7f\u7528\u7684\u6700\u4f18\u754c\u9650\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u534f\u8bae\u8bbe\u8ba1\u548c\u8ba1\u7b97\u4fdd\u8bc1\uff0c\u7f3a\u4e4f\u5bf9\u7cfb\u7edf\u57fa\u672c\u4fe1\u606f\u8bba\u9650\u5236\u7684\u7406\u89e3\uff0c\u5c24\u5176\u662f\u5728\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u4e2d\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4e00\u4e2a\u7531K\u4e2a\u5168\u8fde\u63a5\u7528\u6237\u7ec4\u6210\u7684\u7f51\u7edc\uff0c\u6bcf\u4e2a\u7528\u6237\u6301\u6709\u79c1\u6709\u8f93\u5165\uff0c\u76ee\u6807\u662f\u5b89\u5168\u8ba1\u7b97\u6240\u6709\u8f93\u5165\u7684\u603b\u548c\u3002", "result": "\u786e\u5b9a\u4e86\u6700\u4f18\u901f\u7387\u533a\u57df\uff0c\u8868\u660e\u6bcf\u4e2a\u7528\u6237\u5fc5\u987b\u4f20\u8f93\u81f3\u5c11\u4e00\u4e2a\u7b26\u53f7\u3001\u6301\u6709\u81f3\u5c11\u4e00\u4e2a\u5bc6\u94a5\u7b26\u53f7\uff0c\u4e14\u6240\u6709\u7528\u6237\u5171\u540c\u6301\u6709\u4e0d\u5c11\u4e8eK-1\u4e2a\u72ec\u7acb\u5bc6\u94a5\u7b26\u53f7\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5206\u5e03\u5f0f\u5b66\u4e60\u7cfb\u7edf\u4e2d\u8bbe\u8ba1\u53ef\u8bc1\u660e\u5b89\u5168\u548c\u901a\u4fe1\u9ad8\u6548\u7684\u534f\u8bae\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2508.00282", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00282", "abs": "https://arxiv.org/abs/2508.00282", "authors": ["Yi-Long Lu", "Jiajun Song", "Chunhui Zhang", "Wei Wang"], "title": "Mind the Gap: The Divergence Between Human and LLM-Generated Tasks", "comment": null, "summary": "Humans constantly generate a diverse range of tasks guided by internal\nmotivations. While generative agents powered by large language models (LLMs)\naim to simulate this complex behavior, it remains uncertain whether they\noperate on similar cognitive principles. To address this, we conducted a\ntask-generation experiment comparing human responses with those of an LLM agent\n(GPT-4o). We find that human task generation is consistently influenced by\npsychological drivers, including personal values (e.g., Openness to Change) and\ncognitive style. Even when these psychological drivers are explicitly provided\nto the LLM, it fails to reflect the corresponding behavioral patterns. They\nproduce tasks that are markedly less social, less physical, and thematically\nbiased toward abstraction. Interestingly, while the LLM's tasks were perceived\nas more fun and novel, this highlights a disconnect between its linguistic\nproficiency and its capacity to generate human-like, embodied goals.We conclude\nthat there is a core gap between the value-driven, embodied nature of human\ncognition and the statistical patterns of LLMs, highlighting the necessity of\nincorporating intrinsic motivation and physical grounding into the design of\nmore human-aligned agents.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u4eba\u7c7b\u548cLLM\uff08GPT-4o\uff09\u5728\u4efb\u52a1\u751f\u6210\u4e2d\u7684\u5dee\u5f02\uff0c\u53d1\u73b0\u4eba\u7c7b\u53d7\u5fc3\u7406\u9a71\u52a8\uff08\u5982\u4e2a\u4eba\u4ef7\u503c\u89c2\u548c\u8ba4\u77e5\u98ce\u683c\uff09\u5f71\u54cd\uff0c\u800cLLM\u5373\u4f7f\u63d0\u4f9b\u8fd9\u4e9b\u9a71\u52a8\u4e5f\u65e0\u6cd5\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\uff0c\u751f\u6210\u7684\u4efb\u52a1\u66f4\u62bd\u8c61\u3001\u7f3a\u4e4f\u793e\u4ea4\u548c\u7269\u7406\u6027\u3002\u5c3d\u7ba1LLM\u7684\u4efb\u52a1\u88ab\u8ba4\u4e3a\u66f4\u6709\u8da3\u548c\u65b0\u9896\uff0c\u4f46\u5176\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u5b58\u5728\u672c\u8d28\u5dee\u8ddd\u3002", "motivation": "\u63a2\u8ba8\u751f\u6210\u4ee3\u7406\uff08\u5982LLM\uff09\u662f\u5426\u80fd\u6a21\u62df\u4eba\u7c7b\u57fa\u4e8e\u5185\u5728\u52a8\u673a\u7684\u4efb\u52a1\u751f\u6210\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u4efb\u52a1\u751f\u6210\u5b9e\u9a8c\u6bd4\u8f83\u4eba\u7c7b\u548cLLM\uff08GPT-4o\uff09\u7684\u884c\u4e3a\uff0c\u5206\u6790\u5fc3\u7406\u9a71\u52a8\u5bf9\u4efb\u52a1\u751f\u6210\u7684\u5f71\u54cd\u3002", "result": "\u4eba\u7c7b\u4efb\u52a1\u751f\u6210\u53d7\u5fc3\u7406\u9a71\u52a8\u5f71\u54cd\uff0c\u800cLLM\u751f\u6210\u7684\u4efb\u52a1\u66f4\u62bd\u8c61\u3001\u7f3a\u4e4f\u793e\u4ea4\u548c\u7269\u7406\u6027\uff0c\u4e14\u4e0e\u4eba\u7c7b\u884c\u4e3a\u6a21\u5f0f\u4e0d\u7b26\u3002", "conclusion": "LLM\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u5b58\u5728\u672c\u8d28\u5dee\u8ddd\uff0c\u9700\u5728\u8bbe\u8ba1\u66f4\u4eba\u6027\u5316\u4ee3\u7406\u65f6\u878d\u5165\u5185\u5728\u52a8\u673a\u548c\u7269\u7406\u57fa\u7840\u3002"}}
{"id": "2508.00078", "categories": ["cs.LG", "cs.AI", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2508.00078", "abs": "https://arxiv.org/abs/2508.00078", "authors": ["Imen Mahmoud", "Andrei Velichko"], "title": "Evaluating COVID 19 Feature Contributions to Bitcoin Return Forecasting: Methodology Based on LightGBM and Genetic Optimization", "comment": "22 pages, 5 figures", "summary": "This study proposes a novel methodological framework integrating a LightGBM\nregression model and genetic algorithm (GA) optimization to systematically\nevaluate the contribution of COVID-19-related indicators to Bitcoin return\nprediction. The primary objective was not merely to forecast Bitcoin returns\nbut rather to determine whether including pandemic-related health data\nsignificantly enhances prediction accuracy. A comprehensive dataset comprising\ndaily Bitcoin returns and COVID-19 metrics (vaccination rates,\nhospitalizations, testing statistics) was constructed. Predictive models,\ntrained with and without COVID-19 features, were optimized using GA over 31\nindependent runs, allowing robust statistical assessment. Performance metrics\n(R2, RMSE, MAE) were statistically compared through distribution overlaps and\nMann-Whitney U tests. Permutation Feature Importance (PFI) analysis quantified\nindividual feature contributions. Results indicate that COVID-19 indicators\nsignificantly improved model performance, particularly in capturing extreme\nmarket fluctuations (R2 increased by 40%, RMSE decreased by 2%, both highly\nsignificant statistically). Among COVID-19 features, vaccination metrics,\nespecially the 75th percentile of fully vaccinated individuals, emerged as\ndominant predictors. The proposed methodology extends existing financial\nanalytics tools by incorporating public health signals, providing investors and\npolicymakers with refined indicators to navigate market uncertainty during\nsystemic crises.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LightGBM\u56de\u5f52\u6a21\u578b\u548c\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u7684\u65b0\u65b9\u6cd5\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30COVID-19\u76f8\u5173\u6307\u6807\u5bf9\u6bd4\u7279\u5e01\u56de\u62a5\u9884\u6d4b\u7684\u8d21\u732e\u3002\u7ed3\u679c\u8868\u660e\uff0c\u75ab\u60c5\u6307\u6807\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5c24\u5176\u662f\u75ab\u82d7\u63a5\u79cd\u6570\u636e\u3002", "motivation": "\u7814\u7a76\u7684\u4e3b\u8981\u76ee\u6807\u4e0d\u4ec5\u662f\u9884\u6d4b\u6bd4\u7279\u5e01\u56de\u62a5\uff0c\u800c\u662f\u786e\u5b9a\u662f\u5426\u5305\u542b\u75ab\u60c5\u76f8\u5173\u5065\u5eb7\u6570\u636e\u80fd\u663e\u8457\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b\u6bd4\u7279\u5e01\u56de\u62a5\u548cCOVID-19\u6307\u6807\u7684\u5168\u9762\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u7edf\u8ba1\u65b9\u6cd5\u6bd4\u8f83\u6027\u80fd\u6307\u6807\u3002", "result": "COVID-19\u6307\u6807\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff08R2\u589e\u52a040%\uff0cRMSE\u964d\u4f4e2%\uff09\uff0c\u75ab\u82d7\u63a5\u79cd\u6570\u636e\u662f\u4e3b\u8981\u9884\u6d4b\u56e0\u7d20\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6269\u5c55\u4e86\u91d1\u878d\u5206\u6790\u5de5\u5177\uff0c\u4e3a\u6295\u8d44\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u5728\u7cfb\u7edf\u6027\u5371\u673a\u4e2d\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u5e02\u573a\u6307\u6807\u3002"}}
{"id": "2508.00626", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.00626", "abs": "https://arxiv.org/abs/2508.00626", "authors": ["Zhenyu Liu", "Yi Ma", "Rahim Tafazolli"], "title": "Deep Learning-Based Rate-Adaptive CSI Feedback for Wideband XL-MIMO Systems in the Near-Field Domain", "comment": null, "summary": "Accurate and efficient channel state information (CSI) feedback is crucial\nfor unlocking the substantial spectral efficiency gains of extremely\nlarge-scale MIMO (XL-MIMO) systems in future 6G networks. However, the\ncombination of near-field spherical wave propagation and frequency-dependent\nbeam split effects in wideband scenarios poses significant challenges for CSI\nrepresentation and compression. This paper proposes WideNLNet-CA, a\nrate-adaptive deep learning framework designed to enable efficient CSI feedback\nin wideband near-field XL-MIMO systems. WideNLNet-CA introduces a lightweight\nencoder-decoder architecture with multi-stage downsampling and upsampling,\nincorporating computationally efficient residual blocks to capture complex\nmulti-scale channel features with reduced overhead. A novel compression ratio\nadaptive module with feature importance estimation is introduced to dynamically\nmodulate feature selection based on target compression ratios, enabling\nflexible adaptation across a wide range of feedback rates using a single model.\nEvaluation results demonstrate that WideNLNet-CA consistently outperforms\nexisting compressive sensing and deep learning-based works across various\ncompression ratios and bandwidths, while maintaining fast inference and low\nmodel storage requirements.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWideNLNet-CA\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5bbd\u5e26\u8fd1\u573aXL-MIMO\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u9ad8\u6548\u7684CSI\u53cd\u9988\u3002", "motivation": "\u57286G\u7f51\u7edc\u4e2d\uff0cXL-MIMO\u7cfb\u7edf\u7684\u9891\u8c31\u6548\u7387\u589e\u76ca\u4f9d\u8d56\u4e8e\u51c6\u786e\u4e14\u9ad8\u6548\u7684CSI\u53cd\u9988\uff0c\u4f46\u8fd1\u573a\u7403\u9762\u6ce2\u4f20\u64ad\u548c\u5bbd\u5e26\u573a\u666f\u4e2d\u7684\u9891\u7387\u4f9d\u8d56\u6027\u6ce2\u675f\u5206\u88c2\u6548\u5e94\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "WideNLNet-CA\u91c7\u7528\u8f7b\u91cf\u7ea7\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff0c\u7ed3\u5408\u591a\u9636\u6bb5\u4e0b\u91c7\u6837\u548c\u4e0a\u91c7\u6837\uff0c\u4ee5\u53ca\u8ba1\u7b97\u9ad8\u6548\u7684\u6b8b\u5dee\u5757\uff0c\u5e76\u5f15\u5165\u538b\u7f29\u6bd4\u81ea\u9002\u5e94\u6a21\u5757\u52a8\u6001\u8c03\u6574\u7279\u5f81\u9009\u62e9\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cWideNLNet-CA\u5728\u5404\u79cd\u538b\u7f29\u6bd4\u548c\u5e26\u5bbd\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5feb\u901f\u63a8\u7406\u548c\u4f4e\u5b58\u50a8\u9700\u6c42\u3002", "conclusion": "WideNLNet-CA\u4e3a\u5bbd\u5e26\u8fd1\u573aXL-MIMO\u7cfb\u7edf\u4e2d\u7684CSI\u53cd\u9988\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00323", "abs": "https://arxiv.org/abs/2508.00323", "authors": ["Jianyi Zhang", "Xu Ji", "Ziyin Zhou", "Yuchen Zhou", "Shubo Shi", "Haoyu Wu", "Zhen Li", "Shizhao Liu"], "title": "Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning", "comment": null, "summary": "Evaluating the performance of visual language models (VLMs) in graphic\nreasoning tasks has become an important research topic. However, VLMs still\nshow obvious deficiencies in simulating human-level graphic reasoning\ncapabilities, especially in complex graphic reasoning and abstract problem\nsolving, which are less studied and existing studies only focus on simple\ngraphics. To evaluate the performance of VLMs in complex graphic reasoning, we\npropose ReasonBench, the first evaluation benchmark focused on structured\ngraphic reasoning tasks, which includes 1,613 questions from real-world\nintelligence tests. ReasonBench covers reasoning dimensions related to\nlocation, attribute, quantity, and multi-element tasks, providing a\ncomprehensive evaluation of the performance of VLMs in spatial, relational, and\nabstract reasoning capabilities. We benchmark 11 mainstream VLMs (including\nclosed-source and open-source models) and reveal significant limitations of\ncurrent models. Based on these findings, we propose a dual optimization\nstrategy: Diagrammatic Reasoning Chain (DiaCoT) enhances the interpretability\nof reasoning by decomposing layers, and ReasonTune enhances the task\nadaptability of model reasoning through training, all of which improves VLM\nperformance by 33.5\\%. All experimental data and code are in the repository:\nhttps://huggingface.co/datasets/cistine/ReasonBench.", "AI": {"tldr": "ReasonBench\u662f\u9996\u4e2a\u4e13\u6ce8\u4e8e\u7ed3\u6784\u5316\u56fe\u5f62\u63a8\u7406\u4efb\u52a1\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u590d\u6742\u56fe\u5f62\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u53cc\u91cd\u4f18\u5316\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7b80\u5355\u56fe\u5f62\uff0c\u800cVLMs\u5728\u590d\u6742\u56fe\u5f62\u63a8\u7406\u548c\u62bd\u8c61\u95ee\u9898\u89e3\u51b3\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u63d0\u51faReasonBench\u57fa\u51c6\uff0c\u5305\u542b1,613\u4e2a\u771f\u5b9e\u4e16\u754c\u667a\u529b\u6d4b\u8bd5\u95ee\u9898\uff0c\u6db5\u76d6\u4f4d\u7f6e\u3001\u5c5e\u6027\u3001\u6570\u91cf\u548c\u591a\u5143\u7d20\u4efb\u52a1\u3002\u8bc4\u4f3011\u79cd\u4e3b\u6d41VLMs\uff0c\u5e76\u63d0\u51faDiaCoT\u548cReasonTune\u4f18\u5316\u7b56\u7565\u3002", "result": "\u5f53\u524dVLMs\u5728\u590d\u6742\u56fe\u5f62\u63a8\u7406\u4e2d\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff0c\u4f18\u5316\u7b56\u7565\u4f7f\u6a21\u578b\u6027\u80fd\u63d0\u534733.5%\u3002", "conclusion": "ReasonBench\u4e3aVLMs\u7684\u56fe\u5f62\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u53cc\u91cd\u4f18\u5316\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2508.00098", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.00098", "abs": "https://arxiv.org/abs/2508.00098", "authors": ["Ashkan Shakarami", "Yousef Yeganeh", "Azade Farshad", "Lorenzo Nicole", "Stefano Ghidoni", "Nassir Navab"], "title": "Stress-Aware Resilient Neural Training", "comment": "16 pages, 11 figures", "summary": "This paper introduces Stress-Aware Learning, a resilient neural training\nparadigm in which deep neural networks dynamically adjust their optimization\nbehavior - whether under stable training regimes or in settings with uncertain\ndynamics - based on the concept of Temporary (Elastic) and Permanent (Plastic)\nDeformation, inspired by structural fatigue in materials science. To\ninstantiate this concept, we propose Plastic Deformation Optimizer, a\nstress-aware mechanism that injects adaptive noise into model parameters\nwhenever an internal stress signal - reflecting stagnation in training loss and\naccuracy - indicates persistent optimization difficulty. This enables the model\nto escape sharp minima and converge toward flatter, more generalizable regions\nof the loss landscape. Experiments across six architectures, four optimizers,\nand seven vision benchmarks demonstrate improved robustness and generalization\nwith minimal computational overhead. The code and 3D visuals will be available\non GitHub: https://github.com/Stress-Aware-Learning/SAL.", "AI": {"tldr": "Stress-Aware Learning\uff08SAL\uff09\u662f\u4e00\u79cd\u5f39\u6027\u795e\u7ecf\u8bad\u7ec3\u8303\u5f0f\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4f18\u5316\u884c\u4e3a\uff0c\u63d0\u5347\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u53d7\u6750\u6599\u79d1\u5b66\u4e2d\u7ed3\u6784\u75b2\u52b3\u7684\u542f\u53d1\uff0c\u63d0\u51fa\u4e34\u65f6\uff08\u5f39\u6027\uff09\u548c\u6c38\u4e45\uff08\u5851\u6027\uff09\u53d8\u5f62\u7684\u6982\u5ff5\uff0c\u4ee5\u89e3\u51b3\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u505c\u6ede\u95ee\u9898\u3002", "method": "\u63d0\u51faPlastic Deformation Optimizer\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u566a\u58f0\u6ce8\u5165\u6a21\u578b\u53c2\u6570\uff0c\u5e2e\u52a9\u6a21\u578b\u9003\u79bb\u5c16\u9510\u6700\u5c0f\u503c\uff0c\u6536\u655b\u5230\u66f4\u5e73\u5766\u7684\u635f\u5931\u533a\u57df\u3002", "result": "\u5728\u516d\u79cd\u67b6\u6784\u3001\u56db\u79cd\u4f18\u5316\u5668\u548c\u4e03\u4e2a\u89c6\u89c9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\u3002", "conclusion": "SAL\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4f18\u5316\u884c\u4e3a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4ee3\u7801\u548c3D\u53ef\u89c6\u5316\u5c06\u5728GitHub\u4e0a\u5f00\u6e90\u3002"}}
{"id": "2508.00324", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00324", "abs": "https://arxiv.org/abs/2508.00324", "authors": ["Yeonjun In", "Wonjoong Kim", "Sangwu Park", "Chanyoung Park"], "title": "R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge", "comment": "under review", "summary": "Although large reasoning models (LRMs) have demonstrated impressive\ncapabilities on complex tasks, recent studies reveal that these models\nfrequently fulfill harmful user instructions, raising significant safety\nconcerns. In this paper, we investigate the underlying cause of LRM safety\nrisks and find that models already possess sufficient safety knowledge but fail\nto activate it during reasoning. Based on this insight, we propose R1-Act, a\nsimple and efficient post-training method that explicitly triggers safety\nknowledge through a structured reasoning process. R1-Act achieves strong safety\nimprovements while preserving reasoning performance, outperforming prior\nalignment methods. Notably, it requires only 1,000 training examples and 90\nminutes of training on a single RTX A6000 GPU. Extensive experiments across\nmultiple LRM backbones and sizes demonstrate the robustness, scalability, and\npractical efficiency of our approach.", "AI": {"tldr": "R1-Act\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u89e6\u53d1\u5b89\u5168\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u63a8\u7406\u6a21\u578b\u5177\u5907\u8db3\u591f\u7684\u5b89\u5168\u77e5\u8bc6\uff0c\u4f46\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u672a\u80fd\u6fc0\u6d3b\uff0c\u5bfc\u81f4\u5b89\u5168\u9690\u60a3\u3002", "method": "\u63d0\u51faR1-Act\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u8fc7\u7a0b\u663e\u5f0f\u89e6\u53d1\u5b89\u5168\u77e5\u8bc6\uff0c\u4ec5\u9700\u5c11\u91cf\u8bad\u7ec3\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u3002", "result": "R1-Act\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u5b89\u5168\u6027\u63d0\u5347\u548c\u63a8\u7406\u6027\u80fd\u4fdd\u6301\uff0c\u4f18\u4e8e\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5\u3002", "conclusion": "R1-Act\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u5b9e\u7528\u7684\u5b89\u5168\u589e\u5f3a\u65b9\u6cd5\u3002"}}
{"id": "2508.00117", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00117", "abs": "https://arxiv.org/abs/2508.00117", "authors": ["Md. Ehsanul Haque", "S. M. Jahidul Islam", "Shakil Mia", "Rumana Sharmin", "Ashikuzzaman", "Md Samir Morshed", "Md. Tahmidul Huque"], "title": "StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection", "comment": "Accepted and presented paper of THE 16th INTERNATIONAL IEEE\n  CONFERENCE ON COMPUTING, COMMUNICATION AND NETWORKING TECHNOLOGIES (ICCCNT)\n  INDIA", "summary": "Liver diseases are a serious health concern in the world, which requires\nprecise and timely diagnosis to enhance the survival chances of patients. The\ncurrent literature implemented numerous machine learning and deep learning\nmodels to classify liver diseases, but most of them had some issues like high\nmisclassification error, poor interpretability, prohibitive computational\nexpense, and lack of good preprocessing strategies. In order to address these\ndrawbacks, we introduced StackLiverNet in this study; an interpretable stacked\nensemble model tailored to the liver disease detection task. The framework uses\nadvanced data preprocessing and feature selection technique to increase model\nrobustness and predictive ability. Random undersampling is performed to deal\nwith class imbalance and make the training balanced. StackLiverNet is an\nensemble of several hyperparameter-optimized base classifiers, whose\ncomplementary advantages are used through a LightGBM meta-model. The provided\nmodel demonstrates excellent performance, with the testing accuracy of 99.89%,\nCohen Kappa of 0.9974, and AUC of 0.9993, having only 5 misclassifications, and\nefficient training and inference speeds that are amenable to clinical practice\n(training time 4.2783 seconds, inference time 0.1106 seconds). Besides, Local\nInterpretable Model-Agnostic Explanations (LIME) are applied to generate\ntransparent explanations of individual predictions, revealing high\nconcentrations of Alkaline Phosphatase and moderate SGOT as important\nobservations of liver disease. Also, SHAP was used to rank features by their\nglobal contribution to predictions, while the Morris method confirmed the most\ninfluential features through sensitivity analysis.", "AI": {"tldr": "StackLiverNet\u662f\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u5806\u53e0\u96c6\u6210\u6a21\u578b\uff0c\u7528\u4e8e\u809d\u75c5\u68c0\u6d4b\uff0c\u901a\u8fc7\u9ad8\u7ea7\u6570\u636e\u9884\u5904\u7406\u548c\u7279\u5f81\u9009\u62e9\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\uff0c\u6d4b\u8bd5\u51c6\u786e\u7387\u8fbe99.89%\u3002", "motivation": "\u73b0\u6709\u809d\u75c5\u5206\u7c7b\u6a21\u578b\u5b58\u5728\u9ad8\u8bef\u5206\u7c7b\u7387\u3001\u89e3\u91ca\u6027\u5dee\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u7b49\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u91c7\u7528\u968f\u673a\u6b20\u91c7\u6837\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u6784\u5efa\u8d85\u53c2\u6570\u4f18\u5316\u7684\u57fa\u5206\u7c7b\u5668\u96c6\u6210\uff0c\u901a\u8fc7LightGBM\u5143\u6a21\u578b\u7ed3\u5408\u5176\u4e92\u8865\u4f18\u52bf\uff0c\u5e76\u4f7f\u7528LIME\u548cSHAP\u589e\u5f3a\u89e3\u91ca\u6027\u3002", "result": "\u6d4b\u8bd5\u51c6\u786e\u738799.89%\uff0cCohen Kappa 0.9974\uff0cAUC 0.9993\uff0c\u4ec55\u6b21\u8bef\u5206\u7c7b\uff0c\u8bad\u7ec3\u548c\u63a8\u7406\u901f\u5ea6\u5feb\u3002", "conclusion": "StackLiverNet\u5728\u809d\u75c5\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u517c\u5177\u9ad8\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u9002\u5408\u4e34\u5e8a\u5e94\u7528\u3002"}}
{"id": "2508.00378", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.00378", "abs": "https://arxiv.org/abs/2508.00378", "authors": ["Shixin Yi", "Lin Shang"], "title": "CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding", "comment": "Preparing for AAAI 2026, Multimodal Reasoning", "summary": "Chain-of-Thought (CoT) prompting has shown promise in improving reasoning in\nvision-language models (VLMs), but it often produces explanations that are\nlinguistically fluent yet lack grounding in visual content. We observe that\nsuch hallucinations arise in part from the absence of an explicit verification\nmechanism during multi-step reasoning. To address this, we propose\n\\textbf{CoRGI}(\\textbf{C}hain \\textbf{o}f \\textbf{R}easoning with\n\\textbf{G}rounded \\textbf{I}nsights), a modular framework that introduces\nvisual verification into the reasoning process. CoRGI follows a three-stage\npipeline: it first generates a textual reasoning chain, then extracts\nsupporting visual evidence for each reasoning step via a dedicated module\n(VEVM), and finally synthesizes the textual rationale with visual evidence to\ngenerate a grounded, verified answer. The framework can be integrated with\nexisting VLMs without end-to-end retraining. We evaluate CoRGI on the VCR\nbenchmark and find that it improves reasoning performance on two representative\nopen-source VLM backbones, Qwen-2.5VL and LLaVA-1.6. Ablation studies confirm\nthe contribution of each step in the verification module, and human evaluations\nsuggest that CoRGI leads to more factual and helpful explanations. We also\nexamine alternative designs for the visual verification step and discuss\npotential limitations of post-hoc verification frameworks. These findings\nhighlight the importance of grounding intermediate reasoning steps in visual\nevidence to enhance the robustness of multimodal reasoning.", "AI": {"tldr": "CoRGI\u6846\u67b6\u901a\u8fc7\u89c6\u89c9\u9a8c\u8bc1\u6539\u8fdb\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6b65\u63a8\u7406\uff0c\u51cf\u5c11\u5e7b\u89c9\u73b0\u8c61\u3002", "motivation": "\u89e3\u51b3Chain-of-Thought\u63d0\u793a\u5728\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u4ea7\u751f\u7684\u7f3a\u4e4f\u89c6\u89c9\u4f9d\u636e\u7684\u89e3\u91ca\u95ee\u9898\u3002", "method": "\u63d0\u51faCoRGI\u6846\u67b6\uff0c\u5206\u4e09\u9636\u6bb5\uff1a\u751f\u6210\u6587\u672c\u63a8\u7406\u94fe\u3001\u63d0\u53d6\u89c6\u89c9\u8bc1\u636e\u3001\u7efc\u5408\u751f\u6210\u9a8c\u8bc1\u7b54\u6848\u3002", "result": "\u5728VCR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u5347Qwen-2.5VL\u548cLLaVA-1.6\u7684\u6027\u80fd\uff0c\u751f\u6210\u66f4\u4e8b\u5b9e\u6027\u548c\u6709\u5e2e\u52a9\u7684\u89e3\u91ca\u3002", "conclusion": "\u89c6\u89c9\u8bc1\u636e\u5bf9\u591a\u6a21\u6001\u63a8\u7406\u7684\u7a33\u5065\u6027\u81f3\u5173\u91cd\u8981\uff0cCoRGI\u6846\u67b6\u6709\u6548\u51cf\u5c11\u5e7b\u89c9\u3002"}}
{"id": "2508.00127", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00127", "abs": "https://arxiv.org/abs/2508.00127", "authors": ["Saleh Nikooroo", "Thomas Engel"], "title": "Structured Transformations for Stable and Interpretable Neural Computation", "comment": null, "summary": "Despite their impressive performance, contemporary neural networks often lack\nstructural safeguards that promote stable learning and interpretable behavior.\nIn this work, we introduce a reformulation of layer-level transformations that\ndeparts from the standard unconstrained affine paradigm. Each transformation is\ndecomposed into a structured linear operator and a residual corrective\ncomponent, enabling more disciplined signal propagation and improved training\ndynamics. Our formulation encourages internal consistency and supports stable\ninformation flow across depth, while remaining fully compatible with standard\nlearning objectives and backpropagation. Through a series of synthetic and\nreal-world experiments, we demonstrate that models constructed with these\nstructured transformations exhibit improved gradient conditioning, reduced\nsensitivity to perturbations, and layer-wise robustness. We further show that\nthese benefits persist across architectural scales and training regimes. This\nstudy serves as a foundation for a more principled class of neural\narchitectures that prioritize stability and transparency-offering new tools for\nreasoning about learning behavior without sacrificing expressive power.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u5c42\u53d8\u6362\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7ebf\u6027\u7b97\u5b50\u548c\u6b8b\u5dee\u4fee\u6b63\u7ec4\u4ef6\uff0c\u63d0\u5347\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5f53\u4ee3\u795e\u7ecf\u7f51\u7edc\u7f3a\u4e4f\u7ed3\u6784\u4fdd\u969c\uff0c\u5bfc\u81f4\u5b66\u4e60\u4e0d\u7a33\u5b9a\u548c\u884c\u4e3a\u96be\u4ee5\u89e3\u91ca\u3002", "method": "\u5c06\u5c42\u53d8\u6362\u5206\u89e3\u4e3a\u7ed3\u6784\u5316\u7ebf\u6027\u7b97\u5b50\u548c\u6b8b\u5dee\u4fee\u6b63\u7ec4\u4ef6\uff0c\u4f18\u5316\u4fe1\u53f7\u4f20\u64ad\u548c\u8bad\u7ec3\u52a8\u6001\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6539\u5584\u4e86\u68af\u5ea6\u6761\u4ef6\u3001\u964d\u4f4e\u4e86\u5bf9\u6270\u52a8\u7684\u654f\u611f\u6027\uff0c\u5e76\u589e\u5f3a\u4e86\u5c42\u95f4\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8bbe\u8ba1\u66f4\u7a33\u5b9a\u3001\u900f\u660e\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2508.00401", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.00401", "abs": "https://arxiv.org/abs/2508.00401", "authors": ["Riddhi J. Pitliya", "Ozan Catal", "Toon Van de Maele", "Corrado Pezzato", "Tim Verbelen"], "title": "Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation", "comment": null, "summary": "We present a novel approach to multi-agent cooperation by implementing theory\nof mind (ToM) within active inference. ToM - the ability to understand that\nothers can have differing knowledge and goals - enables agents to reason about\nothers' beliefs while planning their own actions. Unlike previous active\ninference approaches to multi-agent cooperation, our method neither relies on\ntask-specific shared generative models nor requires explicit communication,\nwhile being generalisable. In our framework, the ToM-equipped agent maintains\ndistinct representations of its own and others' beliefs and goals. We extend\nthe sophisticated inference tree-based planning algorithm to systematically\nexplore joint policy spaces through recursive reasoning. Our approach is\nevaluated through collision avoidance and foraging task simulations. Results\ndemonstrate that ToM-equipped agents cooperate better compared to non-ToM\ncounterparts by being able to avoid collisions and reduce redundant efforts.\nCrucially, ToM agents accomplish this by inferring others' beliefs solely from\nobservable behaviour. This work advances practical applications in artificial\nintelligence while providing computational insights into ToM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5fc3\u667a\u7406\u8bba\uff08ToM\uff09\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3b\u52a8\u63a8\u7406\u5b9e\u73b0\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u7684\u5171\u4eab\u751f\u6210\u6a21\u578b\u6216\u663e\u5f0f\u901a\u4fe1\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u5728\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4e2d\u5229\u7528ToM\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u63a8\u7406\u4ed6\u4eba\u7684\u4fe1\u5ff5\u548c\u76ee\u6807\uff0c\u4ece\u800c\u66f4\u9ad8\u6548\u5730\u5408\u4f5c\u3002", "method": "\u6269\u5c55\u4e86\u57fa\u4e8e\u63a8\u7406\u6811\u7684\u89c4\u5212\u7b97\u6cd5\uff0c\u901a\u8fc7\u9012\u5f52\u63a8\u7406\u63a2\u7d22\u8054\u5408\u7b56\u7565\u7a7a\u95f4\uff0c\u667a\u80fd\u4f53\u7ef4\u62a4\u81ea\u8eab\u548c\u4ed6\u4eba\u4fe1\u5ff5\u53ca\u76ee\u6807\u7684\u72ec\u7acb\u8868\u793a\u3002", "result": "\u5728\u78b0\u649e\u907f\u514d\u548c\u89c5\u98df\u4efb\u52a1\u4e2d\uff0cToM\u667a\u80fd\u4f53\u8868\u73b0\u4f18\u4e8e\u975eToM\u667a\u80fd\u4f53\uff0c\u80fd\u51cf\u5c11\u78b0\u649e\u548c\u5197\u4f59\u52aa\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63a8\u52a8\u4e86\u4eba\u5de5\u667a\u80fd\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u8fd8\u4e3aToM\u7684\u8ba1\u7b97\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2508.00131", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00131", "abs": "https://arxiv.org/abs/2508.00131", "authors": ["Christopher Harvey", "Sumaiya Shomaji", "Zijun Yao", "Amit Noheria"], "title": "ECG Latent Feature Extraction with Autoencoders for Downstream Prediction Tasks", "comment": "arXiv admin note: substantial text overlap with arXiv:2410.02937", "summary": "The electrocardiogram (ECG) is an inexpensive and widely available tool for\ncardiac assessment. Despite its standardized format and small file size, the\nhigh complexity and inter-individual variability of ECG signals (typically a\n60,000-size vector with 12 leads at 500 Hz) make it challenging to use in deep\nlearning models, especially when only small training datasets are available.\nThis study addresses these challenges by exploring feature generation methods\nfrom representative beat ECGs, focusing on Principal Component Analysis (PCA)\nand Autoencoders to reduce data complexity. We introduce three novel\nVariational Autoencoder (VAE) variants-Stochastic Autoencoder (SAE), Annealed\nbeta-VAE (A beta-VAE), and Cyclical beta VAE (C beta-VAE)-and compare their\neffectiveness in maintaining signal fidelity and enhancing downstream\nprediction tasks using a Light Gradient Boost Machine (LGBM). The A beta-VAE\nachieved superior signal reconstruction, reducing the mean absolute error (MAE)\nto 15.7+/-3.2 muV, which is at the level of signal noise. Moreover, the SAE\nencodings, when combined with traditional ECG summary features, improved the\nprediction of reduced Left Ventricular Ejection Fraction (LVEF), achieving an\nholdout test set area under the receiver operating characteristic curve (AUROC)\nof 0.901 with a LGBM classifier. This performance nearly matches the 0.909\nAUROC of state-of-the-art CNN model but requires significantly less\ncomputational resources. Further, the ECG feature extraction-LGBM pipeline\navoids overfitting and retains predictive performance when trained with less\ndata. Our findings demonstrate that these VAE encodings are not only effective\nin simplifying ECG data but also provide a practical solution for applying deep\nlearning in contexts with limited-scale labeled training data.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7PCA\u548c\u81ea\u52a8\u7f16\u7801\u5668\u7b80\u5316ECG\u4fe1\u53f7\u7684\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e09\u79cd\u65b0\u7684VAE\u53d8\u4f53\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4fe1\u53f7\u91cd\u5efa\u548c\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "ECG\u4fe1\u53f7\u590d\u6742\u4e14\u4e2a\u4f53\u5dee\u5f02\u5927\uff0c\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u7684\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e09\u79cdVAE\u53d8\u4f53\uff08SAE\u3001A beta-VAE\u3001C beta-VAE\uff09\uff0c\u7ed3\u5408PCA\u548c\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u7528\u4e8eECG\u4fe1\u53f7\u964d\u7ef4\u548c\u7279\u5f81\u63d0\u53d6\u3002", "result": "A beta-VAE\u5728\u4fe1\u53f7\u91cd\u5efa\u4e2d\u8868\u73b0\u6700\u4f73\uff08MAE\u4e3a15.7\u00b13.2 \u03bcV\uff09\uff0cSAE\u7f16\u7801\u7ed3\u5408\u4f20\u7edf\u7279\u5f81\u63d0\u9ad8\u4e86LVEF\u9884\u6d4b\uff08AUROC 0.901\uff09\u3002", "conclusion": "\u63d0\u51fa\u7684VAE\u53d8\u4f53\u4e0d\u4ec5\u7b80\u5316\u4e86ECG\u6570\u636e\uff0c\u8fd8\u4e3a\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\u7684\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00414", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00414", "abs": "https://arxiv.org/abs/2508.00414", "authors": ["Tianqing Fang", "Zhisong Zhang", "Xiaoyang Wang", "Rui Wang", "Can Qin", "Yuxuan Wan", "Jun-Yu Ma", "Ce Zhang", "Jiaqi Chen", "Xiyun Li", "Hongming Zhang", "Haitao Mi", "Dong Yu"], "title": "Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training", "comment": "16 pages", "summary": "General AI Agents are increasingly recognized as foundational frameworks for\nthe next generation of artificial intelligence, enabling complex reasoning, web\ninteraction, coding, and autonomous research capabilities. However, current\nagent systems are either closed-source or heavily reliant on a variety of paid\nAPIs and proprietary tools, limiting accessibility and reproducibility for the\nresearch community. In this work, we present \\textbf{Cognitive Kernel-Pro}, a\nfully open-source and (to the maximum extent) free multi-module agent framework\ndesigned to democratize the development and evaluation of advanced AI agents.\nWithin Cognitive Kernel-Pro, we systematically investigate the curation of\nhigh-quality training data for Agent Foundation Models, focusing on the\nconstruction of queries, trajectories, and verifiable answers across four key\ndomains: web, file, code, and general reasoning. Furthermore, we explore novel\nstrategies for agent test-time reflection and voting to enhance agent\nrobustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving\nstate-of-the-art results among open-source and free agents. Notably, our\n8B-parameter open-source model surpasses previous leading systems such as\nWebDancer and WebSailor, establishing a new performance standard for\naccessible, high-capability AI agents. Code is available at\nhttps://github.com/Tencent/CognitiveKernel-Pro", "AI": {"tldr": "Cognitive Kernel-Pro \u662f\u4e00\u4e2a\u5b8c\u5168\u5f00\u6e90\u4e14\u514d\u8d39\u7684 AI \u4ee3\u7406\u6846\u67b6\uff0c\u65e8\u5728\u63a8\u52a8\u9ad8\u7ea7 AI \u4ee3\u7406\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d AI \u4ee3\u7406\u7cfb\u7edf\u591a\u4e3a\u95ed\u6e90\u6216\u4f9d\u8d56\u4ed8\u8d39 API\uff0c\u9650\u5236\u4e86\u7814\u7a76\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u8bad\u7ec3\u6570\u636e\uff08\u67e5\u8be2\u3001\u8f68\u8ff9\u548c\u53ef\u9a8c\u8bc1\u7b54\u6848\uff09\uff0c\u5e76\u63a2\u7d22\u4ee3\u7406\u6d4b\u8bd5\u65f6\u7684\u53cd\u601d\u548c\u6295\u7968\u7b56\u7565\u3002", "result": "\u5728 GAIA \u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCognitive Kernel-Pro \u53d6\u5f97\u4e86\u5f00\u6e90\u4ee3\u7406\u4e2d\u7684\u6700\u4f73\u6027\u80fd\uff0c8B \u53c2\u6570\u6a21\u578b\u8d85\u8d8a\u4e86 WebDancer \u548c WebSailor\u3002", "conclusion": "Cognitive Kernel-Pro \u4e3a\u9ad8\u6027\u80fd\u3001\u53ef\u8bbf\u95ee\u7684 AI \u4ee3\u7406\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\u3002"}}
{"id": "2508.00141", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00141", "abs": "https://arxiv.org/abs/2508.00141", "authors": ["Mohit Gupta", "Debjit Bhowmick", "Rhys Newbury", "Meead Saberi", "Shirui Pan", "Ben Beck"], "title": "INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling Network Prediction via Reinforcement Learning Boosted Graph Neural Networks", "comment": null, "summary": "Accurate link-level bicycling volume estimation is essential for sustainable\nurban transportation planning. However, many cities face significant challenges\nof high data sparsity due to limited bicycling count sensor coverage. To\naddress this issue, we propose INSPIRE-GNN, a novel Reinforcement Learning\n(RL)-boosted hybrid Graph Neural Network (GNN) framework designed to optimize\nsensor placement and improve link-level bicycling volume estimation in\ndata-sparse environments. INSPIRE-GNN integrates Graph Convolutional Networks\n(GCN) and Graph Attention Networks (GAT) with a Deep Q-Network (DQN)-based RL\nagent, enabling a data-driven strategic selection of sensor locations to\nmaximize estimation performance. Applied to Melbourne's bicycling network,\ncomprising 15,933 road segments with sensor coverage on only 141 road segments\n(99% sparsity) - INSPIRE-GNN demonstrates significant improvements in volume\nestimation by strategically selecting additional sensor locations in\ndeployments of 50, 100, 200 and 500 sensors. Our framework outperforms\ntraditional heuristic methods for sensor placement such as betweenness\ncentrality, closeness centrality, observed bicycling activity and random\nplacement, across key metrics such as Mean Squared Error (MSE), Root Mean\nSquared Error (RMSE) and Mean Absolute Error (MAE). Furthermore, our\nexperiments benchmark INSPIRE-GNN against standard machine learning and deep\nlearning models in the bicycle volume estimation performance, underscoring its\neffectiveness. Our proposed framework provides transport planners actionable\ninsights to effectively expand sensor networks, optimize sensor placement and\nmaximize volume estimation accuracy and reliability of bicycling data for\ninformed transportation planning decisions.", "AI": {"tldr": "INSPIRE-GNN\u662f\u4e00\u79cd\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u7a00\u758f\u6570\u636e\u73af\u5883\u4e2d\u7684\u81ea\u884c\u8f66\u6d41\u91cf\u4f20\u611f\u5668\u5e03\u5c40\u548c\u4f30\u8ba1\u3002", "motivation": "\u89e3\u51b3\u57ce\u5e02\u81ea\u884c\u8f66\u6d41\u91cf\u6570\u636e\u7a00\u758f\u6027\u95ee\u9898\uff0c\u63d0\u5347\u4ea4\u901a\u89c4\u5212\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u7ed3\u5408\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u3001\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff08GAT\uff09\u548c\u6df1\u5ea6Q\u7f51\u7edc\uff08DQN\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\uff0c\u4f18\u5316\u4f20\u611f\u5668\u5e03\u5c40\u3002", "result": "\u5728\u58a8\u5c14\u672c\u81ea\u884c\u8f66\u7f51\u7edc\u4e2d\uff0cINSPIRE-GNN\u663e\u8457\u63d0\u5347\u4e86\u6d41\u91cf\u4f30\u8ba1\u6027\u80fd\uff0c\u4f18\u4e8e\u4f20\u7edf\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u5176\u4ed6\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4ea4\u901a\u89c4\u5212\u8005\u63d0\u4f9b\u4e86\u4f18\u5316\u4f20\u611f\u5668\u7f51\u7edc\u548c\u63d0\u5347\u6570\u636e\u53ef\u9760\u6027\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2508.00459", "categories": ["cs.AI", "68T07, 68T20", "I.2.6; I.2.7; I.2.3"], "pdf": "https://arxiv.org/pdf/2508.00459", "abs": "https://arxiv.org/abs/2508.00459", "authors": ["Andrea Asperti", "Alberto Naibo", "Claudio Sacerdoti Coen"], "title": "Thinking Machines: Mathematical Reasoning in the Age of LLMs", "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable abilities in structured\nreasoning and symbolic tasks, with coding emerging as a particular area of\nstrength. This success has sparked growing interest in applying LLMs to\nmathematics, both in informal problem-solving and formal theorem proving.\nHowever, progress in formal mathematics has proven to be significantly more\ndifficult, despite surface-level similarities between programming and proof\nconstruction. This discrepancy raises important questions about how LLMs\n``reason'', how they are supervised, and whether they internally track a notion\nof computational or deductive state. In this article, we address the\nstate-of-the-art of the discipline, focusing on recent models and benchmarks,\nand explore three central issues at the intersection of machine learning and\nmathematical cognition: (i) the trade-offs between formal and informal\nmathematics as training domains; (ii) the deeper reasons why proof generation\nremains more brittle than code synthesis; (iii) and the question of whether\nLLMs represent, or merely mimic, a notion of evolving logical state. Our goal\nis not to draw hard boundaries, but to identify where the current limits lie,\nand how they might be extended.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6570\u5b66\u9886\u57df\u7684\u5e94\u7528\uff0c\u5c24\u5176\u662f\u5f62\u5f0f\u5316\u6570\u5b66\u8bc1\u660e\u4e2d\u7684\u6311\u6218\uff0c\u5206\u6790\u4e86\u5176\u4e0e\u4ee3\u7801\u5408\u6210\u7684\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u4e86\u4e09\u4e2a\u6838\u5fc3\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u7f16\u7a0b\u548c\u7b26\u53f7\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5f62\u5f0f\u5316\u6570\u5b66\u8bc1\u660e\u4e2d\u8fdb\u5c55\u7f13\u6162\uff0c\u8fd9\u5f15\u53d1\u4e86\u5bf9LLMs\u63a8\u7406\u65b9\u5f0f\u3001\u76d1\u7763\u65b9\u6cd5\u53ca\u5176\u5185\u90e8\u72b6\u6001\u8868\u793a\u7684\u7591\u95ee\u3002", "method": "\u6587\u7ae0\u7efc\u8ff0\u4e86\u8be5\u9886\u57df\u7684\u6700\u65b0\u6a21\u578b\u548c\u57fa\u51c6\uff0c\u91cd\u70b9\u63a2\u8ba8\u4e86\u5f62\u5f0f\u5316\u4e0e\u975e\u5f62\u5f0f\u5316\u6570\u5b66\u7684\u8bad\u7ec3\u6743\u8861\u3001\u8bc1\u660e\u751f\u6210\u8106\u5f31\u6027\u7684\u539f\u56e0\uff0c\u4ee5\u53caLLMs\u662f\u5426\u771f\u6b63\u8868\u793a\u903b\u8f91\u72b6\u6001\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cLLMs\u5728\u5f62\u5f0f\u5316\u6570\u5b66\u8bc1\u660e\u4e2d\u7684\u8868\u73b0\u4e0d\u5982\u4ee3\u7801\u5408\u6210\uff0c\u63ed\u793a\u4e86\u5176\u63a8\u7406\u548c\u72b6\u6001\u8ddf\u8e2a\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u6587\u7ae0\u65e8\u5728\u660e\u786e\u5f53\u524d\u6280\u672f\u7684\u8fb9\u754c\uff0c\u5e76\u63d0\u51fa\u53ef\u80fd\u7684\u6269\u5c55\u65b9\u5411\uff0c\u800c\u975e\u5212\u5b9a\u786c\u6027\u754c\u9650\u3002"}}
{"id": "2508.00161", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00161", "abs": "https://arxiv.org/abs/2508.00161", "authors": ["Ziqian Zhong", "Aditi Raghunathan"], "title": "Watch the Weights: Unsupervised monitoring and control of fine-tuned LLMs", "comment": null, "summary": "The releases of powerful open-weight large language models (LLMs) are often\nnot accompanied by access to their full training data. Existing\ninterpretability methods, particularly those based on activations, often\nrequire or assume distributionally similar data. This is a significant\nlimitation when detecting and defending against novel potential threats like\nbackdoors, which are by definition out-of-distribution.\n  In this work, we introduce a new method for understanding, monitoring and\ncontrolling fine-tuned LLMs that interprets weights, rather than activations,\nthereby side stepping the need for data that is distributionally similar to the\nunknown training data. We demonstrate that the top singular vectors of the\nweight difference between a fine-tuned model and its base model correspond to\nnewly acquired behaviors. By monitoring the cosine similarity of activations\nalong these directions, we can detect salient behaviors introduced during\nfine-tuning with high precision.\n  For backdoored models that bypasses safety mechanisms when a secret trigger\nis present, our method stops up to 100% of attacks with a false positive rate\nbelow 1.2%. For models that have undergone unlearning, we detect inference on\nerased topics with accuracy up to 95.42% and can even steer the model to\nrecover \"unlearned\" information. Besides monitoring, our method also shows\npotential for pre-deployment model auditing: by analyzing commercial\ninstruction-tuned models (OLMo, Llama, Qwen), we are able to uncover\nmodel-specific fine-tuning focus including marketing strategies and Midjourney\nprompt generation.\n  Our implementation can be found at https://github.com/fjzzq2002/WeightWatch.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6743\u91cd\u800c\u975e\u6fc0\u6d3b\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u7406\u89e3\u548c\u76d1\u63a7\u5fae\u8c03\u540e\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u65e0\u9700\u4f9d\u8d56\u4e0e\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u76f8\u4f3c\u7684\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6fc0\u6d3b\u7684\u89e3\u91ca\u65b9\u6cd5\u9700\u8981\u5206\u5e03\u76f8\u4f3c\u7684\u6570\u636e\uff0c\u9650\u5236\u4e86\u5176\u5728\u68c0\u6d4b\u65b0\u578b\u5a01\u80c1\uff08\u5982\u540e\u95e8\uff09\u65f6\u7684\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5fae\u8c03\u6a21\u578b\u4e0e\u57fa\u7840\u6a21\u578b\u6743\u91cd\u5dee\u5f02\u7684\u9876\u90e8\u5947\u5f02\u5411\u91cf\uff0c\u8bc6\u522b\u65b0\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u6fc0\u6d3b\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u76d1\u63a7\u8fd9\u4e9b\u884c\u4e3a\u3002", "result": "\u65b9\u6cd5\u5728\u540e\u95e8\u653b\u51fb\u68c0\u6d4b\u4e2d\u8fbe\u5230100%\u62e6\u622a\u7387\uff08\u5047\u9633\u6027\u7387\u4f4e\u4e8e1.2%\uff09\uff0c\u5728\u672a\u5b66\u4e60\u6a21\u578b\u4e2d\u5bf9\u5df2\u5220\u9664\u4e3b\u9898\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe95.42%\uff0c\u5e76\u80fd\u6062\u590d\u201c\u672a\u5b66\u4e60\u201d\u4fe1\u606f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u6a21\u578b\u76d1\u63a7\uff0c\u8fd8\u53ef\u7528\u4e8e\u9884\u90e8\u7f72\u5ba1\u8ba1\uff0c\u63ed\u793a\u4e86\u5546\u4e1a\u6a21\u578b\u5fae\u8c03\u7684\u7279\u5b9a\u5173\u6ce8\u70b9\u3002"}}
{"id": "2508.00500", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00500", "abs": "https://arxiv.org/abs/2508.00500", "authors": ["Haoyu Wang", "Chris M. Poskitt", "Jun Sun", "Jiali Wei"], "title": "Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking", "comment": null, "summary": "Large Language Model (LLM) agents exhibit powerful autonomous capabilities\nacross domains such as robotics, virtual assistants, and web automation.\nHowever, their stochastic behavior introduces significant safety risks that are\ndifficult to anticipate. Existing rule-based enforcement systems, such as\nAgentSpec, focus on developing reactive safety rules, which typically respond\nonly when unsafe behavior is imminent or has already occurred. These systems\nlack foresight and struggle with long-horizon dependencies and distribution\nshifts. To address these limitations, we propose Pro2Guard, a proactive runtime\nenforcement framework grounded in probabilistic reachability analysis.\nPro2Guard abstracts agent behaviors into symbolic states and learns a\nDiscrete-Time Markov Chain (DTMC) from execution traces. At runtime, it\nanticipates future risks by estimating the probability of reaching unsafe\nstates, triggering interventions before violations occur when the predicted\nrisk exceeds a user-defined threshold. By incorporating semantic validity\nchecks and leveraging PAC bounds, Pro2Guard ensures statistical reliability\nwhile approximating the underlying ground-truth model. We evaluate Pro2Guard\nextensively across two safety-critical domains: embodied household agents and\nautonomous vehicles. In embodied agent tasks, Pro2Guard enforces safety early\non up to 93.6% of unsafe tasks using low thresholds, while configurable modes\n(e.g., reflect) allow balancing safety with task success, maintaining up to\n80.4% task completion. In autonomous driving scenarios, Pro2Guard achieves 100%\nprediction of traffic law violations and collisions, anticipating risks up to\n38.66 seconds ahead.", "AI": {"tldr": "Pro2Guard\u662f\u4e00\u4e2a\u57fa\u4e8e\u6982\u7387\u53ef\u8fbe\u6027\u5206\u6790\u7684\u4e3b\u52a8\u8fd0\u884c\u65f6\u5b89\u5168\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u548c\u9884\u9632LLM\u4ee3\u7406\u7684\u4e0d\u5b89\u5168\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c4\u5219\u7684\u5b89\u5168\u7cfb\u7edf\uff08\u5982AgentSpec\uff09\u7f3a\u4e4f\u9884\u89c1\u6027\uff0c\u96be\u4ee5\u5e94\u5bf9\u957f\u671f\u4f9d\u8d56\u548c\u5206\u5e03\u53d8\u5316\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u4e3b\u52a8\u7684\u5b89\u5168\u6846\u67b6\u3002", "method": "Pro2Guard\u5c06\u4ee3\u7406\u884c\u4e3a\u62bd\u8c61\u4e3a\u7b26\u53f7\u72b6\u6001\uff0c\u5e76\u4ece\u6267\u884c\u8f68\u8ff9\u4e2d\u5b66\u4e60\u79bb\u6563\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\uff08DTMC\uff09\uff0c\u5728\u8fd0\u884c\u65f6\u901a\u8fc7\u4f30\u8ba1\u5230\u8fbe\u4e0d\u5b89\u5168\u72b6\u6001\u7684\u6982\u7387\u6765\u9884\u6d4b\u98ce\u9669\u3002", "result": "\u5728\u5bb6\u5ead\u4ee3\u7406\u548c\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e2d\uff0cPro2Guard\u5206\u522b\u5b9e\u73b0\u4e8693.6%\u548c100%\u7684\u4e0d\u5b89\u5168\u884c\u4e3a\u9884\u6d4b\uff0c\u5e76\u80fd\u63d0\u524d\u5e72\u9884\u3002", "conclusion": "Pro2Guard\u901a\u8fc7\u4e3b\u52a8\u9884\u6d4b\u548c\u5e72\u9884\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u4ee3\u7406\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4efb\u52a1\u5b8c\u6210\u7387\u3002"}}
{"id": "2508.00172", "categories": ["cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2508.00172", "abs": "https://arxiv.org/abs/2508.00172", "authors": ["Fupei Guo", "Hao Zheng", "Xiang Zhang", "Li Chen", "Yue Wang", "Songyang Zhang"], "title": "DiSC-Med: Diffusion-based Semantic Communications for Robust Medical Image Transmission", "comment": "To appear in 2025 IEEE Global Communications Conference (Globecom)", "summary": "The rapid development of artificial intelligence has driven smart health with\nnext-generation wireless communication technologies, stimulating exciting\napplications in remote diagnosis and intervention. To enable a timely and\neffective response for remote healthcare, efficient transmission of medical\ndata through noisy channels with limited bandwidth emerges as a critical\nchallenge. In this work, we propose a novel diffusion-based semantic\ncommunication framework, namely DiSC-Med, for the medical image transmission,\nwhere medical-enhanced compression and denoising blocks are developed for\nbandwidth efficiency and robustness, respectively. Unlike conventional\npixel-wise communication framework, our proposed DiSC-Med is able to capture\nthe key semantic information and achieve superior reconstruction performance\nwith ultra-high bandwidth efficiency against noisy channels. Extensive\nexperiments on real-world medical datasets validate the effectiveness of our\nframework, demonstrating its potential for robust and efficient telehealth\napplications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u8bed\u4e49\u901a\u4fe1\u6846\u67b6DiSC-Med\uff0c\u7528\u4e8e\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u533b\u5b66\u56fe\u50cf\u4f20\u8f93\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u548c\u65e0\u7ebf\u901a\u4fe1\u6280\u672f\u7684\u53d1\u5c55\u63a8\u52a8\u4e86\u8fdc\u7a0b\u533b\u7597\uff0c\u4f46\u533b\u5b66\u6570\u636e\u5728\u6709\u9650\u5e26\u5bbd\u548c\u566a\u58f0\u4fe1\u9053\u4e2d\u7684\u9ad8\u6548\u4f20\u8f93\u6210\u4e3a\u5173\u952e\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u533b\u5b66\u589e\u5f3a\u7684\u538b\u7f29\u548c\u53bb\u566a\u6a21\u5757\uff0c\u7528\u4e8e\u63d0\u9ad8\u5e26\u5bbd\u6548\u7387\u548c\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u8bed\u4e49\u4fe1\u606f\u6355\u83b7\u5b9e\u73b0\u9ad8\u6548\u91cd\u5efa\u3002", "result": "\u5728\u771f\u5b9e\u533b\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u663e\u793a\u51fa\u5728\u8fdc\u7a0b\u533b\u7597\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "DiSC-Med\u5728\u566a\u58f0\u4fe1\u9053\u4e2d\u5b9e\u73b0\u4e86\u8d85\u9ad8\u5e26\u5bbd\u6548\u7387\u548c\u4f18\u5f02\u7684\u91cd\u5efa\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u8fdc\u7a0b\u533b\u7597\u5e94\u7528\u3002"}}
{"id": "2508.00576", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00576", "abs": "https://arxiv.org/abs/2508.00576", "authors": ["Zhanliang Wang", "Kai Wang"], "title": "MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal Interactions in Multimodal AI Models", "comment": null, "summary": "Multimodal AI models have achieved impressive performance in tasks that\nrequire integrating information from multiple modalities, such as vision and\nlanguage. However, their \"black-box\" nature poses a major barrier to deployment\nin high-stakes applications where interpretability and trustworthiness are\nessential. How to explain cross-modal interactions in multimodal AI models\nremains a major challenge. While existing model explanation methods, such as\nattention map and Grad-CAM, offer coarse insights into cross-modal\nrelationships, they cannot precisely quantify the synergistic effects between\nmodalities, and are limited to open-source models with accessible internal\nweights. Here we introduce MultiSHAP, a model-agnostic interpretability\nframework that leverages the Shapley Interaction Index to attribute multimodal\npredictions to pairwise interactions between fine-grained visual and textual\nelements (such as image patches and text tokens), while being applicable to\nboth open- and closed-source models. Our approach provides: (1) instance-level\nexplanations that reveal synergistic and suppressive cross-modal effects for\nindividual samples - \"why the model makes a specific prediction on this input\",\nand (2) dataset-level explanation that uncovers generalizable interaction\npatterns across samples - \"how the model integrates information across\nmodalities\". Experiments on public multimodal benchmarks confirm that MultiSHAP\nfaithfully captures cross-modal reasoning mechanisms, while real-world case\nstudies demonstrate its practical utility. Our framework is extensible beyond\ntwo modalities, offering a general solution for interpreting complex multimodal\nAI models.", "AI": {"tldr": "MultiSHAP\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u53ef\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u591a\u6a21\u6001AI\u6a21\u578b\u4e2d\u89c6\u89c9\u548c\u6587\u672c\u5143\u7d20\u4e4b\u95f4\u7684\u534f\u540c\u6548\u5e94\uff0c\u9002\u7528\u4e8e\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u3002", "motivation": "\u591a\u6a21\u6001AI\u6a21\u578b\u7684'\u9ed1\u76d2'\u7279\u6027\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u9650\u5236\u4e86\u5176\u90e8\u7f72\uff0c\u73b0\u6709\u89e3\u91ca\u65b9\u6cd5\u65e0\u6cd5\u7cbe\u786e\u91cf\u5316\u6a21\u6001\u95f4\u7684\u534f\u540c\u6548\u5e94\u3002", "method": "\u5229\u7528Shapley Interaction Index\uff0c\u5c06\u591a\u6a21\u6001\u9884\u6d4b\u5f52\u56e0\u4e8e\u89c6\u89c9\u548c\u6587\u672c\u5143\u7d20\u7684\u6210\u5bf9\u4ea4\u4e92\uff0c\u63d0\u4f9b\u5b9e\u4f8b\u7ea7\u548c\u6570\u636e\u96c6\u7ea7\u89e3\u91ca\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eMultiSHAP\u80fd\u51c6\u786e\u6355\u6349\u8de8\u6a21\u6001\u63a8\u7406\u673a\u5236\uff0c\u5e76\u5728\u5b9e\u9645\u6848\u4f8b\u4e2d\u5c55\u793a\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "MultiSHAP\u4e3a\u89e3\u91ca\u590d\u6742\u591a\u6a21\u6001AI\u6a21\u578b\u63d0\u4f9b\u4e86\u901a\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u53ef\u6269\u5c55\u81f3\u8d85\u8fc7\u4e24\u79cd\u6a21\u6001\u3002"}}
{"id": "2508.00174", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00174", "abs": "https://arxiv.org/abs/2508.00174", "authors": ["Yongchao Huang"], "title": "RL as Regressor: A Reinforcement Learning Approach for Function Approximation", "comment": "7 pages", "summary": "Standard regression techniques, while powerful, are often constrained by\npredefined, differentiable loss functions such as mean squared error. These\nfunctions may not fully capture the desired behavior of a system, especially\nwhen dealing with asymmetric costs or complex, non-differentiable objectives.\nIn this paper, we explore an alternative paradigm: framing regression as a\nReinforcement Learning (RL) problem. We demonstrate this by treating a model's\nprediction as an action and defining a custom reward signal based on the\nprediction error, and we can leverage powerful RL algorithms to perform\nfunction approximation. Through a progressive case study of learning a noisy\nsine wave, we illustrate the development of an Actor-Critic agent, iteratively\nenhancing it with Prioritized Experience Replay, increased network capacity,\nand positional encoding to enable a capable RL agent for this regression task.\nOur results show that the RL framework not only successfully solves the\nregression problem but also offers enhanced flexibility in defining objectives\nand guiding the learning process.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06\u56de\u5f52\u95ee\u9898\u8f6c\u5316\u4e3a\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u5b9a\u4e49\u5956\u52b1\u4fe1\u53f7\u548cRL\u7b97\u6cd5\u89e3\u51b3\u4f20\u7edf\u56de\u5f52\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u56de\u5f52\u65b9\u6cd5\u53d7\u9650\u4e8e\u9884\u5b9a\u4e49\u7684\u53ef\u5fae\u635f\u5931\u51fd\u6570\uff0c\u65e0\u6cd5\u7075\u6d3b\u5904\u7406\u975e\u5bf9\u79f0\u6210\u672c\u6216\u590d\u6742\u76ee\u6807\u3002", "method": "\u5c06\u6a21\u578b\u9884\u6d4b\u89c6\u4e3a\u52a8\u4f5c\uff0c\u5b9a\u4e49\u57fa\u4e8e\u9884\u6d4b\u8bef\u5dee\u7684\u81ea\u5b9a\u4e49\u5956\u52b1\u4fe1\u53f7\uff0c\u5229\u7528Actor-Critic\u7b97\u6cd5\u53ca\u6539\u8fdb\u6280\u672f\uff08\u5982\u4f18\u5148\u7ecf\u9a8c\u56de\u653e\u3001\u7f51\u7edc\u5bb9\u91cf\u6269\u5c55\u548c\u4f4d\u7f6e\u7f16\u7801\uff09\u8fdb\u884c\u51fd\u6570\u903c\u8fd1\u3002", "result": "RL\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u56de\u5f52\u95ee\u9898\uff0c\u5e76\u5728\u76ee\u6807\u5b9a\u4e49\u548c\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u7075\u6d3b\u6027\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u4e3a\u56de\u5f52\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u9002\u5e94\u590d\u6742\u548c\u975e\u53ef\u5fae\u7684\u76ee\u6807\u3002"}}
{"id": "2508.00581", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00581", "abs": "https://arxiv.org/abs/2508.00581", "authors": ["Ruiqing Ding", "Qianfang Sun", "Yongkang Leng", "Hui Yin", "Xiaojian Li"], "title": "From EMR Data to Clinical Insight: An LLM-Driven Framework for Automated Pre-Consultation Questionnaire Generation", "comment": "16 pages, 10 figures", "summary": "Pre-consultation is a critical component of effective healthcare delivery.\nHowever, generating comprehensive pre-consultation questionnaires from complex,\nvoluminous Electronic Medical Records (EMRs) is a challenging task. Direct\nLarge Language Model (LLM) approaches face difficulties in this task,\nparticularly regarding information completeness, logical order, and\ndisease-level synthesis. To address this issue, we propose a novel multi-stage\nLLM-driven framework: Stage 1 extracts atomic assertions (key facts with\ntiming) from EMRs; Stage 2 constructs personal causal networks and synthesizes\ndisease knowledge by clustering representative networks from an EMR corpus;\nStage 3 generates tailored personal and standardized disease-specific\nquestionnaires based on these structured representations. This framework\novercomes limitations of direct methods by building explicit clinical\nknowledge. Evaluated on a real-world EMR dataset and validated by clinical\nexperts, our method demonstrates superior performance in information coverage,\ndiagnostic relevance, understandability, and generation time, highlighting its\npractical potential to enhance patient information collection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9636\u6bb5LLM\u9a71\u52a8\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u590d\u6742\u7535\u5b50\u75c5\u5386\u751f\u6210\u5168\u9762\u7684\u9884\u54a8\u8be2\u95ee\u5377\uff0c\u89e3\u51b3\u4e86\u76f4\u63a5LLM\u65b9\u6cd5\u5728\u4fe1\u606f\u5b8c\u6574\u6027\u3001\u903b\u8f91\u987a\u5e8f\u548c\u75be\u75c5\u7ea7\u5408\u6210\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u9884\u54a8\u8be2\u662f\u533b\u7597\u4fdd\u5065\u7684\u5173\u952e\u73af\u8282\uff0c\u4f46\u4ece\u590d\u6742\u7535\u5b50\u75c5\u5386\u751f\u6210\u95ee\u5377\u5177\u6709\u6311\u6218\u6027\uff0c\u76f4\u63a5LLM\u65b9\u6cd5\u5728\u4fe1\u606f\u5b8c\u6574\u6027\u548c\u903b\u8f91\u6027\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u5206\u4e09\u9636\u6bb5\uff1a1\uff09\u63d0\u53d6\u539f\u5b50\u65ad\u8a00\uff1b2\uff09\u6784\u5efa\u4e2a\u4eba\u56e0\u679c\u7f51\u7edc\u5e76\u5408\u6210\u75be\u75c5\u77e5\u8bc6\uff1b3\uff09\u751f\u6210\u4e2a\u6027\u5316\u53ca\u6807\u51c6\u5316\u95ee\u5377\u3002", "result": "\u5728\u771f\u5b9e\u7535\u5b50\u75c5\u5386\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u65b9\u6cd5\u5728\u4fe1\u606f\u8986\u76d6\u3001\u8bca\u65ad\u76f8\u5173\u6027\u3001\u53ef\u7406\u89e3\u6027\u548c\u751f\u6210\u65f6\u95f4\u4e0a\u8868\u73b0\u4f18\u8d8a\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6784\u5efa\u663e\u5f0f\u4e34\u5e8a\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u54a8\u8be2\u95ee\u5377\u7684\u8d28\u91cf\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.00180", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.00180", "abs": "https://arxiv.org/abs/2508.00180", "authors": ["Adam Block", "Cyril Zhang"], "title": "EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes", "comment": null, "summary": "Stochasticity in language model fine-tuning, often caused by the small batch\nsizes typically used in this regime, can destabilize training by introducing\nlarge oscillations in generation quality. A popular approach to mitigating this\ninstability is to take an Exponential moving average (EMA) of weights\nthroughout training. While EMA reduces stochasticity, thereby smoothing\ntraining, the introduction of bias from old iterates often creates a lag in\noptimization relative to vanilla training. In this work, we propose the\nBias-Corrected Exponential Moving Average (BEMA), a simple and practical\naugmentation of EMA that retains variance-reduction benefits while eliminating\nbias. BEMA is motivated by a simple theoretical model wherein we demonstrate\nprovable acceleration of BEMA over both a standard EMA and vanilla training.\nThrough an extensive suite of experiments on Language Models, we show that BEMA\nleads to significantly improved convergence rates and final performance over\nboth EMA and vanilla training in a variety of standard LM benchmarks, making\nBEMA a practical and theoretically motivated intervention for more stable and\nefficient fine-tuning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u6307\u6570\u79fb\u52a8\u5e73\u5747\u65b9\u6cd5\uff08BEMA\uff09\uff0c\u7528\u4e8e\u51cf\u5c11\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e2d\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u907f\u514d\u4f20\u7edfEMA\u5f15\u5165\u7684\u504f\u5dee\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e2d\u7684\u968f\u673a\u6027\uff08\u5982\u5c0f\u6279\u91cf\u8bad\u7ec3\uff09\u4f1a\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff0c\u4f20\u7edfEMA\u65b9\u6cd5\u867d\u80fd\u5e73\u6ed1\u8bad\u7ec3\u4f46\u4f1a\u5f15\u5165\u504f\u5dee\uff0c\u5f71\u54cd\u4f18\u5316\u901f\u5ea6\u3002", "method": "\u63d0\u51faBEMA\u65b9\u6cd5\uff0c\u901a\u8fc7\u6821\u6b63\u504f\u5dee\u4fdd\u7559EMA\u7684\u65b9\u5dee\u51cf\u5c11\u4f18\u52bf\uff0c\u540c\u65f6\u6d88\u9664\u504f\u5dee\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eBEMA\u5728\u591a\u79cd\u8bed\u8a00\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6536\u655b\u901f\u5ea6\u548c\u6700\u7ec8\u6027\u80fd\u3002", "conclusion": "BEMA\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u7406\u8bba\u652f\u6301\u7684\u65b9\u6cd5\uff0c\u80fd\u66f4\u7a33\u5b9a\u9ad8\u6548\u5730\u8fdb\u884c\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u3002"}}
{"id": "2508.00201", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00201", "abs": "https://arxiv.org/abs/2508.00201", "authors": ["Mehdi Ben Ayed", "Fei Feng", "Jay Adams", "Vishwakarma Singh", "Kritarth Anand", "Jiajing Xu"], "title": "RecoMind: A Reinforcement Learning Framework for Optimizing In-Session User Satisfaction in Recommendation Systems", "comment": null, "summary": "Existing web-scale recommendation systems commonly use supervised learning\nmethods that prioritize immediate user feedback. Although reinforcement\nlearning (RL) offers a solution to optimize longer-term goals, such as\nin-session engagement, applying it at web scale is challenging due to the\nextremely large action space and engineering complexity. In this paper, we\nintroduce RecoMind, a simulator-based RL framework designed for the effective\noptimization of session-based goals at web-scale. RecoMind leverages existing\nrecommendation models to establish a simulation environment and to bootstrap\nthe RL policy to optimize immediate user interactions from the outset. This\nmethod integrates well with existing industry pipelines, simplifying the\ntraining and deployment of RL policies. Additionally, RecoMind introduces a\ncustom exploration strategy to efficiently explore web-scale action spaces with\nhundreds of millions of items. We evaluated RecoMind through extensive offline\nsimulations and online A/B testing on a video streaming platform. Both methods\nshowed that the RL policy trained using RecoMind significantly outperforms\ntraditional supervised learning recommendation approaches in in-session user\nsatisfaction. In online A/B tests, the RL policy increased videos watched for\nmore than 10 seconds by 15.81\\% and improved session depth by 4.71\\% for\nsessions with at least 10 interactions. As a result, RecoMind presents a\nsystematic and scalable approach for embedding RL into web-scale recommendation\nsystems, showing great promise for optimizing session-based user satisfaction.", "AI": {"tldr": "RecoMind\u662f\u4e00\u4e2a\u57fa\u4e8e\u6a21\u62df\u5668\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u5927\u89c4\u6a21\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u4f1a\u8bdd\u76ee\u6807\uff0c\u663e\u8457\u63d0\u5347\u7528\u6237\u6ee1\u610f\u5ea6\u3002", "motivation": "\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u76d1\u7763\u5b66\u4e60\uff0c\u96be\u4ee5\u4f18\u5316\u957f\u671f\u76ee\u6807\uff08\u5982\u4f1a\u8bdd\u53c2\u4e0e\u5ea6\uff09\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u9762\u4e34\u5de5\u7a0b\u590d\u6742\u6027\u6311\u6218\u3002", "method": "RecoMind\u5229\u7528\u73b0\u6709\u63a8\u8350\u6a21\u578b\u6784\u5efa\u6a21\u62df\u73af\u5883\uff0c\u5e76\u901a\u8fc7\u81ea\u5b9a\u4e49\u63a2\u7d22\u7b56\u7565\u9ad8\u6548\u63a2\u7d22\u5927\u89c4\u6a21\u52a8\u4f5c\u7a7a\u95f4\uff0c\u7b80\u5316RL\u7b56\u7565\u7684\u8bad\u7ec3\u548c\u90e8\u7f72\u3002", "result": "\u79bb\u7ebf\u6a21\u62df\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u8868\u660e\uff0cRecoMind\u8bad\u7ec3\u7684RL\u7b56\u7565\u5728\u4f1a\u8bdd\u7528\u6237\u6ee1\u610f\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u89c6\u9891\u89c2\u770b\u65f6\u957f\u548c\u4f1a\u8bdd\u6df1\u5ea6\u5747\u6709\u63d0\u5347\u3002", "conclusion": "RecoMind\u4e3a\u5927\u89c4\u6a21\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684RL\u5d4c\u5165\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u4f18\u5316\u4f1a\u8bdd\u7528\u6237\u6ee1\u610f\u5ea6\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2508.00658", "categories": ["cs.AI", "cs.LG", "econ.EM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2508.00658", "abs": "https://arxiv.org/abs/2508.00658", "authors": ["Chakattrai Sookkongwaree", "Tattep Lakmuang", "Chainarong Amornbunchornvej"], "title": "Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies", "comment": "First draft", "summary": "Understanding causal relationships in time series is fundamental to many\ndomains, including neuroscience, economics, and behavioral science. Granger\ncausality is one of the well-known techniques for inferring causality in time\nseries. Typically, Granger causality frameworks have a strong fix-lag\nassumption between cause and effect, which is often unrealistic in complex\nsystems. While recent work on variable-lag Granger causality (VLGC) addresses\nthis limitation by allowing a cause to influence an effect with different time\nlags at each time point, it fails to account for the fact that causal\ninteractions may vary not only in time delay but also across frequency bands.\nFor example, in brain signals, alpha-band activity may influence another region\nwith a shorter delay than slower delta-band oscillations. In this work, we\nformalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a\nnovel framework that generalizes traditional VLGC by explicitly modeling\nfrequency-dependent causal delays. We provide a formal definition of MB-VLGC,\ndemonstrate its theoretical soundness, and propose an efficient inference\npipeline. Extensive experiments across multiple domains demonstrate that our\nframework significantly outperforms existing methods on both synthetic and\nreal-world datasets, confirming its broad applicability to any type of time\nseries data. Code and datasets are publicly available.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9891\u5e26\u53ef\u53d8\u6ede\u540e\u683c\u5170\u6770\u56e0\u679c\u5173\u7cfb\uff08MB-VLGC\uff09\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u9891\u7387\u4f9d\u8d56\u6027\u56e0\u679c\u5ef6\u8fdf\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u683c\u5170\u6770\u56e0\u679c\u5173\u7cfb\u65b9\u6cd5\u5047\u8bbe\u56fa\u5b9a\u7684\u65f6\u95f4\u6ede\u540e\uff0c\u800c\u53ef\u53d8\u6ede\u540e\u65b9\u6cd5\uff08VLGC\uff09\u867d\u7136\u89e3\u51b3\u4e86\u65f6\u95f4\u5ef6\u8fdf\u53d8\u5316\u7684\u95ee\u9898\uff0c\u4f46\u5ffd\u7565\u4e86\u56e0\u679c\u5ef6\u8fdf\u53ef\u80fd\u5728\u4e0d\u540c\u9891\u5e26\u4e0a\u53d8\u5316\u7684\u60c5\u51b5\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86MB-VLGC\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u9891\u7387\u4f9d\u8d56\u6027\u56e0\u679c\u5ef6\u8fdf\uff0c\u6269\u5c55\u4e86\u4f20\u7edfVLGC\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u8bc1\u660e\u548c\u9ad8\u6548\u63a8\u7406\u6d41\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMB-VLGC\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MB-VLGC\u6846\u67b6\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u7c7b\u578b\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002"}}
{"id": "2508.00202", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.00202", "abs": "https://arxiv.org/abs/2508.00202", "authors": ["Ecem Bozkurt", "Antonio Ortega"], "title": "Robust Classification under Noisy Labels: A Geometry-Aware Reliability Framework for Foundation Models", "comment": "5 pages, 2 figures, under review at CAMSAP 2025", "summary": "Foundation models (FMs) pretrained on large datasets have become fundamental\nfor various downstream machine learning tasks, in particular in scenarios where\nobtaining perfectly labeled data is prohibitively expensive. In this paper, we\nassume an FM has to be fine-tuned with noisy data and present a two-stage\nframework to ensure robust classification in the presence of label noise\nwithout model retraining. Recent work has shown that simple k-nearest neighbor\n(kNN) approaches using an embedding derived from an FM can achieve good\nperformance even in the presence of severe label noise. Our work is motivated\nby the fact that these methods make use of local geometry. In this paper,\nfollowing a similar two-stage procedure, reliability estimation followed by\nreliability-weighted inference, we show that improved performance can be\nachieved by introducing geometry information. For a given instance, our\nproposed inference uses a local neighborhood of training data, obtained using\nthe non-negative kernel (NNK) neighborhood construction. We propose several\nmethods for reliability estimation that can rely less on distance and local\nneighborhood as the label noise increases. Our evaluation on CIFAR-10 and\nDermaMNIST shows that our methods improve robustness across various noise\nconditions, surpassing standard K-NN approaches and recent\nadaptive-neighborhood baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5229\u7528\u51e0\u4f55\u4fe1\u606f\u5728\u6807\u7b7e\u566a\u58f0\u4e0b\u5b9e\u73b0\u9c81\u68d2\u5206\u7c7b\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002", "motivation": "\u5728\u6807\u7b7e\u566a\u58f0\u73af\u5883\u4e0b\uff0c\u73b0\u6709kNN\u65b9\u6cd5\u4f9d\u8d56\u5c40\u90e8\u51e0\u4f55\u4fe1\u606f\uff0c\u4f46\u6027\u80fd\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u53ef\u9760\u6027\u4f30\u8ba1\u548c\u53ef\u9760\u6027\u52a0\u6743\u63a8\u65ad\uff0c\u5f15\u5165\u975e\u8d1f\u6838\uff08NNK\uff09\u90bb\u57df\u6784\u5efa\u3002", "result": "\u5728CIFAR-10\u548cDermaMNIST\u4e0a\uff0c\u65b9\u6cd5\u4f18\u4e8e\u6807\u51c6kNN\u548c\u81ea\u9002\u5e94\u90bb\u57df\u57fa\u7ebf\u3002", "conclusion": "\u901a\u8fc7\u51e0\u4f55\u4fe1\u606f\u6539\u8fdb\u7684\u53ef\u9760\u6027\u4f30\u8ba1\u548c\u63a8\u65ad\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6807\u7b7e\u566a\u58f0\u4e0b\u7684\u5206\u7c7b\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.00665", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00665", "abs": "https://arxiv.org/abs/2508.00665", "authors": ["Maryam Mosleh", "Marie Devlin", "Ellis Solaiman"], "title": "Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI", "comment": null, "summary": "Artificial intelligence-driven adaptive learning systems are reshaping\neducation through data-driven adaptation of learning experiences. Yet many of\nthese systems lack transparency, offering limited insight into how decisions\nare made. Most explainable AI (XAI) techniques focus on technical outputs but\nneglect user roles and comprehension. This paper proposes a hybrid framework\nthat integrates traditional XAI techniques with generative AI models and user\npersonalisation to generate multimodal, personalised explanations tailored to\nuser needs. We redefine explainability as a dynamic communication process\ntailored to user roles and learning goals. We outline the framework's design,\nkey XAI limitations in education, and research directions on accuracy,\nfairness, and personalisation. Our aim is to move towards explainable AI that\nenhances transparency while supporting user-centred experiences.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4f20\u7edf\u53ef\u89e3\u91caAI\u6280\u672f\u4e0e\u751f\u6210\u5f0fAI\u6a21\u578b\u7684\u6df7\u5408\u6846\u67b6\uff0c\u65e8\u5728\u4e3a\u6559\u80b2\u9886\u57df\u63d0\u4f9b\u591a\u6a21\u6001\u3001\u4e2a\u6027\u5316\u7684\u89e3\u91ca\uff0c\u4ee5\u589e\u5f3a\u900f\u660e\u5ea6\u548c\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u5f53\u524d\u81ea\u9002\u5e94\u5b66\u4e60\u7cfb\u7edf\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u4e14\u73b0\u6709\u53ef\u89e3\u91caAI\u6280\u672f\u5ffd\u89c6\u7528\u6237\u89d2\u8272\u548c\u7406\u89e3\u80fd\u529b\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u52a8\u6001\u3001\u7528\u6237\u4e2d\u5fc3\u7684\u65b9\u6cd5\u3002", "method": "\u6574\u5408\u4f20\u7edfXAI\u6280\u672f\u4e0e\u751f\u6210\u5f0fAI\u6a21\u578b\uff0c\u7ed3\u5408\u7528\u6237\u4e2a\u6027\u5316\u9700\u6c42\uff0c\u8bbe\u8ba1\u52a8\u6001\u89e3\u91ca\u6846\u67b6\u3002", "result": "\u91cd\u65b0\u5b9a\u4e49\u53ef\u89e3\u91ca\u6027\u4e3a\u52a8\u6001\u6c9f\u901a\u8fc7\u7a0b\uff0c\u63d0\u51fa\u6846\u67b6\u8bbe\u8ba1\u5e76\u63a2\u8ba8\u6559\u80b2\u4e2dXAI\u7684\u5c40\u9650\u6027\u53ca\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u76ee\u6807\u662f\u63a8\u52a8\u53ef\u89e3\u91caAI\u5728\u589e\u5f3a\u900f\u660e\u5ea6\u7684\u540c\u65f6\u652f\u6301\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u4f53\u9a8c\u3002"}}
{"id": "2508.00230", "categories": ["cs.LG", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.00230", "abs": "https://arxiv.org/abs/2508.00230", "authors": ["Paul Albert", "Frederic Z. Zhang", "Hemanth Saratchandran", "Anton van den Hengel", "Ehsan Abbasnejad"], "title": "Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product", "comment": "To appear in ICCV 2025", "summary": "Parameter-efficient fine-tuning (PEFT) has become a standard approach for\nadapting large pre-trained models. Amongst PEFT methods, low-rank adaptation\n(LoRA) has achieved notable success. However, recent studies have highlighted\nits limitations compared against full-rank alternatives, particularly when\napplied to multimodal and large language models. In this work, we present a\nquantitative comparison amongst full-rank and low-rank PEFT methods using a\nsynthetic matrix approximation benchmark with controlled spectral properties.\nOur results confirm that LoRA struggles to approximate matrices with relatively\nflat spectrums or high frequency components -- signs of high effective ranks.\nTo this end, we introduce KRAdapter, a novel PEFT algorithm that leverages the\nKhatri-Rao product to produce weight updates, which, by construction, tends to\nproduce matrix product with a high effective rank. We demonstrate performance\ngains with KRAdapter on vision-language models up to 1B parameters and on large\nlanguage models up to 8B parameters, particularly on unseen common-sense\nreasoning tasks. In addition, KRAdapter maintains the memory and compute\nefficiency of LoRA, making it a practical and robust alternative to fine-tune\nbillion-scale parameter models.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u548c\u5168\u79e9PEFT\u65b9\u6cd5\uff0c\u53d1\u73b0LoRA\u5728\u8fd1\u4f3c\u5e73\u5766\u8c31\u6216\u9ad8\u9891\u77e9\u9635\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5KRAdapter\uff0c\u5229\u7528Khatri-Rao\u79ef\u751f\u6210\u9ad8\u6709\u6548\u79e9\u7684\u6743\u91cd\u66f4\u65b0\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u4f18\u52bf\u3002", "motivation": "\u7814\u7a76LoRA\u5728\u591a\u6a21\u6001\u548c\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63a2\u7d22\u66f4\u9ad8\u6548\u7684PEFT\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5408\u6210\u77e9\u9635\u8fd1\u4f3c\u57fa\u51c6\u5b9a\u91cf\u6bd4\u8f83\u5168\u79e9\u548c\u4f4e\u79e9PEFT\u65b9\u6cd5\uff0c\u63d0\u51faKRAdapter\u7b97\u6cd5\u3002", "result": "KRAdapter\u5728\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u8868\u73b0\u4f18\u4e8eLoRA\uff0c\u5c24\u5176\u5728\u672a\u89c1\u5e38\u8bc6\u63a8\u7406\u4efb\u52a1\u4e2d\u3002", "conclusion": "KRAdapter\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u5b9e\u7528\u7684PEFT\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5341\u4ebf\u7ea7\u53c2\u6570\u6a21\u578b\u7684\u5fae\u8c03\u3002"}}
{"id": "2508.00674", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00674", "abs": "https://arxiv.org/abs/2508.00674", "authors": ["Banan Alkhateeb", "Ellis Solaiman"], "title": "Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations", "comment": null, "summary": "Social media platforms today strive to improve user experience through AI\nrecommendations, yet the value of such recommendations vanishes as users do not\nunderstand the reasons behind them. This issue arises because explainability in\nsocial media is general and lacks alignment with user-specific needs. In this\nvision paper, we outline a user-segmented and context-aware explanation layer\nby proposing a visual explanation system with diverse explanation methods. The\nproposed system is framed by the variety of user needs and contexts, showing\nexplanations in different visualized forms, including a technically detailed\nversion for AI experts and a simplified one for lay users. Our framework is the\nfirst to jointly adapt explanation style (visual vs. numeric) and granularity\n(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will\nvalidate its impact on decision-making and trust.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u6237\u5206\u6bb5\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u89e3\u91ca\u7cfb\u7edf\uff0c\u901a\u8fc7\u53ef\u89c6\u5316\u65b9\u6cd5\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u63a8\u8350\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u9002\u5e94\u4e0d\u540c\u7528\u6237\u9700\u6c42\u3002", "motivation": "\u5f53\u524d\u793e\u4ea4\u5a92\u4f53\u63a8\u8350\u7cfb\u7edf\u7684\u89e3\u91ca\u6027\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u4e0e\u7528\u6237\u7279\u5b9a\u9700\u6c42\u7684\u5339\u914d\uff0c\u5bfc\u81f4\u7528\u6237\u5bf9\u63a8\u8350\u7684\u7406\u89e3\u548c\u4fe1\u4efb\u5ea6\u4e0b\u964d\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u89c6\u89c9\u89e3\u91ca\u7cfb\u7edf\uff0c\u63d0\u4f9b\u591a\u6837\u5316\u7684\u89e3\u91ca\u65b9\u6cd5\uff0c\u5305\u62ec\u6280\u672f\u8be6\u7ec6\u7248\u548c\u7b80\u5316\u7248\uff0c\u9002\u5e94\u4e0d\u540c\u7528\u6237\uff08\u5982\u4e13\u5bb6\u548c\u666e\u901a\u7528\u6237\uff09\u3002", "result": "\u7cfb\u7edf\u9996\u6b21\u5728\u540c\u4e00\u6d41\u7a0b\u4e2d\u8054\u5408\u8c03\u6574\u89e3\u91ca\u98ce\u683c\uff08\u89c6\u89c9\u4e0e\u6570\u5b57\uff09\u548c\u7c92\u5ea6\uff08\u4e13\u5bb6\u4e0e\u666e\u901a\uff09\uff0c\u5e76\u901a\u8fc730\u540dX\u7528\u6237\u7684\u516c\u5f00\u8bd5\u70b9\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u7528\u6237\u5bf9\u63a8\u8350\u7684\u7406\u89e3\u548c\u4fe1\u4efb\uff0c\u4e3a\u793e\u4ea4\u5a92\u4f53\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.00264", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.00264", "abs": "https://arxiv.org/abs/2508.00264", "authors": ["Jerry Huang", "Peng Lu", "Qiuhao Zeng"], "title": "Calibrated Language Models and How to Find Them with Label Smoothing", "comment": "Accepted to the Forty-second International Conference on Machine\n  Learning (ICML) 2025. First two authors contributed equally", "summary": "Recent advances in natural language processing (NLP) have opened up greater\nopportunities to enable fine-tuned large language models (LLMs) to behave as\nmore powerful interactive agents through improved instruction-following\nability. However, understanding how this impacts confidence calibration for\nreliable model output has not been researched in full. In this work, we examine\nvarious open-sourced LLMs, identifying significant calibration degradation\nafter instruction tuning in each. Seeking a practical solution, we look towards\nlabel smoothing, which has been shown as an effective method to regularize for\noverconfident predictions but has yet to be widely adopted in the supervised\nfine-tuning (SFT) of LLMs. We first provide insight as to why label smoothing\nis sufficient to maintain calibration throughout the SFT process. However,\nsettings remain where the effectiveness of smoothing is severely diminished, in\nparticular the case of large vocabulary LLMs (LV-LLMs). We posit the cause to\nstem from the ability to become over-confident, which has a direct relationship\nwith the hidden size and vocabulary size, and justify this theoretically and\nexperimentally. Finally, we address an outstanding issue regarding the memory\nfootprint of the cross-entropy loss computation in the label smoothed loss\nsetting, designing a customized kernel to dramatically reduce memory\nconsumption without sacrificing speed or performance in comparison to existing\nsolutions for non-smoothed losses.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u6307\u4ee4\u5fae\u8c03\u4f1a\u5bfc\u81f4\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u9000\u5316\uff0c\u63d0\u51fa\u6807\u7b7e\u5e73\u6ed1\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u9488\u5bf9\u5927\u8bcd\u6c47\u91cfLLMs\u7684\u95ee\u9898\u8fdb\u884c\u4e86\u7406\u8bba\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u540c\u65f6\u4f18\u5316\u4e86\u5185\u5b58\u6d88\u8017\u3002", "motivation": "\u5c3d\u7ba1NLP\u548cLLMs\u7684\u8fdb\u6b65\u63d0\u5347\u4e86\u4ea4\u4e92\u80fd\u529b\uff0c\u4f46\u6307\u4ee4\u5fae\u8c03\u5bf9\u6a21\u578b\u8f93\u51fa\u7f6e\u4fe1\u5ea6\u6821\u51c6\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5f00\u6e90LLMs\uff0c\u53d1\u73b0\u6307\u4ee4\u5fae\u8c03\u5bfc\u81f4\u6821\u51c6\u9000\u5316\uff0c\u63d0\u51fa\u6807\u7b7e\u5e73\u6ed1\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u9488\u5bf9\u5927\u8bcd\u6c47\u91cfLLMs\u7684\u95ee\u9898\u8fdb\u884c\u7406\u8bba\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u6807\u7b7e\u5e73\u6ed1\u80fd\u6709\u6548\u7ef4\u6301\u6821\u51c6\uff0c\u4f46\u5728\u5927\u8bcd\u6c47\u91cfLLMs\u4e2d\u6548\u679c\u53d7\u9650\uff0c\u901a\u8fc7\u5b9a\u5236\u5185\u6838\u4f18\u5316\u4e86\u5185\u5b58\u6d88\u8017\u3002", "conclusion": "\u6807\u7b7e\u5e73\u6ed1\u662f\u6307\u4ee4\u5fae\u8c03\u4e2d\u7ef4\u6301\u6821\u51c6\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4f46\u9700\u9488\u5bf9\u5927\u8bcd\u6c47\u91cfLLMs\u8fdb\u4e00\u6b65\u4f18\u5316\u3002"}}
{"id": "2508.00784", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00784", "abs": "https://arxiv.org/abs/2508.00784", "authors": ["Tom Or", "Omri Azencot"], "title": "Unraveling Hidden Representations: A Multi-Modal Layer Analysis for Better Synthetic Content Forensics", "comment": null, "summary": "Generative models achieve remarkable results in multiple data domains,\nincluding images and texts, among other examples. Unfortunately, malicious\nusers exploit synthetic media for spreading misinformation and disseminating\ndeepfakes. Consequently, the need for robust and stable fake detectors is\npressing, especially when new generative models appear everyday. While the\nmajority of existing work train classifiers that discriminate between real and\nfake information, such tools typically generalize only within the same family\nof generators and data modalities, yielding poor results on other generative\nclasses and data domains. Towards a universal classifier, we propose the use of\nlarge pre-trained multi-modal models for the detection of generative content.\nEffectively, we show that the latent code of these models naturally captures\ninformation discriminating real from fake. Building on this observation, we\ndemonstrate that linear classifiers trained on these features can achieve\nstate-of-the-art results across various modalities, while remaining\ncomputationally efficient, fast to train, and effective even in few-shot\nsettings. Our work primarily focuses on fake detection in audio and images,\nachieving performance that surpasses or matches that of strong baseline\nmethods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u6a21\u578b\u7684\u901a\u7528\u751f\u6210\u5185\u5bb9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u5176\u6f5c\u5728\u7f16\u7801\u533a\u5206\u771f\u5b9e\u4e0e\u865a\u5047\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u8de8\u6a21\u6001\u7684\u9ad8\u6548\u68c0\u6d4b\u3002", "motivation": "\u751f\u6210\u6a21\u578b\u5728\u591a\u4e2a\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u88ab\u6076\u610f\u7528\u4e8e\u4f20\u64ad\u865a\u5047\u4fe1\u606f\uff0c\u73b0\u6709\u68c0\u6d4b\u5de5\u5177\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u4e9f\u9700\u901a\u7528\u4e14\u7a33\u5b9a\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u5927\u578b\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u6a21\u578b\u7684\u6f5c\u5728\u7f16\u7801\uff0c\u8bad\u7ec3\u7ebf\u6027\u5206\u7c7b\u5668\u8fdb\u884c\u751f\u6210\u5185\u5bb9\u68c0\u6d4b\uff0c\u9002\u7528\u4e8e\u97f3\u9891\u548c\u56fe\u50cf\u7b49\u591a\u79cd\u6a21\u6001\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u8de8\u6a21\u6001\u68c0\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8ba1\u7b97\u9ad8\u6548\u4e14\u9002\u7528\u4e8e\u5c11\u6837\u672c\u573a\u666f\uff0c\u6027\u80fd\u8d85\u8d8a\u6216\u5339\u914d\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u6a21\u578b\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u901a\u7528\u7684\u751f\u6210\u5185\u5bb9\u68c0\u6d4b\uff0c\u4e3a\u865a\u5047\u4fe1\u606f\u8bc6\u522b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.00270", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00270", "abs": "https://arxiv.org/abs/2508.00270", "authors": ["Robin Schmucker", "Nimish Pachapurkar", "Shanmuga Bala", "Miral Shah", "Tom Mitchell"], "title": "Learning to Optimize Feedback for One Million Students: Insights from Multi-Armed and Contextual Bandits in Large-Scale Online Tutoring", "comment": null, "summary": "We present an online tutoring system that learns to provide effective\nfeedback to students after they answer questions incorrectly. Using data from\none million students, the system learns which assistance action (e.g., one of\nmultiple hints) to provide for each question to optimize student learning.\nEmploying the multi-armed bandit (MAB) framework and offline policy evaluation,\nwe assess 43,000 assistance actions, and identify trade-offs between assistance\npolicies optimized for different student outcomes (e.g., response correctness,\nsession completion). We design an algorithm that for each question decides on a\nsuitable policy training objective to enhance students' immediate second\nattempt success and overall practice session performance. We evaluate the\nresulting MAB policies in 166,000 practice sessions, verifying significant\nimprovements in student outcomes. While MAB policies optimize feedback for the\noverall student population, we further investigate whether contextual bandit\n(CB) policies can enhance outcomes by personalizing feedback based on\nindividual student features (e.g., ability estimates, response times). Using\ncausal inference, we examine (i) how effects of assistance actions vary across\nstudents and (ii) whether CB policies, which leverage such effect\nheterogeneity, outperform MAB policies. While our analysis reveals that some\nactions for some questions exhibit effect heterogeneity, effect sizes may often\nbe too small for CB policies to provide significant improvements beyond what\nwell-optimized MAB policies that deliver the same action to all students\nalready achieve. We discuss insights gained from deploying data-driven systems\nat scale and implications for future refinements. Today, the teaching policies\noptimized by our system support thousands of students daily.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5728\u7ebf\u8f85\u5bfc\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6\u548c\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\uff0c\u4f18\u5316\u5b66\u751f\u53cd\u9988\u4ee5\u63d0\u9ad8\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u76ee\u6807\u662f\u63d0\u4f9b\u6709\u6548\u7684\u53cd\u9988\u4ee5\u4f18\u5316\u5b66\u751f\u5b66\u4e60\uff0c\u5e76\u63a2\u7d22\u4e2a\u6027\u5316\u53cd\u9988\u7684\u6f5c\u529b\u3002", "method": "\u4f7f\u7528\u591a\u81c2\u8001\u864e\u673a\uff08MAB\uff09\u6846\u67b6\u548c\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\uff0c\u5206\u679043,000\u4e2a\u8f85\u52a9\u52a8\u4f5c\uff0c\u5e76\u8bbe\u8ba1\u7b97\u6cd5\u9009\u62e9\u9002\u5408\u7684\u7b56\u7565\u76ee\u6807\u3002\u8fdb\u4e00\u6b65\u7814\u7a76\u4e0a\u4e0b\u6587\u8001\u864e\u673a\uff08CB\uff09\u7b56\u7565\u7684\u4e2a\u6027\u5316\u6548\u679c\u3002", "result": "\u5728166,000\u6b21\u7ec3\u4e60\u4f1a\u8bdd\u4e2d\u9a8c\u8bc1\uff0cMAB\u7b56\u7565\u663e\u8457\u6539\u5584\u5b66\u751f\u8868\u73b0\u3002CB\u7b56\u7565\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u6548\u679c\u6709\u9650\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u7cfb\u7edf\u5728\u5927\u89c4\u6a21\u90e8\u7f72\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u4e2a\u6027\u5316\u53cd\u9988\u7684\u6548\u679c\u63d0\u5347\u6709\u9650\u3002"}}
{"id": "2508.00286", "categories": ["cs.LG", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.00286", "abs": "https://arxiv.org/abs/2508.00286", "authors": ["Mohsen Zaker Esteghamati"], "title": "Toward using explainable data-driven surrogate models for treating performance-based seismic design as an inverse engineering problem", "comment": null, "summary": "This study presents a methodology to treat performance-based seismic design\nas an inverse engineering problem, where design parameters are directly derived\nto achieve specific performance objectives. By implementing explainable machine\nlearning models, this methodology directly maps design variables and\nperformance metrics, tackling computational inefficiencies of performance-based\ndesign. The resultant machine learning model is integrated as an evaluation\nfunction into a genetic optimization algorithm to solve the inverse problem.\nThe developed methodology is then applied to two different inventories of steel\nand concrete moment frames in Los Angeles and Charleston to obtain sectional\nproperties of frame members that minimize expected annualized seismic loss in\nterms of repair costs. The results show high accuracy of the surrogate models\n(e.g., R2> 90%) across a diverse set of building types, geometries, seismic\ndesign, and site hazard, where the optimization algorithm could identify the\noptimum values of members' properties for a fixed set of geometric variables,\nconsistent with engineering principles.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u6297\u9707\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u9057\u4f20\u4f18\u5316\u7b97\u6cd5\u89e3\u51b3\u8bbe\u8ba1\u53c2\u6570\u4e0e\u6027\u80fd\u76ee\u6807\u4e4b\u95f4\u7684\u9006\u5411\u5de5\u7a0b\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9645\u5efa\u7b51\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u5176\u9ad8\u51c6\u786e\u6027\u548c\u5de5\u7a0b\u4e00\u81f4\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u6027\u80fd\u6297\u9707\u8bbe\u8ba1\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\uff0c\u901a\u8fc7\u9006\u5411\u5de5\u7a0b\u65b9\u6cd5\u76f4\u63a5\u6620\u5c04\u8bbe\u8ba1\u53d8\u91cf\u4e0e\u6027\u80fd\u6307\u6807\u3002", "method": "\u91c7\u7528\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6620\u5c04\u8bbe\u8ba1\u53d8\u91cf\u4e0e\u6027\u80fd\u6307\u6807\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u8bc4\u4f30\u51fd\u6570\u96c6\u6210\u5230\u9057\u4f20\u4f18\u5316\u7b97\u6cd5\u4e2d\u3002", "result": "\u5728\u591a\u79cd\u5efa\u7b51\u7c7b\u578b\u548c\u5730\u9707\u6761\u4ef6\u4e0b\uff0c\u6a21\u578b\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\uff08R2>90%\uff09\uff0c\u4f18\u5316\u7b97\u6cd5\u80fd\u8bc6\u522b\u7b26\u5408\u5de5\u7a0b\u539f\u5219\u7684\u6784\u4ef6\u6700\u4f18\u5c5e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6027\u80fd\u6297\u9707\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u7684\u5efa\u7b51\u548c\u5730\u9707\u6761\u4ef6\u3002"}}
{"id": "2508.00304", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00304", "abs": "https://arxiv.org/abs/2508.00304", "authors": ["Tianyin Liao", "Ziwei Zhang", "Yufei Sun", "Chunyu Hu", "Jianxin Li"], "title": "Invariant Graph Transformer for Out-of-Distribution Generalization", "comment": null, "summary": "Graph Transformers (GTs) have demonstrated great effectiveness across various\ngraph analytical tasks. However, the existing GTs focus on training and testing\ngraph data originated from the same distribution, but fail to generalize under\ndistribution shifts. Graph invariant learning, aiming to capture generalizable\ngraph structural patterns with labels under distribution shifts, is potentially\na promising solution, but how to design attention mechanisms and positional and\nstructural encodings (PSEs) based on graph invariant learning principles\nremains challenging. To solve these challenges, we introduce Graph\nOut-Of-Distribution generalized Transformer (GOODFormer), aiming to learn\ngeneralized graph representations by capturing invariant relationships between\npredictive graph structures and labels through jointly optimizing three\nmodules. Specifically, we first develop a GT-based entropy-guided invariant\nsubgraph disentangler to separate invariant and variant subgraphs while\npreserving the sharpness of the attention function. Next, we design an evolving\nsubgraph positional and structural encoder to effectively and efficiently\ncapture the encoding information of dynamically changing subgraphs during\ntraining. Finally, we propose an invariant learning module utilizing subgraph\nnode representations and encodings to derive generalizable graph\nrepresentations that can to unseen graphs. We also provide theoretical\njustifications for our method. Extensive experiments on benchmark datasets\ndemonstrate the superiority of our method over state-of-the-art baselines under\ndistribution shifts.", "AI": {"tldr": "GOODFormer\u662f\u4e00\u79cd\u57fa\u4e8e\u56fe\u4e0d\u53d8\u5b66\u4e60\u7684Transformer\u6a21\u578b\uff0c\u65e8\u5728\u89e3\u51b3\u56fe\u6570\u636e\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u79bb\u4e0d\u53d8\u548c\u53d8\u4f53\u5b50\u56fe\u3001\u52a8\u6001\u7f16\u7801\u548c\u4e0d\u53d8\u5b66\u4e60\u6a21\u5757\u5b9e\u73b0\u3002", "motivation": "\u73b0\u6709\u56feTransformer\u5728\u6570\u636e\u5206\u5e03\u504f\u79fb\u4e0b\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u56fe\u4e0d\u53d8\u5b66\u4e60\u53ef\u80fd\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5982\u4f55\u8bbe\u8ba1\u76f8\u5173\u673a\u5236\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u63d0\u51faGOODFormer\uff0c\u5305\u542b\u71b5\u5f15\u5bfc\u7684\u4e0d\u53d8\u5b50\u56fe\u5206\u79bb\u5668\u3001\u52a8\u6001\u5b50\u56fe\u7f16\u7801\u5668\u548c\u4e0d\u53d8\u5b66\u4e60\u6a21\u5757\uff0c\u8054\u5408\u4f18\u5316\u4ee5\u6355\u6349\u4e0d\u53d8\u5173\u7cfb\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cGOODFormer\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "GOODFormer\u901a\u8fc7\u4e0d\u53d8\u5b66\u4e60\u673a\u5236\u6709\u6548\u63d0\u5347\u56feTransformer\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.00325", "categories": ["cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2508.00325", "abs": "https://arxiv.org/abs/2508.00325", "authors": ["Yongquan Qu", "Matthieu Blanke", "Sara Shamekh", "Pierre Gentine"], "title": "PnP-DA: Towards Principled Plug-and-Play Integration of Variational Data Assimilation and Generative Models", "comment": null, "summary": "Earth system modeling presents a fundamental challenge in scientific\ncomputing: capturing complex, multiscale nonlinear dynamics in computationally\nefficient models while minimizing forecast errors caused by necessary\nsimplifications. Even the most powerful AI- or physics-based forecast system\nsuffer from gradual error accumulation. Data assimilation (DA) aims to mitigate\nthese errors by optimally blending (noisy) observations with prior model\nforecasts, but conventional variational methods often assume Gaussian error\nstatistics that fail to capture the true, non-Gaussian behavior of chaotic\ndynamical systems. We propose PnP-DA, a Plug-and-Play algorithm that alternates\n(1) a lightweight, gradient-based analysis update (using a Mahalanobis-distance\nmisfit on new observations) with (2) a single forward pass through a pretrained\ngenerative prior conditioned on the background forecast via a conditional\nWasserstein coupling. This strategy relaxes restrictive statistical assumptions\nand leverages rich historical data without requiring an explicit regularization\nfunctional, and it also avoids the need to backpropagate gradients through the\ncomplex neural network that encodes the prior during assimilation cycles.\nExperiments on standard chaotic testbeds demonstrate that this strategy\nconsistently reduces forecast errors across a range of observation sparsities\nand noise levels, outperforming classical variational methods.", "AI": {"tldr": "PnP-DA\u662f\u4e00\u79cd\u65b0\u7684\u6570\u636e\u540c\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u8f7b\u91cf\u7ea7\u68af\u5ea6\u66f4\u65b0\u548c\u9884\u8bad\u7ec3\u751f\u6210\u5148\u9a8c\uff0c\u51cf\u5c11\u5730\u7403\u7cfb\u7edf\u5efa\u6a21\u4e2d\u7684\u9884\u6d4b\u8bef\u5dee\u3002", "motivation": "\u5730\u7403\u7cfb\u7edf\u5efa\u6a21\u9700\u8981\u9ad8\u6548\u8ba1\u7b97\u590d\u6742\u591a\u5c3a\u5ea6\u975e\u7ebf\u6027\u52a8\u6001\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u56e0\u7b80\u5316\u5047\u8bbe\u5bfc\u81f4\u8bef\u5dee\u7d2f\u79ef\u3002\u6570\u636e\u540c\u5316\u65e8\u5728\u4f18\u5316\u89c2\u6d4b\u4e0e\u6a21\u578b\u9884\u6d4b\u7684\u878d\u5408\uff0c\u4f46\u4f20\u7edf\u53d8\u5206\u65b9\u6cd5\u5047\u8bbe\u9ad8\u65af\u8bef\u5dee\u7edf\u8ba1\uff0c\u65e0\u6cd5\u6355\u6349\u6df7\u6c8c\u7cfb\u7edf\u7684\u975e\u9ad8\u65af\u884c\u4e3a\u3002", "method": "PnP-DA\u4ea4\u66ff\u6267\u884c\u8f7b\u91cf\u7ea7\u68af\u5ea6\u5206\u6790\u66f4\u65b0\u548c\u9884\u8bad\u7ec3\u751f\u6210\u5148\u9a8c\u7684\u524d\u5411\u4f20\u9012\uff0c\u5229\u7528\u6761\u4ef6Wasserstein\u8026\u5408\uff0c\u907f\u514d\u590d\u6742\u795e\u7ecf\u7f51\u7edc\u7684\u53cd\u5411\u4f20\u64ad\u3002", "result": "\u5728\u6807\u51c6\u6df7\u6c8c\u6d4b\u8bd5\u4e2d\uff0cPnP-DA\u5728\u4e0d\u540c\u89c2\u6d4b\u7a00\u758f\u6027\u548c\u566a\u58f0\u6c34\u5e73\u4e0b\u5747\u80fd\u51cf\u5c11\u9884\u6d4b\u8bef\u5dee\uff0c\u4f18\u4e8e\u4f20\u7edf\u53d8\u5206\u65b9\u6cd5\u3002", "conclusion": "PnP-DA\u901a\u8fc7\u653e\u677e\u7edf\u8ba1\u5047\u8bbe\u548c\u5229\u7528\u5386\u53f2\u6570\u636e\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u7684\u6570\u636e\u540c\u5316\u7b56\u7565\u3002"}}
{"id": "2508.00331", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00331", "abs": "https://arxiv.org/abs/2508.00331", "authors": ["George Wang", "Garrett Baker", "Andrew Gordon", "Daniel Murfet"], "title": "Embryology of a Language Model", "comment": null, "summary": "Understanding how language models develop their internal computational\nstructure is a central problem in the science of deep learning. While\nsusceptibilities, drawn from statistical physics, offer a promising analytical\ntool, their full potential for visualizing network organization remains\nuntapped. In this work, we introduce an embryological approach, applying UMAP\nto the susceptibility matrix to visualize the model's structural development\nover training. Our visualizations reveal the emergence of a clear ``body\nplan,'' charting the formation of known features like the induction circuit and\ndiscovering previously unknown structures, such as a ``spacing fin'' dedicated\nto counting space tokens. This work demonstrates that susceptibility analysis\ncan move beyond validation to uncover novel mechanisms, providing a powerful,\nholistic lens for studying the developmental principles of complex neural\nnetworks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eUMAP\u548c\u654f\u611f\u6027\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u53ef\u89c6\u5316\u8bed\u8a00\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u7ed3\u6784\u53d1\u5c55\uff0c\u63ed\u793a\u4e86\u65b0\u7684\u7f51\u7edc\u673a\u5236\u3002", "motivation": "\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u7684\u5185\u90e8\u8ba1\u7b97\u7ed3\u6784\u662f\u6df1\u5ea6\u5b66\u4e60\u79d1\u5b66\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u654f\u611f\u6027\u5206\u6790\u4f5c\u4e3a\u5de5\u5177\u5c1a\u672a\u5145\u5206\u53d1\u6325\u6f5c\u529b\u3002", "method": "\u5e94\u7528UMAP\u5bf9\u654f\u611f\u6027\u77e9\u9635\u8fdb\u884c\u53ef\u89c6\u5316\uff0c\u5206\u6790\u6a21\u578b\u5728\u8bad\u7ec3\u4e2d\u7684\u7ed3\u6784\u53d1\u5c55\u3002", "result": "\u53ef\u89c6\u5316\u7ed3\u679c\u63ed\u793a\u4e86\u6a21\u578b\u7ed3\u6784\u7684\u201c\u8eab\u4f53\u8ba1\u5212\u201d\uff0c\u5305\u62ec\u5df2\u77e5\u7279\u5f81\uff08\u5982\u611f\u5e94\u7535\u8def\uff09\u548c\u65b0\u53d1\u73b0\u7684\u7ed3\u6784\uff08\u5982\u7528\u4e8e\u8ba1\u6570\u7a7a\u683c\u6807\u8bb0\u7684\u201c\u95f4\u8ddd\u9ccd\u201d\uff09\u3002", "conclusion": "\u654f\u611f\u6027\u5206\u6790\u4e0d\u4ec5\u80fd\u9a8c\u8bc1\u6a21\u578b\uff0c\u8fd8\u80fd\u53d1\u73b0\u65b0\u673a\u5236\uff0c\u4e3a\u7814\u7a76\u590d\u6742\u795e\u7ecf\u7f51\u7edc\u7684\u53d1\u80b2\u539f\u7406\u63d0\u4f9b\u4e86\u5168\u9762\u89c6\u89d2\u3002"}}
{"id": "2508.00350", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00350", "abs": "https://arxiv.org/abs/2508.00350", "authors": ["Qilin Liao", "Shuo Yang", "Bo Zhao", "Ping Luo", "Hengshuang Zhao"], "title": "BOOD: Boundary-based Out-Of-Distribution Data Generation", "comment": "14 pages, 8 figures, To be published in the Proceedings of the\n  International Conference on Machine Learning (ICML) 2025", "summary": "Harnessing the power of diffusion models to synthesize auxiliary training\ndata based on latent space features has proven effective in enhancing\nout-of-distribution (OOD) detection performance. However, extracting effective\nfeatures outside the in-distribution (ID) boundary in latent space remains\nchallenging due to the difficulty of identifying decision boundaries between\nclasses. This paper proposes a novel framework called Boundary-based\nOut-Of-Distribution data generation (BOOD), which synthesizes high-quality OOD\nfeatures and generates human-compatible outlier images using diffusion models.\nBOOD first learns a text-conditioned latent feature space from the ID dataset,\nselects ID features closest to the decision boundary, and perturbs them to\ncross the decision boundary to form OOD features. These synthetic OOD features\nare then decoded into images in pixel space by a diffusion model. Compared to\nprevious works, BOOD provides a more training efficient strategy for\nsynthesizing informative OOD features, facilitating clearer distinctions\nbetween ID and OOD data. Extensive experimental results on common benchmarks\ndemonstrate that BOOD surpasses the state-of-the-art method significantly,\nachieving a 29.64% decrease in average FPR95 (40.31% vs. 10.67%) and a 7.27%\nimprovement in average AUROC (90.15% vs. 97.42%) on the CIFAR-100 dataset.", "AI": {"tldr": "BOOD\u6846\u67b6\u5229\u7528\u6269\u6563\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cfOOD\u7279\u5f81\u548c\u56fe\u50cf\uff0c\u663e\u8457\u63d0\u5347OOD\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u63d0\u53d6\u6709\u6548OOD\u7279\u5f81\u7684\u6311\u6218\uff0c\u660e\u786eID\u4e0eOOD\u6570\u636e\u7684\u8fb9\u754c\u3002", "method": "\u901a\u8fc7\u6587\u672c\u6761\u4ef6\u6f5c\u5728\u7279\u5f81\u7a7a\u95f4\u5b66\u4e60\uff0c\u6270\u52a8ID\u8fb9\u754c\u7279\u5f81\u751f\u6210OOD\u7279\u5f81\uff0c\u5e76\u7528\u6269\u6563\u6a21\u578b\u89e3\u7801\u4e3a\u56fe\u50cf\u3002", "result": "\u5728CIFAR-100\u4e0a\uff0cFPR95\u964d\u4f4e29.64%\uff0cAUROC\u63d0\u53477.27%\u3002", "conclusion": "BOOD\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684OOD\u7279\u5f81\u751f\u6210\u65b9\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2508.00357", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00357", "abs": "https://arxiv.org/abs/2508.00357", "authors": ["Yoonhyuk Choi", "Jiho Choi", "Chong-Kwon Kim"], "title": "Sheaf Graph Neural Networks via PAC-Bayes Spectral Optimization", "comment": null, "summary": "Over-smoothing in Graph Neural Networks (GNNs) causes collapse in distinct\nnode features, particularly on heterophilic graphs where adjacent nodes often\nhave dissimilar labels. Although sheaf neural networks partially mitigate this\nproblem, they typically rely on static or heavily parameterized sheaf\nstructures that hinder generalization and scalability. Existing sheaf-based\nmodels either predefine restriction maps or introduce excessive complexity, yet\nfail to provide rigorous stability guarantees. In this paper, we introduce a\nnovel scheme called SGPC (Sheaf GNNs with PAC-Bayes Calibration), a unified\narchitecture that combines cellular-sheaf message passing with several\nmechanisms, including optimal transport-based lifting, variance-reduced\ndiffusion, and PAC-Bayes spectral regularization for robust semi-supervised\nnode classification. We establish performance bounds theoretically and\ndemonstrate that the resulting bound-aware objective can be achieved via\nend-to-end training in linear computational complexity. Experiments on nine\nhomophilic and heterophilic benchmarks show that SGPC outperforms\nstate-of-the-art spectral and sheaf-based GNNs while providing certified\nconfidence intervals on unseen nodes.", "AI": {"tldr": "SGPC\u662f\u4e00\u79cd\u7ed3\u5408\u4e86\u7ec6\u80de\u9798\u6d88\u606f\u4f20\u9012\u3001\u6700\u4f18\u4f20\u8f93\u63d0\u5347\u3001\u65b9\u5dee\u51cf\u5c11\u6269\u6563\u548cPAC-Bayes\u8c31\u6b63\u5219\u5316\u7684\u65b0\u578b\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7528\u4e8e\u89e3\u51b3\u5f02\u8d28\u56fe\u4e0a\u7684\u8fc7\u5e73\u6ed1\u95ee\u9898\uff0c\u5e76\u5728\u534a\u76d1\u7763\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u5f02\u8d28\u56fe\u4e0a\u56e0\u8fc7\u5e73\u6ed1\u5bfc\u81f4\u7684\u8282\u70b9\u7279\u5f81\u5d29\u6e83\u95ee\u9898\uff0c\u540c\u65f6\u514b\u670d\u73b0\u6709\u9798\u795e\u7ecf\u7f51\u7edc\u5728\u6cdb\u5316\u548c\u6269\u5c55\u6027\u4e0a\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faSGPC\u67b6\u6784\uff0c\u7ed3\u5408\u7ec6\u80de\u9798\u6d88\u606f\u4f20\u9012\u3001\u6700\u4f18\u4f20\u8f93\u63d0\u5347\u3001\u65b9\u5dee\u51cf\u5c11\u6269\u6563\u548cPAC-Bayes\u8c31\u6b63\u5219\u5316\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u8bad\u7ec3\u5b9e\u73b0\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5728\u4e5d\u4e2a\u540c\u8d28\u548c\u5f02\u8d28\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSGPC\u4f18\u4e8e\u73b0\u6709\u8c31\u548c\u9798\u57fa\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u63d0\u4f9b\u672a\u89c1\u8282\u70b9\u7684\u8ba4\u8bc1\u7f6e\u4fe1\u533a\u95f4\u3002", "conclusion": "SGPC\u901a\u8fc7\u7406\u8bba\u6027\u80fd\u754c\u9650\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u4e3a\u5f02\u8d28\u56fe\u4e0a\u7684\u534a\u76d1\u7763\u8282\u70b9\u5206\u7c7b\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7a33\u5b9a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00364", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00364", "abs": "https://arxiv.org/abs/2508.00364", "authors": ["Chanyoung Yoon", "Sangbong Yoo", "Soobin Yim", "Chansoo Kim", "Yun Jang"], "title": "OID-PPO: Optimal Interior Design using Proximal Policy Optimization by Transforming Design Guidelines into Reward Functions", "comment": null, "summary": "Designing residential interiors strongly impacts occupant satisfaction but\nremains challenging due to unstructured spatial layouts, high computational\ndemands, and reliance on expert knowledge. Existing methods based on\noptimization or deep learning are either computationally expensive or\nconstrained by data scarcity. Reinforcement learning (RL) approaches often\nlimit furniture placement to discrete positions and fail to incorporate design\nprinciples adequately. We propose OID-PPO, a novel RL framework for Optimal\nInterior Design using Proximal Policy Optimization, which integrates\nexpert-defined functional and visual guidelines into a structured reward\nfunction. OID-PPO utilizes a diagonal Gaussian policy for continuous and\nflexible furniture placement, effectively exploring latent environmental\ndynamics under partial observability. Experiments conducted across diverse room\nshapes and furniture configurations demonstrate that OID-PPO significantly\noutperforms state-of-the-art methods in terms of layout quality and\ncomputational efficiency. Ablation studies further demonstrate the impact of\nstructured guideline integration and reveal the distinct contributions of\nindividual design constraints.", "AI": {"tldr": "OID-PPO\u662f\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u5ba4\u5185\u8bbe\u8ba1\uff0c\u901a\u8fc7\u6574\u5408\u4e13\u5bb6\u5b9a\u4e49\u7684\u8bbe\u8ba1\u51c6\u5219\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5e03\u5c40\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u4f4f\u5b85\u5ba4\u5185\u8bbe\u8ba1\u5bf9\u5c45\u4f4f\u6ee1\u610f\u5ea6\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u6570\u636e\u7a00\u7f3a\u6216\u8bbe\u8ba1\u51c6\u5219\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faOID-PPO\u6846\u67b6\uff0c\u7ed3\u5408\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u548c\u4e13\u5bb6\u5b9a\u4e49\u7684\u529f\u80fd\u4e0e\u89c6\u89c9\u51c6\u5219\uff0c\u91c7\u7528\u5bf9\u89d2\u9ad8\u65af\u7b56\u7565\u5b9e\u73b0\u8fde\u7eed\u7075\u6d3b\u7684\u5bb6\u5177\u5e03\u5c40\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cOID-PPO\u5728\u591a\u6837\u5316\u7684\u623f\u95f4\u5f62\u72b6\u548c\u5bb6\u5177\u914d\u7f6e\u4e2d\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "OID-PPO\u901a\u8fc7\u6574\u5408\u8bbe\u8ba1\u51c6\u5219\u548c\u7075\u6d3b\u7684\u5e03\u5c40\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5ba4\u5185\u8bbe\u8ba1\u7684\u6311\u6218\u3002"}}
{"id": "2508.00392", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00392", "abs": "https://arxiv.org/abs/2508.00392", "authors": ["Lijun Zhang", "Wenhao Yang", "Guanghui Wang", "Wei Jiang", "Zhi-Hua Zhou"], "title": "Dual Adaptivity: Universal Algorithms for Minimizing the Adaptive Regret of Convex Functions", "comment": "arXiv admin note: text overlap with arXiv:1906.10851", "summary": "To deal with changing environments, a new performance measure -- adaptive\nregret, defined as the maximum static regret over any interval, was proposed in\nonline learning. Under the setting of online convex optimization, several\nalgorithms have been successfully developed to minimize the adaptive regret.\nHowever, existing algorithms lack universality in the sense that they can only\nhandle one type of convex functions and need apriori knowledge of parameters,\nwhich hinders their application in real-world scenarios. To address this\nlimitation, this paper investigates universal algorithms with dual adaptivity,\nwhich automatically adapt to the property of functions (convex, exponentially\nconcave, or strongly convex), as well as the nature of environments (stationary\nor changing). Specifically, we propose a meta-expert framework for dual\nadaptive algorithms, where multiple experts are created dynamically and\naggregated by a meta-algorithm. The meta-algorithm is required to yield a\nsecond-order bound, which can accommodate unknown function types. We further\nincorporate the technique of sleeping experts to capture the changing\nenvironments. For the construction of experts, we introduce two strategies\n(increasing the number of experts or enhancing the capabilities of experts) to\nachieve universality. Theoretical analysis shows that our algorithms are able\nto minimize the adaptive regret for multiple types of convex functions\nsimultaneously, and also allow the type of functions to switch between rounds.\nMoreover, we extend our meta-expert framework to online composite optimization,\nand develop a universal algorithm for minimizing the adaptive regret of\ncomposite functions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u53cc\u91cd\u9002\u5e94\u6027\u7684\u901a\u7528\u7b97\u6cd5\uff0c\u901a\u8fc7\u5143\u4e13\u5bb6\u6846\u67b6\u52a8\u6001\u521b\u5efa\u548c\u805a\u5408\u4e13\u5bb6\uff0c\u4ee5\u9002\u5e94\u4e0d\u540c\u51f8\u51fd\u6570\u7c7b\u578b\u548c\u53d8\u5316\u73af\u5883\u3002", "motivation": "\u73b0\u6709\u7b97\u6cd5\u7f3a\u4e4f\u901a\u7528\u6027\uff0c\u53ea\u80fd\u5904\u7406\u5355\u4e00\u51f8\u51fd\u6570\u7c7b\u578b\u4e14\u9700\u8981\u5148\u9a8c\u53c2\u6570\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528\u5143\u4e13\u5bb6\u6846\u67b6\uff0c\u52a8\u6001\u521b\u5efa\u591a\u4e2a\u4e13\u5bb6\u5e76\u901a\u8fc7\u5143\u7b97\u6cd5\u805a\u5408\uff0c\u7ed3\u5408\u7761\u7720\u4e13\u5bb6\u6280\u672f\u6355\u6349\u73af\u5883\u53d8\u5316\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u7b97\u6cd5\u80fd\u540c\u65f6\u6700\u5c0f\u5316\u591a\u79cd\u51f8\u51fd\u6570\u7684\u81ea\u9002\u5e94\u9057\u61be\uff0c\u5e76\u5141\u8bb8\u51fd\u6570\u7c7b\u578b\u5728\u8f6e\u6b21\u95f4\u5207\u6362\u3002", "conclusion": "\u8be5\u6846\u67b6\u6269\u5c55\u81f3\u5728\u7ebf\u590d\u5408\u4f18\u5316\uff0c\u5f00\u53d1\u4e86\u901a\u7528\u7b97\u6cd5\u4ee5\u6700\u5c0f\u5316\u590d\u5408\u51fd\u6570\u7684\u81ea\u9002\u5e94\u9057\u61be\u3002"}}
{"id": "2508.00394", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00394", "abs": "https://arxiv.org/abs/2508.00394", "authors": ["Antonis Klironomos", "Baifan Zhou", "Zhipeng Tan", "Zhuoxun Zheng", "Mohamed H. Gad-Elrab", "Heiko Paulheim", "Evgeny Kharlamov"], "title": "ExeKGLib: A Platform for Machine Learning Analytics based on Knowledge Graphs", "comment": null, "summary": "Nowadays machine learning (ML) practitioners have access to numerous ML\nlibraries available online. Such libraries can be used to create ML pipelines\nthat consist of a series of steps where each step may invoke up to several ML\nlibraries that are used for various data-driven analytical tasks. Development\nof high-quality ML pipelines is non-trivial; it requires training, ML\nexpertise, and careful development of each step. At the same time, domain\nexperts in science and engineering may not possess such ML expertise and\ntraining while they are in pressing need of ML-based analytics. In this paper,\nwe present our ExeKGLib, a Python library enhanced with a graphical interface\nlayer that allows users with minimal ML knowledge to build ML pipelines. This\nis achieved by relying on knowledge graphs that encode ML knowledge in simple\nterms accessible to non-ML experts. ExeKGLib also allows improving the\ntransparency and reusability of the built ML workflows and ensures that they\nare executable. We show the usability and usefulness of ExeKGLib by presenting\nreal use cases.", "AI": {"tldr": "ExeKGLib\u662f\u4e00\u4e2aPython\u5e93\uff0c\u901a\u8fc7\u56fe\u5f62\u754c\u9762\u548c\u77e5\u8bc6\u56fe\u8c31\u5e2e\u52a9\u975eML\u4e13\u5bb6\u6784\u5efaML\u7ba1\u9053\uff0c\u63d0\u5347\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u7528\u6027\u3002", "motivation": "\u89e3\u51b3\u9886\u57df\u4e13\u5bb6\u7f3a\u4e4fML\u4e13\u4e1a\u77e5\u8bc6\u4f46\u9700\u8981ML\u5206\u6790\u5de5\u5177\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u7f16\u7801ML\u77e5\u8bc6\uff0c\u63d0\u4f9b\u56fe\u5f62\u754c\u9762\u7b80\u5316ML\u7ba1\u9053\u6784\u5efa\u3002", "result": "\u5c55\u793a\u4e86ExeKGLib\u7684\u5b9e\u9645\u7528\u4f8b\uff0c\u8bc1\u660e\u5176\u53ef\u7528\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "ExeKGLib\u4e3a\u975eML\u4e13\u5bb6\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u900f\u660e\u7684ML\u7ba1\u9053\u6784\u5efa\u5de5\u5177\u3002"}}
{"id": "2508.00410", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00410", "abs": "https://arxiv.org/abs/2508.00410", "authors": ["Zizhuo Zhang", "Jianing Zhu", "Xinmu Ge", "Zihua Zhao", "Zhanke Zhou", "Xuan Li", "Xiao Feng", "Jiangchao Yao", "Bo Han"], "title": "Co-Reward: Self-supervised Reinforcement Learning for Large Language Model Reasoning via Contrastive Agreement", "comment": null, "summary": "Although reinforcement learning with verifiable rewards (RLVR) shows promise\nin improving the reasoning ability of large language models (LLMs), the scaling\nup dilemma remains due to the reliance on human annotated labels especially for\ncomplex tasks. Recent alternatives that explore various self-reward signals\nexhibit the eliciting potential of LLM reasoning, but suffer from the\nnon-negligible collapse issue. Inspired by the success of self-supervised\nlearning, we propose \\textit{Co-Reward}, a novel RL framework that leverages\ncontrastive agreement across semantically analogical questions as a reward\nbasis. Specifically, we construct a similar question for each training sample\n(without labels) and synthesize their individual surrogate labels through a\nsimple rollout voting, and then the reward is constructed by cross-referring\nthe labels of each question pair to enforce the internal reasoning consistency\nacross analogical inputs. Intuitively, such a self-supervised reward-shaping\nmechanism increases the difficulty of learning collapse into a trivial\nsolution, and promotes stable reasoning elicitation and improvement through\nexpanding the input sample variants. Empirically, Co-Reward achieves superior\nperformance compared to other self-reward baselines on multiple reasoning\nbenchmarks and LLM series, and reaches or even surpasses ground-truth (GT)\nlabeled reward, with improvements of up to $+6.8\\%$ on MATH500 over GT reward\non Llama-3.2-3B-Instruct. Our code is publicly available at\nhttps://github.com/tmlr-group/Co-Reward.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCo-Reward\u7684\u65b0\u578b\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u8bed\u4e49\u76f8\u4f3c\u95ee\u9898\u7684\u7b54\u6848\u4e00\u81f4\u6027\u4f5c\u4e3a\u5956\u52b1\u57fa\u7840\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u81ea\u5956\u52b1\u65b9\u6cd5\u4e2d\u7684\u5d29\u6e83\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u4eba\u7c7b\u6807\u6ce8\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u96be\u4ee5\u6269\u5c55\uff0c\u800c\u81ea\u5956\u52b1\u65b9\u6cd5\u867d\u80fd\u6fc0\u53d1\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5b58\u5728\u5d29\u6e83\u95ee\u9898\u3002", "method": "\u5229\u7528\u8bed\u4e49\u76f8\u4f3c\u95ee\u9898\u7684\u5bf9\u6bd4\u4e00\u81f4\u6027\u6784\u5efa\u5956\u52b1\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u6295\u7968\u673a\u5236\u5408\u6210\u4ee3\u7406\u6807\u7b7e\uff0c\u5e76\u4ea4\u53c9\u5f15\u7528\u95ee\u9898\u5bf9\u7684\u6807\u7b7e\u4ee5\u589e\u5f3a\u63a8\u7406\u4e00\u81f4\u6027\u3002", "result": "Co-Reward\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7cfb\u5217\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8d85\u8fc7\u57fa\u4e8e\u771f\u5b9e\u6807\u6ce8\u7684\u5956\u52b1\uff0c\u5982\u5728MATH500\u4e0a\u6bd4\u771f\u5b9e\u6807\u6ce8\u5956\u52b1\u63d0\u53476.8%\u3002", "conclusion": "Co-Reward\u901a\u8fc7\u81ea\u76d1\u7763\u5956\u52b1\u673a\u5236\u6709\u6548\u907f\u514d\u4e86\u5d29\u6e83\u95ee\u9898\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.00415", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00415", "abs": "https://arxiv.org/abs/2508.00415", "authors": ["Yue Yang", "Yuxiang Lin", "Ying Zhang", "Zihan Su", "Chang Chuan Goh", "Tangtangfang Fang", "Anthony Graham Bellotti", "Boon Giin Lee"], "title": "Transforming Credit Risk Analysis: A Time-Series-Driven ResE-BiLSTM Framework for Post-Loan Default Detection", "comment": null, "summary": "Prediction of post-loan default is an important task in credit risk\nmanagement, and can be addressed by detection of financial anomalies using\nmachine learning. This study introduces a ResE-BiLSTM model, using a sliding\nwindow technique, and is evaluated on 44 independent cohorts from the extensive\nFreddie Mac US mortgage dataset, to improve prediction performance. The\nResE-BiLSTM is compared with five baseline models: Long Short-Term Memory\n(LSTM), BiLSTM, Gated Recurrent Units (GRU), Convolutional Neural Networks\n(CNN), and Recurrent Neural Networks (RNN), across multiple metrics, including\nAccuracy, Precision, Recall, F1, and AUC. An ablation study was conducted to\nevaluate the contribution of individual components in the ResE-BiLSTM\narchitecture. Additionally, SHAP analysis was employed to interpret the\nunderlying features the model relied upon for its predictions. Experimental\nresults demonstrate that ResE-BiLSTM achieves superior predictive performance\ncompared to baseline models, underscoring its practical value and applicability\nin real-world scenarios.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cdResE-BiLSTM\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u8d37\u6b3e\u8fdd\u7ea6\uff0c\u901a\u8fc7\u6ed1\u52a8\u7a97\u53e3\u6280\u672f\u548c\u591a\u79cd\u57fa\u7ebf\u6a21\u578b\u6bd4\u8f83\uff0c\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u8d37\u6b3e\u8fdd\u7ea6\u9884\u6d4b\u5bf9\u4fe1\u7528\u98ce\u9669\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u68c0\u6d4b\u8d22\u52a1\u5f02\u5e38\uff0c\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528ResE-BiLSTM\u6a21\u578b\u548c\u6ed1\u52a8\u7a97\u53e3\u6280\u672f\uff0c\u5728Freddie Mac\u62b5\u62bc\u8d37\u6b3e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5e76\u4e0eLSTM\u3001BiLSTM\u3001GRU\u3001CNN\u548cRNN\u7b49\u57fa\u7ebf\u6a21\u578b\u6bd4\u8f83\u3002", "result": "ResE-BiLSTM\u5728\u51c6\u786e\u6027\u3001\u7cbe\u786e\u5ea6\u3001\u53ec\u56de\u7387\u3001F1\u548cAUC\u7b49\u6307\u6807\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "ResE-BiLSTM\u5728\u8d37\u6b3e\u8fdd\u7ea6\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.00472", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00472", "abs": "https://arxiv.org/abs/2508.00472", "authors": ["Leonidas Akritidis", "Panayiotis Bozanis"], "title": "A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces", "comment": null, "summary": "The tabular form constitutes the standard way of representing data in\nrelational database systems and spreadsheets. But, similarly to other forms,\ntabular data suffers from class imbalance, a problem that causes serious\nperformance degradation in a wide variety of machine learning tasks. One of the\nmost effective solutions dictates the usage of Generative Adversarial Networks\n(GANs) in order to synthesize artificial data instances for the\nunder-represented classes. Despite their good performance, none of the proposed\nGAN models takes into account the vector subspaces of the input samples in the\nreal data space, leading to data generation in arbitrary locations. Moreover,\nthe class labels are treated in the same manner as the other categorical\nvariables during training, so conditional sampling by class is rendered less\neffective. To overcome these problems, this study presents ctdGAN, a\nconditional GAN for alleviating class imbalance in tabular datasets. Initially,\nctdGAN executes a space partitioning step to assign cluster labels to the input\nsamples. Subsequently, it utilizes these labels to synthesize samples via a\nnovel probabilistic sampling strategy and a new loss function that penalizes\nboth cluster and class mis-predictions. In this way, ctdGAN is trained to\ngenerate samples in subspaces that resemble those of the original data\ndistribution. We also introduce several other improvements, including a simple,\nyet effective cluster-wise scaling technique that captures multiple feature\nmodes without affecting data dimensionality. The exhaustive evaluation of\nctdGAN with 14 imbalanced datasets demonstrated its superiority in generating\nhigh fidelity samples and improving classification accuracy.", "AI": {"tldr": "ctdGAN\u662f\u4e00\u79cd\u7528\u4e8e\u7f13\u89e3\u8868\u683c\u6570\u636e\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u7684\u6761\u4ef6GAN\uff0c\u901a\u8fc7\u7a7a\u95f4\u5206\u533a\u548c\u65b0\u7684\u635f\u5931\u51fd\u6570\u751f\u6210\u9ad8\u8d28\u91cf\u6837\u672c\u3002", "motivation": "\u8868\u683c\u6570\u636e\u4e2d\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u4f1a\u5bfc\u81f4\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u6027\u80fd\u4e0b\u964d\uff0c\u73b0\u6709GAN\u65b9\u6cd5\u672a\u8003\u8651\u8f93\u5165\u6837\u672c\u7684\u5411\u91cf\u5b50\u7a7a\u95f4\uff0c\u4e14\u7c7b\u522b\u6807\u7b7e\u5904\u7406\u4e0d\u591f\u6709\u6548\u3002", "method": "ctdGAN\u901a\u8fc7\u7a7a\u95f4\u5206\u533a\u5206\u914d\u805a\u7c7b\u6807\u7b7e\uff0c\u5229\u7528\u65b0\u7684\u6982\u7387\u91c7\u6837\u7b56\u7565\u548c\u635f\u5931\u51fd\u6570\u751f\u6210\u6837\u672c\uff0c\u5e76\u7ed3\u5408\u805a\u7c7b\u7f29\u653e\u6280\u672f\u3002", "result": "\u572814\u4e2a\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cctdGAN\u80fd\u751f\u6210\u9ad8\u4fdd\u771f\u6837\u672c\u5e76\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u7387\u3002", "conclusion": "ctdGAN\u901a\u8fc7\u6539\u8fdb\u91c7\u6837\u548c\u635f\u5931\u51fd\u6570\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8868\u683c\u6570\u636e\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002"}}
{"id": "2508.00507", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00507", "abs": "https://arxiv.org/abs/2508.00507", "authors": ["Yiming Xu", "Jiarun Chen", "Zhen Peng", "Zihan Chen", "Qika Lin", "Lan Ma", "Bin Shi", "Bo Dong"], "title": "Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection", "comment": "Accepted by ACM Multimedia 2025 (MM '25)", "summary": "The natural combination of intricate topological structures and rich textual\ninformation in text-attributed graphs (TAGs) opens up a novel perspective for\ngraph anomaly detection (GAD). However, existing GAD methods primarily focus on\ndesigning complex optimization objectives within the graph domain, overlooking\nthe complementary value of the textual modality, whose features are often\nencoded by shallow embedding techniques, such as bag-of-words or skip-gram, so\nthat semantic context related to anomalies may be missed. To unleash the\nenormous potential of textual modality, large language models (LLMs) have\nemerged as promising alternatives due to their strong semantic understanding\nand reasoning capabilities. Nevertheless, their application to TAG anomaly\ndetection remains nascent, and they struggle to encode high-order structural\ninformation inherent in graphs due to input length constraints. For\nhigh-quality anomaly detection in TAGs, we propose CoLL, a novel framework that\ncombines LLMs and graph neural networks (GNNs) to leverage their complementary\nstrengths. CoLL employs multi-LLM collaboration for evidence-augmented\ngeneration to capture anomaly-relevant contexts while delivering human-readable\nrationales for detected anomalies. Moreover, CoLL integrates a GNN equipped\nwith a gating mechanism to adaptively fuse textual features with evidence while\npreserving high-order topological information. Extensive experiments\ndemonstrate the superiority of CoLL, achieving an average improvement of 13.37%\nin AP. This study opens a new avenue for incorporating LLMs in advancing GAD.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u7684\u65b0\u6846\u67b6CoLL\uff0c\u7528\u4e8e\u6587\u672c\u5c5e\u6027\u56fe\uff08TAGs\uff09\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u56fe\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u56fe\u57df\u5185\u7684\u4f18\u5316\u76ee\u6807\uff0c\u5ffd\u7565\u4e86\u6587\u672c\u6a21\u6001\u7684\u4e92\u8865\u4ef7\u503c\uff0c\u4e14\u6587\u672c\u7279\u5f81\u7f16\u7801\u65b9\u5f0f\u6d45\u5c42\uff0c\u53ef\u80fd\u9057\u6f0f\u5f02\u5e38\u76f8\u5173\u7684\u8bed\u4e49\u4fe1\u606f\u3002", "method": "CoLL\u6846\u67b6\u901a\u8fc7\u591aLLM\u534f\u4f5c\u751f\u6210\u8bc1\u636e\u589e\u5f3a\u7684\u6587\u672c\u7279\u5f81\uff0c\u5e76\u7ed3\u5408GNN\u7684\u95e8\u63a7\u673a\u5236\u81ea\u9002\u5e94\u878d\u5408\u6587\u672c\u4e0e\u56fe\u7ed3\u6784\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCoLL\u5728AP\u6307\u6807\u4e0a\u5e73\u5747\u63d0\u534713.37%\u3002", "conclusion": "CoLL\u4e3a\u5c06LLMs\u5e94\u7528\u4e8e\u56fe\u5f02\u5e38\u68c0\u6d4b\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u5c55\u793a\u4e86\u5176\u6f5c\u529b\u3002"}}
{"id": "2508.00513", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00513", "abs": "https://arxiv.org/abs/2508.00513", "authors": ["Yiming Xu", "Xu Hua", "Zhen Peng", "Bin Shi", "Jiarun Chen", "Xingbo Fu", "Song Wang", "Bo Dong"], "title": "Text-Attributed Graph Anomaly Detection via Multi-Scale Cross- and Uni-Modal Contrastive Learning", "comment": "Accepted by ECAI 2025", "summary": "The widespread application of graph data in various high-risk scenarios has\nincreased attention to graph anomaly detection (GAD). Faced with real-world\ngraphs that often carry node descriptions in the form of raw text sequences,\ntermed text-attributed graphs (TAGs), existing graph anomaly detection\npipelines typically involve shallow embedding techniques to encode such textual\ninformation into features, and then rely on complex self-supervised tasks\nwithin the graph domain to detect anomalies. However, this text encoding\nprocess is separated from the anomaly detection training objective in the graph\ndomain, making it difficult to ensure that the extracted textual features focus\non GAD-relevant information, seriously constraining the detection capability.\nHow to seamlessly integrate raw text and graph topology to unleash the vast\npotential of cross-modal data in TAGs for anomaly detection poses a challenging\nissue. This paper presents a novel end-to-end paradigm for text-attributed\ngraph anomaly detection, named CMUCL. We simultaneously model data from both\ntext and graph structures, and jointly train text and graph encoders by\nleveraging cross-modal and uni-modal multi-scale consistency to uncover\npotential anomaly-related information. Accordingly, we design an anomaly score\nestimator based on inconsistency mining to derive node-specific anomaly scores.\nConsidering the lack of benchmark datasets tailored for anomaly detection on\nTAGs, we release 8 datasets to facilitate future research. Extensive\nevaluations show that CMUCL significantly advances in text-attributed graph\nanomaly detection, delivering an 11.13% increase in average accuracy (AP) over\nthe suboptimal.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCMUCL\u7684\u7aef\u5230\u7aef\u65b9\u6cd5\uff0c\u7528\u4e8e\u6587\u672c\u5c5e\u6027\u56fe\u7684\u5f02\u5e38\u68c0\u6d4b\uff0c\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u6587\u672c\u548c\u56fe\u7f16\u7801\u5668\uff0c\u5229\u7528\u8de8\u6a21\u6001\u548c\u591a\u5c3a\u5ea6\u4e00\u81f4\u6027\u63d0\u9ad8\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u6587\u672c\u7f16\u7801\u4e0e\u5f02\u5e38\u68c0\u6d4b\u5206\u79bb\uff0c\u5bfc\u81f4\u63d0\u53d6\u7684\u6587\u672c\u7279\u5f81\u53ef\u80fd\u4e0d\u805a\u7126\u4e8e\u5f02\u5e38\u68c0\u6d4b\u76f8\u5173\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u63d0\u51faCMUCL\u65b9\u6cd5\uff0c\u8054\u5408\u5efa\u6a21\u6587\u672c\u548c\u56fe\u7ed3\u6784\u6570\u636e\uff0c\u5229\u7528\u8de8\u6a21\u6001\u548c\u5355\u6a21\u6001\u591a\u5c3a\u5ea6\u4e00\u81f4\u6027\u8bad\u7ec3\u7f16\u7801\u5668\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u4e0d\u4e00\u81f4\u6027\u6316\u6398\u7684\u5f02\u5e38\u8bc4\u5206\u5668\u3002", "result": "CMUCL\u5728\u6587\u672c\u5c5e\u6027\u56fe\u5f02\u5e38\u68c0\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747\u51c6\u786e\u7387\uff08AP\uff09\u6bd4\u6b21\u4f18\u65b9\u6cd5\u63d0\u534711.13%\u3002", "conclusion": "CMUCL\u901a\u8fc7\u6574\u5408\u6587\u672c\u548c\u56fe\u62d3\u6251\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u53d1\u5e03\u4e868\u4e2a\u6570\u636e\u96c6\u4ee5\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2508.00523", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00523", "abs": "https://arxiv.org/abs/2508.00523", "authors": ["Sifan Yang", "Yuanyu Wan", "Lijun Zhang"], "title": "Online Nonsubmodular Optimization with Delayed Feedback in the Bandit Setting", "comment": null, "summary": "We investigate the online nonsubmodular optimization with delayed feedback in\nthe bandit setting, where the loss function is $\\alpha$-weakly DR-submodular\nand $\\beta$-weakly DR-supermodular. Previous work has established an\n$(\\alpha,\\beta)$-regret bound of $\\mathcal{O}(nd^{1/3}T^{2/3})$, where $n$ is\nthe dimensionality and $d$ is the maximum delay. However, its regret bound\nrelies on the maximum delay and is thus sensitive to irregular delays.\nAdditionally, it couples the effects of delays and bandit feedback as its bound\nis the product of the delay term and the $\\mathcal{O}(nT^{2/3})$ regret bound\nin the bandit setting without delayed feedback. In this paper, we develop two\nalgorithms to address these limitations, respectively. Firstly, we propose a\nnovel method, namely DBGD-NF, which employs the one-point gradient estimator\nand utilizes all the available estimated gradients in each round to update the\ndecision. It achieves a better $\\mathcal{O}(n\\bar{d}^{1/3}T^{2/3})$ regret\nbound, which is relevant to the average delay $\\bar{d} =\n\\frac{1}{T}\\sum_{t=1}^T d_t\\leq d$. Secondly, we extend DBGD-NF by employing a\nblocking update mechanism to decouple the joint effect of the delays and bandit\nfeedback, which enjoys an $\\mathcal{O}(n(T^{2/3} + \\sqrt{dT}))$ regret bound.\nWhen $d = \\mathcal{O}(T^{1/3})$, our regret bound matches the\n$\\mathcal{O}(nT^{2/3})$ bound in the bandit setting without delayed feedback.\nCompared to our first $\\mathcal{O}(n\\bar{d}^{1/3}T^{2/3})$ bound, it is more\nadvantageous when the maximum delay $d = o(\\bar{d}^{2/3}T^{1/3})$. Finally, we\nconduct experiments on structured sparse learning to demonstrate the\nsuperiority of our methods.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u7ebf\u975e\u5b50\u6a21\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u7b97\u6cd5DBGD-NF\u548c\u6539\u8fdb\u7248\uff0c\u5206\u522b\u89e3\u51b3\u4e86\u5ef6\u8fdf\u53cd\u9988\u548c\u5e26\u53cd\u9988\u7684\u8054\u5408\u6548\u5e94\u95ee\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5bf9\u5ef6\u8fdf\u654f\u611f\u4e14\u672a\u89e3\u8026\u5ef6\u8fdf\u4e0e\u5e26\u53cd\u9988\u7684\u8054\u5408\u6548\u5e94\uff0c\u9650\u5236\u4e86\u6027\u80fd\u3002", "method": "\u63d0\u51faDBGD-NF\u7b97\u6cd5\u548c\u6539\u8fdb\u7248\uff0c\u5206\u522b\u5229\u7528\u5355\u70b9\u68af\u5ea6\u4f30\u8ba1\u548c\u5757\u66f4\u65b0\u673a\u5236\u3002", "result": "DBGD-NF\u7684\u9057\u61be\u754c\u4e0e\u5e73\u5747\u5ef6\u8fdf\u76f8\u5173\uff0c\u6539\u8fdb\u7248\u8fdb\u4e00\u6b65\u89e3\u8026\u6548\u5e94\uff0c\u6027\u80fd\u66f4\u4f18\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u5728\u5ef6\u8fdf\u548c\u5e26\u53cd\u9988\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u8d8a\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2508.00539", "categories": ["cs.LG", "Cs"], "pdf": "https://arxiv.org/pdf/2508.00539", "abs": "https://arxiv.org/abs/2508.00539", "authors": ["Judy X Yang"], "title": "Phase-Locked SNR Band Selection for Weak Mineral Signal Detection in Hyperspectral Imagery", "comment": "8 pages, 6 figures", "summary": "Hyperspectral imaging offers detailed spectral information for mineral\nmapping; however, weak mineral signatures are often masked by noisy and\nredundant bands, limiting detection performance. To address this, we propose a\ntwo-stage integrated framework for enhanced mineral detection in the Cuprite\nmining district. In the first stage, we compute the signal-to-noise ratio (SNR)\nfor each spectral band and apply a phase-locked thresholding technique to\ndiscard low-SNR bands, effectively removing redundancy and suppressing\nbackground noise. Savitzky-Golay filtering is then employed for spectral\nsmoothing, serving a dual role first to stabilize trends during band selection,\nand second to preserve fine-grained spectral features during preprocessing. In\nthe second stage, the refined HSI data is reintroduced into the model, where\nKMeans clustering is used to extract 12 endmember spectra (W1 custom), followed\nby non negative least squares (NNLS) for abundance unmixing. The resulting\nendmembers are quantitatively compared with laboratory spectra (W1 raw) using\ncosine similarity and RMSE metrics. Experimental results confirm that our\nproposed pipeline improves unmixing accuracy and enhances the detection of weak\nmineral zones. This two-pass strategy demonstrates a practical and reproducible\nsolution for spectral dimensionality reduction and unmixing in geological HSI\napplications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3aCuprite\u77ff\u533a\u77ff\u7269\u68c0\u6d4b\uff0c\u901a\u8fc7SNR\u9608\u503c\u548cSavitzky-Golay\u6ee4\u6ce2\u964d\u566a\uff0c\u518d\u7ed3\u5408KMeans\u548cNNLS\u63d0\u9ad8\u89e3\u6df7\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3\u9ad8\u5149\u8c31\u6210\u50cf\u4e2d\u5f31\u77ff\u7269\u4fe1\u53f7\u88ab\u566a\u58f0\u548c\u5197\u4f59\u6ce2\u6bb5\u63a9\u76d6\u7684\u95ee\u9898\u3002", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) SNR\u9608\u503c\u548cSavitzky-Golay\u6ee4\u6ce2\u964d\u566a\uff1b2) KMeans\u805a\u7c7b\u548cNNLS\u89e3\u6df7\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5f31\u77ff\u7269\u533a\u57df\u7684\u68c0\u6d4b\u7cbe\u5ea6\u548c\u89e3\u6df7\u6548\u679c\u3002", "conclusion": "\u8be5\u7b56\u7565\u4e3a\u5730\u8d28\u9ad8\u5149\u8c31\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u91cd\u590d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00545", "categories": ["cs.LG", "cs.AI", "cs.NE", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.00545", "abs": "https://arxiv.org/abs/2508.00545", "authors": ["Pietro Barbiero", "Mateo Espinosa Zarlenga", "Alberto Termine", "Mateja Jamnik", "Giuseppe Marra"], "title": "Foundations of Interpretable Models", "comment": null, "summary": "We argue that existing definitions of interpretability are not actionable in\nthat they fail to inform users about general, sound, and robust interpretable\nmodel design. This makes current interpretability research fundamentally\nill-posed. To address this issue, we propose a definition of interpretability\nthat is general, simple, and subsumes existing informal notions within the\ninterpretable AI community. We show that our definition is actionable, as it\ndirectly reveals the foundational properties, underlying assumptions,\nprinciples, data structures, and architectural features necessary for designing\ninterpretable models. Building on this, we propose a general blueprint for\ndesigning interpretable models and introduce the first open-sourced library\nwith native support for interpretable data structures and processes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u89e3\u91ca\u6027\u5b9a\u4e49\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5b9a\u4e49\u4e0d\u5177\u53ef\u64cd\u4f5c\u6027\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8bbe\u8ba1\u53ef\u89e3\u91ca\u6a21\u578b\u7684\u84dd\u56fe\u548c\u5f00\u6e90\u5e93\u3002", "motivation": "\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u5b9a\u4e49\u7f3a\u4e4f\u64cd\u4f5c\u6027\uff0c\u65e0\u6cd5\u6307\u5bfc\u7528\u6237\u8bbe\u8ba1\u901a\u7528\u3001\u53ef\u9760\u4e14\u7a33\u5065\u7684\u53ef\u89e3\u91ca\u6a21\u578b\uff0c\u5bfc\u81f4\u7814\u7a76\u95ee\u9898\u4e0d\u660e\u786e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u3001\u7b80\u5355\u4e14\u6db5\u76d6\u73b0\u6709\u975e\u6b63\u5f0f\u6982\u5ff5\u7684\u53ef\u89e3\u91ca\u6027\u5b9a\u4e49\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u53ef\u89e3\u91ca\u6a21\u578b\u7684\u84dd\u56fe\u548c\u5f00\u6e90\u5e93\u3002", "result": "\u65b0\u5b9a\u4e49\u5177\u6709\u53ef\u64cd\u4f5c\u6027\uff0c\u63ed\u793a\u4e86\u8bbe\u8ba1\u53ef\u89e3\u91ca\u6a21\u578b\u6240\u9700\u7684\u57fa\u672c\u5c5e\u6027\u3001\u5047\u8bbe\u3001\u539f\u5219\u3001\u6570\u636e\u7ed3\u6784\u548c\u67b6\u6784\u7279\u5f81\u3002", "conclusion": "\u8bba\u6587\u901a\u8fc7\u65b0\u5b9a\u4e49\u548c\u5de5\u5177\u63a8\u52a8\u4e86\u53ef\u89e3\u91caAI\u7814\u7a76\u7684\u53d1\u5c55\uff0c\u4f7f\u5176\u66f4\u5177\u5b9e\u8df5\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2508.00615", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00615", "abs": "https://arxiv.org/abs/2508.00615", "authors": ["Mukesh Kumar Sahu", "Pinki Roy"], "title": "Similarity-Based Self-Construct Graph Model for Predicting Patient Criticalness Using Graph Neural Networks and EHR Data", "comment": null, "summary": "Accurately predicting the criticalness of ICU patients (such as in-ICU\nmortality risk) is vital for early intervention in critical care. However,\nconventional models often treat each patient in isolation and struggle to\nexploit the relational structure in Electronic Health Records (EHR). We propose\na Similarity-Based Self-Construct Graph Model (SBSCGM) that dynamically builds\na patient similarity graph from multi-modal EHR data, and a HybridGraphMedGNN\narchitecture that operates on this graph to predict patient mortality and a\ncontinuous criticalness score. SBSCGM uses a hybrid similarity measure\n(combining feature-based and structural similarities) to connect patients with\nanalogous clinical profiles in real-time. The HybridGraphMedGNN integrates\nGraph Convolutional Network (GCN), GraphSAGE, and Graph Attention Network (GAT)\nlayers to learn robust patient representations, leveraging both local and\nglobal graph patterns. In experiments on 6,000 ICU stays from the MIMIC-III\ndataset, our model achieves state-of-the-art performance (AUC-ROC $0.94$)\noutperforming baseline classifiers and single-type GNN models. We also\ndemonstrate improved precision/recall and show that the attention mechanism\nprovides interpretable insights into model predictions. Our framework offers a\nscalable and interpretable solution for critical care risk prediction, with\npotential to support clinicians in real-world ICU deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76f8\u4f3c\u6027\u81ea\u6784\u5efa\u56fe\u6a21\u578b\uff08SBSCGM\uff09\u548c\u6df7\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\uff08HybridGraphMedGNN\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4bICU\u60a3\u8005\u7684\u6b7b\u4ea1\u98ce\u9669\u548c\u5173\u952e\u6027\u8bc4\u5206\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u96be\u4ee5\u5229\u7528\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u4e2d\u7684\u5173\u7cfb\u7ed3\u6784\uff0c\u4e14\u5b64\u7acb\u5904\u7406\u60a3\u8005\u6570\u636e\uff0c\u65e0\u6cd5\u52a8\u6001\u6355\u6349\u60a3\u8005\u95f4\u7684\u76f8\u4f3c\u6027\u3002", "method": "SBSCGM\u52a8\u6001\u6784\u5efa\u60a3\u8005\u76f8\u4f3c\u6027\u56fe\uff0cHybridGraphMedGNN\u7ed3\u5408GCN\u3001GraphSAGE\u548cGAT\u5c42\u5b66\u4e60\u60a3\u8005\u8868\u793a\u3002", "result": "\u5728MIMIC-III\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578bAUC-ROC\u8fbe\u52300.94\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aICU\u98ce\u9669\u9884\u6d4b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u3002"}}
{"id": "2508.00578", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.chem-ph", "physics.comp-ph", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2508.00578", "abs": "https://arxiv.org/abs/2508.00578", "authors": ["Marlen Neubert", "Patrick Reiser", "Frauke Gr\u00e4ter", "Pascal Friederich"], "title": "Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides", "comment": "19 pages, 12 figures, and 4 tables (references and SI included)", "summary": "Hydrogen atom transfer (HAT) reactions are essential in many biological\nprocesses, such as radical migration in damaged proteins, but their mechanistic\npathways remain incompletely understood. Simulating HAT is challenging due to\nthe need for quantum chemical accuracy at biologically relevant scales; thus,\nneither classical force fields nor DFT-based molecular dynamics are applicable.\nMachine-learned potentials offer an alternative, able to learn potential energy\nsurfaces (PESs) with near-quantum accuracy. However, training these models to\ngeneralize across diverse HAT configurations, especially at radical positions\nin proteins, requires tailored data generation and careful model selection.\nHere, we systematically generate HAT configurations in peptides to build large\ndatasets using semiempirical methods and DFT. We benchmark three graph neural\nnetwork architectures (SchNet, Allegro, and MACE) on their ability to learn HAT\nPESs and indirectly predict reaction barriers from energy predictions. MACE\nconsistently outperforms the others in energy, force, and barrier prediction,\nachieving a mean absolute error of 1.13 kcal/mol on out-of-distribution DFT\nbarrier predictions. This accuracy enables integration of ML potentials into\nlarge-scale collagen simulations to compute reaction rates from predicted\nbarriers, advancing mechanistic understanding of HAT and radical migration in\npeptides. We analyze scaling laws, model transferability, and cost-performance\ntrade-offs, and outline strategies for improvement by combining ML potentials\nwith transition state search algorithms and active learning. Our approach is\ngeneralizable to other biomolecular systems, enabling quantum-accurate\nsimulations of chemical reactivity in complex environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u6a21\u62df\u6c22\u539f\u5b50\u8f6c\u79fb\uff08HAT\uff09\u53cd\u5e94\u7684\u52bf\u80fd\u9762\uff0c\u5e76\u901a\u8fc7\u7cfb\u7edf\u751f\u6210\u6570\u636e\u548c\u8bc4\u4f30\u4e0d\u540c\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u53d1\u73b0MACE\u5728\u9884\u6d4b\u80fd\u91cf\u3001\u529b\u548c\u53cd\u5e94\u52bf\u5792\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u6c22\u539f\u5b50\u8f6c\u79fb\uff08HAT\uff09\u53cd\u5e94\u5728\u751f\u7269\u8fc7\u7a0b\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u673a\u7406\u5c1a\u4e0d\u5b8c\u5168\u6e05\u695a\u3002\u4f20\u7edf\u6a21\u62df\u65b9\u6cd5\uff08\u5982\u7ecf\u5178\u529b\u573a\u6216DFT\u5206\u5b50\u52a8\u529b\u5b66\uff09\u65e0\u6cd5\u6ee1\u8db3\u91cf\u5b50\u5316\u5b66\u7cbe\u5ea6\u7684\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u534a\u7ecf\u9a8c\u65b9\u6cd5\u548cDFT\u751f\u6210\u5927\u91cfHAT\u6784\u578b\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e09\u79cd\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff08SchNet\u3001Allegro\u548cMACE\uff09\u5728\u5b66\u4e60\u548c\u9884\u6d4bHAT\u52bf\u80fd\u9762\u53ca\u53cd\u5e94\u52bf\u5792\u65b9\u9762\u7684\u6027\u80fd\u3002", "result": "MACE\u5728\u80fd\u91cf\u3001\u529b\u548c\u52bf\u5792\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u6700\u4f18\uff0c\u5176\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4e3a1.13 kcal/mol\u3002\u8be5\u65b9\u6cd5\u6210\u529f\u5e94\u7528\u4e8e\u80f6\u539f\u86cb\u767d\u6a21\u62df\uff0c\u9884\u6d4b\u53cd\u5e94\u901f\u7387\u5e76\u63ed\u793aHAT\u673a\u7406\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u63a8\u5e7f\u81f3\u5176\u4ed6\u751f\u7269\u5206\u5b50\u7cfb\u7edf\uff0c\u5b9e\u73b0\u590d\u6742\u73af\u5883\u4e2d\u5316\u5b66\u53cd\u5e94\u7684\u9ad8\u7cbe\u5ea6\u6a21\u62df\uff0c\u5e76\u7ed3\u5408\u8fc7\u6e21\u6001\u641c\u7d22\u7b97\u6cd5\u548c\u4e3b\u52a8\u5b66\u4e60\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2508.00707", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00707", "abs": "https://arxiv.org/abs/2508.00707", "authors": ["Yannik Schnitzer", "Alessandro Abate", "David Parker"], "title": "Efficient Solution and Learning of Robust Factored MDPs", "comment": null, "summary": "Robust Markov decision processes (r-MDPs) extend MDPs by explicitly modelling\nepistemic uncertainty about transition dynamics. Learning r-MDPs from\ninteractions with an unknown environment enables the synthesis of robust\npolicies with provable (PAC) guarantees on performance, but this can require a\nlarge number of sample interactions. We propose novel methods for solving and\nlearning r-MDPs based on factored state-space representations that leverage the\nindependence between model uncertainty across system components. Although\npolicy synthesis for factored r-MDPs leads to hard, non-convex optimisation\nproblems, we show how to reformulate these into tractable linear programs.\nBuilding on these, we also propose methods to learn factored model\nrepresentations directly. Our experimental results show that exploiting\nfactored structure can yield dimensional gains in sample efficiency, producing\nmore effective robust policies with tighter performance guarantees than\nstate-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u89e3\u72b6\u6001\u7a7a\u95f4\u8868\u793a\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u548c\u5b66\u4e60\u9c81\u68d2\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08r-MDPs\uff09\uff0c\u901a\u8fc7\u5229\u7528\u7cfb\u7edf\u7ec4\u4ef6\u95f4\u7684\u4e0d\u786e\u5b9a\u6027\u72ec\u7acb\u6027\uff0c\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u3002", "motivation": "r-MDPs\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u8f6c\u79fb\u52a8\u6001\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6269\u5c55\u4e86MDPs\uff0c\u4f46\u5b66\u4e60r-MDPs\u9700\u8981\u5927\u91cf\u6837\u672c\u4ea4\u4e92\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5206\u89e3\u72b6\u6001\u7a7a\u95f4\u8868\u793a\u51cf\u5c11\u6837\u672c\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5206\u89e3\u72b6\u6001\u7a7a\u95f4\u8868\u793a\u7684\u65b9\u6cd5\uff0c\u5c06\u975e\u51f8\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u5904\u7406\u7684\u7ebf\u6027\u89c4\u5212\uff0c\u5e76\u76f4\u63a5\u5b66\u4e60\u5206\u89e3\u6a21\u578b\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5229\u7528\u5206\u89e3\u7ed3\u6784\u53ef\u663e\u8457\u63d0\u9ad8\u6837\u672c\u6548\u7387\uff0c\u751f\u6210\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u6709\u6548\u7684\u9c81\u68d2\u7b56\u7565\u548c\u66f4\u4e25\u683c\u7684\u6027\u80fd\u4fdd\u8bc1\u3002", "conclusion": "\u5206\u89e3\u72b6\u6001\u7a7a\u95f4\u8868\u793a\u662f\u89e3\u51b3\u548c\u5b66\u4e60r-MDPs\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6837\u672c\u6548\u7387\u548c\u7b56\u7565\u6027\u80fd\u3002"}}
{"id": "2508.00586", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00586", "abs": "https://arxiv.org/abs/2508.00586", "authors": ["Thorben Werner", "Lars Schmidt-Thieme", "Vijaya Krishna Yalavarthi"], "title": "The Role of Active Learning in Modern Machine Learning", "comment": null, "summary": "Even though Active Learning (AL) is widely studied, it is rarely applied in\ncontexts outside its own scientific literature. We posit that the reason for\nthis is AL's high computational cost coupled with the comparatively small lifts\nit is typically able to generate in scenarios with few labeled points. In this\nwork we study the impact of different methods to combat this low data scenario,\nnamely data augmentation (DA), semi-supervised learning (SSL) and AL. We find\nthat AL is by far the least efficient method of solving the low data problem,\ngenerating a lift of only 1-4\\% over random sampling, while DA and SSL methods\ncan generate up to 60\\% lift in combination with random sampling. However, when\nAL is combined with strong DA and SSL techniques, it surprisingly is still able\nto provide improvements. Based on these results, we frame AL not as a method to\ncombat missing labels, but as the final building block to squeeze the last bits\nof performance out of data after appropriate DA and SSL methods as been\napplied.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e3b\u52a8\u5b66\u4e60\uff08AL\uff09\u5728\u4f4e\u6570\u636e\u573a\u666f\u4e0b\u6548\u7387\u6700\u4f4e\uff0c\u63d0\u5347\u4ec51-4%\uff0c\u800c\u6570\u636e\u589e\u5f3a\uff08DA\uff09\u548c\u534a\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u63d0\u5347\u53ef\u8fbe60%\u3002\u4f46AL\u4e0eDA\u548cSSL\u7ed3\u5408\u540e\u4ecd\u80fd\u63d0\u4f9b\u989d\u5916\u63d0\u5347\u3002", "motivation": "\u63a2\u8ba8AL\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8f83\u5c11\u4f7f\u7528\u7684\u539f\u56e0\uff0c\u5e76\u7814\u7a76\u5176\u5728\u4f4e\u6570\u636e\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u6bd4\u8f83AL\u3001DA\u548cSSL\u5728\u4f4e\u6570\u636e\u573a\u666f\u4e0b\u7684\u6548\u679c\uff0c\u5e76\u6d4b\u8bd5AL\u4e0eDA\u548cSSL\u7ed3\u5408\u7684\u6548\u679c\u3002", "result": "AL\u5355\u72ec\u6548\u679c\u8f83\u5dee\uff0c\u4f46\u4e0eDA\u548cSSL\u7ed3\u5408\u540e\u4ecd\u80fd\u63d0\u4f9b\u989d\u5916\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "AL\u5e94\u4f5c\u4e3aDA\u548cSSL\u540e\u7684\u8865\u5145\u65b9\u6cd5\uff0c\u800c\u975e\u89e3\u51b3\u6807\u7b7e\u7f3a\u5931\u7684\u4e3b\u8981\u624b\u6bb5\u3002"}}
{"id": "2508.00712", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00712", "abs": "https://arxiv.org/abs/2508.00712", "authors": ["Dien Nguyen", "Diego Perez-Liebana", "Simon Lucas"], "title": "JSON-Bag: A generic game trajectory representation", "comment": "8 pages, 3 figures, 6 tables, to be published in IEEE Conference on\n  Games 2025", "summary": "We introduce JSON Bag-of-Tokens model (JSON-Bag) as a method to generically\nrepresent game trajectories by tokenizing their JSON descriptions and apply\nJensen-Shannon distance (JSD) as distance metric for them. Using a\nprototype-based nearest-neighbor search (P-NNS), we evaluate the validity of\nJSON-Bag with JSD on six tabletop games -- \\textit{7 Wonders},\n\\textit{Dominion}, \\textit{Sea Salt and Paper}, \\textit{Can't Stop},\n\\textit{Connect4}, \\textit{Dots and boxes} -- each over three game trajectory\nclassification tasks: classifying the playing agents, game parameters, or game\nseeds that were used to generate the trajectories.\n  Our approach outperforms a baseline using hand-crafted features in the\nmajority of tasks. Evaluating on N-shot classification suggests using JSON-Bag\nprototype to represent game trajectory classes is also sample efficient.\nAdditionally, we demonstrate JSON-Bag ability for automatic feature extraction\nby treating tokens as individual features to be used in Random Forest to solve\nthe tasks above, which significantly improves accuracy on underperforming\ntasks. Finally, we show that, across all six games, the JSD between JSON-Bag\nprototypes of agent classes highly correlates with the distances between\nagents' policies.", "AI": {"tldr": "JSON-Bag\u6a21\u578b\u901a\u8fc7JSON\u63cf\u8ff0\u7684\u6e38\u620f\u8f68\u8ff9\u8fdb\u884c\u6807\u8bb0\u5316\uff0c\u5e76\u4f7f\u7528Jensen-Shannon\u8ddd\u79bb\uff08JSD\uff09\u4f5c\u4e3a\u5ea6\u91cf\u6807\u51c6\uff0c\u5728\u516d\u6b3e\u684c\u6e38\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u63d0\u51fa\u4e00\u79cd\u901a\u7528\u7684\u6e38\u620f\u8f68\u8ff9\u8868\u793a\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u624b\u5de5\u7279\u5f81\u63d0\u53d6\u7684\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528JSON-Bag\u6a21\u578b\u6807\u8bb0\u5316\u6e38\u620f\u8f68\u8ff9\u7684JSON\u63cf\u8ff0\uff0c\u5e76\u5e94\u7528JSD\u4f5c\u4e3a\u8ddd\u79bb\u5ea6\u91cf\uff0c\u7ed3\u5408\u539f\u578b\u6700\u8fd1\u90bb\u641c\u7d22\uff08P-NNS\uff09\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728\u5927\u591a\u6570\u4efb\u52a1\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u6837\u672c\u6548\u7387\u9ad8\uff1b\u901a\u8fc7\u81ea\u52a8\u7279\u5f81\u63d0\u53d6\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u5206\u7c7b\u51c6\u786e\u6027\u3002", "conclusion": "JSON-Bag\u6a21\u578b\u662f\u4e00\u79cd\u6709\u6548\u7684\u6e38\u620f\u8f68\u8ff9\u8868\u793a\u65b9\u6cd5\uff0cJSD\u4e0e\u7b56\u7565\u8ddd\u79bb\u9ad8\u5ea6\u76f8\u5173\u3002"}}
{"id": "2508.00716", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00716", "abs": "https://arxiv.org/abs/2508.00716", "authors": ["Yingxu Wang", "Mengzhu Wang", "Zhichao Huang", "Suyu Liu"], "title": "Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning", "comment": null, "summary": "Graph Domain Adaptation (GDA) facilitates knowledge transfer from labeled\nsource graphs to unlabeled target graphs by learning domain-invariant\nrepresentations, which is essential in applications such as molecular property\nprediction and social network analysis. However, most existing GDA methods rely\non the assumption of clean source labels, which rarely holds in real-world\nscenarios where annotation noise is pervasive. This label noise severely\nimpairs feature alignment and degrades adaptation performance under domain\nshifts. To address this challenge, we propose Nested Graph Pseudo-Label\nRefinement (NeGPR), a novel framework tailored for graph-level domain\nadaptation with noisy labels. NeGPR first pretrains dual branches, i.e.,\nsemantic and topology branches, by enforcing neighborhood consistency in the\nfeature space, thereby reducing the influence of noisy supervision. To bridge\ndomain gaps, NeGPR employs a nested refinement mechanism in which one branch\nselects high-confidence target samples to guide the adaptation of the other,\nenabling progressive cross-domain learning. Furthermore, since pseudo-labels\nmay still contain noise and the pre-trained branches are already overfitted to\nthe noisy labels in the source domain, NeGPR incorporates a noise-aware\nregularization strategy. This regularization is theoretically proven to\nmitigate the adverse effects of pseudo-label noise, even under the presence of\nsource overfitting, thus enhancing the robustness of the adaptation process.\nExtensive experiments on benchmark datasets demonstrate that NeGPR consistently\noutperforms state-of-the-art methods under severe label noise, achieving gains\nof up to 12.7% in accuracy.", "AI": {"tldr": "NeGPR\u662f\u4e00\u79cd\u9488\u5bf9\u5e26\u566a\u58f0\u6807\u7b7e\u7684\u56fe\u7ea7\u57df\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5206\u652f\u9884\u8bad\u7ec3\u548c\u5d4c\u5957\u4f2a\u6807\u7b7e\u7ec6\u5316\u673a\u5236\u63d0\u5347\u8de8\u57df\u5b66\u4e60\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u56fe\u57df\u9002\u5e94\u65b9\u6cd5\u5047\u8bbe\u6e90\u6807\u7b7e\u5e72\u51c0\uff0c\u4f46\u5b9e\u9645\u4e2d\u6807\u7b7e\u566a\u58f0\u666e\u904d\u5b58\u5728\uff0c\u4e25\u91cd\u5f71\u54cd\u6027\u80fd\u3002", "method": "NeGPR\u901a\u8fc7\u53cc\u5206\u652f\u9884\u8bad\u7ec3\uff08\u8bed\u4e49\u548c\u62d3\u6251\uff09\u548c\u5d4c\u5957\u4f2a\u6807\u7b7e\u7ec6\u5316\u673a\u5236\uff0c\u7ed3\u5408\u566a\u58f0\u611f\u77e5\u6b63\u5219\u5316\u7b56\u7565\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cNeGPR\u5728\u4e25\u91cd\u6807\u7b7e\u566a\u58f0\u4e0b\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe12.7%\u3002", "conclusion": "NeGPR\u6709\u6548\u89e3\u51b3\u4e86\u6807\u7b7e\u566a\u58f0\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u56fe\u57df\u9002\u5e94\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2508.00627", "categories": ["cs.LG", "I.4.9; I.4.6"], "pdf": "https://arxiv.org/pdf/2508.00627", "abs": "https://arxiv.org/abs/2508.00627", "authors": ["Paul Tresson", "Pierre Le Coz", "Hadrien Tulet", "Anthony Malkassian", "Maxime R\u00e9jou M\u00e9chain"], "title": "IAMAP: Unlocking Deep Learning in QGIS for non-coders and limited computing resources", "comment": "11 pages, 5 figures", "summary": "Remote sensing has entered a new era with the rapid development of artificial\nintelligence approaches. However, the implementation of deep learning has\nlargely remained restricted to specialists and has been impractical because it\noften requires (i) large reference datasets for model training and validation;\n(ii) substantial computing resources; and (iii) strong coding skills. Here, we\nintroduce IAMAP, a user-friendly QGIS plugin that addresses these three\nchallenges in an easy yet flexible way. IAMAP builds on recent advancements in\nself-supervised learning strategies, which now provide robust feature\nextractors, often referred to as foundation models. These generalist models can\noften be reliably used in few-shot or zero-shot scenarios (i.e., with little to\nno fine-tuning). IAMAP's interface allows users to streamline several key steps\nin remote sensing image analysis: (i) extracting image features using a wide\nrange of deep learning architectures; (ii) reducing dimensionality with\nbuilt-in algorithms; (iii) performing clustering on features or their reduced\nrepresentations; (iv) generating feature similarity maps; and (v) calibrating\nand validating supervised machine learning models for prediction. By enabling\nnon-AI specialists to leverage the high-quality features provided by recent\ndeep learning approaches without requiring GPU capacity or extensive reference\ndatasets, IAMAP contributes to the democratization of computationally efficient\nand energy-conscious deep learning methods.", "AI": {"tldr": "IAMAP\u662f\u4e00\u4e2a\u7528\u6237\u53cb\u597d\u7684QGIS\u63d2\u4ef6\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u7b56\u7565\u7b80\u5316\u4e86\u9065\u611f\u56fe\u50cf\u5206\u6790\uff0c\u4f7f\u975eAI\u4e13\u5bb6\u4e5f\u80fd\u9ad8\u6548\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u5728\u9065\u611f\u5e94\u7528\u4e2d\u9700\u8981\u5927\u91cf\u6570\u636e\u3001\u8ba1\u7b97\u8d44\u6e90\u548c\u7f16\u7801\u6280\u80fd\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u901a\u7528\u6a21\u578b\uff0c\u63d0\u4f9b\u7279\u5f81\u63d0\u53d6\u3001\u964d\u7ef4\u3001\u805a\u7c7b\u7b49\u529f\u80fd\uff0c\u65e0\u9700GPU\u6216\u5927\u91cf\u6570\u636e\u3002", "result": "IAMAP\u4e3a\u975e\u4e13\u5bb6\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u8282\u80fd\u7684\u6df1\u5ea6\u5b66\u4e60\u5de5\u5177\uff0c\u63a8\u52a8\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u666e\u53ca\u3002", "conclusion": "IAMAP\u901a\u8fc7\u7b80\u5316\u6d41\u7a0b\u548c\u964d\u4f4e\u95e8\u69db\uff0c\u4fc3\u8fdb\u4e86\u9065\u611f\u9886\u57df\u6df1\u5ea6\u5b66\u4e60\u7684\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2508.00734", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00734", "abs": "https://arxiv.org/abs/2508.00734", "authors": ["Liuyun Xu", "Seymour M. J. Spence"], "title": "Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for Failure Analysis of Nonlinear Stochastic Systems", "comment": null, "summary": "Existing variance reduction techniques used in stochastic simulations for\nrare event analysis still require a substantial number of model evaluations to\nestimate small failure probabilities. In the context of complex, nonlinear\nfinite element modeling environments, this can become computationally\nchallenging-particularly for systems subjected to stochastic excitation. To\naddress this challenge, a multi-fidelity stratified sampling scheme with\nadaptive machine learning metamodels is introduced for efficiently propagating\nuncertainties and estimating small failure probabilities. In this approach, a\nhigh-fidelity dataset generated through stratified sampling is used to train a\ndeep learning-based metamodel, which then serves as a cost-effective and highly\ncorrelated low-fidelity model. An adaptive training scheme is proposed to\nbalance the trade-off between approximation quality and computational demand\nassociated with the development of the low-fidelity model. By integrating the\nlow-fidelity outputs with additional high-fidelity results, an unbiased\nestimate of the strata-wise failure probabilities is obtained using a\nmulti-fidelity Monte Carlo framework. The overall probability of failure is\nthen computed using the total probability theorem. Application to a full-scale\nhigh-rise steel building subjected to stochastic wind excitation demonstrates\nthat the proposed scheme can accurately estimate exceedance probability curves\nfor nonlinear responses of interest, while achieving significant computational\nsavings compared to single-fidelity variance reduction approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u4fdd\u771f\u5ea6\u5206\u5c42\u91c7\u6837\u548c\u81ea\u9002\u5e94\u673a\u5668\u5b66\u4e60\u5143\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u4f30\u8ba1\u5c0f\u5931\u6548\u6982\u7387\uff0c\u663e\u8457\u8282\u7701\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u975e\u7ebf\u6027\u6709\u9650\u5143\u6a21\u578b\u4e2d\u8ba1\u7b97\u5c0f\u5931\u6548\u6982\u7387\u65f6\u4ecd\u9700\u8981\u5927\u91cf\u6a21\u578b\u8bc4\u4f30\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u7ed3\u5408\u5206\u5c42\u91c7\u6837\u751f\u6210\u9ad8\u4fdd\u771f\u6570\u636e\u96c6\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u5143\u6a21\u578b\uff0c\u4f5c\u4e3a\u4f4e\u4fdd\u771f\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u8bad\u7ec3\u5e73\u8861\u7cbe\u5ea6\u4e0e\u8ba1\u7b97\u9700\u6c42\u3002", "result": "\u5e94\u7528\u4e8e\u9ad8\u5c42\u94a2\u7ed3\u6784\u5efa\u7b51\uff0c\u80fd\u51c6\u786e\u4f30\u8ba1\u975e\u7ebf\u6027\u54cd\u5e94\u7684\u8d85\u8d8a\u6982\u7387\u66f2\u7ebf\uff0c\u8ba1\u7b97\u6548\u7387\u663e\u8457\u4f18\u4e8e\u5355\u4fdd\u771f\u5ea6\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u8bc1\u7cbe\u5ea6\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u9002\u7528\u4e8e\u590d\u6742\u7cfb\u7edf\u7684\u7f55\u89c1\u4e8b\u4ef6\u5206\u6790\u3002"}}
{"id": "2508.00628", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00628", "abs": "https://arxiv.org/abs/2508.00628", "authors": ["Xiong Xiong", "Zhuo Zhang", "Rongchun Hu", "Chen Gao", "Zichen Deng"], "title": "Separated-Variable Spectral Neural Networks: A Physics-Informed Learning Approach for High-Frequency PDEs", "comment": null, "summary": "Solving high-frequency oscillatory partial differential equations (PDEs) is a\ncritical challenge in scientific computing, with applications in fluid\nmechanics, quantum mechanics, and electromagnetic wave propagation. Traditional\nphysics-informed neural networks (PINNs) suffer from spectral bias, limiting\ntheir ability to capture high-frequency solution components. We introduce\nSeparated-Variable Spectral Neural Networks (SV-SNN), a novel framework that\naddresses these limitations by integrating separation of variables with\nadaptive spectral methods. Our approach features three key innovations: (1)\ndecomposition of multivariate functions into univariate function products,\nenabling independent spatial and temporal networks; (2) adaptive Fourier\nspectral features with learnable frequency parameters for high-frequency\ncapture; and (3) theoretical framework based on singular value decomposition to\nquantify spectral bias. Comprehensive evaluation on benchmark problems\nincluding Heat equation, Helmholtz equation, Poisson equations and\nNavier-Stokes equations demonstrates that SV-SNN achieves 1-3 orders of\nmagnitude improvement in accuracy while reducing parameter count by over 90\\%\nand training time by 60\\%. These results establish SV-SNN as an effective\nsolution to the spectral bias problem in neural PDE solving. The implementation\nwill be made publicly available upon acceptance at\nhttps://github.com/xgxgnpu/SV-SNN.", "AI": {"tldr": "SV-SNN\u662f\u4e00\u79cd\u65b0\u578b\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u53d8\u91cf\u548c\u81ea\u9002\u5e94\u8c31\u65b9\u6cd5\u89e3\u51b3\u4e86\u4f20\u7edfPINNs\u5728\u9ad8\u9891\u632f\u8361PDE\u6c42\u89e3\u4e2d\u7684\u8c31\u504f\u5dee\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cbe\u5ea6\u548c\u6548\u7387\u3002", "motivation": "\u9ad8\u9891\u632f\u8361PDE\u6c42\u89e3\u5728\u79d1\u5b66\u8ba1\u7b97\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edfPINNs\u56e0\u8c31\u504f\u5dee\u96be\u4ee5\u6355\u6349\u9ad8\u9891\u89e3\u5206\u91cf\u3002", "method": "SV-SNN\u5c06\u591a\u5143\u51fd\u6570\u5206\u89e3\u4e3a\u5355\u53d8\u91cf\u51fd\u6570\u4e58\u79ef\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u5085\u91cc\u53f6\u8c31\u7279\u5f81\u548c\u53ef\u5b66\u4e60\u9891\u7387\u53c2\u6570\uff0c\u5e76\u901a\u8fc7SVD\u7406\u8bba\u91cf\u5316\u8c31\u504f\u5dee\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u95ee\u9898\u4e2d\uff0cSV-SNN\u7cbe\u5ea6\u63d0\u53471-3\u4e2a\u6570\u91cf\u7ea7\uff0c\u53c2\u6570\u51cf\u5c1190%\u4ee5\u4e0a\uff0c\u8bad\u7ec3\u65f6\u95f4\u7f29\u77ed60%\u3002", "conclusion": "SV-SNN\u6709\u6548\u89e3\u51b3\u4e86\u795e\u7ecfPDE\u6c42\u89e3\u4e2d\u7684\u8c31\u504f\u5dee\u95ee\u9898\uff0c\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2508.00635", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00635", "abs": "https://arxiv.org/abs/2508.00635", "authors": ["Changning Wu", "Gao Wu", "Rongyao Cai", "Yong Liu", "Kexin Zhang"], "title": "KFS: KAN based adaptive Frequency Selection learning architecture for long term time series forecasting", "comment": null, "summary": "Multi-scale decomposition architectures have emerged as predominant\nmethodologies in time series forecasting. However, real-world time series\nexhibit noise interference across different scales, while heterogeneous\ninformation distribution among frequency components at varying scales leads to\nsuboptimal multi-scale representation. Inspired by Kolmogorov-Arnold Networks\n(KAN) and Parseval's theorem, we propose a KAN based adaptive Frequency\nSelection learning architecture (KFS) to address these challenges. This\nframework tackles prediction challenges stemming from cross-scale noise\ninterference and complex pattern modeling through its FreK module, which\nperforms energy-distribution-based dominant frequency selection in the spectral\ndomain. Simultaneously, KAN enables sophisticated pattern representation while\ntimestamp embedding alignment synchronizes temporal representations across\nscales. The feature mixing module then fuses scale-specific patterns with\naligned temporal features. Extensive experiments across multiple real-world\ntime series datasets demonstrate that KT achieves state-of-the-art performance\nas a simple yet effective architecture.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eKAN\u7684\u81ea\u9002\u5e94\u9891\u7387\u9009\u62e9\u5b66\u4e60\u67b6\u6784\uff08KFS\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u591a\u5c3a\u5ea6\u566a\u58f0\u5e72\u6270\u548c\u9891\u7387\u4fe1\u606f\u5206\u5e03\u4e0d\u5747\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u65f6\u95f4\u5e8f\u5217\u5b58\u5728\u591a\u5c3a\u5ea6\u566a\u58f0\u5e72\u6270\u548c\u9891\u7387\u4fe1\u606f\u5206\u5e03\u4e0d\u5747\uff0c\u5bfc\u81f4\u591a\u5c3a\u5ea6\u8868\u793a\u4e0d\u7406\u60f3\u3002", "method": "\u7ed3\u5408Kolmogorov-Arnold Networks\uff08KAN\uff09\u548cParseval\u5b9a\u7406\uff0c\u8bbe\u8ba1KFS\u67b6\u6784\uff0c\u5305\u62ecFreK\u6a21\u5757\uff08\u57fa\u4e8e\u80fd\u91cf\u5206\u5e03\u9009\u62e9\u4e3b\u5bfc\u9891\u7387\uff09\u3001\u65f6\u95f4\u6233\u5d4c\u5165\u5bf9\u9f50\u548c\u7279\u5f81\u6df7\u5408\u6a21\u5757\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cKFS\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "KFS\u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u67b6\u6784\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u591a\u5c3a\u5ea6\u566a\u58f0\u5e72\u6270\u548c\u590d\u6742\u6a21\u5f0f\u5efa\u6a21\u95ee\u9898\u3002"}}
{"id": "2508.00754", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00754", "abs": "https://arxiv.org/abs/2508.00754", "authors": ["Yaxin Ma", "Benjamin Colburn", "Jose C. Principe"], "title": "A Simple and Effective Method for Uncertainty Quantification and OOD Detection", "comment": null, "summary": "Bayesian neural networks and deep ensemble methods have been proposed for\nuncertainty quantification; however, they are computationally intensive and\nrequire large storage. By utilizing a single deterministic model, we can solve\nthe above issue. We propose an effective method based on feature space density\nto quantify uncertainty for distributional shifts and out-of-distribution (OOD)\ndetection. Specifically, we leverage the information potential field derived\nfrom kernel density estimation to approximate the feature space density of the\ntraining set. By comparing this density with the feature space representation\nof test samples, we can effectively determine whether a distributional shift\nhas occurred. Experiments were conducted on a 2D synthetic dataset (Two Moons\nand Three Spirals) as well as an OOD detection task (CIFAR-10 vs. SVHN). The\nresults demonstrate that our method outperforms baseline models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7279\u5f81\u7a7a\u95f4\u5bc6\u5ea6\u7684\u5355\u786e\u5b9a\u6027\u6a21\u578b\u65b9\u6cd5\uff0c\u7528\u4e8e\u91cf\u5316\u5206\u5e03\u504f\u79fb\u548cOOD\u68c0\u6d4b\uff0c\u89e3\u51b3\u4e86\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u548c\u6df1\u5ea6\u96c6\u6210\u65b9\u6cd5\u7684\u9ad8\u8ba1\u7b97\u548c\u5b58\u50a8\u9700\u6c42\u95ee\u9898\u3002", "motivation": "\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u548c\u6df1\u5ea6\u96c6\u6210\u65b9\u6cd5\u867d\u7136\u80fd\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u4f46\u8ba1\u7b97\u548c\u5b58\u50a8\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u6838\u5bc6\u5ea6\u4f30\u8ba1\u5f97\u5230\u7684\u4fe1\u606f\u52bf\u573a\u8fd1\u4f3c\u8bad\u7ec3\u96c6\u7684\u7279\u5f81\u7a7a\u95f4\u5bc6\u5ea6\uff0c\u901a\u8fc7\u4e0e\u6d4b\u8bd5\u6837\u672c\u7684\u7279\u5f81\u7a7a\u95f4\u8868\u793a\u6bd4\u8f83\uff0c\u68c0\u6d4b\u5206\u5e03\u504f\u79fb\u548cOOD\u6837\u672c\u3002", "result": "\u57282D\u5408\u6210\u6570\u636e\u96c6\uff08Two Moons\u548cThree Spirals\uff09\u548cOOD\u68c0\u6d4b\u4efb\u52a1\uff08CIFAR-10 vs. SVHN\uff09\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u9ad8\u6548\u6027\u548c\u6027\u80fd\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5206\u5e03\u504f\u79fb\u548cOOD\u68c0\u6d4b\u4efb\u52a1\u3002"}}
{"id": "2508.00641", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00641", "abs": "https://arxiv.org/abs/2508.00641", "authors": ["Alessandro Palmas"], "title": "Reinforcement Learning for Decision-Level Interception Prioritization in Drone Swarm Defense", "comment": "11 pages, 10 figures", "summary": "The growing threat of low-cost kamikaze drone swarms poses a critical\nchallenge to modern defense systems demanding rapid and strategic\ndecision-making to prioritize interceptions across multiple effectors and\nhigh-value target zones. In this work, we present a case study demonstrating\nthe practical advantages of reinforcement learning in addressing this\nchallenge. We introduce a high-fidelity simulation environment that captures\nrealistic operational constraints, within which a decision-level reinforcement\nlearning agent learns to coordinate multiple effectors for optimal interception\nprioritization. Operating in a discrete action space, the agent selects which\ndrone to engage per effector based on observed state features such as\npositions, classes, and effector status. We evaluate the learned policy against\na handcrafted rule-based baseline across hundreds of simulated attack\nscenarios. The reinforcement learning based policy consistently achieves lower\naverage damage and higher defensive efficiency in protecting critical zones.\nThis case study highlights the potential of reinforcement learning as a\nstrategic layer within defense architectures, enhancing resilience without\ndisplacing existing control systems. All code and simulation assets are\npublicly released for full reproducibility, and a video demonstration\nillustrates the policy's qualitative behavior.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u9632\u5fa1\u4f4e\u6210\u672c\u81ea\u6740\u5f0f\u65e0\u4eba\u673a\u7fa4\u5a01\u80c1\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u9ad8\u4fdd\u771f\u6a21\u62df\u73af\u5883\u548c\u51b3\u7b56\u7ea7\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\uff0c\u4f18\u5316\u62e6\u622a\u4f18\u5148\u7ea7\uff0c\u663e\u8457\u964d\u4f4e\u5e73\u5747\u635f\u5bb3\u5e76\u63d0\u9ad8\u9632\u5fa1\u6548\u7387\u3002", "motivation": "\u4f4e\u6210\u672c\u81ea\u6740\u5f0f\u65e0\u4eba\u673a\u7fa4\u7684\u5a01\u80c1\u65e5\u76ca\u589e\u957f\uff0c\u73b0\u4ee3\u9632\u5fa1\u7cfb\u7edf\u9700\u8981\u5feb\u901f\u3001\u6218\u7565\u6027\u7684\u51b3\u7b56\u6765\u4f18\u5148\u62e6\u622a\u591a\u4e2a\u6548\u5e94\u5668\u548c\u9ad8\u4ef7\u503c\u76ee\u6807\u533a\u57df\u3002", "method": "\u5f15\u5165\u9ad8\u4fdd\u771f\u6a21\u62df\u73af\u5883\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u534f\u8c03\u591a\u4e2a\u6548\u5e94\u5668\uff0c\u57fa\u4e8e\u72b6\u6001\u7279\u5f81\uff08\u5982\u4f4d\u7f6e\u3001\u7c7b\u522b\u548c\u6548\u5e94\u5668\u72b6\u6001\uff09\u9009\u62e9\u62e6\u622a\u76ee\u6807\u3002", "result": "\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u5728\u6570\u767e\u6b21\u6a21\u62df\u653b\u51fb\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u4e8e\u624b\u5de5\u89c4\u5219\u57fa\u7ebf\uff0c\u5e73\u5747\u635f\u5bb3\u66f4\u4f4e\uff0c\u9632\u5fa1\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u53ef\u4f5c\u4e3a\u9632\u5fa1\u67b6\u6784\u7684\u6218\u7565\u5c42\uff0c\u63d0\u5347\u97e7\u6027\u800c\u4e0d\u53d6\u4ee3\u73b0\u6709\u63a7\u5236\u7cfb\u7edf\uff0c\u4ee3\u7801\u548c\u6a21\u62df\u8d44\u6e90\u5df2\u516c\u5f00\u4ee5\u786e\u4fdd\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2508.00643", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00643", "abs": "https://arxiv.org/abs/2508.00643", "authors": ["Albert Matveev", "Sanmitra Ghosh", "Aamal Hussain", "James-Michael Leahy", "Michalis Michaelides"], "title": "Light-Weight Diffusion Multiplier and Uncertainty Quantification for Fourier Neural Operators", "comment": null, "summary": "Operator learning is a powerful paradigm for solving partial differential\nequations, with Fourier Neural Operators serving as a widely adopted\nfoundation. However, FNOs face significant scalability challenges due to\noverparameterization and offer no native uncertainty quantification -- a key\nrequirement for reliable scientific and engineering applications. Instead,\nneural operators rely on post hoc UQ methods that ignore geometric inductive\nbiases. In this work, we introduce DINOZAUR: a diffusion-based neural operator\nparametrization with uncertainty quantification. Inspired by the structure of\nthe heat kernel, DINOZAUR replaces the dense tensor multiplier in FNOs with a\ndimensionality-independent diffusion multiplier that has a single learnable\ntime parameter per channel, drastically reducing parameter count and memory\nfootprint without compromising predictive performance. By defining priors over\nthose time parameters, we cast DINOZAUR as a Bayesian neural operator to yield\nspatially correlated outputs and calibrated uncertainty estimates. Our method\nachieves competitive or superior performance across several PDE benchmarks\nwhile providing efficient uncertainty quantification.", "AI": {"tldr": "DINOZAUR\u662f\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u795e\u7ecf\u7b97\u5b50\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u529f\u80fd\uff0c\u89e3\u51b3\u4e86FNO\u7684\u8fc7\u53c2\u6570\u5316\u548c\u7f3a\u4e4f\u539f\u751f\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u95ee\u9898\u3002", "motivation": "FNO\u5b58\u5728\u8fc7\u53c2\u6570\u5316\u548c\u7f3a\u4e4f\u539f\u751f\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u79d1\u5b66\u548c\u5de5\u7a0b\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "DINOZAUR\u901a\u8fc7\u5f15\u5165\u6269\u6563\u4e58\u5b50\u66ff\u4ee3FNO\u4e2d\u7684\u5bc6\u96c6\u5f20\u91cf\u4e58\u5b50\uff0c\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u548c\u5185\u5b58\u5360\u7528\uff0c\u5e76\u901a\u8fc7\u8d1d\u53f6\u65af\u65b9\u6cd5\u5b9e\u73b0\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "DINOZAUR\u5728\u591a\u4e2aPDE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "conclusion": "DINOZAUR\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u795e\u7ecf\u7b97\u5b50\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u79d1\u5b66\u548c\u5de5\u7a0b\u5e94\u7528\u3002"}}
{"id": "2508.00657", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00657", "abs": "https://arxiv.org/abs/2508.00657", "authors": ["Sihang Zeng", "Lucas Jing Liu", "Jun Wen", "Meliha Yetisgen", "Ruth Etzioni", "Gang Luo"], "title": "TrajSurv: Learning Continuous Latent Trajectories from Electronic Health Records for Trustworthy Survival Prediction", "comment": "Accepted by MLHC 2025", "summary": "Trustworthy survival prediction is essential for clinical decision making.\nLongitudinal electronic health records (EHRs) provide a uniquely powerful\nopportunity for the prediction. However, it is challenging to accurately model\nthe continuous clinical progression of patients underlying the irregularly\nsampled clinical features and to transparently link the progression to survival\noutcomes. To address these challenges, we develop TrajSurv, a model that learns\ncontinuous latent trajectories from longitudinal EHR data for trustworthy\nsurvival prediction. TrajSurv employs a neural controlled differential equation\n(NCDE) to extract continuous-time latent states from the irregularly sampled\ndata, forming continuous latent trajectories. To ensure the latent trajectories\nreflect the clinical progression, TrajSurv aligns the latent state space with\npatient state space through a time-aware contrastive learning approach. To\ntransparently link clinical progression to the survival outcome, TrajSurv uses\nlatent trajectories in a two-step divide-and-conquer interpretation process.\nFirst, it explains how the changes in clinical features translate into the\nlatent trajectory's evolution using a learned vector field. Second, it clusters\nthese latent trajectories to identify key clinical progression patterns\nassociated with different survival outcomes. Evaluations on two real-world\nmedical datasets, MIMIC-III and eICU, show TrajSurv's competitive accuracy and\nsuperior transparency over existing deep learning methods.", "AI": {"tldr": "TrajSurv\u662f\u4e00\u4e2a\u57fa\u4e8e\u7eb5\u5411\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u7684\u751f\u5b58\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\uff08NCDE\uff09\u5b66\u4e60\u8fde\u7eed\u6f5c\u5728\u8f68\u8ff9\uff0c\u5e76\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548c\u89e3\u91ca\u65b9\u6cd5\u63d0\u9ad8\u900f\u660e\u5ea6\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u7eb5\u5411EHR\u6570\u636e\u4e2d\u4e0d\u89c4\u5219\u91c7\u6837\u7684\u4e34\u5e8a\u7279\u5f81\u5efa\u6a21\u56f0\u96be\uff0c\u4ee5\u53ca\u5982\u4f55\u900f\u660e\u5730\u5c06\u4e34\u5e8a\u8fdb\u5c55\u4e0e\u751f\u5b58\u7ed3\u679c\u5173\u8054\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528NCDE\u63d0\u53d6\u8fde\u7eed\u65f6\u95f4\u6f5c\u5728\u72b6\u6001\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f50\u6f5c\u5728\u72b6\u6001\u4e0e\u60a3\u8005\u72b6\u6001\u7a7a\u95f4\uff0c\u5e76\u91c7\u7528\u4e24\u6b65\u89e3\u91ca\u65b9\u6cd5\uff08\u5411\u91cf\u573a\u548c\u805a\u7c7b\uff09\u5206\u6790\u4e34\u5e8a\u8fdb\u5c55\u4e0e\u751f\u5b58\u7ed3\u679c\u7684\u5173\u7cfb\u3002", "result": "\u5728MIMIC-III\u548ceICU\u6570\u636e\u96c6\u4e0a\uff0cTrajSurv\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\u3002", "conclusion": "TrajSurv\u4e3a\u4e34\u5e8a\u51b3\u7b56\u63d0\u4f9b\u4e86\u53ef\u4fe1\u8d56\u7684\u751f\u5b58\u9884\u6d4b\uff0c\u540c\u65f6\u901a\u8fc7\u900f\u660e\u7684\u65b9\u6cd5\u89e3\u91ca\u4e86\u4e34\u5e8a\u8fdb\u5c55\u4e0e\u751f\u5b58\u7ed3\u679c\u7684\u5173\u7cfb\u3002"}}
{"id": "2508.00664", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00664", "abs": "https://arxiv.org/abs/2508.00664", "authors": ["Jialun Zheng", "Jie Liu", "Jiannong Cao", "Xiao Wang", "Hanchen Yang", "Yankai Chen", "Philip S. Yu"], "title": "DP-DGAD: A Generalist Dynamic Graph Anomaly Detector with Dynamic Prototypes", "comment": null, "summary": "Dynamic graph anomaly detection (DGAD) is essential for identifying anomalies\nin evolving graphs across domains such as finance, traffic, and social\nnetworks. Recently, generalist graph anomaly detection (GAD) models have shown\npromising results. They are pretrained on multiple source datasets and\ngeneralize across domains. While effective on static graphs, they struggle to\ncapture evolving anomalies in dynamic graphs. Moreover, the continuous\nemergence of new domains and the lack of labeled data further challenge\ngeneralist DGAD. Effective cross-domain DGAD requires both domain-specific and\ndomain-agnostic anomalous patterns. Importantly, these patterns evolve\ntemporally within and across domains. Building on these insights, we propose a\nDGAD model with Dynamic Prototypes (DP) to capture evolving domain-specific and\ndomain-agnostic patterns. Firstly, DP-DGAD extracts dynamic prototypes, i.e.,\nevolving representations of normal and anomalous patterns, from temporal\nego-graphs and stores them in a memory buffer. The buffer is selectively\nupdated to retain general, domain-agnostic patterns while incorporating new\ndomain-specific ones. Then, an anomaly scorer compares incoming data with\ndynamic prototypes to flag both general and domain-specific anomalies. Finally,\nDP-DGAD employs confidence-based pseudo-labeling for effective self-supervised\nadaptation in target domains. Extensive experiments demonstrate\nstate-of-the-art performance across ten real-world datasets from different\ndomains.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u539f\u578b\uff08DP\uff09\u7684\u52a8\u6001\u56fe\u5f02\u5e38\u68c0\u6d4b\uff08DGAD\uff09\u6a21\u578b\uff0c\u7528\u4e8e\u6355\u6349\u8de8\u9886\u57df\u548c\u9886\u57df\u5185\u7684\u52a8\u6001\u5f02\u5e38\u6a21\u5f0f\uff0c\u5e76\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u52a8\u6001\u56fe\u5f02\u5e38\u68c0\u6d4b\u5728\u591a\u4e2a\u9886\u57df\uff08\u5982\u91d1\u878d\u3001\u4ea4\u901a\u3001\u793e\u4ea4\u7f51\u7edc\uff09\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u901a\u7528\u6a21\u578b\u96be\u4ee5\u6355\u6349\u52a8\u6001\u56fe\u4e2d\u7684\u5f02\u5e38\u6a21\u5f0f\uff0c\u4e14\u65b0\u9886\u57df\u7f3a\u4e4f\u6807\u6ce8\u6570\u636e\u3002", "method": "\u63d0\u51faDP-DGAD\u6a21\u578b\uff0c\u901a\u8fc7\u52a8\u6001\u539f\u578b\u63d0\u53d6\u548c\u5b58\u50a8\u6f14\u5316\u6a21\u5f0f\uff0c\u9009\u62e9\u6027\u66f4\u65b0\u5185\u5b58\u7f13\u51b2\u533a\uff0c\u5e76\u7ed3\u5408\u5f02\u5e38\u8bc4\u5206\u5668\u548c\u7f6e\u4fe1\u5ea6\u4f2a\u6807\u7b7e\u8fdb\u884c\u81ea\u76d1\u7763\u9002\u5e94\u3002", "result": "\u5728\u5341\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "DP-DGAD\u6a21\u578b\u80fd\u6709\u6548\u6355\u6349\u52a8\u6001\u56fe\u4e2d\u7684\u8de8\u9886\u57df\u548c\u9886\u57df\u5185\u5f02\u5e38\u6a21\u5f0f\uff0c\u9002\u7528\u4e8e\u7f3a\u4e4f\u6807\u6ce8\u6570\u636e\u7684\u65b0\u9886\u57df\u3002"}}
{"id": "2508.00692", "categories": ["cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.00692", "abs": "https://arxiv.org/abs/2508.00692", "authors": ["Young-ho Cho", "Hao Zhu", "Duehee Lee", "Ross Baldick"], "title": "Wind Power Scenario Generation based on the Generalized Dynamic Factor Model and Generative Adversarial Network", "comment": null, "summary": "For conducting resource adequacy studies, we synthesize multiple long-term\nwind power scenarios of distributed wind farms simultaneously by using the\nspatio-temporal features: spatial and temporal correlation, waveforms, marginal\nand ramp rates distributions of waveform, power spectral densities, and\nstatistical characteristics. Generating the spatial correlation in scenarios\nrequires the design of common factors for neighboring wind farms and\nantithetical factors for distant wind farms. The generalized dynamic factor\nmodel (GDFM) can extract the common factors through cross spectral density\nanalysis, but it cannot closely imitate waveforms. The GAN can synthesize\nplausible samples representing the temporal correlation by verifying samples\nthrough a fake sample discriminator. To combine the advantages of GDFM and GAN,\nwe use the GAN to provide a filter that extracts dynamic factors with temporal\ninformation from the observation data, and we then apply this filter in the\nGDFM to represent both spatial and frequency correlations of plausible\nwaveforms. Numerical tests on the combination of GDFM and GAN have demonstrated\nperformance improvements over competing alternatives in synthesizing wind power\nscenarios from Australia, better realizing plausible statistical\ncharacteristics of actual wind power compared to alternatives such as the GDFM\nwith a filter synthesized from distributions of actual dynamic filters and the\nGAN with direct synthesis without dynamic factors.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5e7f\u4e49\u52a8\u6001\u56e0\u5b50\u6a21\u578b\uff08GDFM\uff09\u548c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5408\u6210\u5206\u5e03\u5f0f\u98ce\u7535\u573a\u7684\u957f\u671f\u98ce\u7535\u529f\u7387\u573a\u666f\uff0c\u4ee5\u6539\u8fdb\u8d44\u6e90\u5145\u8db3\u6027\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u7684GDFM\u65b9\u6cd5\u867d\u80fd\u63d0\u53d6\u7a7a\u95f4\u76f8\u5173\u6027\uff0c\u4f46\u65e0\u6cd5\u51c6\u786e\u6a21\u62df\u6ce2\u5f62\uff1b\u800cGAN\u867d\u80fd\u751f\u6210\u65f6\u95f4\u76f8\u5173\u6027\u5f3a\u7684\u6837\u672c\uff0c\u4f46\u7f3a\u4e4f\u52a8\u6001\u56e0\u5b50\u3002\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u4ee5\u63d0\u5347\u98ce\u7535\u573a\u666f\u5408\u6210\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528GAN\u63d0\u53d6\u52a8\u6001\u56e0\u5b50\u5e76\u4f5c\u4e3a\u6ee4\u6ce2\u5668\uff0c\u518d\u5c06\u5176\u5e94\u7528\u4e8eGDFM\u4e2d\uff0c\u4ee5\u540c\u65f6\u6355\u6349\u7a7a\u95f4\u548c\u9891\u7387\u76f8\u5173\u6027\u3002", "result": "\u5728\u6fb3\u5927\u5229\u4e9a\u98ce\u7535\u6570\u636e\u4e0a\u7684\u6d4b\u8bd5\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u98ce\u7535\u573a\u666f\u65f6\u4f18\u4e8e\u5176\u4ed6\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u66f4\u771f\u5b9e\u5730\u53cd\u6620\u5b9e\u9645\u98ce\u7535\u7684\u7edf\u8ba1\u7279\u6027\u3002", "conclusion": "\u7ed3\u5408GDFM\u548cGAN\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u98ce\u7535\u573a\u666f\u5408\u6210\u7684\u6027\u80fd\uff0c\u4e3a\u8d44\u6e90\u5145\u8db3\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u8f93\u5165\u3002"}}
{"id": "2508.00695", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00695", "abs": "https://arxiv.org/abs/2508.00695", "authors": ["Sergio Rubio-Mart\u00edn", "Mar\u00eda Teresa Garc\u00eda-Ord\u00e1s", "Antonio Serrano-Garc\u00eda", "Clara Margarita Franch-Pato", "Arturo Crespo-\u00c1lvaro", "Jos\u00e9 Alberto Ben\u00edtez-Andrades"], "title": "Classification of Psychiatry Clinical Notes by Diagnosis: A Deep Learning and Machine Learning Approach", "comment": null, "summary": "The classification of clinical notes into specific diagnostic categories is\ncritical in healthcare, especially for mental health conditions like Anxiety\nand Adjustment Disorder. In this study, we compare the performance of various\nArtificial Intelligence models, including both traditional Machine Learning\napproaches (Random Forest, Support Vector Machine, K-nearest neighbors,\nDecision Tree, and eXtreme Gradient Boost) and Deep Learning models (DistilBERT\nand SciBERT), to classify clinical notes into these two diagnoses.\nAdditionally, we implemented three oversampling strategies: No Oversampling,\nRandom Oversampling, and Synthetic Minority Oversampling Technique (SMOTE), to\nassess their impact on model performance. Hyperparameter tuning was also\napplied to optimize model accuracy. Our results indicate that oversampling\ntechniques had minimal impact on model performance overall. The only exception\nwas SMOTE, which showed a positive effect specifically with BERT-based models.\nHowever, hyperparameter optimization significantly improved accuracy across the\nmodels, enhancing their ability to generalize and perform on the dataset. The\nDecision Tree and eXtreme Gradient Boost models achieved the highest accuracy\namong machine learning approaches, both reaching 96%, while the DistilBERT and\nSciBERT models also attained 96% accuracy in the deep learning category. These\nfindings underscore the importance of hyperparameter tuning in maximizing model\nperformance. This study contributes to the ongoing research on AI-assisted\ndiagnostic tools in mental health by providing insights into the efficacy of\ndifferent model architectures and data balancing methods.", "AI": {"tldr": "\u6bd4\u8f83\u591a\u79cdAI\u6a21\u578b\uff08\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\uff09\u5bf9\u4e34\u5e8a\u7b14\u8bb0\u5206\u7c7b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u8d85\u53c2\u6570\u8c03\u4f18\u663e\u8457\u63d0\u5347\u6a21\u578b\u51c6\u786e\u6027\uff0c\u800c\u8fc7\u91c7\u6837\u6280\u672f\u5f71\u54cd\u6709\u9650\u3002", "motivation": "\u7814\u7a76AI\u6a21\u578b\u5728\u5fc3\u7406\u5065\u5eb7\u8bca\u65ad\u4e2d\u7684\u5206\u7c7b\u6027\u80fd\uff0c\u4e3aAI\u8f85\u52a9\u8bca\u65ad\u5de5\u5177\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u4f7f\u7528\u591a\u79cd\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7ed3\u5408\u4e0d\u540c\u8fc7\u91c7\u6837\u7b56\u7565\u548c\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u8bc4\u4f30\u5206\u7c7b\u51c6\u786e\u6027\u3002", "result": "\u51b3\u7b56\u6811\u548cXGBoost\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u8868\u73b0\u6700\u4f73\uff0896%\u51c6\u786e\u7387\uff09\uff0cDistilBERT\u548cSciBERT\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u540c\u6837\u8fbe\u523096%\u3002\u8d85\u53c2\u6570\u8c03\u4f18\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u8d85\u53c2\u6570\u8c03\u4f18\u5bf9\u6a21\u578b\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u8fc7\u91c7\u6837\u6280\u672f\u5f71\u54cd\u6709\u9650\uff0c\u7814\u7a76\u4e3aAI\u8f85\u52a9\u5fc3\u7406\u5065\u5eb7\u8bca\u65ad\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2508.00706", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00706", "abs": "https://arxiv.org/abs/2508.00706", "authors": ["Haozhe Tian", "Pietro Ferraro", "Robert Shorten", "Mahdi Jalili", "Homayoun Hamedmoghadam"], "title": "Learning Network Dismantling without Handcrafted Inputs", "comment": null, "summary": "The application of message-passing Graph Neural Networks has been a\nbreakthrough for important network science problems. However, the competitive\nperformance often relies on using handcrafted structural features as inputs,\nwhich increases computational cost and introduces bias into the otherwise\npurely data-driven network representations. Here, we eliminate the need for\nhandcrafted features by introducing an attention mechanism and utilizing\nmessage-iteration profiles, in addition to an effective algorithmic approach to\ngenerate a structurally diverse training set of small synthetic networks.\nThereby, we build an expressive message-passing framework and use it to\nefficiently solve the NP-hard problem of Network Dismantling, virtually\nequivalent to vital node identification, with significant real-world\napplications. Trained solely on diversified synthetic networks, our proposed\nmodel -- MIND: Message Iteration Network Dismantler -- generalizes to large,\nunseen real networks with millions of nodes, outperforming state-of-the-art\nnetwork dismantling methods. Increased efficiency and generalizability of the\nproposed model can be leveraged beyond dismantling in a range of complex\nnetwork problems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u624b\u5de5\u7279\u5f81\u7684\u6d88\u606f\u4f20\u9012\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6MIND\uff0c\u7528\u4e8e\u89e3\u51b3NP\u96be\u7684\u7f51\u7edc\u62c6\u89e3\u95ee\u9898\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u771f\u5b9e\u7f51\u7edc\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u624b\u5de5\u7279\u5f81\uff0c\u589e\u52a0\u4e86\u8ba1\u7b97\u6210\u672c\u5e76\u5f15\u5165\u504f\u5dee\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u7eaf\u7cb9\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u6ce8\u610f\u529b\u673a\u5236\u548c\u6d88\u606f\u8fed\u4ee3\u5256\u9762\uff0c\u7ed3\u5408\u591a\u6837\u5316\u7684\u5408\u6210\u7f51\u7edc\u8bad\u7ec3\u96c6\uff0c\u6784\u5efa\u4e86MIND\u6846\u67b6\u3002", "result": "MIND\u5728\u672a\u89c1\u8fc7\u7684\u767e\u4e07\u8282\u70b9\u771f\u5b9e\u7f51\u7edc\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u9ad8\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MIND\u4e0d\u4ec5\u9002\u7528\u4e8e\u7f51\u7edc\u62c6\u89e3\uff0c\u8fd8\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u590d\u6742\u7f51\u7edc\u95ee\u9898\u3002"}}
{"id": "2508.00718", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00718", "abs": "https://arxiv.org/abs/2508.00718", "authors": ["Ivona Krchova", "Mariana Vargas Vieyra", "Mario Scriminaci", "Andrey Sidorenko"], "title": "Democratizing Tabular Data Access with an Open$\\unicode{x2013}$Source Synthetic$\\unicode{x2013}$Data SDK", "comment": null, "summary": "Machine learning development critically depends on access to high-quality\ndata. However, increasing restrictions due to privacy, proprietary interests,\nand ethical concerns have created significant barriers to data accessibility.\nSynthetic data offers a viable solution by enabling safe, broad data usage\nwithout compromising sensitive information. This paper presents the MOSTLY AI\nSynthetic Data Software Development Kit (SDK), an open-source toolkit designed\nspecifically for synthesizing high-quality tabular data. The SDK integrates\nrobust features such as differential privacy guarantees, fairness-aware data\ngeneration, and automated quality assurance into a flexible and accessible\nPython interface. Leveraging the TabularARGN autoregressive framework, the SDK\nsupports diverse data types and complex multi-table and sequential datasets,\ndelivering competitive performance with notable improvements in speed and\nusability. Currently deployed both as a cloud service and locally installable\nsoftware, the SDK has seen rapid adoption, highlighting its practicality in\naddressing real-world data bottlenecks and promoting widespread data\ndemocratization.", "AI": {"tldr": "MOSTLY AI SDK\u662f\u4e00\u4e2a\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5408\u6210\u8868\u683c\u6570\u636e\uff0c\u89e3\u51b3\u6570\u636e\u9690\u79c1\u548c\u8bbf\u95ee\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u9690\u79c1\u3001\u4e13\u6709\u5229\u76ca\u548c\u4f26\u7406\u95ee\u9898\uff0c\u9ad8\u8d28\u91cf\u6570\u636e\u7684\u83b7\u53d6\u53d7\u9650\uff0c\u5408\u6210\u6570\u636e\u6210\u4e3a\u4e00\u79cd\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8eTabularARGN\u81ea\u56de\u5f52\u6846\u67b6\uff0c\u96c6\u6210\u5dee\u5206\u9690\u79c1\u3001\u516c\u5e73\u6027\u751f\u6210\u548c\u81ea\u52a8\u5316\u8d28\u91cf\u4fdd\u8bc1\u3002", "result": "SDK\u5728\u901f\u5ea6\u548c\u53ef\u7528\u6027\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u652f\u6301\u591a\u79cd\u6570\u636e\u7c7b\u578b\u548c\u590d\u6742\u6570\u636e\u96c6\u3002", "conclusion": "SDK\u7684\u5feb\u901f\u91c7\u7528\u8868\u660e\u5176\u80fd\u6709\u6548\u89e3\u51b3\u6570\u636e\u74f6\u9888\uff0c\u63a8\u52a8\u6570\u636e\u6c11\u4e3b\u5316\u3002"}}
{"id": "2508.00758", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00758", "abs": "https://arxiv.org/abs/2508.00758", "authors": ["Timur Sattarov", "Marco Schreyer", "Damian Borth"], "title": "Diffusion-Scheduled Denoising Autoencoders for Anomaly Detection in Tabular Data", "comment": "22 pages, 16 figures, 7 tables, preprint version", "summary": "Anomaly detection in tabular data remains challenging due to complex feature\ninteractions and the scarcity of anomalous examples. Denoising autoencoders\nrely on fixed-magnitude noise, limiting adaptability to diverse data\ndistributions. Diffusion models introduce scheduled noise and iterative\ndenoising, but lack explicit reconstruction mappings. We propose the\nDiffusion-Scheduled Denoising Autoencoder (DDAE), a framework that integrates\ndiffusion-based noise scheduling and contrastive learning into the encoding\nprocess to improve anomaly detection. We evaluated DDAE on 57 datasets from\nADBench. Our method outperforms in semi-supervised settings and achieves\ncompetitive results in unsupervised settings, improving PR-AUC by up to 65%\n(9%) and ROC-AUC by 16% (6%) over state-of-the-art autoencoder (diffusion)\nmodel baselines. We observed that higher noise levels benefit unsupervised\ntraining, while lower noise with linear scheduling is optimal in\nsemi-supervised settings. These findings underscore the importance of\nprincipled noise strategies in tabular anomaly detection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6269\u6563\u6a21\u578b\u566a\u58f0\u8c03\u5ea6\u548c\u5bf9\u6bd4\u5b66\u4e60\u7684\u53bb\u566a\u81ea\u7f16\u7801\u5668\uff08DDAE\uff09\uff0c\u7528\u4e8e\u8868\u683c\u6570\u636e\u5f02\u5e38\u68c0\u6d4b\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8868\u683c\u6570\u636e\u5f02\u5e38\u68c0\u6d4b\u56e0\u590d\u6742\u7279\u5f81\u4ea4\u4e92\u548c\u5f02\u5e38\u6837\u672c\u7a00\u7f3a\u800c\u56f0\u96be\uff0c\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u53bb\u566a\u81ea\u7f16\u7801\u5668\u548c\u6269\u6563\u6a21\u578b\uff09\u5404\u6709\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faDDAE\u6846\u67b6\uff0c\u6574\u5408\u6269\u6563\u6a21\u578b\u7684\u566a\u58f0\u8c03\u5ea6\u548c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u4f18\u5316\u7f16\u7801\u8fc7\u7a0b\u3002", "result": "\u5728ADBench\u768457\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cDDAE\u5728\u534a\u76d1\u7763\u548c\u65e0\u76d1\u7763\u8bbe\u7f6e\u4e2d\u8868\u73b0\u4f18\u5f02\uff0cPR-AUC\u548cROC-AUC\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u566a\u58f0\u7b56\u7565\u5bf9\u8868\u683c\u5f02\u5e38\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\uff0cDDAE\u901a\u8fc7\u4f18\u5316\u566a\u58f0\u8c03\u5ea6\u548c\u5bf9\u6bd4\u5b66\u4e60\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\u3002"}}
{"id": "2508.00768", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00768", "abs": "https://arxiv.org/abs/2508.00768", "authors": ["Antonio Tudisco", "Andrea Marchesin", "Maurizio Zamboni", "Mariagrazia Graziano", "Giovanna Turvani"], "title": "Evaluating Angle and Amplitude Encoding Strategies for Variational Quantum Machine Learning: their impact on model's accuracy", "comment": null, "summary": "Recent advancements in Quantum Computing and Machine Learning have increased\nattention to Quantum Machine Learning (QML), which aims to develop machine\nlearning models by exploiting the quantum computing paradigm. One of the widely\nused models in this area is the Variational Quantum Circuit (VQC), a hybrid\nmodel where the quantum circuit handles data inference while classical\noptimization adjusts the parameters of the circuit. The quantum circuit\nconsists of an encoding layer, which loads data into the circuit, and a\ntemplate circuit, known as the ansatz, responsible for processing the data.\nThis work involves performing an analysis by considering both Amplitude- and\nAngle-encoding models, and examining how the type of rotational gate applied\naffects the classification performance of the model. This comparison is carried\nout by training the different models on two datasets, Wine and Diabetes, and\nevaluating their performance. The study demonstrates that, under identical\nmodel topologies, the difference in accuracy between the best and worst models\nranges from 10% to 30%, with differences reaching up to 41%. Moreover, the\nresults highlight how the choice of rotational gates used in encoding can\nsignificantly impact the model's classification performance. The findings\nconfirm that the embedding represents a hyperparameter for VQC models.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff08VQC\uff09\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u6bd4\u8f83\u4e86\u632f\u5e45\u548c\u89d2\u5ea6\u7f16\u7801\u6a21\u578b\u5728\u4e0d\u540c\u65cb\u8f6c\u95e8\u4e0b\u7684\u5206\u7c7b\u8868\u73b0\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u548c\u673a\u5668\u5b66\u4e60\u7684\u7ed3\u5408\u63a8\u52a8\u4e86\u91cf\u5b50\u673a\u5668\u5b66\u4e60\uff08QML\uff09\u7684\u53d1\u5c55\uff0c\u5176\u4e2d\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff08VQC\uff09\u662f\u4e00\u79cd\u5e38\u7528\u6a21\u578b\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e0d\u540c\u7f16\u7801\u65b9\u5f0f\u548c\u65cb\u8f6c\u95e8\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u632f\u5e45\u548c\u89d2\u5ea6\u7f16\u7801\u6a21\u578b\uff0c\u7ed3\u5408\u4e0d\u540c\u65cb\u8f6c\u95e8\uff0c\u5728Wine\u548cDiabetes\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u5e76\u8bc4\u4f30VQC\u7684\u5206\u7c7b\u6027\u80fd\u3002", "result": "\u5728\u76f8\u540c\u62d3\u6251\u7ed3\u6784\u4e0b\uff0c\u6700\u4f73\u548c\u6700\u5dee\u6a21\u578b\u7684\u51c6\u786e\u7387\u5dee\u5f02\u4e3a10%\u81f330%\uff0c\u6700\u9ad8\u8fbe41%\u3002\u65cb\u8f6c\u95e8\u7684\u9009\u62e9\u5bf9\u5206\u7c7b\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u7f16\u7801\u65b9\u5f0f\uff08\u5d4c\u5165\uff09\u662fVQC\u6a21\u578b\u7684\u4e00\u4e2a\u91cd\u8981\u8d85\u53c2\u6570\uff0c\u65cb\u8f6c\u95e8\u7684\u9009\u62e9\u663e\u8457\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2508.00785", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00785", "abs": "https://arxiv.org/abs/2508.00785", "authors": ["Bushra Akter", "Md Biplob Hosen", "Sabbir Ahmed", "Mehrin Anannya", "Md. Farhad Hossain"], "title": "Explainable AI and Machine Learning for Exam-based Student Evaluation: Causal and Predictive Analysis of Socio-academic and Economic Factors", "comment": null, "summary": "Academic performance depends on a multivariable nexus of socio-academic and\nfinancial factors. This study investigates these influences to develop\neffective strategies for optimizing students' CGPA. To achieve this, we\nreviewed various literature to identify key influencing factors and constructed\nan initial hypothetical causal graph based on the findings. Additionally, an\nonline survey was conducted, where 1,050 students participated, providing\ncomprehensive data for analysis. Rigorous data preprocessing techniques,\nincluding cleaning and visualization, ensured data quality before analysis.\nCausal analysis validated the relationships among variables, offering deeper\ninsights into their direct and indirect effects on CGPA. Regression models were\nimplemented for CGPA prediction, while classification models categorized\nstudents based on performance levels. Ridge Regression demonstrated strong\npredictive accuracy, achieving a Mean Absolute Error of 0.12 and a Mean Squared\nError of 0.023. Random Forest outperformed in classification, attaining an\nF1-score near perfection and an accuracy of 98.68%. Explainable AI techniques\nsuch as SHAP, LIME, and Interpret enhanced model interpretability, highlighting\ncritical factors such as study hours, scholarships, parental education, and\nprior academic performance. The study culminated in the development of a\nweb-based application that provides students with personalized insights,\nallowing them to predict academic performance, identify areas for improvement,\nand make informed decisions to enhance their outcomes.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5f71\u54cd\u5b66\u751fCGPA\u7684\u591a\u53d8\u91cf\u56e0\u7d20\uff0c\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u8c03\u67e5\u6570\u636e\u6784\u5efa\u56e0\u679c\u56fe\uff0c\u5229\u7528\u56de\u5f52\u548c\u5206\u7c7b\u6a21\u578b\u5206\u6790\uff0c\u5f00\u53d1\u4e86\u9884\u6d4b\u5b66\u672f\u8868\u73b0\u7684Web\u5e94\u7528\u3002", "motivation": "\u63a2\u7a76\u5f71\u54cd\u5b66\u672f\u8868\u73b0\u7684\u591a\u53d8\u91cf\u56e0\u7d20\uff0c\u4f18\u5316\u5b66\u751fCGPA\u3002", "method": "\u6587\u732e\u7efc\u8ff0\u3001\u5728\u7ebf\u8c03\u67e5\u3001\u6570\u636e\u9884\u5904\u7406\u3001\u56e0\u679c\u5206\u6790\u3001\u56de\u5f52\u4e0e\u5206\u7c7b\u6a21\u578b\uff08\u5982Ridge\u56de\u5f52\u548c\u968f\u673a\u68ee\u6797\uff09\u3001\u53ef\u89e3\u91caAI\u6280\u672f\uff08SHAP\u3001LIME\u3001Interpret\uff09\u3002", "result": "Ridge\u56de\u5f52\u9884\u6d4bCGPA\u7684MAE\u4e3a0.12\uff0cMSE\u4e3a0.023\uff1b\u968f\u673a\u68ee\u6797\u5206\u7c7b\u51c6\u786e\u7387\u8fbe98.68%\u3002\u5173\u952e\u56e0\u7d20\u5305\u62ec\u5b66\u4e60\u65f6\u95f4\u3001\u5956\u5b66\u91d1\u3001\u7236\u6bcd\u6559\u80b2\u80cc\u666f\u548c\u5148\u524d\u5b66\u672f\u8868\u73b0\u3002", "conclusion": "\u7814\u7a76\u6210\u529f\u8bc6\u522b\u5173\u952e\u5f71\u54cd\u56e0\u7d20\u5e76\u5f00\u53d1\u4e86Web\u5e94\u7528\uff0c\u4e3a\u5b66\u751f\u63d0\u4f9b\u4e2a\u6027\u5316\u5efa\u8bae\u4ee5\u4f18\u5316\u5b66\u672f\u8868\u73b0\u3002"}}
{"id": "2508.00806", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.00806", "abs": "https://arxiv.org/abs/2508.00806", "authors": ["Ping Chen", "Zhuohong Deng", "Ping Li", "Shuibing He", "Hongzi Zhu", "Yi Zheng", "Zhefeng Wang", "Baoxing Huai", "Minyi Guo"], "title": "Adacc: Adaptive Compression and Activation Checkpointing for LLM Memory Management", "comment": "8 pages", "summary": "Training large language models often employs recomputation to alleviate\nmemory pressure, which can introduce up to 30% overhead in real-world\nscenarios. In this paper, we propose Adacc, a novel memory management framework\nthat combines adaptive compression and activation checkpointing to reduce the\nGPU memory footprint. It comprises three modules: (1) We design layer-specific\ncompression algorithms that account for outliers in LLM tensors, instead of\ndirectly quantizing floats from FP16 to INT4, to ensure model accuracy. (2) We\npropose an optimal scheduling policy that employs MILP to determine the best\nmemory optimization for each tensor. (3) To accommodate changes in training\ntensors, we introduce an adaptive policy evolution mechanism that adjusts the\npolicy during training to enhance throughput. Experimental results show that\nAdacc can accelerate the LLM training by 1.01x to 1.37x compared to\nstate-of-the-art frameworks, while maintaining comparable model accuracy to the\nBaseline.", "AI": {"tldr": "Adacc\u662f\u4e00\u4e2a\u7ed3\u5408\u81ea\u9002\u5e94\u538b\u7f29\u548c\u6fc0\u6d3b\u68c0\u67e5\u70b9\u7684\u5185\u5b58\u7ba1\u7406\u6846\u67b6\uff0c\u65e8\u5728\u51cf\u5c11GPU\u5185\u5b58\u5360\u7528\u5e76\u52a0\u901f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u91cd\u8ba1\u7b97\u4f1a\u5f15\u5165\u9ad8\u8fbe30%\u7684\u5f00\u9500\uff0cAdacc\u65e8\u5728\u901a\u8fc7\u4f18\u5316\u5185\u5b58\u7ba1\u7406\u51cf\u5c11\u8fd9\u4e00\u5f00\u9500\u3002", "method": "Adacc\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff1a\u5c42\u7279\u5b9a\u538b\u7f29\u7b97\u6cd5\u3001\u57fa\u4e8eMILP\u7684\u6700\u4f18\u8c03\u5ea6\u7b56\u7565\u548c\u81ea\u9002\u5e94\u7b56\u7565\u6f14\u5316\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAdacc\u6bd4\u73b0\u6709\u6846\u67b6\u52a0\u901f1.01x\u81f31.37x\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u57fa\u7ebf\u76f8\u5f53\u7684\u6a21\u578b\u7cbe\u5ea6\u3002", "conclusion": "Adacc\u901a\u8fc7\u81ea\u9002\u5e94\u538b\u7f29\u548c\u7b56\u7565\u4f18\u5316\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u6a21\u578b\u7cbe\u5ea6\u3002"}}
