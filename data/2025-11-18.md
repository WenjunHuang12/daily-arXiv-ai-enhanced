<div id=toc></div>

# Table of Contents

- [cs.GT](#cs.GT) [Total: 8]
- [cs.IR](#cs.IR) [Total: 21]
- [cs.MM](#cs.MM) [Total: 2]
- [cs.DS](#cs.DS) [Total: 9]
- [cs.IT](#cs.IT) [Total: 9]
- [cs.DB](#cs.DB) [Total: 3]


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [1] [Collusion-proof Auction Design using Side Information](https://arxiv.org/abs/2511.12456)
*Sukanya Kudva,Anil Aswani*

Main category: cs.GT

TL;DR: 本文研究投标人合谋下的拍卖设计问题，提出混合VCG机制，结合VCG和定价机制，在存在合谋时仍能保证良好的社会福利和收益。


<details>
  <summary>Details</summary>
Motivation: 传统VCG机制虽然能实现效率和真实性，但极易受到投标人合谋攻击；而完全防合谋机制仅限于定价形式，无法保证近似效率。需要设计在部分投标人合谋时仍能保持良好性能的拍卖机制。

Method: 提出混合VCG机制：对非合谋投标人使用VCG机制，对合谋投标人使用定价机制，并假设有黑盒合谋检测算法。该机制是事后占优策略激励相容的。

Result: 证明了H-VCG机制在已知和未知估值分布下都能提供社会福利和收益的概率保证。数值实验显示H-VCG始终优于仅对非合谋投标人使用VCG，且接近理想VCG机制的性能。

Conclusion: 为将合谋检测融入机制设计提供了原则性框架，向防合谋拍卖迈出了重要一步。

Abstract: We study the problem of auction design in the presence of bidder collusion. Specifically, we consider a multi-unit auction of identical items with single-minded bidders, where a subset of bidders may collude by coordinating bids and transferring payments and items among themselves. While the classical Vickrey-Clarke-Groves (VCG) mechanism achieves efficient and truthful outcomes, it is highly vulnerable to collusion. In contrast, fully collusion-proof mechanisms are limited to posted-price formats, which fail to guarantee even approximate efficiency. This paper aims to bridge this gap by designing auctions that achieve good welfare and revenue guarantees even when some bidders collude. We first characterize the strategic behavior of colluding bidders under VCG and prove that such bidders optimally bid shade: they never overbid or take additional items, but instead reduce the auction price. This characterization enables a Bulow-Klemperer type result: adding colluding bidders can only improve welfare and revenue relative to running VCG on the non-colluding group alone. We then propose a Hybrid VCG (H-VCG) mechanism that combines VCG applied to non-colluding bidders with a posted-price mechanism for colluding bidders, assuming access to a black-box collusion detection algorithm. We show that H-VCG is ex-post dominant-strategy incentive compatible (DSIC) and derive probabilistic guarantees on expected welfare and revenue under both known and unknown valuation distributions. Numerical experiments across several distributions demonstrate that H-VCG consistently outperforms VCG restricted to non-colluding bidders and approaches the performance of the ideal VCG mechanism assuming universal truthfulness. Our results provide a principled framework for incorporating collusion detection into mechanism design, offering a step toward collusion-resistant auctions.

</details>


### [2] [Perturbing Best Responses in Zero-Sum Games](https://arxiv.org/abs/2511.12523)
*Adam Dziwoki,Rostislav Horcik*

Main category: cs.GT

TL;DR: 本文研究了在零和博弈中，基于最佳响应的算法（双Oracle和虚拟博弈）在效用扰动下的表现。研究发现扰动可以减少算法迭代次数，在某些情况下甚至能达到对数级别的期望迭代次数。


<details>
  <summary>Details</summary>
Motivation: 研究效用扰动对零和博弈中纳什均衡近似算法的影响，探索如何通过扰动提高算法效率。

Method: 假设Oracle在计算最佳响应时对效用进行扰动，分析双Oracle和虚拟博弈算法在扰动下的表现。

Result: 使用扰动Oracle可以减少两种算法的迭代次数，某些情况下期望迭代次数可达到对数级别。虽然效用扰动计算成本高，但在具有内部结构的博弈中可以高效实现。

Conclusion: 效用扰动能有效提高零和博弈中纳什均衡近似算法的收敛速度，特别是在具有结构化的博弈中可以实现高效扰动。

Abstract: This paper investigates the impact of perturbations on the best-response-based algorithms approximating Nash equilibria in zero-sum games, namely Double Oracle and Fictitious Play. More precisely, we assume that the oracle computing the best responses perturbs the utilities before selecting the best response. We show that using such an oracle reduces the number of iterations for both algorithms. For some cases, suitable perturbations ensure the expected number of iterations is logarithmic. Although the utility perturbation is computationally demanding as it requires iterating through all pure strategies, we demonstrate that one can efficiently perturb the utilities in games where pure strategies have further inner structure.

</details>


### [3] [Bandit Learning in Housing Markets](https://arxiv.org/abs/2511.12629)
*Shiyun Lin*

Main category: cs.GT

TL;DR: 该论文将住房市场模型与多臂老虎机框架结合，提出了在偏好未知情况下通过重复交互学习偏好的统计学习模型，定义了核心遗憾作为市场目标，研究了集中式和分布式方法，并证明了遗憾上界和下界。


<details>
  <summary>Details</summary>
Motivation: 住房市场模型在经济学和计算机科学中已被广泛研究，但偏好未知且需要通过重复交互学习的情况很少受到关注。

Method: 在多玩家多臂老虎机框架下，玩家从随机奖励中学习对商品的偏好，提出了核心遗憾的概念，研究了集中式和分布式两种方法。

Result: 证明了O(N log T / Δ²)的遗憾上界，其中N是玩家数量，T是时间范围，Δ是玩家间最小偏好差距。对于分布式设置，还建立了匹配的下界，表明算法是阶最优的。

Conclusion: 该研究为偏好未知的住房市场提供了有效的学习算法，在集中式和分布式设置下都实现了最优的遗憾界限。

Abstract: The housing market, also known as one-sided matching market, is a classic exchange economy model where each agent on the demand side initially owns an indivisible good (a house) and has a personal preference over all goods. The goal is to find a core-stable allocation that exhausts all mutually beneficial exchanges among subgroups of agents. While this model has been extensively studied in economics and computer science due to its broad applications, little attention has been paid to settings where preferences are unknown and must be learned through repeated interactions. In this paper, we propose a statistical learning model within the multi-player multi-armed bandit framework, where players (agents) learn their preferences over arms (goods) from stochastic rewards. We introduce the notion of core regret for each player as the market objective. We study both centralized and decentralized approaches, proving $O(N \log T / Δ^2)$ upper bounds on regret, where $N$ is the number of players, $T$ is the time horizon and $Δ$ is the minimum preference gap among players. For the decentralized setting, we also establish a matching lower bound, demonstrating that our algorithm is order-optimal.

</details>


### [4] [Rethinking Data Value: Asymmetric Data Shapley for Structure-Aware Valuation in Data Markets and Machine Learning Pipelines](https://arxiv.org/abs/2511.12863)
*Xi Zheng,Yinghui Huang,Xiangyu Chang,Ruoxi Jia,Yong Tan*

Main category: cs.GT

TL;DR: 提出了非对称数据Shapley(ADS)框架，用于在存在方向性和时间依赖性的现代ML/AI流程中进行数据估值，突破了经典数据Shapley的对称性限制。


<details>
  <summary>Details</summary>
Motivation: 经典数据Shapley的对称性假设无法捕捉现代ML/AI工作流中的方向性和时间依赖性，如重复/增强数据对原始数据的依赖以及顺序流程中的特定贡献。

Method: ADS通过仅在应用特定数据组排序一致的排列上平均边际贡献来放松对称性，保持效率和线性性，维持组内对称性和组间方向优先性。

Result: 在具有方向性和时间依赖性的代表性设置中，ADS始终优于基准方法，能够区分新颖和冗余贡献并尊重训练的顺序性。

Conclusion: ADS为数据市场和复杂ML/AI流程中的公平数据估值提供了原则性和实用性的方法。

Abstract: Rigorous valuation of individual data sources is critical for fair compensation in data markets, informed data acquisition, and transparent development of ML/AI models. Classical Data Shapley (DS) provides a essential axiomatic framework for data valuation but is constrained by its symmetry axiom that assumes interchangeability of data sources. This assumption fails to capture the directional and temporal dependencies prevalent in modern ML/AI workflows, including the reliance of duplicated or augmented data on original sources and the order-specific contributions in sequential pipelines such as federated learning and multi-stage LLM fine tuning. To address these limitations, we introduce Asymmetric Data Shapley (ADS), a structure-aware data valuation framework for modern ML/AI pipelines. ADS relaxes symmetry by averaging marginal contributions only over permutations consistent with an application-specific ordering of data groups. It preserves efficiency and linearity, maintains within group symmetry and directional precedence across groups, and reduces to DS when the ordering collapses to a single group. We develop two complementary computational procedures for ADS: (i) a Monte Carlo estimator (MC-ADS) with finite-sample accuracy guarantees, and (ii) a k-nearest neighbor surrogate (KNN-ADS) that is exact and efficient for KNN predictors. Across representative settings with directional and temporal dependence, ADS consistently outperforms benchmark methods by distinguishing novel from redundant contributions and respecting the sequential nature of training. These results establish ADS as a principled and practical approach to equitable data valuation in data markets and complex ML/AI pipelines.

</details>


### [5] [Resilient and Efficient Allocation for Large-Scale Autonomous Fleets via Decentralized Coordination](https://arxiv.org/abs/2511.12879)
*Ashish Kumar Perukari,Polina Khoroshevskaya*

Main category: cs.GT

TL;DR: 提出了一种结合分布预测与去中心化协调的资源分配方法，利用局部侧信息构建风险模型，通过轻量级共识-ADMM算法在稀疏通信图上协调数千个智能体，在真实城市道路网络和卫星星座中验证了性能。


<details>
  <summary>Details</summary>
Motivation: 大规模自主车队运营需要在不确定性下快速、弹性地分配稀缺资源（如能源、充电器访问、维护时段等），传统方法难以同时满足可扩展性和鲁棒性要求。

Method: 结合分布预测与去中心化协调，利用局部侧信息构建每个智能体的风险模型，通过机会约束耦合风险，采用轻量级共识-ADMM算法在稀疏通信图上进行协调。

Result: 在真实城市道路网络和卫星星座测试中，相比贪婪、无侧信息和集中式基准方法，故障率降低30-55%，成本相当，可扩展到数千个智能体且运行时间接近线性，高概率保持可行性。

Conclusion: 该方法实现了接近集中式性能的去中心化资源分配，避免了单点故障，在大规模自主系统中具有实用价值。

Abstract: Operating large autonomous fleets demands fast, resilient allocation of scarce resources (such as energy and fuel, charger access and maintenance slots, time windows, and communication bandwidth) under uncertainty. We propose a side-information-aware approach for resource allocation at scale that combines distributional predictions with decentralized coordination. Local side information shapes per-agent risk models for consumption, which are coupled through chance constraints on failures. A lightweight consensus-ADMM routine coordinates agents over a sparse communication graph, enabling near-centralized performance while avoiding single points of failure. We validate the framework on real urban road networks with autonomous vehicles and on a representative satellite constellation, comparing against greedy, no-side-information, and oracle central baselines. Our method reduces failure rates by 30-55% at matched cost and scales to thousands of agents with near-linear runtime, while preserving feasibility with high probability.

</details>


### [6] [An FPTAS for 7/9-Approximation to Maximin Share Allocations](https://arxiv.org/abs/2511.13056)
*Xin Huang,Shengwei Zhou*

Main category: cs.GT

TL;DR: 提出新算法，将不可分割物品的最大最小份额（MMS）分配近似比从10/13提升到7/9，并开发了FPTAS实现7/9-ε近似，算法更简单


<details>
  <summary>Details</summary>
Motivation: 改进现有MMS分配问题的近似比，当前最佳结果为10/13，寻求更优的近似保证和更简单的算法

Method: 基于新的分析框架设计算法，构建FPTAS在多项式时间内实现7/9-ε近似

Result: 达到7/9近似比，优于之前的10/13，算法复杂度为1/ε的多项式时间

Conclusion: 成功提升了MMS分配的近似比至7/9，同时提供了更简单高效的算法实现

Abstract: We present a new algorithm that achieves a $\frac{7}{9}$-approximation for the maximin share (MMS) allocation of indivisible goods under additive valuations, improving the current best ratio of $\frac{10}{13}$ (Heidari et al., SODA 2026). Building on a new analytical framework, we further obtain an FPTAS that achieves a $\frac{7}{9}-\varepsilon$ approximation in $\tfrac{1}{\varepsilon} \cdot \mathrm{poly}(n,m)$ time. Compared with prior work (Heidari et al., SODA 2026), our algorithm is substantially simpler.

</details>


### [7] [MEV in Multiple Concurrent Proposer Blockchains](https://arxiv.org/abs/2511.13080)
*Steven Landers,Benjamin Marsh*

Main category: cs.GT

TL;DR: 分析多并发提议者区块链中的最大可提取价值，探讨并发性如何打破单构建者假设并引入新的MEV渠道，包括同tick重复窃取、提议者间拍卖和可用性证明延迟驱动的时序竞争。


<details>
  <summary>Details</summary>
Motivation: 研究多并发提议者区块链中MEV的新特征，这些链中多个区块在最终执行顺序确定前就已数据可用，这种并发性打破了顺序链的单构建者假设。

Method: 开发延迟和包含的标准化风险模型，推导闭式延迟包络M(τ)，并描述审查、重复和拍卖博弈的均衡状态。

Result: 展示了确定性优先级DAG调度和重复感知支付如何在不影响吞吐量的情况下消除同tick MEV，确定了简单的协议配置来缓解MCP特定提取而无需集中化构建者。

Conclusion: 多并发提议者区块链需要新的MEV缓解机制，确定性调度和重复感知支付是有效的解决方案，可在保持吞吐量的同时减少MEV提取。

Abstract: We analyze maximal extractable value in multiple concurrent proposer blockchains, where multiple blocks become data available before their final execution order is determined. This concurrency breaks the single builder assumption of sequential chains and introduces new MEV channels, including same tick duplicate steals, proposer to proposer auctions, and timing races driven by proof of availability latency. We develop a hazard normalized model of delay and inclusion, derive a closed form delay envelope \(M(τ)\), and characterize equilibria for censorship, duplication, and auction games. We show how deterministic priority DAG scheduling and duplicate aware payouts neutralize same tick MEV while preserving throughput, identifying simple protocol configurations to mitigate MCP specific extraction without centralized builders.

</details>


### [8] [The Publication Choice Problem](https://arxiv.org/abs/2511.13678)
*Haichuan Wang,Yifan Wu,Haifeng Xu*

Main category: cs.GT

TL;DR: 研究者战略性地选择投稿期刊以最大化影响力，这些出版决策反过来决定期刊的影响因子。本文引入博弈论框架分析这种双向互动关系，研究均衡存在性及其性质，并探讨"亮点"标签对期刊影响力的影响。


<details>
  <summary>Details</summary>
Motivation: 研究学者如何通过选择投稿期刊来最大化其工作影响力，以及这些决策如何反过来塑造期刊的影响因子，揭示这种双向互动关系。

Method: 引入博弈论框架"出版选择问题"，分析纯策略均衡的存在性和唯一性，研究均衡性质，并探讨"亮点"标签对期刊影响力的影响机制。

Result: 证明了出版选择问题中纯策略均衡的存在性，在二元研究者类型下均衡具有唯一性。竞争性期刊使用"亮点"标签会降低其他期刊的总体影响力，而非竞争性期刊使用该标签则有相反效果。

Conclusion: 研究者出版选择与期刊影响因子之间存在复杂的双向互动关系，"亮点"标签的使用效果取决于期刊的竞争程度，为理解学术出版生态提供了新的理论视角。

Abstract: Researchers strategically choose where to submit their work in order to maximize its impact, and these publication decisions in turn determine venues' impact factors. To analyze how individual publication choices both respond to and shape venue impact, we introduce a game-theoretic framework, coined the Publication Choice Problem, that captures this two-way interplay. We show the existence of a pure-strategy equilibrium in the Publication Choice Problem and its uniqueness under binary researcher types. Our characterizations of the equilibrium properties offer insights about what publication behaviors better indicate a researcher's impact level. Through equilibrium analysis, we further investigate how labeling papers with ``spotlight'' affects the impact factor of venues in the research community. Our analysis shows that competitive venue labeling top papers with ``spotlight'' may decrease the overall impact of other venues in the community, while less competitive venues with ``spotlight'' labeling have the opposite impact.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [9] [The Environmental Impact of Ensemble Techniques in Recommender Systems](https://arxiv.org/abs/2511.11649)
*Jannik Nitschke*

Main category: cs.IR

TL;DR: 集成推荐系统能提升10-30%准确率但能耗未被充分评估。研究发现集成方法在提升0.3-5.7%准确率的同时，能耗增加19-2549%，Top Performers策略效率最佳，而穷举平均策略能耗过高。


<details>
  <summary>Details</summary>
Motivation: 集成技术在推荐系统中已证明能提升10-30%的准确率，但其环境影响尚未被测量。深度学习推荐算法每篇论文可产生3297kg CO2，而集成方法的能耗评估不足。

Method: 在两个框架(Surprise用于评分预测，LensKit用于排序)上进行了93次实验，使用四个数据集(10万到780万交互)，评估四种集成策略(平均、加权、堆叠/排序融合、Top Performers)，通过智能插座测量能耗。

Result: 集成方法实现0.3-5.7%准确率提升，但能耗增加19-2549%。Top Performers效率最佳：在MovieLens-1M上RMSE提升0.96%且能耗增加18.8%。穷举平均策略能耗增加88-270%但收益相当。最大数据集上集成方法能耗增加2005%但准确率仅提升1.2%。

Conclusion: 本研究首次系统测量了集成推荐系统的能耗和碳足迹，证明选择性策略比穷举平均更高效，揭示了工业规模下的可扩展性限制，为可持续算法选择提供了依据。

Abstract: Ensemble techniques in recommender systems have demonstrated accuracy improvements of 10-30%, yet their environmental impact remains unmeasured. While deep learning recommendation algorithms can generate up to 3,297 kg CO2 per paper, ensemble methods have not been sufficiently evaluated for energy consumption. This thesis investigates how ensemble techniques influence environmental impact compared to single optimized models.
  We conducted 93 experiments across two frameworks (Surprise for rating prediction, LensKit for ranking) on four datasets spanning 100,000 to 7.8 million interactions. We evaluated four ensemble strategies (Average, Weighted, Stacking/Rank Fusion, Top Performers) against simple baselines and optimized single models, measuring energy consumption with a smart plug.
  Results revealed a non-linear accuracy-energy relationship. Ensemble methods achieved 0.3-5.7% accuracy improvements while consuming 19-2,549% more energy depending on dataset size and strategy. The Top Performers ensemble showed best efficiency: 0.96% RMSE improvement with 18.8% energy overhead on MovieLens-1M, and 5.7% NDCG improvement with 103% overhead on MovieLens-100K. Exhaustive averaging strategies consumed 88-270% more energy for comparable gains. On the largest dataset (Anime, 7.8M interactions), the Surprise ensemble consumed 2,005% more energy (0.21 Wh vs. 0.01 Wh) for 1.2% accuracy improvement, producing 53.8 mg CO2 versus 2.6 mg CO2 for the single model.
  This research provides one of the first systematic measurements of energy and carbon footprint for ensemble recommender systems, demonstrates that selective strategies offer superior efficiency over exhaustive averaging, and identifies scalability limitations at industrial scale. These findings enable informed decisions about sustainable algorithm selection in recommender systems.

</details>


### [10] [GroupRank: A Groupwise Reranking Paradigm Driven by Reinforcement Learning](https://arxiv.org/abs/2511.11653)
*Duolin Sun,Meixiu Long,Dan Yang,Yihan Jiao,Zhehao Tan,Jie Feng,Junjie Wang,Yue Shen,Peng Wei,Jian Wang,Jinjie Gu*

Main category: cs.IR

TL;DR: 提出Groupwise重排序范式，结合点式方法的灵活性和列表式方法的比较能力，通过组内比较和GRPO训练解决现有重排序方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有重排序方法存在核心困境：点式方法独立评估文档，容易陷入'排序近视陷阱'；列表式方法能感知全局排序上下文，但存在'列表刚性'问题，处理大规模候选集时存在可扩展性和灵活性限制。

Method: 提出Groupwise重排序范式，将查询和一组候选文档共同输入模型进行组内比较，为每个文档分配相关性分数。采用GRPO训练，结合排序指标和分布奖励的异构奖励函数。提出合成高质量检索和排序数据的创新流程。

Result: 在两个推理密集型检索基准BRIGHT和R2MED上的广泛实验验证了方法的有效性。

Conclusion: Groupwise重排序范式成功解决了现有方法的局限性，在保持点式方法灵活性的同时实现了列表式方法的比较能力，为RAG系统提供了更优的重排序解决方案。

Abstract: Large Language Models have shown strong potential as rerankers to enhance the overall performance of RAG systems. However, existing reranking paradigms are constrained by a core theoretical and practical dilemma: Pointwise methods, while simple and highly flexible, evaluate documents independently, making them prone to the Ranking Myopia Trap, overlooking the relative importance between documents. In contrast, Listwise methods can perceive the global ranking context, but suffer from inherent List Rigidity, leading to severe scalability and flexibility issues when handling large candidate sets. To address these challenges, we propose Groupwise, a novel reranking paradigm. In this approach, the query and a group of candidate documents are jointly fed into the model, which performs within-group comparisons to assign individual relevance scores to each document. This design retains the flexibility of Pointwise methods while enabling the comparative capability of Listwise methods. We further adopt GRPO for model training, equipped with a heterogeneous reward function that integrates ranking metrics with a distributional reward aimed at aligning score distributions across groups. To overcome the bottleneck caused by the scarcity of high quality labeled data, we further propose an innovative pipeline for synthesizing high quality retrieval and ranking data. The resulting data can be leveraged not only for training the reranker but also for training the retriever. Extensive experiments validate the effectiveness of our approach. On two reasoning intensive retrieval benchmarks, BRIGHT and R2MED.

</details>


### [11] [A Multimodal Manufacturing Safety Chatbot: Knowledge Base Design, Benchmark Development, and Evaluation of Multiple RAG Approaches](https://arxiv.org/abs/2511.11847)
*Ryan Singh,Austin Hamilton,Amanda White,Michael Wise,Ibrahim Yousif,Arthur Carvalho,Zhe Shan,Reza Abrisham Baf,Mohammad Mayyas,Lora A. Cavuoto,Fadel M. Megahed*

Main category: cs.IR

TL;DR: 开发了一个基于大语言模型的多模态聊天机器人，用于工业5.0环境下的安全培训，通过检索增强生成技术实现高准确性、低延迟和低成本的安全指导。


<details>
  <summary>Details</summary>
Motivation: 工业5.0转向以人为本的操作模式，需要满足高精度、低延迟和低成本要求的下一代安全培训系统，以解决现代制造环境中的工人安全问题。

Method: 采用设计科学研究方法，开发基于检索增强生成的多模态聊天机器人，使用完整的因子设计测试24种RAG配置，并通过专家评估验证性能。

Result: 最佳配置达到86.66%的准确率，平均延迟10.04秒，每次查询成本0.005美元，显著提升了安全培训的效果和效率。

Conclusion: 该研究提供了开源的安全培训聊天机器人、验证的评估基准以及系统化的设计方法，为工业5.0环境下的AI辅助安全培训系统开发奠定了基础。

Abstract: Ensuring worker safety remains a critical challenge in modern manufacturing environments. Industry 5.0 reorients the prevailing manufacturing paradigm toward more human-centric operations. Using a design science research methodology, we identify three essential requirements for next-generation safety training systems: high accuracy, low latency, and low cost. We introduce a multimodal chatbot powered by large language models that meets these design requirements. The chatbot uses retrieval-augmented generation to ground its responses in curated regulatory and technical documentation. To evaluate our solution, we developed a domain-specific benchmark of expert-validated question and answer pairs for three representative machines: a Bridgeport manual mill, a Haas TL-1 CNC lathe, and a Universal Robots UR5e collaborative robot. We tested 24 RAG configurations using a full-factorial design and assessed them with automated evaluations of correctness, latency, and cost. Our top 2 configurations were then evaluated by ten industry experts and academic researchers. Our results show that retrieval strategy and model configuration have a significant impact on performance. The top configuration (selected for chatbot deployment) achieved an accuracy of 86.66%, an average latency of 10.04 seconds, and an average cost of $0.005 per query. Overall, our work provides three contributions: an open-source, domain-grounded safety training chatbot; a validated benchmark for evaluating AI-assisted safety instruction; and a systematic methodology for designing and assessing AI-enabled instructional and immersive safety training systems for Industry 5.0 environments.

</details>


### [12] [ComLQ: Benchmarking Complex Logical Queries in Information Retrieval](https://arxiv.org/abs/2511.12004)
*Ganlin Xu,Zhitao Yin,Linghao Zhang,Jiaqing Liang,Weijia Lu,Xiaodong Zhang,Zhifei Yang,Sihang Jiang,Deqing Yang*

Main category: cs.IR

TL;DR: 提出了一个用于复杂逻辑查询的信息检索数据集ComLQ，包含2,909个查询和11,251个候选段落，并设计了新的评估指标LSNC@K来专门评估检索模型处理否定查询的能力。


<details>
  <summary>Details</summary>
Motivation: 现有IR基准主要关注简单查询，忽略了包含一阶逻辑操作（合取、析取、否定）的复杂逻辑查询，无法充分评估IR模型在真实场景中对复杂查询的处理能力。

Method: 利用大语言模型（如GPT-4o）通过子图引导提示生成具有特定逻辑结构的查询，确保查询-段落对的结构一致性和证据分布，并通过专家标注进行验证。

Result: 零样本实验结果表明，现有检索模型在复杂逻辑查询上表现有限，特别是在处理否定查询时，暴露了它们在建模排除关系方面的不足。

Conclusion: ComLQ数据集填补了复杂逻辑查询评估的空白，LSNC@K指标能有效评估检索模型处理否定查询的能力，揭示了现有模型在逻辑推理方面的局限性。

Abstract: Information retrieval (IR) systems play a critical role in navigating information overload across various applications. Existing IR benchmarks primarily focus on simple queries that are semantically analogous to single- and multi-hop relations, overlooking \emph{complex logical queries} involving first-order logic operations such as conjunction ($\land$), disjunction ($\lor$), and negation ($\lnot$). Thus, these benchmarks can not be used to sufficiently evaluate the performance of IR models on complex queries in real-world scenarios. To address this problem, we propose a novel method leveraging large language models (LLMs) to construct a new IR dataset \textbf{ComLQ} for \textbf{Com}plex \textbf{L}ogical \textbf{Q}ueries, which comprises 2,909 queries and 11,251 candidate passages. A key challenge in constructing the dataset lies in capturing the underlying logical structures within unstructured text. Therefore, by designing the subgraph-guided prompt with the subgraph indicator, an LLM (such as GPT-4o) is guided to generate queries with specific logical structures based on selected passages. All query-passage pairs in ComLQ are ensured \emph{structure conformity} and \emph{evidence distribution} through expert annotation. To better evaluate whether retrievers can handle queries with negation, we further propose a new evaluation metric, \textbf{Log-Scaled Negation Consistency} (\textbf{LSNC@$K$}). As a supplement to standard relevance-based metrics (such as nDCG and mAP), LSNC@$K$ measures whether top-$K$ retrieved passages violate negation conditions in queries. Our experimental results under zero-shot settings demonstrate existing retrieval models' limited performance on complex logical queries, especially on queries with negation, exposing their inferior capabilities of modeling exclusion.

</details>


### [13] [From Scaling to Structured Expressivity: Rethinking Transformers for CTR Prediction](https://arxiv.org/abs/2511.12081)
*Bencheng Yan,Yuejie Lei,Zhiyuan Zeng,Di Wang,Kaiyi Lin,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.IR

TL;DR: 提出了Field-Aware Transformer (FAT)来解决CTR预测中Transformer模型与数据语义结构不匹配的问题，通过分解内容对齐和跨字段调制实现更高效的组合推理。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在CTR预测中表现出收益递减，主要原因是其序列组合性假设与CTR数据所需的组合推理不匹配，无结构注意力在极端稀疏性下会放大噪声。

Method: 引入FAT模型，通过分解内容对齐和跨字段调制将基于字段的交互先验嵌入到注意力机制中，使模型复杂度与字段数F而非词汇量n成比例。

Result: FAT在大规模基准测试中AUC提升达+0.51%，在线部署实现+2.33% CTR和+0.66% RPM提升，并首次建立了CTR模型的正式缩放定律。

Conclusion: 推荐系统中的有效缩放不是来自模型大小，而是来自结构化表达能力——架构与数据语义的协调一致性。

Abstract: Despite massive investments in scale, deep models for click-through rate (CTR) prediction often exhibit rapidly diminishing returns - a stark contrast to the smooth, predictable gains seen in large language models. We identify the root cause as a structural misalignment: Transformers assume sequential compositionality, while CTR data demand combinatorial reasoning over high-cardinality semantic fields. Unstructured attention spreads capacity indiscriminately, amplifying noise under extreme sparsity and breaking scalable learning. To restore alignment, we introduce the Field-Aware Transformer (FAT), which embeds field-based interaction priors into attention through decomposed content alignment and cross-field modulation. This design ensures model complexity scales with the number of fields F, not the total vocabulary size n >> F, leading to tighter generalization and, critically, observed power-law scaling in AUC as model width increases. We present the first formal scaling law for CTR models, grounded in Rademacher complexity, that explains and predicts this behavior. On large-scale benchmarks, FAT improves AUC by up to +0.51% over state-of-the-art methods. Deployed online, it delivers +2.33% CTR and +0.66% RPM. Our work establishes that effective scaling in recommendation arises not from size, but from structured expressivity-architectural coherence with data semantics.

</details>


### [14] [Continuous-time Discrete-space Diffusion Model for Recommendation](https://arxiv.org/abs/2511.12114)
*Chengyi Liu,Xiao Chen,Shijie Wang,Wenqi Fan,Qing Li*

Main category: cs.IR

TL;DR: CDRec是一个连续时间离散空间的扩散推荐框架，通过离散扩散算法在连续时间上建模用户行为模式，结合流行度感知噪声调度和多跳协同信号对比学习，在推荐准确性和计算效率方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的推荐方法主要在连续空间中操作，可能导致信息损失和计算效率低下。需要开发一种在离散空间中操作的扩散推荐框架来更好地捕捉用户行为模式。

Method: 提出CDRec框架：1）在连续时间上进行离散空间扩散建模；2）引入流行度感知噪声调度生成有语义意义的扩散轨迹；3）结合一致性参数化快速采样和多跳协同信号对比学习的高效训练框架。

Result: 在真实世界数据集上的广泛实验表明，CDRec在推荐准确性和计算效率方面都表现出优越性能。

Conclusion: CDRec通过连续时间离散空间扩散建模，结合创新的噪声调度和训练策略，为推荐系统提供了一种既准确又高效的解决方案。

Abstract: In the era of information explosion, Recommender Systems (RS) are essential for alleviating information overload and providing personalized user experiences. Recent advances in diffusion-based generative recommenders have shown promise in capturing the dynamic nature of user preferences. These approaches explore a broader range of user interests by progressively perturbing the distribution of user-item interactions and recovering potential preferences from noise, enabling nuanced behavioral understanding. However, existing diffusion-based approaches predominantly operate in continuous space through encoded graph-based historical interactions, which may compromise potential information loss and suffer from computational inefficiency. As such, we propose CDRec, a novel Continuous-time Discrete-space Diffusion Recommendation framework, which models user behavior patterns through discrete diffusion on historical interactions over continuous time. The discrete diffusion algorithm operates via discrete element operations (e.g., masking) while incorporating domain knowledge through transition matrices, producing more meaningful diffusion trajectories. Furthermore, the continuous-time formulation enables flexible adaptive sampling. To better adapt discrete diffusion models to recommendations, CDRec introduces: (1) a novel popularity-aware noise schedule that generates semantically meaningful diffusion trajectories, and (2) an efficient training framework combining consistency parameterization for fast sampling and a contrastive learning objective guided by multi-hop collaborative signals for personalized recommendation. Extensive experiments on real-world datasets demonstrate CDRec's superior performance in both recommendation accuracy and computational efficiency.

</details>


### [15] [Task-Aware Retrieval Augmentation for Dynamic Recommendation](https://arxiv.org/abs/2511.12495)
*Zhen Tao,Xinke Jiang,Qingshuai Feng,Haoyu Zhang,Lun Du,Yuchen Fang,Hao Miao,Bangquan Xie,Qingqiang Sun*

Main category: cs.IR

TL;DR: TarDGR是一个任务感知的检索增强框架，通过引入任务感知评估机制和图Transformer模型，解决动态推荐系统中预训练GNN在微调时的泛化问题，提升模型对用户偏好演变的捕捉能力。


<details>
  <summary>Details</summary>
Motivation: 现有动态推荐系统使用预训练动态GNN建模用户-物品时序交互，但在微调时存在预训练与微调阶段的时间差异导致的泛化问题，限制了模型捕捉用户偏好演变的能力。

Method: 提出TarDGR框架：1）任务感知评估机制识别语义相关历史子图，构建任务特定数据集；2）基于图Transformer的任务感知模型集成语义和结构编码评估子图相关性；3）推理时检索并融合任务感知子图与查询子图，丰富表示并缓解时间泛化问题。

Result: 在多个大规模动态图数据集上的实验表明，TarDGR持续优于最先进方法，大量实证证据证实其具有优越的准确性和泛化能力。

Conclusion: TarDGR通过任务感知检索增强有效解决了动态推荐系统中的时间泛化问题，显著提升了模型的推荐性能和泛化能力。

Abstract: Dynamic recommendation systems aim to provide personalized suggestions by modeling temporal user-item interactions across time-series behavioral data. Recent studies have leveraged pre-trained dynamic graph neural networks (GNNs) to learn user-item representations over temporal snapshot graphs. However, fine-tuning GNNs on these graphs often results in generalization issues due to temporal discrepancies between pre-training and fine-tuning stages, limiting the model's ability to capture evolving user preferences. To address this, we propose TarDGR, a task-aware retrieval-augmented framework designed to enhance generalization capability by incorporating task-aware model and retrieval-augmentation. Specifically, TarDGR introduces a Task-Aware Evaluation Mechanism to identify semantically relevant historical subgraphs, enabling the construction of task-specific datasets without manual labeling. It also presents a Graph Transformer-based Task-Aware Model that integrates semantic and structural encodings to assess subgraph relevance. During inference, TarDGR retrieves and fuses task-aware subgraphs with the query subgraph, enriching its representation and mitigating temporal generalization issues. Experiments on multiple large-scale dynamic graph datasets demonstrate that TarDGR consistently outperforms state-of-the-art methods, with extensive empirical evidence underscoring its superior accuracy and generalization capabilities.

</details>


### [16] [Exploring Multi-Table Retrieval Through Iterative Search](https://arxiv.org/abs/2511.13418)
*Allaa Boutaleb,Bernd Amann,Rafael Angarita,Hubert Naacke*

Main category: cs.IR

TL;DR: 提出了一种迭代式多表检索框架，通过贪心连接感知检索算法平衡相关性、覆盖率和可连接性，在保持竞争力的同时显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决数据湖上开放域问答中多表检索的挑战，需要在语义相关性和结构连贯性（如可连接性）之间取得平衡。精确优化方法计算复杂度过高，而简单贪心启发式方法又难以找到连贯的可连接表集。

Method: 将多表检索构建为迭代搜索过程，提出贪心连接感知检索算法，综合考虑相关性、覆盖率和可连接性进行表选择。

Result: 在5个NL2SQL基准测试中，迭代方法相比基于混合整数规划的方法实现了竞争力的检索性能，同时速度提升了4-400倍。

Conclusion: 迭代启发式方法在实用性、可扩展性和组合感知检索方面具有巨大潜力，为多表检索提供了高效可行的解决方案。

Abstract: Open-domain question answering over datalakes requires retrieving and composing information from multiple tables, a challenging subtask that demands semantic relevance and structural coherence (e.g., joinability). While exact optimization methods like Mixed-Integer Programming (MIP) can ensure coherence, their computational complexity is often prohibitive. Conversely, simpler greedy heuristics that optimize for query coverage alone often fail to find these coherent, joinable sets. This paper frames multi-table retrieval as an iterative search process, arguing this approach offers advantages in scalability, interpretability, and flexibility. We propose a general framework and a concrete instantiation: a fast, effective Greedy Join-Aware Retrieval algorithm that holistically balances relevance, coverage, and joinability. Experiments across 5 NL2SQL benchmarks demonstrate that our iterative method achieves competitive retrieval performance compared to the MIP-based approach while being 4-400x faster depending on the benchmark and search space settings. This work highlights the potential of iterative heuristics for practical, scalable, and composition-aware retrieval.

</details>


### [17] [DualGR: Generative Retrieval with Long and Short-Term Interests Modeling](https://arxiv.org/abs/2511.12518)
*Zhongchao Yi,Kai Feng,Xiaojian Ma,Yalong Wang,Yongqi Liu,Han Li,Zhengyang Zhou,Yang Wang*

Main category: cs.IR

TL;DR: DualGR是一个生成式检索框架，通过双分支长短时路由、基于搜索的语义ID解码和曝光感知的下一个token预测损失，解决了用户兴趣平衡、噪声干扰和负反馈建模三大挑战，在快手短视频推荐系统中取得了显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 解决生成式检索中的三个关键挑战：1) 如何平衡用户的长期和短期兴趣；2) 生成分层语义ID时的噪声干扰；3) 对曝光未点击等负反馈缺乏显式建模。

Method: 1) 双分支长短时路由(DBR)显式建模用户长短期行为；2) 基于搜索的语义ID解码(S2D)控制上下文噪声并提高计算效率；3) 曝光感知的下一个token预测损失(ENTP-Loss)将曝光未点击项作为硬负样本。

Result: 在快手短视频推荐系统的大规模在线A/B测试中，实现了视频观看量+0.527%和观看时长+0.432%的提升。

Conclusion: DualGR为工业级生成式检索提供了一个实用有效的范式，能够显著提升推荐系统性能。

Abstract: In large-scale industrial recommendation systems, retrieval must produce high-quality candidates from massive corpora under strict latency. Recently, Generative Retrieval (GR) has emerged as a viable alternative to Embedding-Based Retrieval (EBR), which quantizes items into a finite token space and decodes candidates autoregressively, providing a scalable path that explicitly models target-history interactions via cross-attention. However, three challenges persist: 1) how to balance users' long-term and short-term interests , 2) noise interference when generating hierarchical semantic IDs (SIDs), 3) the absence of explicit modeling for negative feedback such as exposed items without clicks. To address these challenges, we propose DualGR, a generative retrieval framework that explicitly models dual horizons of user interests with selective activation. Specifically, DualGR utilizes Dual-Branch Long/Short-Term Router (DBR) to cover both stable preferences and transient intents by explicitly modeling users' long- and short-term behaviors. Meanwhile, Search-based SID Decoding (S2D) is presented to control context-induced noise and enhance computational efficiency by constraining candidate interactions to the current coarse (level-1) bucket during fine-grained (level-2/3) SID prediction. % also reinforcing intra-class consistency. Finally, we propose an Exposure-aware Next-Token Prediction Loss (ENTP-Loss) that treats "exposed-but-unclicked" items as hard negatives at level-1, enabling timely interest fade-out. On the large-scale Kuaishou short-video recommendation system, DualGR has achieved outstanding performance. Online A/B testing shows +0.527% video views and +0.432% watch time lifts, validating DualGR as a practical and effective paradigm for industrial generative retrieval.

</details>


### [18] [MindRec: Mind-inspired Coarse-to-fine Decoding for Generative Recommendation](https://arxiv.org/abs/2511.12597)
*Mengyao Gao,Chongming Gao,Haoyan Liu,Qingpeng Cai,Peng Jiang,Jiajia Chen,Shuai Yuan,Xiangnan He*

Main category: cs.IR

TL;DR: MindRec是一个受人类思维启发的推荐系统框架，通过生成关键token和分层类别树来模拟人类决策过程，使用扩散束搜索解决贪婪解码的局部最优问题，在top-1推荐性能上比现有方法平均提升9.5%。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的推荐系统采用自回归生成方式，受限于从左到右的贪婪解码策略和单向逻辑流，无法产生全局最优推荐。而人类推理不是严格的从左到右序列，而是从关键词或直觉洞察开始，然后进行细化和扩展。

Method: 1) 首先生成反映用户偏好的关键token，然后扩展为完整物品；2) 将物品组织成分层类别树，引导模型先产生粗粒度类别，再逐步细化到具体物品；3) 设计扩散束搜索算法来缓解贪婪解码的局部最优问题。

Result: 实验结果显示，MindRec在top-1推荐性能上比最先进方法平均提升9.5%，显著提高了推荐准确性。

Conclusion: MindRec通过模拟人类思维过程，实现了更灵活和人性化的推荐生成，证明了受人类推理启发的生成框架在推荐系统中的有效性。

Abstract: Recent advancements in large language model-based recommendation systems often represent items as text or semantic IDs and generate recommendations in an auto-regressive manner. However, due to the left-to-right greedy decoding strategy and the unidirectional logical flow, such methods often fail to produce globally optimal recommendations. In contrast, human reasoning does not follow a rigid left-to-right sequence. Instead, it often begins with keywords or intuitive insights, which are then refined and expanded. Inspired by this fact, we propose Mind-inspired Recommender (MindRec), a novel generative framework that emulates human thought processes. Particularly, our method first generates key tokens that reflect user preferences, and then expands them into the complete item, enabling flexible and human-like generation. To further emulate the structured nature of human decision-making, we organize items into a hierarchical category tree. This structure guides the model to first produce the coarse-grained category and then progressively refine its selection through finer-grained subcategories before generating the specific item. To mitigate the local optimum problem inherent in greedy decoding, we design a novel beam search algorithm, Diffusion Beam Search, tailored for our mind-inspired generation paradigm. Experimental results demonstrate that MindRec yields a 9.5\% average improvement in top-1 recommendation performance over state-of-the-art methods, highlighting its potential to enhance recommendation accuracy. The implementation is available via https://github.com/Mr-Peach0301/MindRec.

</details>


### [19] [Tokenize Once, Recommend Anywhere: Unified Item Tokenization for Multi-domain LLM-based Recommendation](https://arxiv.org/abs/2511.12922)
*Yu Hou,Won-Yong Shin*

Main category: cs.IR

TL;DR: UniTok是一个统一的物品标记化框架，通过混合专家架构和码本将多领域物品转换为离散标记，实现可扩展的跨领域语义保留。


<details>
  <summary>Details</summary>
Motivation: 现有物品标记化方法需要为每个物品领域训练单独模型，限制了泛化能力，且跨领域的分布和语义差异使得构建统一标记化变得困难。

Method: 使用共享编码器将不同领域物品投影到统一潜在空间，然后路由到领域特定专家捕获独特语义，同时共享专家编码跨领域通用知识。引入互信息校准机制缓解领域间语义不平衡。

Result: 在广泛真实数据集上，UniTok相比强基准提升达51.89%，具有理论有效性，且无需领域重训练就能在多样化领域展现稳健性能。

Conclusion: UniTok框架在效果、理论合理性和泛化能力方面均优于现有基线，支持跨领域统一物品标记化。

Abstract: Large language model (LLM)-based recommender systems have achieved high-quality performance by bridging the discrepancy between the item space and the language space through item tokenization. However, existing item tokenization methods typically require training separate models for each item domain, limiting generalization. Moreover, the diverse distributions and semantics across item domains make it difficult to construct a unified tokenization that preserves domain-specific information. To address these challenges, we propose UniTok, a Unified item Tokenization framework that integrates our own mixture-of-experts (MoE) architecture with a series of codebooks to convert items into discrete tokens, enabling scalable tokenization while preserving semantic information across multiple item domains. Specifically, items from different domains are first projected into a unified latent space through a shared encoder. They are then routed to domain-specific experts to capture the unique semantics, while a shared expert, which is always active, encodes common knowledge transferable across domains. Additionally, to mitigate semantic imbalance across domains, we present a mutual information calibration mechanism, which guides the model towards retaining similar levels of semantic information for each domain. Comprehensive experiments on wide-ranging real-world datasets demonstrate that the proposed UniTok framework is (a) highly effective: achieving up to 51.89% improvements over strong benchmarks, (b) theoretically sound: showing the analytical validity of our architectural design and optimization; and (c) highly generalizable: demonstrating robust performance across diverse domains without requiring per-domain retraining, a capability not supported by existing baselines.

</details>


### [20] [A Plug-and-Play Spatially-Constrained Representation Enhancement Framework for Local-Life Recommendation](https://arxiv.org/abs/2511.12947)
*Hao Jiang,Guoquan Wang,Sheng Yu,Yang Zeng,Wencong Zeng,Guorui Zhou*

Main category: cs.IR

TL;DR: 提出ReST框架解决本地生活推荐中的空间约束和长尾稀疏问题，通过元ID预热和空间约束对比学习增强长尾物品表示。


<details>
  <summary>Details</summary>
Motivation: 本地生活推荐面临空间约束（物品仅展示给有限地理区域用户）和长尾稀疏（热门物品主导交互，高质量长尾物品被忽视）两大挑战。现有方法多从用户角度出发，但本文认为应从物品角度增强长尾物品在空间约束下的表示。

Method: 提出ReST框架：1）元ID预热网络，通过基本属性语义信息初始化ID表示；2）空间约束ID表示增强网络，基于对比学习，采用空间约束硬采样和动态表示对齐策略，识别弱ID表示并增强其在空间约束下的潜在关系。

Result: 该方法能自适应识别基于属性信息的弱ID表示，在保持与热门物品兼容性的同时，增强长尾物品在本地生活服务空间约束特征下的表示。

Conclusion: ReST框架通过物品中心视角有效解决了本地生活推荐中的空间约束和长尾稀疏问题，为长尾物品提供了更好的表示增强方案。

Abstract: Local-life recommendation have witnessed rapid growth, providing users with convenient access to daily essentials. However, this domain faces two key challenges: (1) spatial constraints, driven by the requirements of the local-life scenario, where items are usually shown only to users within a limited geographic area, indirectly reducing their exposure probability; and (2) long-tail sparsity, where few popular items dominate user interactions, while many high-quality long-tail items are largely overlooked due to imbalanced interaction opportunities. Existing methods typically adopt a user-centric perspective, such as modeling spatial user preferences or enhancing long-tail representations with collaborative filtering signals. However, we argue that an item-centric perspective is more suitable for this domain, focusing on enhancing long-tail items representation that align with the spatially-constrained characteristics of local lifestyle services. To tackle this issue, we propose ReST, a Plug-And-Play Spatially-Constrained Representation Enhancement Framework for Long-Tail Local-Life Recommendation. Specifically, we first introduce a Meta ID Warm-up Network, which initializes fundamental ID representations by injecting their basic attribute-level semantic information. Subsequently, we propose a novel Spatially-Constrained ID Representation Enhancement Network (SIDENet) based on contrastive learning, which incorporates two efficient strategies: a spatially-constrained hard sampling strategy and a dynamic representation alignment strategy. This design adaptively identifies weak ID representations based on their attribute-level information during training. It additionally enhances them by capturing latent item relationships within the spatially-constrained characteristics of local lifestyle services, while preserving compatibility with popular items.

</details>


### [21] [Can We Predict the Next Question? A Collaborative Filtering Approach to Modeling User Behavior](https://arxiv.org/abs/2511.12949)
*Bokang Fu,Jiahao Wang,Xiaojing Liu,Yuli Liu*

Main category: cs.IR

TL;DR: 提出了CFQP框架，通过结合个性化记忆模块和图基偏好传播来动态建模用户-问题交互，解决了LLMs在捕捉用户动态行为序列方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型系统通常静态建模用户偏好，无法捕捉交互行为的动态性和序列性，而用户历史问题序列蕴含着丰富的兴趣演变和认知模式信号。

Method: CFQP框架整合个性化记忆模块和图基偏好传播的双重机制，既能自适应学习用户特定历史，又能通过相似用户的协作信号优化预测。

Result: 实验结果表明该方法能有效生成模拟真实用户提问模式的智能体，展示了构建主动适应性对话系统的潜力。

Conclusion: CFQP框架成功弥合了语言建模与行为序列建模之间的鸿沟，为开发更智能的对话系统提供了有效解决方案。

Abstract: In recent years, large language models (LLMs) have excelled in language understanding and generation, powering advanced dialogue and recommendation systems. However, a significant limitation persists: these systems often model user preferences statically, failing to capture the dynamic and sequential nature of interactive behaviors. The sequence of a user's historical questions provides a rich, implicit signal of evolving interests and cognitive patterns, yet leveraging this temporal data for predictive tasks remains challenging due to the inherent disconnect between language modeling and behavioral sequence modeling.
  To bridge this gap, we propose a Collaborative Filtering-enhanced Question Prediction (CFQP) framework. CFQP dynamically models evolving user-question interactions by integrating personalized memory modules with graph-based preference propagation. This dual mechanism allows the system to adaptively learn from user-specific histories while refining predictions through collaborative signals from similar users. Experimental results demonstrate that our approach effectively generates agents that mimic real-user questioning patterns, highlighting its potential for building proactive and adaptive dialogue systems.

</details>


### [22] [Personalized Federated Recommendation With Knowledge Guidance](https://arxiv.org/abs/2511.12959)
*Jaehyung Lim,Wonbin Kweon,Woojoo Kim,Junyoung Kim,Dongha Kim,Hwanjo Yu*

Main category: cs.IR

TL;DR: FedRKG是一个联邦推荐框架，通过知识引导机制在单知识模型的内存限制下实现双知识模型的个性化效果，解决了现有联邦推荐模型在内存效率和性能之间的困境。


<details>
  <summary>Details</summary>
Motivation: 现有联邦推荐模型面临关键困境：内存高效的单知识模型因丢弃有价值的个性化信息而性能受限，而高性能的双知识模型又因内存需求过大难以在实际设备上部署。

Method: 提出知识引导机制，避免完全替换，而是将全局知识融合到保留的本地嵌入中；引入自适应引导机制，为每个用户-物品交互动态调整引导强度。

Result: 在基准数据集上的广泛实验表明，FedRKG显著优于现有最先进方法，验证了该方法的有效性。

Conclusion: FedRKG成功解决了联邦推荐中内存效率与性能的权衡问题，在单知识模型的内存占用下实现了双知识模型的个性化优势。

Abstract: Federated Recommendation (FedRec) has emerged as a key paradigm for building privacy-preserving recommender systems. However, existing FedRec models face a critical dilemma: memory-efficient single-knowledge models suffer from a suboptimal knowledge replacement practice that discards valuable personalization, while high-performance dual-knowledge models are often too memory-intensive for practical on-device deployment. We propose Federated Recommendation with Knowledge Guidance (FedRKG), a model-agnostic framework that resolves this dilemma. The core principle, Knowledge Guidance, avoids full replacement and instead fuses global knowledge into preserved local embeddings, attaining the personalization benefits of dual-knowledge within a single-knowledge memory footprint. Furthermore, we introduce Adaptive Guidance, a fine-grained mechanism that dynamically modulates the intensity of this guidance for each user-item interaction, overcoming the limitations of static fusion methods. Extensive experiments on benchmark datasets demonstrate that FedRKG significantly outperforms state-of-the-art methods, validating the effectiveness of our approach. The code is available at https://github.com/Jaehyung-Lim/fedrkg.

</details>


### [23] [Mitigating Recommendation Biases via Group-Alignment and Global-Uniformity in Representation Learning](https://arxiv.org/abs/2511.13041)
*Miaomiao Cai,Min Hou,Lei Chen,Le Wu,Haoyue Bai,Yong Li,Meng Wang*

Main category: cs.IR

TL;DR: 提出AURL框架，通过表示分布中的组对齐和全局均匀性正则化来缓解推荐系统中的偏见问题


<details>
  <summary>Details</summary>
Motivation: CF方法因训练数据不平衡而产生偏见，倾向于推荐热门商品且对不活跃用户表现不佳，现有方法可能影响准确性或对权重策略敏感

Method: 提出组对齐和全局均匀性两个正则化器，组对齐使长尾实体表示分布接近热门实体，全局均匀性使表示均匀分布以保留信息

Result: 在三个真实数据集和多种推荐骨干网络上的广泛实验验证了该框架的优越性

Conclusion: AURL框架通过直接优化组对齐和全局均匀性正则化项，有效缓解了推荐偏见问题

Abstract: Collaborative Filtering~(CF) plays a crucial role in modern recommender systems, leveraging historical user-item interactions to provide personalized suggestions. However, CF-based methods often encounter biases due to imbalances in training data. This phenomenon makes CF-based methods tend to prioritize recommending popular items and performing unsatisfactorily on inactive users. Existing works address this issue by rebalancing training samples, reranking recommendation results, or making the modeling process robust to the bias. Despite their effectiveness, these approaches can compromise accuracy or be sensitive to weighting strategies, making them challenging to train. In this paper, we deeply analyze the causes and effects of the biases and propose a framework to alleviate biases in recommendation from the perspective of representation distribution, namely Group-Alignment and Global-Uniformity Enhanced Representation Learning for Debiasing Recommendation (AURL). Specifically, we identify two significant problems in the representation distribution of users and items, namely group-discrepancy and global-collapse. These two problems directly lead to biases in the recommendation results. To this end, we propose two simple but effective regularizers in the representation space, respectively named group-alignment and global-uniformity. The goal of group-alignment is to bring the representation distribution of long-tail entities closer to that of popular entities, while global-uniformity aims to preserve the information of entities as much as possible by evenly distributing representations. Our method directly optimizes both the group-alignment and global-uniformity regularization terms to mitigate recommendation biases. Extensive experiments on three real datasets and various recommendation backbones verify the superiority of our proposed framework.

</details>


### [24] [Dimension vs. Precision: A Comparative Analysis of Autoencoders and Quantization for Efficient Vector Retrieval on BEIR SciFact](https://arxiv.org/abs/2511.13057)
*Satyanarayan Pati*

Main category: cs.IR

TL;DR: 对密集检索模型向量嵌入的压缩策略进行实证研究，发现int8量化在4倍压缩下性能损失最小（仅1-2%），而自编码器和二值量化效果较差。


<details>
  <summary>Details</summary>
Motivation: 密集检索模型的高维浮点向量嵌入在真实部署中存在显著的存储和内存挑战，需要有效的压缩解决方案。

Method: 在BEIR SciFact基准上系统评估两种压缩策略：通过自编码器进行维度缩减（384维降至12维）和通过量化进行精度缩减（float16、int8、二值化）。

Result: int8标量量化在4倍压缩下表现最佳，nDCG@10仅下降1-2%；自编码器在同等压缩比下性能损失更大；二值量化导致灾难性性能下降。

Conclusion: int8量化是部署高效高性能检索系统的最实用压缩方法，在压缩比和性能保持之间达到最佳平衡。

Abstract: Dense retrieval models have become a standard for state-of-the-art information retrieval. However, their high-dimensional, high-precision (float32) vector embeddings create significant storage and memory challenges for real-world deployment. To address this, we conduct a rigorous empirical study on the BEIR SciFact benchmark, evaluating the trade-offs between two primary compression strategies: (1) Dimensionality Reduction via deep Autoencoders (AE), reducing original 384-dim vectors to latent spaces from 384 down to 12, and (2) Precision Reduction via Quantization (float16, int8, and binary). We systematically compare each method by measuring the "performance loss" (or gain) relative to a float32 baseline across a full suite of retrieval metrics (NDCG, MAP, MRR, Recall, Precision) at various k cutoffs. Our results show that int8 scalar quantization provides the most effective "sweet spot," achieving a 4x compression with a negligible [~1-2%] drop in nDCG@10. In contrast, Autoencoders show a graceful degradation but suffer a more significant performance loss at equivalent 4x compression ratios (AE-96). binary quantization was found to be unsuitable for this task due to catastrophic performance drops. This work provides a practical guide for deploying efficient, high-performance retrieval systems.

</details>


### [25] [Local Collaborative Filtering: A Collaborative Filtering Method that Utilizes Local Similarities among Users](https://arxiv.org/abs/2511.13166)
*Zhaoxin Shen,Dan Wu*

Main category: cs.IR

TL;DR: 提出了局部协同过滤(LCF)方法，利用用户间的局部相似性，通过大数定律整合用户行为数据，提高推荐系统对互联网用户行为数据的利用效率。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地利用互联网中的用户行为数据来改进推荐系统

Method: 提出局部协同过滤(LCF)方法，基于用户间的局部相似性，运用大数定律整合用户数据

Result: 在Steam游戏数据集上的实验结果表明，LCF的结果符合实际需求

Conclusion: 局部协同过滤方法能够有效提高用户行为数据的利用率，在推荐系统中表现出良好的实用性

Abstract: To leverage user behavior data from the Internet more effectively in recommender systems, this paper proposes a novel collaborative filtering (CF) method called Local Collaborative Filtering (LCF). LCF utilizes local similarities among users and integrates their data using the law of large numbers (LLN), thereby improving the utilization of user behavior data. Experiments are conducted on the Steam game dataset, and the results of LCF align with real-world needs.

</details>


### [26] [Cog-RAG: Cognitive-Inspired Dual-Hypergraph with Theme Alignment Retrieval-Augmented Generation](https://arxiv.org/abs/2511.13201)
*Hao Hu,Yifan Feng,Ruoxue Li,Rundong Xue,Xingliang Hou,Zhiqiang Tian,Yue Gao,Shaoyi Du*

Main category: cs.IR

TL;DR: 提出Cog-RAG框架，通过主题超图和实体超图的双重结构，结合认知启发的两阶段检索策略，显著提升RAG性能。


<details>
  <summary>Details</summary>
Motivation: 现有图结构RAG主要关注低阶成对实体关系，无法捕捉多实体间的高阶关联；超图方法虽然解决了多实体交互，但局限于块间实体级表示，忽略了全局主题组织和跨块对齐。

Method: 提出主题对齐的双超图RAG框架：使用主题超图捕捉块间主题结构，实体超图建模高阶语义关系；设计认知启发的两阶段检索策略，先激活查询相关主题内容，再指导细粒度召回和扩散。

Result: 广泛实验表明Cog-RAG显著优于现有最先进的基线方法。

Conclusion: Cog-RAG通过模拟人类自上而下的认知推理过程，实现了从全局主题到局部细节的语义对齐和一致生成，有效提升了RAG性能。

Abstract: Retrieval-Augmented Generation (RAG) enhances the response quality and domain-specific performance of large language models (LLMs) by incorporating external knowledge to combat hallucinations. In recent research, graph structures have been integrated into RAG to enhance the capture of semantic relations between entities. However, it primarily focuses on low-order pairwise entity relations, limiting the high-order associations among multiple entities. Hypergraph-enhanced approaches address this limitation by modeling multi-entity interactions via hyperedges, but they are typically constrained to inter-chunk entity-level representations, overlooking the global thematic organization and alignment across chunks. Drawing inspiration from the top-down cognitive process of human reasoning, we propose a theme-aligned dual-hypergraph RAG framework (Cog-RAG) that uses a theme hypergraph to capture inter-chunk thematic structure and an entity hypergraph to model high-order semantic relations. Furthermore, we design a cognitive-inspired two-stage retrieval strategy that first activates query-relevant thematic content from the theme hypergraph, and then guides fine-grained recall and diffusion in the entity hypergraph, achieving semantic alignment and consistent generation from global themes to local details. Our extensive experiments demonstrate that Cog-RAG significantly outperforms existing state-of-the-art baseline approaches.

</details>


### [27] [Uncovering Causal Drivers of Energy Efficiency for Industrial Process in Foundry via Time-Series Causal Inference](https://arxiv.org/abs/2511.13389)
*Zhipeng Ma,Bo Nørregaard Jørgensen,Zheng Grace Ma*

Main category: cs.IR

TL;DR: 应用时间序列因果推断框架识别感应炉熔炼中直接影响能源效率的操作因素，通过聚类和PCMCI+算法揭示不同操作模式下的因果关系。


<details>
  <summary>Details</summary>
Motivation: 工业铸造过程能耗高且变量间存在复杂依赖关系，基于相关性的分析难以区分真实因果驱动因素和虚假关联，限制了决策有效性。

Method: 集成时间序列聚类将熔炼周期分割为不同操作模式，使用PCMCI+因果发现算法在每个模式下揭示因果关系。

Result: 发现了能耗、炉温和材料重量之间的稳健因果关系，电压对冷却水温度有延迟影响。高效集群具有稳定因果结构，低效集群存在强化反馈环和非典型依赖。

Conclusion: 提出了集成聚类-因果推断管道作为分析高能耗过程的方法创新，为铸造操作员提供了优化性能、降低能耗和排放的可操作见解。

Abstract: Improving energy efficiency in industrial foundry processes is a critical challenge, as these operations are highly energy-intensive and marked by complex interdependencies among process variables. Correlation-based analyses often fail to distinguish true causal drivers from spurious associations, limiting their usefulness for decision-making. This paper applies a time-series causal inference framework to identify the operational factors that directly affect energy efficiency in induction furnace melting. Using production data from a Danish foundry, the study integrates time-series clustering to segment melting cycles into distinct operational modes with the PCMCI+ algorithm, a state-of-the-art causal discovery method, to uncover cause-effect relationships within each mode. Across clusters, robust causal relations among energy consumption, furnace temperature, and material weight define the core drivers of efficiency, while voltage consistently influences cooling water temperature with a delayed response. Cluster-specific differences further distinguish operational regimes: efficient clusters are characterized by stable causal structures, whereas inefficient ones exhibit reinforcing feedback loops and atypical dependencies. The contributions of this study are twofold. First, it introduces an integrated clustering-causal inference pipeline as a methodological innovation for analyzing energy-intensive processes. Second, it provides actionable insights that enable foundry operators to optimize performance, reduce energy consumption, and lower emissions.

</details>


### [28] [Attention Grounded Enhancement for Visual Document Retrieval](https://arxiv.org/abs/2511.13415)
*Wanqing Cui,Wei Huang,Yazhi Guo,Yibo Hu,Meiguang Jin,Junfeng Ma,Keping Bi*

Main category: cs.IR

TL;DR: 提出AGREE框架，利用多模态大语言模型的跨模态注意力作为局部监督信号，结合全局监督联合优化文档检索器，提升对非抽取式查询的处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有文档检索器仅使用粗粒度的全局相关性标签进行训练，无法识别支持匹配的具体文档区域，导致依赖表面线索且难以处理隐含语义连接的非抽取式查询。

Method: AGREE框架利用多模态大语言模型的跨模态注意力作为代理局部监督，指导识别相关文档区域，在训练中结合局部信号与全局信号联合优化检索器。

Result: 在ViDoRe V2基准测试中显著优于仅使用全局监督的基线方法，定量和定性分析表明AGREE促进了查询术语与文档区域间更深层次的对齐。

Conclusion: AGREE框架通过局部监督增强了检索器的语义理解能力，实现了更准确和可解释的文档检索，超越了表面级匹配。

Abstract: Visual document retrieval requires understanding heterogeneous and multi-modal content to satisfy information needs. Recent advances use screenshot-based document encoding with fine-grained late interaction, significantly improving retrieval performance. However, retrievers are still trained with coarse global relevance labels, without revealing which regions support the match. As a result, retrievers tend to rely on surface-level cues and struggle to capture implicit semantic connections, hindering their ability to handle non-extractive queries. To alleviate this problem, we propose a \textbf{A}ttention-\textbf{G}rounded \textbf{RE}triever \textbf{E}nhancement (AGREE) framework. AGREE leverages cross-modal attention from multimodal large language models as proxy local supervision to guide the identification of relevant document regions. During training, AGREE combines local signals with the global signals to jointly optimize the retriever, enabling it to learn not only whether documents match, but also which content drives relevance. Experiments on the challenging ViDoRe V2 benchmark show that AGREE significantly outperforms the global-supervision-only baseline. Quantitative and qualitative analyses further demonstrate that AGREE promotes deeper alignment between query terms and document regions, moving beyond surface-level matching toward more accurate and interpretable retrieval. Our code is available at: https://anonymous.4open.science/r/AGREE-2025.

</details>


### [29] [Compact Multimodal Language Models as Robust OCR Alternatives for Noisy Textual Clinical Reports](https://arxiv.org/abs/2511.13523)
*Nikita Neveditsin,Pawan Lingras,Salil Patil,Swarup Patil,Vijay Mago*

Main category: cs.IR

TL;DR: 紧凑多模态模型在转录噪声医疗文档方面优于传统OCR系统，特别是在处理印度医疗环境中区域化医学英语的产科超声报告时表现更稳健。


<details>
  <summary>Details</summary>
Motivation: 医疗记录数字化常依赖智能手机拍摄的打印报告照片，这些图像因模糊、阴影等噪声而质量下降。传统OCR系统在清洁扫描上表现良好，但在这种现实条件下性能不佳。

Method: 使用印度医疗环境中常见的区域化医学英语撰写的产科超声报告，比较了八个系统在转录准确性、噪声敏感性、数字准确性和计算效率方面的表现。

Result: 紧凑多模态模型始终优于经典和神经OCR流水线，尽管计算成本较高，但其稳健性和语言适应性使其成为内部部署医疗数字化的可行候选方案。

Conclusion: 紧凑多模态模型因其对噪声的鲁棒性和语言适应性，是医疗文档数字化的有前景的隐私保护替代方案。

Abstract: Digitization of medical records often relies on smartphone photographs of printed reports, producing images degraded by blur, shadows, and other noise. Conventional OCR systems, optimized for clean scans, perform poorly under such real-world conditions. This study evaluates compact multimodal language models as privacy-preserving alternatives for transcribing noisy clinical documents. Using obstetric ultrasound reports written in regionally inflected medical English common to Indian healthcare settings, we compare eight systems in terms of transcription accuracy, noise sensitivity, numeric accuracy, and computational efficiency. Compact multimodal models consistently outperform both classical and neural OCR pipelines. Despite higher computational costs, their robustness and linguistic adaptability position them as viable candidates for on-premises healthcare digitization.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [30] [ProAV-DiT: A Projected Latent Diffusion Transformer for Efficient Synchronized Audio-Video Generation](https://arxiv.org/abs/2511.12072)
*Jiahui Sun,Weining Wang,Mingzhen Sun,Yirong Yang,Xinxin Zhu,Jing Liu*

Main category: cs.MM

TL;DR: ProAV-DiT是一个用于高效同步音视频生成的投影潜在扩散Transformer模型，通过将音频预处理为类视频表示来解决结构不对齐问题，采用多尺度双流时空自编码器和多尺度注意力机制，在标准基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 音视频生成任务面临音频和视频结构不对齐以及多模态数据处理计算成本高的挑战，需要开发能够高效生成同步高质量音视频内容的方法。

Method: 1) 将原始音频预处理为类视频表示以对齐时空维度；2) 使用多尺度双流时空自编码器将两种模态投影到统一潜在空间；3) 引入多尺度注意力机制（多尺度时间自注意力和组间跨模态注意力）；4) 将2D潜在空间堆叠为统一3D潜在空间，通过时空扩散Transformer处理。

Result: 在标准基准测试中，ProAV-DiT在生成质量和计算效率方面均优于现有方法，能够生成高质量同步音视频内容。

Conclusion: ProAV-DiT通过创新的投影潜在空间设计和多尺度注意力机制，有效解决了音视频生成中的结构不对齐和计算效率问题，为同步音视频生成提供了高效解决方案。

Abstract: Sounding Video Generation (SVG) remains a challenging task due to the inherent structural misalignment between audio and video, as well as the high computational cost of multimodal data processing. In this paper, we introduce ProAV-DiT, a Projected Latent Diffusion Transformer designed for efficient and synchronized audio-video generation. To address structural inconsistencies, we preprocess raw audio into video-like representations, aligning both the temporal and spatial dimensions between audio and video. At its core, ProAV-DiT adopts a Multi-scale Dual-stream Spatio-Temporal Autoencoder (MDSA), which projects both modalities into a unified latent space using orthogonal decomposition, enabling fine-grained spatiotemporal modeling and semantic alignment. To further enhance temporal coherence and modality-specific fusion, we introduce a multi-scale attention mechanism, which consists of multi-scale temporal self-attention and group cross-modal attention. Furthermore, we stack the 2D latents from MDSA into a unified 3D latent space, which is processed by a spatio-temporal diffusion Transformer. This design efficiently models spatiotemporal dependencies, enabling the generation of high-fidelity synchronized audio-video content while reducing computational overhead. Extensive experiments conducted on standard benchmarks demonstrate that ProAV-DiT outperforms existing methods in both generation quality and computational efficiency.

</details>


### [31] [SynthGuard: An Open Platform for Detecting AI-Generated Multimedia with Multimodal LLMs](https://arxiv.org/abs/2511.12404)
*Shail Desai,Aditya Pawar,Li Lin,Xin Wang,Shu Hu*

Main category: cs.MM

TL;DR: SynthGuard是一个开源的AI生成多媒体检测平台，结合传统检测器和多模态大语言模型，提供可解释的推理和统一的图像音频支持。


<details>
  <summary>Details</summary>
Motivation: AI生成媒体带来严重风险，包括错误信息、身份滥用和公众信任侵蚀，而现有检测工具多为闭源、模态有限且缺乏透明度。

Method: 使用传统检测器和多模态大语言模型(MLLMs)进行AI生成多媒体检测，提供可解释推理和统一图像音频支持。

Result: 开发了SynthGuard平台，包含交互式界面，使取证分析对研究人员、教育工作者和公众可访问。

Conclusion: SynthGuard解决了现有检测工具的不足，提供了一个开放、用户友好的平台来检测和分析AI生成的多媒体内容。

Abstract: Artificial Intelligence (AI) has made it possible for anyone to create images, audio, and video with unprecedented ease, enriching education, communication, and creative expression. At the same time, the rapid rise of AI-generated media has introduced serious risks, including misinformation, identity misuse, and the erosion of public trust as synthetic content becomes increasingly indistinguishable from real media. Although deepfake detection has advanced, many existing tools remain closed-source, limited in modality, or lacking transparency and educational value, making it difficult for users to understand how detection decisions are made. To address these gaps, we introduce SynthGuard, an open, user-friendly platform for detecting and analyzing AI-generated multimedia using both traditional detectors and multimodal large language models (MLLMs). SynthGuard provides explainable inference, unified image and audio support, and an interactive interface designed to make forensic analysis accessible to researchers, educators, and the public. The SynthGuard platform is available at: https://in-engr-nova.it.purdue.edu/

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [32] [An improved approximation algorithm for k-Median](https://arxiv.org/abs/2511.12230)
*Neal E. Young*

Main category: cs.DS

TL;DR: 提出了一个多项式时间近似算法，用于解决（非度量）k-中位数问题，该算法在规模上达到α近似（α<1+2ln(n/k)），在成本上不超过任何规模为k的解的成本。


<details>
  <summary>Details</summary>
Motivation: 解决k-中位数问题的近似算法设计，特别是要匹配无权重集合覆盖问题中已知的H_Δ和1+ln(n/k)边界。

Method: 设计了一个多项式时间近似算法，运行时间为O(km log(n/k) log m)，其中n是客户数量，m是实例大小。

Result: 算法在常数因子内匹配了无权重集合覆盖问题的已知边界，具体在因子2内匹配H_Δ和1+ln(n/k)边界。

Conclusion: 这是第一个能够在多项式时间内匹配无权重集合覆盖问题已知边界的k-中位数近似算法，在常数因子内达到了最优边界。

Abstract: We give a polynomial-time approximation algorithm for the (not necessarily metric) $k$-Median problem. The algorithm is an $α$-size-approximation algorithm for $α< 1 + 2 \ln(n/k)$. That is, it guarantees a solution having size at most $α\times k$, and cost at most the cost of any size-$k$ solution. This is the first polynomial-time approximation algorithm to match the well-known bounds of $H_Δ$ and $1 + \ln(n/k)$ for unweighted Set Cover (a special case) within a constant factor. It matches these bounds within a factor of 2. The algorithm runs in time $O(k m \log(n/k) \log m)$, where $n$ is the number of customers and $m$ is the instance size.

</details>


### [33] [Shortcutting for Negative-Weight Shortest Path](https://arxiv.org/abs/2511.12714)
*George Z. Li,Jason Li,Satish Rao,Junkai Zhang*

Main category: cs.DS

TL;DR: 提出了一种在带实值边权有向图上解决单源最短路径问题的新算法，时间复杂度为O(n^{2.5}log^{4.5}n)，改进了先前在稠密图上的工作。


<details>
  <summary>Details</summary>
Motivation: 针对带实值边权的有向图单源最短路径问题，现有算法在稠密图上仍有改进空间，需要开发更高效的算法。

Method: 采用一种捷径化程序，迭代地将最短路径上的负权边数量以常数因子减少。

Result: 实现了O(n^{2.5}log^{4.5}n)的时间复杂度，优于Fineman (STOC 2024)和Huang-Jin-Quanrud (SODA 2025, 2026)在稠密图上的结果。

Conclusion: 通过捷径化技术有效减少了最短路径上的负权边数量，为稠密图上的单源最短路径问题提供了更优的解决方案。

Abstract: Consider the single-source shortest paths problem on a directed graph with real-valued edge weights. We solve this problem in $O(n^{2.5}\log^{4.5}n)$ time, improving on prior work of Fineman (STOC 2024) and Huang-Jin-Quanrud (SODA 2025, 2026) on dense graphs. Our main technique is an shortcutting procedure that iteratively reduces the number of negative-weight edges along shortest paths by a constant factor.

</details>


### [34] [Indirect Coflow Scheduling](https://arxiv.org/abs/2511.12854)
*Alexander Lindermayr,Kirk Pruhs,Andréa W. Richa,Tegan Wilson*

Main category: cs.DS

TL;DR: 本文研究可重构网络中的路由问题（即文献中的coflow调度），特别关注当数据传输需求较小时的情况，改进了传统为大数据传输设计的算法。


<details>
  <summary>Details</summary>
Motivation: 现有算法文献通常假设数据传输量很大，使用整数需求矩阵建模。但在实际中，有些数据传输需求可能很小，相对于单轮可传输的数据量而言，传统算法可能效率不高。

Method: 研究使用分数匹配和间接路由等方法来处理小规模数据传输需求，设计专门针对小需求场景的算法。

Result: 设计的算法在小需求情况下比传统为大数据传输设计的算法表现更好。

Conclusion: 对于小规模数据传输需求，采用分数匹配和间接路由等方法的专门算法比传统算法更有效。

Abstract: We consider routing in reconfigurable networks, which is also known as coflow scheduling in the literature. The algorithmic literature generally (perhaps implicitly) assumes that the amount of data to be transferred is large. Thus the standard way to model a collection of requested data transfers is by an integer demand matrix $D$, where the entry in row $i$ and column $j$ of $D$ is an integer representing the amount of information that the application wants to send from machine/node $i$ to machine/node $j$. A feasible coflow schedule is then a sequence of matchings, which represent the sequence of data transfers that covers $D$. In this work, we investigate coflow scheduling when the size of some of the requested data transfers may be small relative to the amount of data that can be transferred in one round. fractional matchings and/or that employ indirect routing, and compare the relative utility of these options. We design algorithms that perform much better for small demands than the algorithms in the literature that were designed for large data transfers.

</details>


### [35] [Maximal Palindromes in MPC: Simple and Optimal](https://arxiv.org/abs/2511.13014)
*Solon P. Pissis*

Main category: cs.DS

TL;DR: 提出了一种在MPC模型中解决最长回文子串问题的简单最优算法，能够在O(1)轮次内完成，总时间和内存为O(n)，每台机器内存为O(n^{1-ε})，且能计算所有最大回文。


<details>
  <summary>Details</summary>
Motivation: 改进Gilbert等人[SPAA 2023]在MPC模型中解决LPS问题的方法，提供更简单且最优的算法，同时突破ε∈(0,0.5]的限制。

Method: 使用简单的并行算法在MPC模型中处理回文子串问题，能够在常数轮次内完成计算，并扩展到Adaptive MPC模型。

Result: 在O(1)轮次内解决LPS问题，总复杂度为O(n)，每台机器内存为O(n^{1-ε})，且能计算所有最大回文。在Adaptive MPC模型中突破了ε的限制。

Conclusion: 提出了一种简单、最优的MPC算法，不仅解决了LPS问题，还能计算所有最大回文，并在Adaptive MPC模型中实现了更广泛的应用范围。

Abstract: In the classical longest palindromic substring (LPS) problem, we are given a string $S$ of length $n$, and the task is to output a longest palindromic substring in $S$. Gilbert, Hajiaghayi, Saleh, and Seddighin [SPAA 2023] showed how to solve the LPS problem in the Massively Parallel Computation (MPC) model in $\mathcal{O}(1)$ rounds using $\mathcal{\widetilde{O}}(n)$ total memory, with $\mathcal{\widetilde{O}}(n^{1-ε})$ memory per machine, for any $ε\in (0,0.5]$.
  We present a simple and optimal algorithm to solve the LPS problem in the MPC model in $\mathcal{O}(1)$ rounds. The total time and memory are $\mathcal{O}(n)$, with $\mathcal{O}(n^{1-ε})$ memory per machine, for any $ε\in (0,0.5]$. A key attribute of our algorithm is its ability to compute all maximal palindromes in the same complexities. Furthermore, our new insights allow us to bypass the constraint $ε\in (0,0.5]$ in the Adaptive MPC model. Our algorithms and the one proposed by Gilbert et al. for the LPS problem are randomized and succeed with high probability.

</details>


### [36] [Greedy matroid base packings with applications to dynamic graph density and orientations](https://arxiv.org/abs/2511.13205)
*Pavel Arkhipov,Vladimir Kolmogorov*

Main category: cs.DS

TL;DR: 本文研究了贪婪最小权重基包在一般拟阵中的过程及其算法应用，特别关注双循环拟阵，改进了动态最密子图密度近似算法的时间复杂度，并给出了树包组合结果的新边界。


<details>
  <summary>Details</summary>
Motivation: 贪婪最小权重生成树包在连通性问题中已被证明很有用。本文旨在研究一般拟阵中贪婪最小权重基包的过程，并探索其算法应用，特别是在双循环拟阵中改进动态最密子图问题的算法性能。

Method: 使用贪婪伪森林包方法，维护动态变化图中的最小权重伪森林。对于一般拟阵，观察基包极限的两个特征，并给出树包组合结果的理论分析。

Result: 在双循环拟阵中，实现了动态最密子图密度(1+ε)-近似算法，最坏情况更新时间O((ρε⁻²+ε⁻⁴)ρlog³m)，改进了对ε的依赖。同时证明了树包组合的新边界：O(λ⁵logm)棵树包含穿过某个最小割一次的树，改进了之前的O(λ⁷log³m)边界。

Conclusion: 贪婪基包方法在拟阵理论中具有重要应用价值，特别是在动态图算法中能显著改进性能。本文的结果为树包组合理论提供了更紧的边界，并证明了Thorup上界在对数因子内是紧的。

Abstract: Greedy minimum weight spanning tree packings have proven to be useful in connectivity-related problems. We study the process of greedy minimum weight base packings in general matroids and explore its algorithmic applications.
  When specialized to bicircular matroids, our results yield an algorithm for the approximate fully-dynamic densest subgraph density $ρ$. We maintain a $(1+\varepsilon)$-approximation of the density with a worst-case update time $O((ρ\varepsilon^{-2}+\varepsilon^{-4})ρ\log^3 m)$. It improves the dependency on $\varepsilon$ from the current state-of-the-art worst-case update time complexity $O(\varepsilon^{-6}\log^3 n\logρ)$ [Chekuri, Christiansen, Holm, van der Hoog, Quanrud, Rotenberg, Schwiegelshohn, SODA'24]. We also can maintain an implicit fractional out-orientation with a guarantee that all out-degrees are at most $(1+\varepsilon)ρ$.
  Our algorithms above work by greedily packing pseudoforests, and require maintenance of a minimum-weight pseudoforest in a dynamically changing graph. We show that this problem can be solved in $O(\log n)$ worst-case time per edge insertion or deletion.
  For general matroids, we observe two characterizations of the limit of the base packings (``the vector of ideal loads''), which imply the characterizations from [Cen, Fleischmann, Li, Li, Panigrahi, FOCS'25], namely, their entropy-minimization theorem and their bottom-up cut hierarchy.
  Finally, we give combinatorial results on the greedy tree packings. We show that a tree packing of $O(λ^5\log m)$ trees contains a tree crossing some min-cut once, which improves the bound $O(λ^7\log^3 m)$ from [Thorup, Combinatorica'07]. We also strengthen the lower bound on the edge load convergence rate from [de Vos, Christiansen, SODA'25], showing that Thorup's upper bound is tight up to a logarithmic factor.

</details>


### [37] [A Complexity Analysis of the c-Closed Vertex Deletion Problem](https://arxiv.org/abs/2511.13301)
*Lisa Lehner,Christian Komusiewicz,Luca Pascal Staus*

Main category: cs.DS

TL;DR: 研究c-闭顶点删除问题的经典和参数化复杂度，包括NP难性证明、核大小上下界分析，以及在特定图类上的多项式时间可解性和固定参数可解性。


<details>
  <summary>Details</summary>
Motivation: 研究图结构性质与顶点删除操作之间的关系，探索c-闭图性质在算法设计中的应用，为图修改问题提供新的理论框架。

Method: 使用参数化复杂度理论分析，包括核化技术、固定参数可解性证明，以及在特定图类（如二分图、单位区间图）上的算法设计。

Result: 证明了该问题在二分图中是NP难的，给出了参数k的核大小上下界，提出了新参数x并得到O(x³+x²c)大小的核，在单位区间图和邻域多样性参数下具有良好算法性质。

Conclusion: c-闭顶点删除问题具有丰富的复杂度结构，通过参数化方法可以设计高效算法，新参数x的引入为问题分析提供了有效工具。

Abstract: A graph is $c$-closed when every pair of nonadjacent vertices has at most $c-1$ common neighbors. In $c$-Closed Vertex Deletion, the input is a graph $G$ and an integer $k$ and we ask whether $G$ can be transformed into a $c$-closed graph by deleting at most $k$ vertices. We study the classic and parameterized complexity of $c$-Closed Vertex Deletion. We obtain, for example, NP-hardness for the case that $G$ is bipartite with bounded maximum degree. We also show upper and lower bounds on the size of problem kernels for the parameter $k$ and introduce a new parameter, the number $x$ of vertices in bad pairs, for which we show a problem kernel of size $\mathcal{O}(x^3 + x^2\cdot c))$. Here, a pair of nonadjacent vertices is bad if they have at least $c$ common neighbors. Finally, we show that $c$-Closed Vertex Deletion can be solved in polynomial time on unit interval graphs with depth at most $c+1$ and that it is fixed-parameter tractable with respect to the neighborhood diversity of $G$.

</details>


### [38] [Dimension-Free Correlated Sampling for the Hypersimplex](https://arxiv.org/abs/2511.13573)
*Joseph,Naor,Nitya Raju,Abhishek Shetty,Aravind Srinivasan,Renata Valieva,David Wajc*

Main category: cs.DS

TL;DR: 本文改进了超单纯形上的相关采样算法，将近似因子从O(log n)提升到O(log k)，并保持了输入稀疏性采样时间、对数并行深度等优良性质。


<details>
  <summary>Details</summary>
Motivation: 自1950年代以来，最大化重叠的多分布采样一直是统计学的重要问题。2000年代以来，概率单纯形上的相关采样成为理论计算机科学多个领域的关键工具。本文旨在将这一技术推广到超单纯形上的集合采样问题。

Method: 提出了一种新的超单纯形相关采样算法，通过改进采样策略来降低近似因子。算法具有输入稀疏性采样时间、对数并行深度、动态更新时间等特性，并能保持子模目标函数。

Result: 将近似因子从之前的O(log n)显著改进为O(log k)，其中k是集合大小，n是环境维度。这一改进与维度n无关，在k远小于n时具有显著优势。

Conclusion: 改进后的超单纯形相关采样算法在近似因子、计算效率等方面均有显著提升，并在在线分页、度量多标记、多场景子模福利近似重分配等应用中展现了广泛潜力。

Abstract: Sampling from multiple distributions so as to maximize overlap has been studied by statisticians since the 1950s. Since the 2000s, such correlated sampling from the probability simplex has been a powerful building block in disparate areas of theoretical computer science. We study a generalization of this problem to sampling sets from given vectors in the hypersimplex, i.e., outputting sets of size (at most) some $k$ in $[n]$, while maximizing the sampled sets' overlap. Specifically, the expected difference between two output sets should be at most $α$ times their input vectors' $\ell_1$ distance. A value of $α=O(\log n)$ is known to be achievable, due to Chen et al.~(ICALP'17). We improve this factor to $O(\log k)$, independent of the ambient dimension~$n$. Our algorithm satisfies other desirable properties, including (up to a $\log^* n$ factor) input-sparsity sampling time, logarithmic parallel depth and dynamic update time, as well as preservation of submodular objectives. Anticipating broader use of correlated sampling algorithms for the hypersimplex, we present applications of our algorithm to online paging, offline approximation of metric multi-labeling and swift multi-scenario submodular welfare approximating reallocation.

</details>


### [39] [The Merkle Mountain Belt](https://arxiv.org/abs/2511.13582)
*Alfonso Cevallos,Robert Hambrock,Alistair Stewart*

Main category: cs.DS

TL;DR: 本文比较了不同Merkle结构在区块链应用中的性能，提出了新的Merkle Mountain Belt (MMB)结构，该结构同时具备简洁性、增量性和最优可加性，能够显著加速轻客户端协议。


<details>
  <summary>Details</summary>
Motivation: 提高轻客户端协议的效率，使用户能够从智能手机等设备高效验证交易，特别是在区块链应用中优化Merkle结构的性能。

Method: 比较不同Merkle结构（如Merkle Mountain Range和Merkle链）的特性，并引入新的Merkle结构MMB和UMMB，这些结构通过轻微不平衡设计使新添加的项目具有更短的成员证明。

Result: MMB是首个同时具备简洁性、增量性和最优可加性的Merkle结构，UMMB还支持异步操作。新结构通过不平衡设计降低了轻客户端的预期成本。

Conclusion: 提出的MMB和UMMB结构在区块链轻客户端应用中具有显著优势，特别是在查询偏向新生成数据的场景下能够有效降低验证成本。

Abstract: Merkle structures are widely used as commitment schemes: they allow a prover to publish a compact commitment to an ordered list $X$ of items, and then efficiently prove to a verifier that $x_i\in X$ is the $i$-th item in it. We compare different Merkle structures and their corresponding properties as commitment schemes in the context of blockchain applications. Our primary goal is to speed up light client protocols so that, e.g., a user can verify a transaction efficiently from their smartphone.
  For instance, the Merkle Mountain Range (MMR) yields a succinct scheme: a light client synchronizing for the first time can do so with a complexity sublinear in $|X|$. On the other hand, the Merkle chain, traditionally used to commit to block headers, is not succinct, but it is incremental - a light client resynchronizing frequently can do so with constant complexity - and optimally additive - the structure can be updated in constant time when a new item is appended to list $X$.
  We introduce new Merkle structures, most notably the Merkle Mountain Belt (MMB), the first to be simultaneously succinct, incremental and optimally additive. A variant called UMMB is also asynchronous: a light client may continue to interact with the network even when out of sync with the public commitment. Our Merkle structures are slightly unbalanced, so that items recently appended to $X$ receive shorter membership proofs than older items. This feature reduces a light client's expected costs, in applications where queries are biased towards recently generated data.

</details>


### [40] [Chasing Submodular Objectives, and Submodular Maximization via Cutting Planes](https://arxiv.org/abs/2511.13605)
*Niv Buchbinder,Joseph,Naor,David Wajc*

Main category: cs.DS

TL;DR: 本文提出了子模目标追踪问题，该问题推广了许多自然且先前研究过的问题：一系列受约束的子模最大化问题随时间揭示，每个步骤中目标和可用基础集都会变化。目标是在保持高近似度的同时，与相同输入序列的精确离线算法相比，具有较低的总调整成本（变更次数）。


<details>
  <summary>Details</summary>
Motivation: 研究随时间变化的子模最大化问题序列，其中目标和约束都在变化，需要在保持高质量近似解的同时最小化解的变化次数（调整成本）。

Method: 提出了一种称为"近似或分离"的新元算法，用于在一般约束下近似最大化多线性扩展。该方法改进了round-and-separate方法，可以结合任何切割平面方法和约束的分离预言机。

Result: 对于基数约束和划分拟阵约束，提供了多项式时间算法，实现了最优的(1-1/e-ε)近似和最优的竞争性调整成本。

Conclusion: 该方法将切割平面方法引入到约束子模最大化中，展示了该方法在静态算法和通信复杂度协议中的进一步应用。

Abstract: We introduce the \emph{submodular objectives chasing problem}, which generalizes many natural and previously-studied problems: a sequence of constrained submodular maximization problems is revealed over time, with both the objective and available ground set changing at each step. The goal is to maintain solutions of high approximation and low total \emph{recourse} (number of changes), compared with exact offline algorithms for the same input sequence. For the central cardinality constraint and partition matroid constraints we provide polynomial-time algorithms achieving both optimal $(1-1/e-ε)$-approximation and optimal competitive recourse for \emph{any} constant-approximation.
  Key to our algorithm's polynomial time, and of possible independent interest, is a new meta-algorithm for $(1-1/e-ε)$-approximately maximizing the multilinear extension under general constraints, which we call {\em approximate-or-separate}. Our algorithm relies on an improvement of the round-and-separate method [Gupta-Levin SODA'20], inspired by an earlier proof by [Vondrák, PhD~Thesis'07]. The algorithm, whose guarantees are similar to the influential {\em continuous greedy} algorithm [Calinescu-Chekuri-Pál-Vondrák SICOMP'11], can use any cutting plane method and separation oracle for the constraints. This allows us to introduce cutting plane methods, used for exact unconstrained submodular minimization since the '80s [Grötschel/Lovász/Schrijver Combinatorica'81], as a useful method for (optimal approximate) constrained submodular maximization. We show further applications of this approach to static algorithms with curvature-sensitive approximation, and to communication complexity protocols.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [41] [Guessing Decoding of Short Blocklength Codes](https://arxiv.org/abs/2511.12108)
*Qianfan Wang,Jifan Liang,Peihong Yuan,Ken R. Duffy,Muriel Médard,Xiao Ma*

Main category: cs.IT

TL;DR: 本文对两种猜测解码方法（GRAND和GCD）进行了统一分析，包括算法实现、ML最优性证明、复杂度分析和性能比较，为下一代短块长通信中的通用解码器提供理论指导和实践建议。


<details>
  <summary>Details</summary>
Motivation: 未来B5G和6G系统需要超可靠、低延迟的短块长通信，这推动了通用解码算法的发展。猜测解码通过按可能性降序推断噪声或码字候选，为短码提供了通用框架。

Method: 对GRAND和GCD两种猜测解码方法进行统一处理：提出算法实现和排序策略；在适当停止准则下证明最大似然最优性；推导平均查询数的鞍点近似；通过仿真验证理论预测。

Result: 分析了有限搜索预算相对于ML性能的性能下降，比较了关键指标（最坏情况和平均复杂度、硬件考虑），并展示了两种方法间的自然技术转移。结果明确了GRAND和GCD表现出优越性能的工作区域。

Conclusion: 这项工作为在下一代短块长通信中部署通用猜测解码器提供了理论见解和实践指南，阐明了两种解码方法在不同工作区域的优势。

Abstract: Future beyond-5G and 6G systems demand ultra-reliable, low-latency communication with short blocklengths, motivating the development of universal decoding algorithms. Guessing decoding, which infers the noise or codeword candidate in order of decreasing (exact or approximate) likelihood, offers a universal framework applicable to short codes. In this paper, we present a unified treatment of two prominent recent families of guessing decoding: guessing random additive noise decoding (GRAND) and guessing codeword decoding (GCD). For each, we (i) present algorithmic implementations and ordering strategies; (ii) prove maximum-likelihood (ML) optimality under appropriate stopping criteria; (iii) derive saddle-point approximations for the average number of queries; and (iv) validate theoretical predictions with simulations. We further analyze the performance degradation due to limited search budgets relative to ML performance, compare key metrics (worst-case and average complexity, hardware considerations), and highlight how advances in one approach transfer naturally to the other. Our results clarify the operating regimes where GRAND and GCD demonstrate superior performance. This work provides both theoretical insights and practical guidelines for deploying universal guessing decoders in next-generation short-blocklength communications.

</details>


### [42] [Tight Lower Bounds on the Bandwidth Cost of MDS Convertible Codes in the Split Regime](https://arxiv.org/abs/2511.12279)
*Shubhransh Singhvi,Saransh Chopra,K. V. Rashmi*

Main category: cs.IT

TL;DR: 本文研究了系统MDS可转换码在拆分机制下的带宽成本基本限制，提出了新的信息论框架，并在更广泛的参数范围内获得了紧致下界。


<details>
  <summary>Details</summary>
Motivation: 分布式存储系统中，根据磁盘故障率调整冗余度可以节省存储空间，但代码转换操作可能很耗资源。可转换码旨在高效完成这种转换，同时保持MDS属性。

Method: 采用新颖的信息论框架，仅假设初始和最终代码是系统的，不依赖线性假设或均匀性假设，推导了拆分机制下带宽成本的下界。

Result: 在所有参数下推导了带宽成本的下界，这些下界在r^F ≥ k^F或r^I ≤ k^F的参数范围内是紧致的，部分解决了Maturana和Rashmi提出的猜想。

Conclusion: 提出的信息论框架为系统MDS可转换码的带宽成本分析提供了更通用的理论基础，扩展了现有结果的应用范围。

Abstract: Recent advances in erasure coding for distributed storage systems have demonstrated that adapting redundancy to varying disk failure rates can lead to substantial storage savings. Such adaptation requires code conversion, wherein data encoded under an initial $[k^I + r^I, k^I]$ code is transformed into data encoded under a final $[k^F + r^F, k^F]$ code - an operation that can be resource-intensive. Convertible codes are a class of codes designed to facilitate this transformation efficiently while preserving desirable properties such as the MDS property. In this work, we investigate the fundamental limits on the bandwidth cost of conversion (total amount of data transferred between the storage nodes during conversion) for systematic MDS convertible codes. Specifically, we study the subclass of conversions known as the split regime (a single initial codeword is converted into multiple final codewords).
  In this setting, prior to this work, the best known lower bounds on the bandwidth cost of conversion for all parameters were derived by Maturana and Rashmi under certain uniformity assumptions on the number of symbols downloaded from each node. Further, these bounds were shown to be tight for the parameter regime where $r^F \geq k^F$ or $r^I \leq r^F$. In this work, we derive lower bounds on the bandwidth cost of systematic MDS convertible codes for all parameters in the split regime without the uniformity assumption. Moreover, our bounds are tight for the broader parameter regime where $r^F \geq k^F$ or $r^I \leq k^F$. Subsequently, our bounds also partially resolve the conjecture proposed by Maturana and Rashmi. We employ a novel information-theoretic framework, which assumes only that the initial and final codes are systematic and does not rely on any linearity assumptions or the aforementioned uniformity assumptions.

</details>


### [43] [Integration of Navigation and Remote Sensing in LEO Satellite Constellations](https://arxiv.org/abs/2511.12430)
*Qi Wang,Xiaoming Chen,Qiao Qi,Zhaolin Wang,Yuanwei Liu*

Main category: cs.IT

TL;DR: 提出一种新型双功能LEO卫星星座框架结构，有效整合导航和遥感功能，通过联合波束成形设计优化导航性能同时保证遥感需求。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星星座正成为下一代卫星网络的核心，需要实现全球高精度导航和高质量遥感的多功能集成。

Method: 推导基于克拉美-罗界的定位、测速和授时误差以及信干噪比作为性能指标，提出最小化导航用户平均加权PVT误差同时保证遥感SAINR需求的联合波束成形设计。

Result: 仿真结果验证了所提出的多卫星协作波束成形设计的有效性，证明其作为下一代多功能LEO卫星星座集成解决方案的可行性。

Conclusion: 该研究为下一代多功能LEO卫星星座提供了一种有效的集成解决方案，通过联合波束成形设计实现了导航和遥感功能的协同优化。

Abstract: Low earth orbit (LEO) satellite constellations are becoming a cornerstone of next-generation satellite networks, enabling worldwide high-precision navigation and high-quality remote sensing. This paper proposes a novel dual-function LEO satellite constellation frame structure that effectively integrating navigation and remote sensing. Then, the Cramer-Rao bound (CRB)-based positioning, velocity measurement, and timing (PVT) error and the signal-to-ambiguity-interference-noise ratio (SAINR) are derived as performance metrics for navigation and remote sensing, respectively. Based on it, a joint beamforming design is proposed by minimizing the average weighted PVT error for navigation user equipments (UEs) while ensuring SAINR requirement for remote sensing. Simulation results validate the proposed multi-satellite cooperative beamforming design, demonstrating its effectiveness as an integrated solution for next-generation multi-function LEO satellite constellations.

</details>


### [44] [Metasurface-Enabled Superheterodyne Transmitter With Decoupled Harmonic-Free Signal Generation and Precoding](https://arxiv.org/abs/2511.12469)
*Xuehui Dong,Miyu Feng,Chen Shao,Bokai Lai,Jianan Zhang,Rujing Xiong,Kai Wan,Tiebin Mi,Robert Caiming Qiu*

Main category: cs.IT

TL;DR: 提出了一种新型超外差架构的可编程超表面发射机，解决了传统超表面发射机在调制阶数、空间一致性和谐波干扰方面的限制，实现了谐波自由波形生成与空间预编码的解耦。


<details>
  <summary>Details</summary>
Motivation: 传统可编程超表面发射机存在调制阶数受限、符号级空间不一致性和显著谐波干扰等问题，这些源于基带信号处理与射频波束成形的内在耦合。

Method: 采用双级上变频过程，包括数字上变频模块进行I/Q调制和基带-中频转换、预编码模块以及定制的幅度-相位解耦超表面作为可重构反射混频器阵列。

Result: 实验验证了MSA的优越性能：生成任意阶QAM调制的空间各向同性星座图，确保多普勒欺骗等应用的一致时频特征，在线性工作区域内实现高达20 Mbps的数据速率，并首次在PM发射机中展示了空间多样性和多流干扰消除能力。

Conclusion: MSA架构通过解耦谐波自由波形生成和空间预编码，克服了现有方法的缺点，为下一代无线系统提供了有前景的解决方案。

Abstract: The evolution of programmable metasurfaces (PM) from passive beamforming to active information transmission marks a paradigm shift for next-generation wireless systems. However, this transition is hindered by fundamental limitations in conventional metasurface transmitter architectures, including restricted modulation orders, symbol-level spatial inconsistency, and significant harmonic interference. These issues stem from the intrinsic coupling between baseband signal processing and radio-frequency beamforming in monolithic designs reliant on simplistic switching mechanisms. This paper proposes a novel metasurface-enabled superheterodyne architecture (MSA) that fundamentally decouples these functionalities. The MSA introduces a dual-stage up-conversion process, comprising a digital up-conversion module for in-phase/quadrature modulation and baseband-to-intermediate frequency conversion, a precoder module for precoding, and a custom-designed magnitude-phase-decoupled metasurface that acts as a reconfigurable reflective mixer array. This decoupling of harmonic-free waveform generation from spatial precoding overcomes the critical drawbacks of existing approaches. Experimental results from a 5.8 GHz proof-of-concept prototype system validate the MSA's superior performance. The system generates spatially isotropic constellations for arbitrary-order QAM modulations, ensures consistent time-frequency signatures for applications like Doppler-spoofing, and achieves data rates up to 20 Mbps within a linear operating region that minimizes nonlinear distortion. The capability of employing spatial diversity and multi-stream interference cancellation has been demonstrated for the first time in a PM-based transmitter.

</details>


### [45] [Leave-One-Out Learning with Log-Loss](https://arxiv.org/abs/2511.12718)
*Yaniv Fogel,Meir Feder*

Main category: cs.IT

TL;DR: 该论文研究了在个体设置下使用对数损失的批量学习问题，提出了基于留一法遗憾的自然准则，并分析了多个假设类的最小最大遗憾值。


<details>
  <summary>Details</summary>
Motivation: 在个体设置中，由于结果序列是确定性的，经验统计不直接适用，因此获取批量学习的遗憾保证长期以来是一个基本挑战。

Method: 提出基于留一法遗憾的准则，分析多类假设类的最小最大遗憾值，包括多项式单纯形和VC维类。

Result: 对于m个符号的多项式单纯形，最小最大遗憾为(m-1)/N + o(1/N)；对于VC维为d的假设类，遗憾最多为d log(N)/N + o(log(N)/N)，并建立了匹配下界。

Conclusion: 这些结果首次证明在个体设置下，使用对数损失的通用批量学习是可能的。

Abstract: We study batch learning with log-loss in the individual setting, where the outcome sequence is deterministic. Because empirical statistics are not directly applicable in this regime, obtaining regret guarantees for batch learning has long posed a fundamental challenge. We propose a natural criterion based on leave-one-out regret and analyze its minimax value for several hypothesis classes. For the multinomial simplex over $m$ symbols, we show that the minimax regret is $\frac{m-1}{N} + o\!\left(\frac{1}{N}\right)$, and compare it to the stochastic realizable case where it is $\frac{m-1}{2N} + o\!\left(\frac{1}{N}\right)$. More generally, we prove that every hypothesis class of VC dimension $d$ is learnable in the individual batch-learning problem, with regret at most $\frac{d\log(N)}{N} + o\!\left(\frac{\log(N)}{N}\right)$, and we establish matching lower bounds for certain classes. We further derive additional upper bounds that depend on structural properties of the hypothesis class. These results establish, for the first time, that universal batch learning with log-loss is possible in the individual setting.

</details>


### [46] [Finite-Horizon Quickest Change Detection Balancing Latency with False Alarm Probability](https://arxiv.org/abs/2511.12803)
*Yu-Han Huang,Venugopal V. Veeravalli*

Main category: cs.IT

TL;DR: 本文研究了有限时间范围内的快速变化检测问题，提出了在给定误报概率下最小化延迟的检测器，并推导了延迟的通用下界。


<details>
  <summary>Details</summary>
Motivation: 研究非平稳环境中学习相关的快速变化检测问题，需要在有限时间范围内平衡检测延迟和误报概率。

Method: 首先考虑已知前后分布的情况，然后推广到非参数情况（仅知分布为次高斯且均值不同），开发了顺序最优的变化检测器。

Result: 推导了延迟的通用下界，并开发了在时间范围上顺序最优的检测器，通过仿真验证了理论结果。

Conclusion: 提出的变化检测方法在有限时间范围内实现了延迟和误报概率的有效平衡，适用于非平稳环境中的学习问题。

Abstract: A finite-horizon variant of the quickest change detection (QCD) problem that is of relevance to learning in non-stationary environments is studied. The metric characterizing false alarms is the probability of a false alarm occurring before the horizon ends. The metric that characterizes the delay is \emph{latency}, which is the smallest value such that the probability that detection delay exceeds this value is upper bounded to a predetermined latency level. The objective is to minimize the latency (at a given latency level), while maintaining a low false alarm probability. Under the pre-specified latency and false alarm levels, a universal lower bound on the latency, which any change detection procedure needs to satisfy, is derived. Change detectors are then developed, which are order-optimal in terms of the horizon. The case where the pre- and post-change distributions are known is considered first, and then the results are generalized to the non-parametric case when they are unknown except that they are sub-Gaussian with different means. Simulations are provided to validate the theoretical results.

</details>


### [47] [Joint Transmit Beamforming and Reflection Optimization for Beyond Diagonal RIS Aided Multi-Cell MIMO Communication](https://arxiv.org/abs/2511.13347)
*Shuo Zheng,Shuowen Zhang*

Main category: cs.IT

TL;DR: 提出了一种基于BD-RIS的多小区多用户MIMO通信系统，通过联合优化基站波束成形和BD-RIS反射矩阵来提升系统加权和速率，有效抑制小区间干扰。


<details>
  <summary>Details</summary>
Motivation: 6G超密集多小区部署会带来严重的小区间干扰，特别是对小区边缘用户，限制了通信性能。需要新的技术来增强期望信号并抑制干扰。

Method: 采用WMMSE方法将问题转化为等价可处理形式，提出基于交替优化的算法，结合拉格朗日对偶理论和流形优化来迭代更新波束成形和BD-RIS反射矩阵。

Result: 数值结果表明所提设计优于多种基准方案，并为多小区系统中BD-RIS部署策略提供了实用的实践见解。

Conclusion: BD-RIS技术能有效提升多小区系统的通信性能，特别是在抑制干扰方面表现出色，为6G网络部署提供了有前景的解决方案。

Abstract: The sixth-generation (6G) wireless networks will rely on ultra-dense multi-cell deployment to meet the high rate and connectivity demands. However, frequency reuse leads to severe inter-cell interference, particularly for cell-edge users, which limits the communication performance. To overcome this challenge, we investigate a beyond diagonal reconfigurable intelligent surface (BD-RIS) aided multi-cell multi-user downlink MIMO communication system, where a BD-RIS is deployed to enhance desired signals and suppress both intra-cell and inter-cell interference.We formulate the joint optimization problem of the transmit beamforming matrices at the BSs and the BD-RIS reflection matrix to maximize the weighted sum rate of all users, subject to the challenging unitary constraint of the BD-RIS reflection matrix and transmit power constraints at the BSs. To tackle this non-convex and difficult problem, we apply the weighted minimum mean squared error (WMMSE) method to transform the problem into an equivalent tractable form, and propose an efficient alternating optimization (AO) based algorithm to iteratively update the transmit beamforming and BD-RIS reflection using Lagrange duality theory and manifold optimization. Numerical results demonstrate the superiority of the proposed design over various benchmark schemes, and provide useful practical insights on the BD-RIS deployment strategy for multi-cell systems.

</details>


### [48] [On the Capacity of Pixel Antenna based MIMO Communication](https://arxiv.org/abs/2511.13482)
*Shenrui Lin,Shuowen Zhang*

Main category: cs.IT

TL;DR: 本文研究了配备像素天线的MIMO系统的容量极限，通过联合优化发射协方差矩阵和天线编码器来解决混合整数非线性规划问题，提出了三种算法来平衡性能与复杂度。


<details>
  <summary>Details</summary>
Motivation: 像素天线技术通过自适应重构辐射模式来提升无线通信数据速率，但现有研究缺乏对配备像素天线的MIMO系统容量极限的深入分析。

Method: 提出了三种算法：穷举搜索法获得最优解，分支定界迭代算法降低复杂度，以及多项式复杂度的交替优化算法。

Result: 数值结果表明所提算法在性能和复杂度之间实现了灵活权衡，像素天线能够显著提升MIMO通信的可达速率。

Conclusion: 像素天线技术是增强MIMO通信性能的有效手段，所提出的算法为解决相关优化问题提供了实用工具。

Abstract: Pixel antenna is a promising technology to enhance the wireless communication data rate by adaptively reconfiguring each antenna's radiation pattern via a so-called antenna coding technique which controls the states of switches connected to multiple pixel ports. This paper studies a multiple-input multiple-output (MIMO) system where both the transmitter and the receiver are equipped with multiple pixel antennas. We aim to characterize the fundamental capacity limit of this MIMO system by jointly optimizing the transmit covariance matrix and the antenna coders at both the transmitter and the receiver. This problem is a mixed-integer non-linear program (MINLP) which is non-convex and particularly challenging to solve due to the binary-valued optimization variables corresponding to the antenna coders. We first propose an exhaustive search based method to obtain the optimal solution to this problem, which corresponds to the fundamental capacity limit. Then, we propose a branch-and-bound based iterative algorithm aiming to find a high-quality suboptimal solution with lower complexity than exhaustive search as the number of pixel ports becomes large. Finally, we devise an alternating optimization (AO) based algorithm with polynomial complexity. Numerical results show that our proposed algorithms achieve a flexible trade-off between performance and complexity. Moreover, equipping the transceivers with pixel antennas can enhance the achievable rate of MIMO communications.

</details>


### [49] [A Deterministic Dimension Property of Twisted Goppa Codes](https://arxiv.org/abs/2511.13601)
*Kai Wang*

Main category: cs.IT

TL;DR: 本文通过大规模计算研究发现扭曲Goppa码的维度具有确定性规律，仅由宏观参数(q,m,t,b,u)唯一决定。


<details>
  <summary>Details</summary>
Motivation: 研究扭曲Goppa码的维度特性，探索其是否存在确定的参数依赖关系。

Method: 对超过50,000个参数集进行系统性分析，研究扭曲Goppa码的维度与宏观参数的关系。

Result: 发现扭曲Goppa码的实际维度k完全由有限域阶数q、扩张次数m、Goppa多项式次数t、自同构平移参数b和变换阶数u这五个宏观参数唯一确定。

Conclusion: 扭曲Goppa码的维度表现出显著的确定性规律，为这类码的结构特性提供了重要见解。

Abstract: This paper presents a large-scale computational study on the dimensional properties of twisted Goppa codes. Through the systematic analysis of over 50,000 parameter sets, we uncover a remarkable deterministic regularity: the actual dimension k of a twisted Goppa code is uniquely determined by a set of macro-parameters (q,m,t,b,u). Specifically, when the order of the finite field q, the extension degree m, the degree t of the Goppa polynomial, the translation parameter b of the automorphism, and the order u of the transformation are fixed, the dimension k of the generated code remains constant.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [50] [GenIE - Simulator-Driven Iterative Data Exploration for Scientific Discovery](https://arxiv.org/abs/2511.12057)
*Ashwin Gerard Colaco,Martin Boissier,Sriram Rao,Shubharoop Ghosh,Sharad Mehrotra,Tilmann Rabl*

Main category: cs.DB

TL;DR: GenIE是一个新的数据库范式，将物理模拟器无缝集成到数据库中，实现模拟工作流的动态编排，支持交互式科学数据分析。


<details>
  <summary>Details</summary>
Motivation: 当前数据库将模拟器视为外部预处理步骤，导致线性工作流程效率低下、延迟高，阻碍了交互式探索，特别是在分析本身需要新模拟数据时。

Method: GenIE作为PostgreSQL的扩展，使数据库具备"模拟感知"能力，能根据用户查询和分析需求动态调用模拟器，避免生成无关数据，重用先前数据，支持渐进式迭代分析。

Result: 初步实验表明，GenIE能将野火烟雾扩散分析和飓风灾害评估等缓慢的静态分析转变为交互式探索，智能管理多个集成模拟器之间的精度与运行时间权衡。

Conclusion: GenIE有潜力成为下一代科学数据分析的基石，但仍面临实现完整愿景的挑战和机遇。

Abstract: Physics-based simulators play a critical role in scientific discovery and risk assessment, enabling what-if analyses for events like wildfires and hurricanes. Today, databases treat these simulators as external pre-processing steps. Analysts must manually run a simulation, export the results, and load them into a database before analysis can begin. This linear workflow is inefficient, incurs high latency, and hinders interactive exploration, especially when the analysis itself dictates the need for new or refined simulation data.
  We envision a new database paradigm, entitled GenIE, that seamlessly integrates multiple simulators into databases to enable dynamic orchestration of simulation workflows. By making the database "simulation-aware," GenIE can dynamically invoke simulators with appropriate parameters based on the user's query and analytical needs. This tight integration allows GenIE to avoid generating data irrelevant to the analysis, reuse previously generated data, and support iterative, incremental analysis where results are progressively refined at interactive speeds.
  We present our vision for GenIE, designed as an extension to PostgreSQL, and demonstrate its potential benefits through comprehensive use cases: wildfire smoke dispersion analysis using WRF-SFIRE and HYSPLIT, and hurricane hazard assessment integrating wind, surge, and flood models. Our preliminary experiments show how GenIE can transform these slow, static analyses into interactive explorations by intelligently managing the trade-off between simulation accuracy and runtime across multiple integrated simulators. We conclude by highlighting the challenges and opportunities ahead in realizing the full vision of GenIE as a cornerstone for next-generation scientific data analysis.

</details>


### [51] [SEE++: Evolving Snowpark Execution Environment for Modern Workloads](https://arxiv.org/abs/2511.12457)
*Gaurav Jain,Brandon Baker,Joe Yin,Chenwei Xie,Zihao Ye,Sidh Kulkarni,Sara Abdelrahman,Nova Qi,Urjeet Shrestha,Mike Halcrow,Dave Bailey,Yuxiong He*

Main category: cs.DB

TL;DR: Snowpark从内部沙箱解决方案迁移到gVisor，以支持更复杂的AI/ML工作负载，通过优化实现安全性和性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着Snowpark采用率增长，工作负载多样性带来了更复杂的沙箱需求，需要更强大和灵活的沙箱解决方案。

Method: 将内部沙箱解决方案迁移到gVisor，并进行针对性优化，构建新的沙箱架构。

Result: 成功升级沙箱架构，解决了迁移过程中的挑战，支持了新的功能特性。

Conclusion: 升级后的架构展示了SEE的可扩展性和灵活性，能够支持下一代Snowpark工作负载。

Abstract: Snowpark enables Data Engineering and AI/ML workloads to run directly within Snowflake by deploying a secure sandbox on virtual warehouse nodes. This Snowpark Execution Environment (SEE) allows users to execute arbitrary workloads in Python and other languages in a secure and performant manner. As adoption has grown, the diversity of workloads has introduced increasingly sophisticated needs for sandboxing. To address these evolving requirements, Snowpark transitioned its in-house sandboxing solution to gVisor, augmented with targeted optimizations. This paper describes both the functional and performance objectives that guided the upgrade, outlines the new sandbox architecture, and details the challenges encountered during the journey, along with the solutions developed to resolve them. Finally, we present case studies that highlight new features enabled by the upgraded architecture, demonstrating SEE's extensibility and flexibility in supporting the next generation of Snowpark workloads.

</details>


### [52] [Redbench: Workload Synthesis From Cloud Traces](https://arxiv.org/abs/2511.13059)
*Johannes Wehrstein,Roman Heinrich,Mihail Stoian,Skander Krid,Martin Stemmer,Andreas Kipf,Carsten Binnig,Muhammad El-Hindi*

Main category: cs.DB

TL;DR: Redbench是一个新型基准测试工具，通过整合多种工作负载生成技术，将现有基准测试转换为保留真实工作负载特征的查询流，弥补了合成工作负载与真实工作负载之间的差距。


<details>
  <summary>Details</summary>
Motivation: 云数据仓库提供商的工作负载跟踪显示，TPC-H和TPC-DS等标准基准测试无法捕捉真实世界工作负载的关键特征，包括查询重复和字符串密集型查询。

Method: 开发了Redbench工作负载生成器，整合多种工作负载生成技术，基于云提供商发布的跟踪数据重现真实世界工作负载特征，将现有基准测试转换为现实的查询流。

Result: 评估显示：(1) Redbench为云数据仓库基准测试生成了更真实和可重现的工作负载；(2) 在四个商业数据仓库平台上揭示了系统优化的影响。

Conclusion: Redbench为推进现代云数据仓库优化技术研究提供了关键基础。

Abstract: Workload traces from cloud data warehouse providers reveal that standard benchmarks such as TPC-H and TPC-DS fail to capture key characteristics of real-world workloads, including query repetition and string-heavy queries. In this paper, we introduce Redbench, a novel benchmark featuring a workload generator that reproduces real-world workload characteristics derived from traces released by cloud providers. Redbench integrates multiple workload generation techniques to tailor workloads to specific objectives, transforming existing benchmarks into realistic query streams that preserve intrinsic workload characteristics. By focusing on inherent workload signals rather than execution-specific metrics, Redbench bridges the gap between synthetic and real workloads. Our evaluation shows that (1) Redbench produces more realistic and reproducible workloads for cloud data warehouse benchmarking, and (2) Redbench reveals the impact of system optimizations across four commercial data warehouse platforms. We believe that Redbench provides a crucial foundation for advancing research on optimization techniques for modern cloud data warehouses.

</details>
