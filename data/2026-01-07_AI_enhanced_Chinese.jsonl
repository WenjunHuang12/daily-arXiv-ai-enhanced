{"id": "2601.02532", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.02532", "abs": "https://arxiv.org/abs/2601.02532", "authors": ["Manuel Lafond", "Francis Sarrazin"], "title": "A $O^*((2 + \u03b5)^k)$ Time Algorithm for Cograph Deletion Using Unavoidable Subgraphs in Large Prime Graphs", "comment": null, "summary": "We study the parameterized complexity of the Cograph Deletion problem, which asks whether one can delete at most $k$ edges from a graph to make it $P_4$-free. This is a well-known graph modification problem with applications in computation biology and social network analysis.\n  All current parameterized algorithms use a similar strategy, which is to find a $P_4$ and explore the local structure around it to perform an efficient recursive branching.\n  The best known algorithm achieves running time $O^*(2.303^k)$ and requires an automated search of the branching cases due to their complexity.\n  Since it appears difficult to further improve the current strategy, we devise a new approach using modular decompositions. We solve each module and the quotient graph independently, with the latter being the core problem. This reduces the problem to solving on a prime graph, in which all modules are trivial. We then use a characterization of Chudnovsky et al. stating that any large enough prime graph has one of seven structures as an induced subgraph. These all have many $P_4$s, with the quantity growing linearly with the graph size, and we show that these allow a recursive branch tree algorithm to achieve running time $O^*((2 + \u03b5)^k)$ for any $\u03b5> 0$.\n  This appears to be the first algorithmic application of the prime graph characterization and it could be applicable to other modification problems. Towards this goal, we provide the exact set of graph classes $\\H$ for which the $\\H$-free editing problem can make use of our reduction to a prime graph, opening the door to improvements for other modification problems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6a21\u5206\u89e3\u7684\u65b0\u65b9\u6cd5\u89e3\u51b3Cograph Deletion\u95ee\u9898\uff0c\u5c06\u8fd0\u884c\u65f6\u95f4\u4eceO*(2.303^k)\u6539\u8fdb\u5230O*((2+\u03b5)^k)\uff0c\u5e76\u9996\u6b21\u5e94\u7528\u4e86\u7d20\u6570\u56fe\u7684\u7ed3\u6784\u7279\u5f81\u3002", "motivation": "Cograph Deletion\u95ee\u9898\u5728\u8ba1\u7b97\u751f\u7269\u5b66\u548c\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u4e2d\u6709\u5e94\u7528\u3002\u73b0\u6709\u53c2\u6570\u5316\u7b97\u6cd5\u90fd\u91c7\u7528\u76f8\u4f3c\u7684\u7b56\u7565\uff0c\u901a\u8fc7\u5bfb\u627eP4\u5e76\u63a2\u7d22\u5176\u5c40\u90e8\u7ed3\u6784\u8fdb\u884c\u9012\u5f52\u5206\u652f\uff0c\u6700\u4f73\u7b97\u6cd5\u8fd0\u884c\u65f6\u95f4\u4e3aO*(2.303^k)\uff0c\u4e14\u7531\u4e8e\u5206\u652f\u60c5\u51b5\u590d\u6742\u9700\u8981\u81ea\u52a8\u641c\u7d22\u3002\u7531\u4e8e\u96be\u4ee5\u8fdb\u4e00\u6b65\u6539\u8fdb\u73b0\u6709\u7b56\u7565\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6a21\u5206\u89e3\u7684\u65b0\u65b9\u6cd5\uff1a1) \u5c06\u56fe\u5206\u89e3\u4e3a\u6a21\u5757\u548c\u5546\u56fe\uff0c\u5206\u522b\u72ec\u7acb\u89e3\u51b3\uff1b2) \u5c06\u95ee\u9898\u7b80\u5316\u4e3a\u5728\u7d20\u6570\u56fe\u4e0a\u6c42\u89e3\uff08\u6240\u6709\u6a21\u5757\u90fd\u662f\u5e73\u51e1\u7684\uff09\uff1b3) \u5229\u7528Chudnovsky\u7b49\u4eba\u7684\u7279\u5f81\u5316\u7ed3\u679c\uff1a\u4efb\u4f55\u8db3\u591f\u5927\u7684\u7d20\u6570\u56fe\u90fd\u5305\u542b\u4e03\u79cd\u7ed3\u6784\u4e4b\u4e00\u4f5c\u4e3a\u8bf1\u5bfc\u5b50\u56fe\uff1b4) \u8fd9\u4e9b\u7ed3\u6784\u90fd\u6709\u5927\u91cfP4\uff08\u6570\u91cf\u968f\u56fe\u5927\u5c0f\u7ebf\u6027\u589e\u957f\uff09\uff0c\u4ece\u800c\u5141\u8bb8\u9012\u5f52\u5206\u652f\u7b97\u6cd5\u8fbe\u5230O*((2+\u03b5)^k)\u7684\u8fd0\u884c\u65f6\u95f4\u3002", "result": "\u5b9e\u73b0\u4e86\u8fd0\u884c\u65f6\u95f4O*((2+\u03b5)^k)\u7684\u53c2\u6570\u5316\u7b97\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684O*(2.303^k)\u3002\u8fd9\u662f\u7d20\u6570\u56fe\u7279\u5f81\u5316\u7684\u9996\u6b21\u7b97\u6cd5\u5e94\u7528\uff0c\u5e76\u4e3a\u5176\u4ed6\u4fee\u6539\u95ee\u9898\u7684\u6539\u8fdb\u6253\u5f00\u4e86\u5927\u95e8\u3002", "conclusion": "\u901a\u8fc7\u6a21\u5206\u89e3\u548c\u7d20\u6570\u56fe\u7ed3\u6784\u7279\u5f81\u5316\u7684\u65b0\u65b9\u6cd5\uff0c\u663e\u8457\u6539\u8fdb\u4e86Cograph Deletion\u95ee\u9898\u7684\u53c2\u6570\u5316\u7b97\u6cd5\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u56fe\u4fee\u6539\u95ee\u9898\uff0c\u8bba\u6587\u8fd8\u786e\u5b9a\u4e86\u54ea\u4e9b\u56fe\u7c7bH\u7684H-free\u7f16\u8f91\u95ee\u9898\u53ef\u4ee5\u5229\u7528\u8fd9\u79cd\u7ea6\u7b80\u5230\u7d20\u6570\u56fe\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.02836", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.02836", "abs": "https://arxiv.org/abs/2601.02836", "authors": ["Klaus Jansen", "Felix Ohnesorge"], "title": "A Practical 73/50 Approximation for Contiguous Monotone Moldable Job Scheduling", "comment": "to appear in STACS 2026", "summary": "In moldable job scheduling, we are provided $m$ identical machines and $n$ jobs that can be executed on a variable number of machines. The execution time of each job depends on the number of machines assigned to execute that job. For the specific problem of monotone moldable job scheduling, jobs are assumed to have a processing time that is non-increasing in the number of machines.\n  The previous best-known algorithms are: (1) a polynomial-time approximation scheme with time complexity $\u03a9(n^{g(1/\\varepsilon)})$, where $g(\\cdot)$ is a super-exponential function [Jansen and Th\u00f6le '08; Jansen and Land '18], (2) a fully polynomial approximation scheme for the case of $m \\geq 8\\frac{n}{\\varepsilon}$ [Jansen and Land '18], and (3) a $\\frac{3}{2}$ approximation with time complexity $O(nm\\log(mn))$ [Wu, Zhang, and Chen '23].\n  We present a new practically efficient algorithm with an approximation ratio of $\\approx (1.4593 + \\varepsilon)$ and a time complexity of $O(nm \\log \\frac{1}{\\varepsilon})$. Our result also applies to the contiguous variant of the problem. In addition to our theoretical results, we implement the presented algorithm and show that the practical performance is significantly better than the theoretical worst-case approximation ratio.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5355\u8c03\u53ef\u5851\u4f5c\u4e1a\u8c03\u5ea6\u7684\u65b0\u7b97\u6cd5\uff0c\u8fd1\u4f3c\u6bd4\u4e3a\u22481.4593+\u03b5\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(nm log(1/\u03b5))\uff0c\u76f8\u6bd4\u4e4b\u524d\u7b97\u6cd5\u5728\u6548\u7387\u548c\u5b9e\u7528\u6027\u4e0a\u6709\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u7684\u5355\u8c03\u53ef\u5851\u4f5c\u4e1a\u8c03\u5ea6\u7b97\u6cd5\u5b58\u5728\u4ee5\u4e0b\u95ee\u9898\uff1a1\uff09PTAS\u7b97\u6cd5\u65f6\u95f4\u590d\u6742\u5ea6\u6781\u9ad8\uff08\u03a9(n^{g(1/\u03b5)})\uff0c\u5176\u4e2dg\u662f\u8d85\u6307\u6570\u51fd\u6570\uff09\uff1b2\uff09\u5b8c\u5168\u591a\u9879\u5f0f\u8fd1\u4f3c\u65b9\u6848\u4ec5\u9002\u7528\u4e8em\u22658n/\u03b5\u7684\u7279\u6b8a\u60c5\u51b5\uff1b3\uff093/2\u8fd1\u4f3c\u7b97\u6cd5\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(nm log(mn))\u3002\u9700\u8981\u5f00\u53d1\u66f4\u5b9e\u7528\u3001\u9ad8\u6548\u7684\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u6838\u5fc3\u601d\u60f3\u662f\u901a\u8fc7\u66f4\u9ad8\u6548\u7684\u8c03\u5ea6\u7b56\u7565\u548c\u4f18\u5316\u6280\u672f\uff0c\u5728\u4fdd\u8bc1\u8fd1\u4f3c\u6bd4\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u65f6\u95f4\u590d\u6742\u5ea6\u3002\u7b97\u6cd5\u91c7\u7528O(nm log(1/\u03b5))\u7684\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u9002\u7528\u4e8e\u8fde\u7eed\u53d8\u4f53\u95ee\u9898\u3002", "result": "\u7b97\u6cd5\u8fbe\u5230\u2248(1.4593+\u03b5)\u7684\u8fd1\u4f3c\u6bd4\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(nm log(1/\u03b5))\u3002\u5b9e\u9645\u5b9e\u73b0\u8868\u660e\uff0c\u7b97\u6cd5\u7684\u5b9e\u9645\u6027\u80fd\u660e\u663e\u4f18\u4e8e\u7406\u8bba\u6700\u574f\u60c5\u51b5\u8fd1\u4f3c\u6bd4\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u90fd\u9ad8\u6548\u7684\u5355\u8c03\u53ef\u5851\u4f5c\u4e1a\u8c03\u5ea6\u7b97\u6cd5\uff0c\u5728\u8fd1\u4f3c\u6bd4\u548c\u65f6\u95f4\u590d\u6742\u5ea6\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u76f8\u6bd4\u73b0\u6709\u7b97\u6cd5\u6709\u663e\u8457\u6539\u8fdb\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.03020", "categories": ["cs.DS", "cs.CC", "cs.FL"], "pdf": "https://arxiv.org/pdf/2601.03020", "abs": "https://arxiv.org/abs/2601.03020", "authors": ["Taisei Nogami", "Tachio Terauchi"], "title": "Hardness of Regular Expression Matching with Extensions", "comment": null, "summary": "The regular expression matching problem asks whether a given regular expression of length $m$ matches a given string of length $n$. As is well known, the problem can be solved in $O(nm)$ time using Thompson's algorithm. Moreover, recent studies have shown that the matching problem for regular expressions extended with a practical extension called lookaround can be solved in the same time complexity. In this work, we consider three well-known extensions to regular expressions called backreference, intersection and complement, and we show that, unlike in the case of lookaround, the matching problem for regular expressions extended with any of the three (for backreference, even when restricted to one capturing group) cannot be solved in $O(n^{2-\\varepsilon} \\mathrm{poly}(m))$ time for any constant $\\varepsilon > 0$ under the Orthogonal Vectors Conjecture. Moreover, we study the matching problem for regular expressions extended with complement in more detail, which is also known as extended regular expression (ERE) matching. We show that there is no ERE matching algorithm that runs in $O(n^{\u03c9-\\varepsilon} \\mathrm{poly}(m))$ time ($2 \\le \u03c9< 2.3716$ is the exponent of square matrix multiplication) for any constant $\\varepsilon > 0$ under the $k$-Clique Hypothesis, and there is no combinatorial ERE matching algorithm that runs in $O(n^{3-\\varepsilon} \\mathrm{poly}(m))$ time for any constant $\\varepsilon > 0$ under the Combinatorial $k$-Clique Hypothesis. This shows that the $O(n^3 m)$-time algorithm introduced by Hopcroft and Ullman in 1979 and recently improved by Bille et al. to run in $O(n^\u03c9m)$ time using fast matrix multiplication was already optimal in a sense, and sheds light on why the theoretical computer science community has struggled to improve the time complexity of ERE matching with respect to $n$ and $m$ for more than 45 years.", "AI": {"tldr": "\u6b63\u5219\u8868\u8fbe\u5f0f\u5339\u914d\u95ee\u9898\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e0b\u754c\u7814\u7a76\uff1a\u5bf9\u4e8e\u5305\u542b\u53cd\u5411\u5f15\u7528\u3001\u4ea4\u96c6\u548c\u8865\u96c6\u6269\u5c55\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\uff0c\u5728OVC\u5047\u8bbe\u4e0b\u65e0\u6cd5\u8fbe\u5230O(n^{2-\u03b5})\u65f6\u95f4\uff1b\u5bf9\u4e8eERE\uff08\u542b\u8865\u96c6\uff09\u5339\u914d\uff0c\u5728k-Clique\u5047\u8bbe\u4e0b\u65e0\u6cd5\u8fbe\u5230O(n^{\u03c9-\u03b5})\u65f6\u95f4\uff0c\u7ec4\u5408\u7b97\u6cd5\u65e0\u6cd5\u8fbe\u5230O(n^{3-\u03b5})\u65f6\u95f4\u3002", "motivation": "\u7814\u7a76\u6b63\u5219\u8868\u8fbe\u5f0f\u5339\u914d\u95ee\u9898\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e0b\u754c\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5305\u542b\u53cd\u5411\u5f15\u7528\u3001\u4ea4\u96c6\u548c\u8865\u96c6\u7b49\u6269\u5c55\u529f\u80fd\u7684\u60c5\u51b5\u3002\u867d\u7136Thompson\u7b97\u6cd5\u80fd\u5728O(nm)\u65f6\u95f4\u5185\u89e3\u51b3\u57fa\u672c\u6b63\u5219\u8868\u8fbe\u5f0f\u5339\u914d\uff0c\u4e14lookaround\u6269\u5c55\u4e5f\u80fd\u4fdd\u6301\u76f8\u540c\u590d\u6742\u5ea6\uff0c\u4f46\u5176\u4ed6\u6269\u5c55\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e0b\u754c\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u57fa\u4e8e\u8ba1\u7b97\u590d\u6742\u6027\u7406\u8bba\u4e2d\u7684\u5047\u8bbe\uff08\u6b63\u4ea4\u5411\u91cf\u731c\u60f3OVC\u548ck-Clique\u5047\u8bbe\uff09\uff0c\u901a\u8fc7\u5f52\u7ea6\u65b9\u6cd5\u8bc1\u660e\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u4e0b\u754c\u3002\u5bf9\u4e8eERE\u5339\u914d\u95ee\u9898\uff0c\u5206\u522b\u8003\u8651\u4e86\u4f7f\u7528\u5feb\u901f\u77e9\u9635\u4e58\u6cd5\u7684\u7b97\u6cd5\u548c\u7ec4\u5408\u7b97\u6cd5\u4e24\u79cd\u60c5\u51b5\u3002", "result": "1. \u5bf9\u4e8e\u5305\u542b\u53cd\u5411\u5f15\u7528\u3001\u4ea4\u96c6\u6216\u8865\u96c6\u6269\u5c55\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u5339\u914d\uff0c\u5728OVC\u5047\u8bbe\u4e0b\u65e0\u6cd5\u5728O(n^{2-\u03b5} poly(m))\u65f6\u95f4\u5185\u89e3\u51b3\uff08\u53cd\u5411\u5f15\u7528\u5373\u4f7f\u9650\u5236\u4e3a\u4e00\u4e2a\u6355\u83b7\u7ec4\uff09\u3002\n2. \u5bf9\u4e8eERE\uff08\u542b\u8865\u96c6\uff09\u5339\u914d\uff0c\u5728k-Clique\u5047\u8bbe\u4e0b\u65e0\u6cd5\u5728O(n^{\u03c9-\u03b5} poly(m))\u65f6\u95f4\u5185\u89e3\u51b3\uff08\u03c9\u4e3a\u77e9\u9635\u4e58\u6cd5\u6307\u6570\uff09\u3002\n3. \u7ec4\u5408ERE\u5339\u914d\u7b97\u6cd5\u5728\u7ec4\u5408k-Clique\u5047\u8bbe\u4e0b\u65e0\u6cd5\u5728O(n^{3-\u03b5} poly(m))\u65f6\u95f4\u5185\u89e3\u51b3\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u6b63\u5219\u8868\u8fbe\u5f0f\u6269\u5c55\u529f\u80fd\u5bf9\u5339\u914d\u95ee\u9898\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u6839\u672c\u5f71\u54cd\uff0c\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48ERE\u5339\u914d\u95ee\u9898\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u572845\u5e74\u6765\u96be\u4ee5\u6539\u8fdb\u3002Hopcroft\u548cUllman\u7684O(n\u00b3m)\u7b97\u6cd5\u4ee5\u53caBille\u7b49\u4eba\u7684O(n^\u03c9m)\u6539\u8fdb\u5df2\u7ecf\u63a5\u8fd1\u6700\u4f18\uff0c\u8fd9\u4e3a\u7406\u89e3\u6b63\u5219\u8868\u8fbe\u5f0f\u5339\u914d\u7684\u8ba1\u7b97\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2601.02824", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.02824", "abs": "https://arxiv.org/abs/2601.02824", "authors": ["John R. Talburt", "Muzakkiruddin Ahmed Mohammed", "Mert Can Cakmak", "Onais Khan Mohammed", "Mahboob Khan Mohammed", "Khizer Syed", "Leon Claasssens"], "title": "Case Count Metric for Comparative Analysis of Entity Resolution Results", "comment": null, "summary": "This paper describes a new process and software system, the Case Count Metric System (CCMS), for systematically comparing and analyzing the outcomes of two different ER clustering processes acting on the same dataset when the true linking (labeling) is not known. The CCMS produces a set of counts that describe how the clusters produced by the first process are transformed by the second process based on four possible transformation scenarios. The transformations are that a cluster formed in the first process either remains unchanged, merges into a larger cluster, is partitioned into smaller clusters, or otherwise overlaps with multiple clusters formed in the second process. The CCMS produces a count for each of these cases, accounting for every cluster formed in the first process. In addition, when run in analysis mode, the CCMS program can assist the user in evaluating these changes by displaying the details for all changes or only for certain types of changes. The paper includes a detailed description of the CCMS process and program and examples of how the CCMS has been applied in university and industry research.", "AI": {"tldr": "\u5f00\u53d1\u4e86Case Count Metric System (CCMS)\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u771f\u5b9e\u94fe\u63a5\u672a\u77e5\u7684\u60c5\u51b5\u4e0b\uff0c\u7cfb\u7edf\u6bd4\u8f83\u548c\u5206\u6790\u4e24\u4e2a\u4e0d\u540cER\u805a\u7c7b\u8fc7\u7a0b\u5728\u540c\u4e00\u6570\u636e\u96c6\u4e0a\u7684\u7ed3\u679c\uff0c\u901a\u8fc7\u56db\u79cd\u8f6c\u6362\u573a\u666f\u7edf\u8ba1\u96c6\u7fa4\u53d8\u5316\u60c5\u51b5\u3002", "motivation": "\u5728\u5b9e\u4f53\u89e3\u6790(ER)\u4e2d\uff0c\u5f53\u4e0d\u77e5\u9053\u771f\u5b9e\u94fe\u63a5\u5173\u7cfb\u65f6\uff0c\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\u6765\u6bd4\u8f83\u4e0d\u540c\u805a\u7c7b\u8fc7\u7a0b\u7684\u7ed3\u679c\uff0c\u4ee5\u8bc4\u4f30\u5b83\u4eec\u5982\u4f55\u8f6c\u6362\u96c6\u7fa4\u7ed3\u6784\u3002", "method": "\u5f00\u53d1CCMS\u7cfb\u7edf\u548c\u8f6f\u4ef6\uff0c\u57fa\u4e8e\u56db\u79cd\u8f6c\u6362\u573a\u666f\u7edf\u8ba1\u96c6\u7fa4\u53d8\u5316\uff1a\u4fdd\u6301\u4e0d\u53d8\u3001\u5408\u5e76\u4e3a\u66f4\u5927\u96c6\u7fa4\u3001\u5206\u5272\u4e3a\u66f4\u5c0f\u96c6\u7fa4\u3001\u4e0e\u591a\u4e2a\u96c6\u7fa4\u91cd\u53e0\u3002\u7cfb\u7edf\u53ef\u4ee5\u5206\u6790\u6a21\u5f0f\u663e\u793a\u8be6\u7ec6\u53d8\u5316\u4fe1\u606f\u3002", "result": "CCMS\u80fd\u591f\u7cfb\u7edf\u91cf\u5316\u4e24\u4e2aER\u805a\u7c7b\u8fc7\u7a0b\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u63d0\u4f9b\u8be6\u7ec6\u7684\u7edf\u8ba1\u8ba1\u6570\uff0c\u5e76\u5728\u5927\u5b66\u548c\u5de5\u4e1a\u7814\u7a76\u4e2d\u5f97\u5230\u5e94\u7528\u9a8c\u8bc1\u3002", "conclusion": "CCMS\u4e3a\u6bd4\u8f83\u672a\u77e5\u771f\u5b9e\u94fe\u63a5\u60c5\u51b5\u4e0b\u7684ER\u805a\u7c7b\u7ed3\u679c\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7cfb\u7edf\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u8bc4\u4f30\u805a\u7c7b\u8fc7\u7a0b\u7684\u8d28\u91cf\u548c\u5dee\u5f02\u3002"}}
{"id": "2601.03129", "categories": ["cs.DS", "cs.DM"], "pdf": "https://arxiv.org/pdf/2601.03129", "abs": "https://arxiv.org/abs/2601.03129", "authors": ["Matthias Bentert", "Tom-Lukas Breitkopf", "Vincent Froese", "Anton Herrmann", "Andr\u00e9 Nichterlein"], "title": "Density Matters: A Complexity Dichotomy of Deleting Edges to Bound Subgraph Density", "comment": "to appear at STACS 2026", "summary": "We study $\u03c4$-Bounded-Density Edge Deletion ($\u03c4$-BDED), where given an undirected graph $G$, the task is to remove as few edges as possible to obtain a graph $G'$ where no subgraph of $G'$ has density more than $\u03c4$. The density of a (sub)graph is the number of edges divided by the number of vertices. This problem was recently introduced and shown to be NP-hard for $\u03c4\\in \\{2/3, 3/4, 1 + 1/25\\}$, but polynomial-time solvable for $\u03c4\\in \\{0,1/2,1\\}$ [Bazgan et al., JCSS 2025]. We provide a complete dichotomy with respect to the target density $\u03c4$:\n  1. If $2\u03c4\\in \\mathbb{N}$ (half-integral target density) or $\u03c4< 2/3$, then $\u03c4$-BDED is polynomial-time solvable.\n  2. Otherwise, $\u03c4$-BDED is NP-hard.\n  We complement the NP-hardness with fixed-parameter tractability with respect to the treewidth of $G$. Moreover, for integral target density $\u03c4\\in \\mathbb{N}$, we show $\u03c4$-BDED to be solvable in randomized $O(m^{1 + o(1)})$ time. Our algorithmic results are based on a reduction to a new general flow problem on restricted networks that, depending on $\u03c4$, can be solved via Maximum s-t-Flow or General Factors. We believe this connection between these variants of flow and matching to be of independent interest.", "AI": {"tldr": "\u03c4-BDED\u95ee\u9898\u7684\u590d\u6742\u6027\u5b8c\u5168\u5206\u7c7b\uff1a\u5f532\u03c4\u4e3a\u6574\u6570\u6216\u03c4<2/3\u65f6\u591a\u9879\u5f0f\u53ef\u89e3\uff0c\u5426\u5219NP\u96be\u3002\u540c\u65f6\u7ed9\u51fa\u4e86\u6811\u5bbd\u53c2\u6570\u4e0b\u7684FPT\u7b97\u6cd5\u548c\u6574\u6570\u03c4\u65f6\u7684\u968f\u673a\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76\u03c4-\u6709\u754c\u5bc6\u5ea6\u8fb9\u5220\u9664\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u8be5\u95ee\u9898\u8981\u6c42\u5220\u9664\u6700\u5c11\u8fb9\u4f7f\u5f97\u56fe\u4e2d\u6240\u6709\u5b50\u56fe\u5bc6\u5ea6\u4e0d\u8d85\u8fc7\u03c4\u3002\u4e4b\u524d\u5df2\u77e5\u90e8\u5206\u03c4\u503c\u7684\u590d\u6742\u6027\uff0c\u9700\u8981\u5b8c\u6574\u7684\u590d\u6742\u6027\u5206\u7c7b\u3002", "method": "\u901a\u8fc7\u5c06\u95ee\u9898\u89c4\u7ea6\u5230\u65b0\u7684\u53d7\u9650\u7f51\u7edc\u6d41\u95ee\u9898\uff0c\u6839\u636e\u03c4\u503c\u5206\u522b\u4f7f\u7528\u6700\u5927s-t\u6d41\u6216\u4e00\u822c\u56e0\u5b50\u5339\u914d\u7b97\u6cd5\u6c42\u89e3\u3002\u5bf9\u4e8eNP\u96be\u60c5\u51b5\uff0c\u63d0\u4f9b\u6811\u5bbd\u53c2\u6570\u4e0b\u7684\u56fa\u5b9a\u53c2\u6570\u53ef\u89e3\u7b97\u6cd5\u3002", "result": "\u5efa\u7acb\u4e86\u5b8c\u6574\u7684\u590d\u6742\u6027\u4e8c\u5206\uff1a\u5f532\u03c4\u2208\u2115\u6216\u03c4<2/3\u65f6\u591a\u9879\u5f0f\u53ef\u89e3\uff0c\u5426\u5219NP\u96be\u3002\u5bf9\u4e8e\u6574\u6570\u03c4\u2208\u2115\uff0c\u7ed9\u51fa\u4e86\u968f\u673aO(m^{1+o(1)})\u65f6\u95f4\u7b97\u6cd5\uff0c\u5e76\u5728\u6811\u5bbd\u53c2\u6570\u4e0b\u83b7\u5f97FPT\u7b97\u6cd5\u3002", "conclusion": "\u5b8c\u5168\u89e3\u51b3\u4e86\u03c4-BDED\u95ee\u9898\u7684\u590d\u6742\u6027\u5206\u7c7b\uff0c\u5efa\u7acb\u4e86\u6d41\u4e0e\u5339\u914d\u53d8\u4f53\u4e4b\u95f4\u7684\u65b0\u8054\u7cfb\uff0c\u8fd9\u4e9b\u6280\u672f\u5177\u6709\u72ec\u7acb\u7684\u7814\u7a76\u4ef7\u503c\u3002"}}
{"id": "2601.03137", "categories": ["cs.DB", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03137", "abs": "https://arxiv.org/abs/2601.03137", "authors": ["Yangfan Jiang", "Fei Wei", "Ergute Bao", "Yaliang Li", "Bolin Ding", "Yin Yang", "Xiaokui Xiao"], "title": "Accurate Table Question Answering with Accessible LLMs", "comment": "accepted for publication in the Proceedings of the IEEE International Conference on Data Engineering (ICDE) 2026", "summary": "Given a table T in a database and a question Q in natural language, the table question answering (TQA) task aims to return an accurate answer to Q based on the content of T. Recent state-of-the-art solutions leverage large language models (LLMs) to obtain high-quality answers. However, most rely on proprietary, large-scale LLMs with costly API access, posing a significant financial barrier. This paper instead focuses on TQA with smaller, open-weight LLMs that can run on a desktop or laptop. This setting is challenging, as such LLMs typically have weaker capabilities than large proprietary models, leading to substantial performance degradation with existing methods.\n  We observe that a key reason for this degradation is that prior approaches often require the LLM to solve a highly sophisticated task using long, complex prompts, which exceed the capabilities of small open-weight LLMs. Motivated by this observation, we present Orchestra, a multi-agent approach that unlocks the potential of accessible LLMs for high-quality, cost-effective TQA. Orchestra coordinates a group of LLM agents, each responsible for a relatively simple task, through a structured, layered workflow to solve complex TQA problems -- akin to an orchestra. By reducing the prompt complexity faced by each agent, Orchestra significantly improves output reliability.\n  We implement Orchestra on top of AgentScope, an open-source multi-agent framework, and evaluate it on multiple TQA benchmarks using a wide range of open-weight LLMs. Experimental results show that Orchestra achieves strong performance even with small- to medium-sized models. For example, with Qwen2.5-14B, Orchestra reaches 72.1% accuracy on WikiTQ, approaching the best prior result of 75.3% achieved with GPT-4; with larger Qwen, Llama, or DeepSeek models, Orchestra outperforms all prior methods and establishes new state-of-the-art results across all benchmarks.", "AI": {"tldr": "Orchestra\uff1a\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u901a\u8fc7\u534f\u8c03\u591a\u4e2a\u5c0f\u578b\u5f00\u6e90LLM\u5b8c\u6210\u7b80\u5355\u4efb\u52a1\uff0c\u89e3\u51b3\u590d\u6742\u8868\u683c\u95ee\u7b54\u95ee\u9898\uff0c\u964d\u4f4e\u4f7f\u7528\u6210\u672c\u5e76\u63d0\u5347\u6027\u80fd", "motivation": "\u5f53\u524d\u8868\u683c\u95ee\u7b54\uff08TQA\uff09\u4efb\u52a1\u4f9d\u8d56\u6602\u8d35\u7684\u5927\u578b\u4e13\u6709LLM\uff0c\u5b58\u5728\u663e\u8457\u7ecf\u6d4e\u969c\u788d\u3002\u5c0f\u578b\u5f00\u6e90LLM\u867d\u7136\u6210\u672c\u4f4e\uff0c\u4f46\u80fd\u529b\u8f83\u5f31\uff0c\u73b0\u6709\u65b9\u6cd5\u5bfc\u81f4\u6027\u80fd\u5927\u5e45\u4e0b\u964d", "method": "\u63d0\u51faOrchestra\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u534f\u8c03\u4e00\u7ec4LLM\u667a\u80fd\u4f53\uff0c\u6bcf\u4e2a\u8d1f\u8d23\u76f8\u5bf9\u7b80\u5355\u7684\u4efb\u52a1\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u5c42\u5de5\u4f5c\u6d41\u7a0b\u89e3\u51b3\u590d\u6742TQA\u95ee\u9898\uff0c\u964d\u4f4e\u6bcf\u4e2a\u667a\u80fd\u4f53\u9762\u4e34\u7684\u63d0\u793a\u590d\u6742\u5ea6", "result": "\u5728\u591a\u4e2aTQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528Qwen2.5-14B\u8fbe\u523072.1%\u51c6\u786e\u7387\uff08\u63a5\u8fd1GPT-4\u768475.3%\uff09\uff1b\u4f7f\u7528\u66f4\u5927\u7684Qwen\u3001Llama\u6216DeepSeek\u6a21\u578b\u65f6\uff0c\u8d85\u8d8a\u6240\u6709\u5148\u524d\u65b9\u6cd5\uff0c\u5728\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5efa\u7acb\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c", "conclusion": "Orchestra\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u663e\u8457\u63d0\u5347\u4e86\u5c0f\u578b\u5f00\u6e90LLM\u5728\u8868\u683c\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848"}}
{"id": "2601.02629", "categories": ["cs.MM"], "pdf": "https://arxiv.org/pdf/2601.02629", "abs": "https://arxiv.org/abs/2601.02629", "authors": ["Arman Nik Khah", "Ravi Prakash"], "title": "Listen to the Unexpected: Self-Supervised Surprise Detection for Efficient Viewport Prediction", "comment": "10 pages, 5 figures, Under review", "summary": "Adaptive streaming of 360-degree video relies on viewport prediction to allocate bandwidth efficiently. Current approaches predominantly use visual saliency or historical gaze patterns, neglecting the role of spatial audio in guiding user attention. This paper presents a self-learning framework for detecting \"surprising\" auditory events -- moments that deviate from learned temporal expectations -- and demonstrates their utility for viewport prediction. The proposed architecture combines $SE(3)$-equivariant graph neural networks with recurrent temporal modeling, trained via a dual self-supervised objective. A key feature is the natural modeling of temporal attention decay: surprise is high at event onset but diminishes as the listener adapts. Experiments on the AVTrack360 dataset show that integrating audio surprise with visual cues reduces bitrate waste by up to 18% compared to visual-only methods.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u5b66\u4e60\u6846\u67b6\u68c0\u6d4b\u97f3\u9891\"\u60ca\u559c\"\u4e8b\u4ef6\uff0c\u7ed3\u5408\u89c6\u89c9\u7ebf\u7d22\u63d0\u5347360\u5ea6\u89c6\u9891\u89c6\u53e3\u9884\u6d4b\uff0c\u51cf\u5c11\u6bd4\u7279\u7387\u6d6a\u8d3918%", "motivation": "\u5f53\u524d360\u5ea6\u89c6\u9891\u81ea\u9002\u5e94\u6d41\u5a92\u4f53\u4e3b\u8981\u4f9d\u8d56\u89c6\u89c9\u663e\u8457\u6027\u6216\u5386\u53f2\u6ce8\u89c6\u6a21\u5f0f\uff0c\u5ffd\u7565\u4e86\u7a7a\u95f4\u97f3\u9891\u5728\u5f15\u5bfc\u7528\u6237\u6ce8\u610f\u529b\u65b9\u9762\u7684\u4f5c\u7528\u3002\u97f3\u9891\u4e2d\u7684\"\u60ca\u559c\"\u4e8b\u4ef6\uff08\u504f\u79bb\u65f6\u95f4\u9884\u671f\u7684\u65f6\u523b\uff09\u53ef\u80fd\u5bf9\u9884\u6d4b\u7528\u6237\u89c6\u53e3\u6709\u91cd\u8981\u4ef7\u503c\u3002", "method": "\u91c7\u7528\u81ea\u5b66\u4e60\u6846\u67b6\u68c0\u6d4b\u97f3\u9891\u60ca\u559c\u4e8b\u4ef6\uff0c\u7ed3\u5408SE(3)-\u7b49\u53d8\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u5faa\u73af\u65f6\u95f4\u5efa\u6a21\uff0c\u901a\u8fc7\u53cc\u91cd\u81ea\u76d1\u7763\u76ee\u6807\u8bad\u7ec3\u3002\u5173\u952e\u7279\u6027\u662f\u81ea\u7136\u5efa\u6a21\u65f6\u95f4\u6ce8\u610f\u529b\u8870\u51cf\uff1a\u4e8b\u4ef6\u5f00\u59cb\u65f6\u60ca\u559c\u5ea6\u9ad8\uff0c\u968f\u7740\u542c\u4f17\u9002\u5e94\u800c\u51cf\u5f31\u3002", "result": "\u5728AVTrack360\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5c06\u97f3\u9891\u60ca\u559c\u4e0e\u89c6\u89c9\u7ebf\u7d22\u7ed3\u5408\uff0c\u76f8\u6bd4\u7eaf\u89c6\u89c9\u65b9\u6cd5\u53ef\u51cf\u5c11\u6bd4\u7279\u7387\u6d6a\u8d39\u9ad8\u8fbe18%\u3002", "conclusion": "\u7a7a\u95f4\u97f3\u9891\u4e2d\u7684\u60ca\u559c\u4e8b\u4ef6\u662f\u9884\u6d4b360\u5ea6\u89c6\u9891\u89c6\u53e3\u7684\u91cd\u8981\u7ebf\u7d22\uff0c\u6574\u5408\u97f3\u9891\u548c\u89c6\u89c9\u4fe1\u606f\u80fd\u663e\u8457\u63d0\u5347\u81ea\u9002\u5e94\u6d41\u5a92\u4f53\u7684\u5e26\u5bbd\u5206\u914d\u6548\u7387\u3002"}}
{"id": "2601.02390", "categories": ["cs.IT", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.02390", "abs": "https://arxiv.org/abs/2601.02390", "authors": ["Alex Thornton", "Ian Halliday", "Harry Saxton", "Xu Xu"], "title": "Breaking Rank -- A Novel Unscented Kalman Filter for Parameter Estimations of a Lumped-Parameter Cardiovascular Model", "comment": null, "summary": "We make modifications to the unscented Kalman filter (UKF) which bestow almost complete practical identifiability upon a lumped-parameter cardiovascular model with 10 parameters and 4 output observables - a highly non-linear, stiff problem of clinical significance. The modifications overcome the challenging problems of rank deficiency when applying the UKF to parameter estimation. Rank deficiency usually means only a small subset of parameters can be estimated. Traditionally, pragmatic compromises are made, such as selecting an optimal subset of parameters for estimation and fixing non-influential parameters. Kalman filters are typically used for dynamical state tracking, to facilitate the control u at every time step. However, for the purpose of parameter estimation, this constraint no longer applies. Our modification has transformed the utility of UKF for the parameter estimation purpose, including minimally influential parameters, with excellent robustness (i.e., under severe noise corruption, challenging patho-physiology, and no prior knowledge of parameter distributions). The modified UKF algorithm is robust in recovering almost all parameters to over 98% accuracy, over 90% of the time, with a challenging target data set of 50, 10-parameter samples. We compare this to the original implementation of the UKF algorithm for parameter estimation and demonstrate a significant improvement.", "AI": {"tldr": "\u63d0\u51fa\u6539\u8fdb\u7684UKF\u7b97\u6cd5\uff0c\u89e3\u51b3\u5fc3\u8840\u7ba1\u6a21\u578b\u53c2\u6570\u4f30\u8ba1\u4e2d\u7684\u79e9\u4e8f\u95ee\u9898\uff0c\u5b9e\u73b010\u4e2a\u53c2\u6570\u7684\u9ad8\u7cbe\u5ea6\u4f30\u8ba1", "motivation": "\u4f20\u7edfUKF\u5728\u53c2\u6570\u4f30\u8ba1\u4e2d\u5b58\u5728\u79e9\u4e8f\u95ee\u9898\uff0c\u53ea\u80fd\u4f30\u8ba1\u5c11\u91cf\u53c2\u6570\uff0c\u9700\u8981\u56fa\u5b9a\u975e\u5173\u952e\u53c2\u6570\uff0c\u9650\u5236\u4e86\u5fc3\u8840\u7ba1\u6a21\u578b\u53c2\u6570\u4f30\u8ba1\u7684\u4e34\u5e8a\u5e94\u7528", "method": "\u5bf9UKF\u8fdb\u884c\u6539\u8fdb\uff0c\u514b\u670d\u79e9\u4e8f\u95ee\u9898\uff0c\u4f7f\u7b97\u6cd5\u80fd\u591f\u540c\u65f6\u4f30\u8ba1\u6240\u6709\u53c2\u6570\uff0c\u5305\u62ec\u5f71\u54cd\u8f83\u5c0f\u7684\u53c2\u6570\uff0c\u65e0\u9700\u5148\u9a8c\u53c2\u6570\u5206\u5e03\u77e5\u8bc6", "result": "\u6539\u8fdb\u7684UKF\u572850\u4e2a10\u53c2\u6570\u6837\u672c\u7684\u6311\u6218\u6027\u6570\u636e\u96c6\u4e0a\uff0c90%\u60c5\u51b5\u4e0b\u80fd\u6062\u590d98%\u4ee5\u4e0a\u7cbe\u5ea6\u7684\u51e0\u4e4e\u6240\u6709\u53c2\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u539f\u59cbUKF", "conclusion": "\u6539\u8fdb\u7684UKF\u6781\u5927\u63d0\u5347\u4e86\u53c2\u6570\u4f30\u8ba1\u7684\u5b9e\u7528\u6027\uff0c\u5b9e\u73b0\u4e86\u5fc3\u8840\u7ba1\u6a21\u578b\u51e0\u4e4e\u6240\u6709\u53c2\u6570\u7684\u5b8c\u5168\u53ef\u8bc6\u522b\u6027\uff0c\u5177\u6709\u4f18\u5f02\u7684\u9c81\u68d2\u6027"}}
{"id": "2601.02361", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02361", "abs": "https://arxiv.org/abs/2601.02361", "authors": ["Ziheng Ni", "Congcong Liu", "Cai Shang", "Yiming Sun", "Junjie Li", "Zhiwei Fang", "Guangpeng Chen", "Jian Li", "Zehua Zhang", "Changping Peng", "Zhangang Lin", "Ching Law", "Jingping Shao"], "title": "GCRank: A Generative Contextual Comprehension Paradigm for Takeout Ranking Model", "comment": null, "summary": "The ranking stage serves as the central optimization and allocation hub in advertising systems, governing economic value distribution through eCPM and orchestrating the user-centric blending of organic and advertising content. Prevailing ranking models often rely on fragmented modules and hand-crafted features, limiting their ability to interpret complex user intent. This challenge is further amplified in location-based services such as food delivery, where user decisions are shaped by dynamic spatial, temporal, and individual contexts. To address these limitations, we propose a novel generative framework that reframes ranking as a context comprehension task, modeling heterogeneous signals in a unified architecture. Our architecture consists of two core components: the Generative Contextual Encoder (GCE) and the Generative Contextual Fusion (GCF). The GCE comprises three specialized modules: a Personalized Context Enhancer (PCE) for user-specific modeling, a Collective Context Enhancer (CCE) for group-level patterns, and a Dynamic Context Enhancer (DCE) for real-time situational adaptation. The GCF module then seamlessly integrates these contextual representations through low-rank adaptation. Extensive experiments confirm that our method achieves significant gains in critical business metrics, including click-through rate and platform revenue. We have successfully deployed our method on a large-scale food delivery advertising platform, demonstrating its substantial practical impact. This work pioneers a new perspective on generative recommendation and highlights its practical potential in industrial advertising systems.", "AI": {"tldr": "\u63d0\u51fa\u751f\u6210\u5f0f\u4e0a\u4e0b\u6587\u7406\u89e3\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u67b6\u6784\u5efa\u6a21\u5f02\u6784\u4fe1\u53f7\uff0c\u89e3\u51b3\u5e7f\u544a\u6392\u5e8f\u4e2d\u7528\u6237\u610f\u56fe\u7406\u89e3\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5728\u98df\u54c1\u914d\u9001\u5e7f\u544a\u5e73\u53f0\u53d6\u5f97\u663e\u8457\u6548\u679c\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u5e7f\u544a\u6392\u5e8f\u6a21\u578b\u4f9d\u8d56\u788e\u7247\u5316\u6a21\u5757\u548c\u624b\u5de5\u7279\u5f81\uff0c\u96be\u4ee5\u7406\u89e3\u590d\u6742\u7528\u6237\u610f\u56fe\uff0c\u7279\u522b\u662f\u5728\u98df\u54c1\u914d\u9001\u7b49\u4f4d\u7f6e\u670d\u52a1\u4e2d\uff0c\u7528\u6237\u51b3\u7b56\u53d7\u52a8\u6001\u7a7a\u95f4\u3001\u65f6\u95f4\u548c\u4e2a\u4f53\u4e0a\u4e0b\u6587\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u751f\u6210\u5f0f\u6846\u67b6\uff0c\u5c06\u6392\u5e8f\u91cd\u6784\u4e3a\u4e0a\u4e0b\u6587\u7406\u89e3\u4efb\u52a1\uff0c\u5305\u542b\u751f\u6210\u5f0f\u4e0a\u4e0b\u6587\u7f16\u7801\u5668(GCE)\u548c\u751f\u6210\u5f0f\u4e0a\u4e0b\u6587\u878d\u5408(GCF)\u3002GCE\u5305\u542b\u4e2a\u6027\u5316\u4e0a\u4e0b\u6587\u589e\u5f3a\u5668(PCE)\u3001\u96c6\u4f53\u4e0a\u4e0b\u6587\u589e\u5f3a\u5668(CCE)\u548c\u52a8\u6001\u4e0a\u4e0b\u6587\u589e\u5f3a\u5668(DCE)\uff0cGCF\u901a\u8fc7\u4f4e\u79e9\u9002\u914d\u65e0\u7f1d\u96c6\u6210\u8fd9\u4e9b\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5173\u952e\u4e1a\u52a1\u6307\u6807\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u5305\u62ec\u70b9\u51fb\u7387\u548c\u5e73\u53f0\u6536\u5165\uff0c\u5df2\u6210\u529f\u90e8\u7f72\u5728\u5927\u578b\u98df\u54c1\u914d\u9001\u5e7f\u544a\u5e73\u53f0\uff0c\u5c55\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5f00\u521b\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u7684\u65b0\u89c6\u89d2\uff0c\u7a81\u51fa\u4e86\u5176\u5728\u5de5\u4e1a\u5e7f\u544a\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u6f5c\u529b\uff0c\u901a\u8fc7\u7edf\u4e00\u67b6\u6784\u5efa\u6a21\u5f02\u6784\u4fe1\u53f7\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5e7f\u544a\u6392\u5e8f\u4e2d\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u6311\u6218\u3002"}}
{"id": "2601.03229", "categories": ["cs.DB", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.03229", "abs": "https://arxiv.org/abs/2601.03229", "authors": ["Tianqi Zhang", "Flavio Ponzina", "Tajana Rosing"], "title": "SpANNS: Optimizing Approximate Nearest Neighbor Search for Sparse Vectors Using Near Memory Processing", "comment": null, "summary": "Approximate Nearest Neighbor Search (ANNS) is a fundamental operation in vector databases, enabling efficient similarity search in high-dimensional spaces. While dense ANNS has been optimized using specialized hardware accelerators, sparse ANNS remains limited by CPU-based implementations, hindering scalability. This limitation is increasingly critical as hybrid retrieval systems, combining sparse and dense embeddings, become standard in Information Retrieval (IR) pipelines. We propose SpANNS, a near-memory processing architecture for sparse ANNS. SpANNS combines a hybrid inverted index with efficient query management and runtime optimizations. The architecture is built on a CXL Type-2 near-memory platform, where a specialized controller manages query parsing and cluster filtering, while compute-enabled DIMMs perform index traversal and distance computations close to the data. It achieves 15.2x to 21.6x faster execution over the state-of-the-art CPU baselines, offering scalable and efficient solutions for sparse vector search.", "AI": {"tldr": "SpANNS\u662f\u4e00\u4e2a\u57fa\u4e8eCXL Type-2\u8fd1\u5185\u5b58\u5904\u7406\u67b6\u6784\u7684\u7a00\u758f\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7cfb\u7edf\uff0c\u901a\u8fc7\u6df7\u5408\u5012\u6392\u7d22\u5f15\u548c\u67e5\u8be2\u4f18\u5316\uff0c\u76f8\u6bd4CPU\u57fa\u7ebf\u5b9e\u73b015.2-21.6\u500d\u7684\u52a0\u901f\u3002", "motivation": "\u7a00\u758f\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\uff08ANNS\uff09\u76ee\u524d\u53d7\u9650\u4e8eCPU\u5b9e\u73b0\uff0c\u800c\u5bc6\u96c6ANNS\u5df2\u6709\u4e13\u7528\u786c\u4ef6\u52a0\u901f\u3002\u968f\u7740\u6df7\u5408\u68c0\u7d22\u7cfb\u7edf\uff08\u7ed3\u5408\u7a00\u758f\u548c\u5bc6\u96c6\u5d4c\u5165\uff09\u6210\u4e3a\u4fe1\u606f\u68c0\u7d22\u6807\u51c6\uff0c\u7a00\u758fANNS\u7684\u6027\u80fd\u74f6\u9888\u65e5\u76ca\u4e25\u91cd\uff0c\u9700\u8981\u786c\u4ef6\u52a0\u901f\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faSpANNS\u8fd1\u5185\u5b58\u5904\u7406\u67b6\u6784\uff0c\u57fa\u4e8eCXL Type-2\u5e73\u53f0\u6784\u5efa\u3002\u91c7\u7528\u6df7\u5408\u5012\u6392\u7d22\u5f15\uff0c\u4e13\u7528\u63a7\u5236\u5668\u5904\u7406\u67e5\u8be2\u89e3\u6790\u548c\u805a\u7c7b\u8fc7\u6ee4\uff0c\u8ba1\u7b97\u4f7f\u80fd\u7684DIMM\u5728\u6570\u636e\u9644\u8fd1\u6267\u884c\u7d22\u5f15\u904d\u5386\u548c\u8ddd\u79bb\u8ba1\u7b97\uff0c\u7ed3\u5408\u9ad8\u6548\u7684\u67e5\u8be2\u7ba1\u7406\u548c\u8fd0\u884c\u65f6\u4f18\u5316\u3002", "result": "SpANNS\u76f8\u6bd4\u6700\u5148\u8fdb\u7684CPU\u57fa\u7ebf\u5b9e\u73b0\u4e8615.2\u500d\u523021.6\u500d\u7684\u6267\u884c\u901f\u5ea6\u63d0\u5347\uff0c\u4e3a\u7a00\u758f\u5411\u91cf\u641c\u7d22\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "SpANNS\u901a\u8fc7\u8fd1\u5185\u5b58\u5904\u7406\u67b6\u6784\u6210\u529f\u89e3\u51b3\u4e86\u7a00\u758fANNS\u7684\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u6df7\u5408\u68c0\u7d22\u7cfb\u7edf\u4e2d\u7684\u7a00\u758f\u5411\u91cf\u641c\u7d22\u63d0\u4f9b\u4e86\u786c\u4ef6\u52a0\u901f\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u641c\u7d22\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2601.02608", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.02608", "abs": "https://arxiv.org/abs/2601.02608", "authors": ["Jay A. Wood"], "title": "Weights on finite fields and failures of the MacWilliams identities", "comment": "32 pages, 1 figure", "summary": "In the 1960s, MacWilliams proved that the Hamming weight enumerator of a linear code over a finite field completely determines, and is determined by, the Hamming weight enumerator of its dual code. In particular, if two linear codes have the same Hamming weight enumerator, then their dual codes have the same Hamming weight enumerator.\n  In contrast, there is a wide class of weights on finite fields whose weight enumerators have the opposite behavior: there exist two linear codes having the same weight enumerator, but their dual codes have different weight enumerators.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u7ebf\u6027\u7801\u7684\u6743\u91cd\u679a\u4e3e\u5668\u4e0e\u5176\u5bf9\u5076\u7801\u6743\u91cd\u679a\u4e3e\u5668\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u6307\u51fa\u6c49\u660e\u6743\u91cd\u679a\u4e3e\u5668\u5177\u6709\u5bf9\u79f0\u6027\uff0c\u4f46\u5b58\u5728\u4e00\u7c7b\u6743\u91cd\u5176\u679a\u4e3e\u5668\u8868\u73b0\u51fa\u76f8\u53cd\u884c\u4e3a\u3002", "motivation": "\u7814\u7a76\u7ebf\u6027\u7801\u4e0e\u5176\u5bf9\u5076\u7801\u4e4b\u95f4\u6743\u91cd\u679a\u4e3e\u5668\u5173\u7cfb\u7684\u666e\u904d\u6027\uff0c\u63a2\u7d22MacWilliams\u5b9a\u7406\u4e4b\u5916\u7684\u7279\u6b8a\u60c5\u51b5\uff0c\u7406\u89e3\u54ea\u4e9b\u6743\u91cd\u7c7b\u578b\u4f1a\u5bfc\u81f4\u5bf9\u5076\u7801\u6743\u91cd\u679a\u4e3e\u5668\u7684\u4e0d\u5bf9\u79f0\u6027\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6784\u9020\u53cd\u4f8b\uff0c\u8bc1\u660e\u5b58\u5728\u4e00\u7c7b\u6709\u9650\u57df\u4e0a\u7684\u6743\u91cd\uff0c\u5176\u6743\u91cd\u679a\u4e3e\u5668\u4e0d\u9075\u5faaMacWilliams\u5b9a\u7406\u7684\u5bf9\u79f0\u6027\uff0c\u5373\u4e24\u4e2a\u5177\u6709\u76f8\u540c\u6743\u91cd\u679a\u4e3e\u5668\u7684\u7ebf\u6027\u7801\uff0c\u5b83\u4eec\u7684\u5bf9\u5076\u7801\u5374\u6709\u4e0d\u540c\u7684\u6743\u91cd\u679a\u4e3e\u5668\u3002", "result": "\u53d1\u73b0\u5e76\u8bc1\u660e\u5b58\u5728\u4e00\u7c7b\u6743\u91cd\uff0c\u5176\u6743\u91cd\u679a\u4e3e\u5668\u8868\u73b0\u51fa\u4e0e\u6c49\u660e\u6743\u91cd\u679a\u4e3e\u5668\u76f8\u53cd\u7684\u884c\u4e3a\uff1a\u4e24\u4e2a\u7ebf\u6027\u7801\u53ef\u4ee5\u6709\u76f8\u540c\u7684\u6743\u91cd\u679a\u4e3e\u5668\uff0c\u4f46\u5b83\u4eec\u7684\u5bf9\u5076\u7801\u5374\u6709\u4e0d\u540c\u7684\u6743\u91cd\u679a\u4e3e\u5668\u3002", "conclusion": "MacWilliams\u5b9a\u7406\u4e2d\u6c49\u660e\u6743\u91cd\u679a\u4e3e\u5668\u7684\u5bf9\u79f0\u6027\u4e0d\u662f\u666e\u904d\u6027\u8d28\uff0c\u5b58\u5728\u4e00\u7c7b\u6743\u91cd\u5176\u679a\u4e3e\u5668\u5173\u7cfb\u8868\u73b0\u51fa\u76f8\u53cd\u884c\u4e3a\uff0c\u8fd9\u6269\u5c55\u4e86\u5bf9\u7ebf\u6027\u7801\u6743\u91cd\u679a\u4e3e\u5668\u7406\u8bba\u7684\u7406\u89e3\u3002"}}
{"id": "2601.02362", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02362", "abs": "https://arxiv.org/abs/2601.02362", "authors": ["Itzhak Ziv", "Moshe Unger", "Hilah Geva"], "title": "The Impact of LLM-Generated Reviews on Recommender Systems: Textual Shifts, Performance Effects, and Strategic Platform Control", "comment": null, "summary": "The rise of generative AI technologies is reshaping content-based recommender systems (RSes), which increasingly encounter AI-generated content alongside human-authored content. This study examines how the introduction of AI-generated reviews influences RS performance and business outcomes. We analyze two distinct pathways through which AI content can enter RSes: user-centric, in which individuals use AI tools to refine their reviews, and platform-centric, in which platforms generate synthetic reviews directly from structured metadata. Using a large-scale dataset of hotel reviews from TripAdvisor, we generate synthetic reviews using LLMs and evaluate their impact across the training and deployment phases of RSes. We find that AI-generated reviews differ systematically from human-authored reviews across multiple textual dimensions. Although both user- and platform-centric AI reviews enhance RS performance relative to models without textual data, models trained on human reviews consistently achieve superior performance, underscoring the quality of authentic human data. Human-trained models generalize robustly to AI content, whereas AI-trained models underperform on both content types. Furthermore, tone-based framing strategies (encouraging, constructive, or critical) substantially enhance platform-generated review effectiveness. Our findings highlight the strategic importance of platform control in governing the generation and integration of AI-generated reviews, ensuring that synthetic content complements recommendation robustness and sustainable business value.", "AI": {"tldr": "\u7814\u7a76AI\u751f\u6210\u8bc4\u8bba\u5bf9\u63a8\u8350\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4eba\u7c7b\u8bc4\u8bba\u8d28\u91cf\u66f4\u9ad8\uff0c\u5e73\u53f0\u63a7\u5236AI\u5185\u5bb9\u751f\u6210\u7b56\u7565\u5f88\u91cd\u8981", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u6280\u672f\u7684\u53d1\u5c55\uff0c\u63a8\u8350\u7cfb\u7edf\u9762\u4e34AI\u751f\u6210\u5185\u5bb9\u4e0e\u4eba\u7c7b\u521b\u4f5c\u5185\u5bb9\u5e76\u5b58\u7684\u65b0\u73af\u5883\uff0c\u9700\u8981\u7814\u7a76AI\u5185\u5bb9\u5982\u4f55\u5f71\u54cd\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u548c\u5546\u4e1a\u7ed3\u679c", "method": "\u4f7f\u7528TripAdvisor\u9152\u5e97\u8bc4\u8bba\u6570\u636e\u96c6\uff0c\u901a\u8fc7LLM\u751f\u6210\u5408\u6210\u8bc4\u8bba\uff0c\u5206\u6790\u7528\u6237\u4e2d\u5fc3\uff08\u7528\u6237\u7528AI\u4f18\u5316\u8bc4\u8bba\uff09\u548c\u5e73\u53f0\u4e2d\u5fc3\uff08\u5e73\u53f0\u4ece\u7ed3\u6784\u5316\u5143\u6570\u636e\u751f\u6210\u8bc4\u8bba\uff09\u4e24\u79cdAI\u5185\u5bb9\u5f15\u5165\u8def\u5f84\uff0c\u8bc4\u4f30\u5176\u5bf9\u63a8\u8350\u7cfb\u7edf\u8bad\u7ec3\u548c\u90e8\u7f72\u9636\u6bb5\u7684\u5f71\u54cd", "result": "AI\u751f\u6210\u8bc4\u8bba\u5728\u591a\u4e2a\u6587\u672c\u7ef4\u5ea6\u4e0a\u4e0e\u4eba\u7c7b\u8bc4\u8bba\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff1b\u867d\u7136AI\u8bc4\u8bba\u76f8\u6bd4\u65e0\u6587\u672c\u6570\u636e\u7684\u6a21\u578b\u80fd\u63d0\u5347\u63a8\u8350\u6027\u80fd\uff0c\u4f46\u4eba\u7c7b\u8bc4\u8bba\u8bad\u7ec3\u7684\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff1b\u4eba\u7c7b\u8bad\u7ec3\u6a21\u578b\u80fd\u5f88\u597d\u6cdb\u5316\u5230AI\u5185\u5bb9\uff0c\u800cAI\u8bad\u7ec3\u6a21\u578b\u5728\u4e24\u79cd\u5185\u5bb9\u4e0a\u90fd\u8868\u73b0\u4e0d\u4f73\uff1b\u57fa\u4e8e\u8bed\u6c14\u7684\u6846\u67b6\u7b56\u7565\uff08\u9f13\u52b1\u6027\u3001\u5efa\u8bbe\u6027\u3001\u6279\u5224\u6027\uff09\u80fd\u663e\u8457\u63d0\u5347\u5e73\u53f0\u751f\u6210\u8bc4\u8bba\u7684\u6548\u679c", "conclusion": "\u5e73\u53f0\u5728\u63a7\u5236AI\u751f\u6210\u8bc4\u8bba\u7684\u751f\u6210\u548c\u6574\u5408\u65b9\u9762\u5177\u6709\u6218\u7565\u91cd\u8981\u6027\uff0c\u9700\u8981\u786e\u4fdd\u5408\u6210\u5185\u5bb9\u80fd\u591f\u8865\u5145\u63a8\u8350\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u53ef\u6301\u7eed\u5546\u4e1a\u4ef7\u503c"}}
{"id": "2601.02802", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.02802", "abs": "https://arxiv.org/abs/2601.02802", "authors": ["Viswanathan Ramachandran"], "title": "State-Dependent Fading Gaussian Channel with Common Reconstruction Constraints", "comment": null, "summary": "The task of jointly communicating a message and reconstructing a common estimate of the channel state is examined for a fading Gaussian model with additive state interference. The state is an independent and identically distributed Gaussian sequence known noncausally at the transmitter, and the instantaneous fading coefficient is perfectly known at both the transmitter and the receiver. The receiver is required to decode the transmitted message and, in addition, reconstruct the state under a common reconstruction constraint ensuring that its estimate coincides with that at the transmitter. A complete characterization of the optimal rate distortion tradeoff region for this setting is the main result of our work. The analytical results are also validated through numerical examples illustrating the rate distortion and power distortion tradeoffs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u9ad8\u65af\u8870\u843d\u4fe1\u9053\u4e2d\u540c\u65f6\u4f20\u8f93\u6d88\u606f\u548c\u8054\u5408\u91cd\u6784\u4fe1\u9053\u72b6\u6001\u7684\u901a\u4fe1\u95ee\u9898\uff0c\u5176\u4e2d\u72b6\u6001\u5e72\u6270\u5df2\u77e5\u4e8e\u53d1\u9001\u7aef\uff0c\u8870\u843d\u7cfb\u6570\u5b8c\u5168\u5df2\u77e5\u4e8e\u6536\u53d1\u53cc\u65b9\uff0c\u63a5\u6536\u7aef\u9700\u89e3\u7801\u6d88\u606f\u5e76\u5728\u5171\u540c\u91cd\u6784\u7ea6\u675f\u4e0b\u4f30\u8ba1\u72b6\u6001\uff0c\u7ed9\u51fa\u4e86\u6700\u4f18\u7387\u5931\u771f\u6743\u8861\u533a\u57df\u7684\u5b8c\u6574\u8868\u5f81\u3002", "motivation": "\u7814\u7a76\u5728\u8870\u843d\u9ad8\u65af\u4fe1\u9053\u4e2d\u540c\u65f6\u5b9e\u73b0\u6d88\u606f\u4f20\u8f93\u548c\u4fe1\u9053\u72b6\u6001\u8054\u5408\u91cd\u6784\u7684\u95ee\u9898\u3002\u4f20\u7edf\u901a\u4fe1\u7cfb\u7edf\u4e3b\u8981\u5173\u6ce8\u6d88\u606f\u4f20\u8f93\uff0c\u4f46\u5728\u8bb8\u591a\u5b9e\u9645\u573a\u666f\u4e2d\uff08\u5982\u4f20\u611f\u901a\u4fe1\u3001\u72b6\u6001\u4f30\u8ba1\u7b49\uff09\uff0c\u63a5\u6536\u7aef\u4e0d\u4ec5\u9700\u8981\u89e3\u7801\u6d88\u606f\uff0c\u8fd8\u9700\u8981\u51c6\u786e\u4f30\u8ba1\u4fe1\u9053\u72b6\u6001\u3002\u672c\u6587\u8003\u8651\u53d1\u9001\u7aef\u975e\u56e0\u679c\u5df2\u77e5\u72b6\u6001\u5e72\u6270\u3001\u6536\u53d1\u53cc\u65b9\u5b8c\u5168\u5df2\u77e5\u77ac\u65f6\u8870\u843d\u7cfb\u6570\u7684\u573a\u666f\uff0c\u63a2\u7d22\u6d88\u606f\u4f20\u8f93\u4e0e\u72b6\u6001\u4f30\u8ba1\u4e4b\u95f4\u7684\u6700\u4f18\u6743\u8861\u3002", "method": "\u91c7\u7528\u4fe1\u606f\u8bba\u65b9\u6cd5\u5206\u6790\u9ad8\u65af\u8870\u843d\u6a21\u578b\uff0c\u5176\u4e2d\u72b6\u6001\u4e3a\u72ec\u7acb\u540c\u5206\u5e03\u9ad8\u65af\u5e8f\u5217\uff0c\u72b6\u6001\u5e72\u6270\u975e\u56e0\u679c\u5df2\u77e5\u4e8e\u53d1\u9001\u7aef\uff0c\u77ac\u65f6\u8870\u843d\u7cfb\u6570\u5b8c\u7f8e\u5df2\u77e5\u4e8e\u6536\u53d1\u53cc\u65b9\u3002\u63a5\u6536\u7aef\u9700\u89e3\u7801\u4f20\u8f93\u6d88\u606f\u5e76\u5728\u5171\u540c\u91cd\u6784\u7ea6\u675f\u4e0b\u4f30\u8ba1\u72b6\u6001\uff0c\u786e\u4fdd\u5176\u4f30\u8ba1\u4e0e\u53d1\u9001\u7aef\u4e00\u81f4\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u63a8\u5bfc\u6700\u4f18\u7387\u5931\u771f\u6743\u8861\u533a\u57df\u3002", "result": "\u5b8c\u6574\u8868\u5f81\u4e86\u8be5\u573a\u666f\u4e0b\u7684\u6700\u4f18\u7387\u5931\u771f\u6743\u8861\u533a\u57df\uff0c\u8fd9\u662f\u672c\u6587\u7684\u4e3b\u8981\u7406\u8bba\u8d21\u732e\u3002\u901a\u8fc7\u6570\u503c\u793a\u4f8b\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\uff0c\u5c55\u793a\u4e86\u7387\u5931\u771f\u548c\u529f\u7387\u5931\u771f\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u89e3\u51b3\u4e86\u8870\u843d\u9ad8\u65af\u4fe1\u9053\u4e2d\u6d88\u606f\u4f20\u8f93\u4e0e\u72b6\u6001\u8054\u5408\u91cd\u6784\u7684\u4f18\u5316\u95ee\u9898\uff0c\u7ed9\u51fa\u4e86\u6700\u4f18\u7387\u5931\u771f\u6743\u8861\u533a\u57df\u7684\u5b8c\u6574\u7406\u8bba\u8868\u5f81\uff0c\u4e3a\u540c\u65f6\u5b9e\u73b0\u53ef\u9760\u901a\u4fe1\u548c\u51c6\u786e\u72b6\u6001\u4f30\u8ba1\u7684\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.02364", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02364", "abs": "https://arxiv.org/abs/2601.02364", "authors": ["Chung Park", "Taesan Kim", "Hyeongjun Yun", "Dongjoon Hong", "Junui Hong", "Kijung Park", "MinCheol Cho", "Mira Myong", "Jihoon Oh", "Min sung Choi"], "title": "Towards Trustworthy LLM-Based Recommendation via Rationale Integration", "comment": "Accepted at RS4SD'25 (CIKM'25 Workshop)", "summary": "Traditional recommender systems (RS) have been primarily optimized for accuracy and short-term engagement, often overlooking transparency and trustworthiness. Recently, platforms such as Amazon and Instagram have begun providing recommendation rationales to users, acknowledging their critical role in fostering trust and enhancing engagement; however, most existing systems still treat them as post-hoc artifacts. We propose an LLM-based recommender (LLM-Rec) that not only predicts items but also generates logically grounded rationales. Our approach leverages a self-annotated rationale dataset and instruction tuning in a rationale-first format, where the model generates an explanation before outputting the recommended item. By adopting this strategy and representing rationales in a chain-of-thought (CoT) style, LLM-Rec strengthens both interpretability and recommendation performance. Experiments on the Fashion and Scientific domains of the Amazon Review dataset demonstrate significant improvements over well-established baselines. To encourage reproducibility and future research, we publicly release a rationale-augmented recommendation dataset containing user histories, rationales, and recommended items.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u63a8\u8350\u7cfb\u7edfLLM-Rec\uff0c\u901a\u8fc7\u751f\u6210\u903b\u8f91\u5408\u7406\u7684\u63a8\u8350\u7406\u7531\u6765\u63d0\u5347\u900f\u660e\u5ea6\u548c\u63a8\u8350\u6027\u80fd\uff0c\u91c7\u7528\u7406\u7531\u4f18\u5148\u7684\u6307\u4ee4\u8c03\u4f18\u7b56\u7565", "motivation": "\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u8fc7\u5ea6\u5173\u6ce8\u51c6\u786e\u6027\u548c\u77ed\u671f\u53c2\u4e0e\u5ea6\uff0c\u5ffd\u89c6\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u3002\u867d\u7136\u4e9a\u9a6c\u900a\u548cInstagram\u7b49\u5e73\u53f0\u5f00\u59cb\u63d0\u4f9b\u63a8\u8350\u7406\u7531\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u5927\u591a\u5c06\u5176\u89c6\u4e3a\u4e8b\u540e\u4ea7\u7269\uff0c\u7f3a\u4e4f\u4e0e\u63a8\u8350\u8fc7\u7a0b\u7684\u6df1\u5ea6\u878d\u5408", "method": "\u63d0\u51faLLM-Rec\u7cfb\u7edf\uff0c\u91c7\u7528\u81ea\u6807\u6ce8\u7406\u7531\u6570\u636e\u96c6\u548c\u7406\u7531\u4f18\u5148\u7684\u6307\u4ee4\u8c03\u4f18\u683c\u5f0f\uff0c\u6a21\u578b\u5148\u751f\u6210\u89e3\u91ca\u518d\u8f93\u51fa\u63a8\u8350\u9879\u76ee\uff0c\u5e76\u4f7f\u7528\u601d\u7ef4\u94fe\u98ce\u683c\u8868\u793a\u7406\u7531", "result": "\u5728Amazon Review\u6570\u636e\u96c6\u7684\u65f6\u5c1a\u548c\u79d1\u5b66\u9886\u57df\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u540c\u65f6\u516c\u5f00\u53d1\u5e03\u4e86\u5305\u542b\u7528\u6237\u5386\u53f2\u3001\u7406\u7531\u548c\u63a8\u8350\u9879\u76ee\u7684\u589e\u5f3a\u6570\u636e\u96c6", "conclusion": "LLM-Rec\u901a\u8fc7\u751f\u6210\u903b\u8f91\u5408\u7406\u7684\u63a8\u8350\u7406\u7531\uff0c\u540c\u65f6\u589e\u5f3a\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u548c\u63a8\u8350\u6027\u80fd\uff0c\u4e3a\u53ef\u89e3\u91ca\u63a8\u8350\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411"}}
{"id": "2601.02822", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.02822", "abs": "https://arxiv.org/abs/2601.02822", "authors": ["Jianhang Zhu", "Tsung-Hui Chang", "Liyao Xiang", "Kaiming Shen"], "title": "DeepFP: Deep-Unfolded Fractional Programming for MIMO Beamforming", "comment": null, "summary": "This work proposes a mixed learning-based and optimization-based approach to the weighted-sum-rates beamforming problem in a multiple-input multiple-output (MIMO) wireless network. The conventional methods, i.e., the fractional programming (FP) method and the weighted minimum mean square error (WMMSE) algorithm, can be computationally demanding for two reasons: (i) they require inverting a sequence of matrices whose sizes are proportional to the number of antennas; (ii) they require tuning a set of Lagrange multipliers to account for the power constraints. The recently proposed method called the reduced WMMSE addresses the above two issues for a single cell. In contrast, for the multicell case, another recent method called the FastFP eliminates the large matrix inversion and the Lagrange multipliers by using an improved FP technique, but the update stepsize in the FastFP can be difficult to decide. As such, we propose integrating the deep unfolding network into the FastFP for the stepsize optimization. Numerical experiments show that the proposed method is much more efficient than the learning method based on the WMMSE algorithm.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u5b66\u4e60\u548c\u4f18\u5316\u7684\u65b9\u6cd5\u6765\u89e3\u51b3MIMO\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u52a0\u6743\u548c\u901f\u7387\u6ce2\u675f\u6210\u5f62\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u6df1\u5ea6\u5c55\u5f00\u7f51\u7edc\u96c6\u6210\u5230FastFP\u7b97\u6cd5\u4e2d\u8fdb\u884c\u6b65\u957f\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\uff08\u5982FP\u548cWMMSE\uff09\u8ba1\u7b97\u91cf\u5927\uff0c\u9700\u8981\u5927\u77e9\u9635\u6c42\u9006\u548c\u62c9\u683c\u6717\u65e5\u4e58\u5b50\u8c03\u4f18\u3002FastFP\u65b9\u6cd5\u6d88\u9664\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u6b65\u957f\u9009\u62e9\u56f0\u96be\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u6df1\u5ea6\u5c55\u5f00\u7f51\u7edc\u96c6\u6210\u5230FastFP\u7b97\u6cd5\u4e2d\uff0c\u7528\u4e8e\u4f18\u5316\u66f4\u65b0\u6b65\u957f\uff0c\u5f62\u6210\u6df7\u5408\u5b66\u4e60\u548c\u4f18\u5316\u7684\u65b9\u6cd5\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u6bd4\u57fa\u4e8eWMMSE\u7b97\u6cd5\u7684\u5b66\u4e60\u65b9\u6cd5\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u5c0f\u533aMIMO\u7f51\u7edc\u4e2d\u52a0\u6743\u548c\u901f\u7387\u6ce2\u675f\u6210\u5f62\u95ee\u9898\uff0c\u901a\u8fc7\u6df1\u5ea6\u5c55\u5f00\u7f51\u7edc\u4f18\u5316FastFP\u6b65\u957f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2601.02365", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02365", "abs": "https://arxiv.org/abs/2601.02365", "authors": ["Tushar Vatsa", "Vibha Belavadi", "Priya Shanmugasundaram", "Suhas Suresha", "Dewang Sultania"], "title": "FUSE : Failure-aware Usage of Subagent Evidence for MultiModal Search and Recommendation", "comment": "ICDM MMSR 2025: Workshop on Multimodal Search and Recommendations", "summary": "Multimodal creative assistants decompose user goals and route tasks to subagents for layout, styling, retrieval, and generation. Retrieval quality is pivotal, yet failures can arise at several stages: understanding user intent, choosing content types, finding candidates (recall), or ranking results. Meanwhile, sending and processing images is costly, making naive multimodal approaches impractical. We present FUSE: Failure-aware Usage of Subagent Evidence for MultiModal Search and Recommendation. FUSE replaces most raw-image prompting with a compact Grounded Design Representation (GDR): a selection aware JSON of canvas elements (image, text, shape, icon, video, logo), structure, styles, salient colors, and user selection provided by the Planner team. FUSE implements seven context budgeting strategies: comprehensive baseline prompting, context compression, chain-of-thought reasoning, mini-shot optimization, retrieval-augmented context, two-stage processing, and zero-shot minimalism. Finally, a pipeline attribution layer monitors system performance by converting subagent signals into simple checks: intent alignment, content-type/routing sanity, recall health (e.g., zero-hit and top-match strength), and ranking displacement analysis. We evaluate the seven context budgeting variants across 788 evaluation queries from diverse users and design templates (refer Figure 3). Our systematic evaluation reveals that Context Compression achieves optimal performance across all pipeline stages, with 93.3% intent accuracy, 86.8% routing success(with fallbacks), 99.4% recall, and 88.5% NDCG@5. This approach demonstrates that strategic context summarization outperforms both comprehensive and minimal contextualization strategies.", "AI": {"tldr": "FUSE\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5931\u8d25\u611f\u77e5\u7684\u591a\u6a21\u6001\u641c\u7d22\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u7d27\u51d1\u7684GDR\u8868\u793a\u548c\u4e03\u79cd\u4e0a\u4e0b\u6587\u9884\u7b97\u7b56\u7565\u4f18\u5316\u68c0\u7d22\u8d28\u91cf\uff0c\u5176\u4e2d\u4e0a\u4e0b\u6587\u538b\u7f29\u7b56\u7565\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u591a\u6a21\u6001\u521b\u610f\u52a9\u624b\u5728\u68c0\u7d22\u8fc7\u7a0b\u4e2d\u5b58\u5728\u591a\u4e2a\u5931\u8d25\u70b9\uff08\u610f\u56fe\u7406\u89e3\u3001\u5185\u5bb9\u7c7b\u578b\u9009\u62e9\u3001\u5019\u9009\u53ec\u56de\u3001\u7ed3\u679c\u6392\u5e8f\uff09\uff0c\u540c\u65f6\u539f\u59cb\u56fe\u50cf\u5904\u7406\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "FUSE\u7cfb\u7edf\u4f7f\u7528\u7d27\u51d1\u7684GDR\u8868\u793a\u66ff\u4ee3\u539f\u59cb\u56fe\u50cf\uff0c\u5b9e\u73b0\u4e03\u79cd\u4e0a\u4e0b\u6587\u9884\u7b97\u7b56\u7565\uff08\u57fa\u7ebf\u63d0\u793a\u3001\u4e0a\u4e0b\u6587\u538b\u7f29\u3001\u601d\u7ef4\u94fe\u63a8\u7406\u3001\u5c0f\u6837\u672c\u4f18\u5316\u3001\u68c0\u7d22\u589e\u5f3a\u4e0a\u4e0b\u6587\u3001\u4e24\u9636\u6bb5\u5904\u7406\u3001\u96f6\u6837\u672c\u6700\u5c0f\u5316\uff09\uff0c\u5e76\u5efa\u7acb\u7ba1\u9053\u5f52\u56e0\u5c42\u76d1\u63a7\u7cfb\u7edf\u6027\u80fd\u3002", "result": "\u5728788\u4e2a\u8bc4\u4f30\u67e5\u8be2\u4e0a\uff0c\u4e0a\u4e0b\u6587\u538b\u7f29\u7b56\u7565\u5728\u6240\u6709\u7ba1\u9053\u9636\u6bb5\u8868\u73b0\u6700\u4f18\uff1a\u610f\u56fe\u51c6\u786e\u738793.3%\uff0c\u8def\u7531\u6210\u529f\u738786.8%\uff08\u542b\u56de\u9000\uff09\uff0c\u53ec\u56de\u738799.4%\uff0cNDCG@5\u4e3a88.5%\u3002", "conclusion": "\u7b56\u7565\u6027\u7684\u4e0a\u4e0b\u6587\u603b\u7ed3\u4f18\u4e8e\u5168\u9762\u548c\u6700\u5c0f\u5316\u7684\u4e0a\u4e0b\u6587\u7b56\u7565\uff0cFUSE\u901a\u8fc7\u7d27\u51d1\u8868\u793a\u548c\u667a\u80fd\u4e0a\u4e0b\u6587\u7ba1\u7406\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u68c0\u7d22\u4e2d\u7684\u5931\u8d25\u70b9\u548c\u6210\u672c\u95ee\u9898\u3002"}}
{"id": "2601.02855", "categories": ["cs.IT", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.02855", "abs": "https://arxiv.org/abs/2601.02855", "authors": ["Heng Zhao", "Sara Saeidian", "Tobias J. Oechtering"], "title": "Context-aware Privacy Bounds for Linear Queries", "comment": "8 pages, 4 figures, submitted to ISIT 2026", "summary": "Linear queries, as the basis of broad analysis tasks, are often released through privacy mechanisms based on differential privacy (DP), the most popular framework for privacy protection. However, DP adopts a context-free definition that operates independently of the data-generating distribution. In this paper, we revisit the privacy analysis of the Laplace mechanism through the lens of pointwise maximal leakage (PML). We demonstrate that the distribution-agnostic definition of the DP framework often mandates excessive noise. To address this, we incorporate an assumption about the prior distribution by lower-bounding the probability of any single record belonging to any specific class. With this assumption, we derive a tight, context-aware leakage bound for general linear queries, and prove that our derived bound is strictly tighter than the standard DP guarantee and converges to the DP guarantee as this probability lower bound approaches zero. Numerical evaluations demonstrate that by exploiting this prior knowledge, the required noise scale can be reduced while maintaining privacy guarantees.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u70b9\u6001\u6700\u5927\u6cc4\u6f0f(PML)\u89c6\u89d2\u91cd\u65b0\u5206\u6790\u62c9\u666e\u62c9\u65af\u673a\u5236\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u53d1\u73b0\u5dee\u5206\u9690\u79c1(DP)\u6846\u67b6\u7684\u5206\u5e03\u65e0\u5173\u5b9a\u4e49\u901a\u5e38\u5bfc\u81f4\u8fc7\u5ea6\u566a\u58f0\u6dfb\u52a0\u3002\u901a\u8fc7\u5f15\u5165\u5148\u9a8c\u5206\u5e03\u5047\u8bbe\uff0c\u4f5c\u8005\u63a8\u5bfc\u51fa\u66f4\u7d27\u81f4\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u6cc4\u6f0f\u8fb9\u754c\uff0c\u80fd\u5728\u4fdd\u6301\u9690\u79c1\u4fdd\u8bc1\u7684\u540c\u65f6\u51cf\u5c11\u6240\u9700\u566a\u58f0\u89c4\u6a21\u3002", "motivation": "\u5dee\u5206\u9690\u79c1(DP)\u4f5c\u4e3a\u6700\u6d41\u884c\u7684\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\uff0c\u91c7\u7528\u4e0e\u6570\u636e\u751f\u6210\u5206\u5e03\u65e0\u5173\u7684\u4e0a\u4e0b\u6587\u65e0\u5173\u5b9a\u4e49\u3002\u8fd9\u79cd\u5b9a\u4e49\u65b9\u5f0f\u5f80\u5f80\u8981\u6c42\u6dfb\u52a0\u8fc7\u591a\u566a\u58f0\uff0c\u5bfc\u81f4\u5206\u6790\u7ed3\u679c\u7cbe\u5ea6\u4e0b\u964d\u3002\u4f5c\u8005\u5e0c\u671b\u5229\u7528\u6570\u636e\u5148\u9a8c\u77e5\u8bc6\uff0c\u5728\u4fdd\u8bc1\u9690\u79c1\u7684\u540c\u65f6\u51cf\u5c11\u566a\u58f0\u6dfb\u52a0\u3002", "method": "\u4f5c\u8005\u4ece\u70b9\u6001\u6700\u5927\u6cc4\u6f0f(PML)\u89c6\u89d2\u91cd\u65b0\u5206\u6790\u62c9\u666e\u62c9\u65af\u673a\u5236\uff0c\u5f15\u5165\u5148\u9a8c\u5206\u5e03\u5047\u8bbe\uff08\u9650\u5b9a\u5355\u4e2a\u8bb0\u5f55\u5c5e\u4e8e\u7279\u5b9a\u7c7b\u522b\u7684\u6982\u7387\u4e0b\u754c\uff09\uff0c\u63a8\u5bfc\u51fa\u9002\u7528\u4e8e\u4e00\u822c\u7ebf\u6027\u67e5\u8be2\u7684\u7d27\u81f4\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u6cc4\u6f0f\u8fb9\u754c\uff0c\u5e76\u8bc1\u660e\u8be5\u8fb9\u754c\u4e25\u683c\u4f18\u4e8e\u6807\u51c6DP\u4fdd\u8bc1\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u63a8\u5bfc\u51fa\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u6cc4\u6f0f\u8fb9\u754c\u4e25\u683c\u4f18\u4e8e\u6807\u51c6DP\u4fdd\u8bc1\uff0c\u4e14\u5f53\u6982\u7387\u4e0b\u754c\u8d8b\u8fd1\u4e8e\u96f6\u65f6\u6536\u655b\u5230DP\u4fdd\u8bc1\u3002\u6570\u503c\u8bc4\u4f30\u8868\u660e\uff0c\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u53ef\u4ee5\u5728\u4fdd\u6301\u9690\u79c1\u4fdd\u8bc1\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u6240\u9700\u566a\u58f0\u89c4\u6a21\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u5148\u9a8c\u5206\u5e03\u77e5\u8bc6\uff0c\u53ef\u4ee5\u8bbe\u8ba1\u66f4\u9ad8\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff0c\u5728\u4fdd\u8bc1\u9690\u79c1\u7684\u540c\u65f6\u51cf\u5c11\u566a\u58f0\u6dfb\u52a0\uff0c\u63d0\u9ad8\u7ebf\u6027\u67e5\u8be2\u7ed3\u679c\u7684\u5b9e\u7528\u6027\u3002\u8fd9\u4e3a\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5e73\u8861\u9690\u79c1\u4fdd\u62a4\u4e0e\u6570\u636e\u5206\u6790\u7cbe\u5ea6\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.02366", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02366", "abs": "https://arxiv.org/abs/2601.02366", "authors": ["Yiwen Chen", "Yiqing Wu", "Huishi Luo", "Fuzhen Zhuang", "Deqing Wang"], "title": "TextBridgeGNN: Pre-training Graph Neural Network for Cross-Domain Recommendation via Text-Guided Transfer", "comment": null, "summary": "Graph-based recommendation has achieved great success in recent years. The classical graph recommendation model utilizes ID embedding to store essential collaborative information. However, this ID-based paradigm faces challenges in transferring to a new domain, making it hard to build a pre-trained graph recommendation model. This phenomenon primarily stems from two inherent challenges: (1) the non-transferability of ID embeddings due to isolated domain-specific ID spaces, and (2) structural incompatibility between heterogeneous interaction graphs across domains.\n  To address these issues, we propose TextBridgeGNN, a pre-training and fine-tuning framework that can effectively transfer knowledge from a pre-trained GNN to downstream tasks. We believe the key lies in how to build the relationship between domains. Specifically, TextBridgeGNN uses text as a semantic bridge to connect domains through multi-level graph propagation. During the pre-training stage, textual information is utilized to break the data islands formed by multiple domains, and hierarchical GNNs are designed to learn both domain-specific and domain-global knowledge with text features, ensuring the retention of collaborative signals and the enhancement of semantics. During the fine-tuning stage, a similarity transfer mechanism is proposed. This mechanism initializes ID embeddings in the target domain by transferring from semantically related nodes, successfully transferring the ID embeddings and graph pattern.\n  Experiments demonstrate that TextBridgeGNN outperforms existing methods in cross-domain, multi-domain, and training-free settings, highlighting its ability to integrate Pre-trained Language Model (PLM)-driven semantics with graph-based collaborative filtering without costly language model fine-tuning or real-time inference overhead.", "AI": {"tldr": "TextBridgeGNN\uff1a\u4e00\u4e2a\u4f7f\u7528\u6587\u672c\u4f5c\u4e3a\u8bed\u4e49\u6865\u6881\u7684\u56fe\u63a8\u8350\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7ea7\u56fe\u4f20\u64ad\u8fde\u63a5\u4e0d\u540c\u9886\u57df\uff0c\u89e3\u51b3ID\u5d4c\u5165\u4e0d\u53ef\u8fc1\u79fb\u548c\u5f02\u6784\u56fe\u7ed3\u6784\u4e0d\u517c\u5bb9\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8eID\u5d4c\u5165\u7684\u56fe\u63a8\u8350\u6a21\u578b\u96be\u4ee5\u8fc1\u79fb\u5230\u65b0\u9886\u57df\uff0c\u4e3b\u8981\u9762\u4e34\u4e24\u4e2a\u6311\u6218\uff1a1) ID\u5d4c\u5165\u56e0\u9886\u57df\u7279\u5b9aID\u7a7a\u95f4\u9694\u79bb\u800c\u4e0d\u53ef\u8fc1\u79fb\uff1b2) \u8de8\u9886\u57df\u5f02\u6784\u4ea4\u4e92\u56fe\u7684\u7ed3\u6784\u4e0d\u517c\u5bb9\u3002\u9700\u8981\u6784\u5efa\u53ef\u9884\u8bad\u7ec3\u7684\u56fe\u63a8\u8350\u6a21\u578b\u3002", "method": "\u63d0\u51faTextBridgeGNN\u6846\u67b6\uff1a1) \u4f7f\u7528\u6587\u672c\u4f5c\u4e3a\u8bed\u4e49\u6865\u6881\u8fde\u63a5\u4e0d\u540c\u9886\u57df\uff1b2) \u9884\u8bad\u7ec3\u9636\u6bb5\u5229\u7528\u6587\u672c\u4fe1\u606f\u6253\u7834\u6570\u636e\u5b64\u5c9b\uff0c\u8bbe\u8ba1\u5206\u5c42GNN\u5b66\u4e60\u9886\u57df\u7279\u5b9a\u548c\u5168\u5c40\u77e5\u8bc6\uff1b3) \u5fae\u8c03\u9636\u6bb5\u63d0\u51fa\u76f8\u4f3c\u6027\u8fc1\u79fb\u673a\u5236\uff0c\u901a\u8fc7\u8bed\u4e49\u76f8\u5173\u8282\u70b9\u521d\u59cb\u5316\u76ee\u6807\u57dfID\u5d4c\u5165\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTextBridgeGNN\u5728\u8de8\u9886\u57df\u3001\u591a\u9886\u57df\u548c\u65e0\u8bad\u7ec3\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u6574\u5408\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u4e0e\u57fa\u4e8e\u56fe\u7684\u534f\u540c\u8fc7\u6ee4\uff0c\u65e0\u9700\u6602\u8d35\u7684\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u6216\u5b9e\u65f6\u63a8\u7406\u5f00\u9500\u3002", "conclusion": "TextBridgeGNN\u6210\u529f\u89e3\u51b3\u4e86\u56fe\u63a8\u8350\u6a21\u578b\u7684\u8fc1\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u6587\u672c\u8bed\u4e49\u6865\u6881\u5b9e\u73b0\u4e86\u77e5\u8bc6\u5728\u4e0d\u540c\u9886\u57df\u95f4\u7684\u6709\u6548\u4f20\u9012\uff0c\u4e3a\u6784\u5efa\u53ef\u9884\u8bad\u7ec3\u7684\u56fe\u63a8\u8350\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.03126", "categories": ["cs.IT", "math.GR"], "pdf": "https://arxiv.org/pdf/2601.03126", "abs": "https://arxiv.org/abs/2601.03126", "authors": ["Jay A. Wood"], "title": "Dualities for finite abelian groups and applications to coding theory", "comment": "32 pages", "summary": "The choice of an isomorphism, a duality, between a finite abelian group $A$ and its character group allows one to define dual codes of additive codes over $A$. Properties of dualities and dual codes are studied, continuing work of Delsarte from 1973 and more recent work of Dougherty and his collaborators.", "AI": {"tldr": "\u7814\u7a76\u6709\u9650\u963f\u8d1d\u5c14\u7fa4\u4e0e\u5176\u7279\u5f81\u7fa4\u4e4b\u95f4\u5bf9\u5076\u6027\u7684\u9009\u62e9\u5982\u4f55\u5f71\u54cd\u52a0\u6cd5\u7801\u7684\u5bf9\u5076\u7801\u5b9a\u4e49\uff0c\u5ef6\u7eedDelsarte(1973)\u548cDougherty\u7b49\u4eba\u7684\u5de5\u4f5c", "motivation": "\u6709\u9650\u963f\u8d1d\u5c14\u7fa4\u4e0e\u5176\u7279\u5f81\u7fa4\u4e4b\u95f4\u5b58\u5728\u591a\u79cd\u540c\u6784\uff08\u5bf9\u5076\u6027\uff09\u9009\u62e9\uff0c\u4e0d\u540c\u7684\u9009\u62e9\u4f1a\u5bfc\u81f4\u4e0d\u540c\u7684\u5bf9\u5076\u7801\u5b9a\u4e49\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u7814\u7a76\u8fd9\u4e9b\u5bf9\u5076\u6027\u7684\u6027\u8d28\u53ca\u5176\u5bf9\u52a0\u6cd5\u7801\u5bf9\u5076\u7801\u7684\u5f71\u54cd\uff0c\u6df1\u5316\u5bf9\u7f16\u7801\u7406\u8bba\u4e2d\u8fd9\u4e00\u57fa\u7840\u95ee\u9898\u7684\u7406\u89e3\u3002", "method": "\u91c7\u7528\u4ee3\u6570\u7f16\u7801\u7406\u8bba\u65b9\u6cd5\uff0c\u7814\u7a76\u6709\u9650\u963f\u8d1d\u5c14\u7fa4\u4e0e\u5176\u7279\u5f81\u7fa4\u4e4b\u95f4\u7684\u5bf9\u5076\u6027\uff08\u540c\u6784\uff09\u3002\u5206\u6790\u4e0d\u540c\u5bf9\u5076\u6027\u9009\u62e9\u5982\u4f55\u5b9a\u4e49\u52a0\u6cd5\u7801\u7684\u5bf9\u5076\u7801\uff0c\u5e76\u7cfb\u7edf\u7814\u7a76\u8fd9\u4e9b\u5bf9\u5076\u6027\u548c\u5bf9\u5076\u7801\u7684\u6570\u5b66\u6027\u8d28\u3002", "result": "\u5efa\u7acb\u4e86\u6709\u9650\u963f\u8d1d\u5c14\u7fa4\u5bf9\u5076\u6027\u7684\u7cfb\u7edf\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u5bf9\u5076\u6027\u9009\u62e9\u5bf9\u52a0\u6cd5\u7801\u5bf9\u5076\u7801\u6027\u8d28\u7684\u5f71\u54cd\u3002\u53ef\u80fd\u53d1\u73b0\u4e86\u67d0\u4e9b\u5bf9\u5076\u6027\u5177\u6709\u66f4\u597d\u7684\u4ee3\u6570\u6027\u8d28\uff0c\u6216\u8005\u5728\u67d0\u4e9b\u5e94\u7528\u573a\u666f\u4e0b\u66f4\u4e3a\u9002\u7528\u3002", "conclusion": "\u6709\u9650\u963f\u8d1d\u5c14\u7fa4\u4e0e\u5176\u7279\u5f81\u7fa4\u4e4b\u95f4\u7684\u5bf9\u5076\u6027\u9009\u62e9\u4e0d\u662f\u552f\u4e00\u7684\uff0c\u8fd9\u79cd\u9009\u62e9\u4f1a\u5f71\u54cd\u52a0\u6cd5\u7801\u5bf9\u5076\u7801\u7684\u5b9a\u4e49\u548c\u6027\u8d28\u3002\u8be5\u7814\u7a76\u4e3a\u7f16\u7801\u7406\u8bba\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u7684\u7406\u8bba\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u7f16\u7801\u65b9\u6848\u3002"}}
{"id": "2601.02368", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02368", "abs": "https://arxiv.org/abs/2601.02368", "authors": ["Ruibing Wang", "Shuhan Guo", "Haotong Du", "Quanming Yao"], "title": "Distillation-based Scenario-Adaptive Mixture-of-Experts for the Matching Stage of Multi-scenario Recommendation", "comment": null, "summary": "Multi-scenario recommendation is pivotal for optimizing user experience across diverse contexts. While Multi-gate Mixture-of-Experts (MMOE) thrives in ranking, its transfer to the matching stage is hindered by the blind optimization inherent to independent two-tower architectures and the parameter dominance of head scenarios. To address these structural and distributional bottlenecks, we propose Distillation-based Scenario-Adaptive Mixture-of-Experts (DSMOE). Specially, we devise a Scenario-Adaptive Projection (SAP) module to generate lightweight, context-specific parameters, effectively preventing expert collapse in long-tail scenarios. Concurrently, we introduce a cross-architecture knowledge distillation framework, where an interaction-aware teacher guides the two-tower student to capture complex matching patterns. Extensive experiments on real-world datasets demonstrate DSMOE's superiority, particularly in significantly improving retrieval quality for under-represented, data-sparse scenarios.", "AI": {"tldr": "DSMOE\u901a\u8fc7\u573a\u666f\u81ea\u9002\u5e94\u6295\u5f71\u6a21\u5757\u548c\u8de8\u67b6\u6784\u77e5\u8bc6\u84b8\u998f\uff0c\u89e3\u51b3\u591a\u573a\u666f\u63a8\u8350\u5339\u914d\u9636\u6bb5\u4e2dMMOE\u7684\u4e13\u5bb6\u5d29\u6e83\u548c\u5934\u90e8\u573a\u666f\u53c2\u6570\u4e3b\u5bfc\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u957f\u5c3e\u573a\u666f\u68c0\u7d22\u8d28\u91cf\u3002", "motivation": "\u591a\u573a\u666f\u63a8\u8350\u4e2d\uff0cMMOE\u5728\u6392\u5e8f\u9636\u6bb5\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5339\u914d\u9636\u6bb5\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u72ec\u7acb\u53cc\u5854\u67b6\u6784\u7684\u76f2\u76ee\u4f18\u5316\uff0c\u4ee5\u53ca\u5934\u90e8\u573a\u666f\u53c2\u6570\u4e3b\u5bfc\u5bfc\u81f4\u957f\u5c3e\u573a\u666f\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faDSMOE\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u573a\u666f\u81ea\u9002\u5e94\u6295\u5f71\u6a21\u5757(SAP)\uff0c\u751f\u6210\u8f7b\u91cf\u7ea7\u3001\u573a\u666f\u7279\u5b9a\u7684\u53c2\u6570\uff0c\u9632\u6b62\u4e13\u5bb6\u5d29\u6e83\uff1b2) \u8de8\u67b6\u6784\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u4f7f\u7528\u4ea4\u4e92\u611f\u77e5\u7684\u6559\u5e08\u6a21\u578b\u6307\u5bfc\u53cc\u5854\u5b66\u751f\u6a21\u578b\u5b66\u4e60\u590d\u6742\u5339\u914d\u6a21\u5f0f\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cDSMOE\u5728\u591a\u573a\u666f\u63a8\u8350\u5339\u914d\u9636\u6bb5\u8868\u73b0\u4f18\u5f02\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u758f\u3001\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u957f\u5c3e\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u8d28\u91cf\u3002", "conclusion": "DSMOE\u901a\u8fc7\u89e3\u51b3\u591a\u573a\u666f\u63a8\u8350\u5339\u914d\u9636\u6bb5\u7684\u7ed3\u6784\u548c\u5206\u5e03\u74f6\u9888\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6574\u4f53\u63a8\u8350\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u957f\u5c3e\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u591a\u573a\u666f\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.03165", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.03165", "abs": "https://arxiv.org/abs/2601.03165", "authors": ["Anuj Kumar Bhagat", "Ritumoni Sarma"], "title": "On the Euclidean duals of the cyclic codes generated by cyclotomic polynomials", "comment": null, "summary": "In this article, we determine the minimum distance of the Euclidean dual of the cyclic code $\\mathcal{C}_n$ generated by the $n$th cyclotomic polynomial $Q_n(x)$ over $\\mathbb{F}_q$, for every positive integer $n$ co-prime to $q$. In particular, we prove that the minimum distance of $\\mathcal{C}_{n}^{\\perp}$ is a function of $n$, namely $2^{\u03c9(n)}$. This was precisely the conjecture posed by us in \\cite{BHAGAT2025}.", "AI": {"tldr": "\u8bc1\u660e\u4e86\u5faa\u73af\u7801C_n\u7684\u6b27\u51e0\u91cc\u5f97\u5bf9\u5076\u7801\u7684\u6700\u5c0f\u8ddd\u79bb\u4e3a2^\u03c9(n)\uff0c\u5176\u4e2d\u03c9(n)\u662fn\u7684\u4e0d\u540c\u7d20\u56e0\u5b50\u4e2a\u6570\uff0c\u9a8c\u8bc1\u4e86\u5148\u524d\u63d0\u51fa\u7684\u731c\u60f3\u3002", "motivation": "\u7814\u7a76\u7531\u7b2cn\u4e2a\u5206\u5706\u591a\u9879\u5f0f\u751f\u6210\u7684\u5faa\u73af\u7801\u7684\u6b27\u51e0\u91cc\u5f97\u5bf9\u5076\u7801\u7684\u6700\u5c0f\u8ddd\u79bb\u7279\u6027\uff0c\u9a8c\u8bc1\u5148\u524d\u63d0\u51fa\u7684\u731c\u60f3\u3002", "method": "\u4f7f\u7528\u6570\u8bba\u548c\u7f16\u7801\u7406\u8bba\u65b9\u6cd5\uff0c\u5206\u6790\u7531\u5206\u5706\u591a\u9879\u5f0f\u751f\u6210\u7684\u5faa\u73af\u7801\u7684\u7ed3\u6784\u7279\u6027\uff0c\u63a8\u5bfc\u5176\u5bf9\u5076\u7801\u7684\u6700\u5c0f\u8ddd\u79bb\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u6240\u6709\u4e0eq\u4e92\u8d28\u7684\u6b63\u6574\u6570n\uff0c\u5faa\u73af\u7801C_n\u7684\u6b27\u51e0\u91cc\u5f97\u5bf9\u5076\u7801\u7684\u6700\u5c0f\u8ddd\u79bb\u4e3a2^\u03c9(n)\uff0c\u5176\u4e2d\u03c9(n)\u662fn\u7684\u4e0d\u540c\u7d20\u56e0\u5b50\u4e2a\u6570\u3002", "conclusion": "\u6210\u529f\u786e\u5b9a\u4e86\u7531\u5206\u5706\u591a\u9879\u5f0f\u751f\u6210\u7684\u5faa\u73af\u7801\u7684\u6b27\u51e0\u91cc\u5f97\u5bf9\u5076\u7801\u7684\u6700\u5c0f\u8ddd\u79bb\u516c\u5f0f\uff0c\u9a8c\u8bc1\u4e86\u5148\u524d\u63d0\u51fa\u7684\u731c\u60f3\uff0c\u4e3a\u8fd9\u7c7b\u7801\u7684\u7ea0\u9519\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002"}}
{"id": "2601.02372", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02372", "abs": "https://arxiv.org/abs/2601.02372", "authors": ["Eunice Kingenga", "Mike Wa Nkongolo"], "title": "Improving News Recommendations through Hybrid Sentiment Modelling and Reinforcement Learning", "comment": "Masters in information technology, University of Pretoria", "summary": "News recommendation systems rely on automated sentiment analysis to personalise content and enhance user engagement. Conventional approaches often struggle with ambiguity, lexicon inconsistencies, and limited contextual understanding, particularly in multi-source news environments. Existing models typically treat sentiment as a secondary feature, reducing their ability to adapt to users' affective preferences. To address these limitations, this study develops an adaptive, sentiment-aware news recommendation framework by integrating hybrid sentiment analysis with reinforcement learning. Using the BBC News dataset, a hybrid sentiment model combines VADER, AFINN, TextBlob, and SentiWordNet scores to generate robust article-level sentiment estimates. Articles are categorised as positive, negative, or neutral, and these sentiment states are embedded within a Q-learning architecture to guide the agent in learning optimal recommendation policies. The proposed system effectively identifies and recommends articles with aligned emotional profiles while continuously improving personalisation through iterative Q-learning updates. The results demonstrate that coupling hybrid sentiment modelling with reinforcement learning provides a feasible, interpretable, and adaptive approach for user-centred news recommendation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df7\u5408\u60c5\u611f\u5206\u6790\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u60c5\u611f\u611f\u77e5\u65b0\u95fb\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7Q-learning\u4f18\u5316\u63a8\u8350\u7b56\u7565\uff0c\u63d0\u5347\u4e2a\u6027\u5316\u63a8\u8350\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u65b0\u95fb\u63a8\u8350\u7cfb\u7edf\u5728\u60c5\u611f\u5206\u6790\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff1a\u5904\u7406\u6b67\u4e49\u6027\u5dee\u3001\u8bcd\u5178\u4e0d\u4e00\u81f4\u3001\u4e0a\u4e0b\u6587\u7406\u89e3\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u591a\u6e90\u65b0\u95fb\u73af\u5883\u4e2d\u3002\u73b0\u6709\u6a21\u578b\u901a\u5e38\u5c06\u60c5\u611f\u4f5c\u4e3a\u6b21\u8981\u7279\u5f81\uff0c\u96be\u4ee5\u9002\u5e94\u7528\u6237\u7684\u60c5\u611f\u504f\u597d\u3002", "method": "1. \u4f7f\u7528BBC News\u6570\u636e\u96c6\n2. \u6784\u5efa\u6df7\u5408\u60c5\u611f\u5206\u6790\u6a21\u578b\uff1a\u7ed3\u5408VADER\u3001AFINN\u3001TextBlob\u548cSentiWordNet\u56db\u79cd\u5de5\u5177\u751f\u6210\u6587\u7ae0\u7ea7\u60c5\u611f\u8bc4\u5206\n3. \u5c06\u6587\u7ae0\u5206\u7c7b\u4e3a\u79ef\u6781\u3001\u6d88\u6781\u6216\u4e2d\u6027\n4. \u5c06\u60c5\u611f\u72b6\u6001\u5d4c\u5165Q-learning\u67b6\u6784\u4e2d\uff0c\u8ba9\u667a\u80fd\u4f53\u5b66\u4e60\u6700\u4f18\u63a8\u8350\u7b56\u7565\n5. \u901a\u8fc7\u8fed\u4ee3Q-learning\u66f4\u65b0\u6301\u7eed\u6539\u8fdb\u4e2a\u6027\u5316\u63a8\u8350", "result": "\u63d0\u51fa\u7684\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u8bc6\u522b\u5e76\u63a8\u8350\u60c5\u611f\u5bf9\u9f50\u7684\u6587\u7ae0\uff0c\u901a\u8fc7\u6df7\u5408\u60c5\u611f\u5efa\u6a21\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u7ed3\u5408\uff0c\u4e3a\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u65b0\u95fb\u63a8\u8350\u63d0\u4f9b\u4e86\u53ef\u884c\u3001\u53ef\u89e3\u91ca\u4e14\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u7ed3\u5408\u6df7\u5408\u60c5\u611f\u5206\u6790\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u4e3a\u65b0\u95fb\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u60c5\u611f\u611f\u77e5\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u597d\u5730\u9002\u5e94\u7528\u6237\u7684\u60c5\u611f\u504f\u597d\uff0c\u63d0\u5347\u4e2a\u6027\u5316\u63a8\u8350\u8d28\u91cf\u3002"}}
{"id": "2601.03241", "categories": ["cs.IT", "cs.CR", "cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.03241", "abs": "https://arxiv.org/abs/2601.03241", "authors": ["Lei Hu", "Sennur Ulukus"], "title": "On the Capacity Region of Individual Key Rates in Vector Linear Secure Aggregation", "comment": null, "summary": "We provide new insights into an open problem recently posed by Yuan-Sun [ISIT 2025], concerning the minimum individual key rate required in the vector linear secure aggregation problem. Consider a distributed system with $K$ users, where each user $k\\in [K]$ holds a data stream $W_k$ and an individual key $Z_k$. A server aims to compute a linear function $\\mathbf{F}[W_1;\\ldots;W_K]$ without learning any information about another linear function $\\mathbf{G}[W_1;\\ldots;W_K]$, where $[W_1;\\ldots;W_K]$ denotes the row stack of $W_1,\\ldots,W_K$. The open problem is to determine the minimum required length of $Z_k$, denoted as $R_k$, $k\\in [K]$. In this paper, we characterize a new achievable region for the rate tuple $(R_1,\\ldots,R_K)$. The region is polyhedral, with vertices characterized by a binary rate assignment $(R_1,\\ldots,R_K) = (\\mathbf{1}(1 \\in \\mathcal{I}),\\ldots,\\mathbf{1}(K\\in \\mathcal{I}))$, where $\\mathcal{I}\\subseteq [K]$ satisfies the \\textit{rank-increment condition}: $\\mathrm{rank}\\left(\\bigl[\\mathbf{F}_{\\mathcal{I}};\\mathbf{G}_{\\mathcal{I}}\\bigr]\\right) =\\mathrm{rank}\\bigl(\\mathbf{F}_{\\mathcal{I}}\\bigr)+N$. Here, $\\mathbf{F}_\\mathcal{I}$ and $\\mathbf{G}_\\mathcal{I}$ are the submatrices formed by the columns indexed by $\\mathcal{I}$. Our results uncover the novel fact that it is not necessary for every user to hold a key, thereby strictly enlarging the best-known achievable region in the literature. Furthermore, we provide a converse analysis to demonstrate its optimality when minimizing the number of users that hold keys.", "AI": {"tldr": "\u8be5\u8bba\u6587\u89e3\u51b3\u4e86\u5411\u91cf\u7ebf\u6027\u5b89\u5168\u805a\u5408\u95ee\u9898\u4e2d\u6700\u5c0f\u4e2a\u4f53\u5bc6\u94a5\u901f\u7387\u7684\u5f00\u653e\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u53ef\u8fbe\u901f\u7387\u533a\u57df\uff0c\u5e76\u8bc1\u660e\u5e76\u975e\u6240\u6709\u7528\u6237\u90fd\u9700\u8981\u6301\u6709\u5bc6\u94a5\u3002", "motivation": "\u89e3\u51b3Yuan-Sun\u5728ISIT 2025\u63d0\u51fa\u7684\u5f00\u653e\u95ee\u9898\uff1a\u786e\u5b9a\u5411\u91cf\u7ebf\u6027\u5b89\u5168\u805a\u5408\u95ee\u9898\u4e2d\u6bcf\u4e2a\u7528\u6237\u6240\u9700\u7684\u6700\u5c0f\u4e2a\u4f53\u5bc6\u94a5\u901f\u7387\u3002\u73b0\u6709\u7814\u7a76\u5bf9\u5bc6\u94a5\u5206\u914d\u8981\u6c42\u8f83\u9ad8\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u5bc6\u94a5\u5206\u914d\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6ee1\u8db3\"\u79e9\u589e\u91cf\u6761\u4ef6\"\u7684\u7d22\u5f15\u96c6I\uff0c\u6784\u9020\u591a\u9762\u4f53\u53ef\u8fbe\u901f\u7387\u533a\u57df\u3002\u8be5\u533a\u57df\u7684\u9876\u70b9\u7531\u4e8c\u8fdb\u5236\u901f\u7387\u5206\u914d(R1,...,RK) = (1(1\u2208I),...,1(K\u2208I))\u8868\u5f81\uff0c\u5176\u4e2dI\u6ee1\u8db3rank([F_I;G_I]) = rank(F_I) + N\u3002", "result": "\u63d0\u51fa\u4e86\u4e25\u683c\u5927\u4e8e\u73b0\u6709\u6700\u4f73\u53ef\u8fbe\u533a\u57df\u7684\u65b0\u53ef\u8fbe\u901f\u7387\u533a\u57df\uff0c\u63ed\u793a\u4e86\u5e76\u975e\u6240\u6709\u7528\u6237\u90fd\u9700\u8981\u6301\u6709\u5bc6\u94a5\u7684\u91cd\u8981\u65b0\u4e8b\u5b9e\u3002\u5f53\u6700\u5c0f\u5316\u6301\u6709\u5bc6\u94a5\u7684\u7528\u6237\u6570\u91cf\u65f6\uff0c\u8be5\u65b9\u6848\u662f\u6700\u4f18\u7684\u3002", "conclusion": "\u8be5\u7814\u7a76\u89e3\u51b3\u4e86\u5411\u91cf\u7ebf\u6027\u5b89\u5168\u805a\u5408\u4e2d\u7684\u5173\u952e\u5f00\u653e\u95ee\u9898\uff0c\u901a\u8fc7\u79e9\u589e\u91cf\u6761\u4ef6\u8868\u5f81\u4e86\u6700\u4f18\u5bc6\u94a5\u5206\u914d\uff0c\u663e\u8457\u6539\u8fdb\u4e86\u73b0\u6709\u65b9\u6848\uff0c\u4e3a\u5206\u5e03\u5f0f\u5b89\u5168\u8ba1\u7b97\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.02374", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02374", "abs": "https://arxiv.org/abs/2601.02374", "authors": ["Melissa Tessa", "Diderot D. Cidjeu", "Rachele Carli", "Sarah Abchiche", "Ahmad Aldarwishd", "Igor Tchappi", "Amro Najjar"], "title": "A Lay User Explainable Food Recommendation System Based on Hybrid Feature Importance Extraction and Large Language Models", "comment": null, "summary": "Large Language Models (LLM) have experienced strong development in recent years, with varied applications. This paper uses LLMs to develop a post-hoc process that provides more elaborated explanations of the results of food recommendation systems. By combining LLM with a hybrid extraction of key variables using SHAP, we obtain dynamic, convincing and more comprehensive explanations to lay user, compared to those in the literature. This approach enhances user trust and transparency by making complex recommendation outcomes easier to understand for a lay user.", "AI": {"tldr": "\u4f7f\u7528LLM\u7ed3\u5408SHAP\u4e3a\u98df\u54c1\u63a8\u8350\u7cfb\u7edf\u751f\u6210\u66f4\u8be6\u7ec6\u3001\u52a8\u6001\u4e14\u6613\u4e8e\u7406\u89e3\u7684\u540e\u5904\u7406\u89e3\u91ca\uff0c\u63d0\u5347\u7528\u6237\u4fe1\u4efb\u548c\u900f\u660e\u5ea6", "motivation": "\u73b0\u6709\u98df\u54c1\u63a8\u8350\u7cfb\u7edf\u7684\u89e3\u91ca\u901a\u5e38\u4e0d\u591f\u8be6\u7ec6\u6216\u96be\u4ee5\u7406\u89e3\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u666e\u901a\u7528\u6237\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u66f4\u5168\u9762\u3001\u52a8\u6001\u4e14\u6613\u4e8e\u7406\u89e3\u7684\u89e3\u91ca\uff0c\u4ee5\u589e\u5f3a\u7528\u6237\u5bf9\u63a8\u8350\u7ed3\u679c\u7684\u4fe1\u4efb\u548c\u7cfb\u7edf\u900f\u660e\u5ea6\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u548cSHAP\uff08SHapley Additive exPlanations\uff09\u7684\u6df7\u5408\u5173\u952e\u53d8\u91cf\u63d0\u53d6\u6280\u672f\u3002\u901a\u8fc7LLM\u751f\u6210\u52a8\u6001\u3001\u6709\u8bf4\u670d\u529b\u7684\u89e3\u91ca\uff0c\u540c\u65f6\u5229\u7528SHAP\u8bc6\u522b\u5f71\u54cd\u63a8\u8350\u7ed3\u679c\u7684\u5173\u952e\u53d8\u91cf\u3002", "result": "\u76f8\u6bd4\u6587\u732e\u4e2d\u7684\u73b0\u6709\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u4e3a\u666e\u901a\u7528\u6237\u63d0\u4f9b\u66f4\u5168\u9762\u3001\u52a8\u6001\u4e14\u4ee4\u4eba\u4fe1\u670d\u7684\u89e3\u91ca\u3002\u8fd9\u4e9b\u89e3\u91ca\u4f7f\u590d\u6742\u7684\u63a8\u8350\u7ed3\u679c\u66f4\u5bb9\u6613\u7406\u89e3\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u7528\u6237\u4fe1\u4efb\u548c\u7cfb\u7edf\u900f\u660e\u5ea6\u3002", "conclusion": "LLM\u4e0eSHAP\u7684\u7ed3\u5408\u4e3a\u98df\u54c1\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u540e\u5904\u7406\u89e3\u91ca\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u66f4\u8be6\u7ec6\u3001\u6613\u4e8e\u7406\u89e3\u7684\u89e3\u91ca\uff0c\u663e\u8457\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u548c\u7cfb\u7edf\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2601.02381", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02381", "abs": "https://arxiv.org/abs/2601.02381", "authors": ["Zhexiang Li"], "title": "TAG-HGT: A Scalable and Cost-Effective Framework for Inductive Cold-Start Academic Recommendation", "comment": "8pages", "summary": "Inductive cold-start recommendation remains the \"Achilles' Heel\" of industrial academic platforms, where thousands of new scholars join daily without historical interaction records. While recent Generative Graph Models (e.g., HiGPT, OFA) demonstrate promising semantic capabilities, their prohibitive inference latency (often exceeding 13 minutes per 1,000 requests) and massive computational costs render them practically undeployable for real-time, million-scale applications. To bridge this gap between generative quality and industrial scalability, we propose TAG-HGT, a cost-effective neuro-symbolic framework. Adopting a decoupled \"Semantics-First, Structure-Refined\" paradigm, TAG-HGT utilizes a frozen Large Language Model (DeepSeek-V3) as an offline semantic factory and distills its knowledge into a lightweight Heterogeneous Graph Transformer (HGT) via Cross-View Contrastive Learning (CVCL). We present a key insight: while LLM semantics provide necessary global recall, structural signals offer the critical local discrimination needed to distinguish valid collaborators from semantically similar but socially unreachable strangers in dense embedding spaces. Validated under a strict Time-Machine Protocol on the massive OpenAlex dataset, TAG-HGT achieves a SOTA System Recall@10 of 91.97%, outperforming structure-only baselines by 20.7%. Most significantly, from an industrial perspective, TAG-HGT reduces inference latency by five orders of magnitude ($4.5 \\times 10^{5}\\times$) compared to generative baselines (from 780s down to 1.73 ms), and slashes inference costs from $\\sim$$1.50 to $<$$0.001 per 1k queries. This 99.9% cost reduction democratizes high-precision academic recommendation.", "AI": {"tldr": "TAG-HGT\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\"\u8bed\u4e49\u4f18\u5148\u3001\u7ed3\u6784\u4f18\u5316\"\u8303\u5f0f\uff0c\u5c06\u51bb\u7ed3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u77e5\u8bc6\u84b8\u998f\u5230\u8f7b\u91cf\u7ea7\u5f02\u6784\u56feTransformer\u4e2d\uff0c\u89e3\u51b3\u4e86\u5b66\u672f\u5e73\u53f0\u51b7\u542f\u52a8\u63a8\u8350\u4e2d\u751f\u6210\u6a21\u578b\u63a8\u7406\u5ef6\u8fdf\u9ad8\u3001\u6210\u672c\u5927\u7684\u95ee\u9898\u3002", "motivation": "\u5de5\u4e1a\u5b66\u672f\u5e73\u53f0\u9762\u4e34\u51b7\u542f\u52a8\u63a8\u8350\u6311\u6218\uff0c\u6bcf\u5929\u6709\u5927\u91cf\u65b0\u5b66\u8005\u52a0\u5165\u4f46\u65e0\u5386\u53f2\u4ea4\u4e92\u8bb0\u5f55\u3002\u73b0\u6709\u751f\u6210\u56fe\u6a21\u578b\u867d\u7136\u8bed\u4e49\u80fd\u529b\u5f3a\uff0c\u4f46\u63a8\u7406\u5ef6\u8fdf\u9ad8\uff0813\u5206\u949f/1000\u8bf7\u6c42\uff09\u3001\u8ba1\u7b97\u6210\u672c\u5927\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u65f6\u3001\u767e\u4e07\u7ea7\u5e94\u7528\u9700\u6c42\u3002", "method": "\u91c7\u7528\u89e3\u8026\u7684\"\u8bed\u4e49\u4f18\u5148\u3001\u7ed3\u6784\u4f18\u5316\"\u8303\u5f0f\uff1a1) \u4f7f\u7528\u51bb\u7ed3\u7684DeepSeek-V3\u4f5c\u4e3a\u79bb\u7ebf\u8bed\u4e49\u5de5\u5382\uff1b2) \u901a\u8fc7\u8de8\u89c6\u56fe\u5bf9\u6bd4\u5b66\u4e60\u5c06LLM\u77e5\u8bc6\u84b8\u998f\u5230\u8f7b\u91cf\u7ea7\u5f02\u6784\u56feTransformer\u4e2d\uff1b3) \u7ed3\u5408LLM\u7684\u5168\u5c40\u53ec\u56de\u80fd\u529b\u548c\u7ed3\u6784\u4fe1\u53f7\u7684\u5c40\u90e8\u533a\u5206\u80fd\u529b\u3002", "result": "\u5728OpenAlex\u6570\u636e\u96c6\u4e0a\uff0cTAG-HGT\u8fbe\u5230SOTA System Recall@10\u4e3a91.97%\uff0c\u6bd4\u7eaf\u7ed3\u6784\u57fa\u7ebf\u63d0\u534720.7%\u3002\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e5\u4e2a\u6570\u91cf\u7ea7\uff08\u4ece780\u79d2\u964d\u81f31.73\u6beb\u79d2\uff09\uff0c\u63a8\u7406\u6210\u672c\u4ece1.50\u7f8e\u5143\u964d\u81f3<0.001\u7f8e\u5143/1000\u67e5\u8be2\uff0c\u6210\u672c\u964d\u4f4e99.9%\u3002", "conclusion": "TAG-HGT\u6210\u529f\u5e73\u8861\u4e86\u751f\u6210\u8d28\u91cf\u548c\u5de5\u4e1a\u53ef\u6269\u5c55\u6027\uff0c\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u5b66\u672f\u63a8\u8350\uff0c\u5927\u5e45\u964d\u4f4e\u4e86\u63a8\u7406\u5ef6\u8fdf\u548c\u6210\u672c\uff0c\u4f7f\u9ad8\u8d28\u91cf\u5b66\u672f\u63a8\u8350\u66f4\u52a0\u6c11\u4e3b\u5316\u3002"}}
{"id": "2601.02386", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02386", "abs": "https://arxiv.org/abs/2601.02386", "authors": ["Hanyang Yuan", "Ning Tang", "Tongya Zheng", "Jiarong Xu", "Xintong Hu", "Renhong Huang", "Shunyu Liu", "Jiacong Hu", "Jiawei Chen", "Mingli Song"], "title": "Tree of Preferences for Diversified Recommendation", "comment": null, "summary": "Diversified recommendation has attracted increasing attention from both researchers and practitioners, which can effectively address the homogeneity of recommended items. Existing approaches predominantly aim to infer the diversity of user preferences from observed user feedback. Nonetheless, due to inherent data biases, the observed data may not fully reflect user interests, where underexplored preferences can be overwhelmed or remain unmanifested. Failing to capture these preferences can lead to suboptimal diversity in recommendations. To fill this gap, this work aims to study diversified recommendation from a data-bias perspective. Inspired by the outstanding performance of large language models (LLMs) in zero-shot inference leveraging world knowledge, we propose a novel approach that utilizes LLMs' expertise to uncover underexplored user preferences from observed behavior, ultimately providing diverse and relevant recommendations. To achieve this, we first introduce Tree of Preferences (ToP), an innovative structure constructed to model user preferences from coarse to fine. ToP enables LLMs to systematically reason over the user's rationale behind their behavior, thereby uncovering their underexplored preferences. To guide diversified recommendations using uncovered preferences, we adopt a data-centric approach, identifying candidate items that match user preferences and generating synthetic interactions that reflect underexplored preferences. These interactions are integrated to train a general recommender for diversification. Moreover, we scale up overall efficiency by dynamically selecting influential users during optimization. Extensive evaluations of both diversity and relevance show that our approach outperforms existing methods in most cases and achieves near-optimal performance in others, with reasonable inference latency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u6570\u636e\u504f\u5dee\u89d2\u5ea6\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u591a\u6837\u6027\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u504f\u597d\u6811\u63ed\u793a\u7528\u6237\u672a\u5145\u5206\u63a2\u7d22\u7684\u5174\u8da3\uff0c\u5e76\u751f\u6210\u5408\u6210\u4ea4\u4e92\u6570\u636e\u6765\u8bad\u7ec3\u63a8\u8350\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u591a\u6837\u5316\u63a8\u8350\u65b9\u6cd5\u4e3b\u8981\u4ece\u89c2\u6d4b\u5230\u7684\u7528\u6237\u53cd\u9988\u63a8\u65ad\u7528\u6237\u504f\u597d\u591a\u6837\u6027\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u504f\u5dee\u7684\u5b58\u5728\uff0c\u89c2\u6d4b\u6570\u636e\u53ef\u80fd\u65e0\u6cd5\u5b8c\u5168\u53cd\u6620\u7528\u6237\u5174\u8da3\uff0c\u5bfc\u81f4\u672a\u5145\u5206\u63a2\u7d22\u7684\u504f\u597d\u88ab\u6df9\u6ca1\u6216\u672a\u663e\u73b0\uff0c\u4ece\u800c\u9020\u6210\u63a8\u8350\u591a\u6837\u6027\u4e0d\u8db3\u3002", "method": "1. \u63d0\u51fa\u504f\u597d\u6811\u7ed3\u6784\uff0c\u4ece\u7c97\u5230\u7ec6\u5efa\u6a21\u7528\u6237\u504f\u597d\uff0c\u4f7fLLM\u80fd\u591f\u7cfb\u7edf\u63a8\u7406\u7528\u6237\u884c\u4e3a\u80cc\u540e\u7684\u903b\u8f91\uff1b2. \u91c7\u7528\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\uff0c\u8bc6\u522b\u5339\u914d\u7528\u6237\u504f\u597d\u7684\u5019\u9009\u7269\u54c1\u5e76\u751f\u6210\u53cd\u6620\u672a\u5145\u5206\u63a2\u7d22\u504f\u597d\u7684\u5408\u6210\u4ea4\u4e92\uff1b3. \u5c06\u8fd9\u4e9b\u4ea4\u4e92\u6574\u5408\u8bad\u7ec3\u901a\u7528\u63a8\u8350\u5668\u5b9e\u73b0\u591a\u6837\u5316\uff1b4. \u901a\u8fc7\u52a8\u6001\u9009\u62e9\u6709\u5f71\u54cd\u529b\u7684\u7528\u6237\u4f18\u5316\u6574\u4f53\u6548\u7387\u3002", "result": "\u5728\u591a\u6837\u6027\u548c\u76f8\u5173\u6027\u65b9\u9762\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u5176\u4ed6\u60c5\u51b5\u4e0b\u8fbe\u5230\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\uff0c\u4e14\u5177\u6709\u5408\u7406\u7684\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "\u4ece\u6570\u636e\u504f\u5dee\u89d2\u5ea6\u7814\u7a76\u591a\u6837\u5316\u63a8\u8350\u662f\u6709\u6548\u7684\uff0c\u5229\u7528LLM\u7684\u4e16\u754c\u77e5\u8bc6\u548c\u96f6\u6837\u672c\u63a8\u7406\u80fd\u529b\u53ef\u4ee5\u63ed\u793a\u7528\u6237\u672a\u5145\u5206\u63a2\u7d22\u7684\u504f\u597d\uff0c\u4ece\u800c\u63d0\u4f9b\u66f4\u76f8\u5173\u4e14\u591a\u6837\u5316\u7684\u63a8\u8350\u3002"}}
{"id": "2601.02412", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02412", "abs": "https://arxiv.org/abs/2601.02412", "authors": ["Lukas Sch\u00fcepp", "Carmen Amo Alonso", "Florian D\u00f6rfler", "Giulia De Pasquale"], "title": "Socially-Aware Recommender Systems Mitigate Opinion Clusterization", "comment": null, "summary": "Recommender systems shape online interactions by matching users with creators content to maximize engagement. Creators, in turn, adapt their content to align with users preferences and enhance their popularity. At the same time, users preferences evolve under the influence of both suggested content from the recommender system and content shared within their social circles. This feedback loop generates a complex interplay between users, creators, and recommender algorithms, which is the key cause of filter bubbles and opinion polarization. We develop a social network-aware recommender system that explicitly accounts for this user-creators feedback interaction and strategically exploits the topology of the user's own social network to promote diversification. Our approach highlights how accounting for and exploiting user's social network in the recommender system design is crucial to mediate filter bubble effects while balancing content diversity with personalization. Provably, opinion clusterization is positively correlated with the influence of recommended content on user opinions. Ultimately, the proposed approach shows the power of socially-aware recommender systems in combating opinion polarization and clusterization phenomena.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u793e\u4ea4\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\u7684\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u5229\u7528\u7528\u6237\u793e\u4ea4\u5173\u7cfb\u6765\u5e73\u8861\u4e2a\u6027\u5316\u4e0e\u5185\u5bb9\u591a\u6837\u6027\uff0c\u4ece\u800c\u7f13\u89e3\u8fc7\u6ee4\u6c14\u6ce1\u548c\u610f\u89c1\u6781\u5316\u95ee\u9898\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u3001\u5185\u5bb9\u521b\u4f5c\u8005\u548c\u7528\u6237\u4e4b\u95f4\u5f62\u6210\u590d\u6742\u7684\u53cd\u9988\u5faa\u73af\uff1a\u63a8\u8350\u7cfb\u7edf\u5f71\u54cd\u7528\u6237\u504f\u597d\uff0c\u7528\u6237\u504f\u597d\u53c8\u5f71\u54cd\u521b\u4f5c\u8005\u5185\u5bb9\uff0c\u521b\u4f5c\u8005\u5185\u5bb9\u518d\u5f71\u54cd\u63a8\u8350\u7ed3\u679c\u3002\u8fd9\u79cd\u5faa\u73af\u5bfc\u81f4\u8fc7\u6ee4\u6c14\u6ce1\u548c\u610f\u89c1\u6781\u5316\u95ee\u9898\u3002\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u672a\u80fd\u5145\u5206\u8003\u8651\u7528\u6237\u793e\u4ea4\u7f51\u7edc\u5728\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u793e\u4ea4\u7f51\u7edc\u611f\u77e5\u7684\u63a8\u8350\u7cfb\u7edf\uff0c\u660e\u786e\u8003\u8651\u7528\u6237-\u521b\u4f5c\u8005\u53cd\u9988\u4e92\u52a8\uff0c\u5e76\u6218\u7565\u6027\u5730\u5229\u7528\u7528\u6237\u81ea\u8eab\u793e\u4ea4\u7f51\u7edc\u7684\u62d3\u6251\u7ed3\u6784\u6765\u4fc3\u8fdb\u5185\u5bb9\u591a\u6837\u5316\u3002\u8be5\u65b9\u6cd5\u5c06\u793e\u4ea4\u7f51\u7edc\u4fe1\u606f\u6574\u5408\u5230\u63a8\u8350\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u610f\u89c1\u805a\u7c7b\u4e0e\u63a8\u8350\u5185\u5bb9\u5bf9\u7528\u6237\u610f\u89c1\u7684\u5f71\u54cd\u529b\u5448\u6b63\u76f8\u5173\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u5c55\u793a\u4e86\u793e\u4ea4\u611f\u77e5\u63a8\u8350\u7cfb\u7edf\u5728\u5bf9\u6297\u610f\u89c1\u6781\u5316\u548c\u805a\u7c7b\u73b0\u8c61\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5e73\u8861\u5185\u5bb9\u591a\u6837\u6027\u4e0e\u4e2a\u6027\u5316\u3002", "conclusion": "\u5728\u63a8\u8350\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u8003\u8651\u5e76\u5229\u7528\u7528\u6237\u793e\u4ea4\u7f51\u7edc\u5bf9\u4e8e\u7f13\u89e3\u8fc7\u6ee4\u6c14\u6ce1\u6548\u5e94\u81f3\u5173\u91cd\u8981\u3002\u793e\u4ea4\u611f\u77e5\u7684\u63a8\u8350\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5e73\u8861\u5185\u5bb9\u591a\u6837\u6027\u4e0e\u4e2a\u6027\u5316\uff0c\u5bf9\u6297\u610f\u89c1\u6781\u5316\u548c\u805a\u7c7b\u73b0\u8c61\uff0c\u4e3a\u6784\u5efa\u66f4\u5065\u5eb7\u7684\u5728\u7ebf\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u601d\u8def\u3002"}}
{"id": "2601.02428", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02428", "abs": "https://arxiv.org/abs/2601.02428", "authors": ["Okan Bursa"], "title": "A Dynamic Retrieval-Augmented Generation System with Selective Memory and Remembrance", "comment": "6 Pages, 2 figures", "summary": "We introduce \\emph{Adaptive RAG Memory} (ARM), a retrieval-augmented generation (RAG) framework that replaces a static vector index with a \\emph{dynamic} memory substrate governed by selective remembrance and decay. Frequently retrieved items are consolidated and protected from forgetting, while rarely used items gradually decay, inspired by cognitive consolidation and forgetting principles. On a lightweight retrieval benchmark, ARM reaches near state-of-the-art performance (e.g., NDCG@5 $\\approx$ 0.940, Recall@5 $=1.000$) with only $\\sim$22M parameters in the embedding layer, achieving the best efficiency among ultra-efficient models ($<$25M parameters). In addition, we compare static vs. dynamic RAG combinations across Llama 3.1 and GPT-4o. Llama 3.1 with static RAG achieves the highest key-term coverage (67.2\\%) at moderate latency, while GPT-4o with a dynamic selective retrieval policy attains the fastest responses (8.2s on average) with competitive coverage (58.7\\%). We further present an engineering optimization of the DynamicRAG implementation, making embedding weights configurable, adjustable at runtime, and robust to invalid settings.\n  ARM yields competitive accuracy, self-regularizing memory growth, and interpretable retention dynamics without retraining the generator\\color{black} and provides practical trade-off between quality, latency and memory efficiency for production and research RAG system.", "AI": {"tldr": "ARM\u662f\u4e00\u79cd\u52a8\u6001\u8bb0\u5fc6RAG\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u8bb0\u5fc6\u548c\u9057\u5fd8\u673a\u5236\u66ff\u4ee3\u9759\u6001\u5411\u91cf\u7d22\u5f15\uff0c\u5b9e\u73b0\u9ad8\u6548\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3002", "motivation": "\u4f20\u7edfRAG\u4f7f\u7528\u9759\u6001\u5411\u91cf\u7d22\u5f15\u5b58\u5728\u6548\u7387\u95ee\u9898\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u8bb0\u5fc6\u7ba1\u7406\u673a\u5236\u6765\u5e73\u8861\u68c0\u7d22\u8d28\u91cf\u3001\u5ef6\u8fdf\u548c\u5185\u5b58\u6548\u7387\u3002", "method": "\u91c7\u7528\u52a8\u6001\u8bb0\u5fc6\u57fa\u677f\uff0c\u57fa\u4e8e\u8ba4\u77e5\u5de9\u56fa\u548c\u9057\u5fd8\u539f\u7406\uff1a\u9891\u7e41\u68c0\u7d22\u7684\u9879\u76ee\u88ab\u5de9\u56fa\u4fdd\u62a4\uff0c\u5f88\u5c11\u4f7f\u7528\u7684\u9879\u76ee\u9010\u6e10\u8870\u51cf\u3002\u8fd8\u5b9e\u73b0\u4e86\u52a8\u6001\u9009\u62e9\u6027\u68c0\u7d22\u7b56\u7565\u548c\u53ef\u914d\u7f6e\u7684\u5d4c\u5165\u6743\u91cd\u4f18\u5316\u3002", "result": "\u5728\u8f7b\u91cf\u7ea7\u68c0\u7d22\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cARM\u4ec5\u7528\u7ea62200\u4e07\u53c2\u6570\u8fbe\u5230\u63a5\u8fd1SOTA\u6027\u80fd\uff08NDCG@5\u22480.940\uff0cRecall@5=1.000\uff09\u3002Llama 3.1+\u9759\u6001RAG\u83b7\u5f97\u6700\u9ad8\u5173\u952e\u8bcd\u8986\u76d6\u7387\uff0867.2%\uff09\uff0cGPT-4o+\u52a8\u6001\u7b56\u7565\u83b7\u5f97\u6700\u5feb\u54cd\u5e94\uff08\u5e73\u57478.2\u79d2\uff09\u3002", "conclusion": "ARM\u5728\u8d28\u91cf\u3001\u5ef6\u8fdf\u548c\u5185\u5b58\u6548\u7387\u4e4b\u95f4\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6743\u8861\uff0c\u5177\u6709\u7ade\u4e89\u6027\u51c6\u786e\u6027\u3001\u81ea\u8c03\u8282\u5185\u5b58\u589e\u957f\u548c\u53ef\u89e3\u91ca\u7684\u4fdd\u7559\u52a8\u6001\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u751f\u6210\u5668\u3002"}}
{"id": "2601.02708", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02708", "abs": "https://arxiv.org/abs/2601.02708", "authors": ["HuiJeong Son", "Hyeongu Kang", "Sunho Kim", "Subeen Ho", "SeongKu Kang", "Dongha Lee", "Susik Yoon"], "title": "CREAM: Continual Retrieval on Dynamic Streaming Corpora with Adaptive Soft Memory", "comment": "Accepted to KDD 2026", "summary": "Information retrieval (IR) in dynamic data streams is emerging as a challenging task, as shifts in data distribution degrade the performance of AI-powered IR systems. To mitigate this issue, memory-based continual learning has been widely adopted for IR. However, existing methods rely on a fixed set of queries with ground-truth relevant documents, which limits generalization to unseen queries and documents, making them impractical for real-world applications. To enable more effective learning with unseen topics of a new corpus without ground-truth labels, we propose CREAM, a self-supervised framework for memory-based continual retrieval. CREAM captures the evolving semantics of streaming queries and documents into dynamically structured soft memory and leverages it to adapt to both seen and unseen topics in an unsupervised setting. We realize this through three key techniques: fine-grained similarity estimation, regularized cluster prototyping, and stratified coreset sampling. Experiments on two benchmark datasets demonstrate that CREAM exhibits superior adaptability and retrieval accuracy, outperforming the strongest method in a label-free setting by 27.79\\% in Success@5 and 44.5\\% in Recall@10 on average, and achieving performance comparable to or even exceeding that of supervised methods.", "AI": {"tldr": "CREAM\u662f\u4e00\u4e2a\u7528\u4e8e\u52a8\u6001\u6570\u636e\u6d41\u4fe1\u606f\u68c0\u7d22\u7684\u81ea\u76d1\u7763\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8f6f\u8bb0\u5fc6\u7ed3\u6784\u9002\u5e94\u5df2\u89c1\u548c\u672a\u89c1\u4e3b\u9898\uff0c\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\u3002", "motivation": "\u52a8\u6001\u6570\u636e\u6d41\u4e2d\u7684\u5206\u5e03\u6f02\u79fb\u4f1a\u964d\u4f4eAI\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u7684\u6027\u80fd\u3002\u73b0\u6709\u57fa\u4e8e\u8bb0\u5fc6\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u67e5\u8be2\u96c6\u548c\u771f\u5b9e\u76f8\u5173\u6587\u6863\uff0c\u9650\u5236\u4e86\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u6cd5\u9002\u5e94\u73b0\u5b9e\u4e16\u754c\u672a\u89c1\u67e5\u8be2\u548c\u6587\u6863\u3002", "method": "\u63d0\u51faCREAM\u81ea\u76d1\u7763\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u76f8\u4f3c\u6027\u4f30\u8ba1\u3001\u6b63\u5219\u5316\u805a\u7c7b\u539f\u578b\u548c\u5206\u5c42\u6838\u5fc3\u96c6\u91c7\u6837\u4e09\u79cd\u5173\u952e\u6280\u672f\uff0c\u5c06\u6d41\u5f0f\u67e5\u8be2\u548c\u6587\u6863\u7684\u6f14\u5316\u8bed\u4e49\u6355\u83b7\u5230\u52a8\u6001\u7ed3\u6784\u5316\u7684\u8f6f\u8bb0\u5fc6\u4e2d\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cCREAM\u5728\u65e0\u6807\u7b7e\u8bbe\u7f6e\u4e0b\u6bd4\u6700\u5f3a\u65b9\u6cd5\u5e73\u5747\u63d0\u534727.79%\u7684Success@5\u548c44.5%\u7684Recall@10\uff0c\u6027\u80fd\u8fbe\u5230\u751a\u81f3\u8d85\u8fc7\u76d1\u7763\u65b9\u6cd5\u3002", "conclusion": "CREAM\u901a\u8fc7\u81ea\u76d1\u7763\u65b9\u5f0f\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u6570\u636e\u6d41\u4fe1\u606f\u68c0\u7d22\u4e2d\u7684\u5206\u5e03\u6f02\u79fb\u95ee\u9898\uff0c\u80fd\u591f\u9002\u5e94\u672a\u89c1\u4e3b\u9898\uff0c\u4e3a\u73b0\u5b9e\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.02750", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02750", "abs": "https://arxiv.org/abs/2601.02750", "authors": ["Bincheng Gu", "Min Gao", "Junliang Yu", "Zongwei Wang", "Zhiyi Liu", "Kai Shu", "Hongyu Zhang"], "title": "Ahead of the Spread: Agent-Driven Virtual Propagation for Early Fake News Detection", "comment": null, "summary": "Early detection of fake news is critical for mitigating its rapid dissemination on social media, which can severely undermine public trust and social stability. Recent advancements show that incorporating propagation dynamics can significantly enhance detection performance compared to previous content-only approaches. However, this remains challenging at early stages due to the absence of observable propagation signals. To address this limitation, we propose AVOID, an \\underline{a}gent-driven \\underline{v}irtual pr\\underline{o}pagat\\underline{i}on for early fake news \\underline{d}etection. AVOID reformulates early detection as a new paradigm of evidence generation, where propagation signals are actively simulated rather than passively observed. Leveraging LLM-powered agents with differentiated roles and data-driven personas, AVOID realistically constructs early-stage diffusion behaviors without requiring real propagation data. The resulting virtual trajectories provide complementary social evidence that enriches content-based detection, while a denoising-guided fusion strategy aligns simulated propagation with content semantics. Extensive experiments on benchmark datasets demonstrate that AVOID consistently outperforms state-of-the-art baselines, highlighting the effectiveness and practical value of virtual propagation augmentation for early fake news detection. The code and data are available at https://github.com/Ironychen/AVOID.", "AI": {"tldr": "AVOID\uff1a\u57fa\u4e8eLLM\u667a\u80fd\u4f53\u9a71\u52a8\u865a\u62df\u4f20\u64ad\u7684\u65e9\u671f\u5047\u65b0\u95fb\u68c0\u6d4b\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u4e3b\u52a8\u6a21\u62df\u800c\u975e\u88ab\u52a8\u89c2\u5bdf\u4f20\u64ad\u4fe1\u53f7\u6765\u751f\u6210\u8bc1\u636e\uff0c\u663e\u8457\u63d0\u5347\u65e9\u671f\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u65e9\u671f\u5047\u65b0\u95fb\u68c0\u6d4b\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u4f20\u64ad\u521d\u671f\u7f3a\u4e4f\u53ef\u89c2\u6d4b\u7684\u4f20\u64ad\u4fe1\u53f7\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5185\u5bb9\u5206\u6790\u6216\u88ab\u52a8\u7b49\u5f85\u4f20\u64ad\u6570\u636e\uff0c\u65e0\u6cd5\u5728\u65e9\u671f\u6709\u6548\u68c0\u6d4b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5728\u4f20\u64ad\u65e9\u671f\u4e3b\u52a8\u751f\u6210\u4f20\u64ad\u8bc1\u636e\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faAVOID\u6846\u67b6\uff1a1\uff09\u4f7f\u7528LLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\uff0c\u8d4b\u4e88\u4e0d\u540c\u89d2\u8272\u548c\u6570\u636e\u9a71\u52a8\u7684\u4eba\u683c\u7279\u5f81\uff1b2\uff09\u4e3b\u52a8\u6a21\u62df\u65e9\u671f\u4f20\u64ad\u884c\u4e3a\uff0c\u65e0\u9700\u771f\u5b9e\u4f20\u64ad\u6570\u636e\uff1b3\uff09\u751f\u6210\u865a\u62df\u4f20\u64ad\u8f68\u8ff9\u4f5c\u4e3a\u8865\u5145\u793e\u4ea4\u8bc1\u636e\uff1b4\uff09\u91c7\u7528\u53bb\u566a\u5f15\u5bfc\u7684\u878d\u5408\u7b56\u7565\uff0c\u5c06\u6a21\u62df\u4f20\u64ad\u4e0e\u5185\u5bb9\u8bed\u4e49\u5bf9\u9f50\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cAVOID\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u865a\u62df\u4f20\u64ad\u589e\u5f3a\u5bf9\u65e9\u671f\u5047\u65b0\u95fb\u68c0\u6d4b\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "AVOID\u5c06\u65e9\u671f\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8bc1\u636e\u751f\u6210\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u4e3b\u52a8\u6a21\u62df\u4f20\u64ad\u4fe1\u53f7\u514b\u670d\u4e86\u65e9\u671f\u9636\u6bb5\u7f3a\u4e4f\u89c2\u6d4b\u6570\u636e\u7684\u9650\u5236\uff0c\u4e3a\u65e9\u671f\u5047\u65b0\u95fb\u68c0\u6d4b\u63d0\u4f9b\u4e86\u521b\u65b0\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.02764", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02764", "abs": "https://arxiv.org/abs/2601.02764", "authors": ["Hyunji Nam", "Sejoon Oh", "Emma Kong", "Yesu Feng", "Moumita Bhattacharya"], "title": "Netflix Artwork Personalization via LLM Post-training", "comment": "6 pages", "summary": "Large language models (LLMs) have demonstrated success in various applications of user recommendation and personalization across e-commerce and entertainment. On many entertainment platforms such as Netflix, users typically interact with a wide range of titles, each represented by an artwork. Since users have diverse preferences, an artwork that appeals to one type of user may not resonate with another with different preferences. Given this user heterogeneity, our work explores the novel problem of personalized artwork recommendations according to diverse user preferences. Similar to the multi-dimensional nature of users' tastes, titles contain different themes and tones that may appeal to different viewers. For example, the same title might feature both heartfelt family drama and intense action scenes. Users who prefer romantic content may like the artwork emphasizing emotional warmth between the characters, while those who prefer action thrillers may find high-intensity action scenes more intriguing. Rather than a one-size-fits-all approach, we conduct post-training of pre-trained LLMs to make personalized artwork recommendations, selecting the most preferred visual representation of a title for each user and thereby improving user satisfaction and engagement. Our experimental results with Llama 3.1 8B models (trained on a dataset of 110K data points and evaluated on 5K held-out user-title pairs) show that the post-trained LLMs achieve 3-5\\% improvements over the Netflix production model, suggesting a promising direction for granular personalized recommendations using LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528LLM\u8fdb\u884c\u4e2a\u6027\u5316\u827a\u672f\u54c1\u63a8\u8350\uff0c\u9488\u5bf9\u7528\u6237\u5f02\u8d28\u6027\u9009\u62e9\u6700\u9002\u5408\u7528\u6237\u504f\u597d\u7684\u6807\u9898\u89c6\u89c9\u8868\u793a\uff0c\u76f8\u6bd4Netflix\u751f\u4ea7\u6a21\u578b\u63d0\u53473-5%", "motivation": "\u5728Netflix\u7b49\u5a31\u4e50\u5e73\u53f0\u4e0a\uff0c\u7528\u6237\u504f\u597d\u591a\u6837\uff0c\u540c\u4e00\u6807\u9898\u7684\u4e0d\u540c\u827a\u672f\u54c1\uff08\u89c6\u89c9\u8868\u793a\uff09\u5bf9\u4e0d\u540c\u7528\u6237\u5438\u5f15\u529b\u4e0d\u540c\u3002\u73b0\u6709\u7684\u4e00\u5200\u5207\u65b9\u6cd5\u65e0\u6cd5\u6ee1\u8db3\u4e2a\u6027\u5316\u9700\u6c42\uff0c\u9700\u8981\u6839\u636e\u7528\u6237\u504f\u597d\u63a8\u8350\u6700\u5408\u9002\u7684\u827a\u672f\u54c1\u6765\u63d0\u5347\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u53c2\u4e0e\u5ea6\u3002", "method": "\u5bf9\u9884\u8bad\u7ec3LLM\u8fdb\u884c\u540e\u8bad\u7ec3\uff0c\u4f7f\u5176\u80fd\u591f\u6839\u636e\u7528\u6237\u504f\u597d\u4e3a\u6bcf\u4e2a\u7528\u6237\u9009\u62e9\u6700\u5408\u9002\u7684\u6807\u9898\u89c6\u89c9\u8868\u793a\u3002\u4f7f\u7528Llama 3.1 8B\u6a21\u578b\uff0c\u572811\u4e07\u6570\u636e\u70b9\u4e0a\u8bad\u7ec3\uff0c\u57285\u5343\u4e2a\u4fdd\u7559\u7684\u7528\u6237-\u6807\u9898\u5bf9\u4e0a\u8bc4\u4f30\u3002", "result": "\u540e\u8bad\u7ec3\u7684LLM\u76f8\u6bd4Netflix\u751f\u4ea7\u6a21\u578b\u53d6\u5f97\u4e863-5%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u4f7f\u7528LLM\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4e2a\u6027\u5316\u63a8\u8350\u7684\u53ef\u884c\u6027\u3002", "conclusion": "LLM\u5728\u4e2a\u6027\u5316\u827a\u672f\u54c1\u63a8\u8350\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u591f\u6839\u636e\u7528\u6237\u5f02\u8d28\u6027\u63d0\u4f9b\u66f4\u7cbe\u51c6\u7684\u89c6\u89c9\u8868\u793a\u9009\u62e9\uff0c\u4e3a\u7ec6\u7c92\u5ea6\u4e2a\u6027\u5316\u63a8\u8350\u5f00\u8f9f\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2601.02807", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02807", "abs": "https://arxiv.org/abs/2601.02807", "authors": ["Sohini Roychowdhury", "Doris Wang", "Qian Ge", "Joy Mu", "Srihari Reddy"], "title": "COFFEE: COdesign Framework for Feature Enriched Embeddings in Ads-Ranking Systems", "comment": "4 pages, 5 figures, 1 table", "summary": "Diverse and enriched data sources are essential for commercial ads-recommendation models to accurately assess user interest both before and after engagement with content. While extended user-engagement histories can improve the prediction of user interests, it is equally important to embed activity sequences from multiple sources to ensure freshness of user and ad-representations, following scaling law principles. In this paper, we present a novel three-dimensional framework for enhancing user-ad representations without increasing model inference or serving complexity. The first dimension examines the impact of incorporating diverse event sources, the second considers the benefits of longer user histories, and the third focuses on enriching data with additional event attributes and multi-modal embeddings. We assess the return on investment (ROI) of our source enrichment framework by comparing organic user engagement sources, such as content viewing, with ad-impression sources. The proposed method can boost the area under curve (AUC) and the slope of scaling curves for ad-impression sources by 1.56 to 2 times compared to organic usage sources even for short online-sequence lengths of 100 to 10K. Additionally, click-through rate (CTR) prediction improves by 0.56% AUC over the baseline production ad-recommendation system when using enriched ad-impression event sources, leading to improved sequence scaling resolutions for longer and offline user-ad representations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4e09\u7ef4\u6846\u67b6\u6765\u589e\u5f3a\u5e7f\u544a\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u7528\u6237-\u5e7f\u544a\u8868\u793a\uff0c\u901a\u8fc7\u6574\u5408\u591a\u6e90\u4e8b\u4ef6\u3001\u5ef6\u957f\u7528\u6237\u5386\u53f2\u3001\u4e30\u5bcc\u4e8b\u4ef6\u5c5e\u6027\u548c\u591a\u6a21\u6001\u5d4c\u5165\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u800c\u4e0d\u589e\u52a0\u63a8\u7406\u590d\u6742\u5ea6\u3002", "motivation": "\u5546\u4e1a\u5e7f\u544a\u63a8\u8350\u6a21\u578b\u9700\u8981\u591a\u6837\u5316\u548c\u4e30\u5bcc\u7684\u6570\u636e\u6e90\u6765\u51c6\u786e\u8bc4\u4f30\u7528\u6237\u5174\u8da3\u3002\u867d\u7136\u6269\u5c55\u7684\u7528\u6237\u53c2\u4e0e\u5386\u53f2\u53ef\u4ee5\u6539\u5584\u7528\u6237\u5174\u8da3\u9884\u6d4b\uff0c\u4f46\u540c\u6837\u91cd\u8981\u7684\u662f\u5d4c\u5165\u6765\u81ea\u591a\u4e2a\u6765\u6e90\u7684\u6d3b\u52a8\u5e8f\u5217\uff0c\u4ee5\u786e\u4fdd\u7528\u6237\u548c\u5e7f\u544a\u8868\u793a\u7684\u65b0\u9c9c\u5ea6\uff0c\u9075\u5faa\u6269\u5c55\u5b9a\u5f8b\u539f\u5219\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u65b0\u9896\u7684\u4e09\u7ef4\u6846\u67b6\uff1a\u7b2c\u4e00\u7ef4\u5ea6\u8003\u5bdf\u6574\u5408\u4e0d\u540c\u4e8b\u4ef6\u6765\u6e90\u7684\u5f71\u54cd\uff1b\u7b2c\u4e8c\u7ef4\u5ea6\u8003\u8651\u66f4\u957f\u7528\u6237\u5386\u53f2\u7684\u597d\u5904\uff1b\u7b2c\u4e09\u7ef4\u5ea6\u4e13\u6ce8\u4e8e\u7528\u989d\u5916\u4e8b\u4ef6\u5c5e\u6027\u548c\u591a\u6a21\u6001\u5d4c\u5165\u6765\u4e30\u5bcc\u6570\u636e\u3002\u901a\u8fc7\u6bd4\u8f83\u6709\u673a\u7528\u6237\u53c2\u4e0e\u6765\u6e90\uff08\u5982\u5185\u5bb9\u6d4f\u89c8\uff09\u4e0e\u5e7f\u544a\u5c55\u793a\u6765\u6e90\u6765\u8bc4\u4f30\u6295\u8d44\u56de\u62a5\u7387\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5c06\u5e7f\u544a\u5c55\u793a\u6765\u6e90\u7684AUC\u548c\u6269\u5c55\u66f2\u7ebf\u659c\u7387\u63d0\u53471.56\u52302\u500d\uff08\u76f8\u6bd4\u6709\u673a\u4f7f\u7528\u6765\u6e90\uff09\uff0c\u5373\u4f7f\u5728\u7ebf\u5e8f\u5217\u957f\u5ea6\u4ec5\u4e3a100\u523010K\u3002\u4f7f\u7528\u4e30\u5bcc\u7684\u5e7f\u544a\u5c55\u793a\u4e8b\u4ef6\u6765\u6e90\u65f6\uff0cCTR\u9884\u6d4b\u7684AUC\u6bd4\u57fa\u7ebf\u751f\u4ea7\u5e7f\u544a\u63a8\u8350\u7cfb\u7edf\u63d0\u9ad80.56%\uff0c\u5e76\u4e3a\u66f4\u957f\u548c\u79bb\u7ebf\u7684\u7528\u6237-\u5e7f\u544a\u8868\u793a\u6539\u8fdb\u4e86\u5e8f\u5217\u6269\u5c55\u5206\u8fa8\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e09\u7ef4\u6e90\u4e30\u5bcc\u6846\u67b6\u80fd\u6709\u6548\u589e\u5f3a\u7528\u6237-\u5e7f\u544a\u8868\u793a\uff0c\u663e\u8457\u63d0\u5347\u5e7f\u544a\u63a8\u8350\u6027\u80fd\uff0c\u540c\u65f6\u4e0d\u589e\u52a0\u6a21\u578b\u63a8\u7406\u6216\u670d\u52a1\u590d\u6742\u5ea6\uff0c\u4e3a\u5546\u4e1a\u5e7f\u544a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6539\u8fdb\u65b9\u6848\u3002"}}
{"id": "2601.02955", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02955", "abs": "https://arxiv.org/abs/2601.02955", "authors": ["Boyang Xia", "Zhou Yu", "Zhiliang Zhu", "Hanxiao Sun", "Biyun Han", "Jun Wang", "Runnan Liu", "Wenwu Ou"], "title": "HarmonRank: Ranking-aligned Multi-objective Ensemble for Live-streaming E-commerce Recommendation", "comment": "11 pages, 5 figures", "summary": "Recommendation for live-streaming e-commerce is gaining increasing attention due to the explosive growth of the live streaming economy. Different from traditional e-commerce, live-streaming e-commerce shifts the focus from products to streamers, which requires ranking mechanism to balance both purchases and user-streamer interactions for long-term ecology. To trade off multiple objectives, a popular solution is to build an ensemble model to integrate multi-objective scores into a unified score. The ensemble model is usually supervised by multiple independent binary classification losses of all objectives. However, this paradigm suffers from two inherent limitations. First, the optimization direction of the binary classification task is misaligned with the ranking task (evaluated by AUC). Second, this paradigm overlooks the alignment between objectives, e.g., comment and buy behaviors are partially dependent which can be revealed in labels correlations. The model can achieve better trade-offs if it learns the aligned parts of ranking abilities among different objectives.\n  To mitigate these limitations, we propose a novel multi-objective ensemble framework HarmonRank to fulfill both alignment to the ranking task and alignment among objectives. For alignment to ranking, we formulate ranking metric AUC as a rank-sum problem and utilize differentiable ranking techniques for ranking-oriented optimization. For inter-objective alignment, we change the original one-step ensemble paradigm to a two-step relation-aware ensemble scheme.\n  Extensive offline experiments results on two industrial datasets and online experiments demonstrate that our approach significantly outperforms existing state-of-the-art methods. The proposed method has been fully deployed in Kuaishou's live-streaming e-commerce recommendation platform with 400 million DAUs, contributing over 2% purchase gain.", "AI": {"tldr": "\u63d0\u51faHarmonRank\u6846\u67b6\uff0c\u89e3\u51b3\u76f4\u64ad\u7535\u5546\u63a8\u8350\u4e2d\u591a\u76ee\u6807\u6392\u5e8f\u7684\u4f18\u5316\u65b9\u5411\u9519\u4f4d\u548c\u8de8\u76ee\u6807\u5bf9\u9f50\u95ee\u9898\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u6392\u5e8f\u6280\u672f\u548c\u5173\u7cfb\u611f\u77e5\u96c6\u6210\u65b9\u6848\u63d0\u5347\u6548\u679c\u3002", "motivation": "\u76f4\u64ad\u7535\u5546\u63a8\u8350\u9700\u8981\u5e73\u8861\u8d2d\u4e70\u548c\u7528\u6237-\u4e3b\u64ad\u4e92\u52a8\u7b49\u591a\u4e2a\u76ee\u6807\uff0c\u4f20\u7edf\u96c6\u6210\u6a21\u578b\u4f7f\u7528\u591a\u4e2a\u72ec\u7acb\u7684\u4e8c\u5206\u7c7b\u635f\u5931\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1) \u4e8c\u5206\u7c7b\u4efb\u52a1\u7684\u4f18\u5316\u65b9\u5411\u4e0e\u6392\u5e8f\u4efb\u52a1\uff08\u4ee5AUC\u8bc4\u4f30\uff09\u4e0d\u4e00\u81f4\uff1b2) \u5ffd\u89c6\u4e86\u76ee\u6807\u95f4\u7684\u76f8\u5173\u6027\uff08\u5982\u8bc4\u8bba\u548c\u8d2d\u4e70\u884c\u4e3a\u7684\u90e8\u5206\u4f9d\u8d56\u5173\u7cfb\uff09\u3002", "method": "\u63d0\u51faHarmonRank\u6846\u67b6\uff1a1) \u5c06\u6392\u5e8f\u6307\u6807AUC\u516c\u5f0f\u5316\u4e3a\u79e9\u548c\u95ee\u9898\uff0c\u4f7f\u7528\u53ef\u5fae\u5206\u6392\u5e8f\u6280\u672f\u8fdb\u884c\u9762\u5411\u6392\u5e8f\u7684\u4f18\u5316\uff1b2) \u5c06\u539f\u59cb\u7684\u4e00\u6b65\u96c6\u6210\u8303\u5f0f\u6539\u4e3a\u4e24\u6b65\u5173\u7cfb\u611f\u77e5\u96c6\u6210\u65b9\u6848\uff0c\u5b66\u4e60\u4e0d\u540c\u76ee\u6807\u95f4\u5bf9\u9f50\u7684\u6392\u5e8f\u80fd\u529b\u3002", "result": "\u5728\u4e24\u4e2a\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u79bb\u7ebf\u5b9e\u9a8c\u548c\u5728\u7ebf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002\u5df2\u5728\u5feb\u624b\u76f4\u64ad\u7535\u5546\u63a8\u8350\u5e73\u53f0\uff084\u4ebf\u65e5\u6d3b\u7528\u6237\uff09\u5168\u9762\u90e8\u7f72\uff0c\u5e26\u6765\u8d85\u8fc72%\u7684\u8d2d\u4e70\u589e\u76ca\u3002", "conclusion": "HarmonRank\u901a\u8fc7\u540c\u65f6\u5b9e\u73b0\u4e0e\u6392\u5e8f\u4efb\u52a1\u7684\u5bf9\u9f50\u548c\u8de8\u76ee\u6807\u95f4\u7684\u5bf9\u9f50\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u76f4\u64ad\u7535\u5546\u63a8\u8350\u4e2d\u7684\u591a\u76ee\u6807\u5e73\u8861\u95ee\u9898\uff0c\u5728\u5b9e\u9645\u5de5\u4e1a\u573a\u666f\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\u63d0\u5347\u3002"}}
{"id": "2601.02962", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02962", "abs": "https://arxiv.org/abs/2601.02962", "authors": ["Fabian Haak", "Philipp Schaer"], "title": "Auditing Search Query Suggestion Bias Through Recursive Algorithm Interrogation", "comment": null, "summary": "Despite their important role in online information search, search query suggestions have not been researched as much as most other aspects of search engines. Although reasons for this are multi-faceted, the sparseness of context and the limited data basis of up to ten suggestions per search query pose the most significant problem in identifying bias in search query suggestions. The most proven method to reduce sparseness and improve the validity of bias identification of search query suggestions so far is to consider suggestions from subsequent searches over time for the same query. This work presents a new, alternative approach to search query bias identification that includes less high-level suggestions to deepen the data basis of bias analyses. We employ recursive algorithm interrogation techniques and create suggestion trees that enable access to more subliminal search query suggestions. Based on these suggestions, we investigate topical group bias in person-related searches in the political domain.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u9012\u5f52\u7b97\u6cd5\u8be2\u95ee\u6784\u5efa\u5efa\u8bae\u6811\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u4e2d\u7684\u504f\u89c1\uff0c\u7279\u522b\u9488\u5bf9\u653f\u6cbb\u9886\u57df\u4eba\u7269\u76f8\u5173\u641c\u7d22\u7684\u4e3b\u9898\u7fa4\u4f53\u504f\u89c1\u3002", "motivation": "\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u5728\u5728\u7ebf\u4fe1\u606f\u641c\u7d22\u4e2d\u626e\u6f14\u91cd\u8981\u89d2\u8272\uff0c\u4f46\u76f8\u5173\u7814\u7a76\u8f83\u5c11\u3002\u4e3b\u8981\u6311\u6218\u5728\u4e8e\u4e0a\u4e0b\u6587\u7a00\u758f\u6027\u548c\u6570\u636e\u57fa\u7840\u6709\u9650\uff08\u6bcf\u4e2a\u67e5\u8be2\u6700\u591a10\u6761\u5efa\u8bae\uff09\uff0c\u8fd9\u4f7f\u5f97\u8bc6\u522b\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u4e2d\u7684\u504f\u89c1\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u91c7\u7528\u9012\u5f52\u7b97\u6cd5\u8be2\u95ee\u6280\u672f\uff0c\u521b\u5efa\u5efa\u8bae\u6811\uff0c\u4ece\u800c\u83b7\u53d6\u66f4\u591a\u6f5c\u610f\u8bc6\u7684\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u3002\u57fa\u4e8e\u8fd9\u4e9b\u5efa\u8bae\uff0c\u7814\u7a76\u653f\u6cbb\u9886\u57df\u4eba\u7269\u76f8\u5173\u641c\u7d22\u4e2d\u7684\u4e3b\u9898\u7fa4\u4f53\u504f\u89c1\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6df1\u5316\u504f\u89c1\u5206\u6790\u7684\u6570\u636e\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u66ff\u4ee3\u65b9\u6cd5\u6765\u8bc6\u522b\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u4e2d\u7684\u504f\u89c1\u3002", "conclusion": "\u901a\u8fc7\u9012\u5f52\u7b97\u6cd5\u8be2\u95ee\u6784\u5efa\u5efa\u8bae\u6811\u7684\u65b9\u6cd5\uff0c\u4e3a\u89e3\u51b3\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u504f\u89c1\u8bc6\u522b\u4e2d\u7684\u6570\u636e\u7a00\u758f\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u7279\u522b\u9002\u7528\u4e8e\u653f\u6cbb\u9886\u57df\u4eba\u7269\u641c\u7d22\u7684\u4e3b\u9898\u7fa4\u4f53\u504f\u89c1\u5206\u6790\u3002"}}
{"id": "2601.03153", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.03153", "abs": "https://arxiv.org/abs/2601.03153", "authors": ["Jiakai Tang", "Xu Chen", "Wen Chen", "Jian Wu", "Yuning Jiang", "Bo Zheng"], "title": "Parallel Latent Reasoning for Sequential Recommendation", "comment": null, "summary": "Capturing complex user preferences from sparse behavioral sequences remains a fundamental challenge in sequential recommendation. Recent latent reasoning methods have shown promise by extending test-time computation through multi-step reasoning, yet they exclusively rely on depth-level scaling along a single trajectory, suffering from diminishing returns as reasoning depth increases. To address this limitation, we propose \\textbf{Parallel Latent Reasoning (PLR)}, a novel framework that pioneers width-level computational scaling by exploring multiple diverse reasoning trajectories simultaneously. PLR constructs parallel reasoning streams through learnable trigger tokens in continuous latent space, preserves diversity across streams via global reasoning regularization, and adaptively synthesizes multi-stream outputs through mixture-of-reasoning-streams aggregation. Extensive experiments on three real-world datasets demonstrate that PLR substantially outperforms state-of-the-art baselines while maintaining real-time inference efficiency. Theoretical analysis further validates the effectiveness of parallel reasoning in improving generalization capability. Our work opens new avenues for enhancing reasoning capacity in sequential recommendation beyond existing depth scaling.", "AI": {"tldr": "PLR\u63d0\u51fa\u5e76\u884c\u6f5c\u5728\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u540c\u65f6\u63a2\u7d22\u591a\u4e2a\u4e0d\u540c\u63a8\u7406\u8f68\u8ff9\u6765\u89e3\u51b3\u5e8f\u5217\u63a8\u8350\u4e2d\u7a00\u758f\u884c\u4e3a\u5e8f\u5217\u7684\u590d\u6742\u7528\u6237\u504f\u597d\u5efa\u6a21\u95ee\u9898\uff0c\u76f8\u6bd4\u73b0\u6709\u4ec5\u4f9d\u8d56\u6df1\u5ea6\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5bbd\u5ea6\u7ea7\u522b\u7684\u8ba1\u7b97\u6269\u5c55\u3002", "motivation": "\u73b0\u6709\u6f5c\u5728\u63a8\u7406\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u5355\u4e00\u8f68\u8ff9\u7684\u6df1\u5ea6\u6269\u5c55\uff0c\u968f\u7740\u63a8\u7406\u6df1\u5ea6\u589e\u52a0\u4f1a\u51fa\u73b0\u6536\u76ca\u9012\u51cf\u95ee\u9898\u3002\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u66f4\u6709\u6548\u5730\u6355\u6349\u7a00\u758f\u884c\u4e3a\u5e8f\u5217\u4e2d\u7684\u590d\u6742\u7528\u6237\u504f\u597d\u3002", "method": "PLR\u6846\u67b6\u901a\u8fc7\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u53ef\u5b66\u4e60\u89e6\u53d1\u4ee4\u724c\u6784\u5efa\u5e76\u884c\u63a8\u7406\u6d41\uff0c\u901a\u8fc7\u5168\u5c40\u63a8\u7406\u6b63\u5219\u5316\u4fdd\u6301\u6d41\u95f4\u591a\u6837\u6027\uff0c\u5e76\u901a\u8fc7\u6df7\u5408\u63a8\u7406\u6d41\u805a\u5408\u81ea\u9002\u5e94\u5408\u6210\u591a\u6d41\u8f93\u51fa\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPLR\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u65f6\u63a8\u7406\u6548\u7387\u3002\u7406\u8bba\u5206\u6790\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5e76\u884c\u63a8\u7406\u5728\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "PLR\u4e3a\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u589e\u5f3a\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u6df1\u5ea6\u6269\u5c55\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5bbd\u5ea6\u7ea7\u522b\u8ba1\u7b97\u6269\u5c55\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.03211", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03211", "abs": "https://arxiv.org/abs/2601.03211", "authors": ["Yue Kang", "Zhuoyi Huang", "Benji Schussheim", "Diana Licon", "Dina Atia", "Shixing Cao", "Jacob Danovitch", "Kunho Kim", "Billy Norcilien", "Jonah Karpman", "Mahmound Sayed", "Mike Taylor", "Tao Sun", "Pavel Metrikov", "Vipul Agarwal", "Chris Quirk", "Ye-Yi Wang", "Nick Craswell", "Irene Shaffer", "Tianwei Chen", "Sulaiman Vesal", "Soundar Srinivasan"], "title": "Fine-tuning Small Language Models as Efficient Enterprise Search Relevance Labelers", "comment": null, "summary": "In enterprise search, building high-quality datasets at scale remains a central challenge due to the difficulty of acquiring labeled data. To resolve this challenge, we propose an efficient approach to fine-tune small language models (SLMs) for accurate relevance labeling, enabling high-throughput, domain-specific labeling comparable or even better in quality to that of state-of-the-art large language models (LLMs). To overcome the lack of high-quality and accessible datasets in the enterprise domain, our method leverages on synthetic data generation. Specifically, we employ an LLM to synthesize realistic enterprise queries from a seed document, apply BM25 to retrieve hard negatives, and use a teacher LLM to assign relevance scores. The resulting dataset is then distilled into an SLM, producing a compact relevance labeler. We evaluate our approach on a high-quality benchmark consisting of 923 enterprise query-document pairs annotated by trained human annotators, and show that the distilled SLM achieves agreement with human judgments on par with or better than the teacher LLM. Furthermore, our fine-tuned labeler substantially improves throughput, achieving 17 times increase while also being 19 times more cost-effective. This approach enables scalable and cost-effective relevance labeling for enterprise-scale retrieval applications, supporting rapid offline evaluation and iteration in real-world settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u751f\u6210\u548c\u5c0f\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\uff0c\u5b9e\u73b0\u4f01\u4e1a\u641c\u7d22\u4e2d\u9ad8\u8d28\u91cf\u3001\u9ad8\u541e\u5410\u91cf\u7684\u76f8\u5173\u6027\u6807\u6ce8\uff0c\u6027\u80fd\u5ab2\u7f8e\u5927\u8bed\u8a00\u6a21\u578b\u4f46\u6210\u672c\u5927\u5e45\u964d\u4f4e\u3002", "motivation": "\u4f01\u4e1a\u641c\u7d22\u4e2d\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u9762\u4e34\u6838\u5fc3\u6311\u6218\uff1a\u96be\u4ee5\u83b7\u53d6\u6807\u6ce8\u6570\u636e\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u76f8\u5173\u6027\u6807\u6ce8\uff0c\u4f46\u6210\u672c\u9ad8\u3001\u541e\u5410\u91cf\u4f4e\uff0c\u96be\u4ee5\u6ee1\u8db3\u4f01\u4e1a\u7ea7\u89c4\u6a21\u5316\u9700\u6c42\u3002", "method": "1. \u4f7f\u7528LLM\u4ece\u79cd\u5b50\u6587\u6863\u5408\u6210\u771f\u5b9e\u4f01\u4e1a\u67e5\u8be2\uff1b2. \u5e94\u7528BM25\u68c0\u7d22\u56f0\u96be\u8d1f\u6837\u672c\uff1b3. \u4f7f\u7528\u6559\u5e08LLM\u5206\u914d\u76f8\u5173\u6027\u5206\u6570\uff1b4. \u5c06\u751f\u6210\u7684\u6570\u636e\u96c6\u84b8\u998f\u5230\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u751f\u6210\u7d27\u51d1\u7684\u76f8\u5173\u6027\u6807\u6ce8\u5668\u3002", "result": "\u5728923\u4e2a\u4f01\u4e1a\u67e5\u8be2-\u6587\u6863\u5bf9\u7684\u4eba\u5de5\u6807\u6ce8\u57fa\u51c6\u4e0a\uff0c\u84b8\u998f\u540e\u7684SLM\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\u8fbe\u5230\u6216\u8d85\u8fc7\u6559\u5e08LLM\u6c34\u5e73\u3002\u541e\u5410\u91cf\u63d0\u9ad817\u500d\uff0c\u6210\u672c\u6548\u76ca\u63d0\u9ad819\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4f01\u4e1a\u7ea7\u68c0\u7d22\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u6210\u672c\u6548\u76ca\u9ad8\u7684\u76f8\u5173\u6027\u6807\u6ce8\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u5feb\u901f\u79bb\u7ebf\u8bc4\u4f30\u548c\u8fed\u4ee3\uff0c\u89e3\u51b3\u4e86\u4f01\u4e1a\u641c\u7d22\u4e2d\u6570\u636e\u6807\u6ce8\u7684\u89c4\u6a21\u5316\u96be\u9898\u3002"}}
