{"id": "2510.23913", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2510.23913", "abs": "https://arxiv.org/abs/2510.23913", "authors": ["Daniel Agassy", "Dani Dorfman", "Haim Kaplan"], "title": "Expander Decomposition for Non-Uniform Vertex Measures", "comment": null, "summary": "A $(\\phi,\\epsilon)$-expander-decomposition of a graph $G$ (with $n$ vertices\nand $m$ edges) is a partition of $V$ into clusters $V_1,\\ldots,V_k$ with\nconductance $\\Phi(G[V_i]) \\ge \\phi$, such that there are at most $\\epsilon m$\ninter-cluster edges. Such a decomposition plays a crucial role in many graph\nalgorithms. [ADK23] gave a randomized $\\tilde{O}(m)$ time algorithm for\ncomputing a $(\\phi, \\phi\\log^2 {n})$-expander decomposition.\n  In this paper we generalize this result for a broader notion of expansion.\nLet $\\mu \\in {\\mathbb{R}}_{\\ge 0 }^n$ be a vertex measure. A standard\ngeneralization of conductance of a cut $(S,\\bar{S})$ is its $\\mu$-expansion\n$\\Phi^{\\mu}_G(S,\\bar{S}) = |E(S,\\bar{S})|/\\min \\mu(S)),\\mu(\\bar{S})\\}$, where\n$\\mu(S) = \\sum_{v\\in S} \\mu(v)$. We present a randomized $\\tilde{O}(m)$ time\nalgorithm for computing a $(\\phi, \\phi \\log^2\n{n}\\left(\\frac{\\mu(V)}{m}\\right))$-expander decomposition with respect to\n$\\mu$-expansion."}
{"id": "2510.24098", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2510.24098", "abs": "https://arxiv.org/abs/2510.24098", "authors": ["Tianyu Zuo", "Xueyan Tang", "Bu Sung Lee", "Jianfei Cai"], "title": "On Competitiveness of Dynamic Replication for Distributed Data Access", "comment": "Extended version of a paper that will appear in ICDCN 2026 conference", "summary": "This paper studies an online cost optimization problem for distributed\nstorage and access. The goal is to dynamically create and delete copies of data\nobjects over time at geo-distributed servers to serve access requests and\nminimize the total storage and network cost. We revisit a recent algorithm in\nthe literature and show that it does not have a competitive ratio of $2$ as\nclaimed by constructing a counterexample. We further prove that no\ndeterministic online algorithm can achieve a competitive ratio bounded by $2$\nfor the general cost optimization problem. We develop an online algorithm and\nprove that it achieves a competitive ratio of $\\max\\{2, \\min\\{\\gamma, 3\\}\\}$,\nwhere $\\gamma$ is the max/min storage cost ratio among all servers. Examples\nare given to confirm the tightness of competitive analysis. We also empirically\nevaluate algorithms using real object access traces."}
{"id": "2510.24621", "categories": ["cs.DS", "cs.CG", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.24621", "abs": "https://arxiv.org/abs/2510.24621", "authors": ["Ziyi Fang", "Lingxiao Huang", "Runkai Yang"], "title": "Coreset for Robust Geometric Median: Eliminating Size Dependency on Outliers", "comment": "This paper has been accepted by NeurIPS 2025", "summary": "We study the robust geometric median problem in Euclidean space\n$\\mathbb{R}^d$, with a focus on coreset construction.A coreset is a compact\nsummary of a dataset $P$ of size $n$ that approximates the robust cost for all\ncenters $c$ within a multiplicative error $\\varepsilon$. Given an outlier count\n$m$, we construct a coreset of size $\\tilde{O}(\\varepsilon^{-2} \\cdot\n\\min\\{\\varepsilon^{-2}, d\\})$ when $n \\geq 4m$, eliminating the $O(m)$\ndependency present in prior work [Huang et al., 2022 & 2023]. For the special\ncase of $d = 1$, we achieve an optimal coreset size of\n$\\tilde{\\Theta}(\\varepsilon^{-1/2} + \\frac{m}{n} \\varepsilon^{-1})$, revealing\na clear separation from the vanilla case studied in [Huang et al., 2023;\nAfshani and Chris, 2024]. Our results further extend to robust\n$(k,z)$-clustering in various metric spaces, eliminating the $m$-dependence\nunder mild data assumptions. The key technical contribution is a novel\nnon-component-wise error analysis, enabling substantial reduction of outlier\ninfluence, unlike prior methods that retain them.Empirically, our algorithms\nconsistently outperform existing baselines in terms of size-accuracy tradeoffs\nand runtime, even when data assumptions are violated across a wide range of\ndatasets."}
{"id": "2510.24307", "categories": ["cs.DB", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.24307", "abs": "https://arxiv.org/abs/2510.24307", "authors": ["Shyam Jesalpura", "Shengda Zhu", "Amir Shaikhha", "Antonio Barbalace", "Boris Grot"], "title": "Odyssey: An End-to-End System for Pareto-Optimal Serverless Query Processing", "comment": null, "summary": "Running data analytics queries on serverless (FaaS) workers has been shown to\nbe cost- and performance-efficient for a variety of real-world scenarios,\nincluding intermittent query arrival patterns, sudden load spikes and\nmanagement challenges that afflict managed VM clusters. Alas, existing\nserverless data analytics works focus primarily on the serverless execution\nengine and assume the existence of a \"good\" query execution plan or rely on\nuser guidance to construct such a plan. Meanwhile, even simple analytics\nqueries on serverless have a huge space of possible plans, with vast\ndifferences in both performance and cost among plans.\n  This paper introduces Odyssey, an end-to-end serverless-native data analytics\npipeline that integrates a query planner, cost model and execution engine.\nOdyssey automatically generates and evaluates serverless query plans, utilizing\nstate space pruning heuristics and a novel search algorithm to identify\nPareto-optimal plans that balance cost and performance with low latency even\nfor complex queries. Our evaluations demonstrate that Odyssey accurately\npredicts both monetary cost and latency, and consistently outperforms AWS\nAthena on cost and/or latency."}
{"id": "2510.24190", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24190", "abs": "https://arxiv.org/abs/2510.24190", "authors": ["Hong Niu", "Jiancheng An", "Chau Yuen"], "title": "Flexible Intelligent Layered Metasurfaces for Downlink Multi-user MISO Communications", "comment": "13 pages", "summary": "Stacked intelligent metasurfaces (SIMs) have recently gained attention as a\nparadigm for wave-domain signal processing with reduced reliance on costly\nradio-frequency (RF) chains. However, conventional SIMs rely on uniform\ninter-layer spacing and require deep stacking to ensure processing capability,\nresulting in severe power attenuation in practice. To address this issue, we\npropose a flexible intelligent layered metasurface (FILM) architecture\nconsisting of two shape-controllable flexible metasurface layers. By replacing\nrigid metasurfaces with flexible ones in both layers, the transmission\ncoefficient matrix can be dynamically adjusted, significantly decreasing the\nnumber of required layers while maintaining signal processing performance.\nFirstly, we develop a two-layer FILM-assisted multi-user multiple-input\nsingle-output (MU-MISO) system, wherein we formulate a channel fitting problem\naimed at reducing the difference between the FILM-induced and target channels.\nThen, we solve this non-convex problem by employing an alternating optimization\n(AO) method, featuring closed-form phase shift updates and a gradient\ndescent-based shape optimization. Furthermore, we analyze the upper bound on\nsum-rate and the complexity of computation to provide insights into design\ntrade-offs. Finally, simulation results demonstrated that the proposed\ntransmissive FILM architecture achieves over 200\\% improvement in sum-rate and\nmore than 7 dB bit-error rate (BER) gain compared to the conventional\nseven-layer SIMs."}
{"id": "2510.23990", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.23990", "abs": "https://arxiv.org/abs/2510.23990", "authors": ["Maruf Ahmed Mridul", "Oshani Seneviratne"], "title": "Resource-Efficient LLM Application for Structured Transformation of Unstructured Financial Contracts", "comment": "5 pages, 1 figure, 2 tables", "summary": "The transformation of unstructured legal contracts into standardized,\nmachine-readable formats is essential for automating financial workflows. The\nCommon Domain Model (CDM) provides a standardized framework for this purpose,\nbut converting complex legal documents like Credit Support Annexes (CSAs) into\nCDM representations remains a significant challenge. In this paper, we present\nan extension of the CDMizer framework, a template-driven solution that ensures\nsyntactic correctness and adherence to the CDM schema during contract-to-CDM\nconversion. We apply this extended framework to a real-world task, comparing\nits performance with a benchmark developed by the International Swaps and\nDerivatives Association (ISDA) for CSA clause extraction. Our results show that\nCDMizer, when integrated with a significantly smaller, open-source Large\nLanguage Model (LLM), achieves competitive performance in terms of accuracy and\nefficiency against larger, proprietary models. This work underscores the\npotential of resource-efficient solutions to automate legal contract\ntransformation, offering a cost-effective and scalable approach that can meet\nthe needs of financial institutions with constrained resources or strict data\nprivacy requirements."}
{"id": "2510.24599", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2510.24599", "abs": "https://arxiv.org/abs/2510.24599", "authors": ["Harsha Kokel", "Aamod Khatiwada", "Tejaswini Pedapati", "Haritha Ananthakrishnan", "Oktie Hassanzadeh", "Horst Samulowitz", "Kavitha Srinivas"], "title": "Evaluating Joinable Column Discovery Approaches for Context-Aware Search", "comment": "This is an Experiments and Analysis paper. The source code, data,\n  and/or other artifacts have been made available at\n  https://github.com/IBM/ContextAwareJoin", "summary": "Joinable Column Discovery is a critical challenge in automating enterprise\ndata analysis. While existing approaches focus on syntactic overlap and\nsemantic similarity, there remains limited understanding of which methods\nperform best for different data characteristics and how multiple criteria\ninfluence discovery effectiveness. We present a comprehensive experimental\nevaluation of joinable column discovery methods across diverse scenarios. Our\nstudy compares syntactic and semantic techniques on seven benchmarks covering\nrelational databases and data lakes. We analyze six key criteria -- unique\nvalues, intersection size, join size, reverse join size, value semantics, and\nmetadata semantics -- and examine how combining them through ensemble ranking\naffects performance. Our analysis reveals differences in method behavior across\ndata contexts and highlights the benefits of integrating multiple criteria for\nrobust join discovery. We provide empirical evidence on when each criterion\nmatters, compare pre-trained embedding models for semantic joins, and offer\npractical guidelines for selecting suitable methods based on dataset\ncharacteristics. Our findings show that metadata and value semantics are\ncrucial for data lakes, size-based criteria play a stronger role in relational\ndatabases, and ensemble approaches consistently outperform single-criterion\nmethods."}
{"id": "2510.24215", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24215", "abs": "https://arxiv.org/abs/2510.24215", "authors": ["Vishal Halder", "Alexandre Reiffers-Masson", "Abdeldjalil AÃ¯ssa-El-Bey", "Gugan Thoppe"], "title": "What Can Be Recovered Under Sparse Adversarial Corruption? Assumption-Free Theory for Linear Measurements", "comment": null, "summary": "Let $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ be an arbitrary, known matrix\nand $\\mathbf{e}$ a $q$-sparse adversarial vector. Given $\\mathbf{y} =\n\\mathbf{A} x^* + \\mathbf{e}$ and $q$, we seek the smallest set containing\n$x^*$-hence the one conveying maximal information about $x^*$-that is uniformly\nrecoverable from $\\mathbf{y}$ without knowing $\\mathbf{e}$. While exact\nrecovery of $x^*$ via strong (and often impractical) structural assumptions on\n$\\mathbf{A}$ or $x^*$ (for example, restricted isometry, sparsity) is well\nstudied, recoverability for arbitrary $\\mathbf{A}$ and $x^*$ remains open. Our\nmain result shows that the best that one can hope to recover is $x^* +\n\\ker(\\mathbf{U})$, where $\\mathbf{U}$ is the unique projection matrix onto the\nintersection of rowspaces of all possible submatrices of $\\mathbf{A}$ obtained\nby deleting $2q$ rows. Moreover, we prove that every $x$ that minimizes the\n$\\ell_0$-norm of $\\mathbf{y} - \\mathbf{A} x$ lies in $x^* + \\ker(\\mathbf{U})$,\nwhich then gives a constructive approach to recover this set."}
{"id": "2510.24369", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.24369", "abs": "https://arxiv.org/abs/2510.24369", "authors": ["Yutian Xiao", "Meng Yuan", "Fuzhen Zhuang", "Wei Chen", "Shukuan Wang", "Shanqi Liu", "Chao Feng", "Wenhui Yu", "Xiang Li", "Lantao Hu", "Han Li", "Zhao Zhang"], "title": "DUET: Dual Model Co-Training for Entire Space CTR Prediction", "comment": null, "summary": "The pre-ranking stage plays a pivotal role in large-scale recommender systems\nbut faces an intrinsic trade-off between model expressiveness and computational\nefficiency. Owing to the massive candidate pool and strict latency constraints,\nindustry systems often rely on lightweight two-tower architectures, which are\ncomputationally efficient yet limited in estimation capability. As a result,\nthey struggle to capture the complex synergistic and suppressive relationships\namong candidate items, which are essential for producing contextually coherent\nand diverse recommendation lists. Moreover, this simplicity further amplifies\nthe Sample Selection Bias (SSB) problem, as coarse-grained models trained on\nbiased exposure data must generalize to a much larger candidate space with\ndistinct distributions.\n  To address these issues, we propose \\textbf{DUET} (\\textbf{DU}al Model\nCo-Training for \\textbf{E}ntire Space C\\textbf{T}R Prediction), a set-wise\npre-ranking framework that achieves expressive modeling under tight\ncomputational budgets. Instead of scoring items independently, DUET performs\nset-level prediction over the entire candidate subset in a single forward pass,\nenabling information-aware interactions among candidates while amortizing the\ncomputational cost across the set. Moreover, a dual model co-training mechanism\nextends supervision to unexposed items via mutual pseudo-label refinement,\neffectively mitigating SSB. Validated through extensive offline experiments and\nonline A/B testing, DUET consistently outperforms state-of-the-art baselines\nand achieves improvements across multiple core business metrics. At present,\nDUET has been fully deployed in Kuaishou and Kuaishou Lite Apps, serving the\nmain traffic for hundreds of millions of users."}
{"id": "2510.24246", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24246", "abs": "https://arxiv.org/abs/2510.24246", "authors": ["Hiroaki Hashida", "Boya Di"], "title": "Precoding-free Hierarchical Rate-Splitting Multiple Access via Stacked Intelligent Metasurface", "comment": "Submitted to IEEE Internet of Things Journal", "summary": "Interference management is a central bottleneck in dense multi-antenna\nwireless networks. Therefore, in this study, we present a digital\nprecoding-free hierarchical rate-splitting multiple access (HRSMA) architecture\nassisted by a stacked intelligent metasurface (SIM) to achieve high spectral\nefficiency and user fairness with reduced hardware complexity. In the proposed\nsystem, the base station performs only scalar power allocation, while a\nmulti-layer SIM acts as a wave-domain processor that spatially separates users\nand mitigates interference via nonlinear wavefront reconfiguration. This design\neliminates the need for digital or hybrid precoding, drastically reducing the\nbaseband computations. A joint optimization problem is formulated to maximize\nthe minimum user rate by jointly optimizing SIM phase shifts, power allocation,\nand user grouping. To efficiently solve the resulting non-convex problem, an\nalternating optimization algorithm is developed, combining simultaneous\nperturbation stochastic approximation (SPSA) for SIM configuration and power\ncontrol with clustering-based grouping refinement. Simulation results\ndemonstrate that the proposed SIM-aided HRSMA achieves substantial gains in\nboth spectral efficiency and fairness compared to hybrid beamforming and\nnon-precoding baselines. Specifically, SIM-aided HRSMA attains comparable or\nsuperior minimum rates with significantly fewer active antennas by exploiting\nthe additional wave-domain degrees of freedom provided by multi-layer SIMs.\nThese findings highlight the potential of SIM-aided HRSMA as a low-cost,\nenergy-efficient, and scalable solution for beyond-6G networks."}
{"id": "2510.24402", "categories": ["cs.IR", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.24402", "abs": "https://arxiv.org/abs/2510.24402", "authors": ["Michail Dadopoulos", "Anestis Ladas", "Stratos Moschidis", "Ioannis Negkakis"], "title": "Metadata-Driven Retrieval-Augmented Generation for Financial Question Answering", "comment": "Preprint version submitted to the International Journal of Accounting\n  Information Systems; currently under major revision. 20 pages, 1 figure, 1\n  table", "summary": "Retrieval-Augmented Generation (RAG) struggles on long, structured financial\nfilings where relevant evidence is sparse and cross-referenced. This paper\npresents a systematic investigation of advanced metadata-driven\nRetrieval-Augmented Generation (RAG) techniques, proposing and evaluating a\nnovel, multi-stage RAG architecture that leverages LLM-generated metadata. We\nintroduce a sophisticated indexing pipeline to create contextually rich\ndocument chunks and benchmark a spectrum of enhancements, including\npre-retrieval filtering, post-retrieval reranking, and enriched embeddings,\nbenchmarked on the FinanceBench dataset. Our results reveal that while a\npowerful reranker is essential for precision, the most significant performance\ngains come from embedding chunk metadata directly with text (\"contextual\nchunks\"). Our proposed optimal architecture combines LLM-driven pre-retrieval\noptimizations with these contextual embeddings to achieve superior performance.\nAdditionally, we present a custom metadata reranker that offers a compelling,\ncost-effective alternative to commercial solutions, highlighting a practical\ntrade-off between peak performance and operational efficiency. This study\nprovides a blueprint for building robust, metadata-aware RAG systems for\nfinancial document analysis."}
{"id": "2510.24480", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24480", "abs": "https://arxiv.org/abs/2510.24480", "authors": ["Qing Xue", "Yun Lan", "Jiajia Guo", "Qianbin Chen", "Shaodan Ma"], "title": "Joint Active and Passive Beamforming with Sensing-Assisted Discrete Phase Shifts for Dual-RIS ISAC Systems", "comment": null, "summary": "Targeting the requirements of 6G, this paper investigates a semi-passive\ndual-reconfigurable intelligent surface (RIS)-assisted integrated sensing and\ncommunication (ISAC) system, tackling the max-min user\nsignal-to-interference-plus-noise ratio (SINR) problem via joint active and\npassive beamforming to enhance system performance and ensure user fairness.\nAddressing this challenge, we first utilize dual RISs for user angle estimation\nto simplify the solution process of the formulated problem, an efficient\nalternating optimization algorithm is then developed. Specifically,\nsemi-definite relaxation and the bisection method are employed to solve the\ntransmit beamforming optimization subproblem. For the RIS discrete phase\nshifts, a sensing-assisted approach is adopted to constrain the optimization\nsearch space, with two distinct low-complexity search strategies introduced for\ndifferent RIS sizes. Numerical simulation results demonstrate that the proposed\nalgorithm achieves performance close to the ideal continuous phase shift\nbenchmark, outperforms conventional discrete phase shift optimization\nalgorithms, and exhibits a significant improvement over single-RIS systems."}
{"id": "2510.24430", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.24430", "abs": "https://arxiv.org/abs/2510.24430", "authors": ["Yejin Kim", "Shaghayegh Agah", "Mayur Nankani", "Neeraj Sharma", "Feifei Peng", "Maria Peifer", "Sardar Hamidian", "H Howie Huang"], "title": "From Time and Place to Preference: LLM-Driven Geo-Temporal Context in Recommendations", "comment": null, "summary": "Most recommender systems treat timestamps as numeric or cyclical values,\noverlooking real-world context such as holidays, events, and seasonal patterns.\nWe propose a scalable framework that uses large language models (LLMs) to\ngenerate geo-temporal embeddings from only a timestamp and coarse location,\ncapturing holidays, seasonal trends, and local/global events. We then introduce\na geo-temporal embedding informativeness test as a lightweight diagnostic,\ndemonstrating on MovieLens, LastFM, and a production dataset that these\nembeddings provide predictive signal consistent with the outcomes of full model\nintegrations. Geo-temporal embeddings are incorporated into sequential models\nthrough (1) direct feature fusion with metadata embeddings or (2) an auxiliary\nloss that enforces semantic and geo-temporal alignment. Our findings highlight\nthe need for adaptive or hybrid recommendation strategies, and we release a\ncontext-enriched MovieLens dataset to support future research."}
{"id": "2510.24546", "categories": ["cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24546", "abs": "https://arxiv.org/abs/2510.24546", "authors": ["Lingyi Wang", "Rashed Shelim", "Walid Saad", "Naren Ramakrishnan"], "title": "Dual-Mind World Models: A General Framework for Learning in Dynamic Wireless Networks", "comment": null, "summary": "Despite the popularity of reinforcement learning (RL) in wireless networks,\nexisting approaches that rely on model-free RL (MFRL) and model-based RL (MBRL)\nare data inefficient and short-sighted. Such RL-based solutions cannot\ngeneralize to novel network states since they capture only statistical patterns\nrather than the underlying physics and logic from wireless data. These\nlimitations become particularly challenging in complex wireless networks with\nhigh dynamics and long-term planning requirements. To address these\nlimitations, in this paper, a novel dual-mind world model-based learning\nframework is proposed with the goal of optimizing completeness-weighted age of\ninformation (CAoI) in a challenging mmWave V2X scenario. Inspired by cognitive\npsychology, the proposed dual-mind world model encompasses a pattern-driven\nSystem 1 component and a logic-driven System 2 component to learn dynamics and\nlogic of the wireless network, and to provide long-term link scheduling over\nreliable imagined trajectories. Link scheduling is learned through end-to-end\ndifferentiable imagined trajectories with logical consistency over an extended\nhorizon rather than relying on wireless data obtained from environment\ninteractions. Moreover, through imagination rollouts, the proposed world model\ncan jointly reason network states and plan link scheduling. During intervals\nwithout observations, the proposed method remains capable of making efficient\ndecisions. Extensive experiments are conducted on a realistic simulator based\non Sionna with real-world physical channel, ray-tracing, and scene objects with\nmaterial properties. Simulation results show that the proposed world model\nachieves a significant improvement in data efficiency and achieves strong\ngeneralization and adaptation to unseen environments, compared to the\nstate-of-the-art RL baselines, and the world model approach with only System 1."}
{"id": "2510.24431", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24431", "abs": "https://arxiv.org/abs/2510.24431", "authors": ["Xiaoyu Kong", "Leheng Sheng", "Junfei Tan", "Yuxin Chen", "Jiancan Wu", "An Zhang", "Xiang Wang", "Xiangnan He"], "title": "MiniOneRec: An Open-Source Framework for Scaling Generative Recommendation", "comment": "Technical Report", "summary": "The recent success of large language models (LLMs) has renewed interest in\nwhether recommender systems can achieve similar scaling benefits. Conventional\nrecommenders, dominated by massive embedding tables, tend to plateau as\nembedding dimensions grow. In contrast, the emerging generative paradigm\nreplaces embeddings with compact Semantic ID (SID) sequences produced by\nautoregressive Transformers. Yet most industrial deployments remain\nproprietary, leaving two fundamental questions open: (1) Do the expected\nscaling laws hold on public benchmarks? (2) What is the minimal post-training\nrecipe that enables competitive performance?\n  We present MiniOneRec, to the best of our knowledge, the first fully\nopen-source generative recommendation framework, which provides an end-to-end\nworkflow spanning SID construction, supervised fine-tuning, and\nrecommendation-oriented reinforcement learning. We generate SIDs via a Residual\nQuantized VAE and post-train Qwen backbones ranging from 0.5B to 7B parameters\non the Amazon Review dataset. Our experiments reveal a consistent downward\ntrend in both training and evaluation losses with increasing model size,\nvalidating the parameter efficiency of the generative approach. To further\nenhance performance, we propose a lightweight yet effective post-training\npipeline that (1) enforces full-process SID alignment and (2) applies\nreinforcement learning with constrained decoding and hybrid rewards. Together,\nthese techniques yield significant improvements in both ranking accuracy and\ncandidate diversity."}
