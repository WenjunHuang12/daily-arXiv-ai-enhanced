{"id": "2511.00290", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.00290", "abs": "https://arxiv.org/abs/2511.00290", "authors": ["Ashwin Gerard Colaco", "Sharad Mehrotra", "Michael J De Lucia", "Kevin Hamlen", "Murat Kantarcioglu", "Latifur Khan", "Ananthram Swami", "Bhavani Thuraisingham"], "title": "NOMAD - Navigating Optimal Model Application to Datastreams", "comment": null, "summary": "NOMAD (Navigating Optimal Model Application for Datastreams) is an\nintelligent framework for data enrichment during ingestion that optimizes\nrealtime multiclass classification by dynamically constructing model chains,\ni.e ,sequences of machine learning models with varying cost-quality tradeoffs,\nselected via a utilitybased criterion. Inspired by predicate ordering\ntechniques from database query processing, NOMAD leverages cheaper models as\ninitial filters, proceeding to more expensive models only when necessary, while\nguaranteeing classification quality remains comparable to a designated role\nmodel through a formal chain safety mechanism. It employs a dynamic belief\nupdate strategy to adapt model selection based on per event predictions and\nshifting data distributions, and extends to scenarios with dependent models\nsuch as earlyexit DNNs and stacking ensembles. Evaluation across multiple\ndatasets demonstrates that NOMAD achieves significant computational savings\ncompared to static and naive approaches while maintaining classification\nquality comparable to that achieved by the most accurate (and often the most\nexpensive) model.", "AI": {"tldr": "NOMAD\u662f\u4e00\u4e2a\u667a\u80fd\u6570\u636e\u6d41\u5904\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u6784\u5efa\u6a21\u578b\u94fe\u6765\u4f18\u5316\u5b9e\u65f6\u591a\u7c7b\u5206\u7c7b\uff0c\u5728\u4fdd\u8bc1\u5206\u7c7b\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5b9e\u65f6\u6570\u636e\u6d41\u5904\u7406\u4e2d\u9ad8\u8d28\u91cf\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u52a8\u6001\u9009\u62e9\u6a21\u578b\u3001\u5e73\u8861\u6210\u672c\u4e0e\u8d28\u91cf\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u52a8\u6001\u6a21\u578b\u94fe\u6784\u5efa\uff0c\u57fa\u4e8e\u6548\u7528\u6807\u51c6\u9009\u62e9\u6a21\u578b\u5e8f\u5217\uff0c\u5229\u7528\u5ec9\u4ef7\u6a21\u578b\u4f5c\u4e3a\u521d\u59cb\u8fc7\u6ee4\u5668\uff0c\u5fc5\u8981\u65f6\u624d\u4f7f\u7528\u6602\u8d35\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5f62\u5f0f\u5316\u94fe\u5b89\u5168\u673a\u5236\u4fdd\u8bc1\u5206\u7c7b\u8d28\u91cf\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cNOMAD\u76f8\u6bd4\u9759\u6001\u548c\u6734\u7d20\u65b9\u6cd5\u663e\u8457\u8282\u7701\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6700\u51c6\u786e\uff08\u901a\u5e38\u4e5f\u662f\u6700\u6602\u8d35\uff09\u6a21\u578b\u76f8\u5f53\u7684\u5206\u7c7b\u8d28\u91cf\u3002", "conclusion": "NOMAD\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5b9e\u65f6\u6570\u636e\u6d41\u5904\u7406\u4e2d\u7684\u6210\u672c-\u8d28\u91cf\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u52a8\u6001\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00414", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.00414", "abs": "https://arxiv.org/abs/2511.00414", "authors": ["Sirintra Vaiwsri", "Thilina Ranbaduge"], "title": "Embedding based Encoding Scheme for Privacy Preserving Record Linkage", "comment": "12 pages", "summary": "To discover new insights from data, there is a growing need to share\ninformation that is often held by different organisations. One key task in data\nintegration is the calculation of similarities between records in different\ndatabases to identify pairs or sets of records that correspond to the same\nreal-world entities. Due to privacy and confidentiality concerns, however, the\nowners of sensitive databases are often not allowed or willing to exchange or\nshare their data with other organisations to allow such similarity\ncalculations. Privacy-preserving record linkage (PPRL) is the process of\nmatching records that refer to the same entity across sensitive databases held\nby different organisations while ensuring no information about the entities is\nrevealed to the participating parties. In this paper, we study how embedding\nbased encoding techniques can be applied in the PPRL context to ensure the\nprivacy of the entities that are being linked. We first convert individual\nq-grams into the embedded space and then convert the embedding of a set of\nq-grams of a given record into a binary representation. The final binary\nrepresentations can be used to link records into matches and non-matches. We\nempirically evaluate our proposed encoding technique against different\nreal-world datasets. The results suggest that our proposed encoding approach\ncan provide better linkage accuracy and protect the privacy of individuals\nagainst attack compared to state-of-the-art techniques for short record values.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5d4c\u5165\u7f16\u7801\u7684\u9690\u79c1\u4fdd\u62a4\u8bb0\u5f55\u94fe\u63a5\u65b9\u6cd5\uff0c\u5c06q-gram\u8f6c\u6362\u4e3a\u5d4c\u5165\u7a7a\u95f4\uff0c\u518d\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u8868\u793a\u7528\u4e8e\u8bb0\u5f55\u5339\u914d\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u77ed\u8bb0\u5f55\u503c\u7684\u94fe\u63a5\u51c6\u786e\u6027\u3002", "motivation": "\u7531\u4e8e\u9690\u79c1\u548c\u4fdd\u5bc6\u95ee\u9898\uff0c\u654f\u611f\u6570\u636e\u5e93\u7684\u6240\u6709\u8005\u901a\u5e38\u4e0d\u613f\u610f\u4e0e\u5176\u4ed6\u7ec4\u7ec7\u4ea4\u6362\u6216\u5171\u4eab\u6570\u636e\u6765\u8fdb\u884c\u76f8\u4f3c\u6027\u8ba1\u7b97\uff0c\u56e0\u6b64\u9700\u8981\u9690\u79c1\u4fdd\u62a4\u8bb0\u5f55\u94fe\u63a5\u6280\u672f\u3002", "method": "\u9996\u5148\u5c06\u5355\u4e2aq-gram\u8f6c\u6362\u4e3a\u5d4c\u5165\u7a7a\u95f4\uff0c\u7136\u540e\u5c06\u8bb0\u5f55\u7684q-gram\u96c6\u5408\u5d4c\u5165\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u8868\u793a\uff0c\u6700\u7ec8\u4f7f\u7528\u8fd9\u4e9b\u4e8c\u8fdb\u5236\u8868\u793a\u8fdb\u884c\u8bb0\u5f55\u5339\u914d\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u6280\u672f\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u77ed\u8bb0\u5f55\u503c\u4e0a\u80fd\u63d0\u4f9b\u66f4\u597d\u7684\u94fe\u63a5\u51c6\u786e\u6027\uff0c\u5e76\u80fd\u6709\u6548\u4fdd\u62a4\u4e2a\u4eba\u9690\u79c1\u514d\u53d7\u653b\u51fb\u3002", "conclusion": "\u57fa\u4e8e\u5d4c\u5165\u7684\u7f16\u7801\u6280\u672f\u53ef\u4ee5\u5728\u9690\u79c1\u4fdd\u62a4\u8bb0\u5f55\u94fe\u63a5\u4e2d\u6709\u6548\u5e73\u8861\u9690\u79c1\u4fdd\u62a4\u548c\u94fe\u63a5\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u77ed\u8bb0\u5f55\u503c\u3002"}}
{"id": "2511.00693", "categories": ["cs.DB", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.00693", "abs": "https://arxiv.org/abs/2511.00693", "authors": ["Saba Latif", "Huma Latif", "Muhammad Rameez Ur Rahman"], "title": "Object-Centric Analysis of XES Event Logs: Integrating OCED Modeling with SPARQL Queries", "comment": "12 pages, 4 figures, PROFES2025 conference", "summary": "Object Centric Event Data (OCED) has gained attention in recent years within\nthe field of process mining. However, there are still many challenges, such as\nconnecting the XES format to object-centric approaches to enable more\ninsightful analysis. It is important for a process miner to understand the\ninsights and dependencies of events in the event log to see what is going on in\nour processes. In previous standards, the dependencies of event logs are only\nused to show events, but not their dependencies among each other and actions in\ndetail as described in OCEDO. There is more information in the event log when\nit is revealed using the OCEDO model. It becomes more understandable and easier\nto grasp the concepts and deal with the processes. This paper proposes the use\nof Object-Centric Event Data Ontology (OCEDO) to overcome the limitations of\nthe XES standard in event logs for process mining. We demonstrate how the OCEDO\napproach, integrated with SPARQL queries, can be applied to the BPIC 2013\ndataset to make the relationships between events and objects more explicit. It\ndescribes dealing with the meta descriptions of the OCEDO model on a business\nprocess challenge as an event log. It improves the completeness and readability\nof process data, suggesting that object-centric modeling allows for richer\nanalyses than traditional approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u5bf9\u8c61\u4e2d\u5fc3\u4e8b\u4ef6\u6570\u636e\u672c\u4f53(OCEDO)\u6765\u514b\u670dXES\u6807\u51c6\u5728\u6d41\u7a0b\u6316\u6398\u4e8b\u4ef6\u65e5\u5fd7\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7BPIC 2013\u6570\u636e\u96c6\u5c55\u793aOCEDO\u4e0eSPARQL\u67e5\u8be2\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u4f7f\u4e8b\u4ef6\u4e0e\u5bf9\u8c61\u95f4\u7684\u5173\u7cfb\u66f4\u52a0\u660e\u786e\u3002", "motivation": "\u4f20\u7edfXES\u683c\u5f0f\u5728\u6d41\u7a0b\u6316\u6398\u4e2d\u65e0\u6cd5\u5145\u5206\u5c55\u793a\u4e8b\u4ef6\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u548c\u8be6\u7ec6\u64cd\u4f5c\uff0cOCED\u6a21\u578b\u80fd\u591f\u63ed\u793a\u4e8b\u4ef6\u65e5\u5fd7\u4e2d\u66f4\u591a\u4fe1\u606f\uff0c\u4f7f\u6d41\u7a0b\u6982\u5ff5\u66f4\u6613\u7406\u89e3\u3002", "method": "\u91c7\u7528\u5bf9\u8c61\u4e2d\u5fc3\u4e8b\u4ef6\u6570\u636e\u672c\u4f53(OCEDO)\u65b9\u6cd5\uff0c\u7ed3\u5408SPARQL\u67e5\u8be2\u6280\u672f\uff0c\u5e94\u7528\u4e8eBPIC 2013\u6570\u636e\u96c6\uff0c\u5904\u7406OCEDO\u6a21\u578b\u7684\u5143\u63cf\u8ff0\u3002", "result": "OCEDO\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6d41\u7a0b\u6570\u636e\u7684\u5b8c\u6574\u6027\u548c\u53ef\u8bfb\u6027\uff0c\u5bf9\u8c61\u4e2d\u5fc3\u5efa\u6a21\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u80fd\u591f\u8fdb\u884c\u66f4\u4e30\u5bcc\u7684\u5206\u6790\u3002", "conclusion": "\u5bf9\u8c61\u4e2d\u5fc3\u4e8b\u4ef6\u6570\u636e\u672c\u4f53(OCEDO)\u80fd\u591f\u514b\u670dXES\u6807\u51c6\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6d41\u7a0b\u6316\u6398\u63d0\u4f9b\u66f4\u6df1\u5165\u7684\u5206\u6790\u80fd\u529b\uff0c\u4f7f\u4e8b\u4ef6\u4e0e\u5bf9\u8c61\u95f4\u7684\u5173\u7cfb\u66f4\u52a0\u660e\u786e\u3002"}}
{"id": "2511.00748", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.00748", "abs": "https://arxiv.org/abs/2511.00748", "authors": ["Yi Yang", "Jian Pei", "Jun Yang", "Jichun Xie"], "title": "Finding Non-Redundant Simpson's Paradox from Multidimensional Data", "comment": "20 pages, 7 figures", "summary": "Simpson's paradox, a long-standing statistical phenomenon, describes the\nreversal of an observed association when data are disaggregated into\nsub-populations. It has critical implications across statistics, epidemiology,\neconomics, and causal inference. Existing methods for detecting Simpson's\nparadox overlook a key issue: many paradoxes are redundant, arising from\nequivalent selections of data subsets, identical partitioning of\nsub-populations, and correlated outcome variables, which obscure essential\npatterns and inflate computational cost. In this paper, we present the first\nframework for discovering non-redundant Simpson's paradoxes. We formalize three\ntypes of redundancy - sibling child, separator, and statistic equivalence - and\nshow that redundancy forms an equivalence relation. Leveraging this insight, we\npropose a concise representation framework for systematically organizing\nredundant paradoxes and design efficient algorithms that integrate depth-first\nmaterialization of the base table with redundancy-aware paradox discovery.\nExperiments on real-world datasets and synthetic benchmarks show that redundant\nparadoxes are widespread, on some real datasets constituting over 40% of all\nparadoxes, while our algorithms scale to millions of records, reduce run time\nby up to 60%, and discover paradoxes that are structurally robust under data\nperturbation. These results demonstrate that Simpson's paradoxes can be\nefficiently identified, concisely summarized, and meaningfully interpreted in\nlarge multidimensional datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u53d1\u73b0\u975e\u5197\u4f59\u8f9b\u666e\u68ee\u6096\u8bba\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u4e09\u79cd\u5197\u4f59\u7c7b\u578b\u5e76\u8bbe\u8ba1\u9ad8\u6548\u7b97\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u8f9b\u666e\u68ee\u6096\u8bba\u68c0\u6d4b\u65b9\u6cd5\u5ffd\u89c6\u4e86\u5197\u4f59\u95ee\u9898\uff0c\u8bb8\u591a\u6096\u8bba\u6e90\u4e8e\u7b49\u6548\u7684\u6570\u636e\u5b50\u96c6\u9009\u62e9\u3001\u76f8\u540c\u5b50\u7fa4\u4f53\u5212\u5206\u548c\u76f8\u5173\u7ed3\u679c\u53d8\u91cf\uff0c\u8fd9\u63a9\u76d6\u4e86\u672c\u8d28\u6a21\u5f0f\u5e76\u589e\u52a0\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u5f62\u5f0f\u5316\u4e86\u4e09\u79cd\u5197\u4f59\u7c7b\u578b\uff08\u5144\u5f1f\u5b50\u96c6\u3001\u5206\u9694\u7b26\u548c\u7edf\u8ba1\u7b49\u4ef7\uff09\uff0c\u63d0\u51fa\u7b80\u6d01\u8868\u793a\u6846\u67b6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u7ed3\u5408\u6df1\u5ea6\u4f18\u5148\u57fa\u7840\u8868\u7269\u5316\u548c\u5197\u4f59\u611f\u77e5\u6096\u8bba\u53d1\u73b0\u7684\u9ad8\u6548\u7b97\u6cd5\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u548c\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5197\u4f59\u6096\u8bba\u666e\u904d\u5b58\u5728\uff08\u67d0\u4e9b\u771f\u5b9e\u6570\u636e\u96c6\u4e2d\u8d85\u8fc740%\uff09\uff0c\u7b97\u6cd5\u53ef\u6269\u5c55\u5230\u6570\u767e\u4e07\u6761\u8bb0\u5f55\uff0c\u8fd0\u884c\u65f6\u95f4\u51cf\u5c11\u9ad8\u8fbe60%\uff0c\u53d1\u73b0\u7684\u6096\u8bba\u5728\u6570\u636e\u6270\u52a8\u4e0b\u5177\u6709\u7ed3\u6784\u9c81\u68d2\u6027\u3002", "conclusion": "\u8f9b\u666e\u68ee\u6096\u8bba\u53ef\u4ee5\u5728\u5927\u578b\u591a\u7ef4\u6570\u636e\u96c6\u4e2d\u88ab\u9ad8\u6548\u8bc6\u522b\u3001\u7b80\u6d01\u603b\u7ed3\u548c\u6709\u610f\u4e49\u5730\u89e3\u91ca\u3002"}}
{"id": "2511.00835", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.00835", "abs": "https://arxiv.org/abs/2511.00835", "authors": ["Taikun Zhu", "Kai Jin", "Ruixi Luo", "Song Cao"], "title": "Optimal Allocations under Strongly Pigou-Dalton Criteria: Hidden Layer Structure & Efficient Combinatorial Approach", "comment": null, "summary": "We investigate optimal social welfare allocations of $m$ items to $n$ agents\nwith binary additive or submodular valuations. For binary additive valuations,\nwe prove that the set of optimal allocations coincides with the set of\nso-called \\emph{stable allocations}, as long as the employed criterion for\nevaluating social welfare is strongly Pigou-Dalton (SPD) and symmetric. Many\ncommon criteria are SPD and symmetric, such as Nash social welfare, leximax,\nleximin, Gini index, entropy, and envy sum. We also design efficient algorithms\nfor finding a stable allocation, including an $O(m^2n)$ time algorithm for the\ncase of indivisible items, and an $O(m^2n^5)$ time one for the case of\ndivisible items. The first is faster than the existing algorithms or has a\nsimpler analysis. The latter is the first combinatorial algorithm for that\nproblem. It utilizes a hidden layer partition of items and agents admitted by\nall stable allocations, and cleverly reduces the case of divisible items to the\ncase of indivisible items.\n  In addition, we show that the profiles of different optimal allocations have\na small Chebyshev distance, which is 0 for the case of divisible items under\nbinary additive valuations, and is at most 1 for the case of indivisible items\nunder binary submodular valuations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u4e8c\u5143\u52a0\u6027\u6216\u6b21\u6a21\u4f30\u503c\u4e0b\uff0c\u6700\u4f18\u793e\u4f1a\u798f\u5229\u5206\u914d\u4e0e\u7a33\u5b9a\u5206\u914d\u7684\u5173\u7cfb\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9ad8\u6548\u7b97\u6cd5\u6765\u5bfb\u627e\u7a33\u5b9a\u5206\u914d\u3002", "motivation": "\u7814\u7a76\u5728\u4e8c\u5143\u52a0\u6027\u6216\u6b21\u6a21\u4f30\u503c\u4e0b\uff0c\u5982\u4f55\u627e\u5230\u6700\u4f18\u793e\u4f1a\u798f\u5229\u5206\u914d\uff0c\u5e76\u63a2\u7d22\u5176\u4e0e\u7a33\u5b9a\u5206\u914d\u7684\u5173\u7cfb\uff0c\u4ee5\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u7b97\u6cd5\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bc1\u660e\u4e86\u5728SPD\u5bf9\u79f0\u6807\u51c6\u4e0b\uff0c\u6700\u4f18\u5206\u914d\u96c6\u4e0e\u7a33\u5b9a\u5206\u914d\u96c6\u91cd\u5408\uff1b\u8bbe\u8ba1\u4e86O(m\u00b2n)\u65f6\u95f4\u7b97\u6cd5\u5904\u7406\u4e0d\u53ef\u5206\u7269\u54c1\uff0cO(m\u00b2n\u2075)\u65f6\u95f4\u7b97\u6cd5\u5904\u7406\u53ef\u5206\u7269\u54c1\uff0c\u540e\u8005\u901a\u8fc7\u9690\u85cf\u5c42\u5212\u5206\u5c06\u53ef\u5206\u7269\u54c1\u95ee\u9898\u7b80\u5316\u4e3a\u4e0d\u53ef\u5206\u7269\u54c1\u95ee\u9898\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u6700\u4f18\u5206\u914d\u7684\u914d\u7f6e\u5177\u6709\u8f83\u5c0f\u7684\u5207\u6bd4\u96ea\u592b\u8ddd\u79bb\uff1a\u5728\u53ef\u5206\u7269\u54c1\u4e8c\u5143\u52a0\u6027\u4f30\u503c\u4e0b\u4e3a0\uff0c\u5728\u4e0d\u53ef\u5206\u7269\u54c1\u4e8c\u5143\u6b21\u6a21\u4f30\u503c\u4e0b\u6700\u591a\u4e3a1\u3002", "conclusion": "\u7a33\u5b9a\u5206\u914d\u4e0e\u6700\u4f18\u793e\u4f1a\u798f\u5229\u5206\u914d\u5728SPD\u5bf9\u79f0\u6807\u51c6\u4e0b\u7b49\u4ef7\uff0c\u4e14\u8bbe\u8ba1\u7684\u7b97\u6cd5\u5728\u6548\u7387\u548c\u7b80\u5316\u5206\u6790\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2511.00015", "categories": ["cs.DS", "cs.AI", "cs.CC"], "pdf": "https://arxiv.org/pdf/2511.00015", "abs": "https://arxiv.org/abs/2511.00015", "authors": ["Swapnoneel Roy", "Asai Asaithambi", "Debajyoti Mukhopadhyay"], "title": "Sorting by Strip Swaps is NP-Hard", "comment": "4 pages", "summary": "We show that \\emph{Sorting by Strip Swaps} (SbSS) is NP-hard by a polynomial\nreduction of \\emph{Block Sorting}. The key idea is a local gadget, a\n\\emph{cage}, that replaces every decreasing adjacency $(a_i,a_{i+1})$ by a\nguarded triple $a_i,m_i,a_{i+1}$ enclosed by guards $L_i,U_i$, so the only\ndecreasing adjacencies are the two inside the cage. Small \\emph{hinge} gadgets\ncouple adjacent cages that share an element and enforce that a strip swap that\nremoves exactly two adjacencies corresponds bijectively to a block move that\nremoves exactly one decreasing adjacency in the source permutation. This yields\na clean equivalence between exact SbSS schedules and perfect block schedules,\nestablishing NP-hardness.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u6392\u5e8f\u5e26\u6761\u4ea4\u6362\u95ee\u9898\uff08SbSS\uff09\u662fNP\u96be\u7684\uff0c\u901a\u8fc7\u5c06\u5757\u6392\u5e8f\u95ee\u9898\u591a\u9879\u5f0f\u5f52\u7ea6\u5230\u8be5\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u6392\u5e8f\u5e26\u6761\u4ea4\u6362\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u786e\u5b9a\u5176\u662f\u5426\u5c5e\u4e8eNP\u96be\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5c40\u90e8\u5c0f\u5de5\u5177\uff08\u7b3c\u5b50\uff09\u5c06\u6bcf\u4e2a\u9012\u51cf\u90bb\u63a5\u5bf9\u66ff\u6362\u4e3a\u53d7\u4fdd\u62a4\u7684\u4e09\u5143\u7ec4\uff0c\u5e76\u901a\u8fc7\u94f0\u94fe\u5c0f\u5de5\u5177\u8026\u5408\u76f8\u90bb\u7b3c\u5b50\uff0c\u5efa\u7acbSbSS\u8c03\u5ea6\u4e0e\u5b8c\u7f8e\u5757\u8c03\u5ea6\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u6392\u5e8f\u5e26\u6761\u4ea4\u6362\u95ee\u9898\u662fNP\u96be\u7684\u3002", "conclusion": "\u6392\u5e8f\u5e26\u6761\u4ea4\u6362\u95ee\u9898\u5177\u6709NP\u96be\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002"}}
{"id": "2511.00279", "categories": ["cs.MM", "cs.AI", "cs.CL", "cs.DC", "cs.LG", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.00279", "abs": "https://arxiv.org/abs/2511.00279", "authors": ["Meituan LongCat Team", "Bairui Wang", "Bayan", "Bin Xiao", "Bo Zhang", "Bolin Rong", "Borun Chen", "Chang Wan", "Chao Zhang", "Chen Huang", "Chen Chen", "Chen Chen", "Chengxu Yang", "Chengzuo Yang", "Cong Han", "Dandan Peng", "Delian Ruan", "Detai Xin", "Disong Wang", "Dongchao Yang", "Fanfan Liu", "Fengjiao Chen", "Fengyu Yang", "Gan Dong", "Gang Huang", "Gang Xu", "Guanglu Wan", "Guoqiang Tan", "Guoqiao Yu", "Haibo Qiu", "Hao Lu", "Hongbo Liu", "Hongyu Xiang", "Jiaheng Wu", "Jian Yang", "Jiaxing Liu", "Jing Huang", "Jingang Wang", "Jinrui Ding", "Juchao Jiang", "Jun Kuang", "Jun Wang", "Junhui Mei", "Ke Ding", "Kefeng Zhang", "Lei Chen", "Liang Shi", "Limeng Qiao", "Liming Zheng", "Lin Ma", "Liuyang Guo", "Liya Ma", "Luying Sun", "Man Gao", "Mengshen Zhu", "Miao Cao", "Minliang Lin", "Nuo Xu", "Peng Shi", "Qi Zhang", "Qian Fang", "Qian Wang", "Qian Yang", "Quanxiu Wang", "Rongxiang Weng", "Rongxin Guo", "Ruoxuan Liang", "Senbin Yang", "Shanbo Xu", "Shanglin Lei", "Shengze Ye", "Shimin Chen", "Shuaiqi Chen", "Shujie Hu", "Shuo Li", "Siqi Yang", "Siyu Xu", "Siyu Ren", "Song Li", "Songxiang Liu", "Tianhao Bai", "Tianye Dai", "Wei Hong", "Wei Wang", "Weixiao Zhao", "Wengang Cao", "Wenlong Zhu", "Wenlong He", "Xi Su", "Xi Nan", "Xiaohan Zhao", "Xiaohao Wang", "Xiaoyu Zhao", "Xiaoyu Wang", "Xiaoyu Li", "Xin Pan", "Xin Chen", "Xiusong Sun", "Xu Xiang", "Xudong Xing", "Xuezhi Cao", "Xunliang Cai", "Yang Yang", "Yanli Tan", "Yao Yao", "Yerui Sun", "Yi Chen", "Yifan Lu", "Yin Gong", "Yining Zhang", "Yitian Chen", "Yiyang Gan", "Yuchen Tang", "Yuchen Xie", "Yueqian Wang", "Yuewen Zheng", "Yufei Zhang", "Yufeng Zhong", "Yulei Qian", "Yuqi Peng", "Yuwei Jiang", "Zeyang Hu", "Zheng Zhang", "Zhengkun Tian", "Zhiqing Hong", "Zhixiong Zeng", "Zhuqi Mi", "Ziran Li", "Ziwen Wang", "Ziyi Zhao", "Ziyuan Zhuang", "Zizhe Zhao"], "title": "LongCat-Flash-Omni Technical Report", "comment": null, "summary": "We introduce LongCat-Flash-Omni, a state-of-the-art open-source omni-modal\nmodel with 560 billion parameters, excelling at real-time audio-visual\ninteraction. By adopting a curriculum-inspired progressive training strategy\nthat transitions from simpler to increasingly complex modality sequence\nmodeling tasks, LongCat-Flash-Omni attains comprehensive multimodal\ncapabilities while maintaining strong unimodal capability. Building upon\nLongCat-Flash, which adopts a high-performance Shortcut-connected\nMixture-of-Experts (MoE) architecture with zero-computation experts,\nLongCat-Flash-Omni integrates efficient multimodal perception and speech\nreconstruction modules. Despite its immense size of 560B parameters (with 27B\nactivated), LongCat-Flash-Omni achieves low-latency real-time audio-visual\ninteraction. For training infrastructure, we developed a modality-decoupled\nparallelism scheme specifically designed to manage the data and model\nheterogeneity inherent in large-scale multimodal training. This innovative\napproach demonstrates exceptional efficiency by sustaining over 90% of the\nthroughput achieved by text-only training. Extensive evaluations show that\nLongCat-Flash-Omni achieves state-of-the-art performance on omni-modal\nbenchmarks among open-source models. Furthermore, it delivers highly\ncompetitive results across a wide range of modality-specific tasks, including\ntext, image, and video understanding, as well as audio understanding and\ngeneration. We provide a comprehensive overview of the model architecture\ndesign, training procedures, and data strategies, and open-source the model to\nfoster future research and development in the community.", "AI": {"tldr": "LongCat-Flash-Omni\u662f\u4e00\u4e2a5600\u4ebf\u53c2\u6570\u7684\u5f00\u6e90\u5168\u6a21\u6001\u6a21\u578b\uff0c\u91c7\u7528\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u7b56\u7565\u548c\u9ad8\u6548\u7684\u591a\u6a21\u6001\u611f\u77e5\u6a21\u5757\uff0c\u5728\u4fdd\u6301\u5f3a\u5927\u5355\u6a21\u6001\u80fd\u529b\u7684\u540c\u65f6\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u5b9e\u65f6\u97f3\u89c6\u9891\u4ea4\u4e92\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u591a\u79cd\u6a21\u6001\uff08\u6587\u672c\u3001\u56fe\u50cf\u3001\u89c6\u9891\u3001\u97f3\u9891\uff09\u5e76\u5b9e\u73b0\u5b9e\u65f6\u97f3\u89c6\u9891\u4ea4\u4e92\u7684\u5927\u89c4\u6a21\u5f00\u6e90\u6a21\u578b\uff0c\u89e3\u51b3\u5927\u89c4\u6a21\u591a\u6a21\u6001\u8bad\u7ec3\u4e2d\u7684\u6570\u636e\u548c\u65b9\u6cd5\u5f02\u6784\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8bfe\u7a0b\u542f\u53d1\u7684\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u7b56\u7565\uff0c\u4ece\u7b80\u5355\u5230\u590d\u6742\u7684\u6a21\u6001\u5e8f\u5217\u5efa\u6a21\u4efb\u52a1\u8fc7\u6e21\uff1b\u57fa\u4e8eShortcut\u8fde\u63a5\u7684MoE\u67b6\u6784\uff0c\u96c6\u6210\u9ad8\u6548\u591a\u6a21\u6001\u611f\u77e5\u548c\u8bed\u97f3\u91cd\u6784\u6a21\u5757\uff1b\u5f00\u53d1\u6a21\u6001\u89e3\u8026\u5e76\u884c\u65b9\u6848\u5904\u7406\u8bad\u7ec3\u6570\u636e\u5f02\u6784\u6027\u3002", "result": "\u57285600\u4ebf\u53c2\u6570\u89c4\u6a21\u4e0b\uff08\u6fc0\u6d3b270\u4ebf\u53c2\u6570\uff09\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u5b9e\u65f6\u97f3\u89c6\u9891\u4ea4\u4e92\uff1b\u5728\u5f00\u6e90\u6a21\u578b\u4e2d\u5728\u5168\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff1b\u5728\u6587\u672c\u3001\u56fe\u50cf\u3001\u89c6\u9891\u7406\u89e3\u548c\u97f3\u9891\u7406\u89e3\u4e0e\u751f\u6210\u7b49\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "LongCat-Flash-Omni\u5c55\u793a\u4e86\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6a21\u578b\u7684\u6709\u6548\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u67b6\u6784\u548c\u8bad\u7ec3\u7b56\u7565\u5b9e\u73b0\u4e86\u5168\u9762\u7684\u591a\u6a21\u6001\u80fd\u529b\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5f00\u6e90\u57fa\u7840\u6a21\u578b\u3002"}}
{"id": "2511.00072", "categories": ["cs.IR", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00072", "abs": "https://arxiv.org/abs/2511.00072", "authors": ["Pradeep M", "Ritesh Pallod", "Satyen Abrol", "Muthu Raman", "Ian Anderson"], "title": "LookSync: Large-Scale Visual Product Search System for AI-Generated Fashion Looks", "comment": "4 pages, 5 figures. Accepted at the International Conference on Data\n  Science (IKDD CODS 2025), Demonstration Track. Demo video:\n  https://youtu.be/DZdlWmTUwjc", "summary": "Generative AI is reshaping fashion by enabling virtual looks and avatars\nmaking it essential to find real products that best match AI-generated styles.\nWe propose an end-to-end product search system that has been deployed in a\nreal-world, internet scale which ensures that AI-generated looks presented to\nusers are matched with the most visually and semantically similar products from\nthe indexed vector space. The search pipeline is composed of four key\ncomponents: query generation, vectorization, candidate retrieval, and reranking\nbased on AI-generated looks. Recommendation quality is evaluated using\nhuman-judged accuracy scores. The system currently serves more than 350,000 AI\nLooks in production per day, covering diverse product categories across global\nmarkets of over 12 million products. In our experiments, we observed that\nacross multiple annotators and categories, CLIP outperformed alternative models\nby a small relative margin of 3--7\\% in mean opinion scores. These\nimprovements, though modest in absolute numbers, resulted in noticeably better\nuser perception matches, establishing CLIP as the most reliable backbone for\nproduction deployment.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u90e8\u7f72\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u4ea7\u54c1\u641c\u7d22\u7cfb\u7edf\uff0c\u7528\u4e8e\u5c06AI\u751f\u6210\u7684\u65f6\u5c1a\u9020\u578b\u4e0e\u6700\u76f8\u4f3c\u7684\u5b9e\u4f53\u4ea7\u54c1\u8fdb\u884c\u5339\u914d\uff0c\u8be5\u7cfb\u7edf\u6bcf\u5929\u5904\u7406\u8d85\u8fc735\u4e07\u4e2aAI\u9020\u578b\uff0c\u8986\u76d61200\u4e07\u4ea7\u54c1\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5728\u65f6\u5c1a\u9886\u57df\u7684\u5e94\u7528\uff0c\u9700\u8981\u627e\u5230\u4e0eAI\u751f\u6210\u9020\u578b\u6700\u5339\u914d\u7684\u771f\u5b9e\u4ea7\u54c1\uff0c\u4ee5\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u548c\u5546\u4e1a\u4ef7\u503c\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u56db\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u67e5\u8be2\u751f\u6210\u3001\u5411\u91cf\u5316\u3001\u5019\u9009\u68c0\u7d22\u548c\u57fa\u4e8eAI\u9020\u578b\u7684\u91cd\u6392\u5e8f\uff0c\u4f7f\u7528CLIP\u6a21\u578b\u8fdb\u884c\u5411\u91cf\u8868\u793a\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0cCLIP\u6a21\u578b\u5728\u5e73\u5747\u610f\u89c1\u5206\u6570\u4e0a\u6bd4\u5176\u4ed6\u6a21\u578b\u9ad8\u51fa3-7%\uff0c\u867d\u7136\u7edd\u5bf9\u6539\u8fdb\u4e0d\u5927\uff0c\u4f46\u663e\u8457\u63d0\u5347\u4e86\u7528\u6237\u611f\u77e5\u5339\u914d\u5ea6\u3002", "conclusion": "CLIP\u88ab\u786e\u7acb\u4e3a\u751f\u4ea7\u90e8\u7f72\u4e2d\u6700\u53ef\u9760\u7684\u9aa8\u5e72\u6a21\u578b\uff0c\u80fd\u591f\u6709\u6548\u5339\u914dAI\u751f\u6210\u7684\u65f6\u5c1a\u9020\u578b\u4e0e\u771f\u5b9e\u4ea7\u54c1\u3002"}}
{"id": "2511.00377", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00377", "abs": "https://arxiv.org/abs/2511.00377", "authors": ["Xiaoling Han", "Bin Lin", "Nan Wu", "Ping Wang", "Zhenyu Na", "Miyuan Zhang"], "title": "Design of a Turbo-based Deep Semantic Autoencoder for Marine Internet of Things", "comment": null, "summary": "With the rapid growth of the global marine economy and flourishing maritime\nactivities, the marine Internet of Things (IoT) is gaining unprecedented\nmomentum. However, current marine equipment is deficient in data transmission\nefficiency and semantic comprehension. To address these issues, this paper\nproposes a novel End-to-End (E2E) coding scheme, namely the Turbo-based Deep\nSemantic Autoencoder (Turbo-DSA). The Turbo-DSA achieves joint source-channel\ncoding at the semantic level through the E2E design of transmitter and\nreceiver, while learning to adapt to environment changes. The semantic encoder\nand decoder are composed of transformer technology, which efficiently converts\nmessages into semantic vectors. These vectors are dynamically adjusted during\nneural network training according to channel characteristics and background\nknowledge base. The Turbo structure further enhances the semantic vectors.\nSpecifically, the channel encoder utilizes Turbo structure to separate semantic\nvectors, ensuring precise transmission of meaning, while the channel decoder\nemploys Turbo iterative decoding to optimize the representation of semantic\nvectors. This deep integration of the transformer and Turbo structure is\nensured by the design of the objective function, semantic extraction, and the\nentire training process. Compared with traditional Turbo coding techniques, the\nTurbo-DSA shows a faster convergence speed, thanks to its efficient processing\nof semantic vectors. Simulation results demonstrate that the Turbo-DSA\nsurpasses existing benchmarks in key performance indicators, such as bilingual\nevaluation understudy scores and sentence similarity. This is particularly\nevident under low signal-to-noise ratio conditions, where it shows superior\ntext semantic transmission efficiency and adaptability to variable marine\nchannel environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTurbo\u7ed3\u6784\u7684\u6df1\u5ea6\u8bed\u4e49\u81ea\u52a8\u7f16\u7801\u5668(Turbo-DSA)\uff0c\u7528\u4e8e\u6d77\u6d0b\u7269\u8054\u7f51\u4e2d\u7684\u7aef\u5230\u7aef\u8bed\u4e49\u901a\u4fe1\uff0c\u901a\u8fc7\u7ed3\u5408Transformer\u548cTurbo\u7f16\u7801\u6280\u672f\uff0c\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u8bed\u4e49\u4f20\u8f93\u6548\u7387\u548c\u73af\u5883\u9002\u5e94\u6027\u3002", "motivation": "\u968f\u7740\u5168\u7403\u6d77\u6d0b\u7ecf\u6d4e\u548c\u6d77\u4e8b\u6d3b\u52a8\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u6d77\u6d0b\u7269\u8054\u7f51\u9762\u4e34\u6570\u636e\u4f20\u8f93\u6548\u7387\u548c\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u8bed\u4e49\u901a\u4fe1\u65b9\u6848\u3002", "method": "\u63d0\u51faTurbo-DSA\u7aef\u5230\u7aef\u7f16\u7801\u65b9\u6848\uff0c\u4f7f\u7528Transformer\u6784\u5efa\u8bed\u4e49\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\uff0c\u5c06\u6d88\u606f\u8f6c\u6362\u4e3a\u8bed\u4e49\u5411\u91cf\uff0c\u5e76\u91c7\u7528Turbo\u7ed3\u6784\u8fdb\u884c\u4fe1\u9053\u7f16\u7801\u548c\u89e3\u7801\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u8bed\u4e49\u5411\u91cf\u8868\u793a\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cTurbo-DSA\u5728\u53cc\u8bed\u8bc4\u4f30\u66ff\u4ee3\u5206\u6570\u548c\u53e5\u5b50\u76f8\u4f3c\u5ea6\u7b49\u5173\u952e\u6307\u6807\u4e0a\u8d85\u8d8a\u73b0\u6709\u57fa\u51c6\uff0c\u7279\u522b\u662f\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6587\u672c\u8bed\u4e49\u4f20\u8f93\u6548\u7387\u548c\u6d77\u6d0b\u4fe1\u9053\u73af\u5883\u9002\u5e94\u6027\u3002", "conclusion": "Turbo-DSA\u901a\u8fc7\u6df1\u5ea6\u96c6\u6210Transformer\u548cTurbo\u7ed3\u6784\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8bed\u4e49\u7ea7\u8054\u5408\u4fe1\u6e90\u4fe1\u9053\u7f16\u7801\uff0c\u4e3a\u6d77\u6d0b\u7269\u8054\u7f51\u901a\u4fe1\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00772", "categories": ["cs.DB", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.00772", "abs": "https://arxiv.org/abs/2511.00772", "authors": ["Raymond M. Xiong", "Panyu Chen", "Tianze Dong", "Jian Lu", "Benjamin Goldstein", "Danyang Zhuo", "Anru R. Zhang"], "title": "Reliable Curation of EHR Dataset via Large Language Models under Environmental Constraints", "comment": null, "summary": "Electronic health records (EHRs) are central to modern healthcare delivery\nand research; yet, many researchers lack the database expertise necessary to\nwrite complex SQL queries or generate effective visualizations, limiting\nefficient data use and scientific discovery. To address this barrier, we\nintroduce CELEC, a large language model (LLM)-powered framework for automated\nEHR data extraction and analytics. CELEC translates natural language queries\ninto SQL using a prompting strategy that integrates schema information,\nfew-shot demonstrations, and chain-of-thought reasoning, which together improve\naccuracy and robustness. On a subset of the EHRSQL benchmark, CELEC achieves\nexecution accuracy comparable to prior systems while maintaining low latency,\ncost efficiency, and strict privacy by exposing only database metadata to the\nLLM. CELEC also adheres to strict privacy protocols: the LLM accesses only\ndatabase metadata (e.g., table and column names), while all query execution\noccurs securely within the institutional environment, ensuring that no\npatient-level data is ever transmitted to or shared with the LLM. Ablation\nstudies confirm that each component of the SQL generation pipeline,\nparticularly the few-shot demonstrations, plays a critical role in performance.\nBy lowering technical barriers and enabling medical researchers to query EHR\ndatabases directly, CELEC streamlines research workflows and accelerates\nbiomedical discovery.", "AI": {"tldr": "CELEC\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\u63d0\u53d6\u548c\u5206\u6790\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u751f\u6210SQL\uff0c\u964d\u4f4e\u533b\u7597\u7814\u7a76\u4eba\u5458\u7684\u6280\u672f\u95e8\u69db\u3002", "motivation": "\u8bb8\u591a\u7814\u7a76\u4eba\u5458\u7f3a\u4e4f\u6570\u636e\u5e93\u4e13\u4e1a\u77e5\u8bc6\u6765\u7f16\u5199\u590d\u6742SQL\u67e5\u8be2\u6216\u751f\u6210\u6709\u6548\u53ef\u89c6\u5316\uff0c\u9650\u5236\u4e86\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\u7684\u9ad8\u6548\u4f7f\u7528\u548c\u79d1\u5b66\u53d1\u73b0\u3002", "method": "\u4f7f\u7528\u63d0\u793a\u7b56\u7565\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3aSQL\uff0c\u6574\u5408\u6a21\u5f0f\u4fe1\u606f\u3001\u5c11\u6837\u672c\u6f14\u793a\u548c\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "result": "\u5728EHRSQL\u57fa\u51c6\u6d4b\u8bd5\u5b50\u96c6\u4e0a\uff0cCELEC\u5b9e\u73b0\u4e86\u4e0e\u5148\u524d\u7cfb\u7edf\u76f8\u5f53\u7684\u6267\u884c\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u3001\u6210\u672c\u6548\u76ca\u548c\u4e25\u683c\u9690\u79c1\u4fdd\u62a4\u3002", "conclusion": "CELEC\u901a\u8fc7\u964d\u4f4e\u6280\u672f\u969c\u788d\uff0c\u4f7f\u533b\u5b66\u7814\u7a76\u4eba\u5458\u80fd\u591f\u76f4\u63a5\u67e5\u8be2EHR\u6570\u636e\u5e93\uff0c\u7b80\u5316\u7814\u7a76\u6d41\u7a0b\u5e76\u52a0\u901f\u751f\u7269\u533b\u5b66\u53d1\u73b0\u3002"}}
{"id": "2511.00847", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00847", "abs": "https://arxiv.org/abs/2511.00847", "authors": ["Yuhan Cao", "Yu Wang", "Sitong Liu", "Miao Li", "Yixin Tao", "Tianxing He"], "title": "Pay for The Second-Best Service: A Game-Theoretic Approach Against Dishonest LLM Providers", "comment": "13 pages, 4 figures", "summary": "The widespread adoption of Large Language Models (LLMs) through Application\nProgramming Interfaces (APIs) induces a critical vulnerability: the potential\nfor dishonest manipulation by service providers. This manipulation can manifest\nin various forms, such as secretly substituting a proclaimed high-performance\nmodel with a low-cost alternative, or inflating responses with meaningless\ntokens to increase billing. This work tackles the issue through the lens of\nalgorithmic game theory and mechanism design. We are the first to propose a\nformal economic model for a realistic user-provider ecosystem, where a user can\niteratively delegate $T$ queries to multiple model providers, and providers can\nengage in a range of strategic behaviors. As our central contribution, we prove\nthat for a continuous strategy space and any $\\epsilon\\in(0,\\frac12)$, there\nexists an approximate incentive-compatible mechanism with an additive\napproximation ratio of $O(T^{1-\\epsilon}\\log T)$, and a guaranteed quasi-linear\nsecond-best user utility. We also prove an impossibility result, stating that\nno mechanism can guarantee an expected user utility that is asymptotically\nbetter than our mechanism. Furthermore, we demonstrate the effectiveness of our\nmechanism in simulation experiments with real-world API settings.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9LLM API\u670d\u52a1\u4e2d\u7684\u63d0\u4f9b\u5546\u6b3a\u8bc8\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u9996\u4e2a\u5f62\u5f0f\u5316\u7ecf\u6d4e\u6a21\u578b\u548c\u8fd1\u4f3c\u6fc0\u52b1\u517c\u5bb9\u673a\u5236\uff0c\u786e\u4fdd\u7528\u6237\u6548\u7528\u5e76\u9632\u6b62\u63d0\u4f9b\u5546\u64cd\u7eb5\u3002", "motivation": "LLM API\u7684\u5e7f\u6cdb\u4f7f\u7528\u5e26\u6765\u4e86\u670d\u52a1\u63d0\u4f9b\u5546\u53ef\u80fd\u8fdb\u884c\u6b3a\u8bc8\u64cd\u7eb5\u7684\u4e25\u91cd\u6f0f\u6d1e\uff0c\u5982\u79d8\u5bc6\u66ff\u6362\u6a21\u578b\u6216\u586b\u5145\u65e0\u7528\u6807\u8bb0\u6765\u589e\u52a0\u8ba1\u8d39\u3002", "method": "\u91c7\u7528\u7b97\u6cd5\u535a\u5f08\u8bba\u548c\u673a\u5236\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5efa\u7acb\u7528\u6237-\u63d0\u4f9b\u5546\u751f\u6001\u7cfb\u7edf\u6a21\u578b\uff0c\u8bbe\u8ba1\u8fd1\u4f3c\u6fc0\u52b1\u517c\u5bb9\u673a\u5236\u6765\u5904\u7406\u8fde\u7eed\u7b56\u7565\u7a7a\u95f4\u3002", "result": "\u8bc1\u660e\u4e86\u5b58\u5728\u8fd1\u4f3c\u6fc0\u52b1\u517c\u5bb9\u673a\u5236\uff0c\u5177\u6709O(T^{1-\u03f5}logT)\u7684\u52a0\u6027\u8fd1\u4f3c\u6bd4\u548c\u51c6\u7ebf\u6027\u6b21\u4f18\u7528\u6237\u6548\u7528\u4fdd\u8bc1\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u673a\u5236\u5728\u7406\u8bba\u4e0a\u548c\u5b9e\u8df5\u4e2d\u90fd\u80fd\u6709\u6548\u5e94\u5bf9LLM API\u670d\u52a1\u4e2d\u7684\u6b3a\u8bc8\u95ee\u9898\uff0c\u4e14\u65e0\u6cd5\u627e\u5230\u6bd4\u8be5\u673a\u5236\u6e10\u8fd1\u66f4\u597d\u7684\u7528\u6237\u6548\u7528\u4fdd\u8bc1\u673a\u5236\u3002"}}
{"id": "2511.00184", "categories": ["cs.DS", "cs.CC"], "pdf": "https://arxiv.org/pdf/2511.00184", "abs": "https://arxiv.org/abs/2511.00184", "authors": ["Sami Davies", "Venkatesan Guruswami", "Xuandi Ren"], "title": "Scheduling Problems with Constrained Rejections", "comment": null, "summary": "We study bicriteria versions of Makespan Minimization on Unrelated Machines\nand Santa Claus by allowing a constrained number of rejections. Given an\ninstance of Makespan Minimization on Unrelated Machines where the optimal\nmakespan for scheduling $n$ jobs on $m$ unrelated machines is $T$, (Feige and\nVondr\\'ak, 2006) gave an algorithm that schedules a $(1-1/e+10^{-180})$\nfraction of jobs in time $T$. We show the ratio can be improved to\n$0.6533>1-1/e+0.02$ if we allow makespan $3T/2$. To the best our knowledge,\nthis is the first result examining the tradeoff between makespan and the\nfraction of scheduled jobs when the makespan is not $T$ or $2T$.\n  For the Santa Claus problem (the Max-Min version of Makespan Minimization),\nthe analogous bicriteria objective was studied by (Golovin, 2005), who gave an\nalgorithm providing an allocation so a $(1-1/k)$ fraction of agents receive\nvalue at least $T/k$, for any $k \\in \\mathbb{Z}^+$ and $T$ being the optimal\nminimum value every agent can receive. We provide the first hardness result by\nshowing there are constants $\\delta,\\varepsilon>0$ such that it is NP-hard to\nfind an allocation where a $(1-\\delta)$ fraction of agents receive value at\nleast $(1-\\varepsilon) T$. To prove this hardness result, we introduce a\nbicriteria version of Set Packing, which may be of independent interest, and\nprove some algorithmic and hardness results for it. Overall, we believe these\nbicriteria scheduling problems warrant further study as they provide an\ninteresting lens to understand how robust the difficulty of the original\noptimization goal might be.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e26\u7ea6\u675f\u62d2\u7edd\u7684\u65e0\u5173\u673a\u8c03\u5ea6\u548cSanta Claus\u95ee\u9898\u7684\u53cc\u6807\u51c6\u7248\u672c\uff0c\u5728\u5141\u8bb8\u4e00\u5b9a\u6bd4\u4f8b\u4f5c\u4e1a\u88ab\u62d2\u7edd\u7684\u60c5\u51b5\u4e0b\uff0c\u6539\u8fdb\u4e86makespan\u4e0e\u8c03\u5ea6\u4f5c\u4e1a\u6bd4\u4f8b\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u5e76\u9996\u6b21\u7ed9\u51fa\u4e86Santa Claus\u95ee\u9898\u7684\u786c\u5ea6\u7ed3\u679c\u3002", "motivation": "\u7814\u7a76\u5728\u5141\u8bb8\u90e8\u5206\u4f5c\u4e1a\u88ab\u62d2\u7edd\u7684\u60c5\u51b5\u4e0b\uff0cmakespan\u6700\u5c0f\u5316\u548cSanta Claus\u95ee\u9898\u4e2d\u76ee\u6807\u503c\u4e0e\u8c03\u5ea6\u6bd4\u4f8b\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u63a2\u7d22\u539f\u59cb\u4f18\u5316\u76ee\u6807\u96be\u5ea6\u7684\u9c81\u68d2\u6027\u3002", "method": "\u5bf9\u4e8e\u65e0\u5173\u673a\u8c03\u5ea6\u95ee\u9898\uff0c\u63d0\u51fa\u6539\u8fdb\u7b97\u6cd5\u5728makespan\u4e3a3T/2\u65f6\u8c03\u5ea6\u6bd4\u4f8b\u53ef\u8fbe0.6533\uff1b\u5bf9\u4e8eSanta Claus\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165\u53cc\u6807\u51c6\u96c6\u5408\u5305\u88c5\u95ee\u9898\u5e76\u8bc1\u660e\u5176\u786c\u5ea6\u7ed3\u679c\u3002", "result": "\u6539\u8fdb\u4e86\u65e0\u5173\u673a\u8c03\u5ea6\u7684\u8c03\u5ea6\u6bd4\u4f8b\u754c\u9650\uff0c\u4ece1-1/e+10^{-180}\u63d0\u5347\u52300.6533\uff1b\u9996\u6b21\u8bc1\u660e\u4e86Santa Claus\u95ee\u9898\u5b58\u5728\u5e38\u6570\u03b4,\u03b5>0\u4f7f\u5f97\u627e\u5230(1-\u03b4)\u6bd4\u4f8b\u4ee3\u7406\u83b7\u5f97\u81f3\u5c11(1-\u03b5)T\u503c\u7684\u5206\u914d\u662fNP\u96be\u7684\u3002", "conclusion": "\u53cc\u6807\u51c6\u8c03\u5ea6\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u89e3\u539f\u59cb\u4f18\u5316\u76ee\u6807\u96be\u5ea6\u9c81\u68d2\u6027\u7684\u6709\u8da3\u89c6\u89d2\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\u6743\u8861\u5173\u7cfb\u3002"}}
{"id": "2511.00707", "categories": ["cs.MM"], "pdf": "https://arxiv.org/pdf/2511.00707", "abs": "https://arxiv.org/abs/2511.00707", "authors": ["Zoha Azimi", "Reza Farahani", "Vignesh V Menon", "Christian Timmerer"], "title": "Predicting Encoding Energy from Low-Pass Anchors for Green Video Streaming", "comment": "7 pages, 8 Figures, 4 tables, confernece paper", "summary": "Video streaming now represents the dominant share of Internet traffic, as\never-higher-resolution content is distributed across a growing range of\nheterogeneous devices to sustain user Quality of Experience (QoE). However,\nthis trend raises significant concerns about energy efficiency and carbon\nemissions, requiring methods to provide a trade-off between energy and QoE.\nThis paper proposes a lightweight energy prediction method that estimates the\nenergy consumption of high-resolution video encodings using reference encodings\ngenerated at lower resolutions (so-called anchors), eliminating the need for\nexhaustive per-segment energy measurements, a process that is infeasible at\nscale. We automatically select encoding parameters, such as resolution and\nquantization parameter (QP), to achieve substantial energy savings while\nmaintaining perceptual quality, as measured by the Video Multimethod Fusion\nAssessment (VMAF), within acceptable limits. We implement and evaluate our\napproach with the open-source VVenC encoder on 100 video sequences from the\nInter4K dataset across multiple encoding settings. Results show that, for an\naverage VMAF score reduction of only 1.68, which stays below the Just\nNoticeable Difference (JND) threshold, our method achieves 51.22% encoding\nenergy savings and 53.54% decoding energy savings compared to a scenario with\nno quality degradation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u80fd\u8017\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f4e\u5206\u8fa8\u7387\u53c2\u8003\u7f16\u7801\u9884\u6d4b\u9ad8\u5206\u8fa8\u7387\u89c6\u9891\u7f16\u7801\u7684\u80fd\u8017\uff0c\u5b9e\u73b0\u7f16\u7801\u80fd\u8017\u8282\u770151.22%\u548c\u89e3\u7801\u80fd\u8017\u8282\u770153.54%\uff0c\u540c\u65f6\u4fdd\u6301\u611f\u77e5\u8d28\u91cf\u5728\u53ef\u63a5\u53d7\u8303\u56f4\u5185\u3002", "motivation": "\u89c6\u9891\u6d41\u5a92\u4f53\u5360\u4e92\u8054\u7f51\u6d41\u91cf\u4e3b\u5bfc\u5730\u4f4d\uff0c\u9ad8\u5206\u8fa8\u7387\u5185\u5bb9\u5728\u5f02\u6784\u8bbe\u5907\u4e0a\u7684\u5206\u53d1\u5e26\u6765\u4e86\u80fd\u6e90\u6548\u7387\u548c\u78b3\u6392\u653e\u95ee\u9898\uff0c\u9700\u8981\u5728\u80fd\u6e90\u6d88\u8017\u548c\u7528\u6237\u4f53\u9a8c\u8d28\u91cf(QoE)\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002", "method": "\u4f7f\u7528\u4f4e\u5206\u8fa8\u7387\u53c2\u8003\u7f16\u7801(\u951a\u70b9)\u9884\u6d4b\u9ad8\u5206\u8fa8\u7387\u89c6\u9891\u7f16\u7801\u7684\u80fd\u8017\uff0c\u81ea\u52a8\u9009\u62e9\u7f16\u7801\u53c2\u6570(\u5982\u5206\u8fa8\u7387\u548c\u91cf\u5316\u53c2\u6570)\uff0c\u5728\u4fdd\u6301VMAF\u611f\u77e5\u8d28\u91cf\u5728\u53ef\u63a5\u53d7\u8303\u56f4\u5185\u7684\u540c\u65f6\u5b9e\u73b0\u80fd\u6e90\u8282\u7701\u3002", "result": "\u5728Inter4K\u6570\u636e\u96c6\u7684100\u4e2a\u89c6\u9891\u5e8f\u5217\u4e0a\u6d4b\u8bd5\uff0c\u5e73\u5747VMAF\u5206\u6570\u4ec5\u964d\u4f4e1.68(\u4f4e\u4e8eJND\u9608\u503c)\uff0c\u7f16\u7801\u80fd\u8017\u8282\u770151.22%\uff0c\u89e3\u7801\u80fd\u8017\u8282\u770153.54%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u80fd\u6e90-QoE\u6743\u8861\u65b9\u6848\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u80fd\u8017\u9884\u6d4b\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u80fd\u6e90\u8282\u7701\uff0c\u540c\u65f6\u7ef4\u6301\u4e86\u7528\u6237\u611f\u77e5\u8d28\u91cf\u3002"}}
{"id": "2511.00176", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00176", "abs": "https://arxiv.org/abs/2511.00176", "authors": ["Milad Sabouri", "Masoud Mansoury", "Kun Lin", "Bamshad Mobasher"], "title": "Effectiveness of LLMs in Temporal User Profiling for Recommendation", "comment": "Accepted to the IEEE International Conference on Data Mining (ICDM\n  2025), Workshop on User Modeling and Recommendation (UMRec). To appear in the\n  IEEE ICDMW 2025 proceedings", "summary": "Effectively modeling the dynamic nature of user preferences is crucial for\nenhancing recommendation accuracy and fostering transparency in recommender\nsystems. Traditional user profiling often overlooks the distinction between\ntransitory short-term interests and stable long-term preferences. This paper\nexamines the capability of leveraging Large Language Models (LLMs) to capture\nthese temporal dynamics, generating richer user representations through\ndistinct short-term and long-term textual summaries of interaction histories.\nOur observations suggest that while LLMs tend to improve recommendation quality\nin domains with more active user engagement, their benefits appear less\npronounced in sparser environments. This disparity likely stems from the\nvarying distinguishability of short-term and long-term preferences across\ndomains; the approach shows greater utility where these temporal interests are\nmore clearly separable (e.g., Movies\\&TV) compared to domains with more stable\nuser profiles (e.g., Video Games). This highlights a critical trade-off between\nenhanced performance and computational costs, suggesting context-dependent LLM\napplication. Beyond predictive capability, this LLM-driven approach inherently\nprovides an intrinsic potential for interpretability through its natural\nlanguage profiles and attention weights. This work contributes insights into\nthe practical capability and inherent interpretability of LLM-driven temporal\nuser profiling, outlining new research directions for developing adaptive and\ntransparent recommender systems.", "AI": {"tldr": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u533a\u5206\u7528\u6237\u77ed\u671f\u548c\u957f\u671f\u5174\u8da3\uff0c\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4f46\u5728\u7528\u6237\u53c2\u4e0e\u5ea6\u4e0d\u540c\u7684\u9886\u57df\u6548\u679c\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u4f20\u7edf\u7528\u6237\u753b\u50cf\u65b9\u6cd5\u5ffd\u89c6\u4e86\u77ed\u671f\u5174\u8da3\u548c\u957f\u671f\u504f\u597d\u7684\u533a\u522b\uff0c\u9700\u8981\u66f4\u597d\u5730\u5efa\u6a21\u7528\u6237\u504f\u597d\u7684\u52a8\u6001\u7279\u6027\u6765\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u7528\u6237\u4ea4\u4e92\u5386\u53f2\u4e2d\u751f\u6210\u72ec\u7acb\u7684\u77ed\u671f\u548c\u957f\u671f\u6587\u672c\u6458\u8981\uff0c\u521b\u5efa\u66f4\u4e30\u5bcc\u7684\u7528\u6237\u8868\u793a\u3002", "result": "\u5728\u7528\u6237\u53c2\u4e0e\u5ea6\u9ad8\u7684\u9886\u57df\uff08\u5982\u7535\u5f71\u7535\u89c6\uff09LLM\u80fd\u663e\u8457\u63d0\u5347\u63a8\u8350\u8d28\u91cf\uff0c\u4f46\u5728\u7a00\u758f\u73af\u5883\u4e2d\u6548\u679c\u4e0d\u660e\u663e\uff0c\u56e0\u4e3a\u4e0d\u540c\u9886\u57df\u77ed\u671f\u548c\u957f\u671f\u5174\u8da3\u7684\u53ef\u533a\u5206\u6027\u4e0d\u540c\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u65f6\u5e8f\u7528\u6237\u753b\u50cf\u5728\u63d0\u5347\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u5185\u5728\u53ef\u89e3\u91ca\u6027\uff0c\u4f46\u9700\u8981\u6839\u636e\u5177\u4f53\u5e94\u7528\u573a\u666f\u6743\u8861\u8ba1\u7b97\u6210\u672c\uff0c\u4e3a\u5f00\u53d1\u81ea\u9002\u5e94\u548c\u900f\u660e\u7684\u63a8\u8350\u7cfb\u7edf\u6307\u660e\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2511.00645", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00645", "abs": "https://arxiv.org/abs/2511.00645", "authors": ["C\u00e9cile Bouette", "Mich\u00e8le Wigger"], "title": "Multi-Sensor Distributed Hypothesis Testing in the Low-Power Regime", "comment": null, "summary": "We characterize the Stein-exponent of a distributed hypothesis testing\nscenario where two sensors transmit information through a memoryless multiple\naccess channel (MAC) subject to a sublinear input cost constraint with respect\nto the number of channel uses and where the decision center has access to an\nadditional local observation. Our main theorem provides conditions on the\nchannel and cost functions for which the Stein-exponent of this distributed\nsetup is no larger than the Stein-exponent of the local test at the decision\ncenter. Under these conditions, communication from the sensors to the decision\ncenter is thus useless in terms of Stein-exponent. The conditions are satisfied\nfor additive noise MACs with generalized Gaussian noise under a p-th moment\nconstraint (including the Gaussian channel with second-moment constraint) and\nfor the class of fully-connected (where all inputs can induce all outputs)\ndiscrete memoryless multiple-access channels (DMMACs) under arbitrary cost\nconstraints. We further show that for DMMACs that are not fully-connected, the\nStein-exponent is larger and coincides with that of a setup with zero-rate\nnoiseless communication links from either both sensors or only one sensor, as\nstudied in [1].", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u5206\u5e03\u5f0f\u5047\u8bbe\u68c0\u9a8c\u573a\u666f\u4e2d\u7684Stein\u6307\u6570\uff0c\u53d1\u73b0\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u4f20\u611f\u5668\u5230\u51b3\u7b56\u4e2d\u5fc3\u7684\u901a\u4fe1\u5bf9Stein\u6307\u6570\u6ca1\u6709\u5e2e\u52a9\u3002", "motivation": "\u7814\u7a76\u5728\u5177\u6709\u5b50\u7ebf\u6027\u8f93\u5165\u6210\u672c\u7ea6\u675f\u7684\u591a\u5740\u63a5\u5165\u4fe1\u9053\u4e0b\uff0c\u5206\u5e03\u5f0f\u5047\u8bbe\u68c0\u9a8c\u7684\u6027\u80fd\u6781\u9650\uff0c\u7279\u522b\u662f\u786e\u5b9a\u901a\u4fe1\u662f\u5426\u6709\u76ca\u4e8eStein\u6307\u6570\u3002", "method": "\u901a\u8fc7\u5206\u6790\u591a\u5740\u63a5\u5165\u4fe1\u9053\u7279\u6027\u548c\u6210\u672c\u51fd\u6570\uff0c\u63a8\u5bfcStein\u6307\u6570\u7684\u4e0a\u4e0b\u754c\uff0c\u7279\u522b\u5173\u6ce8\u5b8c\u5168\u8fde\u901a\u79bb\u6563\u591a\u5740\u63a5\u5165\u4fe1\u9053\u548c\u975e\u5b8c\u5168\u8fde\u901a\u4fe1\u9053\u7684\u60c5\u51b5\u3002", "result": "\u5bf9\u4e8e\u5b8c\u5168\u8fde\u901aDMMACs\u548c\u52a0\u6027\u9ad8\u65af\u566a\u58f0MACs\uff0c\u4f20\u611f\u5668\u901a\u4fe1\u4e0d\u80fd\u63d0\u9ad8Stein\u6307\u6570\uff1b\u5bf9\u4e8e\u975e\u5b8c\u5168\u8fde\u901aDMMACs\uff0cStein\u6307\u6570\u66f4\u9ad8\u4e14\u7b49\u4e8e\u96f6\u901f\u7387\u65e0\u566a\u58f0\u901a\u4fe1\u94fe\u8def\u7684\u6027\u80fd\u3002", "conclusion": "\u5728\u7279\u5b9a\u4fe1\u9053\u6761\u4ef6\u4e0b\uff0c\u5206\u5e03\u5f0f\u4f20\u611f\u5668\u901a\u4fe1\u5bf9\u5047\u8bbe\u68c0\u9a8c\u7684Stein\u6307\u6570\u6ca1\u6709\u589e\u76ca\uff0c\u901a\u4fe1\u662f\u65e0\u7528\u7684\uff1b\u4f46\u5728\u975e\u5b8c\u5168\u8fde\u901a\u4fe1\u9053\u4e2d\u901a\u4fe1\u80fd\u5e26\u6765\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2511.00826", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.00826", "abs": "https://arxiv.org/abs/2511.00826", "authors": ["Shatha Algarni", "Boris Glavic", "Seokki Lee", "Adriane Chapman"], "title": "Efficient Query Repair for Aggregate Constraints", "comment": "19 pages, 63 figures", "summary": "In many real-world scenarios, query results must satisfy domain-specific\nconstraints. For instance, a minimum percentage of interview candidates\nselected based on their qualifications should be female. These requirements can\nbe expressed as constraints over an arithmetic combination of aggregates\nevaluated on the result of the query. In this work, we study how to repair a\nquery to fulfill such constraints by modifying the filter predicates of the\nquery. We introduce a novel query repair technique that leverages bounds on\nsets of candidate solutions and interval arithmetic to efficiently prune the\nsearch space. We demonstrate experimentally, that our technique significantly\noutperforms baselines that consider a single candidate at a time.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u67e5\u8be2\u4fee\u590d\u6280\u672f\uff0c\u901a\u8fc7\u4fee\u6539\u67e5\u8be2\u7684\u8fc7\u6ee4\u8c13\u8bcd\u6765\u6ee1\u8db3\u9886\u57df\u7279\u5b9a\u7684\u805a\u5408\u7ea6\u675f\uff0c\u5229\u7528\u5019\u9009\u89e3\u96c6\u7684\u8fb9\u754c\u548c\u533a\u95f4\u7b97\u672f\u9ad8\u6548\u526a\u679d\u641c\u7d22\u7a7a\u95f4\u3002", "motivation": "\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\uff0c\u67e5\u8be2\u7ed3\u679c\u9700\u8981\u6ee1\u8db3\u9886\u57df\u7279\u5b9a\u7684\u7ea6\u675f\uff08\u5982\u9762\u8bd5\u5019\u9009\u4eba\u4e2d\u5973\u6027\u6bd4\u4f8b\u8981\u6c42\uff09\uff0c\u8fd9\u4e9b\u7ea6\u675f\u53ef\u8868\u793a\u4e3a\u67e5\u8be2\u7ed3\u679c\u4e0a\u805a\u5408\u8ba1\u7b97\u7684\u7b97\u672f\u7ec4\u5408\u3002", "method": "\u4f7f\u7528\u5019\u9009\u89e3\u96c6\u7684\u8fb9\u754c\u548c\u533a\u95f4\u7b97\u672f\u6765\u9ad8\u6548\u526a\u679d\u641c\u7d22\u7a7a\u95f4\uff0c\u901a\u8fc7\u4fee\u6539\u67e5\u8be2\u7684\u8fc7\u6ee4\u8c13\u8bcd\u6765\u4fee\u590d\u67e5\u8be2\u4ee5\u6ee1\u8db3\u7ea6\u675f\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u6280\u672f\u663e\u8457\u4f18\u4e8e\u6bcf\u6b21\u53ea\u8003\u8651\u5355\u4e2a\u5019\u9009\u89e3\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u67e5\u8be2\u4fee\u590d\u6280\u672f\u80fd\u6709\u6548\u5904\u7406\u805a\u5408\u7ea6\u675f\uff0c\u901a\u8fc7\u667a\u80fd\u526a\u679d\u5927\u5e45\u63d0\u5347\u641c\u7d22\u6548\u7387\u3002"}}
{"id": "2511.00986", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.00986", "abs": "https://arxiv.org/abs/2511.00986", "authors": ["Kamesh Munagala", "Qilin Ye", "Ian Zhang"], "title": "Deliberation via Matching", "comment": null, "summary": "We study deliberative social choice, where voters refine their preferences\nthrough small-group discussions before collective aggregation. We introduce a\nsimple and easily implementable deliberation-via-matching protocol: for each\npair of candidates, we form an arbitrary maximum matching among voters who\ndisagree on that pair, and each matched pair deliberates. The resulting\npreferences (individual and deliberative) are then appropriately weighted and\naggregated using the weighted uncovered set tournament rule.\n  We show that our protocol has a tight distortion bound of $3$ within the\nmetric distortion framework. This breaks the previous lower bound of $3.11$ for\ntournament rules without deliberation and matches the lower bound for\ndeterministic social choice rules without deliberation. Our result conceptually\nshows that tournament rules are just as powerful as general social choice\nrules, when the former are given the minimal added power of pairwise\ndeliberations. We prove our bounds via a novel bilinear relaxation of the\nnon-linear program capturing optimal distortion, whose vertices we can\nexplicitly enumerate, leading to an analytic proof. Loosely speaking, our key\ntechnical insight is that the distortion objective, as a function of metric\ndistances to any three alternatives, is both supermodular and convex. We\nbelieve this characterization provides a general analytical framework for\nstudying the distortion of other deliberative protocols, and may be of\nindependent interest.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5339\u914d\u8ba8\u8bba\u7684\u5ba1\u8bae\u5f0f\u793e\u4f1a\u9009\u62e9\u534f\u8bae\uff0c\u8be5\u534f\u8bae\u5728\u5ea6\u91cf\u5931\u771f\u6846\u67b6\u4e0b\u8fbe\u5230\u4e86\u7d27\u81f4\u7684\u5931\u771f\u754c\u96503\uff0c\u7a81\u7834\u4e86\u65e0\u5ba1\u8bae\u60c5\u51b5\u4e0b3.11\u7684\u4e0b\u754c\u3002", "motivation": "\u7814\u7a76\u5ba1\u8bae\u5f0f\u793e\u4f1a\u9009\u62e9\uff0c\u8ba9\u9009\u6c11\u901a\u8fc7\u5c0f\u7ec4\u8ba8\u8bba\u6765\u5b8c\u5584\u504f\u597d\uff0c\u7136\u540e\u8fdb\u884c\u96c6\u4f53\u805a\u5408\uff0c\u65e8\u5728\u63d0\u9ad8\u793e\u4f1a\u9009\u62e9\u7684\u8d28\u91cf\u3002", "method": "\u5f15\u5165\u5ba1\u8bae-\u5339\u914d\u534f\u8bae\uff1a\u5bf9\u6bcf\u5bf9\u5019\u9009\u4eba\uff0c\u5728\u610f\u89c1\u4e0d\u540c\u7684\u9009\u6c11\u4e2d\u5f62\u6210\u6700\u5927\u5339\u914d\uff0c\u5339\u914d\u5bf9\u8fdb\u884c\u5ba1\u8bae\uff0c\u7136\u540e\u4f7f\u7528\u52a0\u6743\u672a\u8986\u76d6\u96c6\u9526\u6807\u8d5b\u89c4\u5219\u805a\u5408\u504f\u597d\u3002", "result": "\u8be5\u534f\u8bae\u5728\u5ea6\u91cf\u5931\u771f\u6846\u67b6\u4e0b\u5177\u6709\u7d27\u81f4\u7684\u5931\u771f\u754c\u96503\uff0c\u7a81\u7834\u4e86\u65e0\u5ba1\u8bae\u60c5\u51b5\u4e0b3.11\u7684\u4e0b\u754c\uff0c\u5339\u914d\u4e86\u65e0\u5ba1\u8bae\u786e\u5b9a\u6027\u793e\u4f1a\u9009\u62e9\u89c4\u5219\u7684\u4e0b\u754c\u3002", "conclusion": "\u9526\u6807\u8d5b\u89c4\u5219\u5728\u83b7\u5f97\u6210\u5bf9\u5ba1\u8bae\u7684\u6700\u5c0f\u9644\u52a0\u80fd\u529b\u540e\uff0c\u4e0e\u4e00\u822c\u793e\u4f1a\u9009\u62e9\u89c4\u5219\u540c\u6837\u5f3a\u5927\uff0c\u6280\u672f\u6d1e\u5bdf\u4e3a\u5931\u771f\u76ee\u6807\u51fd\u6570\u5728\u5ea6\u91cf\u8ddd\u79bb\u4e0a\u5177\u6709\u8d85\u6a21\u6027\u548c\u51f8\u6027\u3002"}}
{"id": "2511.00254", "categories": ["cs.DS", "cs.CG"], "pdf": "https://arxiv.org/pdf/2511.00254", "abs": "https://arxiv.org/abs/2511.00254", "authors": ["Chandra Chekuri", "Guyslain Naves", "Joseph Poremba", "F. Bruce Shepherd"], "title": "Uncrossed Multiflows and Applications to Disjoint Paths", "comment": null, "summary": "A multiflow in a planar graph is uncrossed if the curves identified by its\nsupport paths do not cross in the plane. Such flows have played a role in\nprevious routing algorithms, including Schrijver's Homotopy Method and\nunsplittable flows in directed planar single-source instances. Recently\nuncrossed flows have played a key role in approximation algorithms for maximum\ndisjoint paths in fully-planar instances, where the combined supply plus demand\ngraph is planar. In the fully-planar case, any fractional multiflow can be\nconverted into one that is uncrossed, which is then exploited to find a good\nrounding of the fractional solution. We investigate finding an uncrossed\nmultiflow as a standalone algorithmic problem in general planar instances (not\nnecessarily fully-planar). We consider both a congestion model where the given\ndemands must all be routed, and a maximization model where the goal is to pack\nas much flow in the supply graph as possible (not necessarily equitably).\n  For the congestion model, we show that determining if an instance has an\nuncrossed (fractional) multiflow is NP-hard, but the problem of finding an\nintegral uncrossed flow is polytime solvable if the demands span a bounded\nnumber of faces. For the maximization model, we present a strong (almost\npolynomial) inapproximability result. Regarding integrality gaps, for\nmaximization we show that an uncrossed multiflow in a planar instance can\nalways be rounded to an integral multiflow with a constant fraction of the\noriginal value. This holds in both the edge-capacitated and node-capacitated\nsettings, and generalizes earlier bounds for fully-planar instances. In the\ncongestion model, given an uncrossed fractional multiflow, we give a rounding\nprocedure that produces an integral multiflow with edge congestion 2, which can\nbe made unsplittable with an additional additive error of the maximum demand.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5e73\u9762\u56fe\u4e2d\u65e0\u4ea4\u53c9\u591a\u6d41\u95ee\u9898\uff0c\u5206\u6790\u4e86\u62e5\u585e\u6a21\u578b\u548c\u6700\u5927\u5316\u6a21\u578b\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3001\u8fd1\u4f3c\u6027\u4ee5\u53ca\u6574\u6570\u5316\u95f4\u9699\u3002", "motivation": "\u65e0\u4ea4\u53c9\u591a\u6d41\u5728\u5148\u524d\u8def\u7531\u7b97\u6cd5\u4e2d\u53d1\u6325\u91cd\u8981\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728\u5168\u5e73\u9762\u5b9e\u4f8b\u7684\u6700\u5927\u4e0d\u76f8\u4ea4\u8def\u5f84\u8fd1\u4f3c\u7b97\u6cd5\u4e2d\u3002\u672c\u6587\u7814\u7a76\u5728\u4e00\u822c\u5e73\u9762\u5b9e\u4f8b\u4e2d\u5bfb\u627e\u65e0\u4ea4\u53c9\u591a\u6d41\u4f5c\u4e3a\u72ec\u7acb\u7b97\u6cd5\u95ee\u9898\u3002", "method": "\u8003\u8651\u4e24\u79cd\u6a21\u578b\uff1a\u62e5\u585e\u6a21\u578b\uff08\u5fc5\u987b\u8def\u7531\u6240\u6709\u9700\u6c42\uff09\u548c\u6700\u5927\u5316\u6a21\u578b\uff08\u5c3d\u53ef\u80fd\u591a\u5730\u6253\u5305\u6d41\uff09\u3002\u5206\u6790NP\u96be\u5ea6\u3001\u591a\u9879\u5f0f\u65f6\u95f4\u53ef\u89e3\u6027\u3001\u8fd1\u4f3c\u6027\u4ee5\u53ca\u6574\u6570\u5316\u95f4\u9699\u3002", "result": "\u62e5\u585e\u6a21\u578b\u4e2d\u5224\u65ad\u662f\u5426\u5b58\u5728\u65e0\u4ea4\u53c9\u591a\u6d41\u662fNP\u96be\u7684\uff0c\u4f46\u9700\u6c42\u8de8\u8d8a\u6709\u9650\u9762\u6570\u65f6\u53ef\u591a\u9879\u5f0f\u65f6\u95f4\u6c42\u89e3\u3002\u6700\u5927\u5316\u6a21\u578b\u5b58\u5728\u5f3a\u4e0d\u53ef\u8fd1\u4f3c\u6027\u3002\u65e0\u4ea4\u53c9\u591a\u6d41\u53ef\u5e38\u6570\u6bd4\u4f8b\u820d\u5165\u4e3a\u6574\u6570\u591a\u6d41\u3002", "conclusion": "\u65e0\u4ea4\u53c9\u591a\u6d41\u5728\u5e73\u9762\u56fe\u4e2d\u5177\u6709\u91cd\u8981\u7684\u7b97\u6cd5\u6027\u8d28\uff0c\u62e5\u585e\u6a21\u578b\u53ef\u820d\u5165\u4e3a\u8fb9\u62e5\u585e2\u7684\u6574\u6570\u6d41\uff0c\u6700\u5927\u5316\u6a21\u578b\u5177\u6709\u5e38\u6570\u6574\u6570\u5316\u95f4\u9699\u3002"}}
{"id": "2511.00793", "categories": ["cs.MM", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.00793", "abs": "https://arxiv.org/abs/2511.00793", "authors": ["Barathi Subramanian", "Rathinaraja Jeyaraj", "Anand Paul", "Kapilya Gangadharan"], "title": "Rhythm in the Air: Vision-based Real-Time Music Generation through Gestures", "comment": "8 pages, 7 figures", "summary": "Gesture recognition is an essential component of human-computer interaction\n(HCI), facilitating seamless interconnectivity between users and computer\nsystems without physical touch. This paper introduces an innovative application\nof vision-based dynamic gesture recognition (VDGR) for real-time music\ncomposition through gestures. To implement this application, we generate a\ncustom gesture dataset that encompasses over 15000 samples across 21 classes,\nincorporating 7 musical notes each manifesting at three distinct pitch levels.\nTo effectively deal with the modest volume of training data and to accurately\ndiscern and prioritize complex gesture sequences for music creation, we develop\na multi-layer attention-based gated recurrent unit (MLA-GRU) model, in which\ngated recurrent unit (GRU) is used to learn temporal patterns from the observed\nsequence and an attention layer is employed to focus on musically pertinent\ngesture segments. Our empirical studies demonstrate that MLA-GRU significantly\nsurpasses the classical GRU model, achieving a remarkable accuracy of 96.83%\ncompared to the baseline's 86.7%. Moreover, our approach exhibits superior\nefficiency and processing speed, which are crucial for interactive\napplications. Using our proposed system, we believe that people will interact\nwith music in a new and exciting way. It not only advances HCI experiences but\nalso highlights MLA-GRU's effectiveness in scenarios demanding swift and\nprecise gesture recognition.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9\u7684\u52a8\u6001\u624b\u52bf\u8bc6\u522b\u7cfb\u7edf\uff0c\u7528\u4e8e\u5b9e\u65f6\u97f3\u4e50\u521b\u4f5c\u3002\u901a\u8fc7\u5f00\u53d1\u591a\u5c42\u7ea7\u6ce8\u610f\u529b\u95e8\u63a7\u5faa\u73af\u5355\u5143(MLA-GRU)\u6a21\u578b\uff0c\u5728\u81ea\u5b9a\u4e49\u5305\u542b15000\u4e2a\u6837\u672c\u768421\u7c7b\u624b\u52bf\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8696.83%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u624b\u52bf\u8bc6\u522b\u662f\u4eba\u673a\u4ea4\u4e92\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u89c6\u89c9\u52a8\u6001\u624b\u52bf\u8bc6\u522b\u5b9e\u73b0\u5b9e\u65f6\u97f3\u4e50\u521b\u4f5c\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u65e0\u9700\u7269\u7406\u63a5\u89e6\u7684\u65b0\u578b\u97f3\u4e50\u4ea4\u4e92\u65b9\u5f0f\u3002", "method": "\u751f\u6210\u4e86\u5305\u542b15000\u4e2a\u6837\u672c\u300121\u4e2a\u7c7b\u522b\u7684\u624b\u52bf\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u97f3\u7b26\u5305\u542b\u4e09\u4e2a\u4e0d\u540c\u97f3\u9ad8\u3002\u5f00\u53d1\u4e86MLA-GRU\u6a21\u578b\uff0c\u4f7f\u7528GRU\u5b66\u4e60\u65f6\u95f4\u6a21\u5f0f\uff0c\u6ce8\u610f\u529b\u5c42\u805a\u7126\u97f3\u4e50\u76f8\u5173\u624b\u52bf\u7247\u6bb5\u3002", "result": "MLA-GRU\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u4f20\u7edfGRU\u6a21\u578b\uff0c\u51c6\u786e\u7387\u8fbe\u523096.83%\uff08\u57fa\u7ebf\u4e3a86.7%\uff09\uff0c\u5728\u6548\u7387\u548c\u5904\u7406\u901f\u5ea6\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u5408\u4ea4\u4e92\u5e94\u7528\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u97f3\u4e50\u4ea4\u4e92\u63d0\u4f9b\u4e86\u521b\u65b0\u65b9\u5f0f\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u4eba\u673a\u4ea4\u4e92\u4f53\u9a8c\uff0c\u8fd8\u8bc1\u660e\u4e86MLA-GRU\u5728\u9700\u8981\u5feb\u901f\u51c6\u786e\u624b\u52bf\u8bc6\u522b\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.00436", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.00436", "abs": "https://arxiv.org/abs/2511.00436", "authors": ["Doyun Choi", "Cheonwoo Lee", "Jaemin Yoo"], "title": "Simple and Behavior-Driven Augmentation for Recommendation with Rich Collaborative Signals", "comment": "10 pages. This paper is accepted at IEEE BigData 2025 (Short)", "summary": "Contrastive learning (CL) has been widely used for enhancing the performance\nof graph collaborative filtering (GCF) for personalized recommendation. Since\ndata augmentation plays a crucial role in the success of CL, previous works\nhave designed augmentation methods to remove noisy interactions between users\nand items in order to generate effective augmented views. However, the\nambiguity in defining ''noisiness'' presents a persistent risk of losing core\ninformation and generating unreliable data views, while increasing the overall\ncomplexity of augmentation. In this paper, we propose Simple Collaborative\nAugmentation for Recommendation (SCAR), a novel and intuitive augmentation\nmethod designed to maximize the effectiveness of CL for GCF. Instead of\nremoving information, SCAR leverages collaborative signals extracted from\nuser-item interactions to generate pseudo-interactions, which are then either\nadded to or used to replace existing interactions. This results in more robust\nrepresentations while avoiding the pitfalls of overly complex augmentation\nmodules. We conduct experiments on four benchmark datasets and show that SCAR\noutperforms previous CL-based GCF methods as well as other state-of-the-art\nself-supervised learning approaches across key evaluation metrics. SCAR\nexhibits strong robustness across different hyperparameter settings and is\nparticularly effective in sparse data scenarios.", "AI": {"tldr": "\u63d0\u51faSCAR\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u4f2a\u4ea4\u4e92\u800c\u975e\u5220\u9664\u4fe1\u606f\u6765\u589e\u5f3a\u56fe\u534f\u540c\u8fc7\u6ee4\u7684\u5bf9\u6bd4\u5b66\u4e60\u6548\u679c\uff0c\u5728\u7a00\u758f\u6570\u636e\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02", "motivation": "\u4f20\u7edf\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u901a\u8fc7\u5220\u9664\u566a\u58f0\u4ea4\u4e92\u6765\u751f\u6210\u589e\u5f3a\u89c6\u56fe\uff0c\u4f46\u5b9a\u4e49\"\u566a\u58f0\"\u5b58\u5728\u6a21\u7cca\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u6838\u5fc3\u4fe1\u606f\u4e22\u5931\u548c\u4e0d\u53ef\u9760\u7684\u89c6\u56fe\u751f\u6210\uff0c\u540c\u65f6\u589e\u52a0\u4e86\u589e\u5f3a\u8fc7\u7a0b\u7684\u590d\u6742\u5ea6", "method": "SCAR\u65b9\u6cd5\u4ece\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\u4e2d\u63d0\u53d6\u534f\u540c\u4fe1\u53f7\u6765\u751f\u6210\u4f2a\u4ea4\u4e92\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u4f2a\u4ea4\u4e92\u6dfb\u52a0\u5230\u73b0\u6709\u4ea4\u4e92\u4e2d\u6216\u66ff\u6362\u73b0\u6709\u4ea4\u4e92\uff0c\u4ece\u800c\u751f\u6210\u66f4\u9c81\u68d2\u7684\u8868\u793a", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSCAR\u5728\u5173\u952e\u8bc4\u4f30\u6307\u6807\u4e0a\u4f18\u4e8e\u4e4b\u524d\u7684\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u56fe\u534f\u540c\u8fc7\u6ee4\u65b9\u6cd5\u548c\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u8d85\u53c2\u6570\u8bbe\u7f6e\u4e0b\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027\uff0c\u5728\u7a00\u758f\u6570\u636e\u573a\u666f\u4e0b\u7279\u522b\u6709\u6548", "conclusion": "SCAR\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u4f2a\u4ea4\u4e92\u800c\u975e\u5220\u9664\u4fe1\u606f\u6765\u6700\u5927\u5316\u56fe\u534f\u540c\u8fc7\u6ee4\u4e2d\u5bf9\u6bd4\u5b66\u4e60\u7684\u6548\u679c\uff0c\u907f\u514d\u4e86\u590d\u6742\u589e\u5f3a\u6a21\u5757\u7684\u7f3a\u9677"}}
{"id": "2511.00766", "categories": ["cs.IT", "math.IT", "94B05, 94B35"], "pdf": "https://arxiv.org/pdf/2511.00766", "abs": "https://arxiv.org/abs/2511.00766", "authors": ["Guodong Wang", "Hongwei Liu", "Jinquan Luo"], "title": "Improved Decoding Algorithms for MDS and Almost-MDS Codesfrom Twisted GRS Codes", "comment": null, "summary": "In this paper, firstly, we study decoding of a general class of twisted\ngeneralized Reed-Solomon (TGRS) codes and provide a precise characterization of\nthe key equation for TGRS codes and propose a decoding algorithm. Secondly, we\nfurther study decoding of almost-MDS TGRS codes and provide a decoding\nalgorithm. These two decoding algorithms are more efficient in terms of\nperformance compared with the decoding algorithms presented in [Sun et al.,\nIEEE-TIT, 2024] and [Sui et al., IEEE-TIT, 2023] respectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u66f4\u9ad8\u6548\u7684\u626d\u66f2\u5e7f\u4e49\u91cc\u5fb7-\u6240\u7f57\u95e8\u7801\u89e3\u7801\u7b97\u6cd5\uff0c\u5206\u522b\u9488\u5bf9\u4e00\u822cTGRS\u7801\u548c\u51e0\u4e4eMDS TGRS\u7801\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709TGRS\u7801\u89e3\u7801\u7b97\u6cd5\u6548\u7387\u4e0d\u591f\u9ad8\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u89e3\u7801\u65b9\u6cd5\u6765\u63d0\u5347\u6027\u80fd\u3002", "method": "\u7814\u7a76TGRS\u7801\u7684\u5173\u952e\u65b9\u7a0b\u7279\u6027\uff0c\u63d0\u51fa\u9488\u5bf9\u4e00\u822cTGRS\u7801\u548c\u51e0\u4e4eMDS TGRS\u7801\u7684\u89e3\u7801\u7b97\u6cd5\u3002", "result": "\u63d0\u51fa\u7684\u4e24\u79cd\u89e3\u7801\u7b97\u6cd5\u5728\u6027\u80fd\u4e0a\u6bd4Sun\u7b49\u4eba\u548cSui\u7b49\u4eba\u7684\u65b9\u6cd5\u66f4\u9ad8\u6548\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u66f4\u9ad8\u6548\u7684TGRS\u7801\u89e3\u7801\u7b97\u6cd5\uff0c\u4e3a\u76f8\u5173\u7f16\u7801\u7406\u8bba\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u6848\u3002"}}
{"id": "2511.00855", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.00855", "abs": "https://arxiv.org/abs/2511.00855", "authors": ["Zhonggen Li", "Yougen Li", "Yifan Zhu", "Zhaoqiang Chen", "Yunjun Gao"], "title": "All-in-one Graph-based Indexing for Hybrid Search on GPUs", "comment": null, "summary": "Hybrid search has emerged as a promising paradigm to overcome the limitations\nof single-path retrieval, enhancing accuracy for applications like\nrecommendations, information retrieval, and Retrieval-Augmented Generation.\nHowever, existing methods are constrained by a trilemma: they sacrifice\nflexibility for efficiency, suffer from accuracy degradation due to separate\nretrievals, or incur prohibitive storage overhead for flexible combinations of\nretrieval paths. This paper introduces Allan-Poe, a novel All-in-one graph\nindex accelerated by GPUs for efficient hybrid search. We first analyze the\nlimitations of existing retrieval paradigms and distill key design principles\nfor an effective hybrid search index. Guided by these principles, we architect\na unified graph-based index that flexibly integrates four retrieval paths-dense\nvector, sparse vector, full-text, and knowledge graph-within a single, cohesive\nstructure. To enable efficient construction, we design a GPU-accelerated\npipeline featuring a warp-level hybrid distance kernel, RNG-IP joint pruning,\nand keyword-aware neighbor recycling. For query processing, we introduce a\ndynamic fusion framework that supports any combination of retrieval paths and\nweights without index reconstruction, leveraging logical edges from the\nknowledge graph to resolve complex multi-hop queries. Extensive experiments on\n6 real-world datasets demonstrate that Allan-Poe achieves superior end-to-end\nquery accuracy and outperforms state-of-the-art methods by 1.5-186.4x in\nthroughput, while significantly reducing storage overhead.", "AI": {"tldr": "Allan-Poe\u662f\u4e00\u4e2a\u57fa\u4e8eGPU\u52a0\u901f\u7684\u7edf\u4e00\u56fe\u7d22\u5f15\uff0c\u7528\u4e8e\u9ad8\u6548\u6df7\u5408\u641c\u7d22\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7075\u6d3b\u6027\u3001\u6548\u7387\u548c\u5b58\u50a8\u5f00\u9500\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6df7\u5408\u641c\u7d22\u65b9\u6cd5\u9762\u4e34\u4e09\u96be\u56f0\u5883\uff1a\u8981\u4e48\u727a\u7272\u7075\u6d3b\u6027\u6362\u53d6\u6548\u7387\uff0c\u8981\u4e48\u56e0\u5206\u79bb\u68c0\u7d22\u5bfc\u81f4\u7cbe\u5ea6\u4e0b\u964d\uff0c\u8981\u4e48\u4e3a\u7075\u6d3b\u7ec4\u5408\u68c0\u7d22\u8def\u5f84\u4ea7\u751f\u8fc7\u9ad8\u5b58\u50a8\u5f00\u9500\u3002", "method": "\u8bbe\u8ba1\u7edf\u4e00\u56fe\u7d22\u5f15\u6574\u5408\u56db\u79cd\u68c0\u7d22\u8def\u5f84\uff08\u7a20\u5bc6\u5411\u91cf\u3001\u7a00\u758f\u5411\u91cf\u3001\u5168\u6587\u3001\u77e5\u8bc6\u56fe\u8c31\uff09\uff0c\u91c7\u7528GPU\u52a0\u901f\u6784\u5efa\u6d41\u6c34\u7ebf\uff0c\u652f\u6301\u52a8\u6001\u878d\u5408\u6846\u67b6\u5904\u7406\u4efb\u610f\u8def\u5f84\u7ec4\u5408\u3002", "result": "\u57286\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAllan-Poe\u5728\u7aef\u5230\u7aef\u67e5\u8be2\u7cbe\u5ea6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u541e\u5410\u91cf\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u63d0\u53471.5-186.4\u500d\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5b58\u50a8\u5f00\u9500\u3002", "conclusion": "Allan-Poe\u901a\u8fc7\u7edf\u4e00\u56fe\u7d22\u5f15\u548cGPU\u52a0\u901f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6df7\u5408\u641c\u7d22\u7684\u7075\u6d3b\u6027\u4e0e\u6548\u7387\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u3001\u4fe1\u606f\u68c0\u7d22\u548cRAG\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01157", "categories": ["cs.GT", "econ.TH"], "pdf": "https://arxiv.org/pdf/2511.01157", "abs": "https://arxiv.org/abs/2511.01157", "authors": ["Ce Li", "Qianfan Zhang", "Weiqiang Zheng"], "title": "From Best Responses to Learning: Investment Efficiency in Dynamic Environment", "comment": null, "summary": "We study the welfare of a mechanism in a dynamic environment where a learning\ninvestor can make a costly investment to change her value. In many real-world\nproblems, the common assumption that the investor always makes the best\nresponses, i.e., choosing her utility-maximizing investment option, is\nunrealistic due to incomplete information in a dynamically evolving\nenvironment. To address this, we consider an investor who uses a no-regret\nonline learning algorithm to adaptively select investments through repeated\ninteractions with the environment. We analyze how the welfare guarantees of\napproximation allocation algorithms extend from static to dynamic settings when\nthe investor learns rather than best-responds, by studying the approximation\nratio for optimal welfare as a measurement of an algorithm's performance\nagainst different benchmarks in the dynamic learning environment. First, we\nshow that the approximation ratio in the static environment remains unchanged\nin the dynamic environment against the best-in-hindsight benchmark. Second, we\nprovide tight characterizations of the approximation upper and lower bounds\nrelative to a stronger time-varying benchmark. Bridging mechanism design with\nonline learning theory, our work shows how robust welfare guarantees can be\nmaintained even when an agent cannot make best responses but learns their\ninvestment strategies in complex, uncertain environments.", "AI": {"tldr": "\u7814\u7a76\u52a8\u6001\u73af\u5883\u4e2d\u5b66\u4e60\u578b\u6295\u8d44\u8005\u7684\u798f\u5229\u4fdd\u969c\uff0c\u5206\u6790\u8fd1\u4f3c\u5206\u914d\u7b97\u6cd5\u5728\u6295\u8d44\u8005\u4f7f\u7528\u65e0\u6094\u5728\u7ebf\u5b66\u4e60\u800c\u975e\u6700\u4f18\u54cd\u5e94\u65f6\u7684\u798f\u5229\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u6295\u8d44\u8005\u7531\u4e8e\u52a8\u6001\u73af\u5883\u4e2d\u7684\u4e0d\u5b8c\u5168\u4fe1\u606f\uff0c\u65e0\u6cd5\u603b\u662f\u505a\u51fa\u6700\u4f18\u54cd\u5e94\u51b3\u7b56\uff0c\u9700\u8981\u7814\u7a76\u5b66\u4e60\u578b\u6295\u8d44\u8005\u7684\u798f\u5229\u4fdd\u969c\u95ee\u9898\u3002", "method": "\u8003\u8651\u4f7f\u7528\u65e0\u6094\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u7684\u6295\u8d44\u8005\uff0c\u5206\u6790\u8fd1\u4f3c\u5206\u914d\u7b97\u6cd5\u5728\u52a8\u6001\u5b66\u4e60\u73af\u5883\u4e2d\u7684\u798f\u5229\u4fdd\u8bc1\uff0c\u901a\u8fc7\u8fd1\u4f3c\u6bd4\u7387\u8861\u91cf\u7b97\u6cd5\u6027\u80fd\u3002", "result": "\u9759\u6001\u73af\u5883\u4e2d\u7684\u8fd1\u4f3c\u6bd4\u7387\u5728\u52a8\u6001\u73af\u5883\u4e2d\u76f8\u5bf9\u4e8e\u4e8b\u540e\u6700\u4f18\u57fa\u51c6\u4fdd\u6301\u4e0d\u53d8\uff1b\u5bf9\u66f4\u5f3a\u7684\u65f6\u95f4\u53d8\u5316\u57fa\u51c6\u7ed9\u51fa\u4e86\u7d27\u81f4\u7684\u8fd1\u4f3c\u4e0a\u4e0b\u754c\u523b\u753b\u3002", "conclusion": "\u5c06\u673a\u5236\u8bbe\u8ba1\u4e0e\u5728\u7ebf\u5b66\u4e60\u7406\u8bba\u7ed3\u5408\uff0c\u8868\u660e\u5373\u4f7f\u4ee3\u7406\u65e0\u6cd5\u505a\u51fa\u6700\u4f18\u54cd\u5e94\u4f46\u5728\u590d\u6742\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u5b66\u4e60\u6295\u8d44\u7b56\u7565\u65f6\uff0c\u4ecd\u80fd\u4fdd\u6301\u7a33\u5065\u7684\u798f\u5229\u4fdd\u8bc1\u3002"}}
{"id": "2511.00470", "categories": ["cs.DS", "cs.DM"], "pdf": "https://arxiv.org/pdf/2511.00470", "abs": "https://arxiv.org/abs/2511.00470", "authors": ["Ryuhei Mizutani"], "title": "An Approximation Algorithm for Monotone Submodular Cost Allocation", "comment": null, "summary": "In this paper, we consider the minimum submodular cost allocation (MSCA)\nproblem. The input of MSCA is $k$ non-negative submodular functions\n$f_1,\\ldots,f_k$ on the ground set $N$ given by evaluation oracles, and the\ngoal is to partition $N$ into $k$ (possibly empty) sets $X_1,\\ldots,X_k$ so\nthat $\\sum_{i=1}^k f_i(X_i)$ is minimized. In this paper, we focus on the case\nwhen $f_1,\\ldots,f_k$ are monotone (denoted by Mono-MSCA). We provide a natural\nLP-relaxation for Mono-MSCA, which is equivalent to the convex program\nrelaxation introduced by Chekuri and Ene. We show that the integrality gap of\nthe LP-relaxation is at most $k/2$, which yields a $k/2$-approximation\nalgorithm for Mono-MSCA. We also show that the integrality gap of the\nLP-relaxation is at least $k/2-\\epsilon$ for any constant $\\epsilon>0$ when $k$\nis fixed.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6700\u5c0f\u5b50\u6a21\u6210\u672c\u5206\u914d\u95ee\u9898\uff0c\u9488\u5bf9\u5355\u8c03\u5b50\u6a21\u51fd\u6570\u60c5\u51b5\uff0c\u63d0\u51fa\u4e86LP\u677e\u5f1b\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u79ef\u5206\u95f4\u9699\u4e3ak/2\uff0c\u5e76\u7ed9\u51fa\u4e86\u76f8\u5e94\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3\u6700\u5c0f\u5b50\u6a21\u6210\u672c\u5206\u914d\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5355\u8c03\u5b50\u6a21\u51fd\u6570\u60c5\u51b5\u4e0b\u7684\u8fd1\u4f3c\u7b97\u6cd5\u8bbe\u8ba1\uff0c\u586b\u8865\u4e86\u8be5\u95ee\u9898\u7406\u8bba\u5206\u6790\u7684\u7a7a\u767d\u3002", "method": "\u4f7f\u7528\u81ea\u7136LP\u677e\u5f1b\u65b9\u6cd5\uff0c\u5c06\u5176\u7b49\u4ef7\u4e8eChekuri\u548cEne\u63d0\u51fa\u7684\u51f8\u89c4\u5212\u677e\u5f1b\uff0c\u5206\u6790\u79ef\u5206\u95f4\u9699\u5e76\u8bbe\u8ba1\u8fd1\u4f3c\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86LP\u677e\u5f1b\u7684\u79ef\u5206\u95f4\u9699\u6700\u591a\u4e3ak/2\uff0c\u4ece\u800c\u5f97\u5230\u4e86k/2-\u8fd1\u4f3c\u7b97\u6cd5\uff1b\u540c\u65f6\u8bc1\u660e\u4e86\u5f53k\u56fa\u5b9a\u65f6\uff0c\u79ef\u5206\u95f4\u9699\u81f3\u5c11\u4e3ak/2-\u03b5\u3002", "conclusion": "\u5bf9\u4e8e\u5355\u8c03\u5b50\u6a21\u6210\u672c\u5206\u914d\u95ee\u9898\uff0cLP\u677e\u5f1b\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u7d27\u81f4\u7684k/2\u8fd1\u4f3c\u4fdd\u8bc1\uff0c\u4e3a\u8be5\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01590", "categories": ["cs.MM"], "pdf": "https://arxiv.org/pdf/2511.01590", "abs": "https://arxiv.org/abs/2511.01590", "authors": ["Yongcun Hu", "Yingzhen Zhai", "Jixiang Luo", "Wenrui Dai", "Dell Zhang", "Hongkai Xiong", "Xuelong Li"], "title": "EV-NVC: Efficient Variable bitrate Neural Video Compression", "comment": null, "summary": "Training neural video codec (NVC) with variable rate is a highly challenging\ntask due to its complex training strategies and model structure. In this paper,\nwe train an efficient variable bitrate neural video codec (EV-NVC) with the\npiecewise linear sampler (PLS) to improve the rate-distortion performance in\nhigh bitrate range, and the long-short-term feature fusion module (LSTFFM) to\nenhance the context modeling. Besides, we introduce mixed-precision training\nand discuss the different training strategies for each stage in detail to fully\nevaluate its effectiveness. Experimental results show that our approach reduces\nthe BD-rate by 30.56% compared to HM-16.25 within low-delay mode.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u53ef\u53d8\u6bd4\u7279\u7387\u795e\u7ecf\u89c6\u9891\u7f16\u7801\u5668EV-NVC\uff0c\u901a\u8fc7\u5206\u6bb5\u7ebf\u6027\u91c7\u6837\u5668\u548c\u957f\u77ed\u65f6\u7279\u5f81\u878d\u5408\u6a21\u5757\u63d0\u5347\u9ad8\u6bd4\u7279\u7387\u8303\u56f4\u7684\u7387\u5931\u771f\u6027\u80fd\uff0c\u5e76\u91c7\u7528\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u7b56\u7565\u3002", "motivation": "\u8bad\u7ec3\u53ef\u53d8\u6bd4\u7279\u7387\u795e\u7ecf\u89c6\u9891\u7f16\u7801\u5668\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5176\u590d\u6742\u7684\u8bad\u7ec3\u7b56\u7565\u548c\u6a21\u578b\u7ed3\u6784\u3002\u672c\u6587\u65e8\u5728\u63d0\u9ad8\u9ad8\u6bd4\u7279\u7387\u8303\u56f4\u7684\u7387\u5931\u771f\u6027\u80fd\u5e76\u589e\u5f3a\u4e0a\u4e0b\u6587\u5efa\u6a21\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u5206\u6bb5\u7ebf\u6027\u91c7\u6837\u5668(PLS)\u63d0\u5347\u9ad8\u6bd4\u7279\u7387\u8303\u56f4\u7684\u7387\u5931\u771f\u6027\u80fd\uff0c\u957f\u77ed\u65f6\u7279\u5f81\u878d\u5408\u6a21\u5757(LSTFFM)\u589e\u5f3a\u4e0a\u4e0b\u6587\u5efa\u6a21\uff0c\u5e76\u91c7\u7528\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u548c\u5206\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4f4e\u5ef6\u8fdf\u6a21\u5f0f\u4e0b\uff0c\u4e0eHM-16.25\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5c06BD-rate\u964d\u4f4e\u4e8630.56%\u3002", "conclusion": "\u63d0\u51fa\u7684EV-NVC\u65b9\u6cd5\u5728\u53ef\u53d8\u6bd4\u7279\u7387\u795e\u7ecf\u89c6\u9891\u7f16\u7801\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728\u9ad8\u6bd4\u7279\u7387\u8303\u56f4\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u6a21\u5757\u548c\u8bad\u7ec3\u7b56\u7565\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.00444", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00444", "abs": "https://arxiv.org/abs/2511.00444", "authors": ["Benjamin Clavi\u00e9", "Xianming Li", "Antoine Chaffin", "Omar Khattab", "Tom Aarsen", "Manuel Faysse", "Jing Li"], "title": "LIR: The First Workshop on Late Interaction and Multi Vector Retrieval @ ECIR 2026", "comment": "Accepted workshop at ECIR 2026", "summary": "Late interaction retrieval methods, pioneered by ColBERT, have emerged as a\npowerful alternative to single-vector neural IR. By leveraging fine-grained,\ntoken-level representations, they have been demonstrated to deliver strong\ngeneralisation and robustness, particularly in out-of-domain settings. They\nhave recently been shown to be particularly well-suited for novel use cases,\nsuch as reasoning-based or cross-modality retrieval. At the same time, these\nmodels pose significant challenges of efficiency, usability, and integrations\ninto fully fledged systems; as well as the natural difficulties encountered\nwhile researching novel application domains. Recent years have seen rapid\nadvances across many of these areas, but research efforts remain fragmented\nacross communities and frequently exclude practitioners. The purpose of this\nworkshop is to create an environment where all aspects of late interaction can\nbe discussed, with a focus on early research explorations, real-world outcomes,\nand negative or puzzling results to be freely shared and discussed. The aim of\nLIR is to provide a highly-interactive environment for researchers from various\nbackgrounds and practitioners to freely discuss their experience, fostering\nfurther collaboration.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8ba8\u8bba\u4e86\u5ef6\u8fdf\u4ea4\u4e92\u68c0\u7d22\u65b9\u6cd5\uff08\u4ee5ColBERT\u4e3a\u4ee3\u8868\uff09\u7684\u4f18\u52bf\u3001\u6311\u6218\u53ca\u5176\u5728\u65b0\u578b\u5e94\u7528\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65e8\u5728\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u548c\u5b9e\u8df5\u4ea4\u6d41\u7684\u7814\u8ba8\u4f1a\u3002", "motivation": "\u5ef6\u8fdf\u4ea4\u4e92\u68c0\u7d22\u65b9\u6cd5\u5728\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u8de8\u9886\u57df\u548c\u65b0\u578b\u5e94\u7528\u573a\u666f\uff0c\u4f46\u5b58\u5728\u6548\u7387\u3001\u53ef\u7528\u6027\u548c\u7cfb\u7edf\u96c6\u6210\u7b49\u6311\u6218\u3002\u5f53\u524d\u7814\u7a76\u5206\u6563\u4e14\u7f3a\u4e4f\u5b9e\u8df5\u8005\u53c2\u4e0e\uff0c\u9700\u8981\u4fc3\u8fdb\u4ea4\u6d41\u4e0e\u5408\u4f5c\u3002", "method": "\u901a\u8fc7\u7ec4\u7ec7LIR\u7814\u8ba8\u4f1a\uff0c\u4e3a\u6765\u81ea\u4e0d\u540c\u80cc\u666f\u7684\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e00\u4e2a\u9ad8\u5ea6\u4e92\u52a8\u7684\u73af\u5883\uff0c\u8ba8\u8bba\u5ef6\u8fdf\u4ea4\u4e92\u7684\u5404\u4e2a\u65b9\u9762\uff0c\u5305\u62ec\u65e9\u671f\u7814\u7a76\u63a2\u7d22\u3001\u5b9e\u9645\u5e94\u7528\u6210\u679c\u4ee5\u53ca\u8d1f\u9762\u6216\u4ee4\u4eba\u56f0\u60d1\u7684\u7ed3\u679c\u3002", "result": "\u7814\u8ba8\u4f1a\u65e8\u5728\u4fc3\u8fdb\u5ef6\u8fdf\u4ea4\u4e92\u68c0\u7d22\u65b9\u6cd5\u7684\u7814\u7a76\u548c\u5b9e\u8df5\u4ea4\u6d41\uff0c\u63a8\u52a8\u8fdb\u4e00\u6b65\u5408\u4f5c\uff0c\u89e3\u51b3\u5f53\u524d\u7814\u7a76\u5206\u6563\u548c\u7f3a\u4e4f\u5b9e\u8df5\u8005\u53c2\u4e0e\u7684\u95ee\u9898\u3002", "conclusion": "\u5ef6\u8fdf\u4ea4\u4e92\u68c0\u7d22\u65b9\u6cd5\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4f46\u4e5f\u9762\u4e34\u6311\u6218\u3002\u901a\u8fc7LIR\u7814\u8ba8\u4f1a\uff0c\u53ef\u4ee5\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u548c\u5b9e\u8df5\u7684\u4ea4\u6d41\u4e0e\u5408\u4f5c\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2511.00809", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00809", "abs": "https://arxiv.org/abs/2511.00809", "authors": ["Yang Xu", "Haibin Kan", "Guangyue Han"], "title": "An Elementary Approach to MacWilliams Extension Property and Constant Weight Code with Respect to Weighted Hamming Metric", "comment": null, "summary": "In this paper, we characterize the MacWilliams extension property (MEP) and\nconstant weight codes with respect to $\\omega$-weight defined on\n$\\mathbb{F}^{\\Omega}$ via an elementary approach, where $\\mathbb{F}$ is a\nfinite field, $\\Omega$ is a finite set, and\n$\\omega:\\Omega\\longrightarrow\\mathbb{R}^{+}$ is a weight function. Our approach\nrelies solely on elementary linear algebra and two key identities for\n$\\omega$-weight of subspaces derived from a double-counting argument. When\n$\\omega$ is the constant $1$ map, our results recover two well-known results\nfor Hamming metric code: (1) any Hamming weight preserving map between linear\ncodes extends to a Hamming weight isometry of the entire ambient space; and (2)\nany constant weight Hamming metric code is a repetition of the dual of Hamming\ncode.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u521d\u7b49\u65b9\u6cd5\u7814\u7a76\u4e86\u6709\u9650\u57df\u4e0a\u03c9-\u6743\u91cd\u7684MacWilliams\u6269\u5c55\u6027\u8d28\u548c\u5e38\u91cd\u7801\uff0c\u5f53\u03c9\u4e3a\u5e38\u65701\u65f6\u6062\u590dHamming\u5ea6\u91cf\u7801\u7684\u4e24\u4e2a\u7ecf\u5178\u7ed3\u679c\u3002", "motivation": "\u7814\u7a76\u6709\u9650\u57df\u4e0a\u03c9-\u6743\u91cd\u5b9a\u4e49\u7684MacWilliams\u6269\u5c55\u6027\u8d28\u548c\u5e38\u91cd\u7801\uff0c\u63d0\u4f9b\u4e00\u79cd\u4ec5\u4f9d\u8d56\u521d\u7b49\u7ebf\u6027\u4ee3\u6570\u7684\u7edf\u4e00\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u521d\u7b49\u7ebf\u6027\u4ee3\u6570\u548c\u901a\u8fc7\u53cc\u91cd\u8ba1\u6570\u8bba\u8bc1\u63a8\u5bfc\u51fa\u7684\u03c9-\u6743\u91cd\u5b50\u7a7a\u95f4\u7684\u4e24\u4e2a\u5173\u952e\u6052\u7b49\u5f0f\u3002", "result": "\u5efa\u7acb\u4e86\u03c9-\u6743\u91cd\u4e0b\u7684MacWilliams\u6269\u5c55\u6027\u8d28\u548c\u5e38\u91cd\u7801\u7684\u5b8c\u6574\u523b\u753b\uff0c\u5f53\u03c9\u4e3a\u5e38\u65701\u65f6\u4e0eHamming\u5ea6\u91cf\u7801\u7684\u7ecf\u5178\u7ed3\u679c\u4e00\u81f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7814\u7a76\u5404\u79cd\u6743\u91cd\u5ea6\u91cf\u4e0b\u7684\u7f16\u7801\u6027\u8d28\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u521d\u7b49\u6846\u67b6\uff0c\u6210\u529f\u63a8\u5e7f\u4e86Hamming\u5ea6\u91cf\u7801\u7684\u7ecf\u5178\u7406\u8bba\u3002"}}
{"id": "2511.00865", "categories": ["cs.DB", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.00865", "abs": "https://arxiv.org/abs/2511.00865", "authors": ["Hangdong Zhao", "Zhenghong Yu", "Srinag Rao", "Simon Frisk", "Zhiwei Fan", "Paraschos Koutris"], "title": "FlowLog: Efficient and Extensible Datalog via Incrementality", "comment": "Accepted to VLDB 2026", "summary": "Datalog-based languages are regaining popularity as a powerful abstraction\nfor expressing recursive computations in domains such as program analysis and\ngraph processing. However, existing systems often face a trade-off between\nefficiency and extensibility. Engines like Souffle achieve high efficiency\nthrough domain-specific designs, but lack general-purpose flexibility. Others,\nlike RecStep, offer modularity by layering Datalog on traditional databases,\nbut struggle to integrate Datalog-specific optimizations.\n  This paper bridges this gap by presenting FlowLog, a new Datalog engine that\nuses an explicit relational IR per-rule to cleanly separate recursive control\n(e.g., semi-naive execution) from each rule's logical plan. This boundary lets\nus retain fine-grained, Datalog-aware optimizations at the logical layer, but\nalso reuse off-the-shelf database primitives at execution. At the logical level\n(i.e. IR), we apply proven SQL optimizations, such as logic fusion and subplan\nreuse. To address high volatility in recursive workloads, we adopt a\nrobustness-first approach that pairs a structural optimizer (avoiding\nworst-case joins) with sideways information passing (early filtering). Built\natop Differential Dataflow--a mature framework for streaming analytics--FlowLog\nsupports both batch and incremental Datalog and adds novel recursion-aware\noptimizations called Boolean (or algebraic) specialization. Our evaluation\nshows that FlowLog outperforms state-of-the-art Datalog engines and modern\ndatabases across a broad range of recursive workloads, achieving superior\nscalability while preserving a simple and extensible architecture.", "AI": {"tldr": "FlowLog\u662f\u4e00\u4e2a\u65b0\u7684Datalog\u5f15\u64ce\uff0c\u901a\u8fc7\u663e\u5f0f\u5173\u7cfbIR\u5206\u79bb\u9012\u5f52\u63a7\u5236\u548c\u903b\u8f91\u8ba1\u5212\uff0c\u7ed3\u5408Datalog\u7279\u5b9a\u4f18\u5316\u548c\u6570\u636e\u5e93\u539f\u8bed\uff0c\u5728\u9012\u5f52\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u5b9e\u73b0\u9ad8\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709Datalog\u7cfb\u7edf\u5728\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff1aSouffle\u7b49\u5f15\u64ce\u6548\u7387\u9ad8\u4f46\u7f3a\u4e4f\u901a\u7528\u7075\u6d3b\u6027\uff0cRecStep\u7b49\u7cfb\u7edf\u6a21\u5757\u5316\u4f46\u96be\u4ee5\u96c6\u6210Datalog\u7279\u5b9a\u4f18\u5316\u3002", "method": "\u4f7f\u7528\u663e\u5f0f\u5173\u7cfbIR\u6309\u89c4\u5219\u5206\u79bb\u9012\u5f52\u63a7\u5236\u4e0e\u903b\u8f91\u8ba1\u5212\uff0c\u5728\u903b\u8f91\u5c42\u5e94\u7528SQL\u4f18\u5316\uff08\u903b\u8f91\u878d\u5408\u3001\u5b50\u8ba1\u5212\u91cd\u7528\uff09\uff0c\u91c7\u7528\u7a33\u5065\u6027\u4f18\u5148\u65b9\u6cd5\u7ed3\u5408\u7ed3\u6784\u4f18\u5316\u5668\u548c\u4fa7\u5411\u4fe1\u606f\u4f20\u9012\uff0c\u57fa\u4e8eDifferential Dataflow\u6784\u5efa\u3002", "result": "FlowLog\u5728\u5e7f\u6cdb\u7684\u9012\u5f52\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u4f18\u4e8e\u6700\u5148\u8fdb\u7684Datalog\u5f15\u64ce\u548c\u73b0\u4ee3\u6570\u636e\u5e93\uff0c\u5b9e\u73b0\u5353\u8d8a\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "FlowLog\u901a\u8fc7\u5206\u79bb\u5173\u6ce8\u70b9\u548c\u91cd\u7528\u73b0\u6709\u7ec4\u4ef6\uff0c\u5728\u4fdd\u6301\u7b80\u5355\u53ef\u6269\u5c55\u67b6\u6784\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86Datalog\u7cfb\u7edf\u6548\u7387\u548c\u7075\u6d3b\u6027\u7684\u5e73\u8861\u3002"}}
{"id": "2511.01421", "categories": ["cs.GT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.01421", "abs": "https://arxiv.org/abs/2511.01421", "authors": ["Yusuf Saltan", "Jyun-Jhe Wang", "Arda Kosay", "Chung-Wei Lin", "Muhammed O. Sayin"], "title": "Designing Non-monetary Intersection Control Mechanisms for Efficient Selfish Routing", "comment": null, "summary": "Urban traffic congestion stems from the misalignment between self-interested\nrouting decisions and socially optimal flows. Intersections, as critical\nbottlenecks, amplify these inefficiencies because existing control schemes\noften neglect drivers' strategic behavior. Autonomous intersections, enabled by\nvehicle-to-infrastructure communication, permit vehicle-level scheduling based\non individual requests. Leveraging this fine-grained control, we propose a\nnon-monetary mechanism that strategically adjusts request timestamps-delaying\nor advancing passage times-to incentivize socially efficient routing. We\npresent a hierarchical architecture separating local scheduling by roadside\nunits from network-wide timestamp adjustments by a central planner. We\nestablish an experimentally validated analytical model, prove the existence and\nessential uniqueness of equilibrium flows and formulate the planner's problem\nas an offline bilevel optimization program solvable with standard tools.\nExperiments on the Sioux Falls network show up to a 68% reduction in the\nefficiency gap between equilibrium and optimal flows, demonstrating scalability\nand effectiveness.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u975e\u8d27\u5e01\u673a\u5236\uff0c\u901a\u8fc7\u6218\u7565\u6027\u5730\u8c03\u6574\u8f66\u8f86\u901a\u8fc7\u4ea4\u53c9\u53e3\u7684\u65f6\u95f4\u6233\u6765\u6fc0\u52b1\u793e\u4f1a\u6548\u7387\u6700\u4f18\u7684\u8def\u7531\u9009\u62e9\uff0c\u5728Sioux Falls\u7f51\u7edc\u4e0a\u5b9e\u73b0\u4e86\u5747\u8861\u6d41\u4e0e\u6700\u4f18\u6d41\u4e4b\u95f4\u6548\u7387\u5dee\u8ddd\u51cf\u5c1168%\u7684\u6548\u679c\u3002", "motivation": "\u57ce\u5e02\u4ea4\u901a\u62e5\u5835\u6e90\u4e8e\u81ea\u5229\u8def\u7531\u51b3\u7b56\u4e0e\u793e\u4f1a\u6700\u4f18\u6d41\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u3002\u4ea4\u53c9\u53e3\u4f5c\u4e3a\u5173\u952e\u74f6\u9888\u653e\u5927\u4e86\u8fd9\u4e9b\u4f4e\u6548\u7387\uff0c\u56e0\u4e3a\u73b0\u6709\u63a7\u5236\u65b9\u6848\u5f80\u5f80\u5ffd\u7565\u9a7e\u9a76\u5458\u7684\u6218\u7565\u884c\u4e3a\u3002", "method": "\u91c7\u7528\u5206\u5c42\u67b6\u6784\uff0c\u5c06\u8def\u8fb9\u5355\u5143\u8d1f\u8d23\u7684\u672c\u5730\u8c03\u5ea6\u4e0e\u4e2d\u592e\u89c4\u5212\u5668\u8d1f\u8d23\u7684\u7f51\u7edc\u8303\u56f4\u65f6\u95f4\u6233\u8c03\u6574\u5206\u79bb\u3002\u5efa\u7acb\u5b9e\u9a8c\u9a8c\u8bc1\u7684\u5206\u6790\u6a21\u578b\uff0c\u8bc1\u660e\u5747\u8861\u6d41\u7684\u5b58\u5728\u6027\u548c\u552f\u4e00\u6027\uff0c\u5e76\u5c06\u89c4\u5212\u5668\u95ee\u9898\u8868\u8ff0\u4e3a\u53ef\u79bb\u7ebf\u6c42\u89e3\u7684\u53cc\u5c42\u4f18\u5316\u7a0b\u5e8f\u3002", "result": "\u5728Sioux Falls\u7f51\u7edc\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u5747\u8861\u6d41\u4e0e\u6700\u4f18\u6d41\u4e4b\u95f4\u7684\u6548\u7387\u5dee\u8ddd\u51cf\u5c11\u4e86\u9ad8\u8fbe68%\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u5229\u7528\u8f66\u8f86\u5230\u57fa\u7840\u8bbe\u65bd\u901a\u4fe1\u5b9e\u73b0\u7684\u7cbe\u7ec6\u63a7\u5236\uff0c\u901a\u8fc7\u975e\u8d27\u5e01\u673a\u5236\u6218\u7565\u6027\u5730\u8c03\u6574\u8bf7\u6c42\u65f6\u95f4\u6233\uff0c\u80fd\u591f\u6709\u6548\u6fc0\u52b1\u793e\u4f1a\u6548\u7387\u6700\u4f18\u7684\u8def\u7531\u9009\u62e9\uff0c\u663e\u8457\u6539\u5584\u4ea4\u901a\u62e5\u5835\u95ee\u9898\u3002"}}
{"id": "2511.00869", "categories": ["cs.DS", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00869", "abs": "https://arxiv.org/abs/2511.00869", "authors": ["Hue T. Nguyen", "Tan D. Tran", "Nguyen Long Giang", "Canh V. Pham"], "title": "Fast Stochastic Greedy Algorithm for $k$-Submodular Cover Problem", "comment": null, "summary": "We study the $k$-Submodular Cover ($kSC$) problem, a natural generalization\nof the classical Submodular Cover problem that arises in artificial\nintelligence and combinatorial optimization tasks such as influence\nmaximization, resource allocation, and sensor placement. Existing algorithms\nfor $\\kSC$ often provide weak approximation guarantees or incur prohibitively\nhigh query complexity. To overcome these limitations, we propose a \\textit{Fast\nStochastic Greedy} algorithm that achieves strong bicriteria approximation\nwhile substantially lowering query complexity compared to state-of-the-art\nmethods. Our approach dramatically reduces the number of function evaluations,\nmaking it highly scalable and practical for large-scale real-world AI\napplications where efficiency is essential.", "AI": {"tldr": "\u63d0\u51fa\u4e86Fast Stochastic Greedy\u7b97\u6cd5\u89e3\u51b3k-\u5b50\u6a21\u8986\u76d6\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u5f3a\u53cc\u6807\u51c6\u8fd1\u4f3c\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u67e5\u8be2\u590d\u6742\u5ea6", "motivation": "\u73b0\u6709k-\u5b50\u6a21\u8986\u76d6\u7b97\u6cd5\u5b58\u5728\u8fd1\u4f3c\u4fdd\u8bc1\u5f31\u6216\u67e5\u8be2\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u5728\u5f71\u54cd\u529b\u6700\u5927\u5316\u3001\u8d44\u6e90\u5206\u914d\u7b49AI\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027", "method": "\u4f7f\u7528\u5feb\u901f\u968f\u673a\u8d2a\u5fc3\u7b97\u6cd5\uff0c\u901a\u8fc7\u51cf\u5c11\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u6765\u964d\u4f4e\u67e5\u8be2\u590d\u6742\u5ea6", "result": "\u7b97\u6cd5\u5728\u4fdd\u6301\u5f3a\u53cc\u6807\u51c6\u8fd1\u4f3c\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u67e5\u8be2\u590d\u6742\u5ea6\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u5b9e\u9645AI\u5e94\u7528", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6548\u7387\u74f6\u9888\uff0c\u4e3a\u5927\u89c4\u6a21k-\u5b50\u6a21\u8986\u76d6\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2511.00530", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.00530", "abs": "https://arxiv.org/abs/2511.00530", "authors": ["Hongtao Huang", "Chengkai Huang", "Junda Wu", "Tong Yu", "Julian McAuley", "Lina Yao"], "title": "Listwise Preference Diffusion Optimization for User Behavior Trajectories Prediction", "comment": null, "summary": "Forecasting multi-step user behavior trajectories requires reasoning over\nstructured preferences across future actions, a challenge overlooked by\ntraditional sequential recommendation. This problem is critical for\napplications such as personalized commerce and adaptive content delivery, where\nanticipating a user's complete action sequence enhances both satisfaction and\nbusiness outcomes. We identify an essential limitation of existing paradigms:\ntheir inability to capture global, listwise dependencies among sequence items.\nTo address this, we formulate User Behavior Trajectory Prediction (UBTP) as a\nnew task setting that explicitly models long-term user preferences. We\nintroduce Listwise Preference Diffusion Optimization (LPDO), a diffusion-based\ntraining framework that directly optimizes structured preferences over entire\nitem sequences. LPDO incorporates a Plackett-Luce supervision signal and\nderives a tight variational lower bound aligned with listwise ranking\nlikelihoods, enabling coherent preference generation across denoising steps and\novercoming the independent-token assumption of prior diffusion methods. To\nrigorously evaluate multi-step prediction quality, we propose the task-specific\nmetric Sequential Match (SeqMatch), which measures exact trajectory agreement,\nand adopt Perplexity (PPL), which assesses probabilistic fidelity. Extensive\nexperiments on real-world user behavior benchmarks demonstrate that LPDO\nconsistently outperforms state-of-the-art baselines, establishing a new\nbenchmark for structured preference learning with diffusion models.", "AI": {"tldr": "\u63d0\u51fa\u4e86Listwise Preference Diffusion Optimization (LPDO)\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u7528\u6237\u884c\u4e3a\u8f68\u8ff9\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u76f4\u63a5\u4f18\u5316\u6574\u4e2a\u9879\u76ee\u5e8f\u5217\u7684\u7ed3\u6784\u5316\u504f\u597d\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u5e8f\u5217\u9879\u4e4b\u95f4\u7684\u5168\u5c40\u5217\u8868\u4f9d\u8d56\u5173\u7cfb\uff0c\u8fd9\u5728\u9884\u6d4b\u591a\u6b65\u7528\u6237\u884c\u4e3a\u8f68\u8ff9\u65f6\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u4e2a\u6027\u5316\u5546\u52a1\u548c\u81ea\u9002\u5e94\u5185\u5bb9\u4ea4\u4ed8\u7b49\u5e94\u7528\u4e2d\u3002", "method": "\u5f15\u5165LPDO\u6269\u6563\u8bad\u7ec3\u6846\u67b6\uff0c\u7ed3\u5408Plackett-Luce\u76d1\u7763\u4fe1\u53f7\uff0c\u63a8\u5bfc\u51fa\u4e0e\u5217\u8868\u6392\u5e8f\u4f3c\u7136\u5bf9\u9f50\u7684\u7d27\u5bc6\u53d8\u5206\u4e0b\u754c\uff0c\u5b9e\u73b0\u8de8\u53bb\u566a\u6b65\u9aa4\u7684\u8fde\u8d2f\u504f\u597d\u751f\u6210\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7528\u6237\u884c\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLPDO\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u7684\u7ed3\u6784\u5316\u504f\u597d\u5b66\u4e60\u5efa\u7acb\u4e86\u65b0\u57fa\u51c6\u3002", "conclusion": "LPDO\u901a\u8fc7\u76f4\u63a5\u4f18\u5316\u7ed3\u6784\u5316\u504f\u597d\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u591a\u6b65\u7528\u6237\u884c\u4e3a\u8f68\u8ff9\u9884\u6d4b\u4e2d\u7684\u5168\u5c40\u4f9d\u8d56\u5efa\u6a21\u95ee\u9898\uff0c\u4e3a\u5e8f\u5217\u63a8\u8350\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00887", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00887", "abs": "https://arxiv.org/abs/2511.00887", "authors": ["Trinh Van Chien", "Ngo Tran Anh Thu", "Nguyen Hoang Lam", "Hien Quoc Ngo", "Symeon Chatzinotas", "Huynh Thi Thanh Binh"], "title": "Fairness Designs for Load Balancing Optimization in Satellite-Cell-Free Massive MIMO Systems", "comment": "13 pages, 5 figures, 2 tables. Accepted by TAES", "summary": "Space-ground communication systems are important in providing ubiquitous\nservices in a large area. This paper considers the fairness designs under a\nload-balancing framework with heterogeneous receivers comprising access points\n(APs) and a satellite. We derive an ergodic throughput of each user in the\nuplink data transmission for an arbitrary association pattern and imperfect\nchannel state information, followed by a closed-form expression with the\nmaximum-ratio combining and rich scattering environments. We further formulate\na generic fairness optimization problem, subject to the optimal association\npatterns for all the users. Despite the combinatorial structure, the global\noptimal solution to the association patterns can be obtained by an exhaustive\nsearch for small-scale networks with several APs and users. We design a low\ncomputational complexity algorithm for large-scale networks based on\nevolutionary computation that obtains good patterns in polynomial time.\nSpecifically, the genetic algorithm (GA) is adapted to the discrete feasible\nregion and the concrete fairness metrics. We extensively observe the fairness\ndesign problem by incorporating transmit power control and propose a hybrid\ngenetic algorithm to address the problem. Numerical results demonstrate that\nthe association pattern to each user has a significant impact on the network\nthroughput. Moreover, the proposed GA-based algorithm offers the same\nperformance as an exhaustive search for small-scale networks, while it unveils\ninteresting practical association patterns as the network dimensions go large.\nThe load-balancing approach, combined with power control factors, significantly\nenhances system performance compared to conventional schemes and configurations\nwith fixed factors.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5929\u5730\u4e00\u4f53\u5316\u901a\u4fe1\u7cfb\u7edf\u4e2d\u8003\u8651\u5f02\u6784\u63a5\u6536\u5668\uff08\u63a5\u5165\u70b9\u548c\u536b\u661f\uff09\u7684\u8d1f\u8f7d\u5747\u8861\u516c\u5e73\u6027\u8bbe\u8ba1\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u9ad8\u6548\u5173\u8054\u6a21\u5f0f\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u63d0\u5347\u7f51\u7edc\u541e\u5410\u91cf\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5929\u5730\u4e00\u4f53\u5316\u901a\u4fe1\u7cfb\u7edf\u9700\u8981\u5728\u5927\u8303\u56f4\u533a\u57df\u5185\u63d0\u4f9b\u666e\u904d\u670d\u52a1\uff0c\u4f46\u5f02\u6784\u63a5\u6536\u5668\uff08AP\u548c\u536b\u661f\uff09\u4e4b\u95f4\u7684\u8d1f\u8f7d\u5747\u8861\u548c\u516c\u5e73\u6027\u8bbe\u8ba1\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u7f51\u7edc\u4e2d\u5bfb\u627e\u6700\u4f18\u5173\u8054\u6a21\u5f0f\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u5f88\u9ad8\u3002", "method": "\u63a8\u5bfc\u4e86\u4efb\u610f\u5173\u8054\u6a21\u5f0f\u4e0b\u7528\u6237\u7684\u4e0a\u884c\u94fe\u8def\u904d\u5386\u541e\u5410\u91cf\uff0c\u5efa\u7acb\u4e86\u901a\u7528\u516c\u5e73\u6027\u4f18\u5316\u95ee\u9898\uff0c\u9488\u5bf9\u5c0f\u89c4\u6a21\u7f51\u7edc\u4f7f\u7528\u7a77\u4e3e\u641c\u7d22\uff0c\u9488\u5bf9\u5927\u89c4\u6a21\u7f51\u7edc\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u4f4e\u590d\u6742\u5ea6\u4f18\u5316\u7b97\u6cd5\uff0c\u5e76\u7ed3\u5408\u529f\u7387\u63a7\u5236\u63d0\u51fa\u4e86\u6df7\u5408\u9057\u4f20\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u7528\u6237\u5173\u8054\u6a21\u5f0f\u5bf9\u7f51\u7edc\u541e\u5410\u91cf\u6709\u663e\u8457\u5f71\u54cd\uff0c\u63d0\u51fa\u7684GA\u7b97\u6cd5\u5728\u5c0f\u89c4\u6a21\u7f51\u7edc\u4e2d\u4e0e\u7a77\u4e3e\u641c\u7d22\u6027\u80fd\u76f8\u540c\uff0c\u5728\u5927\u89c4\u6a21\u7f51\u7edc\u4e2d\u80fd\u53d1\u73b0\u5b9e\u7528\u7684\u5173\u8054\u6a21\u5f0f\uff0c\u8d1f\u8f7d\u5747\u8861\u7ed3\u5408\u529f\u7387\u63a7\u5236\u76f8\u6bd4\u4f20\u7edf\u65b9\u6848\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "conclusion": "\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u8d1f\u8f7d\u5747\u8861\u516c\u5e73\u6027\u8bbe\u8ba1\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u5929\u5730\u4e00\u4f53\u5316\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u5173\u8054\u4f18\u5316\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u516c\u5e73\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u541e\u5410\u91cf\u6027\u80fd\u3002"}}
{"id": "2511.00985", "categories": ["cs.DB", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00985", "abs": "https://arxiv.org/abs/2511.00985", "authors": ["Yiwen Jiao", "Tonghui Ren", "Yuche Gao", "Zhenying He", "Yinan Jing", "Kai Zhang", "X. Sean Wang"], "title": "ORANGE: An Online Reflection ANd GEneration framework with Domain Knowledge for Text-to-SQL", "comment": "16 pages, 4 figures, preprint", "summary": "Large Language Models (LLMs) have demonstrated remarkable progress in\ntranslating natural language to SQL, but a significant semantic gap persists\nbetween their general knowledge and domain-specific semantics of databases.\nHistorical translation logs constitute a rich source of this missing in-domain\nknowledge, where SQL queries inherently encapsulate real-world usage patterns\nof database schema. Existing methods primarily enhance the reasoning process\nfor individual translations but fail to accumulate in-domain knowledge from\npast translations. We introduce ORANGE, an online self-evolutionary framework\nthat constructs database-specific knowledge bases by parsing SQL queries from\ntranslation logs. By accumulating in-domain knowledge that contains schema and\ndata semantics, ORANGE progressively reduces the semantic gap and enhances the\naccuracy of subsequent SQL translations. To ensure reliability, we propose a\nnovel nested Chain-of-Thought SQL-to-Text strategy with tuple-semantic\ntracking, which reduces semantic errors during knowledge generation.\nExperiments on multiple benchmarks confirm the practicality of ORANGE,\ndemonstrating its effectiveness for real-world Text-to-SQL deployment,\nparticularly in handling complex and domain-specific queries.", "AI": {"tldr": "ORANGE\u662f\u4e00\u4e2a\u5728\u7ebf\u81ea\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u6790\u7ffb\u8bd1\u65e5\u5fd7\u4e2d\u7684SQL\u67e5\u8be2\u6784\u5efa\u6570\u636e\u5e93\u7279\u5b9a\u77e5\u8bc6\u5e93\uff0c\u9010\u6b65\u51cf\u5c11\u8bed\u4e49\u5dee\u8ddd\uff0c\u63d0\u9ad8SQL\u7ffb\u8bd1\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u8f6cSQL\u65b9\u9762\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5176\u901a\u7528\u77e5\u8bc6\u4e0e\u6570\u636e\u5e93\u9886\u57df\u7279\u5b9a\u8bed\u4e49\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u8bed\u4e49\u9e3f\u6c9f\u3002\u5386\u53f2\u7ffb\u8bd1\u65e5\u5fd7\u5305\u542b\u4e86\u8fd9\u4e9b\u7f3a\u5931\u7684\u9886\u57df\u5185\u77e5\u8bc6\u3002", "method": "\u63d0\u51faORANGE\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u6790\u7ffb\u8bd1\u65e5\u5fd7\u4e2d\u7684SQL\u67e5\u8be2\u6784\u5efa\u6570\u636e\u5e93\u7279\u5b9a\u77e5\u8bc6\u5e93\uff0c\u91c7\u7528\u5d4c\u5957\u601d\u7ef4\u94feSQL\u5230\u6587\u672c\u7b56\u7565\u8fdb\u884c\u8bed\u4e49\u8ddf\u8e2a\uff0c\u786e\u4fdd\u77e5\u8bc6\u751f\u6210\u7684\u53ef\u9760\u6027\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u5b9e\u4e86ORANGE\u7684\u5b9e\u7528\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u548c\u9886\u57df\u7279\u5b9a\u67e5\u8be2\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "ORANGE\u6846\u67b6\u901a\u8fc7\u79ef\u7d2f\u9886\u57df\u5185\u77e5\u8bc6\u6709\u6548\u51cf\u5c11\u4e86\u8bed\u4e49\u9e3f\u6c9f\uff0c\u63d0\u9ad8\u4e86Text-to-SQL\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2511.01852", "categories": ["cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01852", "abs": "https://arxiv.org/abs/2511.01852", "authors": ["Yang Cai", "Constantinos Daskalakis", "Haipeng Luo", "Chen-Yu Wei", "Weiqiang Zheng"], "title": "Proximal Regret and Proximal Correlated Equilibria: A New Tractable Solution Concept for Online Learning and Games", "comment": "This paper presents proximal regret and proximal correlated\n  equilibria results that do not appear in the NeurIPS version of\n  arXiv:2403.08171", "summary": "Learning and computation of equilibria are central problems in algorithmic\ngame theory. In this work, we introduce proximal regret, a new notion of regret\nbased on proximal operators that lies strictly between external and swap\nregret. When every player employs a no-proximal-regret algorithm in a general\nconvex game, the empirical distribution of play converges to proximal\ncorrelated equilibria (PCE), a refinement of coarse correlated equilibria. Our\nframework unifies several emerging notions in online learning and game theory\n-- such as gradient equilibrium and semicoarse correlated equilibrium -- and\nintroduces new ones. Our main result shows that the classic Online Gradient\nDescent (GD) algorithm achieves an optimal $O(\\sqrt{T})$ bound on proximal\nregret, revealing that GD, without modification, minimizes a stronger regret\nnotion than external regret. This provides a new explanation for the\nempirically superior performance of gradient descent in online learning and\ngames. We further extend our analysis to Mirror Descent in the Bregman setting\nand to Optimistic Gradient Descent, which yields faster convergence in smooth\nconvex games.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u8fd1\u7aef\u9057\u61be\u7684\u65b0\u6982\u5ff5\uff0c\u5b83\u4ecb\u4e8e\u5916\u90e8\u9057\u61be\u548c\u4ea4\u6362\u9057\u61be\u4e4b\u95f4\u3002\u5f53\u6240\u6709\u73a9\u5bb6\u5728\u4e00\u822c\u51f8\u535a\u5f08\u4e2d\u4f7f\u7528\u65e0\u8fd1\u7aef\u9057\u61be\u7b97\u6cd5\u65f6\uff0c\u7ecf\u9a8c\u5206\u5e03\u4f1a\u6536\u655b\u5230\u8fd1\u7aef\u76f8\u5173\u5747\u8861\u3002\u4e3b\u8981\u7ed3\u679c\u8868\u660e\u5728\u7ebf\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5b9e\u73b0\u4e86\u6700\u4f18\u7684O(\u221aT)\u8fd1\u7aef\u9057\u61be\u754c\u3002", "motivation": "\u5b66\u4e60\u548c\u8ba1\u7b97\u5747\u8861\u662f\u7b97\u6cd5\u535a\u5f08\u8bba\u7684\u6838\u5fc3\u95ee\u9898\u3002\u73b0\u6709\u9057\u61be\u6982\u5ff5\u5982\u5916\u90e8\u9057\u61be\u548c\u4ea4\u6362\u9057\u61be\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f15\u5165\u66f4\u7cbe\u7ec6\u7684\u9057\u61be\u6982\u5ff5\u6765\u66f4\u597d\u5730\u7406\u89e3\u5728\u7ebf\u5b66\u4e60\u548c\u535a\u5f08\u4e2d\u7684\u6536\u655b\u884c\u4e3a\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u8fd1\u7aef\u7b97\u5b50\u7684\u8fd1\u7aef\u9057\u61be\u6982\u5ff5\uff0c\u5206\u6790\u5728\u7ebf\u68af\u5ea6\u4e0b\u964d\u3001\u955c\u50cf\u4e0b\u964d\u548c\u4e50\u89c2\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5728\u8fd1\u7aef\u9057\u61be\u4e0b\u7684\u6027\u80fd\u3002", "result": "\u5728\u7ebf\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5b9e\u73b0\u4e86\u6700\u4f18\u7684O(\u221aT)\u8fd1\u7aef\u9057\u61be\u754c\uff0c\u955c\u50cf\u4e0b\u964d\u5728Bregman\u8bbe\u7f6e\u4e0b\u4e5f\u6709\u6548\uff0c\u4e50\u89c2\u68af\u5ea6\u4e0b\u964d\u5728\u5149\u6ed1\u51f8\u535a\u5f08\u4e2d\u80fd\u83b7\u5f97\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002", "conclusion": "\u8fd1\u7aef\u9057\u61be\u6846\u67b6\u7edf\u4e00\u4e86\u5728\u7ebf\u5b66\u4e60\u548c\u535a\u5f08\u8bba\u4e2d\u7684\u591a\u4e2a\u65b0\u5174\u6982\u5ff5\uff0c\u4e3a\u68af\u5ea6\u4e0b\u964d\u5728\u5728\u7ebf\u5b66\u4e60\u548c\u535a\u5f08\u4e2d\u4f18\u8d8a\u7684\u5b9e\u8bc1\u8868\u73b0\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89e3\u91ca\u3002"}}
{"id": "2511.01065", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2511.01065", "abs": "https://arxiv.org/abs/2511.01065", "authors": ["Kiarash Banihashem", "Jeff Giliberti", "Samira Goudarzi", "MohammadTaghi Hajiaghayi", "Peyman Jabbarzade", "Morteza Monemizadeh"], "title": "Dynamic Diameter in High-Dimensions against Adaptive Adversary and Beyond", "comment": "NeurIPS'25", "summary": "In this paper, we study the fundamental problems of maintaining the diameter\nand a $k$-center clustering of a dynamic point set $P \\subset \\mathbb{R}^d$,\nwhere points may be inserted or deleted over time and the ambient dimension $d$\nis not constant and may be high. Our focus is on designing algorithms that\nremain effective even in the presence of an adaptive adversary -- an adversary\nthat, at any time $t$, knows the entire history of the algorithm's outputs as\nwell as all the random bits used by the algorithm up to that point. We present\na fully dynamic algorithm that maintains a $2$-approximate diameter with a\nworst-case update time of $\\text{poly}(d, \\log n)$, where $n$ is the length of\nthe stream. Our result is achieved by identifying a robust representative of\nthe dataset that requires infrequent updates, combined with a careful\ndeamortization. To the best of our knowledge, this is the first efficient\nfully-dynamic algorithm for diameter in high dimensions that simultaneously\nachieves a 2-approximation guarantee and robustness against an adaptive\nadversary. We also give an improved dynamic $(4+\\epsilon)$-approximation\nalgorithm for the $k$-center problem, also resilient to an adaptive adversary.\nOur clustering algorithm achieves an amortized update time of $k^{2.5} d \\cdot\n\\text{poly}(\\epsilon^{-1}, \\log n)$, improving upon the amortized update time\nof $k^6 d \\cdot \\text{poly}(\\epsilon^{-1}, \\log n)$ by Biabani et al.\n[NeurIPS'24].", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u9ad8\u7ef4\u52a8\u6001\u70b9\u96c6\u7684\u76f4\u5f84\u548ck-center\u805a\u7c7b\u7ef4\u62a4\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u9488\u5bf9\u81ea\u9002\u5e94\u5bf9\u624b\u7684\u9c81\u68d2\u7b97\u6cd5\uff0c\u5305\u62ec2-\u8fd1\u4f3c\u76f4\u5f84\u7ef4\u62a4\u548c(4+\u03b5)-\u8fd1\u4f3ck-center\u805a\u7c7b\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u52a8\u6001\u7b97\u6cd5\u5927\u591a\u5047\u8bbe\u6570\u636e\u66f4\u65b0\u662f\u968f\u673a\u7684\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5bf9\u624b\u53ef\u80fd\u6839\u636e\u7b97\u6cd5\u5386\u53f2\u8f93\u51fa\u8fdb\u884c\u9002\u5e94\u6027\u653b\u51fb\u3002\u9700\u8981\u8bbe\u8ba1\u80fd\u591f\u62b5\u6297\u81ea\u9002\u5e94\u5bf9\u624b\u7684\u9ad8\u7ef4\u52a8\u6001\u7b97\u6cd5\u3002", "method": "\u901a\u8fc7\u8bc6\u522b\u9700\u8981\u8f83\u5c11\u66f4\u65b0\u7684\u9c81\u68d2\u6570\u636e\u96c6\u4ee3\u8868\uff0c\u7ed3\u5408\u4ed4\u7ec6\u7684\u53bb\u644a\u9500\u5316\u6280\u672f\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u52a8\u6001\u7ef4\u62a4\u3002\u5bf9\u4e8ek-center\u95ee\u9898\uff0c\u6539\u8fdb\u4e86\u73b0\u6709\u7b97\u6cd5\u7684\u66f4\u65b0\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "result": "\u63d0\u51fa\u4e86\u9996\u4e2a\u540c\u65f6\u5b9e\u73b02-\u8fd1\u4f3c\u4fdd\u8bc1\u4e14\u80fd\u62b5\u6297\u81ea\u9002\u5e94\u5bf9\u624b\u7684\u9ad8\u7ef4\u52a8\u6001\u76f4\u5f84\u7b97\u6cd5\uff0c\u6700\u574f\u60c5\u51b5\u66f4\u65b0\u65f6\u95f4\u4e3apoly(d, log n)\u3002k-center\u7b97\u6cd5\u5c06\u644a\u9500\u66f4\u65b0\u65f6\u95f4\u4ecek\u2076d\u6539\u8fdb\u5230k\u00b2.\u2075d\u3002", "conclusion": "\u8bc1\u660e\u4e86\u5728\u9ad8\u7ef4\u52a8\u6001\u73af\u5883\u4e0b\u8bbe\u8ba1\u62b5\u6297\u81ea\u9002\u5e94\u5bf9\u624b\u7684\u9ad8\u6548\u7b97\u6cd5\u662f\u53ef\u884c\u7684\uff0c\u4e3a\u52a8\u6001\u51e0\u4f55\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u9c81\u68d2\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00584", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00584", "abs": "https://arxiv.org/abs/2511.00584", "authors": ["Ke Shi", "Yan Zhang", "Miao Zhang", "Lifan Chen", "Jiali Yi", "Kui Xiao", "Xiaoju Hou", "Zhifei Li"], "title": "Structurally Refined Graph Transformer for Multimodal Recommendation", "comment": "Comment: 13 pages, 7 figures, accepted by IEEE Transactions on\n  Multimedia 2025", "summary": "Multimodal recommendation systems utilize various types of information,\nincluding images and text, to enhance the effectiveness of recommendations. The\nkey challenge is predicting user purchasing behavior from the available data.\nCurrent recommendation models prioritize extracting multimodal information\nwhile neglecting the distinction between redundant and valuable data. They also\nrely heavily on a single semantic framework (e.g., local or global semantics),\nresulting in an incomplete or biased representation of user preferences,\nparticularly those less expressed in prior interactions. Furthermore, these\napproaches fail to capture the complex interactions between users and items,\nlimiting the model's ability to meet diverse users. To address these\nchallenges, we present SRGFormer, a structurally optimized multimodal\nrecommendation model. By modifying the transformer for better integration into\nour model, we capture the overall behavior patterns of users. Then, we enhance\nstructural information by embedding multimodal information into a hypergraph\nstructure to aid in learning the local structures between users and items.\nMeanwhile, applying self-supervised tasks to user-item collaborative signals\nenhances the integration of multimodal information, thereby revealing the\nrepresentational features inherent to the data's modality. Extensive\nexperiments on three public datasets reveal that SRGFormer surpasses previous\nbenchmark models, achieving an average performance improvement of 4.47 percent\non the Sports dataset. The code is publicly available online.", "AI": {"tldr": "SRGFormer\u662f\u4e00\u4e2a\u7ed3\u6784\u4f18\u5316\u7684\u591a\u6a21\u6001\u63a8\u8350\u6a21\u578b\uff0c\u901a\u8fc7\u6539\u8fdbTransformer\u6355\u83b7\u7528\u6237\u6574\u4f53\u884c\u4e3a\u6a21\u5f0f\uff0c\u4f7f\u7528\u8d85\u56fe\u7ed3\u6784\u589e\u5f3a\u5c40\u90e8\u7ed3\u6784\u5b66\u4e60\uff0c\u5e76\u901a\u8fc7\u81ea\u76d1\u7763\u4efb\u52a1\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u51c6\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u63a8\u8350\u6a21\u578b\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u5ffd\u89c6\u5197\u4f59\u4e0e\u6709\u4ef7\u503c\u6570\u636e\u7684\u533a\u5206\uff1b2\uff09\u4f9d\u8d56\u5355\u4e00\u8bed\u4e49\u6846\u67b6\u5bfc\u81f4\u7528\u6237\u504f\u597d\u8868\u793a\u4e0d\u5b8c\u6574\uff1b3\uff09\u672a\u80fd\u5145\u5206\u6355\u6349\u7528\u6237\u4e0e\u7269\u54c1\u95f4\u7684\u590d\u6742\u4ea4\u4e92\u3002", "method": "1\uff09\u6539\u8fdbTransformer\u4ee5\u6355\u83b7\u7528\u6237\u6574\u4f53\u884c\u4e3a\u6a21\u5f0f\uff1b2\uff09\u5c06\u591a\u6a21\u6001\u4fe1\u606f\u5d4c\u5165\u8d85\u56fe\u7ed3\u6784\u5b66\u4e60\u5c40\u90e8\u7ed3\u6784\uff1b3\uff09\u5e94\u7528\u81ea\u76d1\u7763\u4efb\u52a1\u589e\u5f3a\u591a\u6a21\u6001\u4fe1\u606f\u6574\u5408\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSRGFormer\u8d85\u8d8a\u5148\u524d\u57fa\u51c6\u6a21\u578b\uff0c\u5728Sports\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u6027\u80fd\u63d0\u53474.47%\u3002", "conclusion": "SRGFormer\u901a\u8fc7\u7ed3\u6784\u4f18\u5316\u548c\u81ea\u76d1\u7763\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u63a8\u8350\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2511.00896", "categories": ["cs.IT", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00896", "abs": "https://arxiv.org/abs/2511.00896", "authors": ["Daniel E. Lucani", "Marcell Feh\u00e9r"], "title": "HyRES: A Hybrid Replication and Erasure Coding Approach to Data Storage", "comment": "6 pages, 5 figures", "summary": "Reliability in distributed storage systems has typically focused on the\ndesign and deployment of data replication or erasure coding techniques.\nAlthough some scenarios have considered the use of replication for hot data and\nerasure coding for cold data in the same system, each is designed in isolation.\nWe propose HyRES, a hybrid scheme incorporates the best characteristics of each\nscheme, thus, resulting in additional design flexibility and better potential\nperformance for the system. We show that HyRES generalizes previously proposed\nhybrid schemes. We characterize the theoretical performance of HyRES as well as\nthat of replication and erasure coding considering the effects of the size of\nthe storage networks. We validate our theoretical results using simulations.\nThese results show that HyRES can yield simultaneously lower storage costs than\nreplication, lower probabilities of file loss than replication and erasure\ncoding with similar worst case performance, and even lower effective repair\ntraffic than replication when considering the network size.", "AI": {"tldr": "HyRES\u662f\u4e00\u79cd\u6df7\u5408\u5b58\u50a8\u65b9\u6848\uff0c\u7ed3\u5408\u4e86\u590d\u5236\u548c\u7ea0\u5220\u7801\u7684\u6700\u4f73\u7279\u6027\uff0c\u63d0\u4f9b\u66f4\u597d\u7684\u8bbe\u8ba1\u7075\u6d3b\u6027\u548c\u6f5c\u5728\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5206\u5e03\u5f0f\u5b58\u50a8\u7cfb\u7edf\u901a\u5e38\u5355\u72ec\u8bbe\u8ba1\u590d\u5236\u6216\u7ea0\u5220\u7801\u6280\u672f\uff0c\u7f3a\u4e4f\u5c06\u4e24\u8005\u4f18\u52bf\u7ed3\u5408\u7684\u7075\u6d3b\u65b9\u6848\u3002", "method": "\u63d0\u51faHyRES\u6df7\u5408\u65b9\u6848\uff0c\u7efc\u5408\u8003\u8651\u5b58\u50a8\u7f51\u7edc\u89c4\u6a21\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u4eff\u771f\u9a8c\u8bc1\u6027\u80fd\u3002", "result": "HyRES\u76f8\u6bd4\u7eaf\u590d\u5236\u65b9\u6848\u964d\u4f4e\u5b58\u50a8\u6210\u672c\uff0c\u76f8\u6bd4\u590d\u5236\u548c\u7ea0\u5220\u7801\u964d\u4f4e\u6587\u4ef6\u4e22\u5931\u6982\u7387\uff0c\u5728\u7f51\u7edc\u89c4\u6a21\u8003\u8651\u4e0b\u751a\u81f3\u6bd4\u590d\u5236\u65b9\u6848\u6709\u66f4\u4f4e\u7684\u4fee\u590d\u6d41\u91cf\u3002", "conclusion": "HyRES\u80fd\u591f\u540c\u65f6\u5b9e\u73b0\u66f4\u4f4e\u7684\u5b58\u50a8\u6210\u672c\u3001\u66f4\u4f4e\u7684\u6587\u4ef6\u4e22\u5931\u6982\u7387\u548c\u66f4\u597d\u7684\u4fee\u590d\u6027\u80fd\uff0c\u662f\u5206\u5e03\u5f0f\u5b58\u50a8\u7cfb\u7edf\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00995", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.00995", "abs": "https://arxiv.org/abs/2511.00995", "authors": ["Tianming Wu", "Dixin Tang"], "title": "PathFinder: Efficiently Supporting Conjunctions and Disjunctions for Filtered Approximate Nearest Neighbor Search", "comment": null, "summary": "Filtered approximate nearest neighbor search (ANNS) restricts the search to\ndata objects whose attributes satisfy a given filter and retrieves the top-$K$\nobjects that are most semantically similar to the query object. Many\ngraph-based ANNS indexes are proposed to enable efficient filtered ANNS but\nremain limited in applicability or performance: indexes optimized for a\nspecific attribute achieve high efficiency for filters on that attribute but\nfail to support complex filters with arbitrary conjunctions and disjunctions\nover multiple attributes. Inspired by the design of relational databases, this\npaper presents PathFinder, a new indexing framework that allows users to\nselectively create ANNS indexes optimized for filters on specific attributes\nand employs a cost-based optimizer to efficiently utilize them for processing\ncomplex filters. PathFinder includes three novel techniques: 1) a new\noptimization metric that captures the tradeoff between query execution time and\naccuracy, 2) a two-phase optimization for handling filters with conjunctions\nand disjunctions, and 3) an index borrowing optimization that uses an\nattribute-specific index to process filters on another attribute. Experiments\non four real-world datasets show that PathFinder outperforms the best baseline\nby up to 9.8x in query throughput at recall 0.95.", "AI": {"tldr": "PathFinder\u662f\u4e00\u4e2a\u65b0\u7684\u8fc7\u6ee4\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7d22\u5f15\u6846\u67b6\uff0c\u652f\u6301\u590d\u6742\u591a\u5c5e\u6027\u8fc7\u6ee4\u6761\u4ef6\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u521b\u5efa\u5c5e\u6027\u7279\u5b9a\u7d22\u5f15\u548c\u57fa\u4e8e\u6210\u672c\u7684\u4f18\u5316\u5668\u5b9e\u73b0\u9ad8\u6548\u67e5\u8be2\u5904\u7406\u3002", "motivation": "\u73b0\u6709\u56fe\u57faANNS\u7d22\u5f15\u5728\u5904\u7406\u590d\u6742\u591a\u5c5e\u6027\u8fc7\u6ee4\u6761\u4ef6\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u8981\u4e48\u53ea\u9488\u5bf9\u7279\u5b9a\u5c5e\u6027\u4f18\u5316\uff0c\u8981\u4e48\u65e0\u6cd5\u6709\u6548\u652f\u6301\u5305\u542b\u5408\u53d6\u548c\u6790\u53d6\u7684\u590d\u6742\u8fc7\u6ee4\u6761\u4ef6\u3002", "method": "1) \u5f15\u5165\u65b0\u7684\u4f18\u5316\u6307\u6807\u5e73\u8861\u67e5\u8be2\u6267\u884c\u65f6\u95f4\u548c\u51c6\u786e\u6027\uff1b2) \u4e24\u9636\u6bb5\u4f18\u5316\u5904\u7406\u5408\u53d6\u548c\u6790\u53d6\u8fc7\u6ee4\u6761\u4ef6\uff1b3) \u7d22\u5f15\u501f\u7528\u4f18\u5316\uff0c\u4f7f\u7528\u5c5e\u6027\u7279\u5b9a\u7d22\u5f15\u5904\u7406\u5176\u4ed6\u5c5e\u6027\u7684\u8fc7\u6ee4\u6761\u4ef6\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPathFinder\u5728\u53ec\u56de\u73870.95\u65f6\uff0c\u67e5\u8be2\u541e\u5410\u91cf\u6bd4\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u9ad8\u8fbe9.8\u500d\u3002", "conclusion": "PathFinder\u6846\u67b6\u901a\u8fc7\u5173\u7cfb\u6570\u636e\u5e93\u7684\u8bbe\u8ba1\u7406\u5ff5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u8fc7\u6ee4\u6761\u4ef6\u4e0b\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u6027\u80fd\u3002"}}
{"id": "2511.01239", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2511.01239", "abs": "https://arxiv.org/abs/2511.01239", "authors": ["Dipan Dey", "Telikepalli Kavitha"], "title": "Fault-Tolerant Approximate Distance Oracles with a Source Set", "comment": null, "summary": "Our input is an undirected weighted graph $G = (V,E)$ on $n$ vertices along\nwith a source set $S\\subseteq V$. The problem is to preprocess $G$ and build a\ncompact data structure such that upon query $Qu(s,v,f)$ where $(s,v) \\in\nS\\times V$ and $f$ is any faulty edge, we can quickly find a good estimate\n(i.e., within a small multiplicative stretch) of the $s$-$v$ distance in $G-f$.\nWe use a fault-tolerant $ST$-distance oracle from the work of Bil{\\`{o}} et al.\n(STACS 2018) to construct an $S\\times V$ approximate distance oracle or {\\em\nsourcewise} approximate distance oracle of size $\\widetilde{O}(|S|n + n^{3/2})$\nwith multiplicative stretch at most 5. We construct another fault-tolerant\nsourcewise approximate distance oracle of size $\\widetilde{O}(|S|n + n^{4/3})$\nwith multiplicative stretch at most 13. Both the oracles have $O(1)$ query\nanswering time.", "AI": {"tldr": "\u6784\u5efa\u5bb9\u9519\u7684\u6e90\u8fd1\u4f3c\u8ddd\u79bb\u9884\u8a00\u673a\uff0c\u652f\u6301\u5728\u5355\u8fb9\u6545\u969c\u60c5\u51b5\u4e0b\u5feb\u901f\u67e5\u8be2\u6e90\u96c6S\u5230\u4efb\u610f\u9876\u70b9v\u7684\u8fd1\u4f3c\u8ddd\u79bb\u3002", "motivation": "\u89e3\u51b3\u5728\u8fb9\u6545\u969c\u60c5\u51b5\u4e0b\uff0c\u5feb\u901f\u4f30\u8ba1\u6e90\u96c6S\u4e2d\u9876\u70b9\u5230\u5176\u4ed6\u9876\u70b9\u8ddd\u79bb\u7684\u95ee\u9898\uff0c\u8fd9\u5728\u7f51\u7edc\u8def\u7531\u3001\u6545\u969c\u6062\u590d\u7b49\u573a\u666f\u4e2d\u5f88\u91cd\u8981\u3002", "method": "\u57fa\u4e8eBil\u00f2\u7b49\u4eba\u7684\u5bb9\u9519ST\u8ddd\u79bb\u9884\u8a00\u673a\uff0c\u6784\u5efa\u4e24\u79cd\u4e0d\u540c\u5927\u5c0f\u7684\u6e90\u8fd1\u4f3c\u8ddd\u79bb\u9884\u8a00\u673a\uff1a\u4e00\u79cd\u5927\u5c0fO(|S|n + n^{3/2})\uff0c\u53e6\u4e00\u79cdO(|S|n + n^{4/3})\u3002", "result": "\u7b2c\u4e00\u4e2a\u9884\u8a00\u673a\u5177\u67095\u500d\u4e58\u6cd5\u62c9\u4f38\uff0c\u7b2c\u4e8c\u4e2a\u5177\u670913\u500d\u4e58\u6cd5\u62c9\u4f38\uff0c\u4e24\u8005\u90fd\u652f\u6301O(1)\u67e5\u8be2\u65f6\u95f4\u3002", "conclusion": "\u6210\u529f\u6784\u5efa\u4e86\u9ad8\u6548\u7684\u5bb9\u9519\u6e90\u8fd1\u4f3c\u8ddd\u79bb\u9884\u8a00\u673a\uff0c\u5728\u5b58\u50a8\u7a7a\u95f4\u548c\u67e5\u8be2\u7cbe\u5ea6\u4e4b\u95f4\u63d0\u4f9b\u4e86\u6743\u8861\u9009\u62e9\u3002"}}
{"id": "2511.00694", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.00694", "abs": "https://arxiv.org/abs/2511.00694", "authors": ["Uthman Jinadu", "Siawpeng Er", "Le Yu", "Chen Liang", "Bingxin Li", "Yi Ding", "Aleksandar Velkoski"], "title": "Taxonomy-based Negative Sampling In Personalized Semantic Search for E-commerce", "comment": "Accepted at 2025 IEEE International Conference on Big Data", "summary": "Large retail outlets offer products that may be domain-specific, and this\nrequires having a model that can understand subtle differences in similar\nitems. Sampling techniques used to train these models are most of the time,\ncomputationally expensive or logistically challenging. These models also do not\nfactor in users' previous purchase patterns or behavior, thereby retrieving\nirrelevant items for them. We present a semantic retrieval model for e-commerce\nsearch that embeds queries and products into a shared vector space and\nleverages a novel taxonomy-based hard-negative sampling(TB-HNS) strategy to\nmine contextually relevant yet challenging negatives. To further tailor\nretrievals, we incorporate user-level personalization by modeling each\ncustomer's past purchase history and behavior. In offline experiments, our\napproach outperforms BM25, ANCE and leading neural baselines on Recall@K, while\nlive A/B testing shows substantial uplifts in conversion rate, add-to-cart\nrate, and average order value. We also demonstrate that our taxonomy-driven\nnegatives reduce training overhead and accelerate convergence, and we share\npractical lessons from deploying this system at scale.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7535\u5546\u641c\u7d22\u7684\u8bed\u4e49\u68c0\u7d22\u6a21\u578b\uff0c\u91c7\u7528\u57fa\u4e8e\u5206\u7c7b\u7684\u56f0\u96be\u8d1f\u6837\u672c\u91c7\u6837\u7b56\u7565\uff0c\u5e76\u6574\u5408\u7528\u6237\u4e2a\u6027\u5316\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u6548\u679c\u548c\u4e1a\u52a1\u6307\u6807\u3002", "motivation": "\u4f20\u7edf\u7535\u5546\u641c\u7d22\u6a21\u578b\u96be\u4ee5\u7406\u89e3\u7279\u5b9a\u9886\u57df\u7684\u7ec6\u5fae\u5546\u54c1\u5dee\u5f02\uff0c\u91c7\u6837\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4e14\u672a\u8003\u8651\u7528\u6237\u5386\u53f2\u8d2d\u4e70\u884c\u4e3a\uff0c\u5bfc\u81f4\u68c0\u7d22\u7ed3\u679c\u4e0d\u76f8\u5173\u3002", "method": "\u6784\u5efa\u67e5\u8be2\u548c\u5546\u54c1\u5171\u4eab\u5411\u91cf\u7a7a\u95f4\uff0c\u91c7\u7528\u57fa\u4e8e\u5206\u7c7b\u7684\u56f0\u96be\u8d1f\u6837\u672c\u91c7\u6837\u7b56\u7565\u6316\u6398\u4e0a\u4e0b\u6587\u76f8\u5173\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u8d1f\u6837\u672c\uff0c\u5e76\u6574\u5408\u7528\u6237\u5386\u53f2\u8d2d\u4e70\u884c\u4e3a\u8fdb\u884c\u4e2a\u6027\u5316\u5efa\u6a21\u3002", "result": "\u7ebf\u4e0b\u5b9e\u9a8c\u5728Recall@K\u6307\u6807\u4e0a\u4f18\u4e8eBM25\u3001ANCE\u7b49\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7ebf\u4e0aA/B\u6d4b\u8bd5\u663e\u793a\u8f6c\u5316\u7387\u3001\u52a0\u8d2d\u7387\u548c\u5ba2\u5355\u4ef7\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u5206\u7c7b\u9a71\u52a8\u7684\u8d1f\u6837\u672c\u51cf\u5c11\u4e86\u8bad\u7ec3\u5f00\u9500\u5e76\u52a0\u901f\u6536\u655b\u3002", "conclusion": "\u8be5\u8bed\u4e49\u68c0\u7d22\u6a21\u578b\u901a\u8fc7\u6709\u6548\u7684\u8d1f\u6837\u672c\u91c7\u6837\u548c\u4e2a\u6027\u5316\u6574\u5408\uff0c\u5728\u7535\u5546\u641c\u7d22\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5206\u4eab\u4e86\u5927\u89c4\u6a21\u90e8\u7f72\u7684\u5b9e\u8df5\u7ecf\u9a8c\u3002"}}
{"id": "2511.00953", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00953", "abs": "https://arxiv.org/abs/2511.00953", "authors": ["Lewen Wang", "Sihuang Hu"], "title": "Lower Bounds on Conversion Bandwidth for MDS Convertible Codes in Split Regime", "comment": null, "summary": "We propose several new lower bounds on the bandwidth costs of MDS convertible\ncodes using a linear-algebraic framework. The derived bounds improve previous\nresults in certain parameter regimes and match the bandwidth cost of the\nconstruction proposed by Maturana and Rashmi (2022 IEEE International Symposium\non Information Theory) for $r^F\\le r^I\\le k^F$, implying that our bounds are\ntight in this case.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u51e0\u4e2a\u65b0\u7684MDS\u53ef\u8f6c\u6362\u7801\u5e26\u5bbd\u6210\u672c\u4e0b\u754c\uff0c\u6539\u8fdb\u4e86\u7279\u5b9a\u53c2\u6570\u8303\u56f4\u5185\u7684\u5148\u524d\u7ed3\u679c\uff0c\u5e76\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4e0e\u73b0\u6709\u6784\u9020\u5339\u914d\uff0c\u8bc1\u660e\u8fd9\u4e9b\u4e0b\u754c\u662f\u7d27\u7684\u3002", "motivation": "\u73b0\u6709MDS\u53ef\u8f6c\u6362\u7801\u7684\u5e26\u5bbd\u6210\u672c\u4e0b\u754c\u5728\u67d0\u4e9b\u53c2\u6570\u8303\u56f4\u5185\u4e0d\u591f\u7d27\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u7406\u8bba\u754c\u9650\u6765\u6307\u5bfc\u6700\u4f18\u7f16\u7801\u8bbe\u8ba1\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u4ee3\u6570\u6846\u67b6\u63a8\u5bfcMDS\u53ef\u8f6c\u6362\u7801\u7684\u5e26\u5bbd\u6210\u672c\u4e0b\u754c\u3002", "result": "\u63a8\u5bfc\u7684\u4e0b\u754c\u6539\u8fdb\u4e86\u5148\u524d\u7ed3\u679c\uff0c\u5e76\u5728r^F \u2264 r^I \u2264 k^F\u53c2\u6570\u8303\u56f4\u5185\u4e0eMaturana\u548cRashmi\u7684\u6784\u9020\u5339\u914d\uff0c\u8bc1\u660e\u4e0b\u754c\u662f\u7d27\u7684\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ebf\u6027\u4ee3\u6570\u65b9\u6cd5\u6709\u6548\u63a8\u5bfc\u4e86MDS\u53ef\u8f6c\u6362\u7801\u7684\u7d27\u5e26\u5bbd\u6210\u672c\u4e0b\u754c\uff0c\u4e3a\u6700\u4f18\u7f16\u7801\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.01025", "categories": ["cs.DB", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.01025", "abs": "https://arxiv.org/abs/2511.01025", "authors": ["Huihui Yang", "Pingpeng Yuan"], "title": "Fast Answering Pattern-Constrained Reachability Queries with Two-Dimensional Reachability Index", "comment": null, "summary": "Reachability queries ask whether there exists a path from the source vertex\nto the target vertex on a graph. Recently, several powerful reachability\nqueries, such as Label-Constrained Reachability (LCR) queries and Regular Path\nQueries (RPQ), have been proposed for emerging complex edge-labeled digraphs.\nHowever, they cannot allow users to describe complex query requirements by\ncomposing query patterns. Here, we introduce composite patterns, a logical\nexpression of patterns that can express complex constraints on the set of\nlabels. Based on pattern, we propose pattern-constrained reachability queries\n(PCR queries). However, answering PCR queries is NP-hard. Thus, to improve the\nperformance to answer PCR queries, we build a two-dimensional reachability (TDR\nfor short) index which consists of a multi-way index (horizontal dimension) and\na path index (vertical dimension). Because the number of combinations of both\nlabels and vertices is exponential, it is very expensive to build full indices\nthat contain all the reachability information. Thus, the reachable vertices of\na vertex are decomposed into blocks, each of which is hashed into the\nhorizontal dimension index and the vertical dimension index, respectively. The\nindices in the horizontal dimension and the vertical dimension serve as a\nglobal filter and a local filter, respectively, to prune the search space.\nExperimental results demonstrate that our index size and indexing time\noutperform the state-of-the-art label-constrained reachability indexing\ntechnique on 16 real datasets. TDR can efficiently answer pattern-constrained\nreachability queries, including label-constrained reachability queries.", "AI": {"tldr": "\u63d0\u51fa\u6a21\u5f0f\u7ea6\u675f\u53ef\u8fbe\u6027\u67e5\u8be2(PCR)\u548c\u4e8c\u7ef4\u53ef\u8fbe\u6027\u7d22\u5f15(TDR)\uff0c\u7528\u4e8e\u5728\u8fb9\u6807\u8bb0\u6709\u5411\u56fe\u4e0a\u9ad8\u6548\u5904\u7406\u590d\u6742\u7684\u6a21\u5f0f\u7ea6\u675f\u53ef\u8fbe\u6027\u67e5\u8be2\u3002", "motivation": "\u73b0\u6709\u7684\u6807\u7b7e\u7ea6\u675f\u53ef\u8fbe\u6027\u67e5\u8be2\u548c\u6b63\u5219\u8def\u5f84\u67e5\u8be2\u65e0\u6cd5\u901a\u8fc7\u7ec4\u5408\u67e5\u8be2\u6a21\u5f0f\u6765\u63cf\u8ff0\u590d\u6742\u7684\u67e5\u8be2\u9700\u6c42\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8868\u8fbe\u590d\u6742\u6807\u7b7e\u7ea6\u675f\u7684\u53ef\u8fbe\u6027\u67e5\u8be2\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e8c\u7ef4\u53ef\u8fbe\u6027\u7d22\u5f15(TDR)\uff0c\u5305\u542b\u591a\u8def\u7d22\u5f15(\u6c34\u5e73\u7ef4\u5ea6)\u548c\u8def\u5f84\u7d22\u5f15(\u5782\u76f4\u7ef4\u5ea6)\uff0c\u901a\u8fc7\u5c06\u53ef\u8fbe\u9876\u70b9\u5206\u89e3\u4e3a\u5757\u5e76\u5206\u522b\u54c8\u5e0c\u5230\u4e24\u4e2a\u7ef4\u5ea6\u7684\u7d22\u5f15\u4e2d\uff0c\u4f5c\u4e3a\u5168\u5c40\u548c\u5c40\u90e8\u8fc7\u6ee4\u5668\u6765\u526a\u679d\u641c\u7d22\u7a7a\u95f4\u3002", "result": "\u572816\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u7d22\u5f15\u5927\u5c0f\u548c\u7d22\u5f15\u6784\u5efa\u65f6\u95f4\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6807\u7b7e\u7ea6\u675f\u53ef\u8fbe\u6027\u7d22\u5f15\u6280\u672f\uff0c\u80fd\u591f\u9ad8\u6548\u56de\u7b54\u6a21\u5f0f\u7ea6\u675f\u53ef\u8fbe\u6027\u67e5\u8be2\u3002", "conclusion": "\u63d0\u51fa\u7684PCR\u67e5\u8be2\u548cTDR\u7d22\u5f15\u80fd\u591f\u6709\u6548\u5904\u7406\u590d\u6742\u7684\u6a21\u5f0f\u7ea6\u675f\u53ef\u8fbe\u6027\u67e5\u8be2\uff0c\u5305\u62ec\u6807\u7b7e\u7ea6\u675f\u53ef\u8fbe\u6027\u67e5\u8be2\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2511.01376", "categories": ["cs.DS", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.01376", "abs": "https://arxiv.org/abs/2511.01376", "authors": ["Jialong Zhou", "Ben Bals", "Matei Tinca", "Ai Guan", "Panagiotis Charalampopoulos", "Grigorios Loukides", "Solon P. Pissis"], "title": "Subtree Mode and Applications", "comment": "For reproduction, code available at\n  https://github.com/JialongZhou666/subtree-mode-mining", "summary": "The mode of a collection of values (i.e., the most frequent value in the\ncollection) is a key summary statistic. Finding the mode in a given range of an\narray of values is thus of great importance, and constructing a data structure\nto solve this problem is in fact the well-known Range Mode problem. In this\nwork, we introduce the Subtree Mode (SM) problem, the analogous problem in a\nleaf-colored tree, where the task is to compute the most frequent color in the\nleaves of the subtree of a given node. SM is motivated by several applications\nin domains such as text analytics and biology, where the data are hierarchical\nand can thus be represented as a (leaf-colored) tree. Our central contribution\nis a time-optimal algorithm for SM that computes the answer for every node of\nan input $N$-node tree in $O(N)$ time. We further show how our solution can be\nadapted for node-colored trees, or for computing the $k$ most frequent colors,\nin the optimal $O(N)$ time, for any given $k=O(1)$. Moreover, we prove that a\nsimilarly fast solution for when the input is a sink-colored directed acyclic\ngraph instead of a leaf-colored tree is highly unlikely. Our experiments on\nreal datasets with trees of up to 7.3 billion nodes demonstrate that our\nalgorithm is faster than baselines by at least one order of magnitude and much\nmore space efficient. Last, we present case studies showing the effectiveness\nof our approach in pattern mining and sequence-to-database search applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5b50\u6811\u4f17\u6570\u95ee\u9898\uff0c\u5728\u53f6\u7740\u8272\u6811\u4e2d\u8ba1\u7b97\u6bcf\u4e2a\u8282\u70b9\u5b50\u6811\u4e2d\u51fa\u73b0\u6700\u9891\u7e41\u7684\u989c\u8272\uff0c\u5e76\u7ed9\u51fa\u4e86\u65f6\u95f4\u590d\u6742\u5ea6\u6700\u4f18\u7684O(N)\u7b97\u6cd5\u3002", "motivation": "\u5b50\u6811\u4f17\u6570\u95ee\u9898\u5728\u6587\u672c\u5206\u6790\u548c\u751f\u7269\u5b66\u7b49\u5177\u6709\u5c42\u6b21\u7ed3\u6784\u6570\u636e\u7684\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\uff0c\u9700\u8981\u9ad8\u6548\u8ba1\u7b97\u6811\u7ed3\u6784\u4e2d\u6bcf\u4e2a\u8282\u70b9\u7684\u4f17\u6570\u989c\u8272\u3002", "method": "\u5f00\u53d1\u4e86\u65f6\u95f4\u6700\u4f18\u7b97\u6cd5\uff0c\u5728O(N)\u65f6\u95f4\u5185\u8ba1\u7b97\u8f93\u5165N\u8282\u70b9\u6811\u4e2d\u6bcf\u4e2a\u8282\u70b9\u7684\u5b50\u6811\u4f17\u6570\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u8282\u70b9\u7740\u8272\u6811\u548c\u8ba1\u7b97\u524dk\u4e2a\u6700\u9891\u7e41\u989c\u8272\u3002", "result": "\u5728\u5305\u542b73\u4ebf\u4e2a\u8282\u70b9\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u7b97\u6cd5\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5feb\u81f3\u5c11\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u4e14\u7a7a\u95f4\u6548\u7387\u66f4\u9ad8\u3002\u8bc1\u660e\u4e86\u5728\u6709\u5411\u65e0\u73af\u56fe\u4e0a\u7c7b\u4f3c\u5feb\u901f\u89e3\u6cd5\u7684\u53ef\u80fd\u6027\u5f88\u4f4e\u3002", "conclusion": "\u63d0\u51fa\u7684\u5b50\u6811\u4f17\u6570\u7b97\u6cd5\u9ad8\u6548\u5b9e\u7528\uff0c\u5728\u6a21\u5f0f\u6316\u6398\u548c\u5e8f\u5217\u5230\u6570\u636e\u5e93\u641c\u7d22\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5c42\u6b21\u6570\u636e\u7ed3\u6784\u4e2d\u7684\u4f17\u6570\u8ba1\u7b97\u63d0\u4f9b\u4e86\u6700\u4f18\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00805", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.00805", "abs": "https://arxiv.org/abs/2511.00805", "authors": ["Rishita Agarwal", "Himanshu Singhal", "Peter Baile Chen", "Manan Roy Choudhury", "Dan Roth", "Vivek Gupta"], "title": "REaR: Retrieve, Expand and Refine for Effective Multitable Retrieval", "comment": "13 pages, 2 figures, 8 tables", "summary": "Answering natural language queries over relational data often requires\nretrieving and reasoning over multiple tables, yet most retrievers optimize\nonly for query-table relevance and ignore table table compatibility. We\nintroduce REAR (Retrieve, Expand and Refine), a three-stage, LLM-free framework\nthat separates semantic relevance from structural joinability for efficient,\nhigh-fidelity multi-table retrieval. REAR (i) retrieves query-aligned tables,\n(ii) expands these with structurally joinable tables via fast, precomputed\ncolumn-embedding comparisons, and (iii) refines them by pruning noisy or weakly\nrelated candidates. Empirically, REAR is retriever-agnostic and consistently\nimproves dense/sparse retrievers on complex table QA datasets (BIRD, MMQA, and\nSpider) by improving both multi-table retrieval quality and downstream SQL\nexecution. Despite being LLM-free, it delivers performance competitive with\nstate-of-the-art LLM-augmented retrieval systems (e.g.,ARM) while achieving\nmuch lower latency and cost. Ablations confirm complementary gains from\nexpansion and refinement, underscoring REAR as a practical, scalable building\nblock for table-based downstream tasks (e.g., Text-to-SQL).", "AI": {"tldr": "REAR\u662f\u4e00\u4e2a\u4e09\u9636\u6bb5\u3001\u65e0\u9700LLM\u7684\u591a\u8868\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u8bed\u4e49\u76f8\u5173\u6027\u548c\u7ed3\u6784\u53ef\u8fde\u63a5\u6027\u6765\u6539\u8fdb\u590d\u6742\u8868\u683c\u95ee\u7b54\u4e2d\u7684\u591a\u8868\u68c0\u7d22\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u68c0\u7d22\u5668\u4e3b\u8981\u4f18\u5316\u67e5\u8be2-\u8868\u683c\u76f8\u5173\u6027\uff0c\u4f46\u5ffd\u7565\u4e86\u8868\u683c\u95f4\u7684\u7ed3\u6784\u517c\u5bb9\u6027\uff0c\u5bfc\u81f4\u5728\u9700\u8981\u591a\u8868\u63a8\u7406\u7684\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a(1)\u68c0\u7d22\u67e5\u8be2\u5bf9\u9f50\u7684\u8868\u683c\uff0c(2)\u901a\u8fc7\u9884\u8ba1\u7b97\u7684\u5217\u5d4c\u5165\u6bd4\u8f83\u6269\u5c55\u7ed3\u6784\u53ef\u8fde\u63a5\u7684\u8868\u683c\uff0c(3)\u901a\u8fc7\u4fee\u526a\u566a\u58f0\u6216\u5f31\u76f8\u5173\u5019\u9009\u8868\u683c\u8fdb\u884c\u7cbe\u70bc\u3002", "result": "\u5728BIRD\u3001MMQA\u548cSpider\u7b49\u590d\u6742\u8868\u683c\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\uff0cREAR\u663e\u8457\u63d0\u5347\u4e86\u5bc6\u96c6/\u7a00\u758f\u68c0\u7d22\u5668\u7684\u6027\u80fd\uff0c\u5728\u591a\u8868\u68c0\u7d22\u8d28\u91cf\u548c\u4e0b\u6e38SQL\u6267\u884c\u65b9\u9762\u90fd\u6709\u6539\u8fdb\u3002", "conclusion": "REAR\u662f\u4e00\u4e2a\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u7684\u6784\u5efa\u5757\uff0c\u65e0\u9700LLM\u5c31\u80fd\u8fbe\u5230\u4e0e\u6700\u5148\u8fdbLLM\u589e\u5f3a\u68c0\u7d22\u7cfb\u7edf\u7ade\u4e89\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5177\u6709\u66f4\u4f4e\u7684\u5ef6\u8fdf\u548c\u6210\u672c\u3002"}}
{"id": "2511.00959", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00959", "abs": "https://arxiv.org/abs/2511.00959", "authors": ["Bui Duc Son", "Gaosheng Zhao", "Trinh Van Chien", "Dong In Kim"], "title": "Secure Distributed RIS-MIMO over Double Scattering Channels: Adversarial Attack, Defense, and SER Improvement", "comment": "15 pages, 7 figures, 7 tables. Accepted by IEEE TCOM", "summary": "There has been a growing trend toward leveraging machine learning (ML) and\ndeep learning (DL) techniques to optimize and enhance the performance of\nwireless communication systems. However, limited attention has been given to\nthe vulnerabilities of these techniques, particularly in the presence of\nadversarial attacks. This paper investigates the adversarial attack and defense\nin distributed multiple reconfigurable intelligent surfaces (RISs)-aided\nmultiple-input multiple-output (MIMO) communication systems-based autoencoder\nin finite scattering environments. We present the channel propagation model for\ndistributed multiple RIS, including statistical information driven in closed\nform for the aggregated channel. The symbol error rate (SER) is selected to\nevaluate the collaborative dynamics between the distributed RISs and MIMO\ncommunication in depth. The relationship between the number of RISs and the SER\nof the proposed system based on an autoencoder, as well as the impact of\nadversarial attacks on the system's SER, is analyzed in detail. We also propose\na defense mechanism based on adversarial training against the considered\nattacks to enhance the model's robustness. Numerical results indicate that\nincreasing the number of RISs effectively reduces the system's SER but leads to\nthe adversarial attack-based algorithm becoming more destructive in the\nwhite-box attack scenario. The proposed defense method demonstrates strong\neffectiveness by significantly mitigating the attack's impact. It also\nsubstantially reduces the system's SER in the absence of an attack compared to\nthe original model. Moreover, we extend the phenomenon to include decoder\nmobility, demonstrating that the proposed method maintains robustness under\nDoppler-induced channel variations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5206\u5e03\u5f0f\u591aRIS\u8f85\u52a9MIMO\u901a\u4fe1\u7cfb\u7edf\u4e2d\u57fa\u4e8e\u81ea\u52a8\u7f16\u7801\u5668\u7684\u5bf9\u6297\u653b\u51fb\u4e0e\u9632\u5fa1\uff0c\u5206\u6790\u4e86RIS\u6570\u91cf\u4e0e\u7cfb\u7edf\u6027\u80fd\u7684\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u4e86\u6709\u6548\u7684\u5bf9\u6297\u8bad\u7ec3\u9632\u5fa1\u673a\u5236\u3002", "motivation": "\u5f53\u524d\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u5e7f\u6cdb\u91c7\u7528\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u8fdb\u884c\u4f18\u5316\uff0c\u4f46\u8fd9\u4e9b\u6280\u672f\u5728\u9762\u5bf9\u5bf9\u6297\u653b\u51fb\u65f6\u7684\u8106\u5f31\u6027\u7814\u7a76\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u5206\u5e03\u5f0f\u591aRIS\u8f85\u52a9\u7684MIMO\u7cfb\u7edf\u4e2d\u3002", "method": "\u5efa\u7acb\u4e86\u5206\u5e03\u5f0f\u591aRIS\u7684\u4fe1\u9053\u4f20\u64ad\u6a21\u578b\uff0c\u63a8\u5bfc\u4e86\u805a\u5408\u4fe1\u9053\u7684\u95ed\u5f0f\u7edf\u8ba1\u4fe1\u606f\u8868\u8fbe\u5f0f\uff0c\u4f7f\u7528\u7b26\u53f7\u9519\u8bef\u7387(SER)\u8bc4\u4f30\u7cfb\u7edf\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u5bf9\u6297\u8bad\u7ec3\u7684\u9632\u5fa1\u673a\u5236\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff1a\u589e\u52a0RIS\u6570\u91cf\u80fd\u964d\u4f4e\u7cfb\u7edfSER\uff0c\u4f46\u4f1a\u4f7f\u767d\u76d2\u653b\u51fb\u66f4\u5177\u7834\u574f\u6027\uff1b\u63d0\u51fa\u7684\u9632\u5fa1\u65b9\u6cd5\u80fd\u663e\u8457\u51cf\u8f7b\u653b\u51fb\u5f71\u54cd\uff0c\u5e76\u5728\u65e0\u653b\u51fb\u65f6\u76f8\u6bd4\u539f\u59cb\u6a21\u578b\u8fdb\u4e00\u6b65\u964d\u4f4eSER\uff1b\u8be5\u65b9\u6cd5\u5728\u5305\u542b\u591a\u666e\u52d2\u6548\u5e94\u7684\u79fb\u52a8\u573a\u666f\u4e2d\u4ecd\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "\u5206\u5e03\u5f0f\u591aRIS\u7cfb\u7edf\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u5b58\u5728\u8106\u5f31\u6027\uff0c\u4f46\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u8be5\u65b9\u6cd5\u5728\u79fb\u52a8\u573a\u666f\u4e2d\u4f9d\u7136\u6709\u6548\u3002"}}
{"id": "2511.01602", "categories": ["cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01602", "abs": "https://arxiv.org/abs/2511.01602", "authors": ["Xinyue Yang", "Chen Zheng", "Yaoyang Hou", "Renhao Zhang", "Yiyan Zhang", "Yanjun Wu", "Heng Zhang"], "title": "L2T-Tune:LLM-Guided Hybrid Database Tuning with LHS and TD3", "comment": null, "summary": "Configuration tuning is critical for database performance. Although recent\nadvancements in database tuning have shown promising results in throughput and\nlatency improvement, challenges remain. First, the vast knob space makes direct\noptimization unstable and slow to converge. Second, reinforcement learning\npipelines often lack effective warm-start guidance and require long offline\ntraining. Third, transferability is limited: when hardware or workloads change,\nexisting models typically require substantial retraining to recover\nperformance.\n  To address these limitations, we propose L2T-Tune, a new LLM-guided hybrid\ndatabase tuning framework that features a three-stage pipeline: Stage one\nperforms a warm start that simultaneously generates uniform samples across the\nknob space and logs them into a shared pool; Stage two leverages a large\nlanguage model to mine and prioritize tuning hints from manuals and community\ndocuments for rapid convergence. Stage three uses the warm-start sample pool to\nreduce the dimensionality of knobs and state features, then fine-tunes the\nconfiguration with the Twin Delayed Deep Deterministic Policy Gradient\nalgorithm.\n  We conduct experiments on L2T-Tune and the state-of-the-art models. Compared\nwith the best-performing alternative, our approach improves performance by an\naverage of 37.1% across all workloads, and by up to 73% on TPC-C. Compared with\nmodels trained with reinforcement learning, it achieves rapid convergence in\nthe offline tuning stage on a single server. Moreover, during the online tuning\nstage, it only takes 30 steps to achieve best results.", "AI": {"tldr": "L2T-Tune\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6df7\u5408\u6570\u636e\u5e93\u8c03\u4f18\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u6d41\u7a0b\u89e3\u51b3\u4f20\u7edf\u8c03\u4f18\u65b9\u6cd5\u5728\u6536\u655b\u901f\u5ea6\u3001\u51b7\u542f\u52a8\u548c\u53ef\u8fc1\u79fb\u6027\u65b9\u9762\u7684\u6311\u6218\u3002", "motivation": "\u89e3\u51b3\u6570\u636e\u5e93\u914d\u7f6e\u8c03\u4f18\u4e2d\u7684\u4e09\u5927\u6311\u6218\uff1a\u5de8\u5927\u53c2\u6570\u7a7a\u95f4\u5bfc\u81f4\u4f18\u5316\u4e0d\u7a33\u5b9a\u3001\u5f3a\u5316\u5b66\u4e60\u7f3a\u4e4f\u6709\u6548\u9884\u70ed\u6307\u5bfc\u3001\u786c\u4ef6\u6216\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\u65f6\u6a21\u578b\u8fc1\u79fb\u6027\u5dee\u3002", "method": "\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a1) \u9884\u70ed\u9636\u6bb5\u751f\u6210\u5747\u5300\u6837\u672c\u5e76\u5b58\u5165\u5171\u4eab\u6c60\uff1b2) \u4f7f\u7528LLM\u4ece\u624b\u518c\u548c\u793e\u533a\u6587\u6863\u6316\u6398\u8c03\u4f18\u63d0\u793a\uff1b3) \u964d\u7ef4\u540e\u4f7f\u7528TD3\u7b97\u6cd5\u5fae\u8c03\u914d\u7f6e\u3002", "result": "\u76f8\u6bd4\u6700\u4f73\u66ff\u4ee3\u65b9\u6cd5\uff0c\u5728\u6240\u6709\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u5e73\u5747\u6027\u80fd\u63d0\u534737.1%\uff0cTPC-C\u4e0a\u6700\u9ad8\u63d0\u534773%\uff1b\u79bb\u7ebf\u8c03\u4f18\u9636\u6bb5\u5feb\u901f\u6536\u655b\uff0c\u5728\u7ebf\u8c03\u4f18\u4ec5\u970030\u6b65\u8fbe\u5230\u6700\u4f73\u7ed3\u679c\u3002", "conclusion": "L2T-Tune\u901a\u8fc7LLM\u5f15\u5bfc\u7684\u6df7\u5408\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u6570\u636e\u5e93\u8c03\u4f18\u7684\u5173\u952e\u6311\u6218\uff0c\u5728\u6027\u80fd\u548c\u6536\u655b\u901f\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2511.01769", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2511.01769", "abs": "https://arxiv.org/abs/2511.01769", "authors": ["Omri Ben-Eliezer", "Krzysztof Onak", "Sandeep Silwal"], "title": "Robust Streaming Against Low-Memory Adversaries", "comment": null, "summary": "Robust streaming, the study of streaming algorithms that provably work when\nthe stream is generated by an adaptive adversary, has seen tremendous progress\nin recent years. However, fundamental barriers remain: the best known algorithm\nfor turnstile $F_p$-estimation in the robust streaming setting is exponentially\nworse than in the oblivious setting, and closing this gap seems difficult.\nArguably, one possible cause of this barrier is the adversarial model, which\nmay be too strong: unlike the space-bounded streaming algorithm, the adversary\ncan memorize the entire history of the interaction with the algorithm. Can we\nthen close the exponential gap if we insist that the adversary itself is an\nadaptive but low-memory entity, roughly as powerful as (or even weaker than)\nthe algorithm?\n  In this work we present the first set of models and results aimed towards\nthis question. We design efficient robust streaming algorithms against\nadversaries that are fully adaptive but have no long-term memory (\"memoryless\")\nor very little memory of the history of interaction. Roughly speaking, a\nmemoryless adversary only sees, at any given round, the last output of the\nalgorithm (and does not even know the current time) and can generate an\nunlimited number of independent coin tosses. A low-memory adversary is similar,\nbut maintains an additional small buffer. While these adversaries may seem\nquite limited at first glance, we show that this adversarial model is strong\nenough to produce streams that have high flip number and density in the context\nof $F_2$-estimation, which rules out most of known robustification techniques.\nWe then design a new simple approach, similar to the computation paths\nframework, to obtain efficient algorithms against memoryless and low-memory\nadversaries for a wide class of order-invariant problems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u9488\u5bf9\u4f4e\u5185\u5b58\u5bf9\u6297\u8005\u7684\u9c81\u68d2\u6d41\u7b97\u6cd5\uff0c\u63d0\u51fa\u4e86\u5185\u5b58\u65e0\u8bb0\u5fc6\u548c\u4f4e\u5185\u5b58\u5bf9\u6297\u8005\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9488\u5bf9\u8fd9\u7c7b\u5bf9\u6297\u8005\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u9c81\u68d2\u6d41\u7b97\u6cd5\u5728\u5bf9\u6297\u8005\u5b8c\u5168\u81ea\u9002\u5e94\u65f6\u5b58\u5728\u7684\u6307\u6570\u7ea7\u6027\u80fd\u5dee\u8ddd\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u9c81\u68d2\u6d41\u7b97\u6cd5\u5728\u9762\u5bf9\u5b8c\u5168\u81ea\u9002\u5e94\u7684\u5bf9\u6297\u8005\u65f6\u6027\u80fd\u8f83\u5dee\uff0c\u5b58\u5728\u6307\u6570\u7ea7\u5dee\u8ddd\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u53ef\u80fd\u662f\u56e0\u4e3a\u5bf9\u6297\u8005\u6a21\u578b\u8fc7\u4e8e\u5f3a\u5927\uff0c\u80fd\u591f\u8bb0\u4f4f\u6574\u4e2a\u4ea4\u4e92\u5386\u53f2\u3002\u56e0\u6b64\u7814\u7a76\u5f53\u5bf9\u6297\u8005\u672c\u8eab\u4e5f\u662f\u4f4e\u5185\u5b58\u5b9e\u4f53\u65f6\uff0c\u80fd\u5426\u7f29\u5c0f\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u8bbe\u8ba1\u4e86\u5185\u5b58\u65e0\u8bb0\u5fc6\u548c\u4f4e\u5185\u5b58\u5bf9\u6297\u8005\u6a21\u578b\uff0c\u5176\u4e2d\u5185\u5b58\u65e0\u8bb0\u5fc6\u5bf9\u6297\u8005\u53ea\u80fd\u770b\u5230\u7b97\u6cd5\u7684\u6700\u65b0\u8f93\u51fa\uff0c\u4f4e\u5185\u5b58\u5bf9\u6297\u8005\u989d\u5916\u7ef4\u62a4\u4e00\u4e2a\u5c0f\u7f13\u51b2\u533a\u3002\u63d0\u51fa\u4e86\u7c7b\u4f3c\u8ba1\u7b97\u8def\u5f84\u6846\u67b6\u7684\u65b0\u65b9\u6cd5\uff0c\u4e3a\u5e7f\u6cdb\u7c7b\u522b\u7684\u987a\u5e8f\u4e0d\u53d8\u95ee\u9898\u8bbe\u8ba1\u9ad8\u6548\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u8be5\u5bf9\u6297\u6a21\u578b\u8db3\u591f\u5f3a\u5927\uff0c\u80fd\u591f\u4ea7\u751f\u5728F2\u4f30\u8ba1\u4e2d\u5177\u6709\u9ad8\u7ffb\u8f6c\u6570\u548c\u5bc6\u5ea6\u7684\u6d41\uff0c\u6392\u9664\u4e86\u5927\u591a\u6570\u5df2\u77e5\u7684\u9c81\u68d2\u5316\u6280\u672f\u3002\u6210\u529f\u8bbe\u8ba1\u4e86\u9488\u5bf9\u5185\u5b58\u65e0\u8bb0\u5fc6\u548c\u4f4e\u5185\u5b58\u5bf9\u6297\u8005\u7684\u9ad8\u6548\u7b97\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u9650\u5236\u5bf9\u6297\u8005\u7684\u5185\u5b58\u80fd\u529b\uff0c\u80fd\u591f\u663e\u8457\u6539\u5584\u9c81\u68d2\u6d41\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u4e3a\u7f29\u5c0f\u5b8c\u5168\u81ea\u9002\u5e94\u5bf9\u6297\u8005\u4e0e\u65e0\u610f\u8bc6\u5bf9\u6297\u8005\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u548c\u65b9\u6cd5\u3002"}}
{"id": "2511.00875", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00875", "abs": "https://arxiv.org/abs/2511.00875", "authors": ["Amirabbas Afzali", "Amirreza Velae", "Iman Ahmadi", "Mohammad Aliannejadi"], "title": "Controlling Gender Bias in Retrieval via a Backpack Architecture", "comment": null, "summary": "The presence of social biases in large language models (LLMs) has become a\nsignificant concern in AI research. These biases, often embedded in training\ndata, can perpetuate harmful stereotypes and distort decision-making processes.\nWhen LLMs are integrated into ranking systems, they can propagate these biases,\nleading to unfair outcomes in critical applications such as search engines and\nrecommendation systems. Backpack Language Models, unlike traditional\ntransformer-based models that treat text sequences as monolithic structures,\ngenerate outputs as weighted combinations of non-contextual, learned word\naspects, also known as senses. Leveraging this architecture, we propose a\nframework for debiasing ranking tasks. Our experimental results show that this\nframework effectively mitigates gender bias in text retrieval and ranking with\nminimal degradation in performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eBackpack\u8bed\u8a00\u6a21\u578b\u7684\u53bb\u504f\u6846\u67b6\uff0c\u7528\u4e8e\u51cf\u8f7b\u6587\u672c\u68c0\u7d22\u548c\u6392\u5e8f\u4efb\u52a1\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u793e\u4f1a\u504f\u89c1\u4f1a\u4f20\u64ad\u6709\u5bb3\u523b\u677f\u5370\u8c61\uff0c\u5f53\u96c6\u6210\u5230\u6392\u5e8f\u7cfb\u7edf\u4e2d\u65f6\u4f1a\u5bfc\u81f4\u4e0d\u516c\u5e73\u7ed3\u679c\uff0c\u9700\u8981\u6709\u6548\u7684\u53bb\u504f\u65b9\u6cd5\u3002", "method": "\u5229\u7528Backpack\u8bed\u8a00\u6a21\u578b\u7684\u67b6\u6784\u7279\u70b9\uff0c\u901a\u8fc7\u975e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u8bcd\u65b9\u9762\u7ec4\u5408\u751f\u6210\u8f93\u51fa\uff0c\u6784\u5efa\u53bb\u504f\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u6846\u67b6\u80fd\u6709\u6548\u51cf\u8f7b\u6587\u672c\u68c0\u7d22\u548c\u6392\u5e8f\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u4e14\u6027\u80fd\u4e0b\u964d\u6700\u5c0f\u3002", "conclusion": "Backpack\u8bed\u8a00\u6a21\u578b\u7684\u67b6\u6784\u7279\u6027\u4e3a\u6392\u5e8f\u4efb\u52a1\u53bb\u504f\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u80fd\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u51cf\u8f7b\u793e\u4f1a\u504f\u89c1\u3002"}}
{"id": "2511.00999", "categories": ["cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00999", "abs": "https://arxiv.org/abs/2511.00999", "authors": ["Julian Streit", "Franziska Weindel", "Reinhard Heckel"], "title": "Transformer-Based Decoding in Concatenated Coding Schemes Under Synchronization Errors", "comment": "16 pages, 19 figures, a shortened version was published in the ISIT\n  2025 conference", "summary": "We consider the reconstruction of a codeword from multiple noisy copies that\nare independently corrupted by insertions, deletions, and substitutions. This\nproblem arises, for example, in DNA data storage. A common code construction\nuses a concatenated coding scheme that combines an outer linear block code with\nan inner code, which can be either a nonlinear marker code or a convolutional\ncode. Outer decoding is done with Belief Propagation, and inner decoding is\ndone with the Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm. However, the BCJR\nalgorithm scales exponentially with the number of noisy copies, which makes it\ninfeasible to reconstruct a codeword from more than about four copies. In this\nwork, we introduce BCJRFormer, a transformer-based neural inner decoder.\nBCJRFormer achieves error rates comparable to the BCJR algorithm for binary and\nquaternary single-message transmissions of marker codes. Importantly,\nBCJRFormer scales quadratically with the number of noisy copies. This property\nmakes BCJRFormer well-suited for DNA data storage, where multiple reads of the\nsame DNA strand occur. To lower error rates, we replace the Belief Propagation\nouter decoder with a transformer-based decoder. Together, these modifications\nyield an efficient and performant end-to-end transformer-based pipeline for\ndecoding multiple noisy copies affected by insertion, deletion, and\nsubstitution errors. Additionally, we propose a novel cross-attending\ntransformer architecture called ConvBCJRFormer. This architecture extends\nBCJRFormer to decode transmissions of convolutional codewords, serving as an\ninitial step toward joint inner and outer decoding for more general linear code\nclasses.", "AI": {"tldr": "\u63d0\u51faBCJRFormer\uff0c\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u795e\u7ecf\u5185\u89e3\u7801\u5668\uff0c\u7528\u4e8e\u4ece\u591a\u4e2a\u53d7\u63d2\u5165\u3001\u5220\u9664\u548c\u66ff\u6362\u9519\u8bef\u5f71\u54cd\u7684\u566a\u58f0\u526f\u672c\u4e2d\u91cd\u5efa\u7801\u5b57\uff0c\u7279\u522b\u9002\u7528\u4e8eDNA\u6570\u636e\u5b58\u50a8\u573a\u666f\u3002", "motivation": "\u89e3\u51b3DNA\u6570\u636e\u5b58\u50a8\u4e2d\u4ece\u591a\u4e2a\u566a\u58f0\u526f\u672c\u91cd\u5efa\u7801\u5b57\u7684\u95ee\u9898\uff0c\u4f20\u7edfBCJR\u7b97\u6cd5\u5728\u526f\u672c\u6570\u91cf\u589e\u52a0\u65f6\u8ba1\u7b97\u590d\u6742\u5ea6\u5448\u6307\u6570\u589e\u957f\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eTransformer\u7684BCJRFormer\u4f5c\u4e3a\u5185\u89e3\u7801\u5668\u66ff\u4ee3BCJR\u7b97\u6cd5\uff0c\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4ece\u6307\u6570\u7ea7\u964d\u4f4e\u5230\u5e73\u65b9\u7ea7\uff1b\u540c\u65f6\u7528\u57fa\u4e8eTransformer\u7684\u89e3\u7801\u5668\u66ff\u6362\u7f6e\u4fe1\u4f20\u64ad\u5916\u89e3\u7801\u5668\u3002", "result": "BCJRFormer\u5728\u4e8c\u8fdb\u5236\u548c\u56db\u8fdb\u5236\u5355\u6d88\u606f\u4f20\u8f93\u4e2d\u8fbe\u5230\u4e0eBCJR\u7b97\u6cd5\u76f8\u5f53\u7684\u8bef\u7801\u7387\uff0c\u4e14\u80fd\u9ad8\u6548\u5904\u7406\u66f4\u591a\u526f\u672c\u6570\u91cf\u3002", "conclusion": "BCJRFormer\u4e3aDNA\u6570\u636e\u5b58\u50a8\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u6027\u80fd\u826f\u597d\u7684\u7aef\u5230\u7aefTransformer\u89e3\u7801\u7ba1\u9053\uff0c\u5e76\u63d0\u51fa\u4e86ConvBCJRFormer\u67b6\u6784\u4f5c\u4e3a\u5411\u66f4\u901a\u7528\u7ebf\u6027\u7801\u7c7b\u8054\u5408\u89e3\u7801\u7684\u521d\u6b65\u63a2\u7d22\u3002"}}
{"id": "2511.01625", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.01625", "abs": "https://arxiv.org/abs/2511.01625", "authors": ["Han Weng", "Zhou Liu", "Yuanfeng Song", "Xiaoming Yin", "Xing Chen", "Wentao Zhang"], "title": "UniDataBench: Evaluating Data Analytics Agents Across Structured and Unstructured Data", "comment": null, "summary": "In the real business world, data is stored in a variety of sources, including\nstructured relational databases, unstructured databases (e.g., NoSQL\ndatabases), or even CSV/excel files. The ability to extract reasonable insights\nacross these diverse source is vital for business success. Existing benchmarks,\nhowever, are limited in assessing agents' capabilities across these diverse\ndata types. To address this gap, we introduce UniDataBench, a comprehensive\nbenchmark designed to evaluate the performance of data analytics agents in\nhandling diverse data sources. Specifically, UniDataBench is originating from\nreal-life industry analysis report and we then propose a pipeline to remove the\nprivacy and sensitive information. It encompasses a wide array of datasets,\nincluding relational databases, CSV files to NoSQL data, reflecting real-world\nbusiness scenarios, and provides unified framework to assess how effectively\nagents can explore multiple data formats, extract valuable insights, and\ngenerate meaningful summaries and recommendations. Based on UniDataBench, we\npropose a novel LLM-based agent named ReActInsight, an autonomous agent that\nperforms end-to-end analysis over diverse data sources by automatically\ndiscovering cross-source linkages, decomposing goals, and generating robust,\nself-correcting code to extract actionable insights. Our benchmark and agent\ntogether provide a powerful framework for advancing the capabilities of data\nanalytics agents in real-world applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86UniDataBench\u57fa\u51c6\u6d4b\u8bd5\u548cReActInsight\u4ee3\u7406\uff0c\u7528\u4e8e\u8bc4\u4f30\u6570\u636e\u667a\u80fd\u4ee3\u7406\u5728\u5904\u7406\u591a\u6837\u5316\u6570\u636e\u6e90\uff08\u5173\u7cfb\u6570\u636e\u5e93\u3001CSV\u3001NoSQL\u7b49\uff09\u65b9\u9762\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u5b9e\u4e1a\u52a1\u4e2d\u6570\u636e\u5b58\u50a8\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u6e90\u4e2d\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u4ee3\u7406\u5904\u7406\u591a\u6837\u5316\u6570\u636e\u7c7b\u578b\u7684\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u771f\u5b9e\u884c\u4e1a\u5206\u6790\u62a5\u544a\u6784\u5efaUniDataBench\u57fa\u51c6\uff0c\u63d0\u51fa\u9690\u79c1\u4fe1\u606f\u53bb\u9664\u6d41\u7a0b\uff1b\u5f00\u53d1ReActInsight\u4ee3\u7406\uff0c\u80fd\u591f\u81ea\u52a8\u53d1\u73b0\u8de8\u6e90\u5173\u8054\u3001\u5206\u89e3\u76ee\u6807\u5e76\u751f\u6210\u81ea\u4fee\u6b63\u4ee3\u7801\u3002", "result": "\u521b\u5efa\u4e86\u6db5\u76d6\u591a\u79cd\u6570\u636e\u7c7b\u578b\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5f00\u53d1\u4e86\u80fd\u591f\u8fdb\u884c\u7aef\u5230\u7aef\u5206\u6790\u7684\u81ea\u4e3b\u4ee3\u7406\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u548c\u4ee3\u7406\u5171\u540c\u4e3a\u63d0\u5347\u73b0\u5b9e\u5e94\u7528\u4e2d\u6570\u636e\u5206\u6790\u4ee3\u7406\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u5f3a\u5927\u6846\u67b6\u3002"}}
{"id": "2511.01208", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.01208", "abs": "https://arxiv.org/abs/2511.01208", "authors": ["Jerry Huang", "Siddarth Madala", "Cheng Niu", "Julia Hockenmaier", "Tong Zhang"], "title": "Contextual Relevance and Adaptive Sampling for LLM-Based Document Reranking", "comment": null, "summary": "Reranking algorithms have made progress in improving document retrieval\nquality by efficiently aggregating relevance judgments generated by large\nlanguage models (LLMs). However, identifying relevant documents for queries\nthat require in-depth reasoning remains a major challenge. Reasoning-intensive\nqueries often exhibit multifaceted information needs and nuanced\ninterpretations, rendering document relevance inherently context dependent. To\naddress this, we propose contextual relevance, which we define as the\nprobability that a document is relevant to a given query, marginalized over the\ndistribution of different reranking contexts it may appear in (i.e., the set of\ncandidate documents it is ranked alongside and the order in which the documents\nare presented to a reranking model). While prior works have studied methods to\nmitigate the positional bias LLMs exhibit by accounting for the ordering of\ndocuments, we empirically find that the compositions of these batches also\nplays an important role in reranking performance. To efficiently estimate\ncontextual relevance, we propose TS-SetRank, a sampling-based,\nuncertainty-aware reranking algorithm. Empirically, TS-SetRank improves nDCG@10\nover retrieval and reranking baselines by 15-25% on BRIGHT and 6-21% on BEIR,\nhighlighting the importance of modeling relevance as context-dependent.", "AI": {"tldr": "\u63d0\u51fa\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u6982\u5ff5\u548cTS-SetRank\u7b97\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u6587\u6863\u6279\u6b21\u7ec4\u5408\u548c\u6392\u5e8f\u4f4d\u7f6e\u6765\u6539\u8fdb\u9700\u8981\u6df1\u5ea6\u63a8\u7406\u7684\u67e5\u8be2\u7684\u6587\u6863\u91cd\u6392\u5e8f\u6548\u679c", "motivation": "\u73b0\u6709\u91cd\u6392\u5e8f\u7b97\u6cd5\u5728\u5904\u7406\u9700\u8981\u6df1\u5ea6\u63a8\u7406\u7684\u67e5\u8be2\u65f6\u6548\u679c\u6709\u9650\uff0c\u8fd9\u7c7b\u67e5\u8be2\u5177\u6709\u591a\u9762\u6027\u4fe1\u606f\u9700\u6c42\u548c\u7ec6\u5fae\u89e3\u91ca\u5dee\u5f02\uff0c\u6587\u6863\u76f8\u5173\u6027\u9ad8\u5ea6\u4f9d\u8d56\u4e0a\u4e0b\u6587", "method": "\u63d0\u51fa\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u5b9a\u4e49\uff0c\u5f00\u53d1TS-SetRank\u7b97\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u91c7\u6837\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u91cd\u6392\u5e8f\u65b9\u6cd5\uff0c\u540c\u65f6\u8003\u8651\u6587\u6863\u6279\u6b21\u7ec4\u5408\u548c\u6392\u5e8f\u4f4d\u7f6e", "result": "\u5728BRIGHT\u6570\u636e\u96c6\u4e0anDCG@10\u63d0\u534715-25%\uff0c\u5728BEIR\u6570\u636e\u96c6\u4e0a\u63d0\u53476-21%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u68c0\u7d22\u548c\u91cd\u6392\u5e8f\u57fa\u7ebf", "conclusion": "\u5efa\u6a21\u76f8\u5173\u6027\u4e3a\u4e0a\u4e0b\u6587\u4f9d\u8d56\u5bf9\u4e8e\u6539\u8fdb\u91cd\u6392\u5e8f\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u6587\u6863\u6279\u6b21\u7ec4\u5408\u4e0e\u6392\u5e8f\u4f4d\u7f6e\u5171\u540c\u5f71\u54cd\u91cd\u6392\u5e8f\u6548\u679c"}}
{"id": "2511.01071", "categories": ["cs.IT", "math.CO", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01071", "abs": "https://arxiv.org/abs/2511.01071", "authors": ["Fengxing Zhu"], "title": "Sequence Reconstruction over the Deletion Channel", "comment": null, "summary": "In this paper, we consider the Levenshtein's sequence reconstruction problem\nin the case where the transmitted codeword is chosen from $\\{0,1\\}^n$ and the\nchannel can delete up to $t$ symbols from the transmitted codeword. We\ndetermine the minimum number of channel outputs (assuming that they are\ndistinct) required to reconstruct a list of size $\\ell-1$ of candidate\nsequences, one of which corresponds to the original transmitted sequence. More\nspecifically, we determine the maximum possible size of the intersection of\n$\\ell \\geq 3$ deletion balls of radius $t$ centered at $x_1, x_2, \\dots,\nx_{\\ell}$, where $x_i \\in \\{0,1\\}^n$ for all $i \\in \\{1,2,\\dots,\\ell\\}$ and\n$x_i \\neq x_j$ for $i \\neq j$, with $n \\geq t+ \\ell-1$ and $t \\geq 1$.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Levenshtein\u5e8f\u5217\u91cd\u6784\u95ee\u9898\uff0c\u786e\u5b9a\u4e86\u5728\u6700\u591a\u5220\u9664t\u4e2a\u7b26\u53f7\u7684\u60c5\u51b5\u4e0b\uff0c\u91cd\u6784\u5927\u5c0f\u4e3a\u2113-1\u7684\u5019\u9009\u5e8f\u5217\u5217\u8868\u6240\u9700\u7684\u6700\u5c0f\u4fe1\u9053\u8f93\u51fa\u6570\u91cf\u3002", "motivation": "\u7814\u7a76\u5728\u5220\u9664\u4fe1\u9053\u4e0b\u5e8f\u5217\u91cd\u6784\u7684\u7406\u8bba\u754c\u9650\uff0c\u4e3a\u7ea0\u9519\u7801\u548c\u5e8f\u5217\u91cd\u6784\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u901a\u8fc7\u5206\u6790\u2113\u22653\u4e2a\u4e0d\u540c\u5220\u9664\u7403\u7684\u6700\u5927\u4ea4\u96c6\u5927\u5c0f\uff0c\u5176\u4e2d\u6bcf\u4e2a\u7403\u4ee5{0,1}^n\u4e2d\u7684\u5e8f\u5217\u4e3a\u4e2d\u5fc3\uff0c\u534a\u5f84\u4e3at\u3002", "result": "\u786e\u5b9a\u4e86\u5728n\u2265t+\u2113-1\u4e14t\u22651\u6761\u4ef6\u4e0b\uff0c\u2113\u4e2a\u4e0d\u540c\u5220\u9664\u7403\u7684\u6700\u5927\u53ef\u80fd\u4ea4\u96c6\u5927\u5c0f\u3002", "conclusion": "\u4e3aLevenshtein\u5e8f\u5217\u91cd\u6784\u95ee\u9898\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684\u7406\u8bba\u754c\u9650\uff0c\u5bf9\u7406\u89e3\u5220\u9664\u4fe1\u9053\u4e0b\u7684\u5e8f\u5217\u91cd\u6784\u80fd\u529b\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.01716", "categories": ["cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01716", "abs": "https://arxiv.org/abs/2511.01716", "authors": ["Jiale Lao", "Andreas Zimmerer", "Olga Ovcharenko", "Tianji Cong", "Matthew Russo", "Gerardo Vitagliano", "Michael Cochez", "Fatma \u00d6zcan", "Gautam Gupta", "Thibaud Hottelier", "H. V. Jagadish", "Kris Kissel", "Sebastian Schelter", "Andreas Kipf", "Immanuel Trummer"], "title": "SemBench: A Benchmark for Semantic Query Processing Engines", "comment": null, "summary": "We present a benchmark targeting a novel class of systems: semantic query\nprocessing engines. Those systems rely inherently on generative and reasoning\ncapabilities of state-of-the-art large language models (LLMs). They extend SQL\nwith semantic operators, configured by natural language instructions, that are\nevaluated via LLMs and enable users to perform various operations on multimodal\ndata.\n  Our benchmark introduces diversity across three key dimensions: scenarios,\nmodalities, and operators. Included are scenarios ranging from movie review\nanalysis to medical question-answering. Within these scenarios, we cover\ndifferent data modalities, including images, audio, and text. Finally, the\nqueries involve a diverse set of operators, including semantic filters, joins,\nmappings, ranking, and classification operators.\n  We evaluated our benchmark on three academic systems (LOTUS, Palimpzest, and\nThalamusDB) and one industrial system, Google BigQuery. Although these results\nreflect a snapshot of systems under continuous development, our study offers\ncrucial insights into their current strengths and weaknesses, illuminating\npromising directions for future research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u8bed\u4e49\u67e5\u8be2\u5904\u7406\u5f15\u64ce\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u548c\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u6269\u5c55SQL\u8bed\u4e49\u64cd\u4f5c\u7b26\u6765\u5904\u7406\u591a\u6a21\u6001\u6570\u636e\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eLLM\u7684\u8bed\u4e49\u67e5\u8be2\u5904\u7406\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u8fd9\u4e9b\u7cfb\u7edf\u5728\u4e0d\u540c\u573a\u666f\u3001\u6a21\u6001\u548c\u64cd\u4f5c\u7b26\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u591a\u6837\u5316\u573a\u666f\uff08\u7535\u5f71\u8bc4\u8bba\u5206\u6790\u3001\u533b\u7597\u95ee\u7b54\u7b49\uff09\u3001\u591a\u6a21\u6001\u6570\u636e\uff08\u56fe\u50cf\u3001\u97f3\u9891\u3001\u6587\u672c\uff09\u548c\u591a\u79cd\u8bed\u4e49\u64cd\u4f5c\u7b26\uff08\u8bed\u4e49\u8fc7\u6ee4\u3001\u8fde\u63a5\u3001\u6620\u5c04\u3001\u6392\u5e8f\u3001\u5206\u7c7b\uff09\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u8bc4\u4f30\u4e86\u4e09\u4e2a\u5b66\u672f\u7cfb\u7edf\uff08LOTUS\u3001Palimpzest\u3001ThalamusDB\uff09\u548c\u4e00\u4e2a\u5de5\u4e1a\u7cfb\u7edf\uff08Google BigQuery\uff09\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u7cfb\u7edf\u5f53\u524d\u7684\u4f18\u7f3a\u70b9\u548c\u53d1\u5c55\u6f5c\u529b\u3002", "conclusion": "\u8be5\u57fa\u51c6\u4e3a\u8bed\u4e49\u67e5\u8be2\u5904\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6307\u660e\u4e86\u672a\u6765\u7814\u7a76\u7684\u6709\u524d\u666f\u65b9\u5411\uff0c\u5c3d\u7ba1\u8fd9\u4e9b\u7cfb\u7edf\u4ecd\u5728\u6301\u7eed\u5f00\u53d1\u4e2d\u3002"}}
{"id": "2511.01364", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01364", "abs": "https://arxiv.org/abs/2511.01364", "authors": ["Pavan Kumar Perepu"], "title": "A semantic-based deep learning approach for mathematical expression retrieval", "comment": null, "summary": "Mathematical expressions (MEs) have complex two-dimensional structures in\nwhich symbols can be present at any nested depth like superscripts, subscripts,\nabove, below etc. As MEs are represented using LaTeX format, several text\nretrieval methods based on string matching, vector space models etc., have also\nbeen applied for ME retrieval problem in the literature. As these methods are\nbased on syntactic similarity, recently deep learning approaches based on\nembedding have been used for semantic similarity. In our present work, we have\nfocused on the retrieval of mathematical expressions using deep learning\napproaches. In our approach, semantic features are extracted from the MEs using\na deep recurrent neural network (DRNN) and these features have been used for\nmatching and retrieval. We have trained the network for a classification task\nwhich determines the complexity of an ME. ME complexity has been quantified in\nterms of its nested depth. Based on the nested depth, we have considered three\ncomplexity classes of MEs: Simple, Medium and Complex. After training the\nnetwork, outputs just before the the final fully connected layer are extracted\nfor all the MEs. These outputs form the semantic features of MEs and are stored\nin a database. For a given ME query, its semantic features are computed using\nthe trained DRNN and matched against the semantic feature database. Matching is\nperformed based on the standard euclidean distance and top 'k' nearest matches\nare retrieved, where 'k' is a user-defined parameter. Our approach has been\nillustrated on a database of 829 MEs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5faa\u73af\u795e\u7ecf\u7f51\u7edc(DRNN)\u7684\u6570\u5b66\u8868\u8fbe\u5f0f\u68c0\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u8bed\u4e49\u7279\u5f81\u8fdb\u884c\u5339\u914d\uff0c\u5c06\u6570\u5b66\u8868\u8fbe\u5f0f\u6309\u5d4c\u5957\u6df1\u5ea6\u5206\u4e3a\u7b80\u5355\u3001\u4e2d\u7b49\u548c\u590d\u6742\u4e09\u7c7b\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u5b57\u7b26\u4e32\u5339\u914d\u548c\u5411\u91cf\u7a7a\u95f4\u6a21\u578b\u7684\u6570\u5b66\u8868\u8fbe\u5f0f\u68c0\u7d22\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u53e5\u6cd5\u76f8\u4f3c\u6027\uff0c\u7f3a\u4e4f\u8bed\u4e49\u7406\u89e3\u3002\u9700\u8981\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6765\u63d0\u53d6\u8bed\u4e49\u7279\u5f81\u4ee5\u63d0\u9ad8\u68c0\u7d22\u6548\u679c\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u5faa\u73af\u795e\u7ecf\u7f51\u7edc(DRNN)\u8bad\u7ec3\u6570\u5b66\u8868\u8fbe\u5f0f\u590d\u6742\u5ea6\u5206\u7c7b\u4efb\u52a1\uff0c\u63d0\u53d6\u6700\u540e\u4e00\u5c42\u5168\u8fde\u63a5\u5c42\u4e4b\u524d\u7684\u8f93\u51fa\u4f5c\u4e3a\u8bed\u4e49\u7279\u5f81\uff0c\u57fa\u4e8e\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u8fdb\u884c\u7279\u5f81\u5339\u914d\u548c\u68c0\u7d22\u3002", "result": "\u5728\u5305\u542b829\u4e2a\u6570\u5b66\u8868\u8fbe\u5f0f\u7684\u6570\u636e\u5e93\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\uff0c\u80fd\u591f\u6839\u636e\u7528\u6237\u5b9a\u4e49\u7684\u53c2\u6570k\u8fd4\u56de\u6700\u76f8\u4f3c\u7684k\u4e2a\u5339\u914d\u7ed3\u679c\u3002", "conclusion": "\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8bed\u4e49\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u6570\u5b66\u8868\u8fbe\u5f0f\u7684\u68c0\u7d22\u95ee\u9898\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u8bed\u4e49\u7406\u89e3\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2511.01111", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01111", "abs": "https://arxiv.org/abs/2511.01111", "authors": ["Farshad Rostami Ghadi", "Kai-Kit Wong", "Masoud Kaveh", "Hanjiang Hong", "Chan-Byoung Chae", "Lajos Hanzo"], "title": "Coverage Analysis and Optimization of FIRES-Assisted NOMA and OMA Systems", "comment": null, "summary": "Fluid integrated reflecting and emitting surfaces (FIRES) are investigated.\nIn these metasurfaces, each subarea hosts an active element capable of\nsimultaneous transmission and reflection, phase, and geometric positioning\ncontrol within the subarea. We develop a coverage-centric system model for the\ntwo-user downlink scenario (one user per half-space) under spatially correlated\nRician fading and imperfect phase control. First, we derive closed-form\nfar-field line-of-sight (LoS) coverage bounds that reveal the effects of\naperture size, base station (BS) distance, transmit power, energy-splitting\n(ES), and phase errors. Protocol-aware corollaries are then presented for both\northogonal multiple access (OMA) and non-orthogonal multiple access (NOMA),\nincluding conditions for successful successive interference cancellation (SIC).\nSecond, we formulate coverage maximization as a bi-level optimization problem\nconsisting of (i) an outer search over FIRES element positions, selecting one\nactive preset per subarea under minimum-spacing constraints, and (ii) an inner\nresource allocation problem tailored to the multiple-access scheme, which is\none-dimensional for OMA and a small convex program for NOMA. The proposed\nframework explicitly accounts for target rate constraints, ES conservation,\npower budgets, geometric placement limits, and decoding-order feasibility.\nExtensive simulations demonstrate that FIRES, by jointly exploiting geometric\nrepositioning and passive energy control, substantially enlarges the coverage\nregion compared with a conventional simultaneously transmitting and reflecting\nreconfigurable intelligent surface (STAR-RIS) under the same element budget.\nFurthermore, NOMA yields additional coverage gains when feasible. The\nanalytical coverage bounds closely match the simulation results and quantify\nthe robustness of FIRES to phase-control imperfections.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6d41\u4f53\u96c6\u6210\u53cd\u5c04\u548c\u53d1\u5c04\u8868\u9762(FIRES)\uff0c\u8fd9\u662f\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u63a7\u5236\u4f20\u8f93\u548c\u53cd\u5c04\u3001\u76f8\u4f4d\u53ca\u51e0\u4f55\u5b9a\u4f4d\u7684\u667a\u80fd\u8d85\u8868\u9762\u3002\u9488\u5bf9\u4e24\u7528\u6237\u4e0b\u884c\u94fe\u8def\u573a\u666f\uff0c\u5efa\u7acb\u4e86\u8986\u76d6\u4e2d\u5fc3\u7cfb\u7edf\u6a21\u578b\uff0c\u63a8\u5bfc\u4e86\u8986\u76d6\u8303\u56f4\u95ed\u5f0f\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u53cc\u5c42\u4f18\u5316\u6846\u67b6\u6765\u6700\u5927\u5316\u8986\u76d6\u8303\u56f4\u3002\u76f8\u6bd4\u4f20\u7edfSTAR-RIS\uff0cFIRES\u901a\u8fc7\u8054\u5408\u5229\u7528\u51e0\u4f55\u91cd\u5b9a\u4f4d\u548c\u88ab\u52a8\u80fd\u91cf\u63a7\u5236\uff0c\u663e\u8457\u6269\u5927\u4e86\u8986\u76d6\u533a\u57df\u3002", "motivation": "\u4f20\u7edf\u7684\u540c\u65f6\u4f20\u8f93\u548c\u53cd\u5c04\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(STAR-RIS)\u5728\u8986\u76d6\u8303\u56f4\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u540c\u65f6\u63a7\u5236\u4f20\u8f93\u53cd\u5c04\u3001\u76f8\u4f4d\u548c\u51e0\u4f55\u5b9a\u4f4d\u7684\u667a\u80fd\u8d85\u8868\u9762\uff0c\u4ee5\u63d0\u5347\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u7684\u8986\u76d6\u6027\u80fd\u3002", "method": "1. \u5efa\u7acb\u4e86\u4e24\u7528\u6237\u4e0b\u884c\u94fe\u8def\u573a\u666f\u4e0b\u7684\u8986\u76d6\u4e2d\u5fc3\u7cfb\u7edf\u6a21\u578b\uff0c\u8003\u8651\u7a7a\u95f4\u76f8\u5173Rician\u8870\u843d\u548c\u4e0d\u5b8c\u7f8e\u76f8\u4f4d\u63a7\u5236\uff1b2. \u63a8\u5bfc\u4e86\u8fdc\u573a\u89c6\u8ddd\u8986\u76d6\u8303\u56f4\u7684\u95ed\u5f0f\u8fb9\u754c\uff1b3. \u63d0\u51fa\u4e86\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff1a\u5916\u5c42\u641c\u7d22FIRES\u5143\u7d20\u4f4d\u7f6e\uff0c\u5185\u5c42\u6839\u636e\u591a\u5740\u65b9\u6848\u8fdb\u884c\u8d44\u6e90\u5206\u914d\uff1b4. \u5206\u522b\u9488\u5bf9OMA\u548cNOMA\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cFIRES\u76f8\u6bd4\u4f20\u7edfSTAR-RIS\u5728\u76f8\u540c\u5143\u7d20\u9884\u7b97\u4e0b\u663e\u8457\u6269\u5927\u4e86\u8986\u76d6\u533a\u57df\u3002NOMA\u5728\u53ef\u884c\u65f6\u80fd\u63d0\u4f9b\u989d\u5916\u7684\u8986\u76d6\u589e\u76ca\u3002\u5206\u6790\u5f97\u5230\u7684\u8986\u76d6\u8fb9\u754c\u4e0e\u4eff\u771f\u7ed3\u679c\u9ad8\u5ea6\u5339\u914d\uff0c\u5e76\u91cf\u5316\u4e86FIRES\u5bf9\u76f8\u4f4d\u63a7\u5236\u4e0d\u5b8c\u7f8e\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "FIRES\u901a\u8fc7\u8054\u5408\u5229\u7528\u51e0\u4f55\u91cd\u5b9a\u4f4d\u548c\u88ab\u52a8\u80fd\u91cf\u63a7\u5236\uff0c\u4e3a\u667a\u80fd\u8d85\u8868\u9762\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u7684\u8986\u76d6\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u76f8\u4f4d\u63a7\u5236\u4e0d\u5b8c\u7f8e\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u826f\u597d\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.01404", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.01404", "abs": "https://arxiv.org/abs/2511.01404", "authors": ["Xiaoyu Liu", "Yiqing Wu", "Ruidong Han", "Fuzhen Zhuang", "Xiang Li", "Wei Lin"], "title": "A Soft-partitioned Semi-supervised Collaborative Transfer Learning Approach for Multi-Domain Recommendation", "comment": "Accepted by CIKM'25", "summary": "In industrial practice, Multi-domain Recommendation (MDR) plays a crucial\nrole. Shared-specific architectures are widely used in industrial solutions to\ncapture shared and unique attributes via shared and specific parameters.\nHowever, with imbalanced data across different domains, these models face two\nkey issues: (1) Overwhelming: Dominant domain data skews model performance,\nneglecting non-dominant domains. (2) Overfitting: Sparse data in non-dominant\ndomains leads to overfitting in specific parameters. To tackle these\nchallenges, we propose Soft-partitioned Semi-supervised Collaborative Transfer\nLearning (SSCTL) for multi-domain recommendation. SSCTL generates dynamic\nparameters to address the overwhelming issue, thus shifting focus towards\nsamples from non-dominant domains. To combat overfitting, it leverages\npseudo-labels with weights from dominant domain instances to enhance\nnon-dominant domain data. We conduct comprehensive experiments, both online and\noffline, to validate the efficacy of our proposed method. Online tests yielded\nsignificant improvements across various domains, with increases in GMV ranging\nfrom 0.54% to 2.90% and enhancements in CTR ranging from 0.22% to 1.69%.", "AI": {"tldr": "\u63d0\u51fa\u4e86SSCTL\u65b9\u6cd5\u89e3\u51b3\u591a\u57df\u63a8\u8350\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u53c2\u6570\u548c\u4f2a\u6807\u7b7e\u6280\u672f\u6539\u5584\u975e\u4e3b\u5bfc\u57df\u7684\u6027\u80fd\uff0c\u5728\u7ebf\u6d4b\u8bd5\u663e\u793aGMV\u63d0\u53470.54%-2.90%\uff0cCTR\u63d0\u53470.22%-1.69%\u3002", "motivation": "\u89e3\u51b3\u591a\u57df\u63a8\u8350\u4e2d\u6570\u636e\u4e0d\u5e73\u8861\u5bfc\u81f4\u7684\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u4e3b\u5bfc\u57df\u6570\u636e\u538b\u5012\u6a21\u578b\u6027\u80fd\uff0c\u5ffd\u89c6\u975e\u4e3b\u5bfc\u57df\uff1b\u975e\u4e3b\u5bfc\u57df\u6570\u636e\u7a00\u758f\u5bfc\u81f4\u7279\u5b9a\u53c2\u6570\u8fc7\u62df\u5408\u3002", "method": "\u63d0\u51fa\u8f6f\u5206\u533a\u534a\u76d1\u7763\u534f\u540c\u8fc1\u79fb\u5b66\u4e60(SSCTL)\uff0c\u4f7f\u7528\u52a8\u6001\u53c2\u6570\u89e3\u51b3\u538b\u5012\u6027\u95ee\u9898\uff0c\u5229\u7528\u4e3b\u5bfc\u57df\u5b9e\u4f8b\u7684\u5e26\u6743\u4f2a\u6807\u7b7e\u589e\u5f3a\u975e\u4e3b\u5bfc\u57df\u6570\u636e\u4ee5\u9632\u6b62\u8fc7\u62df\u5408\u3002", "result": "\u5728\u7ebf\u6d4b\u8bd5\u663e\u793a\u5728\u5404\u4e2a\u57df\u90fd\u53d6\u5f97\u663e\u8457\u6539\u8fdb\uff0cGMV\u63d0\u53470.54%-2.90%\uff0cCTR\u63d0\u53470.22%-1.69%\u3002", "conclusion": "SSCTL\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u57df\u63a8\u8350\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u53c2\u6570\u548c\u4f2a\u6807\u7b7e\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u975e\u4e3b\u5bfc\u57df\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2511.01162", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01162", "abs": "https://arxiv.org/abs/2511.01162", "authors": ["Yun Long Zhu", "Chang-An Zhao"], "title": "Distributed Matrix Multiplication-Friendly Algebraic Function Fields", "comment": null, "summary": "In this paper, we introduce distributed matrix multiplication (DMM)-friendly\nalgebraic function fields for polynomial codes and Matdot codes, and present\nseveral constructions for such function fields through extensions of the\nrational function field. The primary challenge in extending polynomial codes\nand Matdot codes to algebraic function fields lies in constructing optimal\ndecoding schemes. We establish optimal recovery thresholds for both polynomial\nalgebraic geometry (AG) codes and Matdot AG codes for fixed matrix\nmultiplication. Our proposed function fields support DMM with optimal recovery\nthresholds, while offering rational places that exceed the base finite field\nsize in specific parameter regimes. Although these fields may not achieve\noptimal computational efficiency, our results provide practical improvements\nfor matrix multiplication implementations. Explicit examples of applicable\nfunction fields are provided.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u77e9\u9635\u4e58\u6cd5\u7684\u4ee3\u6570\u51fd\u6570\u57df\u6784\u9020\uff0c\u4e3a\u591a\u9879\u5f0f\u7801\u548cMatdot\u7801\u63d0\u4f9b\u4e86\u652f\u6301\uff0c\u5efa\u7acb\u4e86\u6700\u4f18\u6062\u590d\u9608\u503c\uff0c\u5e76\u5728\u7279\u5b9a\u53c2\u6570\u4e0b\u63d0\u4f9b\u8d85\u8fc7\u57fa\u57df\u5927\u5c0f\u7684\u6709\u7406\u70b9\u3002", "motivation": "\u6269\u5c55\u591a\u9879\u5f0f\u7801\u548cMatdot\u7801\u5230\u4ee3\u6570\u51fd\u6570\u57df\u7684\u4e3b\u8981\u6311\u6218\u5728\u4e8e\u6784\u9020\u6700\u4f18\u89e3\u7801\u65b9\u6848\uff0c\u9700\u8981\u89e3\u51b3\u5206\u5e03\u5f0f\u77e9\u9635\u4e58\u6cd5\u4e2d\u7684\u6062\u590d\u9608\u503c\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6709\u7406\u51fd\u6570\u57df\u7684\u6269\u5c55\u6784\u9020\u5206\u5e03\u5f0f\u77e9\u9635\u4e58\u6cd5\u53cb\u597d\u7684\u4ee3\u6570\u51fd\u6570\u57df\uff0c\u4e3a\u591a\u9879\u5f0f\u4ee3\u6570\u51e0\u4f55\u7801\u548cMatdot\u4ee3\u6570\u51e0\u4f55\u7801\u5efa\u7acb\u6700\u4f18\u6062\u590d\u9608\u503c\u3002", "result": "\u63d0\u51fa\u7684\u51fd\u6570\u57df\u652f\u6301\u5177\u6709\u6700\u4f18\u6062\u590d\u9608\u503c\u7684\u5206\u5e03\u5f0f\u77e9\u9635\u4e58\u6cd5\uff0c\u5728\u7279\u5b9a\u53c2\u6570\u673a\u5236\u4e0b\u63d0\u4f9b\u8d85\u8fc7\u57fa\u6709\u9650\u57df\u5927\u5c0f\u7684\u6709\u7406\u70b9\u3002", "conclusion": "\u867d\u7136\u8fd9\u4e9b\u51fd\u6570\u57df\u53ef\u80fd\u65e0\u6cd5\u8fbe\u5230\u6700\u4f18\u8ba1\u7b97\u6548\u7387\uff0c\u4f46\u7ed3\u679c\u4e3a\u77e9\u9635\u4e58\u6cd5\u5b9e\u73b0\u63d0\u4f9b\u4e86\u5b9e\u9645\u6539\u8fdb\uff0c\u5e76\u7ed9\u51fa\u4e86\u9002\u7528\u7684\u51fd\u6570\u57df\u5177\u4f53\u793a\u4f8b\u3002"}}
{"id": "2511.01448", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.01448", "abs": "https://arxiv.org/abs/2511.01448", "authors": ["Zhengjun Huang", "Zhoujin Tian", "Qintian Guo", "Fangyuan Zhang", "Yingli Zhou", "Di Jiang", "Xiaofang Zhou"], "title": "LiCoMemory: Lightweight and Cognitive Agentic Memory for Efficient Long-Term Reasoning", "comment": null, "summary": "Large Language Model (LLM) agents exhibit remarkable conversational and\nreasoning capabilities but remain constrained by limited context windows and\nthe lack of persistent memory. Recent efforts address these limitations via\nexternal memory architectures, often employing graph-based representations, yet\nmost adopt flat, entangled structures that intertwine semantics with topology,\nleading to redundant representations, unstructured retrieval, and degraded\nefficiency and accuracy. To resolve these issues, we propose LiCoMemory, an\nend-to-end agentic memory framework for real-time updating and retrieval, which\nintroduces CogniGraph, a lightweight hierarchical graph that utilizes entities\nand relations as semantic indexing layers, and employs temporal and\nhierarchy-aware search with integrated reranking for adaptive and coherent\nknowledge retrieval. Experiments on long-term dialogue benchmarks, LoCoMo and\nLongMemEval, show that LiCoMemory not only outperforms established baselines in\ntemporal reasoning, multi-session consistency, and retrieval efficiency, but\nalso notably reduces update latency. Our official code and data are available\nat https://github.com/EverM0re/LiCoMemory.", "AI": {"tldr": "LiCoMemory\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u667a\u80fd\u4f53\u8bb0\u5fc6\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u8f7b\u91cf\u7ea7\u5206\u5c42\u56feCogniGraph\u6765\u89e3\u51b3LLM\u667a\u80fd\u4f53\u4e0a\u4e0b\u6587\u7a97\u53e3\u6709\u9650\u548c\u7f3a\u4e4f\u6301\u4e45\u8bb0\u5fc6\u7684\u95ee\u9898\uff0c\u5728\u957f\u671f\u5bf9\u8bdd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5177\u6709\u51fa\u8272\u7684\u5bf9\u8bdd\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u53d7\u5230\u6709\u9650\u4e0a\u4e0b\u6587\u7a97\u53e3\u548c\u7f3a\u4e4f\u6301\u4e45\u8bb0\u5fc6\u7684\u9650\u5236\u3002\u73b0\u6709\u7684\u5916\u90e8\u8bb0\u5fc6\u67b6\u6784\u901a\u5e38\u91c7\u7528\u56fe\u8868\u793a\uff0c\u4f46\u5927\u591a\u91c7\u7528\u6241\u5e73\u3001\u7ea0\u7f20\u7684\u7ed3\u6784\uff0c\u5bfc\u81f4\u8868\u793a\u5197\u4f59\u3001\u68c0\u7d22\u65e0\u7ed3\u6784\u4ee5\u53ca\u6548\u7387\u548c\u51c6\u786e\u6027\u4e0b\u964d\u3002", "method": "\u63d0\u51faLiCoMemory\u6846\u67b6\uff0c\u5f15\u5165CogniGraph\u8f7b\u91cf\u7ea7\u5206\u5c42\u56fe\uff0c\u4f7f\u7528\u5b9e\u4f53\u548c\u5173\u7cfb\u4f5c\u4e3a\u8bed\u4e49\u7d22\u5f15\u5c42\uff0c\u5e76\u91c7\u7528\u65f6\u95f4\u548c\u5c42\u6b21\u611f\u77e5\u641c\u7d22\u4e0e\u96c6\u6210\u91cd\u6392\u5e8f\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u548c\u8fde\u8d2f\u7684\u77e5\u8bc6\u68c0\u7d22\u3002", "result": "\u5728\u957f\u671f\u5bf9\u8bdd\u57fa\u51c6\u6d4b\u8bd5LoCoMo\u548cLongMemEval\u4e0a\uff0cLiCoMemory\u5728\u65f6\u95f4\u63a8\u7406\u3001\u591a\u4f1a\u8bdd\u4e00\u81f4\u6027\u548c\u68c0\u7d22\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u66f4\u65b0\u5ef6\u8fdf\u3002", "conclusion": "LiCoMemory\u901a\u8fc7\u5206\u5c42\u56fe\u7ed3\u6784\u548c\u667a\u80fd\u68c0\u7d22\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u667a\u80fd\u4f53\u7684\u8bb0\u5fc6\u9650\u5236\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u53d6\u5f97\u4e86\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.01173", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01173", "abs": "https://arxiv.org/abs/2511.01173", "authors": ["Xingyu Zhou", "Le Liang", "Xinjie Li", "Jing Zhang", "Peiwen Jiang", "Xiao Li", "Shi Jin"], "title": "Conditional Diffusion Model-Enabled Scenario-Specific Neural Receivers for Superimposed Pilot Schemes", "comment": "This paper has been accepted for publication by China Communications", "summary": "Neural receivers have demonstrated strong performance in wireless\ncommunication systems. However, their effectiveness typically depends on access\nto large-scale, scenario-specific channel data for training, which is often\ndifficult to obtain in practice. Recently, generative artificial intelligence\n(AI) models, particularly diffusion models (DMs), have emerged as effective\ntools for synthesizing high-dimensional data. This paper presents a\nscenario-specific channel generation method based on conditional DMs, which\naccurately model channel distributions conditioned on user location and\nvelocity information. The generated synthetic channel data are then employed\nfor data augmentation to improve the training of a neural receiver designed for\nsuperimposed pilot-based transmission. Experimental results show that the\nproposed method generates high-fidelity channel samples and significantly\nenhances neural receiver performance in the target scenarios, outperforming\nconventional data augmentation and generative adversarial network-based\ntechniques.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7684\u573a\u666f\u7279\u5b9a\u4fe1\u9053\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u6570\u636e\u589e\u5f3a\u4ee5\u63d0\u5347\u795e\u7ecf\u63a5\u6536\u673a\u6027\u80fd", "motivation": "\u795e\u7ecf\u63a5\u6536\u673a\u9700\u8981\u5927\u91cf\u573a\u666f\u7279\u5b9a\u7684\u4fe1\u9053\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u5b9e\u9645\u4e2d\u96be\u4ee5\u83b7\u53d6\uff0c\u56e0\u6b64\u9700\u8981\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u4fe1\u9053\u6570\u636e", "method": "\u4f7f\u7528\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff0c\u6839\u636e\u7528\u6237\u4f4d\u7f6e\u548c\u901f\u5ea6\u4fe1\u606f\u751f\u6210\u4fe1\u9053\u6570\u636e\uff0c\u7136\u540e\u7528\u4e8e\u53e0\u52a0\u5bfc\u9891\u4f20\u8f93\u7684\u795e\u7ecf\u63a5\u6536\u673a\u8bad\u7ec3", "result": "\u751f\u6210\u9ad8\u4fdd\u771f\u4fe1\u9053\u6837\u672c\uff0c\u663e\u8457\u63d0\u5347\u795e\u7ecf\u63a5\u6536\u673a\u5728\u76ee\u6807\u573a\u666f\u4e2d\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u4f20\u7edf\u6570\u636e\u589e\u5f3a\u548c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u65b9\u6cd5", "conclusion": "\u6761\u4ef6\u6269\u6563\u6a21\u578b\u80fd\u6709\u6548\u751f\u6210\u573a\u666f\u7279\u5b9a\u4fe1\u9053\u6570\u636e\uff0c\u4e3a\u795e\u7ecf\u63a5\u6536\u673a\u8bad\u7ec3\u63d0\u4f9b\u53ef\u9760\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6848"}}
{"id": "2511.01461", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.01461", "abs": "https://arxiv.org/abs/2511.01461", "authors": ["Xiaoyu Liu", "Fuwei Zhang", "Yiqing Wu", "Xinyu Jia", "Zenghua Xia", "Fuzhen Zhuang", "Zhao Zhang", "Fei Jiang", "Wei Lin"], "title": "CAT-ID$^2$: Category-Tree Integrated Document Identifier Learning for Generative Retrieval In E-commerce", "comment": "Accepted by WSDM'26", "summary": "Generative retrieval (GR) has gained significant attention as an effective\nparadigm that integrates the capabilities of large language models (LLMs). It\ngenerally consists of two stages: constructing discrete semantic identifiers\n(IDs) for documents and retrieving documents by autoregressively generating ID\ntokens.The core challenge in GR is how to construct document IDs (DocIDS) with\nstrong representational power. Good IDs should exhibit two key properties:\nsimilar documents should have more similar IDs, and each document should\nmaintain a distinct and unique ID.However, most existing methods ignore native\ncategory information, which is common and critical in E-commerce. Therefore, we\npropose a novel ID learning method, CAtegory-Tree Integrated Document\nIDentifier (CAT-ID$^2$), incorporating prior category information into the\nsemantic IDs.CAT-ID$^2$ includes three key modules: a Hierarchical Class\nConstraint Loss to integrate category information layer by layer during\nquantization, a Cluster Scale Constraint Loss for uniform ID token\ndistribution, and a Dispersion Loss to improve the distinction of reconstructed\ndocuments. These components enable CAT-ID$^2$ to generate IDs that make similar\ndocuments more alike while preserving the uniqueness of different documents'\nrepresentations.Extensive offline and online experiments confirm the\neffectiveness of our method, with online A/B tests showing a 0.33% increase in\naverage orders per thousand users for ambiguous intent queries and 0.24% for\nlong-tail queries.", "AI": {"tldr": "\u63d0\u51faCAT-ID\u00b2\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u7c7b\u522b\u4fe1\u606f\u6539\u8fdb\u751f\u6210\u5f0f\u68c0\u7d22\u4e2d\u7684\u6587\u6863ID\u6784\u5efa\uff0c\u4f7f\u76f8\u4f3c\u6587\u6863\u7684ID\u66f4\u76f8\u4f3c\uff0c\u540c\u65f6\u4fdd\u6301\u4e0d\u540c\u6587\u6863ID\u7684\u72ec\u7279\u6027\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u68c0\u7d22\u65b9\u6cd5\u5ffd\u7565\u4e86\u7535\u5546\u573a\u666f\u4e2d\u5e38\u89c1\u7684\u7c7b\u522b\u4fe1\u606f\uff0c\u800c\u597d\u7684\u6587\u6863ID\u5e94\u8be5\u5177\u6709\u76f8\u4f3c\u6587\u6863ID\u76f8\u4f3c\u3001\u4e0d\u540c\u6587\u6863ID\u72ec\u7279\u7684\u7279\u6027\u3002", "method": "CAT-ID\u00b2\u5305\u542b\u4e09\u4e2a\u5173\u952e\u6a21\u5757\uff1a\u5206\u5c42\u7c7b\u522b\u7ea6\u675f\u635f\u5931\u3001\u805a\u7c7b\u89c4\u6a21\u7ea6\u675f\u635f\u5931\u548c\u5206\u6563\u635f\u5931\uff0c\u901a\u8fc7\u5206\u5c42\u6574\u5408\u7c7b\u522b\u4fe1\u606f\u6765\u6539\u8fdb\u8bed\u4e49ID\u7684\u6784\u5efa\u3002", "result": "\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\u6a21\u7cca\u610f\u56fe\u67e5\u8be2\u7684\u5343\u7528\u6237\u5e73\u5747\u8ba2\u5355\u589e\u52a00.33%\uff0c\u957f\u5c3e\u67e5\u8be2\u589e\u52a00.24%\u3002", "conclusion": "CAT-ID\u00b2\u901a\u8fc7\u6709\u6548\u6574\u5408\u7c7b\u522b\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u5f0f\u68c0\u7d22\u5728\u7535\u5546\u573a\u666f\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2511.01202", "categories": ["cs.IT", "cs.AI", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01202", "abs": "https://arxiv.org/abs/2511.01202", "authors": ["Bo Bai"], "title": "Forget BIT, It is All about TOKEN: Towards Semantic Information Theory for LLMs", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nnumerous real- world applications. While the vast majority of research\nconducted from an experimental perspective is progressing rapidly, it demands\nsubstantial computational power, data, and other resources. Therefore, how to\nopen the black-box of LLMs from a theoretical standpoint has become a critical\nchallenge. This paper takes the theory of rate-distortion function, directed\ninformation, and Granger causality as its starting point to investigate the\ninformation-theoretic principles behind LLMs, leading to the development of\nsemantic information theory for LLMs, where the fundamental unit is token,\nrather than bits that lacks any semantic meaning. By defining the probabilistic\nmodel of LLMs, we discuss structure-agnostic information-theoretic measures,\nsuch as the directed rate- distortion function in pre-training, the directed\nrate-reward function in post-training, and the semantic information flow in\ninference phase. This paper also delves deeply into the theory of token-level\nsemantic embedding and the information-theoretically optimal vectorization\nmethod. Thereafter, we propose a general definition of autoregression LLM,\nwhere the Transformer architecture and its performance such as ELBO,\ngeneralization error bound, memory capacity, and semantic information measures\ncan be derived theoretically. Other architectures, such as Mamba/Mamba2 and\nLLaDA, are also discussed in our framework. Consequently, this paper provides a\ntheoretical framework for understanding LLMs from the perspective of semantic\ninformation theory, which also offers the necessary theoretical tools for\nfurther in-depth research.", "AI": {"tldr": "\u672c\u6587\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u63d0\u51fa\u4e86LLMs\u7684\u8bed\u4e49\u4fe1\u606f\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u57fa\u672c\u5355\u4f4d\u4ece\u65e0\u610f\u4e49\u7684\u6bd4\u7279\u6539\u4e3a\u6709\u8bed\u4e49\u7684token\uff0c\u5efa\u7acb\u4e86\u9884\u8bad\u7ec3\u3001\u540e\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u7684\u4fe1\u606f\u7406\u8bba\u5ea6\u91cf\uff0c\u5e76\u7406\u8bba\u63a8\u5bfc\u4e86Transformer\u7b49\u67b6\u6784\u7684\u6027\u80fd\u754c\u9650\u3002", "motivation": "\u5f53\u524dLLMs\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u548c\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u4ece\u7406\u8bba\u89d2\u5ea6\u6253\u5f00LLMs\u7684\u9ed1\u7bb1\uff0c\u7406\u89e3\u5176\u80cc\u540e\u7684\u4fe1\u606f\u8bba\u539f\u7406\u3002", "method": "\u91c7\u7528\u7387\u5931\u771f\u51fd\u6570\u3001\u6709\u5411\u4fe1\u606f\u548cGranger\u56e0\u679c\u5173\u7cfb\u7406\u8bba\uff0c\u5b9a\u4e49LLMs\u7684\u6982\u7387\u6a21\u578b\uff0c\u63d0\u51fa\u7ed3\u6784\u65e0\u5173\u7684\u4fe1\u606f\u8bba\u5ea6\u91cf\uff0c\u5305\u62ec\u9884\u8bad\u7ec3\u7684\u6709\u5411\u7387\u5931\u771f\u51fd\u6570\u3001\u540e\u8bad\u7ec3\u7684\u6709\u5411\u7387\u5956\u52b1\u51fd\u6570\u548c\u63a8\u7406\u9636\u6bb5\u7684\u8bed\u4e49\u4fe1\u606f\u6d41\u3002", "result": "\u5efa\u7acb\u4e86token\u7ea7\u8bed\u4e49\u5d4c\u5165\u7406\u8bba\u548c\u4fe1\u606f\u8bba\u6700\u4f18\u5411\u91cf\u5316\u65b9\u6cd5\uff0c\u7406\u8bba\u63a8\u5bfc\u4e86Transformer\u67b6\u6784\u7684ELBO\u3001\u6cdb\u5316\u8bef\u5dee\u754c\u9650\u3001\u8bb0\u5fc6\u5bb9\u91cf\u548c\u8bed\u4e49\u4fe1\u606f\u5ea6\u91cf\uff0c\u5e76\u5c06Mamba/Mamba2\u548cLLaDA\u7b49\u67b6\u6784\u7eb3\u5165\u6846\u67b6\u3002", "conclusion": "\u4e3a\u4ece\u8bed\u4e49\u4fe1\u606f\u8bba\u89d2\u5ea6\u7406\u89e3LLMs\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u540e\u7eed\u6df1\u5165\u7814\u7a76\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u7406\u8bba\u5de5\u5177\u3002"}}
{"id": "2511.01857", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01857", "abs": "https://arxiv.org/abs/2511.01857", "authors": ["Reza Esfandiarpoor", "Max Zuo", "Stephen H. Bach"], "title": "Trove: A Flexible Toolkit for Dense Retrieval", "comment": null, "summary": "We introduce Trove, an easy-to-use open-source retrieval toolkit that\nsimplifies research experiments without sacrificing flexibility or speed. For\nthe first time, we introduce efficient data management features that load and\nprocess (filter, select, transform, and combine) retrieval datasets on the fly,\nwith just a few lines of code. This gives users the flexibility to easily\nexperiment with different dataset configurations without the need to compute\nand store multiple copies of large datasets. Trove is highly customizable: in\naddition to many built-in options, it allows users to freely modify existing\ncomponents or replace them entirely with user-defined objects. It also provides\na low-code and unified pipeline for evaluation and hard negative mining, which\nsupports multi-node execution without any code changes. Trove's data management\nfeatures reduce memory consumption by a factor of 2.6. Moreover, Trove's\neasy-to-use inference pipeline incurs no overhead, and inference times decrease\nlinearly with the number of available nodes. Most importantly, we demonstrate\nhow Trove simplifies retrieval experiments and allows for arbitrary\ncustomizations, thus facilitating exploratory research.", "AI": {"tldr": "Trove\u662f\u4e00\u4e2a\u6613\u4e8e\u4f7f\u7528\u7684\u5f00\u6e90\u68c0\u7d22\u5de5\u5177\u5305\uff0c\u7b80\u5316\u7814\u7a76\u5b9e\u9a8c\u800c\u4e0d\u727a\u7272\u7075\u6d3b\u6027\u6216\u901f\u5ea6\uff0c\u63d0\u4f9b\u9ad8\u6548\u6570\u636e\u7ba1\u7406\u529f\u80fd\uff0c\u652f\u6301\u52a8\u6001\u52a0\u8f7d\u548c\u5904\u7406\u68c0\u7d22\u6570\u636e\u96c6\uff0c\u5177\u6709\u9ad8\u5ea6\u53ef\u5b9a\u5236\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u68c0\u7d22\u7814\u7a76\u4e2d\u6570\u636e\u7ba1\u7406\u590d\u6742\u3001\u5b9e\u9a8c\u914d\u7f6e\u4e0d\u7075\u6d3b\u3001\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u5927\u7684\u95ee\u9898\uff0c\u5f00\u53d1\u4e00\u4e2a\u65e2\u80fd\u7b80\u5316\u5b9e\u9a8c\u6d41\u7a0b\u53c8\u80fd\u4fdd\u6301\u9ad8\u5ea6\u7075\u6d3b\u6027\u7684\u5de5\u5177\u5305\u3002", "method": "\u5f15\u5165\u9ad8\u6548\u6570\u636e\u7ba1\u7406\u529f\u80fd\uff0c\u652f\u6301\u52a8\u6001\u52a0\u8f7d\u3001\u8fc7\u6ee4\u3001\u9009\u62e9\u3001\u8f6c\u6362\u548c\u7ec4\u5408\u6570\u636e\u96c6\uff1b\u63d0\u4f9b\u9ad8\u5ea6\u53ef\u5b9a\u5236\u7684\u7ec4\u4ef6\u7cfb\u7edf\uff1b\u8bbe\u8ba1\u4f4e\u4ee3\u7801\u7edf\u4e00\u8bc4\u4f30\u548c\u786c\u8d1f\u4f8b\u6316\u6398\u7ba1\u9053\uff1b\u652f\u6301\u591a\u8282\u70b9\u6267\u884c\u3002", "result": "\u6570\u636e\u7ba1\u7406\u529f\u80fd\u5c06\u5185\u5b58\u6d88\u8017\u51cf\u5c112.6\u500d\uff1b\u63a8\u7406\u7ba1\u9053\u65e0\u989d\u5916\u5f00\u9500\uff0c\u63a8\u7406\u65f6\u95f4\u968f\u8282\u70b9\u6570\u91cf\u7ebf\u6027\u51cf\u5c11\uff1b\u7b80\u5316\u4e86\u68c0\u7d22\u5b9e\u9a8c\u6d41\u7a0b\uff0c\u652f\u6301\u4efb\u610f\u5b9a\u5236\u3002", "conclusion": "Trove\u901a\u8fc7\u7b80\u5316\u68c0\u7d22\u5b9e\u9a8c\u6d41\u7a0b\u548c\u63d0\u4f9b\u9ad8\u5ea6\u53ef\u5b9a\u5236\u6027\uff0c\u6709\u6548\u4fc3\u8fdb\u4e86\u63a2\u7d22\u6027\u7814\u7a76\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u5b9e\u9a8c\u6548\u7387\u3002"}}
{"id": "2511.01280", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01280", "abs": "https://arxiv.org/abs/2511.01280", "authors": ["Dganit Hanania", "Eitan Yaakobi"], "title": "Error-Correcting Codes for Labeled DNA Sequences", "comment": null, "summary": "Labeling of DNA molecules is a fundamental technique for DNA visualization\nand analysis. This process was mathematically modeled in [1], where the\nreceived sequence indicates the positions of the used labels. In this work, we\ndevelop error correcting codes for labeled DNA sequences, establishing bounds\nand constructing explicit systematic encoders for single substitution,\ninsertion, and deletion errors. We focus on two cases: (1) using the complete\nset of length-two labels and (2) using the minimal set of length-two labels\nthat ensures the recovery of DNA sequences from their labeling for 'almost' all\nDNA sequences.", "AI": {"tldr": "\u5f00\u53d1\u7528\u4e8e\u6807\u8bb0DNA\u5e8f\u5217\u7684\u7ea0\u9519\u7801\uff0c\u9488\u5bf9\u5355\u66ff\u6362\u3001\u63d2\u5165\u548c\u5220\u9664\u9519\u8bef\u5efa\u7acb\u754c\u9650\u5e76\u6784\u5efa\u663e\u5f0f\u7cfb\u7edf\u7f16\u7801\u5668\uff0c\u91cd\u70b9\u5173\u6ce8\u4e24\u79cd\u6807\u8bb0\u96c6\u60c5\u51b5\u3002", "motivation": "DNA\u5206\u5b50\u6807\u8bb0\u662fDNA\u53ef\u89c6\u5316\u548c\u5206\u6790\u7684\u57fa\u7840\u6280\u672f\uff0c\u9700\u8981\u5efa\u7acb\u6570\u5b66\u6a21\u578b\u6765\u5904\u7406\u6807\u8bb0\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u9519\u8bef\u3002", "method": "\u5efa\u7acb\u6807\u8bb0DNA\u5e8f\u5217\u7684\u7ea0\u9519\u7801\u7406\u8bba\u6846\u67b6\uff0c\u9488\u5bf9\u5355\u66ff\u6362\u3001\u63d2\u5165\u548c\u5220\u9664\u9519\u8bef\u63a8\u5bfc\u754c\u9650\uff0c\u5e76\u6784\u9020\u663e\u5f0f\u7cfb\u7edf\u7f16\u7801\u5668\u3002\u7814\u7a76\u4e24\u79cd\u6807\u8bb0\u96c6\uff1a\u5b8c\u6574\u957f\u5ea6\u4e8c\u6807\u8bb0\u96c6\u548c\u6700\u5c0f\u957f\u5ea6\u4e8c\u6807\u8bb0\u96c6\u3002", "result": "\u5f00\u53d1\u4e86\u80fd\u591f\u7ea0\u6b63\u5355\u66ff\u6362\u3001\u63d2\u5165\u548c\u5220\u9664\u9519\u8bef\u7684\u7f16\u7801\u65b9\u6848\uff0c\u5e76\u5efa\u7acb\u4e86\u76f8\u5e94\u7684\u7406\u8bba\u754c\u9650\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7ea0\u9519\u7801\u6846\u67b6\u4e3aDNA\u6807\u8bb0\u5e8f\u5217\u7684\u9519\u8bef\u6821\u6b63\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u5b66\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u4f7f\u7528\u4e0d\u540c\u6807\u8bb0\u96c6\u7684\u60c5\u51b5\u4e0b\u90fd\u80fd\u786e\u4fddDNA\u5e8f\u5217\u7684\u6062\u590d\u3002"}}
{"id": "2511.01306", "categories": ["cs.IT", "math.IT", "11T71", "E.4"], "pdf": "https://arxiv.org/pdf/2511.01306", "abs": "https://arxiv.org/abs/2511.01306", "authors": ["Peipei Zheng", "Dong He", "Qunying Liao"], "title": "On the Ding and Helleseth's 9th open problem about optimal ternary cyclic codes", "comment": "20 pages", "summary": "The cyclic code is a subclass of linear codes and has applications in\nconsumer electronics, data storage systems and communication systems as they\nhave efficient encoding and decoding algorithms. In 2013, Ding, et al.\npresented nine open problems about optimal ternary cyclic codes. Till now, the\n1st, 2nd and 6th problems were completely solved, and the 3rd, 7th, 8th and 9th\nproblems were partially solved. In this manuscript, we focus on the 9th\nproblem. By determining the root set of some special polynomials over finite\nfields, we give an incomplete answer for the 9th problem, and then we construct\ntwo classes of optimal ternary cyclic codes with respect to the Sphere Packing\nBound basing on some special polynomials over finite fields", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6700\u4f18\u4e09\u5143\u5faa\u73af\u7801\u7684\u7b2c9\u4e2a\u5f00\u653e\u95ee\u9898\uff0c\u901a\u8fc7\u786e\u5b9a\u6709\u9650\u57df\u4e0a\u7279\u6b8a\u591a\u9879\u5f0f\u7684\u6839\u96c6\uff0c\u7ed9\u51fa\u4e86\u4e0d\u5b8c\u6574\u7684\u7b54\u6848\uff0c\u5e76\u57fa\u4e8e\u7279\u6b8a\u591a\u9879\u5f0f\u6784\u9020\u4e86\u4e24\u7c7b\u6ee1\u8db3\u7403\u586b\u5145\u754c\u7684\u6700\u4f18\u4e09\u5143\u5faa\u73af\u7801\u3002", "motivation": "\u5faa\u73af\u7801\u662f\u7ebf\u6027\u7801\u7684\u5b50\u7c7b\uff0c\u5728\u6d88\u8d39\u7535\u5b50\u3001\u6570\u636e\u5b58\u50a8\u548c\u901a\u4fe1\u7cfb\u7edf\u4e2d\u5177\u6709\u5e94\u7528\u4ef7\u503c\u30022013\u5e74Ding\u7b49\u4eba\u63d0\u51fa\u4e86\u5173\u4e8e\u6700\u4f18\u4e09\u5143\u5faa\u73af\u7801\u76849\u4e2a\u5f00\u653e\u95ee\u9898\uff0c\u5176\u4e2d\u7b2c9\u4e2a\u95ee\u9898\u5c1a\u672a\u5b8c\u5168\u89e3\u51b3\u3002", "method": "\u901a\u8fc7\u786e\u5b9a\u6709\u9650\u57df\u4e0a\u7279\u6b8a\u591a\u9879\u5f0f\u7684\u6839\u96c6\uff0c\u5206\u6790\u8fd9\u4e9b\u591a\u9879\u5f0f\u7684\u6027\u8d28\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u7279\u6b8a\u591a\u9879\u5f0f\u6784\u9020\u5faa\u73af\u7801\u3002", "result": "\u7ed9\u51fa\u4e86\u7b2c9\u4e2a\u95ee\u9898\u7684\u4e0d\u5b8c\u6574\u7b54\u6848\uff0c\u5e76\u6210\u529f\u6784\u9020\u4e86\u4e24\u7c7b\u6ee1\u8db3\u7403\u586b\u5145\u754c\u7684\u6700\u4f18\u4e09\u5143\u5faa\u73af\u7801\u3002", "conclusion": "\u672c\u7814\u7a76\u63a8\u8fdb\u4e86\u5bf9\u6700\u4f18\u4e09\u5143\u5faa\u73af\u7801\u7b2c9\u4e2a\u95ee\u9898\u7684\u7406\u89e3\uff0c\u5e76\u63d0\u4f9b\u4e86\u65b0\u7684\u6700\u4f18\u7801\u6784\u9020\u65b9\u6cd5\u3002"}}
{"id": "2511.01309", "categories": ["cs.IT", "math.IT", "11T71", "E.4"], "pdf": "https://arxiv.org/pdf/2511.01309", "abs": "https://arxiv.org/abs/2511.01309", "authors": ["Qunying Liao", "Zhaohui Zhang", "Peipei Zheng"], "title": "Several classes of three-weight or four-weight linear codes", "comment": "15pages", "summary": "In this manuscript, we construct a class of projective three- weight linear\ncodes and two classes of projective four-weight linear codes over F2 from the\ndefining sets construction, and determine their weight distributions by using\nadditive characters. Especially, the projective three-weight linear code and\none class of projective four-weight linear codes (Theorem 4.1) can be applied\nin secret sharing schemes.", "AI": {"tldr": "\u6784\u5efa\u4e86\u6709\u9650\u57dfF2\u4e0a\u7684\u4e00\u7c7b\u5c04\u5f71\u4e09\u6743\u91cd\u7ebf\u6027\u7801\u548c\u4e24\u7c7b\u5c04\u5f71\u56db\u6743\u91cd\u7ebf\u6027\u7801\uff0c\u4f7f\u7528\u52a0\u6cd5\u7279\u5f81\u786e\u5b9a\u4e86\u5b83\u4eec\u7684\u91cd\u91cf\u5206\u5e03\uff0c\u5e76\u63a2\u8ba8\u4e86\u5728\u79d8\u5bc6\u5171\u4eab\u65b9\u6848\u4e2d\u7684\u5e94\u7528", "motivation": "\u7814\u7a76\u5c04\u5f71\u7ebf\u6027\u7801\u7684\u6784\u9020\u53ca\u5176\u5728\u5bc6\u7801\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u79d8\u5bc6\u5171\u4eab\u65b9\u6848", "method": "\u4f7f\u7528\u5b9a\u4e49\u96c6\u6784\u9020\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a0\u6cd5\u7279\u5f81\u5206\u6790\u786e\u5b9a\u91cd\u91cf\u5206\u5e03", "result": "\u6210\u529f\u6784\u9020\u4e86\u4e00\u7c7b\u5c04\u5f71\u4e09\u6743\u91cd\u7ebf\u6027\u7801\u548c\u4e24\u7c7b\u5c04\u5f71\u56db\u6743\u91cd\u7ebf\u6027\u7801\uff0c\u5e76\u786e\u5b9a\u4e86\u5b83\u4eec\u7684\u91cd\u91cf\u5206\u5e03", "conclusion": "\u6240\u6784\u9020\u7684\u5c04\u5f71\u4e09\u6743\u91cd\u7ebf\u6027\u7801\u548c\u4e00\u7c7b\u5c04\u5f71\u56db\u6743\u91cd\u7ebf\u6027\u7801\u9002\u7528\u4e8e\u79d8\u5bc6\u5171\u4eab\u65b9\u6848"}}
{"id": "2511.01414", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01414", "abs": "https://arxiv.org/abs/2511.01414", "authors": ["Angelos Gkekas", "Nikos A. Mitsiou", "Ioannis Souldatos", "George K. Karagiannidis"], "title": "On the Computability of Finding Capacity-Achieving Codes", "comment": null, "summary": "This work studies the problem of constructing capacity-achieving codes from\nan algorithmic perspective. Specifically, we prove that there exists a Turing\nmachine which, given a discrete memoryless channel $p_{Y|X}$, a target rate $R$\nless than the channel capacity $C(p_{Y|X})$, and an error tolerance $\\epsilon >\n0$, outputs a block code $\\mathcal{C}$ achieving a rate at least $R$ and a\nmaximum block error probability below $\\epsilon$. The machine operates in the\ngeneral case where all transition probabilities of $p_{Y|X}$ are computable\nreal numbers, and the parameters $R$ and $\\epsilon$ are rational. The proof\nbuilds on Shannon's Channel Coding Theorem and relies on an exhaustive search\napproach that systematically enumerates all codes of increasing block length\nuntil a valid code is found. This construction is formalized using the theory\nof recursive functions, yielding a $\\mu$-recursive function $\\mathrm{FindCode}\n: \\mathbb{N}^3 \\rightharpoonup \\mathbb{N}$ that takes as input appropriate\nencodings of $p_{Y|X}$, $R$, and $\\epsilon$, and, whenever $R < C(p_{Y|X})$,\noutputs an encoding of a valid code. By Kleene's Normal Form Theorem, which\nestablishes the computational equivalence between Turing machines and\n$\\mu$-recursive functions, we conclude that the problem is solvable by a Turing\nmachine. This result can also be extended to the case where $\\epsilon$ is a\ncomputable real number, while we further discuss an analogous generalization of\nour analysis when $R$ is computable as well. We note that the assumptions that\nthe probabilities of $p_{Y|X}$, as well as $\\epsilon$ and $R$, are computable\nreal numbers cannot be further weakened, since computable reals constitute the\nlargest subset of $\\mathbb{R}$ representable by algorithmic means.", "AI": {"tldr": "\u8bc1\u660e\u5b58\u5728\u56fe\u7075\u673a\u80fd\u591f\u4e3a\u4efb\u610f\u79bb\u6563\u65e0\u8bb0\u5fc6\u4fe1\u9053\u6784\u9020\u5bb9\u91cf\u53ef\u8fbe\u7801\uff0c\u53ea\u8981\u4fe1\u9053\u8f6c\u79fb\u6982\u7387\u3001\u76ee\u6807\u901f\u7387\u548c\u8bef\u5dee\u5bb9\u9650\u90fd\u662f\u53ef\u8ba1\u7b97\u5b9e\u6570\u3002", "motivation": "\u4ece\u7b97\u6cd5\u89d2\u5ea6\u7814\u7a76\u4fe1\u9053\u7f16\u7801\u95ee\u9898\uff0c\u63a2\u7d22\u5728\u53ef\u8ba1\u7b97\u6027\u6846\u67b6\u4e0b\u6784\u9020\u5bb9\u91cf\u53ef\u8fbe\u7801\u7684\u53ef\u80fd\u6027\u3002", "method": "\u57fa\u4e8e\u9999\u519c\u4fe1\u9053\u7f16\u7801\u5b9a\u7406\uff0c\u91c7\u7528\u7a77\u4e3e\u641c\u7d22\u65b9\u6cd5\u7cfb\u7edf\u679a\u4e3e\u6240\u6709\u9012\u589e\u5757\u957f\u7684\u7801\uff0c\u76f4\u5230\u627e\u5230\u6ee1\u8db3\u901f\u7387\u548c\u8bef\u7801\u7387\u8981\u6c42\u7684\u6709\u6548\u7801\u3002\u4f7f\u7528\u9012\u5f52\u51fd\u6570\u7406\u8bba\u5f62\u5f0f\u5316\u6784\u9020\u8fc7\u7a0b\u3002", "result": "\u8bc1\u660e\u4e86\u5b58\u5728\u03bc-\u9012\u5f52\u51fd\u6570FindCode\uff0c\u5728R<\u4fe1\u9053\u5bb9\u91cf\u65f6\u80fd\u591f\u8f93\u51fa\u6709\u6548\u7801\u7684\u7f16\u7801\u3002\u901a\u8fc7Kleene\u8303\u5f0f\u5b9a\u7406\uff0c\u7b49\u4ef7\u4e8e\u56fe\u7075\u673a\u53ef\u89e3\u3002", "conclusion": "\u5728\u4fe1\u9053\u8f6c\u79fb\u6982\u7387\u3001\u76ee\u6807\u901f\u7387\u548c\u8bef\u5dee\u5bb9\u9650\u5747\u4e3a\u53ef\u8ba1\u7b97\u5b9e\u6570\u7684\u6761\u4ef6\u4e0b\uff0c\u6784\u9020\u5bb9\u91cf\u53ef\u8fbe\u7801\u7684\u95ee\u9898\u662f\u56fe\u7075\u673a\u53ef\u89e3\u7684\uff0c\u4e14\u8fd9\u4e9b\u5047\u8bbe\u65e0\u6cd5\u8fdb\u4e00\u6b65\u5f31\u5316\u3002"}}
{"id": "2511.01539", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01539", "abs": "https://arxiv.org/abs/2511.01539", "authors": ["Tulasi Sowjanya B.", "Prasad Krishnan"], "title": "A Hypergraph based lower bound on Pliable Index Coding based on Nested Side-Information Sets", "comment": null, "summary": "In pliable index coding (PICOD), a number of clients are connected via a\nnoise-free broadcast channel to a server which has a list of messages. Each\nclient has a unique subset of messages at the server as side-information, and\nrequests for any one message not in the side-information. A PICOD scheme of\nlength $\\ell$ is a set of $\\ell$ encoded transmissions broadcast from the\nserver such that all clients are satisfied. Finding the optimal (minimum)\nlength of PICOD and designing PICOD schemes that have small length are the\nfundamental questions in PICOD. In this paper, we present a new lower bound for\nthe optimal PICOD length using a new structural parameter called the nesting\nnumber, denoted by $\\eta(\\ch)$ associated with the hypergraph $\\ch$ that\nrepresents the PICOD problem. While the nesting number bound is not stronger\nthan previously known bounds, it can provide some computational advantages over\nthem. Also, using the nesting number bound, we obtain novel lower bounds for\nsome PICOD problems with special structures, which are tight in some cases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5d4c\u5957\u6570\u7684\u65b0\u4e0b\u754c\u6765\u5206\u6790PICOD\u95ee\u9898\u7684\u6700\u4f18\u957f\u5ea6\uff0c\u867d\u7136\u4e0d\u6bd4\u5176\u4ed6\u5df2\u77e5\u4e0b\u754c\u66f4\u5f3a\uff0c\u4f46\u5177\u6709\u8ba1\u7b97\u4f18\u52bf\uff0c\u5e76\u5bf9\u7279\u6b8a\u7ed3\u6784\u7684PICOD\u95ee\u9898\u7ed9\u51fa\u4e86\u7d27\u4e0b\u754c\u3002", "motivation": "\u5728PICOD\u95ee\u9898\u4e2d\uff0c\u5bfb\u627e\u6700\u4f18\u7f16\u7801\u957f\u5ea6\u548c\u8bbe\u8ba1\u77ed\u957f\u5ea6\u7f16\u7801\u65b9\u6848\u662f\u6838\u5fc3\u95ee\u9898\u3002\u73b0\u6709\u4e0b\u754c\u65b9\u6cd5\u5728\u8ba1\u7b97\u4e0a\u53ef\u80fd\u4e0d\u591f\u9ad8\u6548\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u7ed3\u6784\u53c2\u6570\u6765\u6539\u8fdb\u5206\u6790\u3002", "method": "\u5f15\u5165\u65b0\u7684\u7ed3\u6784\u53c2\u6570\u2014\u2014\u5d4c\u5957\u6570\u03b7(\u210b)\uff0c\u8be5\u53c2\u6570\u4e0e\u8868\u793aPICOD\u95ee\u9898\u7684\u8d85\u56fe\u210b\u76f8\u5173\u8054\uff0c\u7528\u4e8e\u63a8\u5bfc\u6700\u4f18PICOD\u957f\u5ea6\u7684\u65b0\u4e0b\u754c\u3002", "result": "\u5d4c\u5957\u6570\u4e0b\u754c\u867d\u7136\u4e0d\u6bd4\u5176\u4ed6\u5df2\u77e5\u4e0b\u754c\u66f4\u5f3a\uff0c\u4f46\u63d0\u4f9b\u4e86\u8ba1\u7b97\u4f18\u52bf\u3002\u5bf9\u4e8e\u67d0\u4e9b\u7279\u6b8a\u7ed3\u6784\u7684PICOD\u95ee\u9898\uff0c\u57fa\u4e8e\u5d4c\u5957\u6570\u7684\u4e0b\u754c\u662f\u7d27\u7684\u3002", "conclusion": "\u5d4c\u5957\u6570\u4f5c\u4e3a\u65b0\u7684\u7ed3\u6784\u53c2\u6570\uff0c\u4e3aPICOD\u95ee\u9898\u7684\u6700\u4f18\u957f\u5ea6\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u8ba1\u7b97\u4f18\u52bf\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5177\u6709\u7279\u6b8a\u7ed3\u6784\u7684PICOD\u95ee\u9898\u3002"}}
{"id": "2511.01798", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01798", "abs": "https://arxiv.org/abs/2511.01798", "authors": ["Dimitrios Tyrovolas", "Sotiris A. Tegos", "Yue Xiao", "Panagiotis D. Diamantoulakis", "Sotiris Ioannidis", "Christos Liaskos", "George K. Karagiannidis", "Stylianos D. Asimonis"], "title": "Ergodic Rate Analysis of Two-State Pinching-Antenna Systems", "comment": "Submitted to IEEE ICC 2026", "summary": "Programmable wireless environments (PWEs) represent a central paradigm in\nnext-generation communication networks, aiming to transform wireless\npropagation from a passive medium into an intelligent and reconfigurable entity\ncapable of dynamically adapting to network demands. In this context,\npinching-antenna systems (PASs) have emerged as a promising enabler capable of\nreconfiguring both the channel characteristics and the path loss itself by\nselectively exciting radiation points along dielectric waveguides. However,\nexisting studies largely rely on the assumption of continuously reconfigurable\npinching antenna (PA) positions, overlooking the discreteness imposed by\npractical implementations, which allow for only a finite number of PA position.\nIn this paper, an analytical framework is developed for evaluating the rate\nperformance of two-state PASs, where the antenna locations are fixed, and only\ntheir activation states can be controlled. The analysis incorporates the\ndiscrete spatial structure of the waveguide and leads to a closed-form\nexpression for the ergodic achievable data rate, while pinching discretization\nefficiency is introduced to quantify the performance deviation from the ideal\ncontinuous configuration. Simulation results demonstrate that near-continuous\nperformance can be achieved with a limited number of PAs, offering valuable\ninsights into the design and scalability of PASs in PWEs.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u53ef\u7f16\u7a0b\u65e0\u7ebf\u73af\u5883\u4e2d\u5939\u6301\u5929\u7ebf\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u91cd\u70b9\u7814\u7a76\u4e86\u79bb\u6563\u4f4d\u7f6e\u914d\u7f6e\u5bf9\u6570\u636e\u901f\u7387\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u91cf\u5316\u6027\u80fd\u504f\u5dee\u7684\u6307\u6807\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5047\u8bbe\u5939\u6301\u5929\u7ebf\u4f4d\u7f6e\u53ef\u8fde\u7eed\u8c03\u8282\uff0c\u4f46\u5b9e\u9645\u5b9e\u73b0\u4e2d\u53ea\u80fd\u6709\u6709\u9650\u4e2a\u56fa\u5b9a\u4f4d\u7f6e\uff0c\u9700\u8981\u5206\u6790\u8fd9\u79cd\u79bb\u6563\u5316\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u4e86\u5206\u6790\u6846\u67b6\u8bc4\u4f30\u53cc\u72b6\u6001\u5939\u6301\u5929\u7ebf\u7cfb\u7edf\u7684\u901f\u7387\u6027\u80fd\uff0c\u8003\u8651\u4e86\u6ce2\u5bfc\u7684\u79bb\u6563\u7a7a\u95f4\u7ed3\u6784\uff0c\u63a8\u5bfc\u4e86\u904d\u5386\u53ef\u8fbe\u6570\u636e\u901f\u7387\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6709\u9650\u6570\u91cf\u7684\u5939\u6301\u5929\u7ebf\u5c31\u80fd\u5b9e\u73b0\u63a5\u8fd1\u8fde\u7eed\u914d\u7f6e\u7684\u6027\u80fd\uff0c\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u548c\u6269\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002", "conclusion": "\u5939\u6301\u5929\u7ebf\u7cfb\u7edf\u5728\u53ef\u7f16\u7a0b\u65e0\u7ebf\u73af\u5883\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u79bb\u6563\u4f4d\u7f6e\u914d\u7f6e\u4e0d\u4f1a\u663e\u8457\u5f71\u54cd\u6027\u80fd\uff0c\u7cfb\u7edf\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.01838", "categories": ["cs.IT", "cs.AI", "cs.NE", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01838", "abs": "https://arxiv.org/abs/2511.01838", "authors": ["Zirui Deng", "Netanel Raviv"], "title": "Efficient Vector Symbolic Architectures from Histogram Recovery", "comment": null, "summary": "Vector symbolic architectures (VSAs) are a family of information\nrepresentation techniques which enable composition, i.e., creating complex\ninformation structures from atomic vectors via binding and superposition, and\nhave recently found wide ranging applications in various neurosymbolic\nartificial intelligence (AI) systems. Recently, Raviv proposed the use of\nrandom linear codes in VSAs, suggesting that their subcode structure enables\nefficient binding, while preserving the quasi-orthogonality that is necessary\nfor neural processing. Yet, random linear codes are difficult to decode under\nnoise, which severely limits the resulting VSA's ability to support recovery,\ni.e., the retrieval of information objects and their attributes from a noisy\ncompositional representation.\n  In this work we bridge this gap by utilizing coding theoretic tools. First,\nwe argue that the concatenation of Reed-Solomon and Hadamard codes is suitable\nfor VSA, due to the mutual quasi-orthogonality of the resulting codewords (a\nfolklore result). Second, we show that recovery of the resulting compositional\nrepresentations can be done by solving a problem we call histogram recovery. In\nhistogram recovery, a collection of $N$ histograms over a finite field is given\nas input, and one must find a collection of Reed-Solomon codewords of length\n$N$ whose entry-wise symbol frequencies obey those histograms. We present an\noptimal solution to the histogram recovery problem by using algorithms related\nto list-decoding, and analyze the resulting noise resilience. Our results give\nrise to a noise-resilient VSA with formal guarantees regarding efficient\nencoding, quasi-orthogonality, and recovery, without relying on any heuristics\nor training, and while operating at improved parameters relative to similar\nsolutions such as the Hadamard code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ea7\u8054Reed-Solomon\u548cHadamard\u7801\u7684\u566a\u58f0\u5f39\u6027\u5411\u91cf\u7b26\u53f7\u67b6\u6784\uff0c\u901a\u8fc7\u89e3\u51b3\u76f4\u65b9\u56fe\u6062\u590d\u95ee\u9898\u5b9e\u73b0\u4e86\u9ad8\u6548\u7f16\u7801\u3001\u51c6\u6b63\u4ea4\u6027\u548c\u6062\u590d\u80fd\u529b\u3002", "motivation": "\u968f\u673a\u7ebf\u6027\u7801\u5728\u5411\u91cf\u7b26\u53f7\u67b6\u6784\u4e2d\u96be\u4ee5\u5728\u566a\u58f0\u4e0b\u89e3\u7801\uff0c\u9650\u5236\u4e86\u4fe1\u606f\u6062\u590d\u80fd\u529b\uff0c\u9700\u8981\u4e00\u79cd\u5177\u6709\u6b63\u5f0f\u4fdd\u8bc1\u7684\u566a\u58f0\u5f39\u6027\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528Reed-Solomon\u548cHadamard\u7801\u7ea7\u8054\uff0c\u63d0\u51fa\u76f4\u65b9\u56fe\u6062\u590d\u95ee\u9898\uff0c\u5e76\u5229\u7528\u5217\u8868\u89e3\u7801\u76f8\u5173\u7b97\u6cd5\u63d0\u4f9b\u6700\u4f18\u89e3\u3002", "result": "\u5f00\u53d1\u51fa\u5177\u6709\u6b63\u5f0f\u4fdd\u8bc1\u7684\u566a\u58f0\u5f39\u6027VSA\uff0c\u5728\u9ad8\u6548\u7f16\u7801\u3001\u51c6\u6b63\u4ea4\u6027\u548c\u6062\u590d\u65b9\u9762\u4f18\u4e8e\u7c7b\u4f3c\u89e3\u51b3\u65b9\u6848\u5982Hadamard\u7801\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5411\u91cf\u7b26\u53f7\u67b6\u6784\u63d0\u4f9b\u4e86\u4e0d\u4f9d\u8d56\u542f\u53d1\u5f0f\u6216\u8bad\u7ec3\u7684\u566a\u58f0\u5f39\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u6539\u8fdb\u7684\u53c2\u6570\u6027\u80fd\u3002"}}
