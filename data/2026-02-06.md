<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 9]
- [cs.DS](#cs.DS) [Total: 8]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.GT](#cs.GT) [Total: 4]
- [cs.IT](#cs.IT) [Total: 8]
- [cs.IR](#cs.IR) [Total: 15]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Pruning Minimal Reasoning Graphs for Efficient Retrieval-Augmented Generation](https://arxiv.org/abs/2602.04926)
*Ning Wang,Kuanyan Zhu,Daniel Yuehwoon Yee,Yitang Gao,Shiying Huang,Zirun Xu,Sainyam Galhotra*

Main category: cs.DB

TL;DR: 提出AutoPrunedRetriever，一种图式RAG系统，通过持久化最小推理子图并增量扩展，减少重复检索和推理，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统对每个查询都重新检索长段落并从头推理，导致token使用、延迟和成本过高。需要一种能持久化并复用先前推理结果的系统。

Method: 使用图结构存储实体和关系，将问题、事实和答案表示为边序列。采用两层整合策略（快速ANN/KNN别名检测+选择性k-means）保持图紧凑，并剪枝低价值结构。提供两种前端实现：基于REBEL三元组解析器和基于LLM提取器。

Result: 在GraphRAG-Benchmark上比HippoRAG2提升9-11个点，在STEM和TV基准测试中排名第一，同时token使用量比基线减少两个数量级。

Conclusion: AutoPrunedRetriever通过图式持久化和增量扩展，实现了高效的知识复用，为长会话、演化语料库和多智能体管道提供了实用基础。

Abstract: Retrieval-augmented generation (RAG) is now standard for knowledge-intensive LLM tasks, but most systems still treat every query as fresh, repeatedly re-retrieving long passages and re-reasoning from scratch, inflating tokens, latency, and cost. We present AutoPrunedRetriever, a graph-style RAG system that persists the minimal reasoning subgraph built for earlier questions and incrementally extends it for later ones. AutoPrunedRetriever stores entities and relations in a compact, ID-indexed codebook and represents questions, facts, and answers as edge sequences, enabling retrieval and prompting over symbolic structure instead of raw text. To keep the graph compact, we apply a two-layer consolidation policy (fast ANN/KNN alias detection plus selective $k$-means once a memory threshold is reached) and prune low-value structure, while prompts retain only overlap representatives and genuinely new evidence. We instantiate two front ends: AutoPrunedRetriever-REBEL, which uses REBEL as a triplet parser, and AutoPrunedRetriever-llm, which swaps in an LLM extractor. On GraphRAG-Benchmark (Medical and Novel), both variants achieve state-of-the-art complex reasoning accuracy, improving over HippoRAG2 by roughly 9--11 points, and remain competitive on contextual summarize and generation. On our harder STEM and TV benchmarks, AutoPrunedRetriever again ranks first, while using up to two orders of magnitude fewer tokens than graph-heavy baselines, making it a practical substrate for long-running sessions, evolving corpora, and multi-agent pipelines.

</details>


### [2] [DistillER: Knowledge Distillation in Entity Resolution with Large Language Models](https://arxiv.org/abs/2602.05452)
*Alexandros Zeakis,George Papadakis,Dimitrios Skoutas,Manolis Koubarakis*

Main category: cs.DB

TL;DR: DistillER是一个通过知识蒸馏将大语言模型的知识转移到小模型的实体解析框架，无需黄金标签，在效果和效率上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的实体解析方法要么依赖计算成本高昂的大模型，要么需要监督学习的标注数据，存在效率与效果之间的鸿沟。需要一种更实用的方法。

Method: 提出DistillER框架，从三个维度系统解决知识蒸馏问题：数据选择（识别信息丰富的子集）、知识提取（比较单/多教师设置）、蒸馏算法（评估监督微调和强化学习方法）。

Result: 实验表明，在LLM教师生成的噪声标签上进行监督微调的学生模型，持续优于其他知识蒸馏策略，同时能生成高质量的解释。DistillER在效果和效率上都显著优于现有方法。

Conclusion: 知识蒸馏是使LLM驱动的实体解析更实用的有效途径，DistillER框架成功填补了效率与效果之间的关键空白，为实际应用提供了可行方案。

Abstract: Recent advances in Entity Resolution (ER) have leveraged Large Language Models (LLMs), achieving strong performance but at the cost of substantial computational resources or high financial overhead. Existing LLM-based ER approaches operate either in unsupervised settings and rely on very large and costly models, or in supervised settings and require ground-truth annotations, leaving a critical gap between time efficiency and effectiveness. To make LLM-powered ER more practical, we investigate Knowledge Distillation (KD) as a means to transfer knowledge from large, effective models (Teachers) to smaller, more efficient models (Students) without requiring gold labels. We introduce DistillER, the first framework that systematically bridges this gap across three dimensions: (i) Data Selection, where we study strategies for identifying informative subsets of data; (ii) Knowledge Elicitation, where we compare single- and multi-teacher settings across LLMs and smaller language models (SLMs); and (iii) Distillation Algorithms, where we evaluate supervised fine-tuning and reinforcement learning approaches. Our experiments reveal that supervised fine-tuning of Students on noisy labels generated by LLM Teachers consistently outperforms alternative KD strategies, while also enabling high-quality explanation generation. Finally, we benchmark DistillER against established supervised and unsupervised ER methods based on LLMs and SLMs, demonstrating significant improvements in both effectiveness and efficiency.

</details>


### [3] [Repairing Property Graphs under PG-Constraints](https://arxiv.org/abs/2602.05503)
*Christopher Spinrath,Angela Bonifati,Rachid Echahed*

Main category: cs.DB

TL;DR: 该论文研究了在PG-Constraints约束下修复属性图的问题，提出了基于整数线性规划、朴素算法和LP引导贪心算法的三种修复策略，实验显示标签删除比节点/边删除减少59%的删除量，LP引导贪心算法比ILP策略运行时间减少97%且质量相当。


<details>
  <summary>Details</summary>
Motivation: 随着图数据库标准化发展，出现了GQL、SQL/PGQ等标准查询语言和PG-Constraints约束语言。当前需要研究在PG-Constraints约束下如何有效修复属性图，以解决图数据中的约束违反问题。

Method: 识别PG-Constraints的重要子集，支持否定约束和递归特性，允许基于自动机的结构错误分析。提出完整的属性图修复流程，涉及图拓扑结构变更，支持节点、边和可选标签删除。研究了三种算法策略：整数线性规划(ILP)、朴素算法和LP引导贪心算法。

Result: 实验表明，使用标签删除相比节点/边删除可以减少59%的删除操作。LP引导贪心算法相比ILP策略在运行时间上减少高达97%，同时保持相同的修复质量。

Conclusion: 该研究为PG-Constraints约束下的属性图修复提供了有效的解决方案，LP引导贪心算法在效率和质量之间取得了良好平衡，标签删除策略显著减少了修复成本。

Abstract: Recent standardization efforts for graph databases lead to standard query languages like GQL and SQL/PGQ, and constraint languages like Property Graph Constraints (PG-Constraints). In this paper, we embark on the study of repairing property graphs under PG-Constraints. We identify a significant subset of PG-Constraints, encoding denial constraints and including recursion as a key feature, while still permitting automata-based structural analyses of errors. We present a comprehensive repair pipeline for these constraints to repair Property Graphs, involving changes in the graph topology and leading to node, edge and, optionally, label deletions. We investigate three algorithmic strategies for the repair procedure, based on Integer Linear Programming (ILP), a naive, and an LP-guided greedy algorithm. Our experiments on various real-world datasets reveal that repairing with label deletions can achieve a 59% reduction in deletions compared to node/edge deletions. Moreover, the LP-guided greedy algorithm offers a runtime advantage of up to 97% compared to the ILP strategy, while matching the same quality.

</details>


### [4] [Taking the Leap: Efficient and Reliable Fine-Grained NUMA Migration in User-space](https://arxiv.org/abs/2602.05540)
*Felix Schuhknecht,Nick Rassau*

Main category: cs.DB

TL;DR: 论文提出page_leap()，一种新的用户空间内存页面迁移方法，用于优化NUMA架构下的数据库查询性能，相比现有方案具有更高性能和更完整功能集。


<details>
  <summary>Details</summary>
Motivation: 现代多插槽架构虽然提供单一虚拟地址空间，但物理内存分布在多个NUMA区域。当查询在多区域核心上并行执行时，需要将相关数据分布到相同区域以确保本地访问。现有迁移方案（Linux自动NUMA平衡和move_pages()系统调用）在功能集和性能方面存在显著不足。

Method: 提出page_leap()方法，这是一种新的用户空间异步页面迁移技术，通过利用虚拟内存子系统的特性实现高性能迁移。该方法具有以下特点：用户主动触发、确保所有页面最终迁移、正确处理并发写入、支持池化内存、基于工作负载自适应调整迁移粒度、同时支持小页面和大页面。

Result: page_leap()方法在功能完整性和性能方面都优于现有方案，能够有效解决NUMA架构下的数据局部性问题，提升数据库查询的并行执行效率。

Conclusion: page_leap()为NUMA架构下的内存页面迁移提供了一种高效、功能完整的替代方案，特别适用于需要高性能数据局部性优化的数据库系统和其他内存密集型应用。

Abstract: Modern multi-socket architectures offer a single virtual address space, but physically divide main-memory across multiple regions, where each region is attached to a CPU and its cores. While this simplifies the usage, developers must be aware of non-uniform memory access (NUMA), where an access by a thread running on a core-local NUMA region is significantly cheaper than an access from a core-remote region. Obviously, if query answering is parallelized across the cores of multiple regions, then the portion of the database on which the query is operating should be distributed across the same regions to ensure local accesses. As the present data placement might not fit this, migrating pages from one NUMA region to another can be performed to improve the situation. To do so, different options exist: One option is to rely on automatic NUMA balancing integrated in Linux, which is steered by the observed access patterns and frequency. Another option is to actively trigger migration via the system call move_pages(). Unfortunately, both variants have significant downsides in terms of their feature set and performance. As an alternative, we propose a new user-space migration method called page_leap() that can perform page migration asynchronously at a high performance by exploiting features of the virtual memory subsystem. The method is (a) actively triggered by the user, (b) ensures that all pages are eventually migrated, (c) handles concurrent writes correctly, (d) supports pooled memory, (e) adaptively adjusts its migration granularity based on the workload, and (f) supports both small pages and huge pages.

</details>


### [5] [One Size Does NOT Fit All: On the Importance of Physical Representations for Datalog Evaluation](https://arxiv.org/abs/2602.05651)
*Nick Rassau,Felix Schuhknecht*

Main category: cs.DB

TL;DR: 该论文研究Datalog查询引擎中物理表示的选择问题，通过实验分析工作负载特性与物理表示之间的相互作用，并设计基于决策树的自动选择机制。


<details>
  <summary>Details</summary>
Motivation: 现有Datalog引擎在物理表示选择上过于限制，通常采用一刀切的解决方案。Datalog程序的执行计划涉及多种操作类型（插入、查找、包含检查），且不同工作负载特性对操作需求差异很大，需要多样化的物理表示来满足不同场景需求。

Method: 1. 深入实验研究：分析潜在合适的物理表示与Datalog程序的七个工作负载特性维度之间的相互作用；2. 设计自动选择机制：利用一组决策树为给定工作负载识别合适的物理表示。

Result: 通过实验揭示了哪些工作负载特性真正影响物理表示的性能，并开发了能够根据工作负载特征自动选择最优物理表示的决策树系统。

Conclusion: Datalog查询引擎需要根据具体工作负载特性灵活选择物理表示，基于决策树的自动选择机制能够有效提升查询性能，解决了现有引擎物理表示选择过于限制的问题。

Abstract: Datalog is an increasingly popular recursive query language that is declarative by design, meaning its programs must be translated by an engine into the actual physical execution plan. When generating this plan, a central decision is how to physically represent all involved relations, an aspect in which existing Datalog engines are surprisingly restrictive and often resort to one-size-fits-all solutions. The reason for this is that the typical execution plan of a Datalog program not only performs a single type of operation against the physical representations, but a mixture of operations, such as insertions, lookups, and containment-checks. Further, the relevance of each operation type highly depends on the workload characteristics, which range from familiar properties such as the size, multiplicity, and arity of the individual relations to very specific Datalog properties, such as the "interweaving" of rules when relations occur multiple times, and in particular the recursiveness of the query which might generate new tuples on the fly during evaluation. This indicates that a variety of physical representations, each with its own strengths and weaknesses, is required to meet the specific needs of different workload situations. To evaluate this, we conduct an in-depth experimental study of the interplay between potentially suitable physical representations and seven dimensions of workload characteristics that vary across actual Datalog programs, revealing which properties actually matter. Based on these insights, we design an automatic selection mechanism that utilizes a set of decision trees to identify suitable physical representations for a given workload.

</details>


### [6] [Fast Private Adaptive Query Answering for Large Data Domains](https://arxiv.org/abs/2602.05674)
*Miguel Fuentes,Brett Mullins,Yingtai Xiao,Daniel Kifer,Cameron Musco,Daniel Sheldon*

Main category: cs.DB

TL;DR: 提出AIM+GReM机制，通过残差查询和高效重构改进差分隐私边际释放，大幅提升计算效率


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私边际释放机制在从噪声测量重构边际估计时存在计算瓶颈，需要更高效的解决方案

Method: 提出基于多维数组的残差查询概念框架、惰性更新策略和自适应隐私预算分配，将残差查询集成到AIM等自适应机制中

Result: AIM+GReM机制比原始框架快几个数量级，具有竞争性的误差和显著改善的可扩展性

Conclusion: 残差查询与自适应机制的集成能有效解决差分隐私边际释放的计算瓶颈问题，实现高效、准确的隐私保护数据发布

Abstract: Privately releasing marginals of a tabular dataset is a foundational problem in differential privacy. However, state-of-the-art mechanisms suffer from a computational bottleneck when marginal estimates are reconstructed from noisy measurements. Recently, residual queries were introduced and shown to lead to highly efficient reconstruction in the batch query answering setting. We introduce new techniques to integrate residual queries into state-of-the-art adaptive mechanisms such as AIM. Our contributions include a novel conceptual framework for residual queries using multi-dimensional arrays, lazy updating strategies, and adaptive optimization of the per-round privacy budget allocation. Together these contributions reduce error, improve speed, and simplify residual query operations. We integrate these innovations into a new mechanism (AIM+GReM), which improves AIM by using fast residual-based reconstruction instead of a graphical model approach. Our mechanism is orders of magnitude faster than the original framework and demonstrates competitive error and greatly improved scalability.

</details>


### [7] [Cost-Efficient RAG for Entity Matching with LLMs: A Blocking-based Exploration](https://arxiv.org/abs/2602.05708)
*Chuangtao Ma,Zeyu Zhang,Arijit Khan,Sebastian Schelter,Paul Groth*

Main category: cs.DB

TL;DR: CE-RAG4EM：一种用于实体匹配的成本高效RAG架构，通过基于分块的批量检索和生成减少计算开销，在保持匹配质量的同时显著降低端到端运行时间。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG管道在大规模实体匹配应用中存在显著的检索和生成开销，需要更高效的解决方案来平衡性能和计算成本。

Method: 提出CE-RAG4EM架构，采用基于分块的批量检索和生成策略；建立统一的RAG系统分析和评估框架，重点关注分块感知优化和检索粒度。

Result: 实验表明CE-RAG4EM能够达到可比或改进的匹配质量，同时相对于强基线显著减少端到端运行时间；分析揭示了关键配置参数在性能和开销之间的固有权衡。

Conclusion: CE-RAG4EM为实体匹配和数据集成提供了高效可扩展的RAG系统设计，关键配置参数的权衡分析为实际应用提供了实用指导。

Abstract: Retrieval-augmented generation (RAG) enhances LLM reasoning in knowledge-intensive tasks, but existing RAG pipelines incur substantial retrieval and generation overhead when applied to large-scale entity matching. To address this limitation, we introduce CE-RAG4EM, a cost-efficient RAG architecture that reduces computation through blocking-based batch retrieval and generation. We also present a unified framework for analyzing and evaluating RAG systems for entity matching, focusing on blocking-aware optimizations and retrieval granularity. Extensive experiments suggest that CE-RAG4EM can achieve comparable or improved matching quality while substantially reducing end-to-end runtime relative to strong baselines. Our analysis further reveals that key configuration parameters introduce an inherent trade-off between performance and overhead, offering practical guidance for designing efficient and scalable RAG systems for entity matching and data integration.

</details>


### [8] [Even Faster Geosocial Reachability Queries](https://arxiv.org/abs/2602.05928)
*Rick van der Heijden,Nikolay Yakovets,Thekla Hamm*

Main category: cs.DB

TL;DR: 2DReach：一种更简单的地社交网络可达性查询方法，通过为每个组件存储2D R-tree，避免复杂的区间标记，实现更快的索引构建和更稳定的查询性能。


<details>
  <summary>Details</summary>
Motivation: 现有3DReach方法使用区间标记和3D R-tree处理地社交网络可达性查询，但这种方法较为复杂。作者希望开发一种更简单的方法来回答地社交网络可达性查询。

Method: 2DReach将强连通分量压缩为DAG，但不像3DReach那样计算区间标记，而是为每个组件直接存储一个包含所有可达空间顶点的2D R-tree。查询简化为单个2D R-tree查找。还提出了压缩变体，通过排除空间汇点和在具有相同可达集的组件之间共享R-tree来减少存储。

Result: 在四个真实世界数据集上的实验表明，2DReach比3DReach实现了更快的索引构建，压缩变体在所有方法中产生最小的索引大小。2DReach提供竞争性或更优的查询性能，在不同查询参数下具有更稳定的响应时间。

Conclusion: 2DReach通过避免复杂的区间标记，使用更简单的2D R-tree方法，在地社交网络可达性查询中实现了更高效的索引构建和更稳定的查询性能，同时压缩变体显著减少了存储需求。

Abstract: Geosocial reachability queries (\textsc{RangeReach}) determine whether a given vertex in a geosocial network can reach any spatial vertex within a query region. The state-of-the-art 3DReach method answers such queries by encoding graph reachability through interval labelling and indexing spatial vertices in a 3D R-tree. We present 2DReach, a simpler approach that avoids interval labelling entirely. Like 3DReach, 2DReach collapses strongly connected components (SCCs) into a DAG, but instead of computing interval labels, it directly stores a 2D R-tree per component over all reachable spatial vertices. A query then reduces to a single 2D R-tree lookup. We further propose compressed variants that reduce storage by excluding spatial sinks and sharing R-trees between components with identical reachable sets. Experiments on four real-world datasets show that 2DReach achieves faster index construction than 3DReach, with the compressed variant yielding the smallest index size among all methods. 2DReach delivers competitive or superior query performance with more stable response times across varying query parameters.

</details>


### [9] ["Detective Work We Shouldn't Have to Do": Practitioner Challenges in Regulatory-Aligned Data Quality in Machine Learning Systems](https://arxiv.org/abs/2602.05944)
*Yichun Wang,Kristina Irion,Paul Groth,Hazar Harmouch*

Main category: cs.DB

TL;DR: 欧盟监管框架（GDPR、AI法案）对ML系统数据质量提出法律要求，但实践中法律原则与工程工作流存在差距，需要合规工具、清晰治理结构和主动数据治理文化。


<details>
  <summary>Details</summary>
Motivation: 随着欧盟GDPR和AI法案等监管框架对机器学习系统数据质量提出法律要求，需要了解数据从业者如何理解监管要求、面临的挑战以及所需支持，以弥合法律原则与工程实践之间的差距。

Method: 采用定性访谈研究方法，对欧盟地区在受监管环境中从事机器学习系统的数据从业者进行半结构化访谈，探讨他们对监管要求的数据质量的理解、遇到的挑战和所需支持。

Result: 研究发现：法律原则与工程工作流存在持续差距；数据管道碎片化；现有工具存在局限性；技术团队与法律团队责任边界不清晰；质量实践倾向于被动、审计驱动的方式。

Conclusion: 需要开发合规意识工具、建立更清晰的治理结构、推动文化转变以实现主动数据治理，以弥合监管要求与机器学习工程实践之间的差距。

Abstract: Ensuring data quality in machine learning (ML) systems has become increasingly complex as regulatory requirements expand. In the European Union (EU), frameworks such as the General Data Protection Regulation (GDPR) and the Artificial Intelligence Act (AI Act) articulate data quality requirements that closely parallel technical concerns in ML practice, while also extending to legal obligations related to accountability, risk management, and human rights protection. This paper presents a qualitative interview study with EU-based data practitioners working on ML systems in regulated contexts. Through semi-structured interviews, we investigate how practitioners interpret regulatory-aligned data quality, the challenges they encounter, and the supports they identify as necessary. Our findings reveal persistent gaps between legal principles and engineering workflows, fragmentation across data pipelines, limitations of existing tools, unclear responsibility boundaries between technical and legal teams, and a tendency toward reactive, audit-driven quality practices. We also identify practitioners' needs for compliance-aware tooling, clearer governance structures, and cultural shifts toward proactive data governance.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [10] [Deterministic Retrieval at Scale: Optimal-Space LCP Indexing and 308x Energy Reduction on Modern GPUs](https://arxiv.org/abs/2602.04936)
*Stanislav Byriukov*

Main category: cs.DS

TL;DR: 提出一种基于最长公共前缀相似度的确定性top-k检索方法，通过Trie索引和热感知逻辑技术，在保证确定性的同时大幅降低能耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 传统基于两两计算的相似度检索方法在规模扩展时面临内存爆炸问题（O(N²)），而近似方法在某些需要确定性结果的场景中不可接受，需要一种既高效又确定性的检索方案。

Method: 1. 构建Trie索引，使用O(N*L)空间复杂度；2. 提出热感知逻辑(TAL)，将前缀结构转换为范围受限扫描；3. 实现O(L+k)查询时间。

Result: 1. 理论证明：在cell-probe模型中达到Ω(N)空间下界；2. 性能提升：相比传统方法，能耗降低308倍（0.0145J vs 4.46J），p95延迟降低329倍（0.114ms vs 37.5ms）；3. 资源利用：在长时运行中保持接近峰值利用率（~99%）。

Conclusion: 该方法提供了一种确定性检索原语，在需要精确结果的场景中优于近似方法，通过索引和硬件优化实现了大规模高效检索。

Abstract: We study deterministic top-k retrieval under Longest Common Prefix (LCP) similarity for N sequences of length L. We prove a tight Omega(N) space lower bound (cell-probe model) and present a trie-based index using O(N*L) space with O(L+k) query time. We contrast this with pairwise materialization (Theta(N^2)), which hits a practical OOM wall at scale, while our indexed approach remains O(N) in memory. We then introduce Thermal-Aware Logic (TAL), which turns prefix structure into range-bounded scans. In hardware measurements, TAL reduces energy per query by 308x (0.0145 J vs 4.46 J) and cuts p95 latency by 329x (0.114 ms vs 37.5 ms) on a 20M-item range-scan benchmark, while sustaining near-peak utilization (~99%) under long runs. The result is a deterministic retrieval primitive with receipts in regimes where approximate methods are unacceptable.

</details>


### [11] [Parameterized Algorithms for the Drone Delivery Problem](https://arxiv.org/abs/2602.04985)
*Simon Bartlmae,Andreas Hene,Joshua Könen,Heiko Röglin*

Main category: cs.DS

TL;DR: 本文研究了无人机配送问题(DDT)的复杂性，证明了即使在路径图上该问题也无多项式时间近似解，并提出了基于交集图树宽度的FPT算法。


<details>
  <summary>Details</summary>
Motivation: 现代物流行业面临及时配送和最优路径规划的基本挑战。基于先前关于使用多种协作代理（如无人机或卡车）在网络上进行单包裹配送的研究，本文在结构和操作约束下考察了该问题的复杂性，重点关注通过协调不同速度和移动范围的代理来最小化总配送时间。

Method: 1. 证明即使在路径图上，DDT问题也无多项式时间近似解（除非P=NP）；2. 引入代理的交集图概念，其中节点表示代理，边表示两个代理移动区域重叠；3. 对于路径图，提出基于交集图树宽度的精确FPT算法；4. 对于一般图，提出基于交集图最大度和树宽度的FPT算法；5. 对于交集图为树的情况，提供简单多项式时间算法。

Result: 1. 解决了Erlebach等人提出的开放性问题，证明DDT即使在路径图上也无多项式时间近似解；2. 对于路径图，当参数化为交集图的树宽度w时，DDT变得可处理；3. 对于一般图，给出了基于最大度Δ和树宽度w的FPT算法；4. 当交集图为树时，提供了简单的多项式时间算法。

Conclusion: 本文深入分析了无人机配送问题的计算复杂性，证明了即使在简单路径图上该问题也极其困难，但通过引入交集图结构概念和参数化复杂性方法，为特定情况提供了有效的算法解决方案，为物流配送优化提供了理论依据。

Abstract: Timely delivery and optimal routing remain fundamental challenges in the modern logistics industry. Building on prior work that considers single-package delivery across networks using multiple types of collaborative agents with restricted movement areas (e.g., drones or trucks), we examine the complexity of the problem under structural and operational constraints. Our focus is on minimizing total delivery time by coordinating agents that differ in speed and movement range across a graph. This problem formulation aligns with the recently proposed Drone Delivery Problem with respect to delivery time (DDT), introduced by Erlebach et al. [ISAAC 2022].
  We first resolve an open question posed by Erlebach et al. [ISAAC 2022] by showing that even when the delivery network is a path graph, DDT admits no polynomial-time approximation within any polynomially encodable factor $a(n)$, unless P=NP. Additionally, we identify the intersection graph of the agents, where nodes represent agents and edges indicate an overlap of the movement areas of two agents, as an important structural concept. For path graphs, we show that DDT becomes tractable when parameterized by the treewidth $w$ of the intersection graph, and we present an exact FPT algorithm with running time $f(w)\cdot\text{poly}(n,k)$, for some computable function $f$. For general graphs, we give an FPT algorithm with running time $f(Δ,w)\cdot\text{poly}(n,k)$, where $Δ$ is the maximum degree of the intersection graph. In the special case where the intersection graph is a tree, we provide a simple polynomial-time algorithm.

</details>


### [12] [Polynomial-Time Solutions for Longest Common Subsequence Related Problems Between a Sequence and a Pangenome Graph](https://arxiv.org/abs/2602.05193)
*Xingfu Li,Yongping Wang*

Main category: cs.DS

TL;DR: 该研究将序列到泛基因组图的LCS问题及其变体转化为DAG中的最长路径问题，证明了这些问题的多项式时间可解性。


<details>
  <summary>Details</summary>
Motivation: 泛基因组比单一线性基因组能更好地捕捉遗传多样性，但需要有效的序列到泛基因组图相似性评估方法。LCS问题及其变体是评估这种相似性的基本任务。

Method: 提出了四种多项式时间归约，将序列到泛基因组图的LCS问题及其三个变体转化为有向无环图（DAG）中的最长路径问题。

Result: 所有四个问题都可以在多项式时间内解决，证明了它们属于复杂度类P。

Conclusion: 该研究为序列到泛基因组图的相似性评估提供了高效算法，对泛基因组构建和分析具有重要意义。

Abstract: A pangenome captures the genetic diversity across multiple individuals simultaneously, providing a more comprehensive reference for genome analysis than a single linear genome, which may introduce allele bias. A widely adopted pangenome representation is a node-labeled directed graph, wherein the paths correspond to plausible genomic sequences within a species. Consequently, evaluating sequence-to-pangenome graph similarity constitutes a fundamental task in pangenome construction and analysis. This study explores the Longest Common Subsequence (LCS) problem and three of its variants involving a sequence and a pangenome graph. We present four polynomial-time reductions that transform these LCS-related problems into the longest path problem in a directed acyclic graph (DAG). These reductions demonstrate that all four problems can be solved in polynomial time, establishing their membership in the complexity class P.

</details>


### [13] [Tight FPT Approximations for Fair $k$-center with Outliers](https://arxiv.org/abs/2602.05476)
*Ameet Gadekar*

Main category: cs.DS

TL;DR: 提出了第一个确定性的3-近似算法，用于解决带离群点的公平k-center问题，算法在参数k下具有固定参数可处理时间，并证明3-近似是最优的。


<details>
  <summary>Details</summary>
Motivation: k-center问题是一个基础聚类目标，最近研究开始纳入公平性和鲁棒性等现代约束。本文研究带离群点的公平k-center问题，中心点需要满足基于群体的代表性约束，同时允许丢弃最多z个点。之前只有双标准FPT近似算法，缺乏真正的近似算法。

Method: 采用新颖的迭代球寻找框架，基于结构三分法直接构建公平解，而不是基于投影的方法。算法在参数k下具有固定参数可处理时间，并扩展到公平k-supplier问题和更一般的公平范围设置。

Result: 提出了第一个确定性的3-近似算法，运行时间为固定参数可处理时间（参数为k）。算法扩展到公平k-supplier和公平范围设置。证明将近似因子改进到3以下是W[2]-难的，确立了结果的最优性。

Conclusion: 本文首次为带离群点的公平k-center问题提供了真正的近似算法，达到了最优的3-近似因子，并在固定参数可处理时间内运行。结果扩展到相关变体，并建立了理论最优性界限。

Abstract: The $k$-center problem is a fundamental clustering objective that has been extensively studied in approximation algorithms. Recent work has sought to incorporate modern constraints such as fairness and robustness, motivated by biased and noisy data. In this paper, we study fair $k$-center with outliers, where centers must respect group-based representation constraints while up to $z$ points may be discarded.
  While a bi-criteria FPT approximation was previously known, no true approximation algorithm was available for this problem. We present the first deterministic $3$-approximation algorithm running in fixed-parameter tractable time parameterized by $k$. Our approach departs from projection-based methods and instead directly constructs a fair solution using a novel iterative ball-finding framework, based on a structural trichotomy that enables fixed-parameter approximation for the problem.
  We further extend our algorithm to fair $k$-supplier with outliers and to the more general fair-range setting with both lower and upper bounds. Finally, we show that improving the approximation factor below $3$ is $\mathrm{W[2]}$-hard, establishing the optimality of our results.

</details>


### [14] [A Structural Equivalence of Symmetric TSP to a Constrained Group Steiner Tree Problem](https://arxiv.org/abs/2602.05773)
*Yılmaz Arslanoğlu*

Main category: cs.DS

TL;DR: 该论文展示了对称旅行商问题（TSP）与在单纯形关联图上定义的约束组斯坦纳树问题（cGSTP）之间的结构等价性。


<details>
  <summary>Details</summary>
Motivation: 探索TSP与其他组合优化问题之间的结构联系，可能为TSP提供新的求解视角和算法思路。

Method: 将完全加权城市图转换为三角形和边的二分关联图，通过选择可接受的圆盘状三角形集合来诱导唯一的边界循环，在全局连通性和局部正则性约束下建立等价关系。

Result: 证明了在cGSTP中最大化净权重与最小化TSP旅行路径长度完全等价。

Conclusion: 建立了对称TSP与约束组斯坦纳树问题之间的精确结构等价，为TSP研究提供了新的数学框架。

Abstract: We present a brief structural equivalence between the symmetric TSP and a constrained Group Steiner Tree Problem (cGSTP) defined on a simplicial incidence graph. Given the complete weighted graph on the city set V, we form the bipartite incidence graph between triangles and edges. Selecting an admissible, disk-like set of triangles induces a unique boundary cycle. With global connectivity and local regularity constraints, maximizing net weight in the cGSTP is exactly equivalent to minimizing the TSP tour length.

</details>


### [15] [Improved SDP-Based Algorithm for Coloring 3-Colorable Graphs](https://arxiv.org/abs/2602.05904)
*Nikhil Bansal,Neng Huang,Euiwoong Lee*

Main category: cs.DS

TL;DR: 提出了一个多项式时间算法，为任意3可着色n顶点图使用O(n^0.19539)种颜色着色，改进了之前的最佳边界。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在改进3可着色图的近似着色算法，这是近二十年来SDP（半正定规划）方法在该问题上的首次进展。

Method: 扩展了先前SDP算法的分析到第三级邻域，并提出了新的向量5/2着色方法，可以从第三级邻域中提取大的独立集。

Result: 算法将3可着色图的着色颜色数从之前的O(n^0.19747)改进到O(n^0.19539)，实现了显著的渐进改进。

Conclusion: 该工作代表了近二十年来3可着色图SDP方法的首次进展，新的向量着色构造可能具有独立的研究价值。

Abstract: We present a polynomial-time algorithm that colors any 3-colorable $n$-vertex graph using $O(n^{0.19539})$ colors, improving upon the previous best bound of $\widetilde{O}(n^{0.19747})$ by Kawarabayashi, Thorup, and Yoneda [STOC 2024]. Our result constitutes the first progress in nearly two decades on SDP-based approaches to this problem.
  The earlier SDP-based algorithms of Arora, Chlamtáč, and Charikar [STOC 2006] and Chlamtáč [FOCS 2007] rely on extracting a large independent set from a suitably "random-looking" second-level neighborhood, under the assumption that the KMS algorithm [Karger, Motwani, and Sudan, JACM 1998] fails to find one globally. We extend their analysis to third-level neighborhoods. We then come up with a new vector $5/2$-coloring, which allows us to extract a large independent set from some third-level neighborhood. The new vector coloring construction may be of independent interest.

</details>


### [16] [Adaptive Hashing: Faster Hash Functions with Fewer Collisions](https://arxiv.org/abs/2602.05925)
*Gábor Melis*

Main category: cs.DS

TL;DR: 提出自适应哈希函数方法，根据当前键集动态调整哈希函数，以提升哈希表性能


<details>
  <summary>Details</summary>
Motivation: 传统哈希表在整个生命周期中使用固定哈希函数存在局限性：通用哈希函数（如Murmur）对键分布不敏感，导致分桶能力有限且浪费计算；针对特定分布定制的哈希函数在假设不成立时风险高；完美哈希算法成本高且需要预先知道固定键集。需要一种在线自适应的方法来平衡性能与鲁棒性。

Method: 提出在线自适应哈希函数方法，在运行时根据当前键集动态调整哈希函数，以最小开销实现，且不改变哈希表API。该方法结合了弱哈希函数的常见情况性能和通用哈希函数的鲁棒性。

Result: 实验表明自适应方法能够结合弱哈希函数的常见情况性能和通用哈希函数的鲁棒性，实现更好的键分桶和更快的哈希函数计算。

Conclusion: 哈希表哈希函数的在线自适应是提升性能的必要条件，自适应方法能够在运行时根据键集优化哈希函数，实现更好的分桶性能和计算效率。

Abstract: Hash tables are ubiquitous, and the choice of hash function, which maps a key to a bucket, is key to their performance. We argue that the predominant approach of fixing the hash function for the lifetime of the hash table is suboptimal and propose adapting it to the current set of keys. In the prevailing view, good hash functions spread the keys ``randomly'' and are fast to evaluate. General-purpose ones (e.g. Murmur) are designed to do both while remaining agnostic to the distribution of the keys, which limits their bucketing ability and wastes computation. When these shortcomings are recognized, one may specify a hash function more tailored to some assumed key distribution, but doing so almost always introduces an unbounded risk in case this assumption does not bear out in practice. At the other, fully key-aware end of the spectrum, Perfect Hashing algorithms can discover hash functions to bucket a given set of keys optimally, but they are costly to run and require the keys to be known and fixed ahead of time. Our main conceptual contribution is that adapting the hash table's hash function to the keys online is necessary for the best performance, as adaptivity allows for better bucketing of keys \emph{and} faster hash functions. We instantiate the idea of online adaptation with minimal overhead and no change to the hash table API. The experiments show that the adaptive approach marries the common-case performance of weak hash functions with the robustness of general-purpose ones.

</details>


### [17] [Competitive Analysis of Online Facility Assignment Algorithms on Discrete Grid Graphs: Performance Bounds and Remediation Strategies](https://arxiv.org/abs/2602.05953)
*Lamya Alif,Raian Tasnim Saoda,Sumaiya Afrin,Md. Rawha Siddiqi Riad,Md. Tanzeem Rahat,Md Manzurul Hasan*

Main category: cs.DS

TL;DR: 研究网格图上的在线设施分配问题，分析两种基线算法的失败模式，并提出半在线批处理框架作为改进方案


<details>
  <summary>Details</summary>
Motivation: 研究离散网格几何与容量限制如何影响在线设施分配算法的性能，揭示特定于L1度量和硬容量限制的几何失效模式

Method: 1) 构造对抗性序列展示CS-Voronoi算法的区域崩溃效应和Greedy算法的振荡问题；2) 提出半在线扩展，允许延迟分配并通过最小成本流计算批量最优解

Result: 证明了纯局部规则在网格实例上可能产生较大的竞争比，形式化了离散L1度量下的几何失效模式，提出了批处理框架作为补救策略

Conclusion: 离散网格几何与容量限制的交互会导致特定失效模式，半在线批处理框架是潜在的改进方向，但需要进一步研究其竞争性保证

Abstract: We study the \emph{Online Facility Assignment} (OFA) problem on a discrete $r\times c$ grid graph under the standard model of Ahmed, Rahman, and Kobourov: a fixed set of facilities is given, each with limited capacity, and an online sequence of unit-demand requests must be irrevocably assigned upon arrival to an available facility, incurring Manhattan ($L_1$) distance cost. We investigate how the discrete geometry of grids interacts with capacity depletion by analyzing two natural baselines and one capacity-aware heuristic. First, we give explicit adversarial sequences on grid instances showing that purely local rules can be forced into large competitive ratios: (i) a capacity-sensitive weighted-Voronoi heuristic (\textsc{CS-Voronoi}) can suffer cascading \emph{region-collapse} effects when nearby capacity is exhausted; and (ii) nearest-available \textsc{Greedy} (with randomized tie-breaking) can be driven into repeated long reassignments via an \emph{oscillation} construction. These results formalize geometric failure modes that are specific to discrete $L_1$ metrics with hard capacities. Motivated by these lower bounds, we then discuss a semi-online extension in which the algorithm may delay assignment for up to $τ$ time steps and solve each batch optimally via a min-cost flow computation. We present this batching framework as a remediation strategy and delineate the parameters that govern its performance, while leaving sharp competitive guarantees for this semi-online variant as an open direction.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [18] [XEmoGPT: An Explainable Multimodal Emotion Recognition Framework with Cue-Level Perception and Reasoning](https://arxiv.org/abs/2602.05496)
*Hanwen Zhang,Yao Liu,Peiyuan Jiang,Lang Junjie,Xie Jun,Yihui He,Yajiao Deng,Siyu Du,Qiao Liu*

Main category: cs.MM

TL;DR: 提出XEmoGPT框架，通过专门模块增强情感线索感知，构建大规模数据集支持线索级推理，并引入新评估指标


<details>
  <summary>Details</summary>
Motivation: 当前多模态情感识别方法存在两个主要挑战：1)通用模态编码器缺乏对细粒度情感线索的敏感性；2)现有数据集在标注质量和规模之间存在权衡，导致情感线索监督不足。此外，现有评估指标无法有效评估线索级推理性能。

Method: 提出XEmoGPT框架，包含视频情感线索桥(VECB)和音频情感线索桥(AECB)两个专门模块，通过精心设计的任务增强视频和音频编码器的细粒度情感线索感知能力。构建大规模数据集EmoCue支持线索级推理，并引入EmoCue-360自动评估指标和EmoCue-Eval基准。

Result: 实验结果表明，XEmoGPT在情感线索感知和推理方面都取得了强劲的性能表现。

Conclusion: XEmoGPT通过专门的情感线索感知模块、大规模数据集和新的评估指标，有效解决了多模态情感识别中的线索级感知和推理挑战。

Abstract: Explainable Multimodal Emotion Recognition plays a crucial role in applications such as human-computer interaction and social media analytics. However, current approaches struggle with cue-level perception and reasoning due to two main challenges: 1) general-purpose modality encoders are pretrained to capture global structures and general semantics rather than fine-grained emotional cues, resulting in limited sensitivity to emotional signals; and 2) available datasets usually involve a trade-off between annotation quality and scale, which leads to insufficient supervision for emotional cues and ultimately limits cue-level reasoning. Moreover, existing evaluation metrics are inadequate for assessing cue-level reasoning performance. To address these challenges, we propose eXplainable Emotion GPT (XEmoGPT), a novel EMER framework capable of both perceiving and reasoning over emotional cues. It incorporates two specialized modules: the Video Emotional Cue Bridge (VECB) and the Audio Emotional Cue Bridge (AECB), which enhance the video and audio encoders through carefully designed tasks for fine-grained emotional cue perception. To further support cue-level reasoning, we construct a large-scale dataset, EmoCue, designed to teach XEmoGPT how to reason over multimodal emotional cues. In addition, we introduce EmoCue-360, an automated metric that extracts and matches emotional cues using semantic similarity, and release EmoCue-Eval, a benchmark of 400 expert-annotated samples covering diverse emotional scenarios. Experimental results show that XEmoGPT achieves strong performance in both emotional cue perception and reasoning.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [19] [A Data Driven Structural Decomposition of Dynamic Games via Best Response Maps](https://arxiv.org/abs/2602.05324)
*Mahdis Rabbani,Navid Mojahed,Shima Nazari*

Main category: cs.GT

TL;DR: 提出一种新的动态博弈求解方法，通过数据驱动的结构简化，用离线编译的最佳响应映射替代嵌套优化，降低计算复杂度并保持均衡一致性。


<details>
  <summary>Details</summary>
Motivation: 动态博弈是建模多智能体决策的有力工具，但计算纳什均衡（广义纳什均衡）仍然面临挑战：紧耦合的最优性条件、嵌套优化结构、数值条件差。现有方法要么直接求解联合博弈（需要显式建模所有智能体的目标函数和约束），要么通过预测或策略近似解耦交互（牺牲均衡一致性）。

Method: 提出概念新颖的动态博弈公式化方法：通过数据驱动的结构简化重构均衡计算。不是求解完全耦合的博弈，也不是通过预测或策略近似解耦智能体，而是提出将离线编译的最佳响应映射作为可行性约束嵌入，从而移除嵌套优化层和导数耦合。

Result: 在标准正则条件下，当最佳响应算子精确时，简化问题的任何收敛解对应于原始博弈的局部开环纳什（广义纳什）均衡；使用学习代理时，解在最佳响应近似误差范围内近似均衡一致。通过数学证明支持，并在自动驾驶赛车问题的双玩家开环动态博弈中进行大规模蒙特卡洛研究。

Conclusion: 该方法在解质量、计算成本和约束满足方面与最先进的联合博弈求解器进行了比较，展示了其有效性。通过结构简化动态博弈，提供了一种既保持均衡一致性又降低计算复杂度的新途径。

Abstract: Dynamic games are powerful tools to model multi-agent decision-making, yet computing Nash (generalized Nash) equilibria remains a central challenge in such settings. Complexity arises from tightly coupled optimality conditions, nested optimization structures, and poor numerical conditioning. Existing game-theoretic solvers address these challenges by directly solving the joint game, typically requiring explicit modeling of all agents' objective functions and constraints, while learning-based approaches often decouple interaction through prediction or policy approximation, sacrificing equilibrium consistency. This paper introduces a conceptually novel formulation for dynamic games by restructuring the equilibrium computation. Rather than solving a fully coupled game or decoupling agents through prediction or policy approximation, a data-driven structural reduction of the game is proposed that removes nested optimization layers and derivative coupling by embedding an offline-compiled best-response map as a feasibility constraint. Under standard regularity conditions, when the best-response operator is exact, any converged solution of the reduced problem corresponds to a local open-loop Nash (GNE) equilibrium of the original game; with a learned surrogate, the solution is approximately equilibrium-consistent up to the best-response approximation error. The proposed formulation is supported by mathematical proofs, accompanying a large-scale Monte Carlo study in a two-player open-loop dynamic game motivated by the autonomous racing problem. Comparisons are made against state-of-the-art joint game solvers, and results are reported on solution quality, computational cost, and constraint satisfaction.

</details>


### [20] [A Stronger Benchmark for Online Bilateral Trade: From Fixed Prices to Distributions](https://arxiv.org/abs/2602.05681)
*Anna Lunghi,Mattia Piccinato,Matteo Castiglioni,Alberto Marchesi*

Main category: cs.GT

TL;DR: 本文研究在线双边交易，学习者在重复交易中最大化交易收益(GFT)，同时保证不补贴市场。现有算法基于每轮弱预算平衡(WBB)，但全局预算平衡(GBB)约束可将GFT提升两倍。作者首次提出在随机环境下实现针对GBB基准的次线性遗憾算法。


<details>
  <summary>Details</summary>
Motivation: 现有在线双边交易算法主要关注每轮弱预算平衡(WBB)约束，但Bernasconi等人[2024]发现全局预算平衡(GBB)约束能显著提升交易收益。然而，所有现有WBB算法在GBB基准下都有线性遗憾，因此需要开发能在GBB约束下实现次线性遗憾的新算法。

Method: 提出首个在随机环境下针对GBB基准的次线性遗憾算法。在估值联合分布具有有界密度的条件下，算法使用单比特反馈，实现$\widetilde{\mathcal{O}}(T^{3/4})$的遗憾界。算法表明学习最优WBB价格的一维问题与学习最优GBB价格对分布的二维问题之间没有分离。

Result: 当估值联合分布具有有界密度时，提出的算法在单比特反馈下实现$\widetilde{\mathcal{O}}(T^{3/4})$的遗憾界。这是首个在随机环境下针对GBB基准实现次线性遗憾的算法，填补了现有研究的空白。

Conclusion: 全局预算平衡(GBB)约束相比弱预算平衡(WBB)能显著提升在线双边交易的性能。提出的算法首次在随机环境下实现针对GBB基准的次线性遗憾，证明学习最优WBB价格与学习最优GBB价格对分布之间没有根本性难度差异。

Abstract: We study online bilateral trade, where a learner facilitates repeated exchanges between a buyer and a seller to maximize the Gain From Trade (GFT), i.e., the social welfare. In doing so, the learner must guarantee not to subsidize the market. This constraint is usually imposed per round through Weak Budget Balance (WBB). Despite that, Bernasconi et al. [2024] show that a Global Budget Balance (GBB) constraint on the profit -- enforced over the entire time horizon -- can improve the GFT by a multiplicative factor of two. While this might appear to be a marginal relaxation, this implies that all existing WBB-focused algorithms suffer linear regret when measured against the GBB optimum. In this work, we provide the first algorithm to achieve sublinear regret against the GBB benchmark in stochastic environments under one-bit feedback. In particular, we show that when the joint distribution of valuations has a bounded density, our algorithm achieves $\widetilde{\mathcal{O}}(T^{3/4})$ regret. Our result shows that there is no separation between the one-dimensional problem of learning the optimal WBB price and the two-dimensional problem of learning the optimal GBB distribution over pairs of prices.

</details>


### [21] [Bandit Social Learning with Exploration Episodes](https://arxiv.org/abs/2602.05835)
*Kiarash Banihashem,Natalie Collina,Aleksandrs Slivkins*

Main category: cs.GT

TL;DR: 研究社会学习动态中自利代理人的集体探索失败问题，即使个体在各自决策序列中有探索动机，但整体探索仍然不足。


<details>
  <summary>Details</summary>
Motivation: 研究在重复交互场景（如用户与AI互动、市场购物）中，自利代理人遵循多臂老虎机协议时的集体探索行为。虽然个体有探索动机，但需要了解整体探索是否有效。

Method: 采用风格化的社会学习动态模型，每个代理人控制一个"片段"（连续决策序列），分析自利代理人在多臂老虎机协议下的集体行为。

Result: 发现集体探索失败：贝叶斯遗憾随时间线性增长。这种失败是典型情况而非最坏情况，即使代理人效用函数是每轮结果的固定函数（如最小值、最大值或总和）也成立。

Conclusion: 即使存在一定程度的有机探索，仍需要外部驱动的探索机制来确保有效的集体学习。

Abstract: We study a stylized social learning dynamics where self-interested agents collectively follow a simple multi-armed bandit protocol. Each agent controls an ``episode": a short sequence of consecutive decisions. Motivating applications include users repeatedly interacting with an AI, or repeatedly shopping at a marketplace. While agents are incentivized to explore within their respective episodes, we show that the aggregate exploration fails: e.g., its Bayesian regret grows linearly over time. In fact, such failure is a (very) typical case, not just a worst-case scenario. This conclusion persists even if an agent's per-episode utility is some fixed function of the per-round outcomes: e.g., $\min$ or $\max$, not just the sum. Thus, externally driven exploration is needed even when some amount of exploration happens organically.

</details>


### [22] [Metric Hedonic Games on the Line](https://arxiv.org/abs/2602.05888)
*Merlin de la Haye,Pascal Lenzner,Farehe Soheil,Marcus Wunderlich*

Main category: cs.GT

TL;DR: 提出基于类型值的简洁享乐博弈模型，研究线型度量空间中基于距离阈值、最大/平均差异的联盟稳定性、价格等性质


<details>
  <summary>Details</summary>
Motivation: 传统享乐博弈需要定义指数级效用函数，计算复杂。本文提出简洁表示的新变体，基于代理类型值差异建模自然场景（如运动员按水平分组、选民按政治光谱分区）

Method: 定义基于类型值的享乐博弈模型，代理成本基于与联盟内其他成员的类型值差异。研究三种成本函数：距离阈值、最大差异、平均差异。分析交换稳定性和跳跃稳定性，考虑联盟数量限制

Result: 稳定联盟结构始终存在，但其性质和效率差异很大。在线型度量空间中发现了丰富的模型景观，部分结果具有反直觉行为。价格和稳定性受联盟数量和大小限制的影响

Conclusion: 尽管设定简单（线型度量空间），但揭示了丰富的模型行为。稳定联盟总是存在，但质量和特性变化显著。同时研究交换和跳跃稳定性有助于理解联盟数量和大小固定的影响

Abstract: Hedonic games are fundamental models for investigating the formation of coalitions among a set of strategic agents, where every agent has a certain utility for every possible coalition of agents it can be part of. To avoid the intractability of defining exponentially many utilities for all possible coalitions, many variants with succinct representations of the agents' utility functions have been devised and analyzed, e.g., modified fractional hedonic games by Monaco et al. [JAAMAS 2020]. We extend this by studying a novel succinct variant that is related to modified fractional hedonic games. In our model, each agent has a fixed type-value and an agent's cost for some given coalition is based on the differences between its value and those of the other members of its coalition. This allows to model natural situations like athletes forming training groups with similar performance levels or voters that partition themselves along a political spectrum.
  In particular, we investigate natural variants where an agent's cost is defined by distance thresholds, or by the maximum or average value difference to the other agents in its coalition. For these settings, we study the existence of stable coalition structures, their properties, and their quality in terms of the price of anarchy and the price of stability. Further, we investigate the impact of limiting the maximum number of coalitions. Despite the simple setting with metric distances on a line, we uncover a rich landscape of models, partially with counter-intuitive behavior. Also, our focus on both swap stability and jump stability allows us to study the influence of fixing the number and the size of the coalitions. Overall, we find that stable coalition structures always exist but that their properties and quality can vary widely.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [23] [Correcting Contextual Deletions in DNA Nanopore Readouts](https://arxiv.org/abs/2602.05072)
*Yuan-Pon Chen,Olgica Milenkovic,João Ribeiro,Jin Sima*

Main category: cs.IT

TL;DR: 研究DNA存储中纳米孔测序的上下文相关删除错误，分析两种运行长度阈值k的编码方案：k=Clogn时构造高效纠删码，k为常数时研究极端上下文删除信道的容量极限。


<details>
  <summary>Details</summary>
Motivation: DNA数据存储系统中纳米孔测序器会产生上下文相关的删除错误，而非传统假设的独立随机错误。现有模型假设删除独立且与序列上下文无关，这与实际不符，需要研究上下文相关的纳米孔删除错误模型。

Method: 研究确定性单删除跟随长度至少为k的完整运行长度后的错误模型。分析两种k值情况：1) k=Clogn时，研究能纠正t个上下文删除的纠删码，给出冗余度上下界并构造高效编解码方案；2) k为常数时，研究极端上下文删除信道（每个长度≥k的运行后都发生删除），推导最大可达速率。

Result: 对于k=Clogn：冗余度上下界为(1-C)tlogn到2(1-C)tlogn之间，是任意t-删除纠正码的(1-C)分数。构造了t=1且C>1/2时的高效编码，冗余度接近理论上界。对于k为常数：获得了极端上下文删除信道下任意常数k的最大可达速率的精确界限。

Conclusion: 上下文相关的删除错误模型更符合纳米孔测序实际，相比传统独立删除模型能显著降低冗余度要求。研究为DNA存储系统提供了更高效的编码方案设计理论基础，区分了两种不同k值情况下的编码性能极限。

Abstract: The problem of designing codes for deletion-correction and synchronization has received renewed interest due to applications in DNA-based data storage systems that use nanopore sequencers as readout platforms. In almost all instances, deletions are assumed to be imposed independently of each other and of the sequence context. These assumptions are not valid in practice, since nanopore errors tend to occur within specific contexts. We study contextual nanopore deletion-errors through the example setting of deterministic single deletions following (complete) runlengths of length at least $k$. The model critically depends on the runlength threshold $k$, and we examine two regimes for $k$: a) $k=C\log n$ for a constant $C\in(0,1)$; in this case, we study error-correcting codes that can protect from a constant number $t$ of contextual deletions, and show that the minimum redundancy (ignoring lower-order terms) is between $(1-C)t\log n$ and $2(1-C)t\log n$, meaning that it is a ($1-C$)-fraction of that of arbitrary $t$-deletion-correcting codes. To complement our non-constructive redundancy upper bound, we design efficiently and encodable and decodable codes for any constant $t$. In particular, for $t=1$ and $C>1/2$ we construct efficient codes with redundancy that essentially matches our non-constructive upper bound; b) $k$ equal a constant; in this case we consider the extremal problem where the number of deletions is not bounded and a deletion is imposed after every run of length at least $k$, which we call the extremal contextual deletion channel. This combinatorial setting arises naturally by considering a probabilistic channel that introduces contextual deletions after each run of length at least $k$ with probability $p$ and taking the limit $p\to 1$. We obtain sharp bounds on the maximum achievable rate under the extremal contextual deletion channel for arbitrary constant $k$.

</details>


### [24] [On QC and GQC algebraic geometry codes](https://arxiv.org/abs/2602.05097)
*Matteo Bonini,Arianna Dionigi,Francesco Ghiandoni*

Main category: cs.IT

TL;DR: 提出从代数曲线构造准循环码和广义准循环码的新方法，适用于Kummer扩张曲线，包括超椭圆曲线、范迹曲线和Hermitian曲线


<details>
  <summary>Details</summary>
Motivation: 传统基于椭圆曲线的准循环码构造方法受限，需要更灵活、参数更丰富的构造方法，特别是能够适应不同协指数的准循环码

Method: 利用代数曲线构造准循环码和广义准循环码，特别是Kummer扩张的有理函数域曲线，包括超椭圆曲线、范迹曲线和Hermitian曲线

Result: 获得了具有灵活协指数的准循环码，并利用已知的自同构群分类推导出明确的参数公式

Conclusion: 该方法扩展了准循环码的构造范围，提供了更灵活的参数选择，为编码理论提供了新的构造工具

Abstract: We present new constructions of quasi-cyclic (QC) and generalized quasi-cyclic (GQC) codes from algebraic curves. Unlike previous approaches based on elliptic curves, our method applies to curves that are Kummer extensions of the rational function field, including hyperelliptic, norm-trace, and Hermitian curves. This allows QC codes with flexible co-index. Explicit parameter formulas are derived using known automorphism-group classifications.

</details>


### [25] [Enabling Large-Scale Channel Sounding for 6G: A Framework for Sparse Sampling and Multipath Component Extraction](https://arxiv.org/abs/2602.05405)
*Yi Chen,Li Ming,Chong Han*

Main category: cs.IT

TL;DR: 提出一种新型信道测量框架，通过稀疏非均匀采样和LR-SAGE算法，在6G系统中实现50倍测量加速和99.96%计算复杂度降低


<details>
  <summary>Details</summary>
Motivation: 实现6G的AI和ISAC愿景需要大规模真实信道数据集，但传统频域信道测量方法因避免延迟模糊需要大量频点而效率低下

Method: 提出抛物线频率采样(PFS)策略进行非均匀频点分布，结合似然校正空间交替广义期望最大化(LR-SAGE)算法提取多径分量

Result: 在280-300GHz验证中，实现50倍测量加速、98%数据量减少和99.96%后处理计算复杂度降低，同时保持与传统测量一致的多径分量捕获

Conclusion: 该框架为构建AI原生6G系统所需的大规模ISAC数据集提供了基础使能技术，能够充分利用AI扩展定律的潜力

Abstract: Realizing the 6G vision of artificial intelligence (AI) and integrated sensing and communication (ISAC) critically requires large-scale real-world channel datasets for channel modeling and data-driven AI models. However, traditional frequency-domain channel sounding methods suffer from low efficiency due to a prohibitive number of frequency points to avoid delay ambiguity. This paper proposes a novel channel sounding framework involving sparse nonuniform sampling along with a likelihood-rectified space-alternating generalized expectation-maximization (LR-SAGE) algorithm for multipath component extraction. This framework enables the acquisition of channel datasets that are tens or even hundreds of times larger within the same channel measurement duration, thereby providing the massive data required to harness the full potential of AI scaling laws. Specifically, we propose a Parabolic Frequency Sampling (PFS) strategy that non-uniformly distributes frequency points, effectively eliminating delay ambiguity while reducing sampling overhead by orders of magnitude. To efficiently extract multipath components (MPCs) from the channel data measured by PFS, we develop a LR-SAGE algorithm, rectifying the likelihood distortion caused by nonuniform sampling and molecular absorption effect. Simulation results and experimental validation at 280--300~GHz confirm that the proposed PFS and LR-SAGE algorithm not only achieve 50$\times$ faster measurement, a 98\% reduction in data volume and a 99.96\% reduction in post-processing computational complexity, but also successfully captures MPCs and channel characteristics consistent with traditional exhaustive measurements, demonstrating its potential as a fundamental enabler for constructing the massive ISAC datasets required by AI-native 6G systems.

</details>


### [26] [Explicit List-Decodable Linearized Reed-Solomon Subspace Codes via Subspace Designs](https://arxiv.org/abs/2602.05462)
*Kuo Shang,Chen Yuan,Ruiqi Zhu*

Main category: cs.IT

TL;DR: 本文构造了在任意域上的𝔽_h-线性sum-rank度量码，实现了高效列表译码，译码半径达到ρ，码率1-ρ-ε，列表大小受h^poly(1/ε)限制。同时扩展到折叠线性化Reed-Solomon码，首次实现了超越唯一译码半径的高效列表译码。


<details>
  <summary>Details</summary>
Motivation: sum-rank度量在多种编码应用中很重要，但缺乏超越唯一译码半径的高效列表译码构造。现有线性化Reed-Solomon码虽然推广了Reed-Solomon和Gabidulin码，但需要新的方法来突破唯一译码限制。

Method: 构造𝔽_h-线性sum-rank度量码作为LRS码的子码，通过子空间设计限制消息多项式到特定𝔽_h-子空间。建立线性代数译码框架，证明折叠求值满足插值条件，解空间形成低维结构仿射子空间。

Result: 实现了码率1-ρ-ε、译码半径ρ的高效列表译码，列表大小h^poly(1/ε)。首次构造出超越唯一译码半径的正码率FLRS子码，为sum-rank度量码提供了新的高效译码框架。

Conclusion: 本文提出了首个超越唯一译码半径的正码率sum-rank度量码的显式构造，建立了高效的线性代数列表译码框架，为sum-rank度量码的设计和应用开辟了新途径。

Abstract: The sum-rank metric is the mixture of the Hamming and rank metrics. The sum-rank metric found its application in network coding, locally repairable codes, space-time coding, and quantum-resistant cryptography. Linearized Reed-Solomon (LRS) codes are the sum-rank analogue of Reed-Solomon codes and strictly generalize both Reed-Solomon and Gabidulin codes.
  In this work, we construct an explicit family of $\mathbb{F}_h$-linear sum-rank metric codes over arbitrary fields $\mathbb{F}_h$. Our construction enables efficient list decoding up to a fraction $ρ$ of errors in the sum-rank metric with rate $1-ρ-\varepsilon$, for any desired $ρ\in (0,1)$ and $\varepsilon>0$. Our codes are subcodes of LRS codes, obtained by restricting message polynomials to an $\mathbb{F}_h$-subspace derived from subspace designs, and the decoding list size is bounded by $h^{\mathrm{poly}(1/\varepsilon)}$.
  Beyond the standard LRS setting, we further extend our linear-algebraic decoding framework to folded Linearized Reed-Solomon (FLRS) codes. We show that folded evaluations satisfy appropriate interpolation conditions and that the corresponding solution space forms a low-dimensional, structured affine subspace. This structure enables effective control of the list size and yields the first explicit positive-rate FLRS subcodes that are efficiently list decodable beyond the unique-decoding radius. To the best of our knowledge, this also constitutes the first explicit construction of positive-rate sum-rank metric codes that admit efficient list decoding beyond the unique decoding radius, thereby providing a new general framework for constructing efficiently decodable codes under the sum-rank metric.

</details>


### [27] [Low-complexity Design for Beam Coverage in Near-field and Far-field: A Fourier Transform Approach](https://arxiv.org/abs/2602.05666)
*Chao Zhou,Changsheng You,Cong Zhou,Li Chen,Yi Gong,Chengwen Xing*

Main category: cs.IT

TL;DR: 提出基于傅里叶变换的低复杂度波束覆盖设计方法，适用于远场和近场多天线系统，在保证性能的同时大幅降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有基于采样的波束覆盖优化方法计算复杂度高，需要设计一种低复杂度且高效的波束覆盖设计方法。

Method: 将波束覆盖设计转化为空间频率滤波问题，通过逆傅里叶变换实现角度覆盖。针对有限天线数引入的滚降效应，提出具有保护放大的滚降感知设计。对于近场情况，通过对近场信道导向矢量进行一阶泰勒近似，将二维波束覆盖设计转化为二维逆傅里叶变换。

Result: 所提出的FT-based方法在实现与常规采样优化方法相当的波束成形性能的同时，显著降低了计算复杂度。同时观察到近场范围散焦效应，表明足够宽的角度覆盖会导致范围不敏感的波束导向。

Conclusion: 提出的基于傅里叶变换的方法为多天线系统的波束覆盖设计提供了一种高效低复杂度的解决方案，适用于远场和近场场景，在性能和复杂度之间取得了良好平衡。

Abstract: In this paper, we study efficient beam coverage design for multi-antenna systems in both far-field and near-field cases. To reduce the computational complexity of existing sampling-based optimization methods, we propose a new low-complexity yet efficient beam coverage design. To this end, we first formulate a general beam coverage optimization problem to maximize the worst-case beamforming gain over a target region. For the far-field case, we show that the beam coverage design can be viewed as a spatial-frequency filtering problem, where angular coverage can be achieved by weight-shaping in the antenna domain via an inverse FT, yielding an infinite-length weighting sequence. Under the constraint of a finite number of antennas, a surrogate scheme is proposed by directly truncating this sequence, which inevitably introduces a roll-off effect at the angular boundaries, yielding degraded worst-case beamforming gain. To address this issue, we characterize the finite-antenna-induced roll-off effect, based on which a roll-off-aware design with a protective zoom is developed to ensure a flat beamforming-gain profile within the target angular region. Next, we extend the proposed method to the near-field case. Specifically, by applying a first-order Taylor approximation to the near-field channel steering vector (CSV), the two-dimensional (2D) beam coverage design (in both angle and inverse-range) can be transformed into a 2D inverse FT, leading to a low-complexity beamforming design. Furthermore, an inherent near-field range defocusing effect is observed, indicating that sufficiently wide angular coverage results in range-insensitive beam steering. Finally, numerical results demonstrate that the proposed FT-based approach achieves a comparable worst-case beamforming performance with that of conventional sampling-based optimization methods while significantly reducing the computational complexity.

</details>


### [28] [Generalized Pinsker Inequality for Bregman Divergences of Negative Tsallis Entropies](https://arxiv.org/abs/2602.05744)
*Guglielmo Beretta,Tommaso Cesari,Roberto Colomboni*

Main category: cs.IT

TL;DR: 本文针对Tsallis损失的概率预测和在线学习应用，建立了负α-Tsallis熵生成的Bregman散度（即β-散度）的广义Pinsker不等式，给出了任意概率单纯形内两点间散度的尖锐下界。


<details>
  <summary>Details</summary>
Motivation: 传统Pinsker不等式将Kullback-Leibler散度下界表示为总变差，为将KL散度控制转换为L1范数控制提供了标准方法。本文动机源于Tsallis损失的概率预测和在线学习应用，需要建立更一般的Bregman散度（特别是负α-Tsallis熵生成的β-散度）的类似不等式。

Method: 针对负α-Tsallis熵生成的Bregman散度Dα（即β-散度），研究其在概率单纯形Δ^K相对内部任意两点p,q之间的下界关系。通过数学分析确定最优常数C_{α,K}，证明对于所有(α,K)选择，不等式Dα(p∥q) ≥ C_{α,K}/2·‖p-q‖₁²成立。

Result: 证明了广义Pinsker不等式：对于概率单纯形Δ^K相对内部任意p,q，有Dα(p∥q) ≥ C_{α,K}/2·‖p-q‖₁²，其中C_{α,K}是最优常数。为每个(α,K)组合明确确定了最优常数，建立了β-散度的尖锐下界。

Conclusion: 本文成功建立了负α-Tsallis熵生成的Bregman散度的广义Pinsker不等式，为Tsallis损失的概率预测和在线学习应用提供了理论工具，将传统Pinsker不等式推广到更一般的散度度量框架。

Abstract: The Pinsker inequality lower bounds the Kullback--Leibler divergence $D_{\textrm{KL}}$ in terms of total variation and provides a canonical way to convert $D_{\textrm{KL}}$ control into $\lVert \cdot \rVert_1$-control. Motivated by applications to probabilistic prediction with Tsallis losses and online learning, we establish a generalized Pinsker inequality for the Bregman divergences $D_α$ generated by the negative $α$-Tsallis entropies -- also known as $β$-divergences. Specifically, for any $p$, $q$ in the relative interior of the probability simplex $Δ^K$, we prove the sharp bound \[
  D_α(p\Vert q) \ge \frac{C_{α,K}}{2}\cdot \|p-q\|_1^2, \] and we determine the optimal constant $C_{α,K}$ explicitly for every choice of $(α,K)$.

</details>


### [29] [MU-MIMO Uplink Timely Throughput Maximization for Extended Reality Applications](https://arxiv.org/abs/2602.05751)
*Ravi Sharan Bhagavathula,Pavan Koteshwar Srinath,Alvaro Valcarce Rial,Baltasar-Beferull Lozano*

Main category: cs.IT

TL;DR: 提出一种基于加权比例公平的迭代启发式算法，通过上行MU-MIMO调度最大化XR应用的跨层及时吞吐量，在保持系统总吞吐量的同时显著提升XR容量。


<details>
  <summary>Details</summary>
Motivation: 研究扩展现实(XR)应用的上行多用户MIMO调度中的跨层及时吞吐量最大化问题，需要满足用户对信息新鲜度（PAoI）的要求。

Method: 采用无信令的加权比例公平迭代启发式算法，权重根据PAoI指标推导，将及时调度机会作为用户满意度约束纳入网络侧优化问题。

Result: 广泛的数值仿真结果表明，所提算法在保持整体系统吞吐量的同时，在XR容量方面始终优于现有基线方法。

Conclusion: 该算法有效解决了NP-hard的跨层及时吞吐量优化问题，为XR应用提供了更好的服务质量保障。

Abstract: In this work, we study the cross-layer timely throughput maximization for extended reality (XR) applications through uplink multi-user MIMO (MU-MIMO) scheduling. Timely scheduling opportunities are characterized by the peak age of information (PAoI)-metric and are incorporated into a network-side optimization problem as constraints modeling user satisfaction. The problem being NP-hard, we resort to a signaling-free, weighted proportional fair-based iterative heuristic algorithm, where the weights are derived with respect to the PAoI metric. Extensive numerical simulation results demonstrate that the proposed algorithm consistently outperforms existing baselines in terms of XR capacity without sacrificing the overall system throughput.

</details>


### [30] [Price of universality in vector quantization is at most 0.11 bit](https://arxiv.org/abs/2602.05790)
*Alina Harbuzova,Or Ordentlich,Yury Polyanskiy*

Main category: cs.IT

TL;DR: 该论文证明了存在一个通用码本，对于所有可能的输入统计特性都近似最优，比针对特定统计特性设计的最优码本仅多消耗0.11比特/维度的额外码率。


<details>
  <summary>Details</summary>
Motivation: 在LLM部署中，低精度近似（仅权重量化）是提高效率的流行方法。信息论表明，最优的量化算法依赖于输入X的统计特性，需要将矢量量化码本与X的PCA方向对齐（水填充分配）。但这种对X统计特性的依赖在实际中不切实际，因此需要寻找不依赖统计特性的通用解决方案。

Method: 通过理论证明的方法，展示了存在一个通用码本，该码本对所有可能的输入统计特性都同时近似最优。等价地，证明了在ℝⁿ中存在一个网络，该网络能够同时以所有希尔伯特范数近似最优地覆盖球面。

Result: 存在一个通用码本，对于所有可能的输入统计特性，其性能至少与针对特定统计特性设计的水填充码本（码率减少0.11比特/维度）一样好。该结果是非构造性的存在性证明。

Conclusion: 虽然存在性证明是非构造性的，但该结果理论上证明了通用低精度存储格式的可能性，这为现代LLM部署中的高效量化方案提供了重要的理论依据，是当前研究的热点话题。

Abstract: Fast computation of a matrix product $W^\top X$ is a workhorse of modern LLMs. To make their deployment more efficient, a popular approach is that of using a low-precision approximation $\widehat W$ in place of true $W$ ("weight-only quantization''). Information theory demonstrates that an optimal algorithm for reducing precision of $W$ depends on the (second order) statistics of $X$ and requires a careful alignment of vector quantization codebook with PCA directions of $X$ (a process known as "waterfilling allocation''). Dependence of the codebook on statistics of $X$, however, is highly impractical. This paper proves that there exist a universal codebook that is simultaneously near-optimal for all possible statistics of $X$, in the sense of being at least as good as an $X$-adapted waterfilling codebook with rate reduced by 0.11 bit per dimension. Such universal codebook would be an ideal candidate for the low-precision storage format, a topic of active modern research, but alas the existence proof is non-constructive.
  Equivalently, our result shows existence of a net in $\mathbb{R}^n$ that is a nearly-optimal covering of a sphere simultaneously with respect to all Hilbert norms.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [31] [Atomic Information Flow: A Network Flow Model for Tool Attributions in RAG Systems](https://arxiv.org/abs/2602.04912)
*James Gao,Josh Zhou,Qi Sun,Ryan Huang,Steven Yoo*

Main category: cs.IR

TL;DR: 提出Atomic Information Flow (AIF)框架，将工具RAG系统的信息流建模为原子单元的网络流，并训练轻量级Gemma3模型作为上下文压缩器，显著提升关键信息识别准确率。


<details>
  <summary>Details</summary>
Motivation: 当前基于工具的检索增强生成(RAG)系统缺乏将最终响应追溯到特定工具组件的精确机制，这在系统扩展到复杂多智能体架构时成为关键缺陷。

Method: 提出原子信息流(AIF)模型，将工具输出和LLM调用分解为不可分割的自包含信息原子单元，建模为从工具/LLM节点到响应超级汇的有向流。基于网络流理论的最大流最小割定理，训练轻量级Gemma3(4B参数)模型作为上下文压缩器，使用AIF计算的离线流信号来近似工具原子的最小割。

Result: 基础Gemma3-4B模型在HotpotQA上识别关键信息准确率仅为54.7%，略优于词法基线(BM25)。经过AIF信号训练后，准确率提升至82.71%(+28.01点)，同时实现87.52%(+1.85%)的上下文token压缩，性能接近7倍大的Gemma3-27B变体。

Conclusion: AIF框架为工具RAG系统提供了细粒度的可追溯性，通过训练轻量级模型作为上下文压缩器，显著提升了关键信息识别能力，为AI可解释性提供了有效的归因度量方法。

Abstract: Many tool-based Retrieval Augmented Generation (RAG) systems lack precise mechanisms for tracing final responses back to specific tool components -- a critical gap as systems scale to complex multi-agent architectures. We present \textbf{Atomic Information Flow (AIF)}, a graph-based network flow model that decomposes tool outputs and LLM calls into atoms: indivisible, self-contained units of information. By modeling LLM orchestration as a directed flow of atoms from tool and LLM nodes to a response super-sink, AIF enables granular attribution metrics for AI explainability.
  Motivated by the max-flow min-cut theorem in network flow theory, we train a lightweight Gemma3 (4B parameter) language model as a context compressor to approximate the minimum cut of tool atoms using flow signals computed offline by AIF. We note that the base Gemma3-4B model struggles to identify critical information with \textbf{54.7\%} accuracy on HotpotQA, barely outperforming lexical baselines (BM25). However, post-training on AIF signals boosts accuracy to \textbf{82.71\%} (+28.01 points) while achieving \textbf{87.52\%} (+1.85\%) context token compression -- bridging the gap with the Gemma3-27B variant, a model nearly $7\times$ larger.

</details>


### [32] [Scaling Laws for Embedding Dimension in Information Retrieval](https://arxiv.org/abs/2602.05062)
*Julian Killingback,Mahta Rafiee,Madine Manas,Hamed Zamani*

Main category: cs.IR

TL;DR: 本文通过实验分析发现，稠密检索模型的嵌入维度与检索性能之间存在幂律缩放关系，性能随维度增加而提升但收益递减，且任务对齐程度影响性能可预测性。


<details>
  <summary>Details</summary>
Motivation: 随着稠密检索任务复杂性增加，基于单向量和内积的底层数据结构与相似度度量的局限性日益明显。先前研究揭示了与嵌入维度相关的理论限制，理解嵌入维度缩放如何影响检索性能对于构建平衡效果与效率的下一代检索模型至关重要。

Method: 采用两个模型家族和一系列不同规模的模型进行综合实验，构建详细的嵌入缩放行为图景。通过实验分析嵌入维度与检索性能的关系，推导缩放规律。

Result: 发现缩放行为符合幂律关系，能够仅基于嵌入维度推导性能缩放规律，以及考虑嵌入维度和模型规模的联合规律。对于与训练任务对齐的评估任务，性能随嵌入维度增加而持续改善但收益递减；对于与训练任务对齐度较低的评估数据，性能可预测性较差，某些任务中较大嵌入维度会导致性能下降。

Conclusion: 本研究为理解嵌入的局限性及其行为提供了新见解，并为选择模型和嵌入维度以实现最佳性能同时降低存储和计算成本提供了实用指南。

Abstract: Dense retrieval, which encodes queries and documents into a single dense vector, has become the dominant neural retrieval approach due to its simplicity and compatibility with fast approximate nearest neighbor algorithms. As the tasks dense retrieval performs grow in complexity, the fundamental limitations of the underlying data structure and similarity metric -- namely vectors and inner-products -- become more apparent. Prior recent work has shown theoretical limitations inherent to single vectors and inner-products that are generally tied to the embedding dimension. Given the importance of embedding dimension for retrieval capacity, understanding how dense retrieval performance changes as embedding dimension is scaled is fundamental to building next generation retrieval models that balance effectiveness and efficiency. In this work, we conduct a comprehensive analysis of the relationship between embedding dimension and retrieval performance. Our experiments include two model families and a range of model sizes from each to construct a detailed picture of embedding scaling behavior. We find that the scaling behavior fits a power law, allowing us to derive scaling laws for performance given only embedding dimension, as well as a joint law accounting for embedding dimension and model size. Our analysis shows that for evaluation tasks aligned with the training task, performance continues to improve as embedding size increases, though with diminishing returns. For evaluation data that is less aligned with the training task, we find that performance is less predictable, with performance degrading with larger embedding dimensions for certain tasks. We hope our work provides additional insight into the limitations of embeddings and their behavior as well as offers a practical guide for selecting model and embedding dimension to achieve optimal performance with reduced storage and compute costs.

</details>


### [33] [RAG without Forgetting: Continual Query-Infused Key Memory](https://arxiv.org/abs/2602.05152)
*Yuntong Hu,Sha Li,Naren Ramakrishnan,Liang Zhao*

Main category: cs.IR

TL;DR: ERM框架将查询时的临时扩展转化为持久的检索改进，通过正确性门控反馈选择性更新文档键，实现零推理开销的持续学习。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在查询时进行扩展（如查询扩展、迭代检索）是临时性的，每次查询都需要重新计算，无法累积学习且产生重复推理成本。索引端方法（如键扩展）虽然持久但依赖离线预处理或启发式更新，与下游任务效用对齐弱，导致语义漂移和噪声累积。

Method: 提出ERM（演化检索记忆）框架：1）通过正确性门控反馈更新检索索引；2）将原子扩展信号选择性归因到受益的文档键；3）通过稳定、范数有界的更新逐步演化键。理论证明查询扩展和键扩展在标准相似度函数下等价，并证明ERM选择性更新的收敛性。

Result: 在BEIR和BRIGHT的13个领域实验中，检索和生成性能均获得一致提升，特别是在推理密集型任务上，同时保持原生检索速度。

Conclusion: ERM成功将查询时的临时增益转化为持久的检索改进，实现了零推理开销的持续学习，解决了现有RAG系统无法累积学习和重复计算的问题。

Abstract: Retrieval-augmented generation (RAG) systems commonly improve robustness via query-time adaptations such as query expansion and iterative retrieval. While effective, these approaches are inherently stateless: adaptations are recomputed for each query and discarded thereafter, precluding cumulative learning and repeatedly incurring inference-time cost. Index-side approaches like key expansion introduce persistence but rely on offline preprocessing or heuristic updates that are weakly aligned with downstream task utility, leading to semantic drift and noise accumulation. We propose Evolving Retrieval Memory (ERM), a training-free framework that transforms transient query-time gains into persistent retrieval improvements. ERM updates the retrieval index through correctness-gated feedback, selectively attributes atomic expansion signals to the document keys they benefit, and progressively evolves keys via stable, norm-bounded updates. We show that query and key expansion are theoretically equivalent under standard similarity functions and prove convergence of ERM's selective updates, amortizing optimal query expansion into a stable index with zero inference-time overhead. Experiments on BEIR and BRIGHT across 13 domains demonstrate consistent gains in retrieval and generation, particularly on reasoning-intensive tasks, at native retrieval speed.

</details>


### [34] [Semantic Search over 9 Million Mathematical Theorems](https://arxiv.org/abs/2602.05216)
*Luke Alexander,Eric Leonen,Sophie Szeto,Artemii Remizov,Ignacio Tejeda,Giovanni Inchiostro,Vasily Ilin*

Main category: cs.IR

TL;DR: 开发了一个大规模语义定理检索系统，在920万个定理语句的统一语料库上实现了比现有基线更好的定理级和论文级检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有数学检索工具通常返回整篇论文，而数学家和定理证明代理通常需要查找特定的定理、引理或命题。虽然语义搜索发展迅速，但在大型、高度技术性的研究级数学定理语料库上的表现仍不清楚。

Method: 从arXiv和其他七个来源提取了920万个定理语句，构建了最大的公开研究级定理语料库。使用简短的自然语言描述作为检索表示，系统分析了表示上下文、语言模型选择、嵌入模型和提示策略对检索质量的影响。

Result: 在专业数学家编写的定理搜索查询评估集上，该方法在定理级和论文级检索方面都显著优于现有基线，证明语义定理搜索在Web规模上是可行且有效的。

Conclusion: 语义定理搜索在大规模数学语料库上是可行的，该方法显著改进了数学内容的检索效果，相关工具和数据集已公开可用。

Abstract: Searching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek a specific theorem, lemma, or proposition that answers a query. While semantic search has seen rapid progress, its behavior on large, highly technical corpora such as research-level mathematical theorems remains poorly understood. In this work, we introduce and study semantic theorem retrieval at scale over a unified corpus of $9.2$ million theorem statements extracted from arXiv and seven other sources, representing the largest publicly available corpus of human-authored, research-level theorems. We represent each theorem with a short natural-language description as a retrieval representation and systematically analyze how representation context, language model choice, embedding model, and prompting strategy affect retrieval quality. On a curated evaluation set of theorem-search queries written by professional mathematicians, our approach substantially improves both theorem-level and paper-level retrieval compared to existing baselines, demonstrating that semantic theorem search is feasible and effective at web scale. The theorem search tool is available at \href{https://huggingface.co/spaces/uw-math-ai/theorem-search}{this link}, and the dataset is available at \href{https://huggingface.co/datasets/uw-math-ai/TheoremSearch}{this link}.

</details>


### [35] [NeuCLIRTech: Chinese Monolingual and Cross-Language Information Retrieval Evaluation in a Challenging Domain](https://arxiv.org/abs/2602.05334)
*Dawn Lawrie,James Mayfield,Eugene Yang,Andrew Yates,Sean MacAvaney,Ronak Pradeep,Scott Miller,Paul McNamee,Luca Soldaini*

Main category: cs.IR

TL;DR: NeuCLIRTech是一个用于技术信息跨语言检索的评估数据集，包含中文技术文档及其英文机器翻译版本，提供110个查询和35,962个文档相关性标注，支持中文单语检索和英文查询的跨语言检索场景。


<details>
  <summary>Details</summary>
Motivation: 为了准确衡量检索系统的进展，需要能够可靠区分系统性能的测试集。当前缺乏专门针对技术信息跨语言检索的评估资源，特别是在中文-英文技术文档场景下。

Method: 整合TREC NeuCLIR 2023和2024赛道主题，构建包含原生中文技术文档及其英文机器翻译版本的数据集。包含110个查询和35,962个文档相关性标注，提供强统计区分能力。还包含基于神经检索系统的融合基线，避免重排序算法依赖BM25作为第一级检索器。

Result: 创建了NeuCLIRTech评估数据集，支持两种检索场景：中文单语检索和英文查询的跨语言检索。数据集和工具已发布在Huggingface Datasets平台上。

Conclusion: NeuCLIRTech为技术信息跨语言检索提供了高质量的评估资源，具有强统计区分能力，能够可靠地评估和比较不同检索方法，特别是为重排序算法提供了更好的基线支持。

Abstract: Measuring advances in retrieval requires test collections with relevance judgments that can faithfully distinguish systems. This paper presents NeuCLIRTech, an evaluation collection for cross-language retrieval over technical information. The collection consists of technical documents written natively in Chinese and those same documents machine translated into English. It includes 110 queries with relevance judgments. The collection supports two retrieval scenarios: monolingual retrieval in Chinese, and cross-language retrieval with English as the query language. NeuCLIRTech combines the TREC NeuCLIR track topics of 2023 and 2024. The 110 queries with 35,962 document judgments provide strong statistical discriminatory power when trying to distinguish retrieval approaches. A fusion baseline of strong neural retrieval systems is included so that developers of reranking algorithms are not reliant on BM25 as their first stage retriever. The dataset and artifacts are released on Huggingface Datasets

</details>


### [36] [Multi-Field Tool Retrieval](https://arxiv.org/abs/2602.05366)
*Yichen Tang,Weihang Su,Yiqun Liu,Qingyao Ai*

Main category: cs.IR

TL;DR: 该论文提出了一种多字段工具检索框架，通过细粒度多字段建模解决LLM工具检索中的文档不完整、语义不匹配和多维度工具效用问题，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有工具检索方法将工具检索视为传统ad-hoc检索任务，存在三个根本挑战：1) 工具文档不完整和结构不一致；2) 用户查询与技术工具文档之间的显著语义和粒度不匹配；3) 工具效用的多维度特性（功能、输入约束、输出格式等）。

Method: 提出多字段工具检索框架，通过细粒度多字段建模对齐用户意图与工具表示，解决文档不完整、语义不匹配和多维度工具效用问题。

Result: 实验结果表明，该框架在五个数据集和一个混合基准测试中实现了SOTA性能，表现出优异的泛化能力和鲁棒性。

Conclusion: 多字段工具检索框架有效解决了现有工具检索方法的局限性，通过细粒度建模显著提升了工具检索的性能和实用性。

Abstract: Integrating external tools enables Large Language Models (LLMs) to interact with real-world environments and solve complex tasks. Given the growing scale of available tools, effective tool retrieval is essential to mitigate constraints of LLMs' context windows and ensure computational efficiency. Existing approaches typically treat tool retrieval as a traditional ad-hoc retrieval task, matching user queries against the entire raw tool documentation. In this paper, we identify three fundamental challenges that limit the effectiveness of this paradigm: (i) the incompleteness and structural inconsistency of tool documentation; (ii) the significant semantic and granular mismatch between user queries and technical tool documents; and, most importantly, (iii) the multi-aspect nature of tool utility, that involves distinct dimensions, such as functionality, input constraints, and output formats, varying in format and importance. To address these challenges, we introduce Multi-Field Tool Retrieval, a framework designed to align user intent with tool representations through fine-grained, multi-field modeling. Experimental results show that our framework achieves SOTA performance on five datasets and a mixed benchmark, exhibiting superior generalizability and robustness.

</details>


### [37] [Rich-Media Re-Ranker: A User Satisfaction-Driven LLM Re-ranking Framework for Rich-Media Search](https://arxiv.org/abs/2602.05408)
*Zihao Guo,Ligang Zhou,Zeyang Tang,Feicheng Li,Ying Nie,Zhiming Peng,Qingyun Sun,Jianxin Li*

Main category: cs.IR

TL;DR: 提出Rich-Media Re-Ranker框架，通过多维度细粒度建模提升搜索满意度，结合查询意图分析、视觉内容信号和LLM重排序，已在工业系统部署并显著改善用户参与度。


<details>
  <summary>Details</summary>
Motivation: 现有重排序方法存在两个主要局限：1) 对多面用户意图建模不足；2) 忽视视觉感知等丰富侧信息。这限制了搜索满意度的提升。

Method: 1) Query Planner分析会话中的查询序列捕获真实意图，分解为互补子查询；2) 整合候选结果的丰富侧信息，包括VLM生成的视觉内容信号；3) 设计重排序原则考虑内容相关性、质量、信息增益、新颖性和封面视觉呈现；4) LLM基于这些原则和信号进行整体评估；5) 通过多任务强化学习增强VLM评估器和LLM重排序器的场景适应性。

Result: 实验表明方法显著优于现有最先进基线。框架已在大型工业搜索系统部署，在线用户参与率和满意度指标获得实质性提升。

Conclusion: Rich-Media Re-Ranker框架通过多维度细粒度建模有效提升搜索满意度，成功解决了现有方法在意图建模和侧信息利用方面的不足，并在实际工业应用中验证了其有效性。

Abstract: Re-ranking plays a crucial role in modern information search systems by refining the ranking of initial search results to better satisfy user information needs. However, existing methods show two notable limitations in improving user search satisfaction: inadequate modeling of multifaceted user intents and neglect of rich side information such as visual perception signals. To address these challenges, we propose the Rich-Media Re-Ranker framework, which aims to enhance user search satisfaction through multi-dimensional and fine-grained modeling. Our approach begins with a Query Planner that analyzes the sequence of query refinements within a session to capture genuine search intents, decomposing the query into clear and complementary sub-queries to enable broader coverage of users' potential intents. Subsequently, moving beyond primary text content, we integrate richer side information of candidate results, including signals modeling visual content generated by the VLM-based evaluator. These comprehensive signals are then processed alongside carefully designed re-ranking principle that considers multiple facets, including content relevance and quality, information gain, information novelty, and the visual presentation of cover images. Then, the LLM-based re-ranker performs the holistic evaluation based on these principles and integrated signals. To enhance the scenario adaptability of the VLM-based evaluator and the LLM-based re-ranker, we further enhance their capabilities through multi-task reinforcement learning. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines. Notably, the proposed framework has been deployed in a large-scale industrial search system, yielding substantial improvements in online user engagement rates and satisfaction metrics.

</details>


### [38] [SciDef: Automating Definition Extraction from Academic Literature with Large Language Models](https://arxiv.org/abs/2602.05413)
*Filip Kučera,Christoph Mandl,Isao Echizen,Radu Timofte,Timo Spinde*

Main category: cs.IR

TL;DR: SciDef：基于LLM的自动定义提取管道，在科学文献中提取定义，性能达86.4%，但存在过度生成问题


<details>
  <summary>Details</summary>
Motivation: 随着科学出版物数量激增，手动收集相关定义变得困难，需要自动化工具来提取科学文献中的定义

Method: 开发SciDef管道，使用16种语言模型测试不同提示策略（多步和DSPy优化），创建DefExtra（定义提取）和DefSim（定义相似性）数据集进行评估

Result: LLM能够从科学文献中提取86.4%的定义，多步和DSPy优化提示策略提升性能，NLI-based评估方法最可靠，但模型倾向于过度生成定义

Conclusion: LLM在定义提取方面表现良好，但未来工作应关注识别相关定义而非仅找到定义，因为模型存在过度生成倾向

Abstract: Definitions are the foundation for any scientific work, but with a significant increase in publication numbers, gathering definitions relevant to any keyword has become challenging. We therefore introduce SciDef, an LLM-based pipeline for automated definition extraction. We test SciDef on DefExtra & DefSim, novel datasets of human-extracted definitions and definition-pairs' similarity, respectively. Evaluating 16 language models across prompting strategies, we demonstrate that multi-step and DSPy-optimized prompting improve extraction performance. To evaluate extraction, we test various metrics and show that an NLI-based method yields the most reliable results. We show that LLMs are largely able to extract definitions from scientific literature (86.4% of definitions from our test-set); yet future work should focus not just on finding definitions, but on identifying relevant ones, as models tend to over-generate them.
  Code & datasets are available at https://github.com/Media-Bias-Group/SciDef.

</details>


### [39] [Forward Index Compression for Learned Sparse Retrieval](https://arxiv.org/abs/2602.05445)
*Sebastian Bruch,Martino Fontana,Franco Maria Nardini,Cosimo Rulli,Rossano Venturini*

Main category: cs.IR

TL;DR: 本文研究稀疏检索算法中前向索引的压缩技术，提出DotVByte算法，在保持检索质量的同时显著减少存储空间


<details>
  <summary>Details</summary>
Motivation: 稀疏检索算法虽然高效，但其前向索引占用了大量存储空间，需要在不影响检索质量和计算延迟的情况下压缩前向索引

Method: 首先评估多种整数压缩技术，发现StreamVByte效果最佳；然后提出专门针对内积计算的DotVByte算法进行改进

Result: 在MsMarco数据集上实验显示，改进后的方法实现了显著的空间节省，同时保持了检索效率

Conclusion: DotVByte算法为稀疏检索提供了有效的前向索引压缩方案，在存储空间和检索性能之间取得了良好平衡

Abstract: Text retrieval using learned sparse representations of queries and documents has, over the years, evolved into a highly effective approach to search. It is thanks to recent advances in approximate nearest neighbor search-with the emergence of highly efficient algorithms such as the inverted index-based Seismic and the graph-based Hnsw-that retrieval with sparse representations became viable in practice. In this work, we scrutinize the efficiency of sparse retrieval algorithms and focus particularly on the size of a data structure that is common to all algorithmic flavors and that constitutes a substantial fraction of the overall index size: the forward index. In particular, we seek compression techniques to reduce the storage footprint of the forward index without compromising search quality or inner product computation latency. In our examination with various integer compression techniques, we report that StreamVByte achieves the best trade-off between memory footprint, retrieval accuracy, and latency. We then improve StreamVByte by introducing DotVByte, a new algorithm tailored to inner product computation. Experiments on MsMarco show that our improvements lead to significant space savings while maintaining retrieval efficiency.

</details>


### [40] [LMMRec: LLM-driven Motivation-aware Multimodal Recommendation](https://arxiv.org/abs/2602.05474)
*Yicheng Di,Zhanjie Zhang,Yun Wangc,Jinren Liue,Jiaqi Yanf,Jiyu Wei,Xiangyu Chend,Yuan Liu*

Main category: cs.IR

TL;DR: 提出LMMRec框架，利用大语言模型提取细粒度动机，通过双编码器架构实现跨模态对齐，解决动机融合中的噪声和语义漂移问题，在三个数据集上性能提升最高达4.98%


<details>
  <summary>Details</summary>
Motivation: 现有基于动机的推荐系统通常将动机视为交互数据中的潜在变量，忽略了评论文本等多模态信息。在多模态动机融合中存在两个挑战：1) 在噪声中实现稳定的跨模态对齐；2) 识别跨模态反映相同底层动机的特征

Method: 提出LMMRec框架，利用大语言模型获取深度语义先验和动机理解。使用思维链提示从文本中提取细粒度用户和物品动机。采用双编码器架构建模文本和交互动机，通过动机协调策略和交互-文本对应方法，结合对比学习和动量更新来缓解噪声和语义漂移

Result: 在三个数据集上的实验表明，LMMRec实现了最高4.98%的性能提升

Conclusion: LMMRec通过大语言模型驱动的动机感知多模态推荐框架，有效解决了跨模态动机融合中的对齐和特征识别问题，显著提升了推荐性能

Abstract: Motivation-based recommendation systems uncover user behavior drivers. Motivation modeling, crucial for decision-making and content preference, explains recommendation generation. Existing methods often treat motivation as latent variables from interaction data, neglecting heterogeneous information like review text. In multimodal motivation fusion, two challenges arise: 1) achieving stable cross-modal alignment amid noise, and 2) identifying features reflecting the same underlying motivation across modalities. To address these, we propose LLM-driven Motivation-aware Multimodal Recommendation (LMMRec), a model-agnostic framework leveraging large language models for deep semantic priors and motivation understanding. LMMRec uses chain-of-thought prompting to extract fine-grained user and item motivations from text. A dual-encoder architecture models textual and interaction-based motivations for cross-modal alignment, while Motivation Coordination Strategy and Interaction-Text Correspondence Method mitigate noise and semantic drift through contrastive learning and momentum updates. Experiments on three datasets show LMMRec achieves up to a 4.98\% performance improvement.

</details>


### [41] [GLASS: A Generative Recommender for Long-sequence Modeling via SID-Tier and Semantic Search](https://arxiv.org/abs/2602.05663)
*Shiteng Cao,Junda She,Ji Liu,Bin Zeng,Chengcheng Guo,Kuo Cai,Qiang Luo,Ruiming Tang,Han Li,Kun Gai,Zhiheng Li,Cheng Yang*

Main category: cs.IR

TL;DR: GLASS是一个生成式推荐框架，通过SID-Tier和语义搜索将长期用户兴趣整合到生成过程中，解决了传统生成推荐系统难以建模长历史序列的问题。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐系统作为变革性范式，在有效建模长历史序列方面面临挑战。传统检索模型难以处理大规模物品空间，需要新的方法来整合长期用户行为模式。

Method: 1. SID-Tier模块：将长期交互映射为统一兴趣向量，增强初始SID令牌预测；2. 语义硬搜索：使用生成的粗粒度语义ID作为动态键提取相关历史行为；3. 自适应门控融合模块：重新校准后续细粒度令牌轨迹；4. 语义邻居增强和码本调整策略解决数据稀疏性。

Result: 在TAOBAO-MM和KuaiRec两个大规模真实数据集上的实验表明，GLASS显著优于最先进的基线方法，在推荐质量上取得显著提升。

Conclusion: GLASS通过整合长期用户兴趣到生成过程中，有效解决了生成式推荐系统处理长历史序列的挑战，为生成式推荐提供了新的研究方向。

Abstract: Leveraging long-term user behavioral patterns is a key trajectory for enhancing the accuracy of modern recommender systems. While generative recommender systems have emerged as a transformative paradigm, they face hurdles in effectively modeling extensive historical sequences. To address this challenge, we propose GLASS, a novel framework that integrates long-term user interests into the generative process via SID-Tier and Semantic Search. We first introduce SID-Tier, a module that maps long-term interactions into a unified interest vector to enhance the prediction of the initial SID token. Unlike traditional retrieval models that struggle with massive item spaces, SID-Tier leverages the compact nature of the semantic codebook to incorporate cross features between the user's long-term history and candidate semantic codes. Furthermore, we present semantic hard search, which utilizes generated coarse-grained semantic ID as dynamic keys to extract relevant historical behaviors, which are then fused via an adaptive gated fusion module to recalibrate the trajectory of subsequent fine-grained tokens. To address the inherent data sparsity in semantic hard search, we propose two strategies: semantic neighbor augmentation and codebook resizing. Extensive experiments on two large-scale real-world datasets, TAOBAO-MM and KuaiRec, demonstrate that GLASS outperforms state-of-the-art baselines, achieving significant gains in recommendation quality. Our codes are made publicly available to facilitate further research in generative recommendation.

</details>


### [42] [Evaluating the impact of word embeddings on similarity scoring in practical information retrieval](https://arxiv.org/abs/2602.05734)
*Niall McCarroll,Kevin Curran,Eugene McNamee,Angela Clist,Andrew Brammer*

Main category: cs.IR

TL;DR: 该论文提出使用词移距离（WMD）结合词嵌入技术来改进查询-语句相似性度量，相比传统的词向量质心方法，在信息检索任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统基于词嵌入质心的相似性度量方法可能无法充分捕捉查询和语句之间的语义关联。受词移距离（WMD）模型启发，研究者希望探索通过计算查询和语句中单个词语之间的距离来更精确地评估语义相似性。

Method: 采用词移距离（WMD）模型来评估查询和语句之间的相似性，该方法计算查询和语句中单个词语之间的距离，而不是使用常见的词嵌入质心相似性度量。将WMD与预训练的词嵌入技术（如GloVe）结合使用。

Result: WMD+GloVe组合在查询和响应语句的排序任务中表现出最佳性能，显著超越了所有其他最先进的检索模型，包括Doc2Vec和基线LSA模型。该方法在相似性排序方面取得了显著的性能提升。

Conclusion: 使用在大规模数据上预训练的词嵌入结合词移距离方法，可以创建领域无关的语言处理解决方案，这些方案可移植到多样化的商业应用场景中，显著提高了信息检索的准确性。

Abstract: Search behaviour is characterised using synonymy and polysemy as users often want to search information based on meaning. Semantic representation strategies represent a move towards richer associative connections that can adequately capture this complex usage of language. Vector Space Modelling (VSM) and neural word embeddings play a crucial role in modern machine learning and Natural Language Processing (NLP) pipelines. Embeddings use distributional semantics to represent words, sentences, paragraphs or entire documents as vectors in high dimensional spaces. This can be leveraged by Information Retrieval (IR) systems to exploit the semantic relatedness between queries and answers.
  This paper evaluates an alternative approach to measuring query statement similarity that moves away from the common similarity measure of centroids of neural word embeddings. Motivated by the Word Movers Distance (WMD) model, similarity is evaluated using the distance between individual words of queries and statements. Results from ranked query and response statements demonstrate significant gains in accuracy using the combined approach of similarity ranking through WMD with the word embedding techniques. The top performing WMD + GloVe combination outperforms all other state-of-the-art retrieval models including Doc2Vec and the baseline LSA model. Along with the significant gains in performance of similarity ranking through WMD, we conclude that the use of pre-trained word embeddings, trained on vast amounts of data, result in domain agnostic language processing solutions that are portable to diverse business use-cases.

</details>


### [43] [Bagging-Based Model Merging for Robust General Text Embeddings](https://arxiv.org/abs/2602.05787)
*Hengran Zhang,Keping Bi,Jiafeng Guo,Jiaming Zhang,Wenbo Yang,Daiting Shi,Xueqi Cheng*

Main category: cs.IR

TL;DR: 该论文研究了文本嵌入模型的多任务训练策略，发现简单的批量级混洗效果最好但存在域外泛化不足和增量学习成本高的问题，提出了基于Bagging的鲁棒模型合并方法来解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 通用文本嵌入模型广泛应用于NLP和信息检索，通常通过多任务训练实现泛化。然而，不同多任务训练策略的实际效果比较不明确，且随着新领域和数据类型的不断出现，如何高效适应嵌入模型仍不清楚。

Method: 从数据调度和模型合并两个角度系统研究多任务训练：比较批量级混洗、顺序训练变体、两阶段训练和多种合并粒度。提出Bagging-based rObust mOdel Merging (BOOM)方法，训练多个嵌入模型在采样子集上并合并为单一模型，同时支持通过训练轻量更新模型实现高效增量更新。

Result: 批量级混洗始终产生最强的整体性能，表明任务冲突有限且训练数据基本互补。但存在域外泛化不足和增量学习成本高的问题。BOOM方法在多样化嵌入基准测试中，相比全语料批量级混洗持续提升域内和域外性能，同时在增量学习设置中显著降低训练成本。

Conclusion: 批量级混洗是有效的多任务训练策略，但存在实际限制。提出的BOOM方法通过模型合并和Bagging技术，不仅提升了性能鲁棒性，还实现了高效的增量学习，为文本嵌入模型的持续适应提供了实用解决方案。

Abstract: General-purpose text embedding models underpin a wide range of NLP and information retrieval applications, and are typically trained on large-scale multi-task corpora to encourage broad generalization. However, it remains unclear how different multi-task training strategies compare in practice, and how to efficiently adapt embedding models as new domains and data types continually emerge. In this work, we present a systematic study of multi-task training for text embeddings from two perspectives: data scheduling and model merging. We compare batch-level shuffling, sequential training variants, two-stage training, and multiple merging granularities, and find that simple batch-level shuffling consistently yields the strongest overall performance, suggesting that task conflicts are limited and training datasets are largely complementary. Despite its effectiveness, batch-level shuffling exhibits two practical limitations: suboptimal out-of-domain (OOD) generalization and poor suitability for incremental learning due to expensive full retraining. To address these issues, we propose Bagging-based rObust mOdel Merging (\modelname), which trains multiple embedding models on sampled subsets and merges them into a single model, improving robustness while retaining single-model inference efficiency. Moreover, \modelname naturally supports efficient incremental updates by training lightweight update models on new data with a small historical subset and merging them into the existing model. Experiments across diverse embedding benchmarks demonstrate that \modelname consistently improves both in-domain and OOD performance over full-corpus batch-level shuffling, while substantially reducing training cost in incremental learning settings.

</details>


### [44] [AgenticTagger: Structured Item Representation for Recommendation with LLM Agents](https://arxiv.org/abs/2602.05945)
*Zhouhang Xie,Bo Peng,Zhankui He,Ziqi Chen,Alice Han,Isabella Ye,Benjamin Coleman,Noveen Sachdeva,Fernando Pereira,Julian McAuley,Wang-Cheng Kang,Derek Zhiyuan Cheng,Beidou Wang,Randolph Brown*

Main category: cs.IR

TL;DR: AgenticTagger是一个基于LLM的生成式描述符框架，通过两阶段方法（词汇构建和词汇分配）为推荐系统生成高质量、低基数的文本描述符。


<details>
  <summary>Details</summary>
Motivation: 高质量的表示是有效推荐的核心需求。当前LLM生成描述符的方法存在开放生成空间难以控制的问题，导致描述符基数高、质量低，给下游建模带来挑战。

Method: 提出AgenticTagger框架：1) 词汇构建阶段：通过多智能体反思机制，架构LLM在标注LLM的并行反馈指导下迭代优化，构建层次化、低基数、高质量的描述符词汇表；2) 词汇分配阶段：LLM将词汇表中的描述符分配给项目。

Result: 在公开和私有数据上的实验表明，AgenticTagger在多种推荐场景中带来一致改进，包括生成式和基于术语的检索、排序，以及面向可控性的基于批评的推荐。

Conclusion: AgenticTagger通过控制生成空间和降低描述符基数，有效解决了LLM生成描述符的挑战，为推荐系统提供了高质量的文本表示。

Abstract: High-quality representations are a core requirement for effective recommendation. In this work, we study the problem of LLM-based descriptor generation, i.e., keyphrase-like natural language item representation generation frameworks with minimal constraints on downstream applications. We propose AgenticTagger, a framework that queries LLMs for representing items with sequences of text descriptors. However, open-ended generation provides little control over the generation space, leading to high cardinality, low-performance descriptors that renders downstream modeling challenging. To this end, AgenticTagger features two core stages: (1) a vocabulary building stage where a set of hierarchical, low-cardinality, and high-quality descriptors is identified, and (2) a vocabulary assignment stage where LLMs assign in-vocabulary descriptors to items. To effectively and efficiently ground vocabulary in the item corpus of interest, we design a multi-agent reflection mechanism where an architect LLM iteratively refines the vocabulary guided by parallelized feedback from annotator LLMs that validates the vocabulary against item data. Experiments on public and private data show AgenticTagger brings consistent improvements across diverse recommendation scenarios, including generative and term-based retrieval, ranking, and controllability-oriented, critique-based recommendation.

</details>


### [45] [SAGE: Benchmarking and Improving Retrieval for Deep Research Agents](https://arxiv.org/abs/2602.05975)
*Tiansheng Hu,Yilun Zhao,Canyu Zhang,Arman Cohan,Chen Zhao*

Main category: cs.IR

TL;DR: 论文提出了SAGE基准测试，评估深度研究代理在科学文献检索中的表现，发现现有系统在处理推理密集型检索时表现不佳，BM25检索器优于LLM检索器，并提出了基于LLM的文档增强框架来提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着深度研究代理在复杂查询处理中的兴起，以及LLM检索器在指令遵循和推理方面的强大能力，研究LLM检索器能否有效贡献于深度研究代理工作流程成为一个关键问题。

Method: 1) 引入SAGE基准测试，包含4个科学领域的1200个查询和20万篇论文的检索语料库；2) 评估6个深度研究代理；3) 比较BM25和LLM检索器(ReasonIR和gte-Qwen2-7B-instruct)；4) 提出语料库级测试时扩展框架，使用LLM通过元数据和关键词增强文档。

Result: 1) 所有深度研究代理在推理密集型检索中都表现不佳；2) BM25检索器显著优于LLM检索器约30%；3) 提出的文档增强框架在简短问题和开放式问题上分别带来8%和2%的性能提升。

Conclusion: 当前深度研究代理倾向于生成关键词导向的子查询，限制了LLM检索器的优势。通过LLM增强文档内容，可以使现成检索器更容易找到相关信息，有效提升检索性能。

Abstract: Deep research agents have emerged as powerful systems for addressing complex queries. Meanwhile, LLM-based retrievers have demonstrated strong capability in following instructions or reasoning. This raises a critical question: can LLM-based retrievers effectively contribute to deep research agent workflows? To investigate this, we introduce SAGE, a benchmark for scientific literature retrieval comprising 1,200 queries across four scientific domains, with a 200,000 paper retrieval corpus.We evaluate six deep research agents and find that all systems struggle with reasoning-intensive retrieval. Using DR Tulu as backbone, we further compare BM25 and LLM-based retrievers (i.e., ReasonIR and gte-Qwen2-7B-instruct) as alternative search tools. Surprisingly, BM25 significantly outperforms LLM-based retrievers by approximately 30%, as existing agents generate keyword-oriented sub-queries. To improve performance, we propose a corpus-level test-time scaling framework that uses LLMs to augment documents with metadata and keywords, making retrieval easier for off-the-shelf retrievers. This yields 8% and 2% gains on short-form and open-ended questions, respectively.

</details>
