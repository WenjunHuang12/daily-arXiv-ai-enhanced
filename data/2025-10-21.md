<div id=toc></div>

# Table of Contents

- [cs.GT](#cs.GT) [Total: 4]
- [cs.IT](#cs.IT) [Total: 13]
- [cs.DB](#cs.DB) [Total: 7]
- [cs.DS](#cs.DS) [Total: 19]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.IR](#cs.IR) [Total: 11]


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [1] [The Strongly Stable Roommates Problem and Linear Programming](https://arxiv.org/abs/2510.16385)
*Naoyuki Kamiyama*

Main category: cs.GT

TL;DR: 提出了一种新的多项式时间算法，用于检查带平局的稳定室友问题中是否存在强稳定匹配，扩展了Abeledo和Blum的线性规划方法。


<details>
  <summary>Details</summary>
Motivation: 稳定室友问题是稳定匹配问题的非二分图版本，本文关注带平局情况下的强稳定性问题，这是带平局稳定室友问题中的主要稳定性概念之一。

Method: 将Abeledo和Blum在严格偏好稳定室友问题中的线性规划方法扩展到带平局的情况。

Result: 开发了一个多项式时间算法来检查强稳定匹配的存在性。

Conclusion: 成功扩展了线性规划方法，为带平局的稳定室友问题提供了有效的强稳定性检查算法。

Abstract: The stable roommates problem is a non-bipartite version of the stable
matching problem in a bipartite graph. In this paper, we consider the stable
roommates problem with ties. In particular, we focus on strong stability, which
is one of the main stability concepts in the stable roommates problem with
ties. We propose a new polynomial-time algorithm for the problem of checking
the existence of a strongly stable matching in the stable roommates problem
with ties. More concretely, we extend the linear programming approach of
Abeledo and Blum to the stable roommates problem with strict preferences to our
problem.

</details>


### [2] [No-Regret Online Autobidding Algorithms in First-price Auctions](https://arxiv.org/abs/2510.16869)
*Yuan Deng,Yilin Li,Wei Tang,Hanrui Zhang*

Main category: cs.GT

TL;DR: 本文针对带有ROI约束的非真实机制，开发了在线竞价算法，用于重复的一价拍卖，并与事后最优随机策略进行基准比较。


<details>
  <summary>Details</summary>
Motivation: 在线广告中，自动化竞价在ROI约束和预算约束下被广泛采用。关键挑战在于为非真实机制设计算法，而先前工作主要关注真实拍卖或较弱的基准。

Method: 在完全反馈设置下（观察到最大竞争出价），算法达到近最优的$\widetilde{O}(\sqrt{T})$遗憾界；在强盗反馈设置下（仅观察到是否赢得拍卖），算法达到$\widetilde{O}(T^{3/4})$遗憾界。

Result: 算法在完全反馈和强盗反馈设置下分别实现了$\widetilde{O}(\sqrt{T})$和$\widetilde{O}(T^{3/4})$的遗憾界。

Conclusion: 本文为非真实机制下的在线竞价问题提供了显著的改进，特别是在ROI约束下的一价拍卖中，实现了接近最优的遗憾界。

Abstract: Automated bidding to optimize online advertising with various constraints,
e.g. ROI constraints and budget constraints, is widely adopted by advertisers.
A key challenge lies in designing algorithms for non-truthful mechanisms with
ROI constraints. While prior work has addressed truthful auctions or
non-truthful auctions with weaker benchmarks, this paper provides a significant
improvement: We develop online bidding algorithms for repeated first-price
auctions with ROI constraints, benchmarking against the optimal randomized
strategy in hindsight. In the full feedback setting, where the maximum
competing bid is observed, our algorithm achieves a near-optimal
$\widetilde{O}(\sqrt{T})$ regret bound, and in the bandit feedback setting
(where the bidder only observes whether the bidder wins each auction), our
algorithm attains $\widetilde{O}(T^{3/4})$ regret bound.

</details>


### [3] [Convergence of Regret Matching in Potential Games and Constrained Optimization](https://arxiv.org/abs/2510.17067)
*Ioannis Anagnostides,Emanuel Tewolde,Brian Hu Zhang,Ioannis Panageas,Vincent Conitzer,Tuomas Sandholm*

Main category: cs.GT

TL;DR: 本文证明了交替遗憾匹配+（RM+）在约束优化问题中收敛到ε-KKT点的复杂度为O(1/ε⁴)，在遗憾有界时改进到O(1/ε²)。同时证明了原始RM算法即使在两人势博弈中也可能需要指数时间收敛，首次建立了RM与RM+的最坏情况分离。


<details>
  <summary>Details</summary>
Motivation: 遗憾匹配算法在解决零和博弈方面取得了突破性成果，但其在更广泛场景（如势博弈和约束优化）中的理论收敛性研究不足。特别是RM在势博弈中是否收敛到纳什均衡的问题已开放20年。

Method: 采用交替遗憾匹配+（RM+）算法，通过分析KKT间隙与累积遗憾的关系，证明算法会快速进入并保持在某个区域，该区域内具有一步改进性质。

Result: 交替RM+收敛到ε-KKT点的迭代复杂度为O(1/ε⁴)，当遗憾有界时改进为O(1/ε²)。同时证明原始RM算法在两人势博弈中收敛到粗糙近似解可能需要指数时间。

Conclusion: RM+是有效的一阶优化器，而RM与RM+在最坏情况下存在指数级性能差异，表明在势博弈中收敛到粗相关均衡比收敛到纳什均衡快得多。

Abstract: Regret matching (RM} -- and its modern variants -- is a foundational online
algorithm that has been at the heart of many AI breakthrough results in solving
benchmark zero-sum games, such as poker. Yet, surprisingly little is known so
far in theory about its convergence beyond two-player zero-sum games. For
example, whether regret matching converges to Nash equilibria in potential
games has been an open problem for two decades. Even beyond games, one could
try to use RM variants for general constrained optimization problems. Recent
empirical evidence suggests that they -- particularly regret matching$^+$
(RM$^+$) -- attain strong performance on benchmark constrained optimization
problems, outperforming traditional gradient descent-type algorithms.
  We show that alternating RM$^+$ converges to an $\epsilon$-KKT point after
$O_\epsilon(1/\epsilon^4)$ iterations, establishing for the first time that it
is a sound and fast first-order optimizer. Our argument relates the KKT gap to
the accumulated regret, two quantities that are entirely disparate in general
but interact in an intriguing way in our setting, so much so that when regrets
are bounded, our complexity bound improves all the way to
$O_\epsilon(1/\epsilon^2)$. From a technical standpoint, while RM$^+$ does not
have the usual one-step improvement property in general, we show that it does
in a certain region that the algorithm will quickly reach and remain in
thereafter. In sharp contrast, our second main result establishes a lower
bound: RM, with or without alternation, can take an exponential number of
iterations to reach a crude approximate solution even in two-player potential
games. This represents the first worst-case separation between RM and RM$^+$.
Our lower bound shows that convergence to coarse correlated equilibria in
potential games is exponentially faster than convergence to Nash equilibria.

</details>


### [4] [Eliciting Truthful Feedback for Preference-Based Learning via the VCG Mechanism](https://arxiv.org/abs/2510.17285)
*Leo Landolt,Anna Maddux,Andreas Schlaginhaufen,Saurabh Vaishampayan,Maryam Kamgarpour*

Main category: cs.GT

TL;DR: 提出了结合偏好学习和VCG支付的资源分配机制，解决代理成本函数未知和策略性误报问题，在单次和在线设置中分别实现近似真实性和效率保证。


<details>
  <summary>Details</summary>
Motivation: 解决资源分配中代理成本函数未知或难以显式指定，以及代理可能策略性误报成本的两个主要挑战。

Method: 使用D-最优设计选择信息性偏好查询，通过最大似然估计成本参数，基于估计值计算VCG分配和支付。

Result: 单次设置中机制近似真实、个体理性且效率误差为O(K^{-1/2})；在线设置中保证渐进成立，后悔率为O(T^{2/3})。

Conclusion: 通过本地电力市场需求响应的数值案例验证了方法的有效性，证明了偏好学习与VCG支付结合在资源分配问题中的可行性。

Abstract: We study resource allocation problems in which a central planner allocates
resources among strategic agents with private cost functions in order to
minimize a social cost, defined as an aggregate of the agents' costs. This
setting poses two main challenges: (i) the agents' cost functions may be
unknown to them or difficult to specify explicitly, and (ii) agents may
misreport their costs strategically. To address these challenges, we propose an
algorithm that combines preference-based learning with Vickrey-Clarke-Groves
(VCG) payments to incentivize truthful reporting. Our algorithm selects
informative preference queries via D-optimal design, estimates cost parameters
through maximum likelihood, and computes VCG allocations and payments based on
these estimates. In a one-shot setting, we prove that the mechanism is
approximately truthful, individually rational, and efficient up to an error of
$\tilde{\mathcal O}(K^{-1/2})$ for $K$ preference queries per agent. In an
online setting, these guarantees hold asymptotically with sublinear regret at a
rate of $\tilde{\mathcal O}(T^{2/3})$ after $T$ rounds. Finally, we validate
our approach through a numerical case study on demand response in local
electricity markets.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [5] [A Semantic Generalization of Shannon's Information Theory and Applications](https://arxiv.org/abs/2510.15871)
*Chenguang Lu*

Main category: cs.IT

TL;DR: 本文提出了语义信息理论G理论，将香农信息论推广到语义通信领域，用语义约束替代失真约束，并展示了在机器学习、通信等领域的应用。


<details>
  <summary>Details</summary>
Motivation: 探讨语义通信是否需要独立于香农信息论的语义信息理论，还是可以通过推广香农理论来实现语义通信。

Method: 引入G理论，使用真值函数作为语义通道来替代失真约束，定义语义失真、语义信息度量和语义信息损失。

Result: 建立了最大语义信息准则与最大似然准则的等价性，展示了在机器学习、通信、控制等领域的应用，并与统计物理概念建立了联系。

Conclusion: 香农信息论可以通过G理论推广到语义通信，但该理论在处理复杂数据语义表示方面存在局限性。

Abstract: Does semantic communication require a semantic information theory parallel to
Shannon's information theory, or can Shannon's work be generalized for semantic
communication? This paper advocates for the latter and introduces a semantic
generalization of Shannon's information theory (G theory for short). The core
idea is to replace the distortion constraint with the semantic constraint,
achieved by utilizing a set of truth functions as a semantic channel. These
truth functions enable the expressions of semantic distortion, semantic
information measures, and semantic information loss. Notably, the maximum
semantic information criterion is equivalent to the maximum likelihood
criterion and similar to the Regularized Least Squares criterion. This paper
shows G theory's applications to daily and electronic semantic communication,
machine learning, constraint control, Bayesian confirmation, portfolio theory,
and information value. The improvements in machine learning methods involve
multilabel learning and classification, maximum mutual information
classification, mixture models, and solving latent variables. Furthermore,
insights from statistical physics are discussed: Shannon information is similar
to free energy; semantic information to free energy in local equilibrium
systems; and information efficiency to the efficiency of free energy in
performing work. The paper also proposes refining Friston's minimum free energy
principle into the maximum information efficiency principle. Lastly, it
compares G theory with other semantic information theories and discusses its
limitation in representing the semantics of complex data.

</details>


### [6] [Cluster-wise processing in fronthaul-aware cell-free massive MIMO systems](https://arxiv.org/abs/2510.16432)
*Zahra Mobini,Ahmet Hasim Gokceoglu,Li Wang,Gunnar Peters,Hyundong Shin,Hien Quoc Ngo*

Main category: cs.IT

TL;DR: 提出了一种基于集群架构的用户中心化无蜂窝大规模MIMO系统，通过不同接入点间的协作程度实现可扩展部署，解决了前传容量限制下的资源分配和预编码优化问题。


<details>
  <summary>Details</summary>
Motivation: 解决前传容量限制下用户中心化无蜂窝大规模MIMO系统的可扩展实现问题，通过集群化处理来平衡性能与复杂度。

Method: 将接入点分组为多个处理集群，使用局部信道状态信息，基于改进的加权最小均方误差方法解决非凸混合整数优化问题，包括联合预编码、用户关联和功率分配。

Result: 开发了两种优化方案：一种在小尺度衰落时间尺度联合优化，另一种在大尺度衰落时间尺度优化，均能有效提升系统性能。

Conclusion: 所提出的集群架构和优化方法能够在前传容量限制下实现用户中心化无蜂窝大规模MIMO系统的可扩展部署，为实际系统设计提供了有效解决方案。

Abstract: We exploit a general cluster-based network architecture for a
fronthaul-limited user-centric cell-free massive multiple-input multiple-output
(CF-mMIMO) system under different degrees of cooperation among the access
points (APs) to achieve scalable implementation. In particular, we consider a
CF-mMIMO system wherein the available APs are grouped into multiple processing
clusters (PCs) to share channel state information (CSI), ensuring that they
have knowledge of the CSI for all users assigned to the given cluster for the
purposes of designing resource allocation and precoding. We utilize the sum
pseudo-SE metric, which accounts for intra-cluster interference and
intercluster-leakage, providing a close approximation to the true sum
achievable SE. For a given PC, we formulate two optimization problems to
maximize the cluster-wise weighted sum pseudo-SE under fronthaul constraints,
relying solely on local CSI. These optimization problems are associated with
different computational complexity requirements. The first optimization problem
jointly designs precoding, user association, and power allocation, and is
performed at the small-scale fading time scale. The second optimization problem
optimizes user association and power allocation at the large-scale fading time
scale. Accordingly, we develop a novel application of modified weighted minimum
mean square error (WMMSE)-based approach to solve the challenging formulated
non-convex mixed-integer problems.

</details>


### [7] [Hybrid CNN-Transformer Based Sparse Channel Prediction for High-Mobility OTFS Systems](https://arxiv.org/abs/2510.16539)
*Zhaowei Guan,Wenkun Wen,Peiran Wu,Chen Wang,Minghua Xia*

Main category: cs.IT

TL;DR: 提出了一种基于CNN-Transformer混合架构的OTFS系统信道预测框架，在高速移动场景下显著优于现有方法，支持URLLC需求。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络中的高速移动场景（如车联网）需要超可靠低延迟通信，但快速时变信道对传统OFDM系统构成挑战。OTFS调制通过在延迟多普勒域表示信道提供鲁棒性。

Method: 使用混合CNN-Transformer架构：CNN提取利用DD域信道矩阵稀疏性的紧凑特征，Transformer通过因果掩码建模时间依赖性以确保一致性。

Result: 在500km/h极端移动条件下，所提方法优于最先进基线，均方根误差和平均绝对误差分别降低12.2%和9.4%。

Conclusion: DD域表示和所提模型能有效预测高速移动场景下的信道，支持未来无线系统中严格的URLLC要求。

Abstract: High-mobility scenarios in next-generation wireless networks, such as those
involving vehicular communications, require ultra-reliable and low-latency
communications (URLLC). However, rapidly time-varying channels pose significant
challenges to traditional OFDM-based systems due to the Doppler effect and
channel aging. Orthogonal time frequency space (OTFS) modulation offers
resilience by representing channels in the quasi-static delay-Doppler (DD)
domain. This letter proposes a novel channel prediction framework for OTFS
systems using a hybrid convolutional neural network and transformer
(CNN-Transformer) architecture. The CNN extracts compact features that exploit
the DD-domain sparsity of the channel matrices, while the transformer models
temporal dependencies with causal masking for consistency. Simulation
experiments under extreme $500$ \si{km/h} mobility conditions demonstrate that
the proposed method outperforms state-of-the-art baselines, reducing the root
mean square error and mean absolute error by $12.2\%$ and $9.4\%$,
respectively. These results demonstrate the effectiveness of DD-domain
representations and the proposed model in accurately predicting channels in
high-mobility scenarios, thereby supporting the stringent URLLC requirements in
future wireless systems.

</details>


### [8] [Enhancing Channel Estimation in RIS-aided Systems via Observation Matrix Design](https://arxiv.org/abs/2510.16576)
*Zijian Zhang,Mingyao Cui*

Main category: cs.IT

TL;DR: 提出了一种基于贝叶斯优化的可重构智能表面信道估计观测矩阵设计方法，使用交替黎曼流形优化算法来提升估计精度。


<details>
  <summary>Details</summary>
Motivation: 可重构智能表面(RIS)通过密集天线阵列增强无线通信性能，但需要准确的信道估计才能充分发挥其潜力。

Method: 采用贝叶斯优化框架设计观测矩阵以最大化接收导频信号与RIS信道之间的互信息，开发交替黎曼流形优化(ARMO)算法交替更新接收机组合器和RIS相移矩阵，并引入自适应核训练策略迭代优化信道协方差矩阵。

Result: 仿真结果表明，提出的ARMO增强估计器在估计精度上相比现有先进方法有显著提升。

Conclusion: 该方法有效提升了RIS信道估计性能，无需额外导频资源即可实现更好的估计效果。

Abstract: Reconfigurable intelligent surfaces (RISs) have emerged as a promising
technology for enhancing wireless communications through dense antenna arrays.
Accurate channel estimation is critical to unlocking their full performance
potential. To enhance RIS channel estimators, this paper proposes a novel
observation matrix design scheme. Bayesian optimization framework is adopted to
generate observation matrices that maximize the mutual information between
received pilot signals and RIS channels. To solve the formulated problem
efficiently, we develop an alternating Riemannian manifold optimization (ARMO)
algorithm to alternately update the receiver combiners and RIS phase-shift
matrices. An adaptive kernel training strategy is further introduced to
iteratively refine the channel covariance matrix without requiring additional
pilot resources. Simulation results demonstrate that the proposed ARMO-enhanced
estimator achieves substantial gains in estimation accuracy over
state-of-the-art methods.

</details>


### [9] [Feedback Lunch: Deep Feedback Codes for Wiretap Channels](https://arxiv.org/abs/2510.16620)
*Yingyao Zhou,Natasha Devroye,Onur Günlü*

Main category: cs.IT

TL;DR: 提出了一个用于高斯窃听信道的种子模块化代码设计，结合通用哈希函数和基于反馈的学习代码，在信道输出反馈下实现正保密率。


<details>
  <summary>Details</summary>
Motivation: 针对反向退化窃听信道，在没有信道反馈时保密容量为零的问题，研究如何利用反馈来克服窃听者的安全优势。

Method: 使用种子模块化代码设计，结合通用哈希函数确保安全性，基于反馈的学习代码确保可靠性。

Result: 反馈使合法方能够协商共享密钥，实现正保密率，突破了窃听者的安全优势。

Conclusion: 反馈机制是实现安全通信的关键，为下一代集成感知与通信方法中的感知辅助安全通信提供了代码设计思路。

Abstract: We consider reversely-degraded wiretap channels, for which the secrecy
capacity is zero if there is no channel feedback. This work focuses on a seeded
modular code design for the Gaussian wiretap channel with channel output
feedback, combining universal hash functions for security and learned
feedback-based codes for reliability to achieve positive secrecy rates. We
study the trade-off between communication reliability and information leakage,
illustrating that feedback enables agreeing on a secret key shared between
legitimate parties, overcoming the security advantage of the wiretapper. Our
findings also motivate code designs for sensing-assisted secure communication,
to be used in next-generation integrated sensing and communication methods.

</details>


### [10] [Non-Orthogonal Pilot Sequence Design for Multi-Cells Interference Networks](https://arxiv.org/abs/2510.16792)
*Zhi Gu,Wai Ho Mow*

Main category: cs.IT

TL;DR: 本文针对多小区无线通信系统，提出了扩展总平方相关(ETSC)作为新的序列设计准则，推导了ETSC的闭式下界，并开发了ETSC-MM算法来生成低ETSC序列集。


<details>
  <summary>Details</summary>
Motivation: 在无线通信中，当用户数超过序列长度时，非正交序列集的性能显著影响多用户干扰水平。在多小区系统中，由于来自本小区和邻小区信道的强度差异，需要新的序列设计准则来优化系统性能。

Method: 提出了扩展总平方相关(ETSC)作为序列设计新准则，推导了ETSC的闭式下界，并基于Majorization-Minimization(MM)优化框架开发了ETSC-MM算法来生成低ETSC序列集。

Result: 推导的ETSC下界是Welch界和扩展Welch界的推广，当干扰功率因子矩阵正定时，可以从界值必要条件轻松获得最优序列集。ETSC-MM算法能在特定参数条件下生成低ETSC序列集。

Conclusion: ETSC是适用于多小区系统的有效序列设计准则，推导的下界具有理论意义，ETSC-MM算法解决了特定参数条件下序列生成方法的缺失问题。

Abstract: In wireless communications, the performance of non-orthogonal sequence sets
significantly affects the level of multi-user interference when the number of
users surpasses the sequence length. The design of non-orthogonal sequences
plays a crucial role in both the non-orthogonality of the pilots in multi-cell
systems and the signature sequences in overloaded code-division multiple-access
(CDMA) systems. In multi-cell systems, considering the strength disparity
between channels originating from the home cell and the neighboring cells, the
extended total squared correlation (ETSC) is proposed as a new sequence design
criterion, which is defined as the sum of squares of the weighted correlations
among sequences. In this paper, we derive a closed-form expression for the
lower bound of ETSC for multi-cell systems with a given sequence length $\tau$,
where $\tau \leq K$ and $K$ is the number of users per cell. This can be
regarded as a generalization of the well-known Welch bound (Welch, 1974, IEEE
TIT) and the extended Welch bound (Wang et al., 2021, IEEE TWC). Additionally,
from the necessary conditions of the bound, the optimal sequence set can be
easily obtained when the interference power factor matrix is positive definite.
On the other hand, to address the lack of sequence generation methods under
certain parameter conditions, we propose the ETSC-MM algorithm, which generates
sequence sets with low ETSC based on a Majorization-Minimization (MM)
optimization framework.

</details>


### [11] [Unlocking Off-the-Grid Sparse Recovery with Unlimited Sensing: Simultaneous Super-Resolution in Time and Amplitude](https://arxiv.org/abs/2510.16948)
*Ruiming Guo,Ayush Bhandari*

Main category: cs.IT

TL;DR: 该论文提出了一种基于无限感知框架(USF)的模数编码方法，通过增强测量精度实现数字超分辨率，突破了传统量化限制，能够在低比特量化下同时实现幅度和时间维度的超分辨率。


<details>
  <summary>Details</summary>
Motivation: 传统数字采集在处理强-弱幅度差异大的脉冲信号时，会出现强分量削波或弱分量被量化噪声淹没的问题。在固定比特预算下，这种信息损失是不可避免的，需要同时解决幅度和时间结构的超分辨率问题。

Method: 基于无限感知框架(USF)的模数编码方法，开发了适用于实际中常见非带限核的新理论结果，并提出了鲁棒的离格稀疏恢复算法。

Result: 数值仿真和硬件实验验证了该方法在低比特量化下的有效性，能够实现幅度和时间的超分辨率。

Conclusion: 无限感知框架的模数编码能够克服传统数字采集的基本限制，通过增强测量精度实现数字超分辨率，解锁了超越传统极限的时间超分辨率能力。

Abstract: The recovery of Dirac impulses, or spikes, from filtered measurements is a
classical problem in signal processing. As the spikes lie in the continuous
domain while measurements are discrete, this task is known as super-resolution
or off-the-grid sparse recovery. Despite significant theoretical and
algorithmic advances over the past decade, these developments often overlook
critical challenges at the analog-digital interface. In particular, when spikes
exhibit strong-weak amplitude disparity, conventional digital acquisition may
result in clipping of strong components or loss of weak ones beneath the
quantization noise floor. This motivates a broader perspective:
super-resolution must simultaneously resolve both amplitude and temporal
structure. Under a fixed bit budget, such information loss is unavoidable. In
contrast, the emerging theory and practice of the Unlimited Sensing Framework
(USF) demonstrate that these fundamental limitations can be overcome. Building
on this foundation, we demonstrate that modulo encoding within USF enables
digital super-resolution by enhancing measurement precision, thereby unlocking
temporal super-resolution beyond conventional limits. We develop new
theoretical results that extend to non-bandlimited kernels commonly encountered
in practice and introduce a robust algorithm for off-the-grid sparse recovery.
To demonstrate practical impact, we instantiate our framework in the context of
time-of-flight imaging. Both numerical simulations and hardware experiments
validate the effectiveness of our approach under low-bit quantization, enabling
super-resolution in amplitude and time.

</details>


### [12] [Channel Capacity for FMCW-based Optical Wireless Integrated Sensing and Communication: Asymptotic Analysis and Envelope Design](https://arxiv.org/abs/2510.17093)
*Yunfeng Wen,Fang Yang,Jian Song,Zhu Han*

Main category: cs.IT

TL;DR: 本文分析了基于FMCW的相干光学无线集成感知与通信系统的信道容量，推导了感知约束下的容量上下界，为脉冲幅度调制的包络设计提供指导，并揭示了通信与感知功能之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 光学无线集成感知与通信(OW-ISAC)作为射频对应技术的补充和增强正在快速发展，需要分析信道容量来指导基于FMCW的相干OW-ISAC系统设计。

Method: 将基于FMCW的OW-ISAC系统模型重新表述为信息论框架，施加谐波均值约束来保证感知性能，推导感知约束下的信道容量上下界，并给出低高信噪比区域的渐近表达式。

Result: 获得了感知约束下的信道容量上下界，分析了脉冲幅度调制包络设计的容量实现能力，数值结果验证了容量实现能力，仿真揭示了通信与感知功能之间的权衡。

Conclusion: 在感知约束下分析信道容量为OW-ISAC设计的最优性和实用性提供了见解，指导了基于脉冲幅度调制的包络设计。

Abstract: Optical wireless integrated sensing and communication (OW-ISAC) is rapidly
burgeoning as a complement and augmentation to its radio-frequency counterpart.
In this paper, the channel capacity is analyzed to guide the design of a
coherent OW-ISAC system based on frequency-modulated continuous wave (FMCW).
Firstly, the system model of FMCW-based OW-ISAC is recast into an
information-theoretic formulation, where an additional harmonic-mean constraint
is imposed to ensure the sensing performance. Subsequently, both lower and
upper bounds for channel capacity are derived under the imposed sensing
constraint, based on which asymptotic expressions for channel capacity are
presented for both low and high signal-to-noise-ratio regions. Moreover, the
analysis of channel capacity provides guidance for the envelope design based on
pulse amplitude modulation, whose capacity-achieving capabilities are
demonstrated by numerical results. Furthermore, simulations reveal the
trade-off between communication and sensing functionalities. In summary, the
analysis of channel capacity under the sensing constraint provides insights
into both the optimality and the practicality of OW-ISAC design.

</details>


### [13] [Delay-Doppler Pulse Shaping in Zak-OTFS Using Hermite Basis Functions](https://arxiv.org/abs/2510.17466)
*Fathima Jesbin,Ananthanarayanan Chockalingam*

Main category: cs.IT

TL;DR: 提出了一种基于Hermite基函数的系统化DD脉冲设计框架，通过约束优化最小化符号间干扰能量，在Zak-OTFS调制中实现优于传统sinc和高斯脉冲的性能。


<details>
  <summary>Details</summary>
Motivation: Zak-OTFS调制性能高度依赖于DD域脉冲整形滤波器的选择，需要在时间-频率定位性和正交性之间进行权衡，而现有脉冲设计存在局限性。

Method: 将脉冲表示为Hermite基函数的线性组合，通过奇异值分解求解约束优化问题，获得最小化符号间干扰能量的最优系数。

Result: 仿真显示优化脉冲在Vehicular-A信道中显著优于传统sinc和高斯脉冲，与最先进的GS脉冲性能相当，同时提供更好的ISI和旁瓣能量控制灵活性。

Conclusion: 提出的Hermite脉冲设计框架为Zak-OTFS提供了系统化的脉冲设计方法，在保持高性能的同时提供了更大的设计灵活性。

Abstract: The performance of Zak-OTFS modulation is critically dependent on the choice
of the delay-Doppler (DD) domain pulse shaping filter. The design of pulses for
$L^2(\mathbb{R})$ is constrained by the Balian-Low Theorem, which imposes an
inescapable trade-off between time-frequency localization and orthogonality for
spectrally efficient systems. In Zak-OTFS, this trade-off requires balancing
the need for localization for input/output (I/O) relation estimation with the
need for orthogonality for reliable data detection when operating without time
or bandwidth expansion. The well-known sinc and Gaussian pulse shapes represent
the canonical extremes of this trade-off, while composite constructions such as
the Gaussian-sinc (GS) pulse shape offer a good compromise. In this work, we
propose a systematic DD pulse design framework for Zak-OTFS that expresses the
pulse as a linear combination of Hermite basis functions. We obtain the optimal
coefficients for the Hermite basis functions that minimize the inter-symbol
interference (ISI) energy at the DD sampling points by solving a constrained
optimization problem via singular value decomposition. For the proposed class
of Hermite pulses, we derive closed-form expressions for the I/O relation and
noise covariance in Zak-OTFS. Simulation results of Zak-OTFS with embedded
pilot and model-free I/O relation estimation in Vehicular-A channels with
fractional DDs demonstrate that the optimized pulse shape achieves a bit error
rate performance that is significantly superior compared to those of the
canonical sinc and Gaussian pulses and is on par with that of the
state-of-the-art GS pulse, validating the proposed framework which provides
greater design flexibility in terms of control of ISI and sidelobe energies.

</details>


### [14] [Multihead Finite-State Compression](https://arxiv.org/abs/2510.17544)
*Neil Lutz*

Main category: cs.IT

TL;DR: 本文发展了多头有限状态压缩模型，作为有限状态压缩的推广。主要定理证明对于任意序列和正整数h，h头有限状态无损压缩器达到的压缩比率下确界等于该序列的h头有限状态预测维数。


<details>
  <summary>Details</summary>
Motivation: 推广有限状态压缩模型，引入多头有限状态压缩器，研究其在序列压缩中的性能极限，与多头有限状态维度理论形成互补。

Method: 使用具有恒定数量有限状态读头的压缩器模型，读头在序列中向前移动，基于读取的符号按照有限状态规则产生输出。

Result: 建立了主要定理：对于任意序列和正整数h，h头有限状态无损压缩器达到的压缩比率下确界等于该序列的h头有限状态预测维数。

Conclusion: 多头有限状态压缩模型的理论分析表明，压缩性能的极限由序列的多头有限状态预测维数决定，为序列压缩提供了新的理论框架。

Abstract: This paper develops multihead finite-state compression, a generalization of
finite-state compression, complementary to the multihead finite-state
dimensions of Huang, Li, Lutz, and Lutz (2025). In this model, an infinite
sequence of symbols is compressed by a compressor that produces outputs
according to finite-state rules, based on the symbols read by a constant number
of finite-state read heads moving forward obliviously through the sequence. The
main theorem of this work establishes that for every sequence and every
positive integer $h$, the infimum of the compression ratios achieved by
$h$-head finite-state information-lossless compressors equals the $h$-head
finite-state predimension of the sequence. As an immediate corollary, the
infimum of these ratios over all $h$ is the multihead finite-state dimension of
the sequence.

</details>


### [15] [Mode Switching-based STAR-RIS with Discrete Phase Shifters](https://arxiv.org/abs/2510.17613)
*MohammadHossein Alishahi,Ming Zeng,Paul Fortier,Ji Wang,Nian Xia,Gongpu Wang*

Main category: cs.IT

TL;DR: 提出了一种用于6G物联网系统的模式切换离散相位移相器STAR-RIS辅助多天线接入点网络的联合优化方法，以实现和速率最大化。


<details>
  <summary>Details</summary>
Motivation: 6G网络对成本效益高、高速物联网应用的需求日益增长，需要提高频谱效率并简化硬件设计。

Method: 采用混合整数非线性优化框架，使用块坐标下降法将问题分解为三个子问题，结合差凸规划和组合优化技术求解。

Result: 数值结果表明所提出的联合优化方法在总和速率性能上优于部分优化方法。

Conclusion: 该方法在高效和可扩展的6G物联网系统中具有潜力。

Abstract: The increasing demand for cost-effective, high-speed Internet of Things (IoT)
applications in the coming sixth-generation (6G) networks has driven research
toward maximizing spectral efficiency and simplifying hardware designs. In this
context, we investigate the sum rate maximization problem for a mode-switching
discrete-phase shifters simultaneously transmitting and reflecting
reconfigurable intelligent surface (STAR-RIS)-aided multi-antenna access point
network, emphasizing hardware efficiency and reduced cost. A mixed-integer
nonlinear optimization framework is formulated for joint optimization of the
active beamforming matrix, user power allocation, and STAR-RIS phase shift
vectors, including binary transmission/reflection amplitudes and discrete phase
shifters. To solve the formulated problem, we employ a block coordinate descent
method, dividing it into three subproblems tackled using difference-of-concave
programming and combinatorial optimization techniques. Numerical results
validate the effectiveness of the proposed joint optimization approach,
consistently achieving superior sum rate performance compared to partial
optimization methods, thereby underscoring its potential for efficient and
scalable 6G IoT systems.

</details>


### [16] [Space-Time Rate-Splitting Multiple Access for Multibeam LEO Satellite Networks](https://arxiv.org/abs/2510.17625)
*Jaehyup Seong,Byungju Lee,Aryan Kaushik,Wonjae Shin*

Main category: cs.IT

TL;DR: 提出了一种新颖的时空速率分割多址(ST-RSMA)框架，用于多波束低轨卫星通信系统，通过在公共流传输中集成空时编码来实现全分集增益。


<details>
  <summary>Details</summary>
Motivation: 克服传统RSMA使用单一波束成形向量带来的性能限制，解决信道状态信息不确定性和网络负载变化条件下的性能问题。

Method: 开发了基于加权最小均方误差(WMMSE)的算法，联合优化公共流的功率分配和私有流的功率/波束成形向量，以最大化最小用户速率。

Result: 数值结果表明ST-RSMA显著优于传统RSMA和其他多址技术。

Conclusion: ST-RSMA为LEO卫星通信提供了稳健且可扩展的解决方案。

Abstract: This paper proposes a novel space-time rate-splitting multiple access
(ST-RSMA) framework for multibeam low Earth orbit (LEO) satellite
communications (SATCOM) systems, where space-time coding is integrated into the
common stream transmission. This design enables full diversity gain in the
common stream transmission for all users, regardless of the uncertainty of the
channel state information (CSI) and network load conditions, thereby overcoming
the performance limitations of conventional RSMA that employs a single
beamforming vector for all users. To further enhance performance, we develop a
weighted minimum mean square error (WMMSE)-based algorithm tailored to ST-RSMA
that jointly optimizes the power allocation for the common stream and the
power/beamforming vectors for private streams, aiming to maximize the minimum
user rate. Numerical results show that ST-RSMA significantly outperforms
conventional RSMA and other multiple access techniques, offering a robust and
scalable solution for LEO SATCOM.

</details>


### [17] [On the Capacity of Erasure-prone Quantum Storage with Erasure-prone Entanglement Assistance](https://arxiv.org/abs/2510.17781)
*Hua Sun,Syed A. Jafar*

Main category: cs.IT

TL;DR: 该论文研究了在存储节点和纠缠辅助节点都存在擦除风险的情况下，量子消息的分布式存储容量问题。通过引入经典的存储问题作为关键工具，论文在大多数情况下完全刻画了容量与系统参数的关系，仅在一个特定情况下容量仍待解决。


<details>
  <summary>Details</summary>
Motivation: 研究在量子存储系统中，当存储节点和纠缠辅助节点都可能发生擦除时，如何设计编码方案以确保量子消息的可恢复性，并确定系统的最大存储容量。

Method: 引入了一个类似的经典存储问题作为关键工具，识别了一组约束条件，使得经典线性码构造可以转化为量子存储码，并且两个设置的反向界限利用了相似的见解。

Result: 在大多数情况下完全刻画了容量与系统参数N、K、N_B、K_B、λ_B的函数关系，仅在一个中间范围的λ_B值情况下（当N个存储节点中的严格多数和N_B个EA节点中的严格非零少数被擦除时）容量仍待解决。

Conclusion: 经典和量子设置的容量刻画在所有容量已确定的情况下是相同的，这证明了经典编码理论在量子存储问题中的适用性。

Abstract: A quantum message is encoded into $N$ storage nodes (quantum systems
$Q_1\dots Q_N$) with assistance from $N_B$ maximally entangled bi-partite
quantum systems $A_1B_1, \dots, A_{N_B}B_{N_B}$, that are prepared in advance
such that $B_1\dots B_{N_B}$ are stored separately as entanglement assistance
(EA) nodes, while $A_1\dots A_{N_B}$ are made available to the encoder. Both
the storage nodes and EA nodes are erasure-prone. The quantum message must be
recoverable given any $K$ of the $N$ storage nodes along with any $K_B$ of the
$N_B$ EA nodes. The capacity for this setting is the maximum size of the
quantum message, given that the size of each EA node is $\lambda_B$. All node
sizes are relative to the size of a storage node, which is normalized to unity.
The exact capacity is characterized as a function of $N,K,N_B,K_B, \lambda_B$
in all cases, with one exception. The capacity remains open for an intermediate
range of $\lambda_B$ values when a strict majority of the $N$ storage nodes,
and a strict non-zero minority of the $N_B$ EA nodes, are erased. As a key
stepping stone, an analogous classical storage (with shared-randomness
assistance) problem is introduced. A set of constraints is identified for the
classical problem, such that classical linear code constructions translate to
quantum storage codes, and the converse bounds for the two settings utilize
similar insights. In particular, the capacity characterizations for the
classical and quantum settings are shown to be identical in all cases where the
capacity is settled.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [18] [Unified Peripartum Database with Natural-Language-to-SQL Capabilities at Udine University Hospital: Design and Prototype](https://arxiv.org/abs/2510.16388)
*Doriana Armenise,Ginevra Battello,Andrea Brunello,Lorenza Driul,Angelo Montanari,Elisa Rizzante,Nicola Saccomanno,Andrea Salvador,Serena Xodo,Silvia Zermano*

Main category: cs.DB

TL;DR: 提出一个统一围产期关系数据库蓝图，整合产科电子病历、设备存储库和实验室系统的异构数据，并配备自然语言转SQL功能，以改善产科护理和可重复研究。


<details>
  <summary>Details</summary>
Motivation: 产科信息分散在不同电子病历模块、设备存储库和实验室系统中，阻碍了产时护理和可重复研究。

Method: 与临床医生共同定义需求，设计实体关系图，推导逻辑模式和SQL实现，整合异构数据源，并开发自然语言转SQL功能。

Result: 成功在乌迪内大学医院产科诊所原型实现了统一围产期关系数据库，能够连接产妇病史、当前妊娠发现、产时过程和分娩新生儿结局。

Conclusion: 该数据库系统通过整合异构围产期记录并配备自然语言查询功能，有效降低了临床审核和探索性分析的门槛。

Abstract: The fragmentation of obstetric information across electronic health record
modules, device repositories, and laboratory systems, as it is common in
hospitals, hinders both intrapartum care and reproducible research. In this
work, we present a practical blueprint for transforming heterogeneous
peripartum records into computable, queryable assets by designing and
prototyping a unified peripartum relational database with
natural-language-to-SQL (NL2SQL) capabilities at the Obstetrics Clinic of Udine
University Hospital. Requirements were co-defined with clinicians and
formalized as an Entity-Relationship diagram, from which the logical schema and
SQL implementation of the database were then derived. The latter integrates
heterogeneous sources to connect maternal anamnestic and longitudinal history,
current-pregnancy findings, intrapartum course, and delivery and neonatal
outcomes. The NL2SQL layer enables clinicians to pose natural-language queries
to the system, lowering barriers to audit and exploratory analysis.

</details>


### [19] [Declarative Techniques for NL Queries over Heterogeneous Data](https://arxiv.org/abs/2510.16470)
*Elham Khabiri,Jeffrey O. Kephart,Fenno F. Heath III,Srideepika Jayaraman,Fateh A. Tipu,Yingjie Li,Dhruv Shah,Achille Fokoue,Anu Bhamidipaty*

Main category: cs.DB

TL;DR: 本文提出了处理工业环境中数据源异构性的声明式方法，通过扩展Spider基准数据集来模拟真实场景，证明该方法优于现有的LLM代理系统。


<details>
  <summary>Details</summary>
Motivation: 在工业环境中，用户希望通过自然语言查询需要整合多种结构化数据源的信息，但现有LLM应用无法有效处理数据源异构性问题。

Method: 引入两个扩展的Spider基准数据集，模拟工业环境中的数据异构性，并提出声明式方法来处理数据库和API调用的组合。

Result: 实验表明，声明式方法在处理数据源异构性方面显著优于最先进的基于LLM的代理或命令式代码生成系统。

Conclusion: 提出的声明式方法能有效应对工业环境中的数据异构性挑战，扩展的基准数据集已向研究社区开放。

Abstract: In many industrial settings, users wish to ask questions in natural language,
the answers to which require assembling information from diverse structured
data sources. With the advent of Large Language Models (LLMs), applications can
now translate natural language questions into a set of API calls or database
calls, execute them, and combine the results into an appropriate natural
language response. However, these applications remain impractical in realistic
industrial settings because they do not cope with the data source heterogeneity
that typifies such environments. In this work, we simulate the heterogeneity of
real industry settings by introducing two extensions of the popular Spider
benchmark dataset that require a combination of database and API calls. Then,
we introduce a declarative approach to handling such data heterogeneity and
demonstrate that it copes with data source heterogeneity significantly better
than state-of-the-art LLM-based agentic or imperative code generation systems.
Our augmented benchmarks are available to the research community.

</details>


### [20] [AVOCADO: The Streaming Process Mining Challenge](https://arxiv.org/abs/2510.17089)
*Christian Imenkamp,Andrea Maldonado,Hendrik Reiter,Martin Werner,Wilhelm Hasselbring,Agnes Koschmider,Andrea Burattin*

Main category: cs.DB

TL;DR: 提出了AVOCADO框架，这是一个用于流式流程挖掘算法评估的标准化挑战框架，通过分离概念层和实例层来系统化处理流式数据复杂性。


<details>
  <summary>Details</summary>
Motivation: 流式流程挖掘需要能够增量处理数据的算法，但该领域缺乏系统化的评估标准来应对流式数据的复杂性。

Method: 设计AVOCADO框架，提供清晰的结构划分：分离流式流程挖掘挑战的概念层和实例层，评估算法在准确性、MAE、RMSE、处理延迟和鲁棒性等流式特定指标上的表现。

Result: 建立了一个标准化的挑战框架，能够系统评估流式流程挖掘算法的性能，并促进该领域的创新和社区讨论。

Conclusion: AVOCADO框架为流式流程挖掘领域提供了基础评估标准，邀请社区贡献新挑战，如集成系统吞吐量和内存消耗指标，扩展以处理现实世界流复杂性（如乱序事件到达）。

Abstract: Streaming process mining deals with the real-time analysis of streaming data.
Event streams require algorithms capable of processing data incrementally. To
systematically address the complexities of this domain, we propose AVOCADO, a
standardized challenge framework that provides clear structural divisions:
separating the concept and instantiation layers of challenges in streaming
process mining for algorithm evaluation. The AVOCADO evaluates algorithms on
streaming-specific metrics like accuracy, Mean Absolute Error (MAE), Root Mean
Square Error (RMSE), Processing Latency, and robustness. This initiative seeks
to foster innovation and community-driven discussions to advance the field of
streaming process mining. We present this framework as a foundation and invite
the community to contribute to its evolution by suggesting new challenges, such
as integrating metrics for system throughput and memory consumption, and
expanding the scope to address real-world stream complexities like out-of-order
event arrival.

</details>


### [21] [Comprehending Spatio-temporal Data via Cinematic Storytelling using Large Language Models](https://arxiv.org/abs/2510.17301)
*Panos Kalnis. Shuo Shang,Christian S. Jensen*

Main category: cs.DB

TL;DR: MapMuse是一个基于故事叙述的框架，用于解释时空数据集，将其转化为引人入胜的叙事驱动体验，使用LLM和RAG技术生成全面故事。


<details>
  <summary>Details</summary>
Motivation: 传统时空数据可视化复杂且需要专业知识，难以引起广泛受众共鸣，需要更有效的沟通工具。

Method: 利用大语言模型、检索增强生成和基于代理的技术，借鉴电影叙事原则，强调清晰度、情感连接和以受众为中心的设计。

Result: 通过出租车轨迹案例研究展示了两种视角：基于热图揭示城市移动模式的故事，以及跟随单个长途出租车旅程的详细叙事。

Conclusion: 数据故事叙述能够从时空信息中驱动洞察、参与度和行动，MapMuse能够弥合数据复杂性与人类理解之间的差距。

Abstract: Spatio-temporal data captures complex dynamics across both space and time,
yet traditional visualizations are complex, require domain expertise and often
fail to resonate with broader audiences. Here, we propose MapMuse, a
storytelling-based framework for interpreting spatio-temporal datasets,
transforming them into compelling, narrative-driven experiences. We utilize
large language models and employ retrieval augmented generation (RAG) and
agent-based techniques to generate comprehensive stories. Drawing on principles
common in cinematic storytelling, we emphasize clarity, emotional connection,
and audience-centric design. As a case study, we analyze a dataset of taxi
trajectories. Two perspectives are presented: a captivating story based on a
heat map that visualizes millions of taxi trip endpoints to uncover urban
mobility patterns; and a detailed narrative following a single long taxi
journey, enriched with city landmarks and temporal shifts. By portraying
locations as characters and movement as plot, we argue that data storytelling
drives insight, engagement, and action from spatio-temporal information. The
case study illustrates how MapMuse can bridge the gap between data complexity
and human understanding. The aim of this short paper is to provide a glimpse to
the potential of the cinematic storytelling technique as an effective
communication tool for spatio-temporal data, as well as to describe open
problems and opportunities for future research.

</details>


### [22] [Approximate Nearest Neighbor Search of Large Scale Vectors on Distributed Storage](https://arxiv.org/abs/2510.17326)
*Kun Yu,Jiabao Jin,Xiaoyao Zhong,Peng Cheng,Lei Chen,Zhitao Shen,Jingkuan Song,Hengtao Shen,Xuemin Lin*

Main category: cs.DB

TL;DR: DSANN是一个支持分布式存储的近似最近邻搜索系统，通过图-聚类混合索引方法在分布式存储中高效索引、存储和搜索十亿级向量数据库。


<details>
  <summary>Details</summary>
Motivation: 现有ANNS算法需要将索引存储在单机内存或磁盘中，存在存储成本高、规模受限和单点故障问题，而分布式存储缺乏高效有效的向量索引算法。

Method: 采用并发索引构建方法降低索引构建复杂度，使用点聚合图利用图结构信息聚合相似向量，通过异步I/O优化存储效率和查询吞吐量。

Result: 实验表明DSANN能够在分布式存储场景下高效有效地索引、存储和搜索大规模向量数据集。

Conclusion: DSANN为分布式存储环境中的大规模向量搜索提供了高效可靠的解决方案，解决了现有方法的存储限制和可用性问题。

Abstract: Approximate Nearest Neighbor Search (ANNS) in high-dimensional space is an
essential operator in many online services, such as information retrieval and
recommendation. Indices constructed by the state-of-the-art ANNS algorithms
must be stored in single machine's memory or disk for high recall rate and
throughput, suffering from substantial storage cost, constraint of limited
scale and single point of failure. While distributed storage can provide a
cost-effective and robust solution, there is no efficient and effective
algorithms for indexing vectors in distributed storage scenarios. In this
paper, we present a new graph-cluster hybrid indexing and search system which
supports Distributed Storage Approximate Nearest Neighbor Search, called DSANN.
DSANN can efficiently index, store, search billion-scale vector database in
distributed storage and guarantee the high availability of index service. DSANN
employs the concurrent index construction method to significantly reduces the
complexity of index building. Then, DSANN applies Point Aggregation Graph to
leverage the structural information of graph to aggregate similar vectors,
optimizing storage efficiency and improving query throughput via asynchronous
I/O in distributed storage. Through extensive experiments, we demonstrate DSANN
can efficiently and effectively index, store and search large-scale vector
datasets in distributed storage scenarios.

</details>


### [23] [DeepEye-SQL: A Software-Engineering-Inspired Text-to-SQL Framework](https://arxiv.org/abs/2510.17586)
*Boyan Li,Chong Chen,Zhujun Xue,Yinan Mei,Yuyu Luo*

Main category: cs.DB

TL;DR: DeepEye-SQL是一个受软件工程启发的Text-to-SQL框架，将SQL查询生成重新定义为软件开发过程，通过SDLC指导的可验证流程实现系统级可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL解决方案在系统级可靠性方面存在不足，问题不仅在于单个模块，更关键的是缺乏结构化编排来确保整个工作流程的正确性。

Method: 采用软件开发生命周期(SDLC)方法，包含四个协同阶段：语义值检索和模式链接、使用多样化推理范式的N版本SQL生成、单元测试和LLM引导修订的确定性验证、基于置信度的选择和裁决。

Result: 使用约300亿参数的开源LLM且无需微调，在BIRD-Dev上达到73.5%执行准确率，在Spider-Test上达到89.8%，优于最先进解决方案。

Conclusion: 原则性编排而非单纯的LLM扩展是实现Text-to-SQL系统级可靠性的关键。

Abstract: Large language models (LLMs) have advanced Text-to-SQL, yet existing
solutions still fall short of system-level reliability. The limitation is not
merely in individual modules - e.g., schema linking, reasoning, and
verification - but more critically in the lack of structured orchestration that
enforces correctness across the entire workflow. This gap motivates a paradigm
shift: treating Text-to-SQL not as free-form language generation but as a
software-engineering problem that demands structured, verifiable orchestration.
We present DeepEye-SQL, a software-engineering-inspired framework that reframes
Text-to-SQL as the development of a small software program, executed through a
verifiable process guided by the Software Development Life Cycle (SDLC).
DeepEye-SQL integrates four synergistic stages: it grounds ambiguous user
intent through semantic value retrieval and robust schema linking; enhances
fault tolerance with N-version SQL generation using diverse reasoning
paradigms; ensures deterministic verification via a tool-chain of unit tests
and targeted LLM-guided revision; and introduces confidence-aware selection
that clusters execution results to estimate confidence and then takes a
high-confidence shortcut or runs unbalanced pairwise adjudication in
low-confidence cases, yielding a calibrated, quality-gated output. This
SDLC-aligned workflow transforms ad hoc query generation into a disciplined
engineering process. Using ~30B open-source LLMs without any fine-tuning,
DeepEye-SQL achieves 73.5% execution accuracy on BIRD-Dev and 89.8% on
Spider-Test, outperforming state-of-the-art solutions. This highlights that
principled orchestration, rather than LLM scaling alone, is key to achieving
system-level reliability in Text-to-SQL.

</details>


### [24] [This is Going to Sound Crazy, But What If We Used Large Language Models to Boost Automatic Database Tuning Algorithms By Leveraging Prior History? We Will Find Better Configurations More Quickly Than Retraining From Scratch!](https://arxiv.org/abs/2510.17748)
*William Zhang,Wan Shen Lim,Andrew Pavlo*

Main category: cs.DB

TL;DR: Booster框架通过利用查询级别的历史洞察，帮助现有数据库调优器适应环境变化（如工作负载漂移、模式迁移），使用LLM生成查询级配置建议并通过波束搜索组合成整体配置。


<details>
  <summary>Details</summary>
Motivation: 现有自动调优器难以适应环境变化，因为它们的设计无法利用查询级别的历史洞察，导致在环境变化时重新优化DBMS效率低下。

Method: 将历史工件结构化为查询-配置上下文，使用LLM为每个查询生成配置建议，然后通过波束搜索将这些查询级建议组合成整体配置。

Result: 在多个OLAP工作负载上，Booster帮助不同调优器发现比传统方法快4.7倍、性能提升74%的配置。

Conclusion: Booster框架通过查询级洞察的组合，显著提升了数据库调优器在环境变化下的适应能力和效率。

Abstract: Tuning database management systems (DBMSs) is challenging due to trillions of
possible configurations and evolving workloads. Recent advances in tuning have
led to breakthroughs in optimizing over the possible configurations. However,
due to their design and inability to leverage query-level historical insights,
existing automated tuners struggle to adapt and re-optimize the DBMS when the
environment changes (e.g., workload drift, schema transfer).
  This paper presents the Booster framework that assists existing tuners in
adapting to environment changes (e.g., drift, cross-schema transfer). Booster
structures historical artifacts into query-configuration contexts, prompts
large language models (LLMs) to suggest configurations for each query based on
relevant contexts, and then composes the query-level suggestions into a
holistic configuration with beam search. With multiple OLAP workloads, we
evaluate Booster's ability to assist different state-of-the-art tuners (e.g.,
cost-/machine learning-/LLM-based) in adapting to environment changes. By
composing recommendations derived from query-level insights, Booster assists
tuners in discovering configurations that are up to 74% better and in up to
4.7x less time than the alternative approach of continuing to tune from
historical configurations.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [25] [Is Zadeh's Least-Entered Pivot Rule Exponential?](https://arxiv.org/abs/2510.16055)
*Norman Zadeh*

Main category: cs.DS

TL;DR: 本文反驳了Friedmann等人关于Zadeh最小进入规则在最坏情况下需要指数级枢轴变换的论断，指出其构造存在多个缺陷，未能提供有效的反例。


<details>
  <summary>Details</summary>
Motivation: 针对Friedmann等人声称Zadeh最小进入规则在最坏情况下需要指数级枢轴变换的论断进行反驳，证明其论证存在根本性错误。

Method: 分析Friedmann等人提出的病态线性规划构造，指出其约束条件存在三个主要缺陷：退出概率大于进入概率、某些节点退出概率超过1、忽略决策节点间的流动。

Result: 作者提供的首批病态线性规划要么不可行，要么与对应的马尔可夫决策过程不匹配，未能证明最小进入规则的最坏情况行为。

Conclusion: Zadeh最小进入规则的最坏情况行为尚未被证明，Friedmann等人的反例构造存在根本性数学错误。

Abstract: In 2011, Friedmann [F 7] claimed to have proved that pathological linear
programs existed for which the Simplex method using Zadeh's least-entered rule
[Z 14] would take an exponential number of pivots. In 2019, Disser and Hopp [DH
5] argued that there were errors in Friedmann's 2011 construction. In 2020,
Disser, Friedmann, and Hopp [DFH 3,4] again contended that the least-entered
rule was exponential. We show that their arguments contain multiple flaws. In
other words, the worst-case behavior of the least-entered rule has not been
established. Neither [F 7] nor [DFH 3,4] provides pathological linear programs
that can be tested. Instead, the authors contend that their pathological linear
programs are of the form (P) as shown on page 12 of [DFH 3]. The authors
contend that the constraints of (P) ensure that the probability of entering a
vertex u is equal to the probability of exiting u. In fact, we note that the
authors' constraints (P) are flawed in at least three ways: a) they require the
probability of exiting u to exceed the probability of entering u, b) they
require the probability of exiting some nodes to exceed 1, and c) they overlook
flows from decision nodes to decision nodes. At my request, in August of 2025,
Disser, Friedmann, and Hopp provided me with their first ten purportedly
pathological LPs and the graph of their first purportedly pathological Markov
Decision Process (MDP1). It is shown that: a) their first two pathological LPs
are infeasible if the variables are supposed to be probabilities, as the
authors contend, and b) their first purportedly pathological LP does not match
up with their first purportedly pathological MDP. In other words, the authors
have not come close to providing counterexamples to the least-entered rule.

</details>


### [26] [Near-linear time subhypergraph counting in bounded degeneracy hypergraphs](https://arxiv.org/abs/2510.16330)
*Daniel Paul-Pena,C. Seshadhri*

Main category: cs.DS

TL;DR: 该论文研究了在具有有界退化性的超图中计算小模式出现次数的问题，提出了超图退化性的多种定义，并精确刻画了哪些模式可以在(近)线性时间内计数。


<details>
  <summary>Details</summary>
Motivation: 随着理论和实践中对超图算法的兴趣增长，需要研究在超图中计算模式出现次数的高效算法。受图算法进展的启发，作者探索在具有有界退化性的超图中实现线性时间算法的条件。

Method: 提出了覆盖所有现有概念的超图退化性定义谱系。对于每种定义，通过发现一组"障碍模式"来精确刻画可计数模式：如果H不包含障碍，则可以在O(n log n)时间内精确计数；如果包含障碍，则假设精细复杂度猜想，不存在o(n^{1+γ})时间算法。

Result: 发现了障碍模式集合，这些集合可以针对所有超图退化性概念进行定义。对于不包含障碍的模式H，可以在O(n log n)时间内精确计数H-子超图的数量；对于包含障碍的模式，则不存在亚多项式时间算法。

Conclusion: 该工作为超图模式计数提供了完整的复杂性分类，建立了退化性概念与计算复杂性之间的精确对应关系，为超图算法设计提供了理论基础。

Abstract: Counting small patterns in a large dataset is a fundamental algorithmic task.
The most common version of this task is subgraph/homomorphism counting, wherein
we count the number of occurrences of a small pattern graph $H$ in an input
graph $G$. The study of this problem is a field in and of itself. Recently,
both in theory and practice, there has been an interest in \emph{hypergraph}
algorithms, where $G = (V,E)$ is a hypergraph. One can view $G$ as a set system
where hyperedges are subsets of the universe $V$.
  Counting patterns $H$ in hypergraphs is less studied, although there are many
applications in network science and database algorithms. Inspired by advances
in the graph literature, we study when linear time algorithms are possible.
  We focus on input hypergraphs $G$ that have bounded \emph{degeneracy}, a
well-studied concept for graph algorithms. We give a spectrum of definitions
for hypergraph degeneracy that cover all existing notions. For each such
definition, we give a precise characterization of the patterns $H$ that can be
counted in (near) linear time. Specifically, we discover a set of ``obstruction
patterns". If $H$ does not contain an obstruction, then the number of
$H$-subhypergraphs can be counted exactly in $O(n\log n)$ time (where $n$ is
the number of vertices in $G$). If $H$ contains an obstruction, then (assuming
hypergraph variants of fine-grained complexity conjectures), there is a
constant $\gamma > 0$, such that there is no $o(n^{1+\gamma})$ time algorithm
for counting $H$-subhypergraphs. These sets of obstructions can be defined for
all notions of hypergraph degeneracy.

</details>


### [27] [A (Very) Nearly Optimal Sketch for $k$-Edge Connectivity Certificates](https://arxiv.org/abs/2510.16336)
*Pachara Sawettamalya,Huacheng Yu*

Main category: cs.DS

TL;DR: 提出了一种在动态图流中计算k连通性证书的简单算法，空间复杂度为O(n log²n · max{k, log n log k})，改进了之前的工作。


<details>
  <summary>Details</summary>
Motivation: 改进Ahn等人提出的k连通性证书算法，降低空间复杂度，使其更接近已知下界。

Method: 设计了一个简单的算法，在动态图流中计算k连通性证书，优化空间使用。

Result: 算法空间复杂度为O(n log²n · max{k, log n log k})，对于k=Ω(log n log log n)时达到最优Θ(kn log²n)，对于较小的k值仅差一个双对数因子。

Conclusion: 该算法在k连通性证书计算问题上取得了接近最优的空间复杂度，特别是对于较大的k值完全解决了空间复杂度问题。

Abstract: In this note, we present a simple algorithm for computing a
\emph{$k$-connectivity certificate} in dynamic graph streams. Our algorithm
uses $O(n \log^2 n \cdot \max\{k, \log n \log k\})$ bits of space which
improves upon the $O(kn \log^3 n)$-space algorithm of Ahn, Guha, and McGregor
(SODA'12). For the values of $k$ that are truly sublinear, our space usage
\emph{very nearly} matches the known lower bound $\Omega(n \log^2 n \cdot
\max\{k, \log n\})$ established by Nelson and Yu (SODA'19; implicit) and
Robinson (DISC'24). In particular, our algorithm fully settles the space
complexity at $\Theta(kn \log^2{n})$ for $k = \Omega(\log n \log \log n)$, and
bridges the gap down to only a doubly-logarithmic factor of $O(\log \log n)$
for a smaller range of $k = o(\log n \log \log n)$.

</details>


### [28] [Truly Subquadratic Time Algorithms for Diameter and Related Problems in Graphs of Bounded VC-dimension](https://arxiv.org/abs/2510.16346)
*Timothy M. Chan,Hsien-Chih Chang,Jie Gao,Sándor Kisfaludi-Bak,Hung Le,Da Wei Zheng*

Main category: cs.DS

TL;DR: 提出了首个真正次二次时间算法（O*(n^{2-1/18})）来计算单位圆盘图的直径，解决了文献中的核心开放问题。该框架适用于不同图族和距离问题，绕过了传统的子线性分隔器方法。


<details>
  <summary>Details</summary>
Motivation: 解决单位圆盘图直径计算的核心开放问题，为不同图族和距离问题提供统一的次二次时间算法框架。

Method: 使用基本形式的低直径分解，利用输入图相关集合系统的有界VC维数，以及新的几何数据结构思想。完全绕过了传统算法中使用的子线性分隔器或r-divisions。

Result: 1. 对VC维数为d的稀疏无权图，得到O~(mn^{1-1/(2d)})时间算法；2. 对任意大小的轴对齐正方形交集图，得到O~(n^{2-1/12})时间算法；3. 首次为其他距离相关问题提供真正次二次复杂度算法。

Conclusion: 提出了一个通用框架，首次为多个图族和距离问题提供了真正次二次时间算法，特别是解决了单位圆盘图直径计算这一长期开放问题。

Abstract: We give the first truly subquadratic time algorithm, with $O^*(n^{2-1/18})$
running time, for computing the diameter of an $n$-vertex unit-disk graph,
resolving a central open problem in the literature. Our result is obtained as
an instance of a general framework, applicable to different graph families and
distance problems. Surprisingly, our framework completely bypasses sublinear
separators (or $r$-divisions) which were used in all previous algorithms.
Instead, we use low-diameter decompositions in their most elementary form. We
also exploit bounded VC-dimension of set systems associated with the input
graph, as well as new ideas on geometric data structures. Among the numerous
applications of the general framework, we obtain:
  1. An $\tilde{O}(mn^{1-1/(2d)})$ time algorithm for computing the diameter of
$m$-edge sparse unweighted graphs with constant VC-dimension $d$. The
previously known algorithms by Ducoffe, Habib, and Viennot [SODA 2019] and
Duraj, Konieczny, and Pot\c{e}pa [ESA 2024] are truly subquadratic only when
the diameter is a small polynomial. Our result thus generalizes truly
subquadratic time algorithms known for planar and minor-free graphs (in fact,
it slightly improves the previous time bound for minor-free graphs).
  2. An $\tilde{O}(n^{2-1/12})$ time algorithm for computing the diameter of
intersection graphs of axis-aligned squares with arbitrary size. The best-known
algorithm by Duraj, Konieczny, and Pot\c{e}pa [ESA 2024] only works for unit
squares and is only truly subquadratic in the low-diameter regime.
  3. The first algorithms with truly subquadratic complexity for other
distance-related problems, including all-vertex eccentricities, Wiener index,
and exact distance oracles. (... truncated to meet the arXiv abstract
requirement.)

</details>


### [29] [Trading Prophets with Initial Capital](https://arxiv.org/abs/2510.16516)
*Yossi Azar,Niv Buchbinder,Roie Levin,Or Vardi*

Main category: cs.DS

TL;DR: 本文研究了带有初始资本的交易先知问题，证明了3的竞争比是最优的，并进一步考虑了包含交易成本的更现实模型。


<details>
  <summary>Details</summary>
Motivation: Correa等人[EC'2023]提出的交易先知问题中，在无初始资本的情况下无法与知晓所有未来价格的先知竞争。本文探索了当交易者拥有初始资本时的情况。

Method: 研究带有初始资本的交易先知问题，分析交易者在知晓价格分布的情况下与全知先知的竞争关系，并考虑包含乘性和加性交易成本的更现实模型。

Result: 证明初始资本足以绕过不可能性结果，获得相对于全知先知（也拥有资本）的竞争比为3，且该竞争比是最优的。

Conclusion: 初始资本是解决交易先知问题的关键因素，能够在交易成本存在的情况下实现有意义的竞争性能。

Abstract: Correa et al. [EC' 2023] introduced the following trading prophets problem. A
trader observes a sequence of stochastic prices for a stock, each drawn from a
known distribution, and at each time must decide whether to buy or sell.
Unfortunately, they observed that in this setting it is impossible to compete
with a prophet who knows all future stock prices.
  In this paper, we explore the trading prophets problem when we are given
initial capital with which to start trading. We show that initial capital is
enough to bypass the impossibility result and obtain a competitive ratio of $3$
with respect to a prophet who knows all future prices (and who also starts with
capital), and we show that this competitive ratio is best possible. We further
study a more realistic model in which the trader must pay multiplicative and/or
additive transaction costs for trading which model dynamics such as bid-ask
spreads and broker fees.

</details>


### [30] [Tight Pair Query Lower Bounds for Matching and Earth Mover's Distance](https://arxiv.org/abs/2510.16351)
*Amir Azarmehr,Soheil Behnezhad,Mohammad Roghani,Aviad Rubinstein*

Main category: cs.DS

TL;DR: 本文研究了估算n顶点图最大匹配大小所需的邻接矩阵查询数量，证明了[BKS'23]算法的查询复杂度下界为Ω(n^{2-δ})，表明该算法是最优的。


<details>
  <summary>Details</summary>
Motivation: 现有研究在邻接矩阵查询模型下，最大匹配大小估算的上界为n^{2-Ω_ε(1)}，而下界仅为Ω(n)，存在巨大差距。本文旨在填补这一理论空白。

Method: 通过理论分析，证明了对于任意固定δ>0，存在固定ε>0，使得获得εn精度内的最大匹配大小估算需要Ω(n^{2-δ})次邻接矩阵查询。

Result: 建立了首个超线性的下界，完全填补了[BKS'23]算法复杂度分析的理论空白，证明了该算法的最优性。

Conclusion: 该下界结果不仅解决了最大匹配估算的查询复杂度问题，还对地球移动距离估算等问题的算法改进可能性给出了否定答案。

Abstract: How many adjacency matrix queries (also known as pair queries) are required
to estimate the size of a maximum matching in an $n$-vertex graph $G$? We study
this fundamental question in this paper.
  On the upper bound side, an algorithm of Bhattacharya, Kiss, and Saranurak
[FOCS'23] gives an estimate that is within $\epsilon n$ of the right bound with
$n^{2-\Omega_\epsilon(1)}$ queries, which is subquadratic in $n$ (and thus
sublinear in the matrix size) for any fixed $\epsilon > 0$. On the lower bound
side, while there has been a lot of progress in the adjacency list model, no
non-trivial lower bound has been established for algorithms with adjacency
matrix query access. In particular, the only known lower bound is a folklore
bound of $\Omega(n)$, leaving a huge gap.
  In this paper, we present the first superlinear in $n$ lower bound for this
problem. In fact, we close the gap mentioned above entirely by showing that the
algorithm of [BKS'23] is optimal. Formally, we prove that for any fixed $\delta
> 0$, there is a fixed $\epsilon > 0$ such that an estimate that is within
$\epsilon n$ of the true bound requires $\Omega(n^{2-\delta})$ adjacency matrix
queries.
  Our lower bound also has strong implications for estimating the earth mover's
distance between distributions. For this problem, Beretta and Rubinstein
[STOC'24] gave an $n^{2-\Omega_\epsilon(1)}$ time algorithm that obtains an
additive $\epsilon$-approximation and works for any distance function. Whether
this can be improved generally, or even for metric spaces, had remained open.
Our lower bound rules out the possibility of any improvements over this bound,
even under the strong assumption that the underlying distances are in a (1,
2)-metric.

</details>


### [31] [Online computation of normalized substring complexity](https://arxiv.org/abs/2510.16454)
*Gregory Kucherov,Yakov Nekrich*

Main category: cs.DS

TL;DR: 提出了两种在线计算字符串归一化子串复杂度δ的算法，分别具有O(log n)摊销时间和O(log³ n)最坏情况时间


<details>
  <summary>Details</summary>
Motivation: 归一化子串复杂度δ与流行的字符串压缩算法有密切关系，需要高效的在线计算方法

Method: 设计了两种在线算法：一种基于摊销分析，另一种保证最坏情况性能，都使用polylog时间处理每个字符

Result: 实现了第一个polylog时间的在线解决方案，能够高效处理流式字符串

Conclusion: 成功解决了在线计算字符串归一化子串复杂度的问题，为流式字符串分析提供了高效工具

Abstract: The normalized substring complexity $\delta$ of a string is defined as
$\max_k \{c[k]/k\}$, where $c[k]$ is the number of \textit{distinct} substrings
of length $k$. This simply defined measure has recently attracted attention due
to its established relationship to popular string compression algorithms. We
consider the problem of computing $\delta$ online, when the string is provided
from a stream. We present two algorithms solving the problem: one working in
$O(\log n)$ amortized time per character, and the other in $O(\log^3 n)$
worst-case time per character. To our knowledge, this is the first polylog-time
online solution to this problem.

</details>


### [32] [Robust Dynamic Staffing with Predictions](https://arxiv.org/abs/2510.16663)
*Yiding Feng,Vahideh Manshadi,Rad Niazadeh,Saba Neyshabouri*

Main category: cs.DS

TL;DR: 本文研究了一个动态人员配置问题，决策者在有限时间内顺序雇佣工人以满足未知需求。预测随时间推移变得更加准确，但工人可用性下降，需要在早期雇佣（工人更多但预测不准）和晚期雇佣（预测更准但工人更少）之间权衡。


<details>
  <summary>Details</summary>
Motivation: 该问题受到最后一英里配送运营的启发，如亚马逊依赖零工经济工人，其可用性在运营日临近时下降。为了克服贝叶斯模型的局限性，研究在对抗性预测下的问题。

Method: 在对抗性预测模型下，顺序预测是包含真实需求的对抗性选择的不确定性区间。目标是使最坏情况下的人员配置不平衡成本最小化。提出了一个简单且计算高效的在线算法。

Result: 主要结果是提出了一个极小极大最优的在线算法。通过多项式大小的线性程序表征受限对抗下的极小极大成本，然后在一般情况下模拟该解决方案。

Conclusion: 数值实验表明，该算法在成本和速度上都优于贝叶斯启发式方法，并且当可以计算贝叶斯最优策略时，与这些策略具有竞争力。

Abstract: We consider a natural dynamic staffing problem in which a decision-maker
sequentially hires workers over a finite horizon to meet an unknown demand
revealed at the end. Predictions about demand arrive over time and become
increasingly accurate, while worker availability decreases. This creates a
fundamental trade-off between hiring early to avoid understaffing (when workers
are more available but forecasts are less reliable) and hiring late to avoid
overstaffing (when forecasts are more accurate but availability is lower). This
problem is motivated by last-mile delivery operations, where companies such as
Amazon rely on gig-economy workers whose availability declines closer to the
operating day.
  To address practical limitations of Bayesian models (in particular, to remain
agnostic to the underlying forecasting method), we study this problem under
adversarial predictions. In this model, sequential predictions are
adversarially chosen uncertainty intervals that (approximately) contain the
true demand. The objective is to minimize worst-case staffing imbalance cost.
Our main result is a simple and computationally efficient online algorithm that
is minimax optimal. We first characterize the minimax cost against a restricted
adversary via a polynomial-size linear program, then show how to emulate this
solution in the general case. While our base model focuses on a single demand,
we extend the framework to multiple demands (with egalitarian/utilitarian
objectives), to settings with costly reversals of hiring decisions, and to
inconsistent prediction intervals. We also introduce a practical "re-solving"
variant of our algorithm, which we prove is also minimax optimal. Finally we
conduct numerical experiments showing that our algorithms outperform Bayesian
heuristics in both cost and speed, and are competitive with (approximate or
exact) Bayesian-optimal policies when those can be computed.

</details>


### [33] [An Exact Algorithm for the Unanimous Vote Problem](https://arxiv.org/abs/2510.16678)
*Feyza Duman Keles,Lisa Hellerstein,Kunal Marwaha,Christopher Musco,Xinchen Yang*

Main category: cs.DS

TL;DR: 本文解决了Unanimous Vote问题，证明了该问题可以在O(n log n)时间内精确求解，而非NP难问题，并给出了1.2±o(1)的自适应性差距。


<details>
  <summary>Details</summary>
Motivation: Gkenosis等人之前给出了该问题的多项式时间φ-近似算法(φ≈1.618)，但未解决该问题是否为NP难问题。本文旨在回答这个开放性问题。

Method: 使用简单的交换论证证明最优排序必须接近自然贪心算法产生的排序，并给出了精确的O(n log n)时间算法。

Result: 证明了Unanimous Vote问题可以在O(n log n)时间内精确求解，成为Stochastic Boolean Function Evaluation问题中少数已知可在多项式时间内求解的问题之一。

Conclusion: Unanimous Vote问题不是NP难问题，可以在多项式时间内精确求解，并且与最佳自适应策略相比存在1.2±o(1)的自适应性差距。

Abstract: Consider $n$ independent, biased coins, each with a known probability of
heads. Presented with an ordering of these coins, flip (i.e., toss) each coin
once, in that order, until we have observed both a *head* and a *tail*, or
flipped all coins. The Unanimous Vote problem asks us to find the ordering that
minimizes the expected number of flips. Gkenosis et al. [arXiv:1806.10660] gave
a polynomial-time $\phi$-approximation algorithm for this problem, where $\phi
\approx 1.618$ is the golden ratio. They left open whether the problem was
NP-hard. We answer this question by giving an exact algorithm that runs in time
$O(n \log n)$. The Unanimous Vote problem is an instance of the more general
Stochastic Boolean Function Evaluation problem: it thus becomes one of the only
such problems known to be solvable in polynomial time. Our proof uses simple
interchange arguments to show that the optimal ordering must be close to the
ordering produced by a natural greedy algorithm. Beyond our main result, we
compare the optimal ordering with the best adaptive strategy, proving a tight
adaptivity gap of $1.2\pm o(1)$ for the Unanimous Vote problem.

</details>


### [34] [All-Pairs Minimum Cut using $\tilde{O}(n^{7/4})$ Cut Queries](https://arxiv.org/abs/2510.16741)
*Yotam Kenneth-Mordoch,Robert Krauthgamer*

Main category: cs.DS

TL;DR: 提出了首个在割查询模型中的非平凡全对最小割算法，使用随机化方法构建Gomory-Hu树，仅需Õ(n^{7/4})次割查询


<details>
  <summary>Details</summary>
Motivation: 在割查询模型中解决全对最小割问题，该模型限制了算法只能通过查询割的大小来获取图信息，需要开发高效的查询算法

Method: 使用随机化算法，通过割查询访问无权重图，构建Gomory-Hu树来表示所有顶点对之间的最小割

Result: 成功实现了Õ(n^{7/4})次割查询的算法复杂度，这是该问题在割查询模型中的首个非平凡结果

Conclusion: 该工作证明了在割查询模型下全对最小割问题可以在亚线性查询复杂度下解决，为图算法的查询复杂度研究提供了重要进展

Abstract: We present the first non-trivial algorithm for the all-pairs minimum cut
problem in the cut-query model. Given cut-query access to an unweighted graph
$G=(V,E)$ with $n$ vertices, our randomized algorithm constructs a Gomory-Hu
tree of $G$, and thus solves the all-pairs minimum cut problem, using
$\tilde{O}(n^{7/4})$ cut queries.

</details>


### [35] [Combinatorial Maximum Flow via Weighted Push-Relabel on Shortcut Graphs](https://arxiv.org/abs/2510.17182)
*Aaron Bernstein,Joakim Blikstad,Jason Li,Thatchaphol Saranurak,Ta-Wei Tu*

Main category: cs.DS

TL;DR: 提出了一种组合算法，可在稠密图中以近最优时间计算有向图的最大流，显著简化了现有算法并提供了完整实现。


<details>
  <summary>Details</summary>
Motivation: 现有最大流算法在稠密图上效率不足，且复杂度过高。本文旨在开发更简单、高效的算法，特别是在稠密图上达到近最优性能。

Method: 使用组合算法，基于切割匹配游戏，针对边容量为{1,...,U}的有向图，在O(n²logU)时间内计算精确最大流。

Result: 算法在稠密图上达到近最优性能，比现有算法快n^{o(1)}倍，且显著简化。还实现了确定性版本，在顶点容量最大流问题上获得首个确定性近线性时间算法。

Conclusion: 该算法是超越O(m√n)时间的最简单算法之一，通过简化设计和完整实现证明了其可行性，并为顶点容量最大流问题提供了首个确定性近线性时间解。

Abstract: We give a combinatorial algorithm for computing exact maximum flows in
directed graphs with $n$ vertices and edge capacities from $\{1,\dots,U\}$ in
$\tilde{O}(n^{2}\log U)$ time, which is near-optimal on dense graphs. This
shaves an $n^{o(1)}$ factor from the recent result of
[Bernstein-Blikstad-Saranurak-Tu FOCS'24] and, more importantly, greatly
simplifies their algorithm. We believe that ours is by a significant margin the
simplest of all algorithms that go beyond $\tilde{O}(m\sqrt{n})$ time in
general graphs. To highlight this relative simplicity, we provide a full
implementation of the algorithm in C++.
  The only randomized component of our work is the cut-matching game. Via
existing tools, we show how to derandomize it for vertex-capacitated max flow
and obtain a deterministic $\tilde{O}(n^2)$ time algorithm. This marks the
first deterministic near-linear time algorithm for this problem (or even for
the special case of bipartite matching) in any density regime.

</details>


### [36] [Finding 4-Additive Spanners: Faster, Stronger, and Simpler](https://arxiv.org/abs/2510.17262)
*Chuhan Qi*

Main category: cs.DS

TL;DR: 提出了一种新的确定性算法来构建4-加性生成器，匹配已知的边界$\tilde{O}(n^{7/5})$，同时将运行时间改进到$\tilde{O}(\min\{mn^{3/5}, n^{11/5}\})$。


<details>
  <summary>Details</summary>
Motivation: 加性生成器在网络设计、图稀疏化和距离近似中有广泛应用，特别是4-加性生成器能保持所有点对距离的加性误差不超过4。

Method: 提出了一种新的确定性算法，相比之前的随机化构造，该算法不仅更快（在稠密图情况下），而且是完全确定性的，概念更简单，更易于实现和分析。

Result: 算法匹配了已知的边界$\tilde{O}(n^{7/5})$，同时将运行时间从之前的$\tilde{O}(mn^{3/5})$改进到$\tilde{O}(\min\{mn^{3/5}, n^{11/5}\})$。

Conclusion: 该工作提供了一个更高效、确定性的4-加性生成器构造算法，在保持最优边界的同时显著改进了运行时间。

Abstract: Additive spanners are fundamental graph structures with wide applications in
network design, graph sparsification, and distance approximation. In
particular, a $4$-additive spanner is a subgraph that preserves all pairwise
distances up to an additive error of $4$. In this paper, we present a new
deterministic algorithm for constructing $4$-additive spanners that matches the
best known edge bound of $\tilde{O}(n^{7/5})$ (up to polylogarithmic factors),
while improving the running time to $\tilde{O}(\min\{mn^{3/5}, n^{11/5}\})$,
compared to the previous $\tilde{O}(mn^{3/5})$ randomized construction. Our
algorithm is not only faster in the dense regime but also fully deterministic,
conceptually simpler, and easier to implement and analyze.

</details>


### [37] [On Algorithmic Meta-Theorems for Solution Discovery: Tractability and Barriers](https://arxiv.org/abs/2510.17344)
*Nicolas Bousquet,Amer E. Mouawad,Stephanie Maaz,Naomi Nishimura,Sebastian Siebertz*

Main category: cs.DS

TL;DR: 本文研究了图问题中解决方案发现问题的元定理，关注参数化复杂性和不涉及变换预算b的结构图参数，给出了MSO和FO可定义问题的正负结果。


<details>
  <summary>Details</summary>
Motivation: 研究解决方案发现问题（从不可行起始配置通过有限变换步骤得到可行解）的元定理，特别关注参数化复杂性和结构图参数，而不考虑变换预算b。

Method: 使用单子二阶逻辑（MSO₁和MSO₂）和一阶逻辑（FO）定义图问题，变换步骤是将令牌滑动到相邻顶点，分析参数化复杂性和各种结构图参数。

Result: MSO₂-Discovery在树宽参数化下属于XP类；MSO₁-Discovery在邻域多样性参数化下是固定参数可处理的；FO-Discovery在星调制器、路径调制器和双覆盖数参数化下是W[1]-难的；MSO₁-Discovery在带宽参数化下是W[1]-难的。

Conclusion: 为MSO和FO可定义图问题的解决方案发现问题提供了近乎完整的固定参数可处理元定理研究，补充了当预算b包含在参数中时的简单观察结果。

Abstract: Solution discovery asks whether a given (infeasible) starting configuration
to a problem can be transformed into a feasible solution using a limited number
of transformation steps. This paper investigates meta-theorems for solution
discovery for graph problems definable in monadic second-order logic (MSO$_1$
and MSO$_2$) and first-order logic (FO) where the transformation step is to
slide a token to an adjacent vertex, focusing on parameterized complexity and
structural graph parameters that do not involve the transformation budget $b$.
We present both positive and negative results. On the algorithmic side, we
prove that MSO$_2$-Discovery is in XP when parameterized by treewidth and that
MSO$_1$-Discovery is fixed-parameter tractable when parameterized by
neighborhood diversity. On the hardness side, we establish that FO-Discovery is
W[1]-hard when parameterized by modulator to stars, modulator to paths, as well
as twin cover, numbers. Additionally, we prove that MSO$_1$-Discovery is
W[1]-hard when parameterized by bandwidth. These results complement the
straightforward observation that solution discovery for the studied problems is
fixed-parameter tractable when the budget $b$ is included in the parameter (in
particular, parameterized by cliquewidth$+b$, where the cliquewidth of a graph
is at most any of the studied parameters), and provide a near-complete
(fixed-parameter tractability) meta-theorems investigation for solution
discovery problems for MSO- and FO-definable graph problems and structural
parameters larger than cliquewidth.

</details>


### [38] [Approximating Asymmetric A Priori TSP beyond the Adaptivity Gap](https://arxiv.org/abs/2510.17595)
*Manuel Christalla,Luise Puhlmann,Vera Traub*

Main category: cs.DS

TL;DR: 本文研究了非对称先验TSP问题，证明了自适应差距的多项式下界，并提出了一个拟多项式时间随机算法，能够达到对数多项式近似比。


<details>
  <summary>Details</summary>
Motivation: 研究非对称先验TSP问题，其中每个顶点有独立的激活概率，目标是计算一个路径，使得在随机采样的活跃顶点集合上期望路径长度最小。

Method: 通过一系列多项式时间归约：首先归约到新的Hop-ATSP问题，然后使用有向低直径分解获得结构化实例，再归约到覆盖问题，最终归约到在无环有向图中寻找最小化特定目标函数的路径问题。

Result: 证明了非对称先验TSP的自适应差距存在多项式下界，并给出了一个拟多项式时间随机算法，能够达到O(log n)的近似比。

Conclusion: 非对称先验TSP问题存在多项式自适应差距下界，但可以通过拟多项式时间算法获得低于自适应差距的近似比。

Abstract: In Asymmetric A Priori TSP (with independent activation probabilities) we are
given an instance of the Asymmetric Traveling Salesman Problem together with an
activation probability for each vertex. The task is to compute a tour that
minimizes the expected length after short-cutting to the randomly sampled set
of active vertices.
  We prove a polynomial lower bound on the adaptivity gap for Asymmetric A
Priori TSP. Moreover, we show that a poly-logarithmic approximation ratio, and
hence an approximation ratio below the adaptivity gap, can be achieved by a
randomized algorithm with quasi-polynomial running time.
  To achieve this, we provide a series of polynomial-time reductions. First we
reduce to a novel generalization of the Asymmetric Traveling Salesman Problem,
called Hop-ATSP. Next, we use directed low-diameter decompositions to obtain
structured instances, for which we then provide a reduction to a covering
problem. Eventually, we obtain a polynomial-time reduction of Asymmetric A
Priori TSP to a problem of finding a path in an acyclic digraph minimizing a
particular objective function, for which we give an O(log n)-approximation
algorithm in quasi-polynomial time.

</details>


### [39] [Near-Optimal Property Testers for Pattern Matching](https://arxiv.org/abs/2510.17645)
*Ce Jin,Tomasz Kociumaka*

Main category: cs.DS

TL;DR: 本文提出了精确模式匹配问题的自适应和非自适应属性测试器，覆盖了所有参数范围。在n=m+Θ(m)的典型情况下，非自适应测试器的时间复杂度为Õ(n/√k)，比之前最好的Õ(n/∛k)有所改进。在n=m+o(m)的新情况下，发现了自适应和非自适应算法之间的显著分离。


<details>
  <summary>Details</summary>
Motivation: 经典的精确模式匹配问题需要判断模式P是否作为子串出现在文本T中。属性测试器需要区分两种情况：P出现在T中，或者P与T的每个子串的汉明距离都大于k。现有的解决方案要么查询复杂度最优但需要Ω(n)时间，要么时间复杂度过高。

Method: 设计了自适应和非自适应的属性测试器，针对不同的参数范围（n=m+Θ(m)、n=m+Ω(m)、n=m+o(m)）分别优化算法。通过理论分析建立了时间复杂度和查询复杂度的下界。

Result: 在n=m+Θ(m)情况下，非自适应测试器的时间复杂度为Õ(n/√k)，比之前的Õ(n/∛k)有显著改进。在n=m+o(m)情况下，发现自适应和非自适应算法之间存在分离，自适应算法的时间复杂度为Õ(√((n-m+1)m/k)+n/k)，而非自适应算法为Õ(min(n√(n-m+1)/k,√(nm/k)+n/k))。

Conclusion: 本文为精确模式匹配问题提供了覆盖所有参数范围的最优属性测试器，在多个参数范围内改进了现有结果，并在n=m+o(m)情况下首次发现了自适应和非自适应算法之间的分离现象。

Abstract: The classic exact pattern matching problem, given two strings -- a pattern
$P$ of length $m$ and a text $T$ of length $n$ -- asks whether $P$ occurs as a
substring of $T$. A property tester for the problem needs to distinguish (with
high probability) the following two cases for some threshold $k$: the YES case,
where $P$ occurs as a substring of $T$, and the NO case, where $P$ has Hamming
distance greater than $k$ from every substring of $T$, that is, $P$ has no
$k$-mismatch occurrence in $T$.
  In this work, we provide adaptive and non-adaptive property testers for the
exact pattern matching problem, jointly covering the whole spectrum of
parameters. We further establish unconditional lower bounds demonstrating that
the time and query complexities of our algorithms are optimal, up to
$\mathrm{polylog}\, n$ factors hidden within the $\tilde O(\cdot)$ notation
below.
  In the most studied regime of $n=m+\Theta(m)$, our non-adaptive property
tester has the time complexity of $\tilde O(n/\sqrt{k})$, and a matching lower
bound remains valid for the query complexity of adaptive algorithms. This
improves both upon a folklore solution that attains the optimal query
complexity but requires $\Omega(n)$ time, and upon the only previously known
sublinear-time property tester, by Chan, Golan, Kociumaka, Kopelowitz, and
Porat [STOC 2020], with time complexity $\tilde O(n/\sqrt[3]{k})$. The
aforementioned results remain valid for $n=m+\Omega(m)$, where our optimal
running time $\tilde O(\sqrt{nm/k}+n/k)$ improves upon the previously best time
complexity of $\tilde O(\sqrt[3]{n^2m/k}+n/k)$. In the regime of $n=m+o(m)$,
which has not been targeted in any previous work, we establish a surprising
separation between adaptive and non-adaptive algorithms, whose optimal time and
query complexities are $\tilde O(\sqrt{(n-m+1)m/k}+n/k)$ and $\tilde
O(\min(n\sqrt{n-m+1}/k,\sqrt{nm/k}+n/k))$, respectively.

</details>


### [40] [The Marked Edge Walk: A Novel MCMC Algorithm for Sampling of Graph Partitions](https://arxiv.org/abs/2510.17714)
*Atticus McWhorter,Daryl DeFord*

Main category: cs.DS

TL;DR: 提出了一种新的MCMC算法——标记边行走(MEW)，用于从可调分布中采样图分区，克服了现有算法局限于采样与生成树相关分布的约束。


<details>
  <summary>Details</summary>
Motivation: 现有的MCMC重分区算法如RevReCom和MFR只能采样与生成树相关的分布，限制了应用的灵活性。需要开发能够从更广泛分布中采样的新算法。

Method: 提出标记边行走(MEW)算法，在带有标记边的生成树空间上操作，允许计算可用的转移概率，用于Metropolis-Hastings算法。

Result: 在真实世界对偶图上的实证结果显示，该算法在与生成树无关的目标分布下能够收敛。

Conclusion: MEW代表了灵活集成生成的重要进展，能够从可调分布中采样图分区。

Abstract: Novel Markov Chain Monte Carlo (MCMC) methods have enabled the generation of
large ensembles of redistricting plans through graph partitioning. However,
existing algorithms such as Reversible Recombination (RevReCom) and
Metropolized Forest Recombination (MFR) are constrained to sampling from
distributions related to spanning trees. We introduce the marked edge walk
(MEW), a novel MCMC algorithm for sampling from the space of graph partitions
under a tunable distribution. The walk operates on the space of spanning trees
with marked edges, allowing for calculable transition probabilities for use in
the Metropolis-Hastings algorithm. Empirical results on real-world dual graphs
show convergence under target distributions unrelated to spanning trees. For
this reason, MEW represents an advancement in flexible ensemble generation.

</details>


### [41] [Generalized Flow in Nearly-linear Time on Moderately Dense Graphs](https://arxiv.org/abs/2510.17740)
*Shunhua Jiang,Michael Kapralov,Lawrence Li,Aaron Sidford*

Main category: cs.DS

TL;DR: 提出了一个随机化算法，用于解决广义最大流和广义最小成本流问题，时间复杂度为$\tilde{O}( (m + n^{1.5}) \cdot \mathrm{polylog}(\frac{W}{\delta}))$，相比之前的最佳算法$\tilde{O}(m \sqrt{n} \cdot \log^2(\frac{W}{\delta}))$有所改进。


<details>
  <summary>Details</summary>
Motivation: 广义流问题中，每条边都有一个损失因子来控制流量的增减，现有的算法时间复杂度较高，需要更高效的解决方案。

Method: 使用新的动态数据结构和谱分析技术，结合Brand等人提出的内点法框架来解决广义流问题。

Result: 开发了一个比现有最佳算法更快的随机化算法，时间复杂度从$\tilde{O}(m \sqrt{n})$改进到$\tilde{O}(m + n^{1.5})$。

Conclusion: 通过新的动态数据结构和谱分析技术，成功改进了广义流问题的时间复杂度，为相关优化问题提供了更高效的解决方案。

Abstract: In this paper we consider generalized flow problems where there is an
$m$-edge $n$-node directed graph $G = (V,E)$ and each edge $e \in E$ has a loss
factor $\gamma_e >0$ governing whether the flow is increased or decreased as it
crosses edge $e$. We provide a randomized $\tilde{O}( (m + n^{1.5}) \cdot
\mathrm{polylog}(\frac{W}{\delta}))$ time algorithm for solving the generalized
maximum flow and generalized minimum cost flow problems in this setting where
$\delta$ is the target accuracy and $W$ is the maximum of all costs,
capacities, and loss factors and their inverses. This improves upon the
previous state-of-the-art $\tilde{O}(m \sqrt{n} \cdot \log^2(\frac{W}{\delta})
)$ time algorithm, obtained by combining the algorithm of [Daitch-Spielman,
2008] with techniques from [Lee-Sidford, 2014]. To obtain this result we
provide new dynamic data structures and spectral results regarding the matrices
associated to generalized flows and apply them through the interior point
method framework of [Brand-Lee-Liu-Saranurak-Sidford-Song-Wang, 2021].

</details>


### [42] [Pattern Matching under Weighted Edit Distance](https://arxiv.org/abs/2510.17752)
*Panagiotis Charalampopoulos,Tomasz Kociumaka,Philip Wellnitz*

Main category: cs.DS

TL;DR: 本文研究了带权编辑距离的模式匹配问题（PMWED），提出了三种不同时间复杂度的算法，分别适用于一般权重、度量权重和小整数权重的情况。


<details>
  <summary>Details</summary>
Motivation: 传统的模式匹配编辑距离问题（PMED）假设所有编辑操作的单位成本相同，但现实应用中编辑成本往往与涉及的字符相关。PMWED通过引入权重函数更准确地捕捉实际应用场景。

Method: 开发了三种算法：(a) 简单直观的O(nk)时间算法；(b) 针对度量权重函数的O(n+k^3.5·W^4·n/m)时间算法；(c) 适用于任意权重的O(n+k^4·n/m)时间算法。

Result: 在度量权重且权重值为小整数的情况下，算法性能接近PMED（W=1）的最优结果，为带权编辑距离的模式匹配提供了高效的解决方案。

Conclusion: PMWED比PMED更能准确反映实际应用，提出的算法在不同权重设置下都达到了良好的时间复杂度，特别是在小整数权重情况下接近最优性能。

Abstract: In Pattern Matching with Weighted Edits (PMWED), we are given a pattern $P$
of length $m$, a text $T$ of length $n$, a positive threshold $k$, and oracle
access to a weight function that specifies the costs of edits (depending on the
involved characters, and normalized so that the cost of each edit is at least
$1$). The goal is to compute the starting positions of all fragments of $T$
that can be obtained from $P$ with edits of total cost at most $k$. PMWED
captures typical real-world applications more accurately than its unweighted
variant (PMED), where all edits have unit costs.
  We obtain three main results:
  (a) a conceptually simple $\tilde{O}(nk)$-time algorithm for PMWED, very
different from that of Landau and Vishkin for PMED;
  (b) a significantly more complicated $\tilde{O}(n+k^{3.5} \cdot W^4\cdot
n/m)$-time algorithm for PMWED under the assumption that the weight function is
a metric with integer values between $0$ and $W$; and
  (c) an $\tilde{O}(n+k^4 \cdot n/m)$-time algorithm for PMWED for the case of
arbitrary weights.
  In the setting of metrics with small integer values, we nearly match the
state of the art for PMED where $W=1$.

</details>


### [43] [Dynamic Dyck and Tree Edit Distance: Decompositions and Reductions to String Edit Distance](https://arxiv.org/abs/2510.17799)
*Debarati Das,Jacob Gilbert,MohammadTaghi Hajiaghayi,Tomasz Kociumaka,Barna Saha*

Main category: cs.DS

TL;DR: 提出了首个具有亚多项式更新时间的Dyck和树编辑距离动态算法，通过将问题转化为可高效维护的字符串编辑距离实例，实现了n^{o(1)}近似比和更新时间。


<details>
  <summary>Details</summary>
Motivation: Dyck编辑距离测量括号串与良好括号表达式的距离，树编辑距离量化转换两棵树所需的最小操作数。这些在LaTeX文档、JSON/XML文件和RNA二级结构等演化结构化数据中自然出现，但之前没有高效的动态算法。

Method: 通过一系列归约和分解技术，将Dyck和树编辑距离实例转化为可高效维护的字符串编辑距离实例。关键组件包括动态维护历史无关的轻重分解，以及新的静态和动态分解方法。

Result: 对于Dyck编辑距离，获得n^{o(1)}近似比和n^{o(1)}更新时间；对于树编辑距离，静态近似比从n^{3/4}改进到Õ(√n)，动态实现n^{1/2+o(1)}近似比和n^{o(1)}更新时间。还提供了当编辑距离最多为k时的O(k log n)近似算法。

Conclusion: 该工作首次为Dyck和树编辑距离提供了高效的动态算法，通过创新的归约和分解技术显著改进了近似比和计算效率，为处理演化结构化数据提供了实用工具。

Abstract: We present the first dynamic algorithms for Dyck and tree edit distances with
subpolynomial update times. Dyck edit distance measures how far a parenthesis
string is from a well-parenthesized expression, while tree edit distance
quantifies the minimum number of node insertions, deletions, and substitutions
required to transform one rooted, ordered, labeled tree into another. Despite
extensive study, no prior work has addressed efficient dynamic algorithms for
these problems, which naturally arise in evolving structured data such as LaTeX
documents, JSON or XML files, and RNA secondary structures.
  Our main contribution is a set of reductions and decompositions that
transform Dyck and tree edit distance instances into efficiently maintainable
string edit distance instances, which can be approximated within a $n^{o(1)}$
factor in $n^{o(1)}$ update time. For Dyck edit distance, our reduction incurs
only polylogarithmic overheads in approximation and update time, yielding an
$n^{o(1)}$-approximation with $n^{o(1)}$ updates. For tree edit distance, we
introduce a new static reduction that improves the best-known approximation
ratio from $n^{3/4}$ to $\tilde{O}(\sqrt{n})$ and removes the restriction to
constant-degree trees. Extending this reduction dynamically achieves
$n^{1/2+o(1)}$ approximation with $n^{o(1)}$ update time.
  A key component is a dynamic maintenance algorithm for history-independent
heavy-light decompositions, of independent interest. We also provide a novel
static and dynamic decomposition achieving an $O(k \log n)$-approximation when
the tree edit distance is at most $k$. Combined with the trivial bound $k \le
n$, this yields a dynamic deterministic $O(\sqrt{n \log n})$-approximation. In
the static setting, our algorithm runs in near-linear time; dynamically, it
requires only polylogarithmic updates, improving on prior linear-time static
$O(\sqrt{n})$-approximation.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [44] [Taming Modality Entanglement in Continual Audio-Visual Segmentation](https://arxiv.org/abs/2510.17234)
*Yuyang Hong,Qi Yang,Tao Zhang,Zili Wang,Zhaojin Fu,Kun Ding,Bin Fan,Shiming Xiang*

Main category: cs.MM

TL;DR: 本文提出了持续音频-视觉分割任务，通过碰撞式多模态重放框架解决多模态语义漂移和共现混淆问题，在三个音频-视觉增量场景中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态持续学习方法主要关注粗粒度任务，在细粒度持续学习中处理模态纠缠存在局限性。为填补这一空白，引入了持续音频-视觉分割任务。

Method: 设计了碰撞式多模态重放框架，包括多模态样本选择策略和碰撞式样本重放机制，分别解决多模态语义漂移和共现混淆问题。

Result: 综合实验表明，该方法显著优于单模态持续学习方法，在三个音频-视觉增量场景中验证了有效性。

Conclusion: 提出的CMR框架成功解决了细粒度多模态持续学习中的关键挑战，为音频-视觉分割任务提供了有效的持续学习解决方案。

Abstract: Recently, significant progress has been made in multi-modal continual
learning, aiming to learn new tasks sequentially in multi-modal settings while
preserving performance on previously learned ones. However, existing methods
mainly focus on coarse-grained tasks, with limitations in addressing modality
entanglement in fine-grained continual learning settings. To bridge this gap,
we introduce a novel Continual Audio-Visual Segmentation (CAVS) task, aiming to
continuously segment new classes guided by audio. Through comprehensive
analysis, two critical challenges are identified: 1) multi-modal semantic
drift, where a sounding objects is labeled as background in sequential tasks;
2) co-occurrence confusion, where frequent co-occurring classes tend to be
confused. In this work, a Collision-based Multi-modal Rehearsal (CMR) framework
is designed to address these challenges. Specifically, for multi-modal semantic
drift, a Multi-modal Sample Selection (MSS) strategy is proposed to select
samples with high modal consistency for rehearsal. Meanwhile, for co-occurence
confusion, a Collision-based Sample Rehearsal (CSR) mechanism is designed,
allowing for the increase of rehearsal sample frequency of those confusable
classes during training process. Moreover, we construct three audio-visual
incremental scenarios to verify effectiveness of our method. Comprehensive
experiments demonstrate that our method significantly outperforms single-modal
continual learning methods.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [45] [Investigating the Association Between Text-Based Indications of Foodborne Illness from Yelp Reviews and New York City Health Inspection Outcomes (2023)](https://arxiv.org/abs/2510.16334)
*Eden Shaveet,Crystal Su,Daniel Hsu,Luis Gravano*

Main category: cs.IR

TL;DR: 该研究分析了Yelp评论中的食品中毒信号与纽约市官方餐厅检查结果之间的关联，发现在人口普查区层面两者相关性很小，且与C级餐厅数量无显著差异。


<details>
  <summary>Details</summary>
Motivation: 食品中毒是严重的公共卫生问题，餐厅是调查疫情的关键场所。社交媒体平台上的用户生成内容可以提供及时的公共卫生信号，而官方报告渠道有限。

Method: 使用分层S型注意力网络(HSAN)分类器分析Yelp评论信号，并与纽约市卫生局2023年的官方餐厅检查结果进行比较，在人口普查区层面评估相关性、比较分布并绘制空间模式。

Result: 在人口普查区层面，HSAN信号与检查分数之间相关性很小，且不同C级餐厅数量的区域间HSAN得分分布无显著差异。

Conclusion: 社交媒体信号与官方检查结果在宏观层面关联有限，需要进一步进行地址级别的分析来更好地理解两者的关系。

Abstract: Foodborne illnesses are gastrointestinal conditions caused by consuming
contaminated food. Restaurants are critical venues to investigate outbreaks
because they share sourcing, preparation, and distribution of foods. Public
reporting of illness via formal channels is limited, whereas social media
platforms host abundant user-generated content that can provide timely public
health signals. This paper analyzes signals from Yelp reviews produced by a
Hierarchical Sigmoid Attention Network (HSAN) classifier and compares them with
official restaurant inspection outcomes issued by the New York City Department
of Health and Mental Hygiene (NYC DOHMH) in 2023. We evaluate correlations at
the Census tract level, compare distributions of HSAN scores by prevalence of
C-graded restaurants, and map spatial patterns across NYC. We find minimal
correlation between HSAN signals and inspection scores at the tract level and
no significant differences by number of C-graded restaurants. We discuss
implications and outline next steps toward address-level analyses.

</details>


### [46] [Blending Learning to Rank and Dense Representations for Efficient and Effective Cascades](https://arxiv.org/abs/2510.16393)
*Franco Maria Nardini,Raffaele Perego,Nicola Tonellotto,Salvatore Trani*

Main category: cs.IR

TL;DR: 该论文提出了一种结合词汇和神经相关性信号的混合检索方法，通过两阶段架构（神经检索器+学习排序模型）显著提升检索效果，同时保持较高的效率。


<details>
  <summary>Details</summary>
Motivation: 探索如何有效结合词汇特征和神经表示这两种不同的相关性信号，以提升ad-hoc段落检索的性能。

Method: 采用两阶段架构：第一阶段使用密集神经检索器进行最近邻搜索，第二阶段使用基于决策树森林的学习排序模型，融合253个手工词汇特征和神经表示来重新排序候选结果。

Result: 在公开数据集上的实验显示，该方法显著提升了端到端排序性能，nDCG@10指标提升高达11%，而平均查询延迟仅增加4.3%。

Conclusion: 无缝结合词汇和神经两种不同信号家族能够相互补充，有效提升检索效果，同时相对最小化效率影响。

Abstract: We investigate the exploitation of both lexical and neural relevance signals
for ad-hoc passage retrieval. Our exploration involves a large-scale training
dataset in which dense neural representations of MS-MARCO queries and passages
are complemented and integrated with 253 hand-crafted lexical features
extracted from the same corpus. Blending of the relevance signals from the two
different groups of features is learned by a classical Learning-to-Rank (LTR)
model based on a forest of decision trees. To evaluate our solution, we employ
a pipelined architecture where a dense neural retriever serves as the first
stage and performs a nearest-neighbor search over the neural representations of
the documents. Our LTR model acts instead as the second stage that re-ranks the
set of candidates retrieved by the first stage to enhance effectiveness. The
results of reproducible experiments conducted with state-of-the-art dense
retrievers on publicly available resources show that the proposed solution
significantly enhances the end-to-end ranking performance while relatively
minimally impacting efficiency. Specifically, we achieve a boost in nDCG@10 of
up to 11% with an increase in average query latency of only 4.3%. This confirms
the advantage of seamlessly combining two distinct families of signals that
mutually contribute to retrieval effectiveness.

</details>


### [47] [FRONTIER-RevRec: A Large-scale Dataset for Reviewer Recommendation](https://arxiv.org/abs/2510.16597)
*Qiyao Peng,Chen Wang,Yinghui Wang,Hongtao Liu,Xuan Guo,Wenjun Wang*

Main category: cs.IR

TL;DR: 提出了FRONTIER-RevRec数据集，这是一个基于Frontiers开放获取平台真实同行评审记录的大规模审稿人推荐基准数据集，包含177,941位审稿人和478,379篇论文，涵盖209种期刊。研究发现基于内容的方法显著优于协同过滤，语言模型方法在捕捉论文内容与审稿人专业知识的语义对齐方面特别有效。


<details>
  <summary>Details</summary>
Motivation: 审稿人推荐研究长期以来因缺乏高质量基准数据集而受阻，现有数据集通常规模有限、学科范围狭窄，且缺乏不同方法的比较分析。

Method: 从Frontiers开放获取出版平台（2007-2025年）的真实同行评审记录构建大规模数据集，并进行全面的评估，比较内容基方法和协同过滤方法的效果。

Result: 基于内容的方法显著优于协同过滤，语言模型方法在捕捉语义对齐方面特别有效。结构分析揭示了学术推荐与商业领域的基本差异。实验确定了增强推荐流程的最佳聚合策略。

Conclusion: FRONTIER-RevRec数据集可作为审稿人推荐研究的综合基准，推动更有效的学术同行评审系统的发展。

Abstract: Reviewer recommendation is a critical task for enhancing the efficiency of
academic publishing workflows. However, research in this area has been
persistently hindered by the lack of high-quality benchmark datasets, which are
often limited in scale, disciplinary scope, and comparative analyses of
different methodologies. To address this gap, we introduce FRONTIER-RevRec, a
large-scale dataset constructed from authentic peer review records (2007-2025)
from the Frontiers open-access publishing platform
https://www.frontiersin.org/. The dataset contains 177941 distinct reviewers
and 478379 papers across 209 journals spanning multiple disciplines including
clinical medicine, biology, psychology, engineering, and social sciences. Our
comprehensive evaluation on this dataset reveals that content-based methods
significantly outperform collaborative filtering. This finding is explained by
our structural analysis, which uncovers fundamental differences between
academic recommendation and commercial domains. Notably, approaches leveraging
language models are particularly effective at capturing the semantic alignment
between a paper's content and a reviewer's expertise. Furthermore, our
experiments identify optimal aggregation strategies to enhance the
recommendation pipeline. FRONTIER-RevRec is intended to serve as a
comprehensive benchmark to advance research in reviewer recommendation and
facilitate the development of more effective academic peer review systems. The
FRONTIER-RevRec dataset is available at:
https://anonymous.4open.science/r/FRONTIER-RevRec-5D05.

</details>


### [48] [Right Answer at the Right Time - Temporal Retrieval-Augmented Generation via Graph Summarization](https://arxiv.org/abs/2510.16715)
*Zulun Zhu,Haoyu Liu,Mengke He,Siqiang Luo*

Main category: cs.IR

TL;DR: STAR-RAG是一个时间知识图谱问答框架，通过构建时间对齐规则图并进行传播来缩小搜索空间，优先考虑语义相关且时间一致的证据，从而提高准确性并减少token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法主要基于语义，通常忽略显式时间约束，导致时间不一致的答案和过高的token使用量。需要一种既时间一致又高效的检索方法。

Method: 构建时间对齐规则图，并在该图上进行传播以缩小搜索空间，优先选择语义相关且时间一致的证据。该方法在检索过程中强制时间邻近性。

Result: 在真实世界时间知识图谱数据集上的广泛实验表明，该方法在消耗更少token的同时实现了比强GraphRAG基线更高的答案准确性。

Conclusion: STAR-RAG无需繁重的模型训练和微调，降低了计算成本并显著简化了部署，在保持准确性的同时减少了token消耗。

Abstract: Question answering in temporal knowledge graphs requires retrieval that is
both time-consistent and efficient. Existing RAG methods are largely semantic
and typically neglect explicit temporal constraints, which leads to
time-inconsistent answers and inflated token usage. We propose STAR-RAG, a
temporal GraphRAG framework that relies on two key ideas: building a
time-aligned rule graph and conducting propagation on this graph to narrow the
search space and prioritize semantically relevant, time-consistent evidence.
This design enforces temporal proximity during retrieval, reduces the candidate
set of retrieval results, and lowers token consumption without sacrificing
accuracy. Compared with existing temporal RAG approaches, STAR-RAG eliminates
the need for heavy model training and fine-tuning, thereby reducing
computational cost and significantly simplifying deployment.Extensive
experiments on real-world temporal KG datasets show that our method achieves
improved answer accuracy while consuming fewer tokens than strong GraphRAG
baselines.

</details>


### [49] [Exact Nearest-Neighbor Search on Energy-Efficient FPGA Devices](https://arxiv.org/abs/2510.16736)
*Patrizio Dazzi,William Guglielmo,Franco Maria Nardini,Raffaele Perego,Salvatore Trani*

Main category: cs.IR

TL;DR: 该论文提出了两种基于FPGA的能效优化kNN搜索解决方案，分别针对高吞吐量和低延迟场景，在图像和文本数据集上相比CPU方案实现了最高16.6倍的性能提升和11.9倍的能耗节省。


<details>
  <summary>Details</summary>
Motivation: 支持神经网络编码器模型的大规模应用，使其更加绿色和包容，通过FPGA设备实现高维潜在空间中能效优化的精确kNN搜索。

Method: 提出两种FPGA解决方案：第一种通过流式处理批量查询最大化系统吞吐量；第二种通过内存内并行处理单个查询最小化延迟。两种方案采用相同的FPGA底层配置。

Result: 在公开图像和文本数据集上的实验显示，FPGA解决方案在吞吐量、延迟和能耗方面均优于最先进的CPU方案，吞吐量提升最高达16.6倍，能耗节省最高达11.9倍。

Conclusion: FPGA为高维潜在空间的精确kNN搜索提供了能效优化的有效解决方案，显著提升了性能并降低了能耗，支持神经网络编码器模型的绿色大规模应用。

Abstract: This paper investigates the usage of FPGA devices for energy-efficient exact
kNN search in high-dimension latent spaces. This work intercepts a relevant
trend that tries to support the increasing popularity of learned
representations based on neural encoder models by making their large-scale
adoption greener and more inclusive. The paper proposes two different
energy-efficient solutions adopting the same FPGA low-level configuration. The
first solution maximizes system throughput by processing the queries of a batch
in parallel over a streamed dataset not fitting into the FPGA memory. The
second minimizes latency by processing each kNN incoming query in parallel over
an in-memory dataset. Reproducible experiments on publicly available image and
text datasets show that our solution outperforms state-of-the-art CPU-based
competitors regarding throughput, latency, and energy consumption.
Specifically, experiments show that the proposed FPGA solutions achieve the
best throughput in terms of queries per second and the best-observed latency
with scale-up factors of up to 16.6X. Similar considerations can be made
regarding energy efficiency, where results show that our solutions can achieve
up to 11.9X energy saving w.r.t. strong CPU-based competitors.

</details>


### [50] [An Efficient Framework for Whole-Page Reranking via Single-Modal Supervision](https://arxiv.org/abs/2510.16803)
*Zishuai Zhang,Sihao Yu,Wenyi Xie,Ying Nie,Junfeng Wang,Zhiming Zheng,Dawei Yin,Hainan Zhang*

Main category: cs.IR

TL;DR: SMAR是一个新颖的全页重排框架，利用强单模态排序器指导模态间相关性对齐，仅使用有限的全页标注就能超越完全标注的重排模型，显著降低标注成本70-90%。


<details>
  <summary>Details</summary>
Motivation: 全页重排对搜索引擎用户体验至关重要，但现有方法依赖大规模人工标注，成本高且耗时。全页标注比单模态标注复杂得多，需要评估整个结果页面并考虑跨模态相关性差异。

Method: 首先为各模态训练高质量单模态排序器，然后为每个查询选择其输出子集构建候选页面并进行页面级人工标注，最后使用有限标注训练全页重排器，并强制与单模态偏好保持一致以维持各模态内排序质量。

Result: 在Qilin和Baidu数据集上的实验表明，SMAR减少标注成本约70-90%，同时相比基线实现显著排序改进。在百度APP上的离线和在线A/B测试也显示标准排序指标和用户体验指标的显著提升。

Conclusion: SMAR在现实搜索场景中验证了其有效性和实用价值，能够在显著降低标注成本的同时提升全页重排性能。

Abstract: The whole-page reranking plays a critical role in shaping the user experience
of search engines, which integrates retrieval results from multiple modalities,
such as documents, images, videos, and LLM outputs. Existing methods mainly
rely on large-scale human-annotated data, which is costly to obtain and
time-consuming. This is because whole-page annotation is far more complex than
single-modal: it requires assessing the entire result page while accounting for
cross-modal relevance differences. Thus, how to improve whole-page reranking
performance while reducing annotation costs is still a key challenge in
optimizing search engine result pages(SERP). In this paper, we propose SMAR, a
novel whole-page reranking framework that leverages strong Single-modal rankers
to guide Modal-wise relevance Alignment for effective Reranking, using only
limited whole-page annotation to outperform fully-annotated reranking models.
Specifically, high-quality single-modal rankers are first trained on data
specific to their respective modalities. Then, for each query, we select a
subset of their outputs to construct candidate pages and perform human
annotation at the page level. Finally, we train the whole-page reranker using
these limited annotations and enforcing consistency with single-modal
preferences to maintain ranking quality within each modality. Experiments on
the Qilin and Baidu datasets demonstrate that SMAR reduces annotation costs by
about 70-90\% while achieving significant ranking improvements compared to
baselines. Further offline and online A/B testing on Baidu APPs also shows
notable gains in standard ranking metrics as well as user experience
indicators, fully validating the effectiveness and practical value of our
approach in real-world search scenarios.

</details>


### [51] [The Layout Is the Model: On Action-Item Coupling in Generative Recommendation](https://arxiv.org/abs/2510.16804)
*Xiaokai Wei,Jiajun Wu,Daiyao Yi,Reza Shirkavand,Michelle Gong*

Main category: cs.IR

TL;DR: 本文研究了生成式推荐模型中的token布局设计，提出了基于三个设计原则的统一框架，并开发了一种新颖的非交错布局方法LAC，在保持准确性的同时显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐模型将用户交互历史视为序列进行自回归预测。当同时建模物品和动作时，token的布局（排序和可见性）决定了模型能使用什么信息以及如何泛化，因此需要系统研究布局设计。

Method: 提出了基于三个设计原则的统一框架：(P1)最大化输入/输出空间的物品/动作信号，(P2)保持"给定物品的动作"条件关系，(P3)无信息泄露。设计了Lagged Action Conditioning (LAC)方法，这是一种表面奇怪但符合设计原则的非交错布局方法。

Result: 在公共数据集和大规模生产日志上的综合实验验证了设计原则。提出的非交错方法LAC在显著降低FLOPs的情况下，达到了与交错布局相当或更优的质量。

Conclusion: 研究结果为构建既准确又高效的生成式推荐系统提供了可行的指导，LAC方法在保持性能的同时大幅提升了计算效率。

Abstract: Generative Recommendation (GR) models treat a user's interaction history as a
sequence to be autoregressively predicted. When both items and actions (e.g.,
watch time, purchase, comment) are modeled, the layout-the ordering and
visibility of item/action tokens-critically determines what information the
model can use and how it generalizes. We present a unified study of token
layouts for GR grounded in first principles: (P1) maximize item/action signal
in both input/output space, (P2) preserve the conditioning relationship "action
given item" and (P3) no information leakage.
  While interleaved layout (where item and action occupy separate tokens)
naturally satisfies these principles, it also bloats sequence length with
larger training/inference cost. On the non-interleaved front, we design a novel
and effective approach, Lagged Action Conditioning (LAC), which appears strange
on the surface but aligns well with the design principles to yield strong
accuracy. Comprehensive experiments on public datasets and large-scale
production logs evaluate different layout options and empirically verifies the
design principles. Our proposed non-interleaved method, LAC, achieves
competitive or superior quality at substantially lower FLOPs than interleaving.
Our findings offer actionable guidance for assembling GR systems that are both
accurate and efficient.

</details>


### [52] [Towards Context-aware Reasoning-enhanced Generative Searching in E-commerce](https://arxiv.org/abs/2510.16925)
*Zhiding Liu,Ben Chen,Mingyue Cheng,Enchong Chen,Li Li,Chenyi Lei,Wenwu Ou,Han Li,Kun Gai*

Main category: cs.IR

TL;DR: 提出了一种上下文感知的推理增强生成搜索框架，通过统一异构上下文信息、自演化的后训练范式以及去偏见的强化学习，提升电商搜索推荐的性能。


<details>
  <summary>Details</summary>
Motivation: 电商搜索推荐中，用户的复杂搜索上下文（时空因素、历史交互、当前查询信息）反映了隐含偏好，但现有方法在整合这些上下文信息方面存在局限，无法充分捕捉用户意图。

Method: 将异构用户和物品上下文统一为文本表示或基于文本的语义标识符并进行对齐；引入自演化后训练范式，结合监督微调和强化学习迭代增强模型推理能力；提出去偏见的GRPO变体改进排序性能。

Result: 在真实电商平台搜索日志数据上的大量实验表明，该方法相比强基线实现了更优越的性能，验证了其在搜索推荐中的有效性。

Conclusion: 该上下文感知推理增强生成搜索框架能够更好地理解复杂上下文，有效提升搜索推荐性能，为解决电商搜索中的上下文建模挑战提供了有效方案。

Abstract: Search-based recommendation is one of the most critical application scenarios
in e-commerce platforms. Users' complex search contexts--such as spatiotemporal
factors, historical interactions, and current query's information--constitute
an essential part of their decision-making, reflecting implicit preferences
that complement explicit query terms. Modeling such rich contextual signals and
their intricate associations with candidate items remains a key challenge.
Although numerous efforts have been devoted to building more effective search
methods, existing approaches still show limitations in integrating contextual
information, which hinders their ability to fully capture user intent.
  To address these challenges, we propose a context-aware reasoning-enhanced
generative search framework for better \textbf{understanding the complicated
context}. Specifically, the framework first unifies heterogeneous user and item
contexts into textual representations or text-based semantic identifiers and
aligns them. To overcome the lack of explicit reasoning trajectories, we
introduce a self-evolving post-training paradigm that iteratively combines
supervised fine-tuning and reinforcement learning to progressively enhance the
model's reasoning capability. In addition, we identify potential biases in
existing RL algorithms when applied to search scenarios and present a debiased
variant of GRPO to improve ranking performance. Extensive experiments on search
log data collected from a real-world e-commerce platform demonstrate that our
approach achieves superior performance compared with strong baselines,
validating its effectiveness for search-based recommendation.

</details>


### [53] [DSEBench: A Test Collection for Explainable Dataset Search with Examples](https://arxiv.org/abs/2510.17228)
*Qing Shi,Jing He,Qiaosheng Chen,Gong Cheng*

Main category: cs.IR

TL;DR: 本文提出了可解释的数据集搜索任务，构建了DSEBench测试集，并使用大语言模型生成标注数据来训练和评估多种检索、重排序和解释方法。


<details>
  <summary>Details</summary>
Motivation: 当前的数据集搜索要么基于关键词查询，要么基于目标数据集相似性，需要结合这两种信息需求，并扩展到可解释的数据集搜索。

Method: 构建DSEBench测试集，使用大语言模型生成标注数据，评估稀疏、稠密和基于LLM的检索、重排序和解释方法。

Result: 建立了DSEBench测试集，提供了高质量的数据集和字段级标注，并评估了多种基线方法。

Conclusion: 提出了可解释的数据集搜索任务，构建了评估基准，为未来研究提供了基础。

Abstract: Dataset search has been an established information retrieval task. Current
paradigms either retrieve datasets that are relevant to a keyword query or find
datasets that are similar to an input target dataset. To allow for their
combined specification of information needs, in this article, we investigate
the more generalized task of Dataset Search with Examples (DSE) and further
extend it to Explainable DSE that requires identifying the metadata and content
fields of a dataset that indicate its relevance to the query and similarity to
the target datasets. To facilitate this research, we construct DSEBench, a test
collection that provides high-quality dataset- and field-level annotations to
enable the evaluation of explainable DSE. We also employ a large language model
to generate numerous annotations to be used for training. We establish
extensive baselines on DSEBench by adapting and evaluating a variety of sparse,
dense, and LLM-based retrieval, reranking, and explanation methods.

</details>


### [54] [On Efficiency-Effectiveness Trade-off of Diffusion-based Recommenders](https://arxiv.org/abs/2510.17245)
*Wenyu Mao,Jiancan Wu,Guoqing Hu,Wei Ji,Xiang Wang*

Main category: cs.IR

TL;DR: TA-Rec是一个两阶段框架，通过预训练时平滑去噪函数实现一步生成，并在微调时通过用户偏好对齐减轻轨迹偏差，解决了扩散模型在序列推荐中计算效率与推荐效果之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在序列推荐中通常需要多步去噪过程，这依赖于离散近似并引入离散化误差，导致计算效率与推荐效果之间存在权衡。

Method: 提出TA-Rec两阶段框架：1) 预训练阶段使用时间一致性正则化平滑去噪函数；2) 微调阶段引入自适应偏好对齐，基于偏好对相似性和时间步长将去噪过程与用户偏好对齐。

Result: 广泛的实验证明TA-Rec的两阶段目标有效缓解了离散化误差引起的权衡问题，提升了基于扩散的推荐器的效率和效果。

Conclusion: TA-Rec通过两阶段框架成功解决了扩散模型在序列推荐中的效率-效果权衡问题，实现了高效且有效的推荐生成。

Abstract: Diffusion models have emerged as a powerful paradigm for generative
sequential recommendation, which typically generate next items to recommend
guided by user interaction histories with a multi-step denoising process.
However, the multi-step process relies on discrete approximations, introducing
discretization error that creates a trade-off between computational efficiency
and recommendation effectiveness. To address this trade-off, we propose TA-Rec,
a two-stage framework that achieves one-step generation by smoothing the
denoising function during pretraining while alleviating trajectory deviation by
aligning with user preferences during fine-tuning. Specifically, to improve the
efficiency without sacrificing the recommendation performance, TA-Rec pretrains
the denoising model with Temporal Consistency Regularization (TCR), enforcing
the consistency between the denoising results across adjacent steps. Thus, we
can smooth the denoising function to map the noise as oracle items in one step
with bounded error. To further enhance effectiveness, TA-Rec introduces
Adaptive Preference Alignment (APA) that aligns the denoising process with user
preference adaptively based on preference pair similarity and timesteps.
Extensive experiments prove that TA-Rec's two-stage objective effectively
mitigates the discretization errors-induced trade-off, enhancing both
efficiency and effectiveness of diffusion-based recommenders.

</details>


### [55] [How role-play shapes relevance judgment in zero-shot LLM rankers](https://arxiv.org/abs/2510.17535)
*Yumeng Wang,Jirui Qi,Catherine Chen,Panagiotis Eustratiadis,Suzan Verberne*

Main category: cs.IR

TL;DR: 本文系统研究了角色扮演提示对零样本LLM排序器的影响，通过因果干预技术揭示了角色描述在早期层编码、与任务指令在中间层交互的机制，并识别了关键注意力头。


<details>
  <summary>Details</summary>
Motivation: 角色扮演提示能提升LLM排序器的鲁棒性和准确性，但其作用机制和多样性尚未充分探索，限制了有效使用和可解释性。

Method: 采用机制可解释性的因果干预技术，追踪角色扮演信息如何影响LLM的相关性判断，分析不同角色描述变体对排序质量的影响。

Result: 发现角色描述对排序质量有显著影响；角色信号主要在早期层编码，在中间层与任务指令交互，但与查询或文档表示的交互有限；识别了编码角色条件相关性信息的关键注意力头。

Conclusion: 研究揭示了角色扮演在LLM排序中的内部工作机制，为设计更有效的提示提供了指导，并指出了在零样本应用中利用角色扮演的广泛机会。

Abstract: Large Language Models (LLMs) have emerged as promising zero-shot rankers, but
their performance is highly sensitive to prompt formulation. In particular,
role-play prompts, where the model is assigned a functional role or identity,
often give more robust and accurate relevance rankings. However, the mechanisms
and diversity of role-play effects remain underexplored, limiting both
effective use and interpretability. In this work, we systematically examine how
role-play variations influence zero-shot LLM rankers. We employ causal
intervention techniques from mechanistic interpretability to trace how
role-play information shapes relevance judgments in LLMs. Our analysis reveals
that (1) careful formulation of role descriptions have a large effect on the
ranking quality of the LLM; (2) role-play signals are predominantly encoded in
early layers and communicate with task instructions in middle layers, while
receiving limited interaction with query or document representations.
Specifically, we identify a group of attention heads that encode information
critical for role-conditioned relevance. These findings not only shed light on
the inner workings of role-play in LLM ranking but also offer guidance for
designing more effective prompts in IR and beyond, pointing toward broader
opportunities for leveraging role-play in zero-shot applications.

</details>
